[{"content":"今天做了什么：\n创建项目 spring-cloud-examples，测试 spring cloud config 使用本地文件和 git 仓库作为配置中心 Spring Cloud Config使用本地文件和Git仓库作为配置中心 spring cloud config是一个基于http协议的远程配置实现方式。通过统一的配置管理服务器进行配置管理，客户端通过http协议主动的拉取服务的的配置信息，完成配置获取。\nSpring Cloud Config 支持以下几种存储方式：\nGit 仓库 本地文件 Vault JDBC 数据库 本地文件 服务端应用 使用 spring cli 创建一个 maven 项目\nmkdir spring-cloud-examples cd spring-cloud-examples mkdir config cd config spring init \\ --boot-version=3.2.2 \\ --type=maven-project \\ --java-version=8 \\ --name=config-server-file \\ --package-name=com.chensoul.springcloud \\ --groupId=com.chensoul.springcloud \\ --dependencies=cloud-config-server,actuator \\ config-server-file ​\t将 spring-boot-starter-parent 版本改为 2.7.18，对应的将 spring-cloud.version 改为 2021.0.9\n添加 @EnableConfigServer 注解\n@EnableConfigServer @SpringBootApplication public class ConfigServerFileApplication { public static void main(final String[] args) { SpringApplication.run(ConfigServerFileApplication.class, args); } } 修改配置文件\nserver: port: 8888 spring.application.name: config-server-file spring.profiles.active: native # default value: classpath:/, classpath:/config, file:./, file:./config spring.cloud.config.server.native.search-locations: file://${PWD}/config-repo 创建 config-repo 目录：\nmkdir config-repo 创建一个测试文件 foo.yml：\nfoo: hello world 启动应用\nspring cloud config server 暴露以下几个端点：\n/actuator /encrypt 和 /decrypt /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties 说明：\napplication：应用名称 profile：spring 的 profile label：git 仓库的分支名称 针对当前项目，可以访问的路径有：\ncurl localhost:8888/foo/native curl localhost:8888/foo-native.yml curl localhost:8888/foo-native.yaml curl localhost:8888/foo-native.properties #如果是git仓库保存配置文件，则可以访问以下路径 #curl localhost:8888/foo/native/master #curl localhost:8888/foo/native,default/master #curl localhost:8888/master/foo-native.properties 例如，访问 localhost:8888/foo/native :\n$ curl -s localhost:8888/foo/native | jq { \u0026#34;name\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;profiles\u0026#34;: [ \u0026#34;native\u0026#34; ], \u0026#34;label\u0026#34;: null, \u0026#34;version\u0026#34;: null, \u0026#34;state\u0026#34;: null, \u0026#34;propertySources\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;file:/Users/chensoul/workspace/IdeaProjects/spring-cloud-examples/config-repo/foo.yml\u0026#34;, \u0026#34;source\u0026#34;: { \u0026#34;foo\u0026#34;: \u0026#34;hello world\u0026#34; } } ] } 访问 http://localhost:8888/actuator/env 可以查看所有 propertySources 配置：\n$ curl -s localhost:8080/actuator/env | jq { \u0026#34;activeProfiles\u0026#34;: [ \u0026#34;native\u0026#34; ], \u0026#34;propertySources\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;server.ports\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;local.server.port\u0026#34;: { \u0026#34;value\u0026#34;: 8888 } } }, { \u0026#34;name\u0026#34;: \u0026#34;servletContextInitParams\u0026#34;, \u0026#34;properties\u0026#34;: {} }, { \u0026#34;name\u0026#34;: \u0026#34;systemProperties\u0026#34;, \u0026#34;properties\u0026#34;: { } }, { \u0026#34;name\u0026#34;: \u0026#34;systemEnvironment\u0026#34;, \u0026#34;properties\u0026#34;: { } }, { \u0026#34;name\u0026#34;: \u0026#34;configServerClient\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;spring.cloud.config.enabled\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;false\u0026#34; } } }, { \u0026#34;name\u0026#34;: \u0026#34;springCloudClientHostInfo\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;spring.cloud.client.hostname\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;192.168.3.214\u0026#34; }, \u0026#34;spring.cloud.client.ip-address\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;192.168.3.214\u0026#34; } } }, { \u0026#34;name\u0026#34;: \u0026#34;Config resource \u0026#39;class path resource [application.yml]\u0026#39; via location \u0026#39;optional:classpath:/\u0026#39;\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;server.port\u0026#34;: { \u0026#34;value\u0026#34;: 8888, \u0026#34;origin\u0026#34;: \u0026#34;class path resource [application.yml] - 2:9\u0026#34; }, \u0026#34;spring.profiles.active\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;native\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;class path resource [application.yml] - 6:13\u0026#34; }, \u0026#34;spring.cloud.config.server.native.search-locations\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;file:/Users/chensoul/workspace/IdeaProjects/spring-cloud-examples/config-repo\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;class path resource [application.yml] - 9:53\u0026#34; }, \u0026#34;management.endpoints.web.exposure.include\u0026#34;: { \u0026#34;value\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;origin\u0026#34;: \u0026#34;class path resource [application.yml] - 15:18\u0026#34; }, \u0026#34;management.endpoint.env.post.enabled\u0026#34;: { \u0026#34;value\u0026#34;: true, \u0026#34;origin\u0026#34;: \u0026#34;class path resource [application.yml] - 19:18\u0026#34; } } } ] } propertySources 包括：\nserver.ports servletContextInitParams systemProperties systemEnvironment configServerClient springCloudClientHostInfo \u0026lsquo;optional:classpath:/\u0026rsquo; 中的 application.yml 开启 Security\n添加 security 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 修改配置文件，设置用户名和密码：\nspring.security.user.name: ${SPRING_SECURITY_USER_NAME:root} spring.security.user.password: ${SPRING_SECURITY_USER_PASSWORD:123456} 或者通过环境变量 SPRING_SECURITY_USER_NAME、SPRING_SECURITY_USER_PASSWORD 进行设置\n重启应用，查看 foo.yml 文件内容：\n$ curl http://root:123456@localhost:8888/foo/native -s | jq test: hello world 加密解密敏感信息\n支持两种配置方式：\n第一种，对称加密。配置加密 key 和 salt\nencrypt: key: 123456 salt: deadbeef 或者通过环境变量 ENCRYPT_KEY 进行设置\n第二种，分对称加密。\n生成 keystore 文件：\ncd config-server-file/src/main/resources keytool -genkeypair -alias mytestkey -storetype PKCS12 -keyalg RSA -dname \u0026#34;CN=Web Server,OU=Unit,O=Organization,L=City,S=State,C=US\u0026#34; -keypass changeme -keystore server.jks -storepass changeme 添加配置：\nencrypt: key-store: location: classpath:server.jks password: changeme alias: mytestkey secret: changeme 使用第一种配置方式，重启应用，然后测试。加密 \u0026ldquo;hello world\u0026rdquo;：\n$ curl -s http://root:123456@localhost:8888/encrypt --data-urlencode \u0026#34;hello world\u0026#34; 1245fd945d0a14e529a0cafe0b6367206d69cad381d4d733ba21d348a303865e 解密：\n$ curl -s http://root:123456@localhost:8888/decrypt -d 1245fd945d0a14e529a0cafe0b6367206d69cad381d4d733ba21d348a303865e hello world 在配置文件使用加密字符串。修改 foo.yml 中 test 的值为上面生成的加密字符串：\nfoo: \u0026#39;{cipher}1245fd945d0a14e529a0cafe0b6367206d69cad381d4d733ba21d348a303865e\u0026#39; 重启应用，查看 foo.yml 文件内容：\n$ curl http://root:123456@localhost:8888/foo/native -s | jq foo: hello world 配置高可用\n有两种方式：\nspring.cloud.config.uri 配置多个地址，使用逗号分隔 注册到注册中心，部署多实例 客户端应用 使用 spring cli 创建一个 maven 项目\nspring init \\ --boot-version=3.2.2 \\ --type=maven-project \\ --java-version=8 \\ --name=config-server-file-client \\ --package-name=com.chensoul.springcloud \\ --groupId=com.chensoul.springcloud \\ --dependencies=cloud-config-client,web,actuator \\ config-client 将 spring-boot-starter-parent 版本改为 2.7.18，对应的将 spring-cloud.version 改为 2021.0.9\n修改配置文件\n# 1. 默认从 http://localhost:8888 获取配置 # 2. 如果没有配置 optional: 则 Config Client 连接不到 Config Server 时就会失败 # 3. import 配置优先于 uri 配置 # 4. 配置了后就不需要 bootstrap 引导文件 spring.config.import: \u0026#34;optional:configserver:\u0026#34; spring.application.name: config-client spring: cloud: config: uri: http://localhost:8888 # WARNING: Exposing all management endpoints over http should only be used during development, must be locked down in production! management.endpoint.health.show-details: \u0026#34;ALWAYS\u0026#34; management.endpoints.web.exposure.include: \u0026#34;*\u0026#34; 在 config-repo 目录添加客户端配置文件 config-client.yml\ntest: hello world 添加一个 controller：\n@RefreshScope @RestController @SpringBootApplication public class ConfigClientApplication { @Value(\u0026#34;${test}\u0026#34;) private String test; @GetMapping(\u0026#34;/test\u0026#34;) public String test() { return this.test; } public static void main(final String[] args) { SpringApplication.run(ConfigFileClientApplication.class, args); } } 启动应用，查看 test 的值\n$ curl http://localhost:8080/test hello world 配置重试\n添加 spring-retry 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.retry\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-retry\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 修改配置添加重试参数：\n# 1. 默认从 http://localhost:8888 获取配置 # 2. 如果没有配置 optional: 则 Config Client 连接不到 Config Server 时就会失败 # 3. import 配置优先于 uri 配置 # 4. 配置了后就不需要 bootstrap 引导文件 spring.config.import: \u0026#34;optional:configserver:\u0026#34; spring.application.name: config-client spring: cloud: config: # 配置重试，需要引入 spring-retry retry: initialInterval: 1000 multiplier: 1.1 maxInterval: 10000 maxAttempts: 6 uri: http://localhost:8888 注意：重试参数也可以添加到 url 后面：\nspring.config.import: configserver:http://configserver.example.com?fail-fast=true\u0026amp;max-attempts=10\u0026amp;max-interval=1500\u0026amp;multiplier=1.2\u0026amp;initial-interval=1100\u0026#34; 配置其他参数\n配置客户端快速失败和连接超时：\n# 1. 默认从 http://localhost:8888 获取配置 # 2. 如果没有配置 optional: 则 Config Client 连接不到 Config Server 时就会失败 # 3. import 配置优先于 uri 配置 # 4. 配置了后就不需要 bootstrap 引导文件 spring.config.import: \u0026#34;optional:configserver:\u0026#34; spring.application.name: config-client spring: cloud: config: # 客户端配置快速失败 fail-fast: true # 配置重试，需要引入 spring-retry retry: initialInterval: 1000 multiplier: 1.1 maxInterval: 10000 maxAttempts: 6 uri: http://localhost:8888 request-connect-timeout: 3000 request-read-timeout: 3000 开启 Security\n添加 security 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 修改配置文件，添加 用户名和密码：\nspring.security.user.name: ${SPRING_SECURITY_USER_NAME:root} spring.security.user.password: ${SPRING_SECURITY_USER_PASSWORD:123456} 再次查看 test 的值，需要设置用户名和密码：\n$ curl http://root:123456@localhost:8080/test hello world Git 仓库 服务端应用 使用 spring cli 创建一个 maven 项目\ncd config spring init \\ --boot-version=3.2.2 \\ --type=maven-project \\ --java-version=8 \\ --name=config-server-git \\ --package-name=com.chensoul.springcloud \\ --groupId=com.chensoul.springcloud \\ --dependencies=cloud-config-server,actuator,security \\ config-server-git ​\t将 spring-boot-starter-parent 版本改为 2.7.18，对应的将 spring-cloud.version 改为 2021.0.9\n添加 @EnableConfigServer 注解\n@EnableConfigServer @SpringBootApplication public class ConfigServerGitApplication { public static void main(final String[] args) { SpringApplication.run(ConfigServerGitApplication.class, args); } } 修改配置文件\n将 application.properties 重命名为 application.yml，并添加如下配置\nserver: port: 8888 spring.application.name: config-server-git spring.cloud.config.server.git.uri: https://github.com/chensoul/spring-cloud-examples spring.cloud.config.server.git.search-paths: config-repo spring.cloud.config.server.git.default-label: cloud-config spring.security.user.name: ${SPRING_SECURITY_USER_NAME:root} spring.security.user.password: ${SPRING_SECURITY_USER_PASSWORD:123456} encrypt: key: 123456 # WARNING: Exposing all management endpoints over http should only be used during development, must be locked down in production! management.endpoint.health.show-details: \u0026#34;ALWAYS\u0026#34; management.endpoints.web.exposure.include: \u0026#34;*\u0026#34; 配置认证\n如果是私有仓库，则需要配置认证。\n可以使用用户名密码的方式：\nspring.cloud.config.server.git.username: username spring.cloud.config.server.git.password: password 或者使用 ssh 私钥，配置方式，请参考 Git SSH configuration using properties。\n其他配置参数\nspring: cloud: config: server: git: uri: file:${PWD}/config-repo skipSslValidation: true timeout: 4 force-pull: true deleteUntrackedBranches: true refreshRate: 0 defaultLabel: main tryMasterBranch: false 启动应用\n客户端应用 在 config-client 项目基础上，修改配置文件\n因为服务端配置文件是在 cloud-config 分区（spring.cloud.config.server.git.default-label: cloud-config），故客户端也应该设置分区 spring.cloud.config.label: cloud-config：\n# 1. 默认从 http://localhost:8888 获取配置 # 2. 如果没有配置 optional: 则 Config Client 连接不到 Config Server 时就会失败 # 3. import 配置优先于 uri 配置 # 4. 配置了后就不需要 bootstrap 引导文件 spring.config.import: \u0026#34;optional:configserver:\u0026#34; spring.application.name: config-client spring: cloud: config: # 客户端配置快速失败 fail-fast: true # 配置重试，需要引入 spring-retry retry: initialInterval: 1000 multiplier: 1.1 maxInterval: 10000 maxAttempts: 6 uri: http://localhost:8888 label: cloud-config spring.security.user.name: ${SPRING_SECURITY_USER_NAME:root} spring.security.user.password: ${SPRING_SECURITY_USER_PASSWORD:123456} # WARNING: Exposing all management endpoints over http should only be used during development, must be locked down in production! management.endpoint.health.show-details: \u0026#34;ALWAYS\u0026#34; management.endpoints.web.exposure.include: \u0026#34;*\u0026#34; 重启应用，查看 test 的值\n$ curl http://root:123456@localhost:8080/test hello world 修改 config-client.yml 文件中 test 的值为 \u0026ldquo;hello world 1111\u0026rdquo;，并提交到 git 仓库。然后，再次查看 test 的值：\n$ curl http://root:123456@localhost:8080/test hello world 发现 test 值并没有更新，这时候需要手动更新\n手动更新配置\ncurl -X POST http://localhost:8080/actuator/refresh 再次访问，发现 test 值已修改为 \u0026ldquo;hello world 1111\u0026rdquo;：\n$ curl http://root:123456@localhost:8080/test hello world 1111 ","permalink":"https://blog.chensoul.cc/posts/2024/02/05/til/","summary":"今天做了什么：\n创建项目 spring-cloud-examples，测试 spring cloud config 使用本地文件和 git 仓库作为配置中心 Spring Cloud Config使用本地文件和Git仓库作为配置中心 spring cloud config是一个基于http协议的远程配置实现方式。通过统一的配置管理服务器进行配置管理，客户端通过http协议主动的拉取服务的的配置信息，完成配置获取。\nSpring Cloud Config 支持以下几种存储方式：\nGit 仓库 本地文件 Vault JDBC 数据库 本地文件 服务端应用 使用 spring cli 创建一个 maven 项目\nmkdir spring-cloud-examples cd spring-cloud-examples mkdir config cd config spring init \\ --boot-version=3.2.2 \\ --type=maven-project \\ --java-version=8 \\ --name=config-server-file \\ --package-name=com.chensoul.springcloud \\ --groupId=com.chensoul.springcloud \\ --dependencies=cloud-config-server,actuator \\ config-server-file ​\t将 spring-boot-starter-parent 版本改为 2.7.18，对应的将 spring-cloud.version 改为 2021.0.9\n添加 @EnableConfigServer 注解\n@EnableConfigServer @SpringBootApplication public class ConfigServerFileApplication { public static void main(final String[] args) { SpringApplication.run(ConfigServerFileApplication.class, args); } } 修改配置文件\nserver: port: 8888 spring.application.name: config-server-file spring.profiles.active: native # default value: classpath:/, classpath:/config, file:.","title":"2024-02-05｜Spring Cloud Config使用本地文件和Git仓库作为配置中心"},{"content":"今天做了什么：\n重构 foodie-cloud 项目\n集成 Resilience4j 修改 README.md 文档 阅读博客 https://blog.csdn.net/weixin_42189048\nEnum + Validation 的个人最佳实践 demo 分享 ","permalink":"https://blog.chensoul.cc/posts/2024/02/04/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目\n集成 Resilience4j 修改 README.md 文档 阅读博客 https://blog.csdn.net/weixin_42189048\nEnum + Validation 的个人最佳实践 demo 分享 ","title":"2024-02-04｜foodie-cloud集成Resilience4j"},{"content":"今天做了什么：\n参考 《Microservices with Spring Boot 3 and Spring Cloud》，重构 foodie-cloud 项目 集成 Spring Cloud Config 使用文件保存配置文件\n集成 SpringDoc OpenAPI 基于 Javadoc 生成 API 文档\ntodo：\n集成 Resilience4j\n集成 Zipkin\n部署到 Kubernetes\n集成 EFK\n集成 Spring Cloud Bus\n","permalink":"https://blog.chensoul.cc/posts/2024/02/02/til/","summary":"今天做了什么：\n参考 《Microservices with Spring Boot 3 and Spring Cloud》，重构 foodie-cloud 项目 集成 Spring Cloud Config 使用文件保存配置文件\n集成 SpringDoc OpenAPI 基于 Javadoc 生成 API 文档\ntodo：\n集成 Resilience4j\n集成 Zipkin\n部署到 Kubernetes\n集成 EFK\n集成 Spring Cloud Bus","title":"2024-02-02｜foodie-cloud集成Spring Cloud Config和SpringDoc"},{"content":"今天做了什么：\n重构 foodie-cloud 项目，部署到 docker 容器 使用 Spring Initializr 创建项目 使用 Spring Initializr 创建项目 安装 spring cli\n使用 brew 安装的 spring cli 版本是 3.x 版本\nbrew tap pivotal/tap brew install springboot 使用 sdkman 安装：\nsdk install springboot 3.2.2 查看版本：\n$ spring version Spring CLI v3.2.2 查看 spring cli 支持的命令\nspring help 查看 init 命令说明：\nspring help init 参考 spring init 命令：\nspring init --list 可以看到支持的依赖\nactivemq actuator amqp artemis azure-active-directory azure-cosmos-db azure-keyvault azure-storage azure-support batch cache camel cloud-bus cloud-config-client cloud-config-server cloud-contract-stub-runner cloud-contract-verifier cloud-eureka cloud-eureka-server cloud-feign cloud-function cloud-gateway cloud-gateway-reactive cloud-gcp cloud-gcp-pubsub cloud-gcp-storage cloud-loadbalancer cloud-resilience4j cloud-starter cloud-starter-consul-config cloud-starter-consul-discovery cloud-starter-vault-config cloud-starter-zookeeper-config cloud-starter-zookeeper-discovery cloud-stream cloud-task codecentric-spring-boot-admin-client codecentric-spring-boot-admin-server configuration-processor data-cassandra data-cassandra-reactive data-couchbase data-couchbase-reactive data-elasticsearch data-jdbc data-jpa data-ldap data-mongodb data-mongodb-reactive data-neo4j data-r2dbc data-redis data-redis-reactive data-rest data-rest-explorer datadog db2 derby devtools dgs-codegen distributed-tracing docker-compose dynatrace flyway freemarker graphite graphql groovy-templates h2 hateoas hilla hsql influx integration jdbc jersey jooq kafka kafka-streams liquibase lombok mail mariadb modulith mustache mybatis mysql native new-relic oauth2-authorization-server oauth2-client oauth2-resource-server okta oracle picocli postgresql prometheus pulsar pulsar-reactive quartz restdocs rsocket scs-config-client scs-service-registry security sentry session solace spring-shell sqlserver testcontainers thymeleaf timefold-solver unboundid-ldap vaadin validation wavefront web web-services webflux websocket zipkin 支持的构建系统有：\ngradle-build gradle-project gradle-project-kotlin maven-build maven-project 支持的参数有：\nartifactId bootVersion description groupId javaVersion language name packageName packaging type version 创建项目 spring init 使用的是 start.spring.io 创建项目，而目前 start.spring.io 支持的 spring boot 版本最低为 3.1.0。如果想创建 spring boot2 的项目，需要创建项目之后手动修改版本号。\nspring init \\ --boot-version=3.2.2 \\ --type=maven-project \\ --java-version=8 \\ --name=config-file \\ --package-name=com.chensoul.springcloud \\ --groupId=com.chensoul.springcloud \\ --dependencies=cloud-config-server \\ config-file ","permalink":"https://blog.chensoul.cc/posts/2024/02/01/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目，部署到 docker 容器 使用 Spring Initializr 创建项目 使用 Spring Initializr 创建项目 安装 spring cli\n使用 brew 安装的 spring cli 版本是 3.x 版本\nbrew tap pivotal/tap brew install springboot 使用 sdkman 安装：\nsdk install springboot 3.2.2 查看版本：\n$ spring version Spring CLI v3.2.2 查看 spring cli 支持的命令\nspring help 查看 init 命令说明：\nspring help init 参考 spring init 命令：\nspring init --list 可以看到支持的依赖\nactivemq actuator amqp artemis azure-active-directory azure-cosmos-db azure-keyvault azure-storage azure-support batch cache camel cloud-bus cloud-config-client cloud-config-server cloud-contract-stub-runner cloud-contract-verifier cloud-eureka cloud-eureka-server cloud-feign cloud-function cloud-gateway cloud-gateway-reactive cloud-gcp cloud-gcp-pubsub cloud-gcp-storage cloud-loadbalancer cloud-resilience4j cloud-starter cloud-starter-consul-config cloud-starter-consul-discovery cloud-starter-vault-config cloud-starter-zookeeper-config cloud-starter-zookeeper-discovery cloud-stream cloud-task codecentric-spring-boot-admin-client codecentric-spring-boot-admin-server configuration-processor data-cassandra data-cassandra-reactive data-couchbase data-couchbase-reactive data-elasticsearch data-jdbc data-jpa data-ldap data-mongodb data-mongodb-reactive data-neo4j data-r2dbc data-redis data-redis-reactive data-rest data-rest-explorer datadog db2 derby devtools dgs-codegen distributed-tracing docker-compose dynatrace flyway freemarker graphite graphql groovy-templates h2 hateoas hilla hsql influx integration jdbc jersey jooq kafka kafka-streams liquibase lombok mail mariadb modulith mustache mybatis mysql native new-relic oauth2-authorization-server oauth2-client oauth2-resource-server okta oracle picocli postgresql prometheus pulsar pulsar-reactive quartz restdocs rsocket scs-config-client scs-service-registry security sentry session solace spring-shell sqlserver testcontainers thymeleaf timefold-solver unboundid-ldap vaadin validation wavefront web web-services webflux websocket zipkin 支持的构建系统有：","title":"2024-02-01｜使用 Spring Initializr 创建项目"},{"content":"今天做了什么：\n下载 《Microservices with Spring Boot 3 and Spring Cloud》，源码在 github\nRedis 事务\nRedis事务 原理 Redis 是一个内存数据库，它支持事务操作。Redis 事务是一系列的命令操作，这些命令会被一起执行，要么全部成功，要么全部失败。在事务执行期间，其他客户端提交的命令不会被插入到事务中，确保事务的原子性。\nRedis 事务使用以下命令进行管理：\nMULTI：标记事务的开始。 EXEC：执行事务中的所有命令。 DISCARD：取消事务，放弃之前的所有命令。 WATCH：监视一个或多个键，如果在事务执行之前有其他客户端对这些键进行了修改，则事务会被中止。 UNWATCH：取消对所有键的监视。 在执行事务之前，先使用 MULTI 命令标记事务的开始，然后按顺序执行多个命令。在所有命令都被添加到事务队列之后，使用 EXEC 命令来执行事务中的所有命令。如果执行成功，事务中的所有命令会被一起执行，然后返回结果。如果在执行事务期间发生错误，事务会被中止，所有的修改都会被回滚。\n示例 以下是一个使用 Redis 事务的示例：\n#开启事务 MULTI SET key1 \u0026#34;value1\u0026#34; SET key2 \u0026#34;value2\u0026#34; GET key1 GET key2 #执行事务 EXEC # 取消事务 discard 上述事务包含了两个 SET 命令和两个 GET 命令。在 EXEC 命令执行之后，将会依次执行这些命令，并返回相应的结果。\n需要注意的是，Redis 的事务是乐观锁，并不会在执行期间对键进行加锁。因此，在使用事务时要注意并发操作可能引发的竞态条件。\nRedis对于命令执行错误处理，有两种解决方式：\n语法错误（编译） 执行错误（运行） 语法错误：执行命令的语法不正确。\n#开启事务 multi #命令 set name zhangsan set age seterror sex male #执行事务 exec #获取正确指令数据 get name 此时整个事务队列中，存在一条正确指令，两条语法错误指令， 当执行exec后，会直接返回错误，正确的命令也不会执行。\n执行错误：命令在运行过程中出现错误。\n#开启事务 multi #命令 set lesson java rpush lesson eureka feign nacos set lesson redis #执行事务 exec #获取数据 get lesson 通过上面事务执行可以看到，语法本身是没有问题的，所以运行之前redis无法发现错误，但是在执行时出现了错误，因此只会错误的命令不执行， 而正确的命令仍然能够正常执行。\nSpringBoot实现事务操作 1）修改RedisConfig配置类，开启事务控制\n@Configuration public class RedisConfig { @Autowired private RedisConnectionFactory redisConnectionFactory; @Bean public RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate() { RedisTemplate\u0026lt;String, Object\u0026gt; template = new RedisTemplate\u0026lt;\u0026gt;(); template.setConnectionFactory(redisConnectionFactory); // 设置序列化器等其他配置... template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new GenericJackson2JsonRedisSerializer()); //开启redis事务控制 template.setEnableTransactionSupport(true); return template; } } 2）自定义方法，测试事务效果\n@Test public void multiTest(){ //开启事务 redisTemplate.multi(); try{ redisTemplate.opsForValue().set(\u0026#34;lesson\u0026#34;,\u0026#34;java\u0026#34;); redisTemplate.opsForSet().add(\u0026#34;lesson\u0026#34;,\u0026#34;eureka\u0026#34;,\u0026#34;feign\u0026#34;,\u0026#34;gateway\u0026#34;); redisTemplate.opsForValue().set(\u0026#34;lesson\u0026#34;,\u0026#34;redis\u0026#34;); System.out.println(redisTemplate.opsForValue().get(\u0026#34;lesson\u0026#34;)); }catch (Exception e){ //回滚 System.out.println(\u0026#34;出现异常\u0026#34;); redisTemplate.discard(); }finally { redisTemplate.exec(); } } FAQ Redis 事务的原子性是如何保证的？ Redis 事务的原子性是通过 Redis 的单线程执行和乐观锁来保证的。\n在 Redis 中，事务的执行是通过将多个命令按顺序放入事务队列中，然后由 Redis 依次执行这些命令。在事务执行期间，Redis 会确保其他客户端提交的命令不会被插入到当前事务中，从而保证事务的原子性。\n当执行 EXEC 命令时，Redis 会按照顺序执行事务队列中的所有命令，并返回每个命令的执行结果。如果在执行期间出现错误，例如其中一个命令返回了错误，Redis 会终止事务的执行，并返回相应的错误信息。\n此外，Redis 使用乐观锁来保证事务的原子性。在事务执行期间，Redis 不会对事务中的键进行加锁。相反，Redis 会在执行事务之前使用 WATCH 命令监视一个或多个键。如果在事务执行期间有其他客户端对这些被监视的键进行了修改，Redis 会中止事务的执行，并返回一个错误。通过使用乐观锁，Redis 确保了事务在执行期间不会被其他客户端的修改所干扰。\n需要注意的是，Redis 的事务并不是隔离的，即事务执行期间其他客户端提交的命令仍然可以修改事务中的键。因此，在使用 Redis 事务时，需要注意并发操作可能引发的竞态条件。如果需要更严格的隔离性，可以使用 Redis 的 WATCH 和 MULTI 命令结合 Lua 脚本来实现更复杂的事务逻辑。\nRedis 事务的乐观锁是如何工作的？ Redis 的事务乐观锁机制是通过 WATCH 命令和检测事务执行期间键的变化来实现的。\n当调用 WATCH 命令时，Redis 会监视一个或多个键。在事务执行期间，如果任何被监视的键发生了变化（被其他客户端修改），Redis 将中止事务的执行。\n以下是乐观锁在 Redis 事务中的工作原理：\n客户端调用 WATCH 命令，指定要监视的键。 Redis 开始监视这些键，并记录它们的当前值。 客户端开始执行事务中的命令。 在执行 EXEC 命令之前，Redis 检查被监视的键是否发生了变化。 如果任何被监视的键发生了变化，Redis 中止事务的执行，并返回一个错误。 如果被监视的键没有发生变化，则 Redis 执行事务中的命令，并返回结果。 乐观锁的关键在于在执行 EXEC 命令之前检查键的变化。如果在事务执行期间，有其他客户端修改了被监视的键，那么 Redis 会中止事务的执行，因为它无法保证事务的原子性。\n需要注意的是，乐观锁并不会对被监视的键进行加锁。它只是在事务执行之前检查键的变化情况。这意味着其他客户端仍然可以修改被监视的键，但是当事务执行时，如果键发生了变化，事务将被中止。\n乐观锁在 Redis 事务中的应用场景是保证在执行事务期间被监视的键没有被其他客户端修改。如果需要更严格的隔离性，可以结合使用 WATCH 和 MULTI 命令以及 Lua 脚本来实现更复杂的事务逻辑。\nRedis 事务是否支持嵌套？ 在 Redis 中，事务是不支持嵌套的。也就是说，你不能在一个事务中开启另一个事务。\n当你调用 MULTI 命令开始一个事务后，后续的命令都会被添加到当前事务队列中，直到调用 EXEC 命令执行事务。事务中的命令会按照顺序执行，要么全部成功，要么全部失败。\n虽然 Redis 提供了 MULTI 和 EXEC 命令来支持事务，但这并不意味着事务的嵌套。如果在一个事务中调用 MULTI 命令开启另一个事务，实际上仍然是在当前事务中执行了一个 MULTI 命令，而不是启动了一个新的嵌套事务。因此，嵌套事务的概念在 Redis 中并不存在。\n如果你需要在 Redis 中进行复杂的操作，可以使用 Lua 脚本来实现。Lua 脚本可以在一个原子性操作中执行多个 Redis 命令，并且支持条件判断和流程控制，以满足更复杂的业务需求。\nRedis 是否支持回滚事务？ 在 Redis 中，事务是支持回滚的。当事务执行过程中发生错误或者通过客户端显式地调用 DISCARD 命令时，Redis 将会回滚事务中的所有命令，将数据恢复到事务执行之前的状态。\n以下是 Redis 中回滚事务的情况：\n当事务执行过程中发生错误时，比如其中一个命令返回了错误，Redis 将自动中止事务的执行，并丢弃事务队列中尚未执行的命令。这样可以确保事务的原子性，未执行的命令不会对数据产生影响。 客户端可以显式地调用 DISCARD 命令来取消事务，放弃之前的所有命令。这将导致 Redis 丢弃事务队列中的所有命令，并将数据恢复到事务开始之前的状态。 需要注意的是，Redis 的事务回滚只会影响当前连接的事务，不会对其他客户端产生影响。如果一个客户端在执行事务期间发生错误或者回滚，其他客户端的操作不会受到影响，它们仍然可以正常地操作和访问 Redis 数据库。\n另外，需要注意的是 Redis 的事务并不是隔离的，即事务执行期间其他客户端提交的命令仍然可以修改事务中的键。因此，在使用 Redis 事务时，需要注意并发操作可能引发的竞态条件。如果需要更严格的隔离性，可以结合使用 WATCH 和 MULTI 命令以及 Lua 脚本来实现更复杂的事务逻辑和控制。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/31/til/","summary":"今天做了什么：\n下载 《Microservices with Spring Boot 3 and Spring Cloud》，源码在 github\nRedis 事务\nRedis事务 原理 Redis 是一个内存数据库，它支持事务操作。Redis 事务是一系列的命令操作，这些命令会被一起执行，要么全部成功，要么全部失败。在事务执行期间，其他客户端提交的命令不会被插入到事务中，确保事务的原子性。\nRedis 事务使用以下命令进行管理：\nMULTI：标记事务的开始。 EXEC：执行事务中的所有命令。 DISCARD：取消事务，放弃之前的所有命令。 WATCH：监视一个或多个键，如果在事务执行之前有其他客户端对这些键进行了修改，则事务会被中止。 UNWATCH：取消对所有键的监视。 在执行事务之前，先使用 MULTI 命令标记事务的开始，然后按顺序执行多个命令。在所有命令都被添加到事务队列之后，使用 EXEC 命令来执行事务中的所有命令。如果执行成功，事务中的所有命令会被一起执行，然后返回结果。如果在执行事务期间发生错误，事务会被中止，所有的修改都会被回滚。\n示例 以下是一个使用 Redis 事务的示例：\n#开启事务 MULTI SET key1 \u0026#34;value1\u0026#34; SET key2 \u0026#34;value2\u0026#34; GET key1 GET key2 #执行事务 EXEC # 取消事务 discard 上述事务包含了两个 SET 命令和两个 GET 命令。在 EXEC 命令执行之后，将会依次执行这些命令，并返回相应的结果。\n需要注意的是，Redis 的事务是乐观锁，并不会在执行期间对键进行加锁。因此，在使用事务时要注意并发操作可能引发的竞态条件。\nRedis对于命令执行错误处理，有两种解决方式：\n语法错误（编译） 执行错误（运行） 语法错误：执行命令的语法不正确。\n#开启事务 multi #命令 set name zhangsan set age seterror sex male #执行事务 exec #获取正确指令数据 get name 此时整个事务队列中，存在一条正确指令，两条语法错误指令， 当执行exec后，会直接返回错误，正确的命令也不会执行。\n执行错误：命令在运行过程中出现错误。\n#开启事务 multi #命令 set lesson java rpush lesson eureka feign nacos set lesson redis #执行事务 exec #获取数据 get lesson 通过上面事务执行可以看到，语法本身是没有问题的，所以运行之前redis无法发现错误，但是在执行时出现了错误，因此只会错误的命令不执行， 而正确的命令仍然能够正常执行。","title":"2024-01-31｜Redis事务"},{"content":"今天做了什么：\n重构 foodie-cloud 项目 参考 DDD 组织包结构 Mybatis plus 配置主键生成策略和数据审计功能 Jackson 配置日期序列化 重构 foodie-cloud 项目 Mybatis plus 配置主键生成策略 实体类中可以不用添加@TableId，减少实体类对 mybatis-plus-annotation的依赖\npublic class BaseEntity implements Serializable { private Long id; private LocalDateTime createTime; private LocalDateTime updateTime; } 改为使用配置：\nmybatis-plus: global-config: db-config: id-type: ASSIGN_ID Mybatis plus 配置数据审计功能 添加下面的类\n@Component @Slf4j public class CustomMetaObjecthandler implements MetaObjectHandler { protected static void fillValIfNullByName( final String fieldName,final Object fieldVal, final MetaObject metaObject,final boolean isCover) { // 1. 没有 set 方法 if (!metaObject.hasSetter(fieldName)) { return; } // 2. 如果用户有手动设置的值 if (metaObject.getValue(fieldName) != null \u0026amp;\u0026amp; !isCover) { return; } // 3. field 类型相同时设置 final Class\u0026lt;?\u0026gt; getterType = metaObject.getGetterType(fieldName); if (ClassUtils.isAssignableValue(getterType, fieldVal)) { metaObject.setValue(fieldName, fieldVal); } } @Override public void insertFill(final MetaObject metaObject) { final LocalDateTime now = LocalDateTime.now(); final String username = SecurityContextHolder.getContext().getAuthentication().getName(); log.info(\u0026#34;公共字段自动填充[insert]: {},{}\u0026#34;, now, username); fillValIfNullByName(\u0026#34;createTime\u0026#34;, now, metaObject, false); fillValIfNullByName(\u0026#34;createUser\u0026#34;, username, metaObject, false); } @Override public void updateFill(final MetaObject metaObject) { final LocalDateTime now = LocalDateTime.now(); final String username = SecurityContextHolder.getContext().getAuthentication().getName(); log.info(\u0026#34;公共字段自动填充[update]: {},{}\u0026#34;, now, username); fillValIfNullByName(\u0026#34;updateTime\u0026#34;, now, metaObject, true); fillValIfNullByName(\u0026#34;updateUser\u0026#34;, username, metaObject, true); } } 并在实体类上的对应属性添加注解：\n@Getter @Setter public class BaseEntity implements Serializable { private static final long serialVersionUID = 6595513467381653081L; private Long id; @TableField(fill = FieldFill.INSERT) private LocalDateTime createTime; @TableField(fill = FieldFill.INSERT_UPDATE) private LocalDateTime updateTime; } Jackson 配置日期序列化 自定义一个 ObjectMapper：\npublic class CustomObjectMapper extends ObjectMapper { public static final String DEFAULT_DATE_FORMAT = \u0026#34;yyyy-MM-dd\u0026#34;; public static final String DEFAULT_DATE_TIME_FORMAT = \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;; public static final String DEFAULT_TIME_FORMAT = \u0026#34;HH:mm:ss\u0026#34;; public CustomObjectMapper() { //收到未知属性时不报异常 this.configure(FAIL_ON_UNKNOWN_PROPERTIES, false); //反序列化时，属性不存在的兼容处理 this.getDeserializationConfig().withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); final SimpleModule simpleModule = new SimpleModule() .addSerializer(BigInteger.class, ToStringSerializer.instance) .addSerializer(Long.class, ToStringSerializer.instance) .addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))) .addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_TIME_FORMAT))) .addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(DEFAULT_DATE_FORMAT))) .addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(DEFAULT_TIME_FORMAT))); //注册功能模块 例如，可以添加自定义序列化器和反序列化器 this.registerModule(simpleModule); } } 然后，注入的 spring 容器：\n@Configuration public class JacksonConfig { @Bean @Primary public ObjectMapper objectMapper() { return new CustomObjectMapper(); } } 这样，就可以不用在 LocalDateTime 类型的属性上添加 @JsonFormat 注解。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/30/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目 参考 DDD 组织包结构 Mybatis plus 配置主键生成策略和数据审计功能 Jackson 配置日期序列化 重构 foodie-cloud 项目 Mybatis plus 配置主键生成策略 实体类中可以不用添加@TableId，减少实体类对 mybatis-plus-annotation的依赖\npublic class BaseEntity implements Serializable { private Long id; private LocalDateTime createTime; private LocalDateTime updateTime; } 改为使用配置：\nmybatis-plus: global-config: db-config: id-type: ASSIGN_ID Mybatis plus 配置数据审计功能 添加下面的类\n@Component @Slf4j public class CustomMetaObjecthandler implements MetaObjectHandler { protected static void fillValIfNullByName( final String fieldName,final Object fieldVal, final MetaObject metaObject,final boolean isCover) { // 1. 没有 set 方法 if (!metaObject.hasSetter(fieldName)) { return; } // 2. 如果用户有手动设置的值 if (metaObject.getValue(fieldName) != null \u0026amp;\u0026amp; !isCover) { return; } // 3. field 类型相同时设置 final Class\u0026lt;?\u0026gt; getterType = metaObject.getGetterType(fieldName); if (ClassUtils.","title":"2024-01-30｜Mybatis plus和Jackson配置"},{"content":"今天做了什么：\n重构 foodie-cloud 项目\nC4 架构模型\nC4架构模型 C4 架构模型是一种简洁且易于理解的软件架构描述方法，由 Simon Brown 提出。C4 表示 Context, Containers, Components, and Code，这四个层级帮助我们组织和描述软件系统的不同抽象层次。\n以下是 C4 架构模型的四个层级：\nContext（上下文）：这是最高级别的层级，用于描述系统的整体环境和目标。在这个层级，我们关注系统与外部实体（如用户、其他系统、硬件设备等）的交互。可以使用上下文图（Context Diagram）来展示系统和相关实体之间的关系。 Containers（容器）：这个层级用于描述系统内部的主要逻辑组件，通常是一个独立的运行时进程或线程。容器可以是 Web 服务器、数据库、消息队列、桌面应用等，它们在系统中承担着不同的角色和责任。通过容器图（Container Diagram），我们可以展示系统中的容器及其之间的关系。 Components（组件）：这个层级用于进一步划分容器，描述容器内部的组织结构和组件之间的关系。组件是系统的构建块，代表了较细粒度的功能单元或模块。可以使用组件图（Component Diagram）来展示组件及其之间的关系。 Code（代码）：这个层级用于描述组件内部的代码结构和实现细节。在这个层级，我们可以使用类图、包图等来展示代码级别的结构和关系。 C4 架构模型通过层级化的方式，帮助我们从高级别到低级别逐步展示和描述软件系统的不同抽象层次，使得架构描述更加清晰和易于理解。它适用于不同规模和复杂度的软件系统，并且可以方便地与其他架构描述方法（如 UML）结合使用。\n参考资料：\n用于软件架构的C4模型 C4 模型- 可视化架构设计- lex-wu https://c4model.com/ ","permalink":"https://blog.chensoul.cc/posts/2024/01/29/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目\nC4 架构模型\nC4架构模型 C4 架构模型是一种简洁且易于理解的软件架构描述方法，由 Simon Brown 提出。C4 表示 Context, Containers, Components, and Code，这四个层级帮助我们组织和描述软件系统的不同抽象层次。\n以下是 C4 架构模型的四个层级：\nContext（上下文）：这是最高级别的层级，用于描述系统的整体环境和目标。在这个层级，我们关注系统与外部实体（如用户、其他系统、硬件设备等）的交互。可以使用上下文图（Context Diagram）来展示系统和相关实体之间的关系。 Containers（容器）：这个层级用于描述系统内部的主要逻辑组件，通常是一个独立的运行时进程或线程。容器可以是 Web 服务器、数据库、消息队列、桌面应用等，它们在系统中承担着不同的角色和责任。通过容器图（Container Diagram），我们可以展示系统中的容器及其之间的关系。 Components（组件）：这个层级用于进一步划分容器，描述容器内部的组织结构和组件之间的关系。组件是系统的构建块，代表了较细粒度的功能单元或模块。可以使用组件图（Component Diagram）来展示组件及其之间的关系。 Code（代码）：这个层级用于描述组件内部的代码结构和实现细节。在这个层级，我们可以使用类图、包图等来展示代码级别的结构和关系。 C4 架构模型通过层级化的方式，帮助我们从高级别到低级别逐步展示和描述软件系统的不同抽象层次，使得架构描述更加清晰和易于理解。它适用于不同规模和复杂度的软件系统，并且可以方便地与其他架构描述方法（如 UML）结合使用。\n参考资料：\n用于软件架构的C4模型 C4 模型- 可视化架构设计- lex-wu https://c4model.com/ ","title":"2024-01-29｜C4架构模型"},{"content":"今天做了什么：\n重构 foodie-cloud 项目\n集成 Feign 替换 RestTemplate 认证服务负责用户的维护和登录 整理 Feign、Eureka、Seata、Sentinel 相关文档\neureka分区的深入讲解 Spring Cloud Eureka详解 ","permalink":"https://blog.chensoul.cc/posts/2024/01/26/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目\n集成 Feign 替换 RestTemplate 认证服务负责用户的维护和登录 整理 Feign、Eureka、Seata、Sentinel 相关文档\neureka分区的深入讲解 Spring Cloud Eureka详解 ","title":"2024-01-26｜foodie-cloud集成Feign"},{"content":"今天做了什么：\n整理 Idea 快捷键 整理 zsh 中定义的常用的快捷键 Idea 快捷键 使用快捷键 command +1 打开 Project 窗口\n输入 control + R 可以运行 Java 代码\n上下文 在 for 方法上，输入 option + enter，可以调出上下文，替换 for 表达式\n在字符串上面输入 option + enter，可以调出上下文。\n在字符串上面或者双击选中，然后双击两次 ⇧ ，打开 Search Everywhere 弹窗，然后输入 case ，选择 Toggle Case 将 AVERAGE 变为小写。\n在没有使用的方法参数 redundant 上，输入 option + enter，可以选择 Safe delete 'redunant' 删除该参数\n在三目运算，输入 option + enter，可以选择 Negate '?:'\n搜索 查找最近文件：comand + E\n输入 ⇧ + command + A 可以打开 Find Action 窗口。\n双击两次 ⇧ 可以打开 Search Everywhere 窗口。输入关键字，可以搜索 java 类。\n如果想搜索Java类，则可以输入 command + O，并可以选择在 All Places 搜索。\n如果想搜索方法或者变量名称，则可以使用 option + command + O\n自动补全 command + ↑ + enter 补全方法体、if、while、for 、switch 后面括号\n以下代码，在 new 后面输入 Ran ，然后按 tab 键可以补全 Random，然后在括号内，按 control+space ，可以调出查找窗口，然后选择 PROCESS_ID，最后按 ⇧ + command + enter 完成\nclass BasicCompletionDemo { private int PROCESS_ID = 0; public void systemProcess(){ System.out.println(PROCESS_ID++); } public BasicCompletionDemo() { byte b = MAX_VALUE; } public void random() { Random random = new ; } } 输入一个表达式，然后按 . 键\ncontrol + ⇧ + space\n注释 输入 command + / ，注释当行代码。 选中一段代码块，输入 option + command + /，可以注释代码块。 在 java 里面，添加的是 /**/ 在 xml 里面，添加的是\u0026lt;!----\u0026gt; 代码 代码格式化\noption + command + L 格式化代码。\n对选中的代码，使用 option + command + L ，可以格式化代码。再使用该快捷键，可以对整个文件进行格式化。\n⇧+option + command + L 可以查看格式化代码的设置\ncommand + P 查看方法签名\nF1 查看方法的 Javadoc\noption + space 或者 command + Y 查看方法的定义\n使用 option + command + T 可以打开 Surround with 窗口；使用 option + command + del 可以打开 Unwrap 窗口\n重构 重命名 ⇧ + F6\n抽取变量 option + command + V\n抽取方法 option + command + M\n调出重构窗口 control + T\n复制和删掉代码 复制一行代码，使用 command + D\n按 ⇧ + ↑ 两次，可以选择两行，然后 使用 command + D，可以复制两行代码。\n如果要删除当前行代码，可以使用 command + del 快捷键。\n剪切行代码，使用 command + x\n复制代码，使用 command + c\n鼠标在某一行，输入 command + c 可以选中该行 选中 把鼠标停留在一个单词，输入 option + ↑，可以选择单词；再次输入 option + ↑，可以选择一句话；再次输入 option + ↑，可以选中整个字符串变量；再次输入 option + ↑，可以选择方法的所有变量；再次输入 option + ↑，可以选中方法加所有参数；再次输入 option + ↑，可以选中整行内容。\n使用 control + G 选中鼠标所在单词\n再次使用 control + G 选中下一个鼠标所在单词\n使用 control + ⇧ + G 取消选择上一个\n使用 control + command + G 选择所有出现鼠标所在单词，然后，输入一个单词，会替换所有选中的单词。\n移动代码 将当前行代码向上移：option + ⇧ + ↑\n将当前行代码向下移：option + ⇧ + ↓\n将当前方法向上移：command + ⇧ + ↑\n将当前方法向下移：command + ⇧ + ↓\n收缩代码 收缩代码：command + -\n展开代码：command + =\n收缩一个文件的所有代码：command + ⇧ + -\n展开一个文件的所有代码：command + ⇧ + =\nzsh中定义的快捷键 ~/.oh-my-zsh/plugins/git/git.plugin.zsh\nalias g=\u0026#39;git\u0026#39; alias ga=\u0026#39;git add\u0026#39; alias gaa=\u0026#39;git add --all\u0026#39; #将所有变更添加到暂存区 alias gapa=\u0026#39;git add --patch\u0026#39; #交互式的选中变更添加到暂存区 #分支相关 alias gb=\u0026#39;git branch\u0026#39; #列出当前仓库中所有的分支，并在当前分支前面标记一个星号 alias gba=\u0026#39;git branch -a\u0026#39; #列出所有的本地分支和远程分支 alias gbd=\u0026#39;git branch -d\u0026#39; #命令用于删除指定的本地分支 alias gbD=\u0026#39;git branch -d --force\u0026#39; # 命令用于强制删除指定的本地分支 alias gbm=\u0026#39;git branch -m\u0026#39; #重命名分支 alias gbnm=\u0026#39;git branch --no-merged\u0026#39; #列出所有未合并到当前分支的分支 alias gbr=\u0026#39;git branch --remote\u0026#39; #列出远程分支 alias ggsup=\u0026#39;git branch --set-upstream-to=origin/$(git_current_branch)\u0026#39; #将当前分支与远程仓库的同名分支建立起追踪关系 #在本地和远程仓库中重命名 Git 分支 function grename() { if [[ -z \u0026#34;$1\u0026#34; || -z \u0026#34;$2\u0026#34; ]]; then echo \u0026#34;Usage: $0 old_branch new_branch\u0026#34; return 1 fi # Rename branch locally git branch -m \u0026#34;$1\u0026#34; \u0026#34;$2\u0026#34; # Rename branch in origin remote if git push origin :\u0026#34;$1\u0026#34;; then git push --set-upstream origin \u0026#34;$2\u0026#34; fi } alias gc=\u0026#39;git commit --verbose\u0026#39; #提交当前暂存区中的变更，并显示详细的提交信息 alias gc!=\u0026#39;git commit --verbose --amend\u0026#39;#修改最近一次的提交，并在提交过程中显示详细的变更信息 alias gcmsg=\u0026#39;git commit -m\u0026#39; #提交当前暂存区中的变更并提供提交信息 alias gco=\u0026#39;git checkout\u0026#39; alias gcor=\u0026#39;git checkout --recurse-submodules\u0026#39; #递归地切换到主仓库以及所有子模块的相应提交或分支 alias gcb=\u0026#39;git checkout -b\u0026#39; #创建一个新分支并切换到该分支 alias gcB=\u0026#39;git checkout -B\u0026#39; #创建一个新分支并强制切换到该分支 alias gcd=\u0026#39;git checkout $(git_develop_branch)\u0026#39; alias gcm=\u0026#39;git checkout $(git_main_branch)\u0026#39; alias gcl=\u0026#39;git clone --recurse-submodules\u0026#39; #克隆代码 gccd #克隆代码并进入目录 alias gcf=\u0026#39;git config --list\u0026#39; alias gf=\u0026#39;git fetch\u0026#39; alias gfo=\u0026#39;git fetch origin\u0026#39; alias gm=\u0026#39;git merge\u0026#39; alias gma=\u0026#39;git merge --abort\u0026#39; alias gms=\u0026#34;git merge --squash\u0026#34; alias gmom=\u0026#39;git merge origin/$(git_main_branch)\u0026#39; alias gmum=\u0026#39;git merge upstream/$(git_main_branch)\u0026#39; #拉取代码 alias gl=\u0026#39;git pull\u0026#39; alias gpr=\u0026#39;git pull --rebase\u0026#39; #拉取远程仓库的最新提交，并将本地提交应用到最新提交 alias gpra=\u0026#39;git pull --rebase --autostash\u0026#39; #拉取远程仓库的最新提交，并将本地提交应用到最新提交之上，同时自动保存和恢复未提交的更改 alias ggpull=\u0026#39;git pull origin \u0026#34;$(git_current_branch)\u0026#34;\u0026#39; #从远程仓库拉取最新提交，并使用 rebase 的方式将本地提交应用到拉取的提交之 function ggu() { [[ \u0026#34;$#\u0026#34; != 1 ]] \u0026amp;\u0026amp; local b=\u0026#34;$(git_current_branch)\u0026#34; git pull --rebase origin \u0026#34;${b:=$1}\u0026#34; } #提交代码 alias gp=\u0026#39;git push\u0026#39; alias gpd=\u0026#39;git push --dry-run\u0026#39; alias ggpush=\u0026#39;git push origin \u0026#34;$(git_current_branch)\u0026#34;\u0026#39; #拉取代码并提交 function ggpnp() { if [[ \u0026#34;$#\u0026#34; == 0 ]]; then ggl \u0026amp;\u0026amp; ggp else ggl \u0026#34;${*}\u0026#34; \u0026amp;\u0026amp; ggp \u0026#34;${*}\u0026#34; fi } alias grb=\u0026#39;git rebase\u0026#39; alias grba=\u0026#39;git rebase --abort\u0026#39; alias grbc=\u0026#39;git rebase --continue\u0026#39; alias grbi=\u0026#39;git rebase --interactive\u0026#39; alias grbo=\u0026#39;git rebase --onto\u0026#39; alias grbs=\u0026#39;git rebase --skip\u0026#39; alias grbd=\u0026#39;git rebase $(git_develop_branch)\u0026#39; alias grbm=\u0026#39;git rebase $(git_main_branch)\u0026#39; alias grbom=\u0026#39;git rebase origin/$(git_main_branch)\u0026#39; alias gr=\u0026#39;git remote\u0026#39; alias gra=\u0026#39;git remote add\u0026#39; alias grrm=\u0026#39;git remote remove\u0026#39; alias grmv=\u0026#39;git remote rename\u0026#39; alias grset=\u0026#39;git remote set-url\u0026#39; alias grup=\u0026#39;git remote update\u0026#39; alias gst=\u0026#39;git status\u0026#39; ","permalink":"https://blog.chensoul.cc/posts/2024/01/25/til/","summary":"今天做了什么：\n整理 Idea 快捷键 整理 zsh 中定义的常用的快捷键 Idea 快捷键 使用快捷键 command +1 打开 Project 窗口\n输入 control + R 可以运行 Java 代码\n上下文 在 for 方法上，输入 option + enter，可以调出上下文，替换 for 表达式\n在字符串上面输入 option + enter，可以调出上下文。\n在字符串上面或者双击选中，然后双击两次 ⇧ ，打开 Search Everywhere 弹窗，然后输入 case ，选择 Toggle Case 将 AVERAGE 变为小写。\n在没有使用的方法参数 redundant 上，输入 option + enter，可以选择 Safe delete 'redunant' 删除该参数\n在三目运算，输入 option + enter，可以选择 Negate '?:'\n搜索 查找最近文件：comand + E\n输入 ⇧ + command + A 可以打开 Find Action 窗口。\n双击两次 ⇧ 可以打开 Search Everywhere 窗口。输入关键字，可以搜索 java 类。\n如果想搜索Java类，则可以输入 command + O，并可以选择在 All Places 搜索。\n如果想搜索方法或者变量名称，则可以使用 option + command + O\n自动补全 command + ↑ + enter 补全方法体、if、while、for 、switch 后面括号","title":"2024-01-25｜Idea和zsh快捷键"},{"content":"今天做了什么：\n观看 B 站视频《鸟宝的春天11_security编码实现》\n参考视频中示例使用 SecurityFilterChain DSL 语法实现用户名密码登录功能。\n扩展 WebAuthenticationDetails ，修改客户端 IP 获取方式，并记录服务端 IP。\npublic class CustomWebAuthenticationDetails extends WebAuthenticationDetails { private static final long serialVersionUID = 4441359628463408329L; @Getter private final String serverAddress; public CustomWebAuthenticationDetails(final HttpServletRequest request, final String serverAddress) { super(HttpRequestUtils.getClientIp(request), extractSessionId(request)); this.serverAddress = serverAddress; } protected static String extractSessionId(final HttpServletRequest request) { final HttpSession session = request.getSession(false); return (session != null) ? session.getId() : null; } } 获取客户端 IP 使用了 HttpRequestUtils 类，实际上就是从 Request 的 header 中获取 IP。\nprivate static final List\u0026lt;String\u0026gt; CLIENT_IP_HEADER_NAMES = Arrays.asList(\u0026#34;X-Forwarded-For\u0026#34;, \u0026#34;X-Real-IP\u0026#34;, \u0026#34;Proxy-Client-IP\u0026#34;, \u0026#34;WL-Proxy-Client-IP\u0026#34;, \u0026#34;HTTP_CLIENT_IP\u0026#34;, \u0026#34;HTTP_X_FORWARDED_FOR\u0026#34;); public static String getClientIp(HttpServletRequest request, String... otherHeaderNames) { if (request == null) { return null; } if (ArrayUtils.isNotEmpty(otherHeaderNames)) { CLIENT_IP_HEADER_NAMES.addAll(Arrays.asList(otherHeaderNames)); } String ip; for (String header : CLIENT_IP_HEADER_NAMES) { ip = request.getHeader(header); if (!NetUtils.isUnknown(ip)) { return NetUtils.getMultistageReverseProxyIp(ip); } } ip = request.getRemoteHost(); return NetUtils.getMultistageReverseProxyIp(ip); } ","permalink":"https://blog.chensoul.cc/posts/2024/01/24/til/","summary":"今天做了什么：\n观看 B 站视频《鸟宝的春天11_security编码实现》\n参考视频中示例使用 SecurityFilterChain DSL 语法实现用户名密码登录功能。\n扩展 WebAuthenticationDetails ，修改客户端 IP 获取方式，并记录服务端 IP。\npublic class CustomWebAuthenticationDetails extends WebAuthenticationDetails { private static final long serialVersionUID = 4441359628463408329L; @Getter private final String serverAddress; public CustomWebAuthenticationDetails(final HttpServletRequest request, final String serverAddress) { super(HttpRequestUtils.getClientIp(request), extractSessionId(request)); this.serverAddress = serverAddress; } protected static String extractSessionId(final HttpServletRequest request) { final HttpSession session = request.getSession(false); return (session != null) ? session.getId() : null; } } 获取客户端 IP 使用了 HttpRequestUtils 类，实际上就是从 Request 的 header 中获取 IP。\nprivate static final List\u0026lt;String\u0026gt; CLIENT_IP_HEADER_NAMES = Arrays.asList(\u0026#34;X-Forwarded-For\u0026#34;, \u0026#34;X-Real-IP\u0026#34;, \u0026#34;Proxy-Client-IP\u0026#34;, \u0026#34;WL-Proxy-Client-IP\u0026#34;, \u0026#34;HTTP_CLIENT_IP\u0026#34;, \u0026#34;HTTP_X_FORWARDED_FOR\u0026#34;); public static String getClientIp(HttpServletRequest request, String... otherHeaderNames) { if (request == null) { return null; } if (ArrayUtils.","title":"2024-01-24｜今天做了什么"},{"content":"今天做了什么：\n重构 foodie-cloud 项目，修改模块名称、表名及字段名。\n修改 spring-security-oauth2-legacy-examples ，测试资源服务器通过 jwt、jwk、远程三种方式获取用户信息；测试 sso 单点登录（进行中）。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/23/til/","summary":"今天做了什么：\n重构 foodie-cloud 项目，修改模块名称、表名及字段名。\n修改 spring-security-oauth2-legacy-examples ，测试资源服务器通过 jwt、jwk、远程三种方式获取用户信息；测试 sso 单点登录（进行中）。","title":"2024-01-23｜今天做了什么"},{"content":"今天做了什么：\n修改瑞吉外卖项目 reggie：\n去掉 .mvn 相关文件，去掉 github action 中用到 .mvn 的 workflow 参考 DDD 修改包结构 配置 Redis 持久化\nchensoul-parent 发布 v1.0.40 ，升级 maven 插件版本，去掉 sortpom、impsort 插件\nvps 禁用防火墙\n观看慕课网视频《高级Redis进阶课 解决Redis实际问题+掌握Redis6.x特性》，网盘地址：https://www.aliyundrive.com/s/DqXP972AJnk。注意：其中没有项目资料，如有需要，可以联系我。\n重构 《高级Redis进阶课 解决Redis实际问题+掌握Redis6.x特性》 资料中的 food-social-contact-parent 源代码，重命名为 foodie-cloud 并提交到 Github 仓库 foodie-cloud （原来的 foodie-cloud 源码已删除）。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/22/til/","summary":"今天做了什么：\n修改瑞吉外卖项目 reggie：\n去掉 .mvn 相关文件，去掉 github action 中用到 .mvn 的 workflow 参考 DDD 修改包结构 配置 Redis 持久化\nchensoul-parent 发布 v1.0.40 ，升级 maven 插件版本，去掉 sortpom、impsort 插件\nvps 禁用防火墙\n观看慕课网视频《高级Redis进阶课 解决Redis实际问题+掌握Redis6.x特性》，网盘地址：https://www.aliyundrive.com/s/DqXP972AJnk。注意：其中没有项目资料，如有需要，可以联系我。\n重构 《高级Redis进阶课 解决Redis实际问题+掌握Redis6.x特性》 资料中的 food-social-contact-parent 源代码，重命名为 foodie-cloud 并提交到 Github 仓库 foodie-cloud （原来的 foodie-cloud 源码已删除）。","title":"2024-01-22｜今天做了什么"},{"content":"今天做了什么：\n修改瑞吉外卖项目 reggie：\n修改数据源配置，使用 HikariCP 数据源 修改接口返回字段和前端文件，code=0 表示成功 添加 mysql、redis 安装文档 添加 openresty lua 脚本实现 redis 缓存 基于 springboot 使用 sharding-jdbc 测试读写分离、分库分表。代码在：https://github.com/chensoul/sharding-examples\n测试 RabbitMQ 生产、消费，代码在：https://github.com/chensoul/rabbitmq-examples\n观看 B 站视频《【IT老齐455】SpringBoot、Caffine、Redis本地远程二级缓存》，视频中的代码在：second-cache\n","permalink":"https://blog.chensoul.cc/posts/2024/01/18/til/","summary":"今天做了什么：\n修改瑞吉外卖项目 reggie：\n修改数据源配置，使用 HikariCP 数据源 修改接口返回字段和前端文件，code=0 表示成功 添加 mysql、redis 安装文档 添加 openresty lua 脚本实现 redis 缓存 基于 springboot 使用 sharding-jdbc 测试读写分离、分库分表。代码在：https://github.com/chensoul/sharding-examples\n测试 RabbitMQ 生产、消费，代码在：https://github.com/chensoul/rabbitmq-examples\n观看 B 站视频《【IT老齐455】SpringBoot、Caffine、Redis本地远程二级缓存》，视频中的代码在：second-cache","title":"2024-01-18｜今天做了什么"},{"content":"今天做了什么：\n观看《2022年黑马程序员新版java课程》中 MySQL 主从复制和读写分离相关视频，使用 Docker 搭建 MySQL 主从复制环境。\nfoodie-cloud 已归档，不再更新，改为更新瑞吉外卖项目 reggie 。\nDocker 搭建 MySQL 主从复制环境 参考文章 ：基于 Docker 的 MySQL 主从复制搭建及原理（真正弄懂）\n先创建两个容器：\nMYSQL_ROOT_PASSWORD=123456 docker run \\ -d \\ --restart unless-stopped \\ --name mysql-master \\ -p 3307:3306 \\ -e MYSQL_ROOT_HOST=\u0026#34;%\u0026#34; \\ -e MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD \\ -e TZ=Asia/Shanghai \\ mysql:8.1.0 \\ --log-bin=mysql-bin \\ --server-id=1 \\ --lower_case_table_names=1 \\ --skip-ssl \\ --explicit_defaults_for_timestamp \\ --default-authentication-plugin=mysql_native_password docker run \\ -d \\ --restart unless-stopped \\ --name mysql-slave \\ -p 3308:3306 \\ -e MYSQL_ROOT_HOST=\u0026#34;%\u0026#34; \\ -e MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD \\ -e TZ=Asia/Shanghai \\ mysql:8.1.0 \\ --log-bin=mysql-bin \\ --server-id=2 \\ --lower_case_table_names=1 \\ --skip-ssl \\ --explicit_defaults_for_timestamp \\ --default-authentication-plugin=mysql_native_password 进入主数据库，设置权限，并查询主库状态：\ndocker exec -it mysql-master /bin/bash mysql -uroot -p123456 CREATE USER \u0026#39;xiaoming\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;Root@123456\u0026#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \u0026#39;xiaoming\u0026#39;@\u0026#39;%\u0026#39;; SHOW MASTER STATUS; 进入从数据库，连接主库并开启复制：\n# 查询主库IP：192.168.215.4 docker inspect --format=\u0026#39;{{.NetworkSettings.IPAddress}}\u0026#39; mysql-master docker exec -it mysql-slave /bin/bash mysql -uroot -p123456 \u0026gt; change master to master_host=\u0026#39;192.168.215.4\u0026#39;,master_user=\u0026#39;xiaoming\u0026#39;,master_password=\u0026#39;Root@123456\u0026#39;,master_log_file=\u0026#39;mysql-bin.000003\u0026#39;,master_log_pos=688; \u0026gt;SHOW SLAVE STATUS \\G; 正常情况下，SlaveIORunning 和 SlaveSQLRunning 都是 No，因为我们还没有开启主从复制过程。使用 start slave 开启主从复制过程，然后再次查询主从同步状态 show slave status \\G;。\n\u0026gt;start slave; \u0026gt;SHOW SLAVE STATUS \\G; \u0026gt;SHOW BINARY LOGS; 瑞吉外卖项目 reggie 该项目是一个基于 Spring Boot2、Mybatis Plus、Docker 等前沿技术搭建的黑马程序员《瑞吉外卖》单体项目，包含了用户、员工、订单、菜品等模块。\n项目介绍如下：\n特性 主体框架：采用 Spring Boot2 版本进行系统设计。 在线文档：通过接入 OpenAPI，实现在线 API 文档的查看与调试。 业务分离：采用前后端分离的框架设计，提高开发效率、降低维护成本、增强系统稳定性和灵活性。 消息中间件：采用 ActiveMQ 实现服务之间消息转发。 分布式定时器：采用 XxlJob 实现多个微服务分布式任务调度。 开发环境 组件 用途 版本号 Maven 依赖管理 3.0.4以上 Java 编译运行项目 1.8以上（推荐8u161以后的版本，否则要装JCE插件） IDEA 开发环境 版本随意 MySQL 数据库 5.7 Redis 缓存组件 5.0.4 RabbitMQ 消息中间件 3.7.15 Kafka 消息中间件 2.2.0 Lua 限流脚本 5.3.5 版本依赖 依赖 本项目版本 新版 说明 spring-boot 2.7.18 限制 Spring Boot 2.x mybatis 2.1.3 限制 Spring Boot 2.x，指 mybatis-spring-boot-starter mybatis-plus 3.5.5 springdoc 1.7.0 用于生成 API doc，支持从 javadoc 中获取字段注释 shardingsphere-jdbc 4.1.1 MySQL 主从复制、读写分离 xxl-job 2.4.0 分布式任务调度平台XXL-JOB 开发计划 集成 Springdoc，实现在线 API 文档的查看与调试 LVS + Keepalive + Nginx 实现高可用集群 Redis 主从复制高可用集群 MySQL 主从复制和读写分离 分布式会话与单点登录SSO 分布式搜索引擎 Elasticsearch 分布式消息队列 RabbitMQ 分布式锁 分布式事务和数据一致性 分布式接口幂等性，分布式限流 容器化部署 集成 Springdoc + Javadoc 添加依赖 spring-boot2 使用 springdoc-openapi 1.7.0 版本\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-javadoc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 集成 springdoc 使用 javadoc 注释作为文档 参考 https://springdoc.org/#javadoc-support ，修改 maven-compiler-plugin 插件：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${maven-compiler-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;parameters\u0026gt;true\u0026lt;/parameters\u0026gt; \u0026lt;annotationProcessorPaths\u0026gt; \u0026lt;!-- https://springdoc.org/#javadoc-support --\u0026gt; \u0026lt;path\u0026gt; \u0026lt;groupId\u0026gt;com.github.therapi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;therapi-runtime-javadoc-scribe\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${therapi-runtime-javadoc.version}\u0026lt;/version\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;!-- 修复 lombok、springdoc 冲突 --\u0026gt; \u0026lt;path\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${lombok.version}\u0026lt;/version\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;/annotationProcessorPaths\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 添加依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.therapi\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;therapi-runtime-javadoc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${therapi-runtime-javadoc.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 启动应用 访问：\nhttp://localhost:8080/swagger-ui.html http://localhost:8080/v3/api-docs 说明：\n访问 swagger-ui.html 会显示 petstore 的 api 接口信息。具体原因，可以参考 https://stackoverflow.com/questions/71721477/springdoc-swagger-ui-not-using-swagger-config 目前，没有找到解决办法。曲线救国的方法是使用其他 Swagger UI，如 Knife4j。 ","permalink":"https://blog.chensoul.cc/posts/2024/01/17/til/","summary":"今天做了什么：\n观看《2022年黑马程序员新版java课程》中 MySQL 主从复制和读写分离相关视频，使用 Docker 搭建 MySQL 主从复制环境。\nfoodie-cloud 已归档，不再更新，改为更新瑞吉外卖项目 reggie 。\nDocker 搭建 MySQL 主从复制环境 参考文章 ：基于 Docker 的 MySQL 主从复制搭建及原理（真正弄懂）\n先创建两个容器：\nMYSQL_ROOT_PASSWORD=123456 docker run \\ -d \\ --restart unless-stopped \\ --name mysql-master \\ -p 3307:3306 \\ -e MYSQL_ROOT_HOST=\u0026#34;%\u0026#34; \\ -e MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD \\ -e TZ=Asia/Shanghai \\ mysql:8.1.0 \\ --log-bin=mysql-bin \\ --server-id=1 \\ --lower_case_table_names=1 \\ --skip-ssl \\ --explicit_defaults_for_timestamp \\ --default-authentication-plugin=mysql_native_password docker run \\ -d \\ --restart unless-stopped \\ --name mysql-slave \\ -p 3308:3306 \\ -e MYSQL_ROOT_HOST=\u0026#34;%\u0026#34; \\ -e MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD \\ -e TZ=Asia/Shanghai \\ mysql:8.1.0 \\ --log-bin=mysql-bin \\ --server-id=2 \\ --lower_case_table_names=1 \\ --skip-ssl \\ --explicit_defaults_for_timestamp \\ --default-authentication-plugin=mysql_native_password 进入主数据库，设置权限，并查询主库状态：\ndocker exec -it mysql-master /bin/bash mysql -uroot -p123456 CREATE USER \u0026#39;xiaoming\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;Root@123456\u0026#39;; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.","title":"2024-01-17｜MySQL 主从复制、瑞吉外卖项目、集成Springdoc+Javadoc"},{"content":"今天做了什么：\n1、spring-cloud-netflix-examples 添加分布式锁、rabbitmq、kafka、分库分表等示例代码\n2、foodie-cloud 添加登录部分代码\n3、整理 Redis 安装文档\nRedis 安装 Centos7 通过 yum 安装 在 CentOS 7 上通过 yum 安装 Redis，可以按照以下步骤进行操作：\n更新系统软件包：\nsudo yum update 安装 Redis：\nsudo yum install redis 可以看到默认安装的 redis 版本是 3.2.12-2.el7\n如果需要安装 redis 7，这需要下载 yum 源：\nsudo yum install epel-release sudo yum -y install http://rpms.remirepo.net/enterprise/remi-release-7.rpm 然后，在指定源进行安装：\nyum --enablerepo=remi install redis 启动 Redis 服务：\nsudo systemctl start redis 配置 Redis 开机自启动：\nsudo systemctl enable redis 修改配置文件 /etc/redis.conf\n修改 bind 和 requirepass\nbind 0.0.0.0 requirepass 123456 然后重启 redis：\nsudo systemctl restart redis 运行 redis-cli\nredis-cli 127.0.0.1:6379\u0026gt; auth 123456 OK Centos7 通过 snap 安装 安装 redis\nsudo snap install redis 查看 snap 安装的包：\nsnap list 启动 Redis：\nsudo snap start redis 运行 redis-cli\nRedis的snap安装没有预配置的文件(redis.conf)。因此，我们需要使用Redis的CLI进入控制台并进行配置。\nredis.cli # 打印所有的配置 127.0.0.1:6379\u0026gt; CONFIG GET * 配置外网访问\n要配置Redis以允许外部网络访问，使用以下命令：\n127.0.0.1:6379\u0026gt; CONFIG GET bind 127.0.0.1:6379\u0026gt; config set bind 0.0.0.0 这将绑定Redis服务器到0.0.0.0 IP地址，使其对外可访问。请注意，这可能会带来一些安全风险，因此请谨慎操作。\n设置保护模式\n127.0.0.1:6379\u0026gt; CONFIG SET protected-mode no 该模式控制外部网是否可以连接 redis 服务，默认是 yes, 所以默认我们外网是无法访问的，如需外网连接 rendis 服务则需要将此属性改为 no。\n设置访问密码\n127.0.0.1:6379\u0026gt; config set requirepass mypass 这将设置一个名为\u0026quot;mypass\u0026quot;的密码作为访问Redis的要求。请确保将\u0026quot;mypass\u0026quot;替换为您选择的强密码。\n开启防火墙（可选）\n# 添加 redis 端口 firewall-cmd --zone=public --add-port=6379/tcp --permanent firewall-cmd --zone=public --add-port=6379/udp --permanent # 重启防火墙 firewall-cmd --reload 升级\nsudo snap refresh redis 卸载\nsudo snap remove redis MacOS 上安装 安装 Redis：\nbrew install redis 启动 Redis 服务器：\nbrew services start redis 这将启动 Redis 服务器并使其在后台运行。\n查看 Redis 状态\nbrew services info redis 验证 Redis 安装：\n您可以使用以下命令来验证 Redis 是否成功安装并正在运行：\nredis-cli ping 如果 Redis 正常运行，它将返回 \u0026ldquo;PONG\u0026rdquo;。\n停止 Redis 服务器：\nbrew services stop redis 源码安装 下载源代码\nwget https://download.redis.io/redis-stable.tar.gz 编译\ntar -xzvf redis-stable.tar.gz cd redis-stable make 启动 Redis 服务器\nredis-server Docker 安装 通过 docker 安装：\nREDIS_PASSWORD=123456 docker run \\ -d \\ --restart always \\ --privileged=true \\ --name redis \\ -v /etc/localtime:/etc/localtime \\ -p 6379:6379 \\ redis:7.2.2 \\ --requirepass $REDIS_PASSWORD \\ --appendonly yes 通过 docker-compose 安装：\nversion: \u0026#39;3\u0026#39; services: redis: image: redis:7.2.2 restart: unless-stopped environment: TZ: Asia/Shanghai command: redis-server --requirepass 123456 ports: - \u0026#34;6379:6379\u0026#34; ","permalink":"https://blog.chensoul.cc/posts/2024/01/16/til/","summary":"今天做了什么：\n1、spring-cloud-netflix-examples 添加分布式锁、rabbitmq、kafka、分库分表等示例代码\n2、foodie-cloud 添加登录部分代码\n3、整理 Redis 安装文档\nRedis 安装 Centos7 通过 yum 安装 在 CentOS 7 上通过 yum 安装 Redis，可以按照以下步骤进行操作：\n更新系统软件包：\nsudo yum update 安装 Redis：\nsudo yum install redis 可以看到默认安装的 redis 版本是 3.2.12-2.el7\n如果需要安装 redis 7，这需要下载 yum 源：\nsudo yum install epel-release sudo yum -y install http://rpms.remirepo.net/enterprise/remi-release-7.rpm 然后，在指定源进行安装：\nyum --enablerepo=remi install redis 启动 Redis 服务：\nsudo systemctl start redis 配置 Redis 开机自启动：\nsudo systemctl enable redis 修改配置文件 /etc/redis.conf\n修改 bind 和 requirepass\nbind 0.0.0.0 requirepass 123456 然后重启 redis：\nsudo systemctl restart redis 运行 redis-cli\nredis-cli 127.0.0.1:6379\u0026gt; auth 123456 OK Centos7 通过 snap 安装 安装 redis\nsudo snap install redis 查看 snap 安装的包：","title":"2024-01-16｜Redis安装"},{"content":"今天做了什么：\n1、看 JHipster 源码发现这两个类库\njackson-datatypes-collections 支持 hppc 数据类型。hppc：Java 的高性能原始集合，HPPC 为所有 Java 基元类型提供典型集合的模板生成实现，例如列表、集合和映射。HPPC 背后的主要驱动力是针对最高性能和内存效率的优化。\nHandy-URI-Templates A Java URI Template processor implementing RFC6570\n2、整理文档《Nginx进程模型》、《Nginx配置结构与指令语法》\nNginx配置结构与指令语法 Nginx的配置文件使用一种块结构和指令语法来定义服务器的行为和属性。以下是Nginx配置文件的基本结构和指令语法：\n基本结构和指令语法 配置文件结构： Nginx配置文件由多个块（Block）组成，每个块用花括号 {} 括起来。 主要的配置块是 http 块，用于全局HTTP配置。 在 http 块内部，可以包含多个 server 块，每个 server 块用于配置一个虚拟主机。 在 server 块内部，可以包含多个其他块（如 location 块），用于配置请求的处理规则。 指令语法： 指令是配置文件中的关键字，用于指定服务器的行为和属性。 指令通常由指令名称和参数组成，中间使用空格分隔。 指令以分号 ; 结束。 有些指令可以包含块结构，以定义更复杂的配置规则。 以下是一个示例的Nginx配置文件的结构和指令语法：\n# 全局配置块 http { # 全局指令 directive_name parameter; # 服务器块 server { # 服务器指令 directive_name parameter; # 位置块 location / { # 位置指令 directive_name parameter; } } } 在上面的示例中，http 是全局配置块，server 是服务器块，location 是位置块。每个块内部可以包含相应的指令。\n注意事项：\n指令名称对大小写不敏感，但通常以小写字母表示。 多个指令可以在同一行上用分号 ; 分隔。 注释以 # 开头，并在行的任何位置添加。 可以使用变量和预定义变量来设置指令参数。 nginx.conf 配置 user：设置Nginx工作进程的运行用户和用户组。默认情况下，Nginx以nobody用户运行。 语法：user username [groupname] 例如：user nginx; 或 user nginx nginx; worker_processes：设置Nginx工作进程的数量。可以是一个整数值或auto。通常，建议将其设置为服务器可用CPU核心数量的一倍或两倍，以充分利用服务器的性能。 语法：worker_processes number | auto error_log：用于设置错误日志文件的路径和级别 语法：error_log file [level]; file：指定错误日志文件的路径。 level：可选参数，指定记录的错误级别。 常见的级别包括 emerg、alert、crit、error、warn、notice、info 和 debug。 默认情况下，错误日志的级别为 error。 可以使用 syslog:facility.level 格式将错误日志发送到系统日志（syslog）中。 events：配置与Nginx事件相关的参数。 语法：events {} 常用的参数包括： worker_connections：每个工作进程的最大并发连接数。 multi_accept：是否接受多个请求同时处理。 use：指定事件模块（如epoll、kqueue等）。 http： 语法：http {} 定义全局HTTP配置。 常用的指令包括： include：包含其他配置文件。 default_type：设置默认的Content-Type。 access_log：定义访问日志的位置和格式。 sendfile：用于控制是否使用操作系统提供的零拷贝技术进行文件传输。当启用 sendfile 时，Nginx 可以直接将文件从磁盘读取并发送到客户端，而无需将文件内容复制到用户空间。这可以显著提高文件传输的效率和性能。 当 sendfile 设置为 on 时，Nginx 将尝试使用操作系统提供的 sendfile() 系统调用进行文件传输。 当 sendfile 设置为 off 时，Nginx 将使用普通的方式进行文件传输，即通过将文件内容从磁盘复制到用户空间再发送给客户端。 在大多数情况下，默认值 sendfile off 是安全和可靠的选择，但在某些情况下，启用 sendfile 可能会带来更好的性能和效率。 启用 sendfile 可以降低 CPU 和内存的使用量，但在某些特定的操作系统或文件系统中，可能会出现某些问题，如传输不完整或文件内容损坏等。因此，在启用 sendfile 之前，建议进行充分的测试和评估。 tcp_nopush： 当 tcp_nopush 设置为 on 时，Nginx 将启用 TCP_CORK 选项，数据将被缓冲并一次性发送给客户端，以提高传输效率。 当 tcp_nopush 设置为 off 时，Nginx 将禁用 TCP_CORK 选项，数据将立即发送给客户端，减少延迟。 在大多数情况下，使用默认值 tcp_nopush off 是安全和可靠的选择，可以减少延迟。 然而，在某些具体的场景中，如高带宽、低延迟的网络环境，启用 tcp_nopush on 可以提高传输效率，但可能会增加延迟。 keepalive_timeout：设置与客户端的 HTTP keep-alive 连接的超时时间。HTTP keep-alive 允许客户端和服务器之间的多个 HTTP 请求和响应共享同一个 TCP 连接，以减少连接建立和关闭的开销。 keepalive_timeout 指定了一个持续连接的超时时间。如果在超过指定的时间内没有新的请求到达，Nginx 将关闭 keep-alive 连接。 当客户端发送新请求时，超过 keepalive_timeout 的连接将被关闭，并在必要时重新创建一个新的连接。 默认情况下，keepalive_timeout 设置为 65 秒。 如果将 keepalive_timeout 设置为 0，表示禁用 keep-alive 连接，每个请求将使用独立的连接。 可以使用 s 后缀表示秒，或使用 ms 后缀表示毫秒。 gzip：用于启用或禁用对响应进行 Gzip 压缩。Gzip 压缩是一种在服务器端将响应内容进行压缩，然后再发送给客户端的技术，可以减少传输数据的大小，提高网络传输效率。 当 gzip 设置为 on 时，Nginx 将对响应内容进行 Gzip 压缩。 当 gzip 设置为 off 时，Nginx 将禁用 Gzip 压缩。 启用 Gzip 压缩可以显著减少传输数据的大小，提高网络传输效率，但会增加服务器的 CPU 和内存负载。 在启用 Gzip 压缩之前，建议评估服务器的性能和资源使用情况，确保服务器具备足够的计算资源来处理压缩操作。 可以通过配置 gzip_types 指令来指定要进行 Gzip 压缩的 MIME 类型。 还可以通过配置 gzip_comp_level 指令来调整 Gzip 压缩的压缩级别。 server： 语法：server {} 配置虚拟主机。 常用的指令包括： listen：定义监听的端口号和地址。 server_name：定义虚拟主机的域名。 root：指定根目录的路径。 index：定义默认的索引文件。 error_page：用于定义在特定 HTTP 错误状态码出现时，向客户端发送自定义错误页面的路径或重定向到其他 URL。 语法：error_page [error_code] [action]; 适用范围：http, server, location 配置块内部。 error_page 指定了特定 HTTP 错误状态码的处理方式。 error_code 参数指定了要处理的 HTTP 错误状态码，如 404、500 等。还可以使用通配符 * 匹配所有错误状态码。 action 参数定义了对应错误状态码的处理行为。可以有以下几种处理方式： 发送自定义错误页面：error_page error_code path;，其中 path 是自定义错误页面的路径。 重定向到其他 URL：error_page error_code redirect_url;，其中 redirect_url 是要重定向的 URL。 使用默认的 Nginx 错误页面：error_page error_code =default;，将使用 Nginx 默认的错误页面。 返回空响应：error_page error_code =;，将返回一个空的响应，即不发送任何内容给客户端。 location： 语法：location [modifier] uri {} 配置请求的处理规则。 常用的指令包括： root：指定根目录的路径。 proxy_pass：反向代理到指定的后端服务器。 try_files：尝试匹配多个文件或路径。 user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { #默认使用 epoll 模式 use epoll; worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; #gzip_types text/plain text/html; #gzip_comp_level 5; include /etc/nginx/conf.d/*.conf; } ","permalink":"https://blog.chensoul.cc/posts/2024/01/15/til/","summary":"今天做了什么：\n1、看 JHipster 源码发现这两个类库\njackson-datatypes-collections 支持 hppc 数据类型。hppc：Java 的高性能原始集合，HPPC 为所有 Java 基元类型提供典型集合的模板生成实现，例如列表、集合和映射。HPPC 背后的主要驱动力是针对最高性能和内存效率的优化。\nHandy-URI-Templates A Java URI Template processor implementing RFC6570\n2、整理文档《Nginx进程模型》、《Nginx配置结构与指令语法》\nNginx配置结构与指令语法 Nginx的配置文件使用一种块结构和指令语法来定义服务器的行为和属性。以下是Nginx配置文件的基本结构和指令语法：\n基本结构和指令语法 配置文件结构： Nginx配置文件由多个块（Block）组成，每个块用花括号 {} 括起来。 主要的配置块是 http 块，用于全局HTTP配置。 在 http 块内部，可以包含多个 server 块，每个 server 块用于配置一个虚拟主机。 在 server 块内部，可以包含多个其他块（如 location 块），用于配置请求的处理规则。 指令语法： 指令是配置文件中的关键字，用于指定服务器的行为和属性。 指令通常由指令名称和参数组成，中间使用空格分隔。 指令以分号 ; 结束。 有些指令可以包含块结构，以定义更复杂的配置规则。 以下是一个示例的Nginx配置文件的结构和指令语法：\n# 全局配置块 http { # 全局指令 directive_name parameter; # 服务器块 server { # 服务器指令 directive_name parameter; # 位置块 location / { # 位置指令 directive_name parameter; } } } 在上面的示例中，http 是全局配置块，server 是服务器块，location 是位置块。每个块内部可以包含相应的指令。\n注意事项：\n指令名称对大小写不敏感，但通常以小写字母表示。 多个指令可以在同一行上用分号 ; 分隔。 注释以 # 开头，并在行的任何位置添加。 可以使用变量和预定义变量来设置指令参数。 nginx.conf 配置 user：设置Nginx工作进程的运行用户和用户组。默认情况下，Nginx以nobody用户运行。 语法：user username [groupname] 例如：user nginx; 或 user nginx nginx; worker_processes：设置Nginx工作进程的数量。可以是一个整数值或auto。通常，建议将其设置为服务器可用CPU核心数量的一倍或两倍，以充分利用服务器的性能。 语法：worker_processes number | auto error_log：用于设置错误日志文件的路径和级别 语法：error_log file [level]; file：指定错误日志文件的路径。 level：可选参数，指定记录的错误级别。 常见的级别包括 emerg、alert、crit、error、warn、notice、info 和 debug。 默认情况下，错误日志的级别为 error。 可以使用 syslog:facility.","title":"2024-01-15｜Nginx配置结构与指令语法"},{"content":"今天做了什么：\n1、观看 B 站 《SSO单点登录》视频\n2、参考 https://github.com/jOOQ/jOOL 和 https://github.com/vavr-io/vavr ，将 CheckedXXX 的类加入公司项目中。\n涉及的类有：Async.java、Blocking.java、CheckedBiConsumer.java、CheckedBiFunction.java、CheckedBiPredicate.java、CheckedComparator.java、CheckedConsumer.java、CheckedFunction.java、CheckedPredicate.java、CheckedRunnable.java、CheckedSupplier.java、FunctionUtils.java、OnceConsumer.java、SameExecutorCompletionStage.java、UncheckedException.java，并添加单元测试类。\n示例代码：\n@FunctionalInterface public interface CheckedConsumer\u0026lt;T\u0026gt; { void accept(T t) throws Throwable; default CheckedConsumer\u0026lt;T\u0026gt; andThen(CheckedConsumer\u0026lt;? super T\u0026gt; after) { Objects.requireNonNull(after, \u0026#34;after is null\u0026#34;); return (T t) -\u0026gt; { accept(t); after.accept(t); }; } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; sneaky(CheckedConsumer\u0026lt;T\u0026gt; consumer) { return unchecked(consumer, RETHROW_ALL); } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; unchecked(CheckedConsumer\u0026lt;T\u0026gt; consumer) { return unchecked(consumer, THROWABLE_TO_RUNTIME_EXCEPTION); } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; unchecked(CheckedConsumer\u0026lt;T\u0026gt; consumer, Consumer\u0026lt;Throwable\u0026gt; handler) { return t -\u0026gt; { try { consumer.accept(t); } catch (Throwable e) { handler.accept(e); throw new IllegalStateException(\u0026#34;Exception handler must throw a RuntimeException\u0026#34;, e); } }; } } 3、重构公司微服务框架\n4、明天待办事项：\n重写微服务日志记录模块 继续重构 foodie-cloud 支持单点登录 支持全文检索 集成 Spring Security OAuth2 Session和Cookie的区别 Session和Cookie是Web开发中常用的两种技术，用于在客户端和服务器之间存储和传递数据。它们在一些方面有相似之处，但也有一些重要的区别。\n数据存储位置：\nCookie：Cookie是一小段文本信息，存储在用户的浏览器中。每当用户访问相应的网站时，浏览器会将Cookie发送给服务器。 Session：Session是服务器上的一段存储用户数据的空间，数据存储在服务器上，而不是在用户的浏览器中。 数据安全性：\nCookie：Cookie的数据存储在用户的浏览器中，因此可以被用户篡改或者被其他恶意用户窃取。为了增加安全性，可以使用加密和签名等技术对Cookie进行保护。 Session：Session的数据存储在服务器上，相对来说更安全，用户无法直接篡改或者窃取Session数据。但是，服务器需要采取措施来保护Session数据的安全性，例如使用合适的存储方式和安全传输协议。 存储容量：\nCookie：Cookie的存储容量有限，通常为几KB。不同浏览器对Cookie的容量限制可能不同。 Session：Session的存储容量相对较大，通常没有明确的限制。服务器的硬盘空间和内存大小会影响Session的容量限制。 生命周期：\nCookie：Cookie可以设置过期时间，可以是会话级别的（当浏览器关闭时失效）或者持久性的（在一段时间后失效）。 Session：Session通常在用户首次访问网站时创建，并在用户关闭浏览器或者一段时间不活动后过期。Session的生命周期由服务器管理。 访问方式：\nCookie：Cookie存储在浏览器中，可以通过JavaScript或服务器端代码直接读取和写入。 Session：Session存储在服务器上，通过服务器端代码访问和操作。 总结： Cookie适合存储少量的简单数据，且需要在客户端保持状态。Session适合存储较大的用户数据或敏感数据，且需要在服务器端保持状态。在实际应用中，Cookie和Session通常会结合使用，Session ID会存储在Cookie中，用于标识和关联客户端和服务器上的Session数据。\n单点登录和三方登录的区别 单点登录（Single Sign-On，SSO）和三方登录（Third-party Login）是两种不同的身份认证机制。\n单点登录（SSO）：\n定义：单点登录是一种身份验证机制，允许用户只需登录一次，即可访问多个关联的应用程序或系统。 流程：用户在通过身份验证后，会获得一个令牌，用于表示他们已经通过认证。这个令牌可以在多个应用程序之间共享，使用户可以无需重复登录即可访问这些应用程序。 优点：提供了便利性，用户只需登录一次即可访问多个应用程序，无需为每个应用程序单独进行身份验证。同时，SSO还可以提高安全性，因为用户只需在一个受信任的身份提供者进行身份验证。 示例：CAS（Central Authentication Service）是一个常见的SSO协议和技术，用于实现单点登录。 三方登录：\n定义：三方登录是一种身份验证机制，允许用户使用其在第三方身份提供者（如社交媒体平台）上已有的身份认证来登录应用程序或网站。 流程：用户选择使用三方登录，并提供其在第三方身份提供者上的凭据。应用程序将向第三方身份提供者发送请求，以验证用户的身份，并获得一些基本信息。应用程序可以选择使用这些信息来创建一个本地账户，也可以仅依赖第三方身份提供者进行身份验证和授权。 优点：提供了便利性，用户可以使用其在第三方平台上已有的身份进行登录，无需创建新的账户和密码。同时，三方登录还可以提供额外的用户信息，以便应用程序个性化用户体验。 示例：使用Facebook、Google或Twitter账户登录某个应用程序或网站，就是一种常见的三方登录。 总结： 单点登录（SSO）是一种身份认证机制，允许用户只需登录一次，即可访问多个关联的应用程序或系统。三方登录是一种身份认证机制，允许用户使用其在第三方身份提供者上已有的身份认证来登录应用程序或网站。两者的主要区别在于单点登录关注的是用户在多个应用程序之间的身份验证和授权，而三方登录关注的是用户使用第三方身份提供者的凭据进行身份验证。\nSession跨域如何实现 在Web开发中，由于浏览器的同源策略（Same-Origin Policy），默认情况下，跨域访问Session是不被允许的。然而，可以通过一些技术手段来实现跨域访问Session。以下是几种常见的实现方法：\nJSONP（JSON with Padding）：JSONP是一种利用动态创建\u0026lt;script\u0026gt;标签来实现跨域请求的技术。通过在跨域请求中包含一个回调函数的名称，服务器会将数据包装在该函数中作为响应返回。客户端可以定义一个全局的回调函数来接收响应，并在回调函数中处理数据和设置Session。\nCORS（Cross-Origin Resource Sharing）：CORS是一种基于HTTP头部的跨域解决方案。服务器端可以通过设置特定的响应头部，允许指定的域名或一组域名跨域访问资源。对于跨域访问Session，服务器端需要在响应中包含Access-Control-Allow-Credentials: true头部，并在请求中设置withCredentials: true以允许携带Cookie信息。\n代理服务器：可以设置一个代理服务器，将跨域请求转发到目标服务器。客户端通过访问代理服务器，代理服务器在内部转发请求并携带Session信息。由于代理服务器与目标服务器在同一域名下，因此可以实现跨域访问Session。\n需要注意的是，这些方法都需要服务器端的支持和相应的配置。另外，跨域访问Session涉及安全问题，需要谨慎处理，确保只有受信任的域名可以访问Session，并采取适当的安全措施保护用户的数据。\nNginx实现共享 Session 优缺点 使用 Nginx 的 ip_hash 指令实现会话共享具有以下优点和缺点：\n优点：\n会话一致性：ip_hash 指令基于客户端的 IP 地址将请求路由到后端服务器。这意味着相同 IP 的客户端将始终被路由到同一台后端服务器，从而实现了会话一致性。这对于某些应用程序来说非常重要，因为它们需要确保会话中的数据始终存储在同一服务器上。 无需共享会话存储：由于相同 IP 的客户端被路由到同一台后端服务器，因此不需要在不同服务器之间共享会话数据。每个服务器都可以独立地管理和存储会话数据，简化了架构和部署。 易于扩展：通过使用 ip_hash，可以在增加服务器时轻松扩展应用程序的容量。每当引入新的服务器时，部分客户端会话将自动路由到新服务器，从而实现负载均衡和扩展性。 缺点：\n不适用于动态 IP 地址：ip_hash 指令是基于客户端的 IP 地址进行路由的，因此对于使用动态 IP 地址的客户端，会话一致性可能无法实现。当客户端的 IP 地址发生变化时，会导致会话被重新分配到不同的服务器上，可能导致会话状态丢失。 不适用于共享负载均衡：使用 ip_hash 时，每个客户端被路由到特定的服务器，这可能导致服务器之间的负载不均衡。如果某些客户端的 IP 地址集中在某几个服务器上，而其他服务器的负载较轻，则会导致资源利用不均衡。 单点故障：如果某个服务器出现故障，所有与该服务器关联的客户端会话将受到影响，因为它们无法被正确路由到其他服务器。这可能导致服务中断和数据丢失。 总结起来，ip_hash 提供了简单且有效的会话共享方法，适用于某些特定场景。然而，它也存在一些限制，特别是对于动态 IP 地址和负载均衡的需求。在决定是否使用 ip_hash 时，需要仔细考虑应用程序的需求和架构，并权衡其中的优缺点。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/11/til/","summary":"今天做了什么：\n1、观看 B 站 《SSO单点登录》视频\n2、参考 https://github.com/jOOQ/jOOL 和 https://github.com/vavr-io/vavr ，将 CheckedXXX 的类加入公司项目中。\n涉及的类有：Async.java、Blocking.java、CheckedBiConsumer.java、CheckedBiFunction.java、CheckedBiPredicate.java、CheckedComparator.java、CheckedConsumer.java、CheckedFunction.java、CheckedPredicate.java、CheckedRunnable.java、CheckedSupplier.java、FunctionUtils.java、OnceConsumer.java、SameExecutorCompletionStage.java、UncheckedException.java，并添加单元测试类。\n示例代码：\n@FunctionalInterface public interface CheckedConsumer\u0026lt;T\u0026gt; { void accept(T t) throws Throwable; default CheckedConsumer\u0026lt;T\u0026gt; andThen(CheckedConsumer\u0026lt;? super T\u0026gt; after) { Objects.requireNonNull(after, \u0026#34;after is null\u0026#34;); return (T t) -\u0026gt; { accept(t); after.accept(t); }; } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; sneaky(CheckedConsumer\u0026lt;T\u0026gt; consumer) { return unchecked(consumer, RETHROW_ALL); } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; unchecked(CheckedConsumer\u0026lt;T\u0026gt; consumer) { return unchecked(consumer, THROWABLE_TO_RUNTIME_EXCEPTION); } static \u0026lt;T\u0026gt; Consumer\u0026lt;T\u0026gt; unchecked(CheckedConsumer\u0026lt;T\u0026gt; consumer, Consumer\u0026lt;Throwable\u0026gt; handler) { return t -\u0026gt; { try { consumer.accept(t); } catch (Throwable e) { handler.accept(e); throw new IllegalStateException(\u0026#34;Exception handler must throw a RuntimeException\u0026#34;, e); } }; } } 3、重构公司微服务框架\n4、明天待办事项：","title":"2024-01-11｜今天做了什么"},{"content":"今天做了什么：\n1、Java Lambda 增强 https://github.com/jOOQ/jOOL 和 https://github.com/vavr-io/vavr ，jOOL 在 jdk8 下存在编译错误，计划，整合这两个项目，创建一个新的项目，只引入自己需要的一些类。\n2、https://www.pac4j.org/ 一个安全框架\n3、https://github.com/apereo/inspektr 一个轻量级的 Java 审计框架。这个是在看 CAS 源码的过程中，发现的。\n在 CAS 的源码中，有一些比较不错的代码，引入到自己的项目中，另外，打算仿照这个 inspektr 框架，重写公司微服务项目中的日志记录模块。\n4、分享一个安全相关的 wiki 网站：https://wukong-doc.redhtc.com/security\n总结：\n待办事项：\n重写微服务日志记录模块 写一个 Lambda 类库 重构公司微服务框架 继续重构 foodie-cloud 支持单点登录 支持全文检索 集成 Spring Security OAuth2 ","permalink":"https://blog.chensoul.cc/posts/2024/01/10/til/","summary":"今天做了什么：\n1、Java Lambda 增强 https://github.com/jOOQ/jOOL 和 https://github.com/vavr-io/vavr ，jOOL 在 jdk8 下存在编译错误，计划，整合这两个项目，创建一个新的项目，只引入自己需要的一些类。\n2、https://www.pac4j.org/ 一个安全框架\n3、https://github.com/apereo/inspektr 一个轻量级的 Java 审计框架。这个是在看 CAS 源码的过程中，发现的。\n在 CAS 的源码中，有一些比较不错的代码，引入到自己的项目中，另外，打算仿照这个 inspektr 框架，重写公司微服务项目中的日志记录模块。\n4、分享一个安全相关的 wiki 网站：https://wukong-doc.redhtc.com/security\n总结：\n待办事项：\n重写微服务日志记录模块 写一个 Lambda 类库 重构公司微服务框架 继续重构 foodie-cloud 支持单点登录 支持全文检索 集成 Spring Security OAuth2 ","title":"2024-01-10｜今天做了什么"},{"content":"今天做了什么：\n使用 renovate 监控第三方依赖更新 ，renovate 貌似需要付费，放弃。 spring-security-oauth2-samples 示例工程重命名模块和包名，代码见 spring-security-oauth2-boot 实现单点登录并测试 实现单点登录并测试 实现单点登录（Single Sign-On，SSO）可以采用多种思路和技术。下面是几种常见的实现思路：\n基于令牌（Token）的SSO：用户在登录时，认证服务器颁发一个令牌给用户，该令牌包含用户的身份信息。用户在访问其他应用时，将令牌发送给应用服务器进行验证，从而实现单点登录。 基于会话（Session）的SSO：用户在登录时，认证服务器创建一个会话，并将会话ID发送给用户的浏览器。用户在访问其他应用时，浏览器将会话ID发送给应用服务器进行验证，从而实现单点登录。 基于身份提供者（Identity Provider，IdP）的SSO：使用一个独立的身份提供者（如OpenID Connect、SAML等），用户在登录时将身份验证委托给身份提供者。身份提供者负责验证用户身份，并向应用程序提供令牌或身份凭证，实现单点登录。 基于代理（Proxy）的SSO：通过在前端部署反向代理服务器或负载均衡器，将用户的登录状态存储在代理服务器中。用户访问其他应用时，代理服务器将用户的身份信息传递给应用服务器，从而实现单点登录。 基于统一认证系统（CAS）的SSO：使用CAS作为中央认证服务器，用户在登录时通过CAS进行认证，并获取一个票据（ticket）。用户访问其他应用时，应用服务器将票据发送给CAS进行验证，从而实现单点登录。 这些思路和技术并非互斥，可以根据具体需求和系统架构的复杂性选择适合的实现方式。此外，还可以使用现有的SSO解决方案和身份管理平台，如Auth0、Okta、Keycloak等，简化SSO的实现过程。\n基于 OAuth2 单点登录 在 spring-security-oauth2-legacy-examples 添加单点登录 github 示例。参考了 oauth2-sample-java-webapp\nCAS 实现单点登录 CAS（Central Authentication Service）是一套完整的统一身份认证解决方案，完整资料可查阅其 官方网站。CAS包括对应的协议(CAS Protocol)、协议的实现(CAS Server)和与CAS服务交互的软件包(CAS Client)。\nCAS Client接入示例：https://github.com/apereo?q=client\nCAS 交互时序图：https://apereo.github.io/cas/7.0.x/images/cas_flow_diagram.png\n参考 SpringBoot+CAS整合服务端和客户端实现SSO单点登录与登出快速入门上手 这篇文章，代码在 这里。\n","permalink":"https://blog.chensoul.cc/posts/2024/01/09/til/","summary":"今天做了什么：\n使用 renovate 监控第三方依赖更新 ，renovate 貌似需要付费，放弃。 spring-security-oauth2-samples 示例工程重命名模块和包名，代码见 spring-security-oauth2-boot 实现单点登录并测试 实现单点登录并测试 实现单点登录（Single Sign-On，SSO）可以采用多种思路和技术。下面是几种常见的实现思路：\n基于令牌（Token）的SSO：用户在登录时，认证服务器颁发一个令牌给用户，该令牌包含用户的身份信息。用户在访问其他应用时，将令牌发送给应用服务器进行验证，从而实现单点登录。 基于会话（Session）的SSO：用户在登录时，认证服务器创建一个会话，并将会话ID发送给用户的浏览器。用户在访问其他应用时，浏览器将会话ID发送给应用服务器进行验证，从而实现单点登录。 基于身份提供者（Identity Provider，IdP）的SSO：使用一个独立的身份提供者（如OpenID Connect、SAML等），用户在登录时将身份验证委托给身份提供者。身份提供者负责验证用户身份，并向应用程序提供令牌或身份凭证，实现单点登录。 基于代理（Proxy）的SSO：通过在前端部署反向代理服务器或负载均衡器，将用户的登录状态存储在代理服务器中。用户访问其他应用时，代理服务器将用户的身份信息传递给应用服务器，从而实现单点登录。 基于统一认证系统（CAS）的SSO：使用CAS作为中央认证服务器，用户在登录时通过CAS进行认证，并获取一个票据（ticket）。用户访问其他应用时，应用服务器将票据发送给CAS进行验证，从而实现单点登录。 这些思路和技术并非互斥，可以根据具体需求和系统架构的复杂性选择适合的实现方式。此外，还可以使用现有的SSO解决方案和身份管理平台，如Auth0、Okta、Keycloak等，简化SSO的实现过程。\n基于 OAuth2 单点登录 在 spring-security-oauth2-legacy-examples 添加单点登录 github 示例。参考了 oauth2-sample-java-webapp\nCAS 实现单点登录 CAS（Central Authentication Service）是一套完整的统一身份认证解决方案，完整资料可查阅其 官方网站。CAS包括对应的协议(CAS Protocol)、协议的实现(CAS Server)和与CAS服务交互的软件包(CAS Client)。\nCAS Client接入示例：https://github.com/apereo?q=client\nCAS 交互时序图：https://apereo.github.io/cas/7.0.x/images/cas_flow_diagram.png\n参考 SpringBoot+CAS整合服务端和客户端实现SSO单点登录与登出快速入门上手 这篇文章，代码在 这里。","title":"2024-01-09｜今天做了什么"},{"content":"今天做了什么：\nVPS 迁移\n继续重构 foodie-cloud\n参考 https://github.com/mybatis/parent/ 重构 chensoul-parent\n修改了 maven 插件 添加了 Github Actions VPS 迁移 迁移步骤：\n旧的 VPS 上备份数据库、nginx 配置文件、docker-compose 文件 新的 VPS 上安装 docker、docker-compose、nginx 新的 VPS 上恢复数据库，配置 nginx 修改 DNS 解析 ","permalink":"https://blog.chensoul.cc/posts/2024/01/08/til/","summary":"今天做了什么：\nVPS 迁移\n继续重构 foodie-cloud\n参考 https://github.com/mybatis/parent/ 重构 chensoul-parent\n修改了 maven 插件 添加了 Github Actions VPS 迁移 迁移步骤：\n旧的 VPS 上备份数据库、nginx 配置文件、docker-compose 文件 新的 VPS 上安装 docker、docker-compose、nginx 新的 VPS 上恢复数据库，配置 nginx 修改 DNS 解析 ","title":"2024-01-08｜今天做了什么"},{"content":"今天做了什么：\nNginx、正向代理和反向代理 Nginx 介绍 Nginx（发音为\u0026quot;engine-x\u0026quot;）是一个高性能的开源Web服务器和反向代理服务器。它专注于高并发、低内存消耗和高度模块化的架构，因此被广泛用于构建性能出色的网站、应用程序和服务。\n以下是一些关于 Nginx 的关键特点：\n高性能：Nginx 的设计目标之一是在高并发情况下提供卓越的性能。它使用异步、事件驱动的架构来处理请求，有效地管理系统资源，提供快速响应和高吞吐量。 高度可定制化：Nginx 的模块化架构使其高度可定制。它支持许多第三方模块和插件，可以根据具体需求进行扩展和定制。这使得开发人员可以根据自己的要求添加额外的功能和扩展 Nginx 的能力。 轻量级和低内存消耗：Nginx 是一个轻量级的服务器，具有低内存消耗。这使得它能够在资源受限的环境中高效运行，并处理大量的并发连接。 简单的配置和易于使用：Nginx 的配置文件采用简单的语法，易于理解和修改。它提供了清晰的文档和丰富的示例，使得用户可以快速上手并进行必要的配置。 功能：\n反向代理和负载均衡：Nginx 可以作为反向代理服务器，将客户端请求转发到后端服务器。它还支持负载均衡，可以将流量分配到多个后端服务器，提高系统的可靠性和性能。 静态文件服务：Nginx 可以快速、可靠地提供静态文件，减轻后端应用程序的负担。它可以通过高效的文件传输和缓存机制提供静态内容，提高网站的响应速度。 SSL/TLS 加密：Nginx 支持 SSL/TLS 加密，可以安全地传输数据。它提供强大的加密功能和配置选项，以保护网站和应用程序的安全性。 动态内容支持：尽管 Nginx 主要用于处理静态内容，但它也可以与后端应用程序（如 PHP、Python、Node.js 等）集成，以处理动态生成的内容。 HTTP/2 和 HTTP/3 支持：Nginx 支持最新的 HTTP/2 和 HTTP/3 协议，这些协议提供更快的数据传输和更低的延迟，改善用户体验。 高度可扩展：Nginx 的模块化架构使得它可以轻松地扩展和定制。它支持各种第三方模块和插件，可以满足不同场景和需求的要求。 正向代理和反向代理 正向代理 正向代理（Forward Proxy）是一种代理服务器的使用方式，它代表客户端向其他服务器发送请求。当客户端想要访问互联网上的资源时，它首先发送请求到正向代理服务器，然后由代理服务器代表客户端向目标服务器发起请求，获取响应并将其返回给客户端。\n正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。\n正向代理一般是在客户端设置代理服务器，通过代理服务器转发请求，最终访问到目标服务器。\n以下是正向代理的主要特点和用途：\n隐藏客户端身份：正向代理可以隐藏客户端的真实IP地址和身份，保护客户端的隐私和安全。目标服务器只能看到正向代理服务器的IP地址和请求，无法直接识别和追踪客户端。 访问控制和过滤：正向代理可以实施访问控制和过滤策略，限制客户端对特定资源的访问。它可以用于实施访问权限、URL过滤、内容过滤等，以便控制和管理客户端对互联网资源的访问。 缓存和加速：正向代理服务器可以缓存经常请求的资源，以提高访问速度并减轻目标服务器的负载。当多个客户端请求相同的资源时，代理服务器可以直接提供缓存的副本，而无需每次都向目标服务器发送请求。 对抗访问限制：在某些情况下，客户端可能无法直接访问某些资源，例如由于地理位置限制或网络防火墙的阻塞。通过使用正向代理，客户端可以通过代理服务器来访问被限制的资源，代理服务器充当中间人来获取资源并传递给客户端。 匿名上网：正向代理可以为用户提供匿名上网的功能，隐藏用户的真实身份和位置信息。这对于保护用户隐私、绕过地域限制和访问受限资源等情况非常有用。 总而言之，正向代理充当客户端和目标服务器之间的中间人，代表客户端发送请求并获取响应。它可以隐藏客户端身份、实施访问控制、提供缓存和加速等功能，为用户提供更安全和更灵活的访问互联网的方式。\n反向代理 反向代理（Reverse Proxy）服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源，反向代理服务器负责将请求转发给目标服务器。用户不需要知道目标服务器的地址，也无须在用户端作任何设定，对于用户来说，访问反向代理服务器是完全无感知的。\n以下是反向代理的主要特点和用途：\n负载均衡：反向代理可以作为负载均衡器，将客户端请求分发给多个后端服务器，以实现负载均衡。它可以根据服务器的负载情况、响应时间等指标动态地决定将请求发送到哪个后端服务器，以确保请求被合理地分散处理。 高可用性和故障恢复：通过反向代理，可以配置多个后端服务器作为冗余的备份。如果某个后端服务器出现故障或不可用，反向代理可以自动将请求转发到其他正常工作的后端服务器，以确保服务的可用性。 SSL 加密和安全性：反向代理可以与客户端之间建立安全的 SSL/TLS 连接，提供加密和身份验证功能。这样可以保护客户端与反向代理之间的通信，增强数据的安全性。 缓存和加速：反向代理可以缓存后端服务器返回的静态资源，如图片、CSS、JavaScript 文件等。当客户端请求这些资源时，反向代理可以直接提供缓存的副本，减轻后端服务器的负载并提高响应速度。 提供统一入口：反向代理可以将多个后端服务器提供的不同服务（如Web应用、API服务等）通过统一的入口点进行访问。这样客户端只需与反向代理通信，并由反向代理根据请求的路径将其转发到适当的后端服务器。 总结起来，反向代理充当了客户端和后端服务器之间的中间人，负责接收客户端的请求并将其转发给后端服务器。它可以实现负载均衡、提供高可用性、增加安全性、缓存和加速等功能，为客户端提供更高效、安全和可靠的访问体验。\n总结 正向代理：客户端请求目标服务器，请求会先经过代理服务器，然后再转发请求到目标服务器，获得内容后最后再响应给客户端。 反向代理：用户请求目标服务器，由代理服务器决定访问哪个 IP。 转发代理是位于用户设备和互联网之间的服务器。\n正向代理通常用于：\n保护客户端 避免浏览限制 阻止访问某些内容 反向代理是一种服务器，它接受客户端的请求，将请求转发到 Web 服务器，并将结果返回给客户端，就好像代理服务器已经处理了请求一样。\n反向代理适用于：\n保护服务器 负载均衡 缓存静态内容 加密和解密 SSL 通信 ","permalink":"https://blog.chensoul.cc/posts/2024/01/05/til/","summary":"今天做了什么：\nNginx、正向代理和反向代理 Nginx 介绍 Nginx（发音为\u0026quot;engine-x\u0026quot;）是一个高性能的开源Web服务器和反向代理服务器。它专注于高并发、低内存消耗和高度模块化的架构，因此被广泛用于构建性能出色的网站、应用程序和服务。\n以下是一些关于 Nginx 的关键特点：\n高性能：Nginx 的设计目标之一是在高并发情况下提供卓越的性能。它使用异步、事件驱动的架构来处理请求，有效地管理系统资源，提供快速响应和高吞吐量。 高度可定制化：Nginx 的模块化架构使其高度可定制。它支持许多第三方模块和插件，可以根据具体需求进行扩展和定制。这使得开发人员可以根据自己的要求添加额外的功能和扩展 Nginx 的能力。 轻量级和低内存消耗：Nginx 是一个轻量级的服务器，具有低内存消耗。这使得它能够在资源受限的环境中高效运行，并处理大量的并发连接。 简单的配置和易于使用：Nginx 的配置文件采用简单的语法，易于理解和修改。它提供了清晰的文档和丰富的示例，使得用户可以快速上手并进行必要的配置。 功能：\n反向代理和负载均衡：Nginx 可以作为反向代理服务器，将客户端请求转发到后端服务器。它还支持负载均衡，可以将流量分配到多个后端服务器，提高系统的可靠性和性能。 静态文件服务：Nginx 可以快速、可靠地提供静态文件，减轻后端应用程序的负担。它可以通过高效的文件传输和缓存机制提供静态内容，提高网站的响应速度。 SSL/TLS 加密：Nginx 支持 SSL/TLS 加密，可以安全地传输数据。它提供强大的加密功能和配置选项，以保护网站和应用程序的安全性。 动态内容支持：尽管 Nginx 主要用于处理静态内容，但它也可以与后端应用程序（如 PHP、Python、Node.js 等）集成，以处理动态生成的内容。 HTTP/2 和 HTTP/3 支持：Nginx 支持最新的 HTTP/2 和 HTTP/3 协议，这些协议提供更快的数据传输和更低的延迟，改善用户体验。 高度可扩展：Nginx 的模块化架构使得它可以轻松地扩展和定制。它支持各种第三方模块和插件，可以满足不同场景和需求的要求。 正向代理和反向代理 正向代理 正向代理（Forward Proxy）是一种代理服务器的使用方式，它代表客户端向其他服务器发送请求。当客户端想要访问互联网上的资源时，它首先发送请求到正向代理服务器，然后由代理服务器代表客户端向目标服务器发起请求，获取响应并将其返回给客户端。\n正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。\n正向代理一般是在客户端设置代理服务器，通过代理服务器转发请求，最终访问到目标服务器。\n以下是正向代理的主要特点和用途：\n隐藏客户端身份：正向代理可以隐藏客户端的真实IP地址和身份，保护客户端的隐私和安全。目标服务器只能看到正向代理服务器的IP地址和请求，无法直接识别和追踪客户端。 访问控制和过滤：正向代理可以实施访问控制和过滤策略，限制客户端对特定资源的访问。它可以用于实施访问权限、URL过滤、内容过滤等，以便控制和管理客户端对互联网资源的访问。 缓存和加速：正向代理服务器可以缓存经常请求的资源，以提高访问速度并减轻目标服务器的负载。当多个客户端请求相同的资源时，代理服务器可以直接提供缓存的副本，而无需每次都向目标服务器发送请求。 对抗访问限制：在某些情况下，客户端可能无法直接访问某些资源，例如由于地理位置限制或网络防火墙的阻塞。通过使用正向代理，客户端可以通过代理服务器来访问被限制的资源，代理服务器充当中间人来获取资源并传递给客户端。 匿名上网：正向代理可以为用户提供匿名上网的功能，隐藏用户的真实身份和位置信息。这对于保护用户隐私、绕过地域限制和访问受限资源等情况非常有用。 总而言之，正向代理充当客户端和目标服务器之间的中间人，代表客户端发送请求并获取响应。它可以隐藏客户端身份、实施访问控制、提供缓存和加速等功能，为用户提供更安全和更灵活的访问互联网的方式。\n反向代理 反向代理（Reverse Proxy）服务器位于用户与目标服务器之间，但是对于用户而言，反向代理服务器就相当于目标服务器，即用户直接访问反向代理服务器就可以获得目标服务器的资源，反向代理服务器负责将请求转发给目标服务器。用户不需要知道目标服务器的地址，也无须在用户端作任何设定，对于用户来说，访问反向代理服务器是完全无感知的。\n以下是反向代理的主要特点和用途：\n负载均衡：反向代理可以作为负载均衡器，将客户端请求分发给多个后端服务器，以实现负载均衡。它可以根据服务器的负载情况、响应时间等指标动态地决定将请求发送到哪个后端服务器，以确保请求被合理地分散处理。 高可用性和故障恢复：通过反向代理，可以配置多个后端服务器作为冗余的备份。如果某个后端服务器出现故障或不可用，反向代理可以自动将请求转发到其他正常工作的后端服务器，以确保服务的可用性。 SSL 加密和安全性：反向代理可以与客户端之间建立安全的 SSL/TLS 连接，提供加密和身份验证功能。这样可以保护客户端与反向代理之间的通信，增强数据的安全性。 缓存和加速：反向代理可以缓存后端服务器返回的静态资源，如图片、CSS、JavaScript 文件等。当客户端请求这些资源时，反向代理可以直接提供缓存的副本，减轻后端服务器的负载并提高响应速度。 提供统一入口：反向代理可以将多个后端服务器提供的不同服务（如Web应用、API服务等）通过统一的入口点进行访问。这样客户端只需与反向代理通信，并由反向代理根据请求的路径将其转发到适当的后端服务器。 总结起来，反向代理充当了客户端和后端服务器之间的中间人，负责接收客户端的请求并将其转发给后端服务器。它可以实现负载均衡、提供高可用性、增加安全性、缓存和加速等功能，为客户端提供更高效、安全和可靠的访问体验。\n总结 正向代理：客户端请求目标服务器，请求会先经过代理服务器，然后再转发请求到目标服务器，获得内容后最后再响应给客户端。 反向代理：用户请求目标服务器，由代理服务器决定访问哪个 IP。 转发代理是位于用户设备和互联网之间的服务器。\n正向代理通常用于：\n保护客户端 避免浏览限制 阻止访问某些内容 反向代理是一种服务器，它接受客户端的请求，将请求转发到 Web 服务器，并将结果返回给客户端，就好像代理服务器已经处理了请求一样。\n反向代理适用于：\n保护服务器 负载均衡 缓存静态内容 加密和解密 SSL 通信 ","title":"2024-01-05｜Nginx、正向代理和反向代理"},{"content":"今天做了什么：\n修改个人联系方式 注销亚马逊账号 利用GitHub Actions自动优雅地为项目构建Releases 利用GitHub Actions自动构建项目的docker镜像并发布到DockerHub 修改个人联系方式 使用 ichensoul 注册了新的 Gmail、163 邮箱，并将各种网站绑定的邮箱修改到新的 gmail 邮箱。自此，gmail、github、推特、微信、163 的账号都保持为一致，都是 ichensoul。\n以下是 github 上我的个人联系方式。\n健康，爱情和使命，按照这个顺序，其它的都不重要。 \u0026mdash;\u0026mdash; 纳瓦尔\n我是 ChenSoul，一个 Java 软件开发工程师，目前工作在武汉。\n热爱编程，喜欢跑步。读书、健身、定投、帮朋友、陪家人，做一个长期主义者。\n网站 博客：https://blog.chensoul.cc/ 跑步：https://run.chensoul.cc/ Memos：https://memos.chensoul.cc/ 找到我 微信：@ichensoul 邮箱：ichensoul@gmail.com Github：https://github.com/chensoul、https://github.com/ichensoul Twitter：https://twitter.com/ichensoul Telegram频道：https://t.me/chensoul_share 注销亚马逊账号 缘由是，之前总是收到亚马逊的付款账单（每个月 0.5 美元，有时候1 美元），故元旦放假的时候登陆了亚马逊账号查找付费原因。找了半天没有找到是哪里产生的费用，就一怒之下把在亚马逊注册的域名（chensoul.com，一年 12 美元，一次性付费了 5 年）删除了。\n这几天发现本博客无法访问，于是提工单询问是否可以恢复域名。得到的回复是必须支付 66 美元，才能恢复一年。对此，我肯定无法接受。于是，决定注销亚马逊，在其他平台重新注册一个域名。\n今天在 CF 上注册了一个新的域名 chensoul.cc，一年 8 美元，一次性付费 5 年。在重新设置 DNS，修改 VPS 上的相关服务的域名为新域名之后，博客恢复正常。\n利用GitHub Actions自动优雅地为项目构建Releases 参考 利用GitHub Actions自动优雅地为项目构建Releases 为 github 上的项目 https://github.com/chensoul/chensoul-parent 添加一个机器人字段构建 Release。\n使用方法：\n1、参考 官方文档，在仓库里面配置一个 GitHub Action ，例如：.github/workflows/release-drafter.yml\nname: Release Drafter on: push: # branches to consider in the event; optional, defaults to all branches: - main # pull_request event is required only for autolabeler pull_request: # Only following types are handled by the action, but one can default to all as well types: [opened, reopened, synchronize] # pull_request_target event is required for autolabeler to support PRs from forks # pull_request_target: # types: [opened, reopened, synchronize] permissions: contents: read jobs: update_release_draft: permissions: # write permission is required to create a github release contents: write # write permission is required for autolabeler # otherwise, read permission is required at least pull-requests: write runs-on: ubuntu-latest steps: # (Optional) GitHub Enterprise requires GHE_HOST variable set #- name: Set GHE_HOST # run: | # echo \u0026#34;GHE_HOST=${GITHUB_SERVER_URL##https:\\/\\/}\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV # Drafts your next Release notes as Pull Requests are merged into \u0026#34;master\u0026#34; - uses: release-drafter/release-drafter@v5 # (Optional) specify config name to use, relative to .github/. Default: release-drafter.yml # with: # config-name: my-config.yml # disable-autolabeler: true env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} 说明：\n该 action 只对 main 分支起作用 该 action 只对 opened, reopened, synchronize 类型的 pull_request 起作用 2、添加 .github/release-drafter.yml 配置生成的 Release 内容\n# Configuration for Release Drafter: https://github.com/toolmantim/release-drafter name-template: \u0026#39;v$NEXT_PATCH_VERSION\u0026#39; tag-template: \u0026#39;v$NEXT_PATCH_VERSION\u0026#39; version-template: $MAJOR.$MINOR.$PATCH # Emoji reference: https://gitmoji.carloscuesta.me/ categories: - title: \u0026#39;⭐ New Features\u0026#39; labels: - \u0026#39;feature\u0026#39; - \u0026#39;enhancement\u0026#39; - \u0026#39;kind/feature\u0026#39; - title: \u0026#39;🐞 Bug Fixes\u0026#39; labels: - \u0026#39;fix\u0026#39; - \u0026#39;bugfix\u0026#39; - \u0026#39;bug\u0026#39; - \u0026#39;regression\u0026#39; - \u0026#39;kind/bug\u0026#39; - title: \u0026#39;📝 Documentation\u0026#39; labels: - documentation - \u0026#39;kind/doc\u0026#39; - title: \u0026#39;🧰 Dependency Upgrades\u0026#39; labels: - chore - dependencies - \u0026#39;kind/chore\u0026#39; - \u0026#39;kind/dep\u0026#39; - title: \u0026#39;🚦 Tests\u0026#39; labels: - test - tests exclude-labels: - reverted - no-changelog - skip-changelog - invalid change-template: \u0026#39;* $TITLE (#$NUMBER) @$AUTHOR\u0026#39; template: | ## What’s Changed $CHANGES 模板的含义是当提交的 PR 符合其中的 labels 时，对应提交的标题会作为当次提交的说明信息，生成在 release 的草稿中。\n有了这些内容，在每次 push 或者 pr 的时候，Actions 都会自动将当次的内容写入到 release 的草稿中，下次再有 pr 则内容将会是追加，并不会覆盖一开始的草稿。\n3、通常普通协作者在提交 pr 的时候，大概都很少会有主动给 pr 添加 labels 的，每次还需要项目负责人自己添加，会比较麻烦，而这个功能又是依赖 pr 的 labels 的，因此可以再加一个配置 .github/PULL_REQUEST_TEMPLATE.md，该文件配置可以仓库 GitHub pull request template。\nspring-boot 项目中的 .github/PULL_REQUEST_TEMPLATE.md 内容如下：\n\u0026lt;!-- Thanks for contributing to Spring Boot. Please review the following notes before submitting a pull request. Please submit only genuine pull-requests. Do not use this repository as a GitHub playground. Security Vulnerabilities STOP! If your contribution fixes a security vulnerability, please do not submit it. Instead, please head over to https://spring.io/security-policy to learn how to disclose a vulnerability responsibly. Dependency Upgrades Please do not open a pull request for a straightforward dependency upgrade (one that only updates the version property). We have a semi-automated process for such upgrades that we prefer to use. However, if the upgrade is more involved (such as requiring changes for removed or deprecated API) your pull request is most welcome. Describing Your Changes If, having reviewed the notes above, you\u0026#39;re ready to submit your pull request, please provide a brief description of the proposed changes. If they fix a bug, please describe the broken behaviour and how the changes fix it. If they make an enhancement, please describe the new functionality and why you believe it\u0026#39;s useful. If your pull request relates to any existing issues, please reference them by using the issue number prefixed with #. --\u0026gt; 综合上面的例子，我的 .github/PULL_REQUEST_TEMPLATE.md 内容如下：\n\u0026lt;!-- Thanks for contributing to this project. Please review the following notes before submitting a pull request. Please submit only genuine pull-requests. Do not use this repository as a GitHub playground. Dependency Upgrades Please do not open a pull request for a straightforward dependency upgrade (one that only updates the version property). We have a semi-automated process for such upgrades that we prefer to use. However, if the upgrade is more involved (such as requiring changes for removed or deprecated API) your pull request is most welcome. Describing Your Changes If, having reviewed the notes above, you\u0026#39;re ready to submit your pull request, please provide a brief description of the proposed changes. If they fix a bug, please describe the broken behaviour and how the changes fix it. If they make an enhancement, please describe the new functionality and why you believe it\u0026#39;s useful. If your pull request relates to any existing issues, please reference them by using the issue number prefixed with #. --\u0026gt; ## Describing Your Changes ## Checklist before requesting a review - [ ] I have performed a self-review of my code - [ ] If it is a core feature, I have added thorough tests. - [ ] Do we need to implement analytics? - [ ] Will this be part of a product update? If yes, please write one phrase about this update. 这样协作者提交 pr 的时候就会主动提示协作者尽量给当次 pr 添加一个或多个合适的 labels。\n最后来看下生成的 release drafter：\n利用GitHub Actions自动构建项目的docker镜像并发布到DockerHub 参考 利用GitHub Actions自动构建项目的docker镜像并发布到DockerHub ，给 https://github.com/chensoul/maven-hello-world 添加了一个 docker action： .github/workflows/docker-image.yml name: build_docker on: release: types: [created] # 表示在创建正式的 Release 时触发 jobs: build_docker: name: Build docker runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 # 利用github-slug-action暴漏Github Action上下文中的关键变量 https://wiki.eryajf.net/pages/77e2fe - name: Inject slug/short variables uses: rlespinasse/github-slug-action@v4 - name: Set up QEMU uses: docker/setup-qemu-action@v2 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v2 - name: Login to DockerHub uses: docker/login-action@v2 with: username: ${{ secrets.DOCKERHUB_USERNAME }} password: ${{ secrets.DOCKERHUB_TOKEN }} - name: Build And Push uses: docker/build-push-action@v3 with: context: . platforms: linux/amd64,linux/arm64 push: ${{ github.event_name != \u0026#39;pull_request\u0026#39; }} tags: | ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.GITHUB_REPOSITORY_NAME_PART }}:${{ env.GITHUB_REF_NAME }} ${{ secrets.DOCKERHUB_USERNAME }}/${{ env.GITHUB_REPOSITORY_NAME_PART }}:latest 关键点：使用 rlespinasse/github-slug-action@v4 暴漏Github Action上下文中的关键变量。请参考：利用github-slug-action暴漏Github Action上下文中的关键变量 。\nWakatime 编码统计 Wakatime记录的今日编码时间统计：\n参考文章 利用GitHub Actions自动优雅地为项目构建Releases 利用GitHub Actions自动构建项目的docker镜像并发布到DockerHub 利用github-slug-action暴漏Github Action上下文中的关键变量 ","permalink":"https://blog.chensoul.cc/posts/2024/01/04/til/","summary":"今天做了什么：\n修改个人联系方式 注销亚马逊账号 利用GitHub Actions自动优雅地为项目构建Releases 利用GitHub Actions自动构建项目的docker镜像并发布到DockerHub 修改个人联系方式 使用 ichensoul 注册了新的 Gmail、163 邮箱，并将各种网站绑定的邮箱修改到新的 gmail 邮箱。自此，gmail、github、推特、微信、163 的账号都保持为一致，都是 ichensoul。\n以下是 github 上我的个人联系方式。\n健康，爱情和使命，按照这个顺序，其它的都不重要。 \u0026mdash;\u0026mdash; 纳瓦尔\n我是 ChenSoul，一个 Java 软件开发工程师，目前工作在武汉。\n热爱编程，喜欢跑步。读书、健身、定投、帮朋友、陪家人，做一个长期主义者。\n网站 博客：https://blog.chensoul.cc/ 跑步：https://run.chensoul.cc/ Memos：https://memos.chensoul.cc/ 找到我 微信：@ichensoul 邮箱：ichensoul@gmail.com Github：https://github.com/chensoul、https://github.com/ichensoul Twitter：https://twitter.com/ichensoul Telegram频道：https://t.me/chensoul_share 注销亚马逊账号 缘由是，之前总是收到亚马逊的付款账单（每个月 0.5 美元，有时候1 美元），故元旦放假的时候登陆了亚马逊账号查找付费原因。找了半天没有找到是哪里产生的费用，就一怒之下把在亚马逊注册的域名（chensoul.com，一年 12 美元，一次性付费了 5 年）删除了。\n这几天发现本博客无法访问，于是提工单询问是否可以恢复域名。得到的回复是必须支付 66 美元，才能恢复一年。对此，我肯定无法接受。于是，决定注销亚马逊，在其他平台重新注册一个域名。\n今天在 CF 上注册了一个新的域名 chensoul.cc，一年 8 美元，一次性付费 5 年。在重新设置 DNS，修改 VPS 上的相关服务的域名为新域名之后，博客恢复正常。\n利用GitHub Actions自动优雅地为项目构建Releases 参考 利用GitHub Actions自动优雅地为项目构建Releases 为 github 上的项目 https://github.com/chensoul/chensoul-parent 添加一个机器人字段构建 Release。\n使用方法：\n1、参考 官方文档，在仓库里面配置一个 GitHub Action ，例如：.github/workflows/release-drafter.yml\nname: Release Drafter on: push: # branches to consider in the event; optional, defaults to all branches: - main # pull_request event is required only for autolabeler pull_request: # Only following types are handled by the action, but one can default to all as well types: [opened, reopened, synchronize] # pull_request_target event is required for autolabeler to support PRs from forks # pull_request_target: # types: [opened, reopened, synchronize] permissions: contents: read jobs: update_release_draft: permissions: # write permission is required to create a github release contents: write # write permission is required for autolabeler # otherwise, read permission is required at least pull-requests: write runs-on: ubuntu-latest steps: # (Optional) GitHub Enterprise requires GHE_HOST variable set #- name: Set GHE_HOST # run: | # echo \u0026#34;GHE_HOST=${GITHUB_SERVER_URL##https:\\/\\/}\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV # Drafts your next Release notes as Pull Requests are merged into \u0026#34;master\u0026#34; - uses: release-drafter/release-drafter@v5 # (Optional) specify config name to use, relative to .","title":"2024-01-04｜今天做了什么"},{"content":"今天做了什么：\nidworker-client ，一个开源的 ID 生成器，适合在单机使用 github 上创建了一个使用 spring cloud netflix 相关组件的微服务项目 spring-cloud-netflix-examples 重构了狂野架构师课程中的微服务版本的源码 foodie-cloud 重构慕课网 Java架构师-技术专家 课程中的 源码，我做了一些改动：\n升级 Spring Boot 和 Spring Cloud 版本 去掉 tk-mybatis 改为使用 mybatis-plus 重构模块和部分代码 重构后的源码地址：https://github.com/chensoul/foodie-cloud\n后续计划：\ndocker 容器编排 k8s 容器编排 集成 Spring Security OAuth2 集成 Spring Cloud alibaba 开发环境和开源项目版本 软件版本：\n组件 用途 版本号 Redis 缓存组件 5.0.4 RabbitMQ 消息中间件 3.7.15 Kafka 消息中间件 2.2.0 Lua 限流脚本 5.3.5 MySQL 数据库 5.7 IDEA 开发环境 版本随意 Java 编译运行项目 1.8以上（推荐8u161以后的版本，否则要装JCE插件） Maven 依赖管理 3.0.4以上 Maven 依赖版本：\n组件 版本号 Spring Cloud 2021.0.9 Spring Boot 2.7.18 Mybatis Plus 3.5.5 技术选型 Spring Cloud每个业务领域都有多个可供选择的组件，这里也列出了微服务章节中将要用到的组件+中间件的技术选型，这也是当前主流的选型。\n内容 技术选型 服务治理 Eureka 负载均衡 Ribbon 服务间调用 Feign 服务容错 Hystrix + Turbine + Dashboard 配置管理 Config + Github 消息总线 Bus + RabbitMQ 服务网关 Gateway 调用链追踪 Sleuth + Zipkin + ELK 消息驱动 Stream + RabbitMQ 流控 Sentinel 基于RPC的服务治理（不集成到电商项目） Dubbo + Admin Portal 默认端口 内容 端口 Eureka 20000 Turbine 20001 Hystrix-Dashboard 20002 Config-Server 20003 Gateway 20004 Zipkin 9411 ELK镜像-ES 9200 ELK镜像-Logstash 5044 ELK镜像-Kibana 5601 redis（单机模式） 6379 rabbitmq（单机模式） 5672 mariadb/mysql（单机模式） 3306 商品微服务 10001 用户微服务 10002 订单微服务 10003 购物车微服务 10004 权限微服务 10006 主搜微服务 同学们自己实现 支付服务 没变，但回调地址要改一下 启动方式 可以在IDEA里启动，也可以使用Maven编译后在命令行窗口启动，命令行启动方式需要在maven编译好项目之后，cd到对应项目下的target目录，然后使用命令\u0026quot;java -jar xxx.jar\u0026quot;执行编译好的jar包即可。\n启动顺序：\n先确保RabbitMQ，Redis和Mariadb/MySQL处于启动状态 启动Eureka - 所有微服务和SC平台组件都依赖Eureka做服务注册 启动Config-Server - 部分微服务依赖配置中心拉取配置项 启动Hystrix监控模块 - Turbine和Hystrix-Dashboard，等到后续微服务注册到注册中心后，Turbine下次做服务发现之后就可以正常收集数据了 启动链路追踪组件 - Zipkin和ELK容器 依次启动Auth微服务 -\u0026gt; User微服务 -\u0026gt; Item微服务 -\u0026gt; Cart微服务 -\u0026gt; Order微服务，以及留给同学们完成的主搜服务，支付中心 最后启动Gateway网关 - 在微服务都启动好之后再启动网关，可以保证网关启动后立即生效。反过来先启动网关再注册微服务也行，但是Gateway会处于短暂的不可用状态，因为Gateway启动的时候微服务还没注册，需要等Gateway做服务发现后才能生效 ","permalink":"https://blog.chensoul.cc/posts/2024/01/03/til/","summary":"今天做了什么：\nidworker-client ，一个开源的 ID 生成器，适合在单机使用 github 上创建了一个使用 spring cloud netflix 相关组件的微服务项目 spring-cloud-netflix-examples 重构了狂野架构师课程中的微服务版本的源码 foodie-cloud 重构慕课网 Java架构师-技术专家 课程中的 源码，我做了一些改动：\n升级 Spring Boot 和 Spring Cloud 版本 去掉 tk-mybatis 改为使用 mybatis-plus 重构模块和部分代码 重构后的源码地址：https://github.com/chensoul/foodie-cloud\n后续计划：\ndocker 容器编排 k8s 容器编排 集成 Spring Security OAuth2 集成 Spring Cloud alibaba 开发环境和开源项目版本 软件版本：\n组件 用途 版本号 Redis 缓存组件 5.0.4 RabbitMQ 消息中间件 3.7.15 Kafka 消息中间件 2.2.0 Lua 限流脚本 5.3.5 MySQL 数据库 5.7 IDEA 开发环境 版本随意 Java 编译运行项目 1.8以上（推荐8u161以后的版本，否则要装JCE插件） Maven 依赖管理 3.0.4以上 Maven 依赖版本：\n组件 版本号 Spring Cloud 2021.0.9 Spring Boot 2.7.18 Mybatis Plus 3.5.5 技术选型 Spring Cloud每个业务领域都有多个可供选择的组件，这里也列出了微服务章节中将要用到的组件+中间件的技术选型，这也是当前主流的选型。\n内容 技术选型 服务治理 Eureka 负载均衡 Ribbon 服务间调用 Feign 服务容错 Hystrix + Turbine + Dashboard 配置管理 Config + Github 消息总线 Bus + RabbitMQ 服务网关 Gateway 调用链追踪 Sleuth + Zipkin + ELK 消息驱动 Stream + RabbitMQ 流控 Sentinel 基于RPC的服务治理（不集成到电商项目） Dubbo + Admin Portal 默认端口 内容 端口 Eureka 20000 Turbine 20001 Hystrix-Dashboard 20002 Config-Server 20003 Gateway 20004 Zipkin 9411 ELK镜像-ES 9200 ELK镜像-Logstash 5044 ELK镜像-Kibana 5601 redis（单机模式） 6379 rabbitmq（单机模式） 5672 mariadb/mysql（单机模式） 3306 商品微服务 10001 用户微服务 10002 订单微服务 10003 购物车微服务 10004 权限微服务 10006 主搜微服务 同学们自己实现 支付服务 没变，但回调地址要改一下 启动方式 可以在IDEA里启动，也可以使用Maven编译后在命令行窗口启动，命令行启动方式需要在maven编译好项目之后，cd到对应项目下的target目录，然后使用命令\u0026quot;java -jar xxx.","title":"2024-01-03｜今天做了什么"},{"content":"今天做了什么：\n雪崩问题 Spring Cloud微服务集成 Sentinel 扩展 Sentinel 集成 OpenFeign，实现自动降级 雪崩问题 1、什么是雪崩问题？\n雪崩问题（Avalanche Effect）是指在分布式系统中，当一个节点或服务出现故障或不可用时，其影响会扩散到其他节点或服务，导致级联故障的现象。这种现象类似于雪崩，一旦开始，会不断放大和蔓延，最终导致整个系统崩溃。\n雪崩问题的主要原因是系统中的节点或服务之间存在过度依赖、高度耦合，以及缺乏容错机制。当一个节点或服务出现故障时，由于其他节点或服务无法及时处理或适应，故障会不断传播，最终导致整个系统的崩溃。\n2、如何解决雪崩问题？\n超时处理：在请求其他节点或服务时，设置适当的超时时间。如果在规定的时间内未收到响应，可以认为请求失败，并进行相应的处理，如返回默认值或错误信息。超时处理可以防止因等待过长的响应时间导致的请求堆积和资源浪费。 线程隔离：通过将不同的请求在不同的线程中执行，可以避免因某个请求的执行时间过长而影响其他请求的处理。线程隔离可以通过线程池或独立的线程来实现。每个请求都在独立的线程中执行，发生故障或异常时只会影响当前请求，而不会影响整个系统的稳定性。 降级熔断：当系统压力过大或出现故障时，可以通过降级熔断机制暂时关闭或减少对某些功能或服务的请求，以保护核心功能的稳定性。例如，当请求某个服务的失败率超过阈值时，可以自动触发熔断机制，暂时停止对该服务的请求，并返回一个默认值或错误信息。 流量控制：通过实施流量控制策略，限制对系统的并发请求数量。可以使用令牌桶算法或漏桶算法等进行流量控制。这可以避免过多的请求集中在某个节点或服务上，导致其负载过重，进而引发雪崩效应。 负载均衡：使用负载均衡器将请求分发到多个节点或服务上，以均衡系统的负载。负载均衡可以基于不同的算法，如轮询、随机、加权轮询等。通过负载均衡，可以避免单一节点或服务承受过大的压力，从而减少故障和雪崩的风险。 这些方法可以单独或组合使用，具体的选择和实施取决于系统的需求和架构。此外，还需要定期进行系统性能评估和压力测试，以便及时发现和解决潜在的雪崩问题，并不断优化系统的可靠性和稳定性。\nSpring Cloud 微服务集成 Sentinel 添加 maven 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加配置文件：\nspring.cloud.sentinel.transport.dashboard=localhost:8080 配置文件打开 Sentinel 对 Feign 的支持：feign.sentinel.enabled=true\n加入 spring-cloud-starter-openfeign 依赖使 Sentinel starter 中的自动化配置类生效：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 RestTemplate 支持 sentinel：\n@Bean @SentinelRestTemplate( blockHandler = \u0026#34;handleBlock\u0026#34;, fallback = \u0026#34;handleFallback\u0026#34;, fallbackClass = SentinelFallbackBlockHandler.class, blockHandlerClass = SentinelFallbackBlockHandler.class) public RestTemplate restTemplate() { return new RestTemplate(); } SentinelFallbackBlockHandler 类：\npublic class SentinelFallbackBlockHandler { public static ClientHttpResponse handleBlock(HttpRequest request, byte[] body, ClientHttpRequestExecution execution, BlockException exception) { return new SentinelClientHttpResponse(); } public static ClientHttpResponse handleFallback(HttpRequest request, byte[] body, ClientHttpRequestExecution execution, BlockException ex) { return new SentinelClientHttpResponse(); } } 扩展 Sentinel 集成 OpenFeign，实现自动降级 1、扩展 BlockExceptionHandler，实现 JSON 输出\n@Slf4j @RequiredArgsConstructor public class JsonBlockExceptionHandler implements BlockExceptionHandler { private final ObjectMapper objectMapper; @Override public void handle(HttpServletRequest request, HttpServletResponse response, BlockException e) throws Exception { log.error(\u0026#34;Sentinel fallback , resource is {}\u0026#34;, e.getRule().getResource(), e); response.setContentType(MediaType.APPLICATION_JSON_VALUE); response.setStatus(HttpStatus.TOO_MANY_REQUESTS.value()); response.getWriter().print(objectMapper.writeValueAsString(Result.error(ResultCode.TOO_MANY_REQUESTS))); } } 2、重写 SentinelInvocationHandler，实现自动降级处理\n@Slf4j public class AutoFallbackSentinelInvocationHandler implements InvocationHandler { public static final String EQUALS = \u0026#34;equals\u0026#34;; public static final String HASH_CODE = \u0026#34;hashCode\u0026#34;; public static final String TO_STRING = \u0026#34;toString\u0026#34;; private final Target\u0026lt;?\u0026gt; target; private final Map\u0026lt;Method, InvocationHandlerFactory.MethodHandler\u0026gt; dispatch; private FallbackFactory\u0026lt;?\u0026gt; fallbackFactory; private Map\u0026lt;Method, Method\u0026gt; fallbackMethodMap; AutoFallbackSentinelInvocationHandler(Target\u0026lt;?\u0026gt; target, Map\u0026lt;Method, InvocationHandlerFactory.MethodHandler\u0026gt; dispatch, FallbackFactory\u0026lt;?\u0026gt; fallbackFactory) { this.target = checkNotNull(target, \u0026#34;target\u0026#34;); this.dispatch = checkNotNull(dispatch, \u0026#34;dispatch\u0026#34;); this.fallbackFactory = fallbackFactory; this.fallbackMethodMap = toFallbackMethod(dispatch); } AutoFallbackSentinelInvocationHandler(Target\u0026lt;?\u0026gt; target, Map\u0026lt;Method, InvocationHandlerFactory.MethodHandler\u0026gt; dispatch) { this.target = checkNotNull(target, \u0026#34;target\u0026#34;); this.dispatch = checkNotNull(dispatch, \u0026#34;dispatch\u0026#34;); } @Override public Object invoke(final Object proxy, final Method method, final Object[] args) throws Throwable { if (EQUALS.equals(method.getName())) { try { Object otherHandler = args.length \u0026gt; 0 \u0026amp;\u0026amp; args[0] != null ? Proxy.getInvocationHandler(args[0]) : null; return equals(otherHandler); } catch (IllegalArgumentException e) { return false; } } else if (HASH_CODE.equals(method.getName())) { return hashCode(); } else if (TO_STRING.equals(method.getName())) { return toString(); } Object result; InvocationHandlerFactory.MethodHandler methodHandler = this.dispatch.get(method); // only handle by HardCodedTarget if (target instanceof Target.HardCodedTarget) { Target.HardCodedTarget\u0026lt;?\u0026gt; hardCodedTarget = (Target.HardCodedTarget) target; MethodMetadata methodMetadata = SentinelContractHolder.METADATA_MAP .get(hardCodedTarget.type().getName() + Feign.configKey(hardCodedTarget.type(), method)); // resource default is HttpMethod:protocol://url if (methodMetadata == null) { result = methodHandler.invoke(args); } else { String resourceName = methodMetadata.template().method().toUpperCase() + \u0026#39;:\u0026#39; + hardCodedTarget.url() + methodMetadata.template().path(); Entry entry = null; try { ContextUtil.enter(resourceName); entry = SphU.entry(resourceName, EntryType.OUT, 1, args); result = methodHandler.invoke(args); } catch (Throwable ex) { // fallback handle if (!BlockException.isBlockException(ex)) { Tracer.trace(ex); } if (fallbackFactory != null) { try { return fallbackMethodMap.get(method).invoke(fallbackFactory.create(ex), args); } catch (IllegalAccessException e) { // shouldn\u0026#39;t happen as method is public due to being an // interface throw new AssertionError(e); } catch (InvocationTargetException e) { throw new AssertionError(e.getCause()); } } else { // 若是Result类型 并且不包含@FeignRetry 执行自动降级返回 FeignRetry feignRetry = AnnotationUtils.findAnnotation(method, FeignRetry.class); if (Result.class == method.getReturnType() \u0026amp;\u0026amp; Objects.isNull(feignRetry)) { log.error(\u0026#34;服务调用异常\u0026#34;, ex); return Result.error(ResultCode.INNER_SERVICE_ERROR, ex.getMessage()); } else { throw ex; } } } finally { if (entry != null) { entry.exit(1, args); } ContextUtil.exit(); } } } else { // other target type using default strategy result = methodHandler.invoke(args); } return result; } @Override public boolean equals(Object obj) { if (obj instanceof SentinelInvocationHandler) { AutoFallbackSentinelInvocationHandler other = (AutoFallbackSentinelInvocationHandler) obj; return target.equals(other.target); } return false; } @Override public int hashCode() { return target.hashCode(); } @Override public String toString() { return target.toString(); } static Map\u0026lt;Method, Method\u0026gt; toFallbackMethod(Map\u0026lt;Method, InvocationHandlerFactory.MethodHandler\u0026gt; dispatch) { Map\u0026lt;Method, Method\u0026gt; result = new LinkedHashMap\u0026lt;\u0026gt;(); for (Method method : dispatch.keySet()) { method.setAccessible(true); result.put(method, method); } return result; } } 3、重写 SentinelFeign，支持自动降级注入\npublic final class AutoFallbackSentinelFeign { private AutoFallbackSentinelFeign() { } public static Builder builder() { return new Builder(); } public static final class Builder extends Feign.Builder implements ApplicationContextAware { private Contract contract = new Contract.Default(); private ApplicationContext applicationContext; private FeignContext feignContext; @Override public Feign.Builder invocationHandlerFactory(InvocationHandlerFactory invocationHandlerFactory) { throw new UnsupportedOperationException(); } @Override public Builder contract(Contract contract) { this.contract = contract; return this; } @Override public Feign build() { super.invocationHandlerFactory(new InvocationHandlerFactory() { @Override public InvocationHandler create(Target target, Map\u0026lt;Method, MethodHandler\u0026gt; dispatch) { // 查找 FeignClient 上的 降级策略 FeignClient feignClient = AnnotationUtils.findAnnotation(target.type(), FeignClient.class); Class\u0026lt;?\u0026gt; fallback = feignClient.fallback(); Class\u0026lt;?\u0026gt; fallbackFactory = feignClient.fallbackFactory(); String beanName = feignClient.contextId(); if (!StringUtils.hasText(beanName)) { beanName = feignClient.name(); } Object fallbackInstance; FallbackFactory\u0026lt;?\u0026gt; fallbackFactoryInstance; if (void.class != fallback) { fallbackInstance = getFromContext(beanName, \u0026#34;fallback\u0026#34;, fallback, target.type()); return new AutoFallbackSentinelInvocationHandler(target, dispatch, new FallbackFactory.Default(fallbackInstance)); } if (void.class != fallbackFactory) { //针对 hystrix fallbackFactory 特殊处理 try { fallbackFactoryInstance = (FallbackFactory\u0026lt;?\u0026gt;) getFromContext(beanName, \u0026#34;fallbackFactory\u0026#34;, fallbackFactory, FallbackFactory.class); } catch (Exception e) { return new AutoFallbackSentinelInvocationHandler(target, dispatch); } return new AutoFallbackSentinelInvocationHandler(target, dispatch, fallbackFactoryInstance); } return new AutoFallbackSentinelInvocationHandler(target, dispatch); } private Object getFromContext(String name, String type, Class\u0026lt;?\u0026gt; fallbackType, Class\u0026lt;?\u0026gt; targetType) { Object fallbackInstance = feignContext.getInstance(name, fallbackType); if (fallbackInstance == null) { throw new IllegalStateException(String .format(\u0026#34;No %s instance of type %s found for loadbalance client %s\u0026#34;, type, fallbackType, name)); } if (!targetType.isAssignableFrom(fallbackType)) { throw new IllegalStateException(String.format( \u0026#34;Incompatible %s instance. Fallback/fallbackFactory of type %s is not assignable to %s for loadbalance client %s\u0026#34;, type, fallbackType, targetType, name)); } return fallbackInstance; } }); super.contract(new SentinelContractHolder(contract)); return super.build(); } private Object getFieldValue(Object instance, String fieldName) { Field field = ReflectionUtils.findField(instance.getClass(), fieldName); field.setAccessible(true); try { return field.get(instance); } catch (IllegalAccessException e) { // ignore } return null; } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { this.applicationContext = applicationContext; feignContext = this.applicationContext.getBean(FeignContext.class); } } } 最后，再进行自动装配：\n@AutoConfiguration @AutoConfigureBefore(SentinelFeignAutoConfiguration.class) @ConditionalOnProperty(name = \u0026#34;feign.sentinel.enabled\u0026#34;, havingValue = \u0026#34;true\u0026#34;) public class SentinelFeignConfiguration { @Bean @Scope(\u0026#34;prototype\u0026#34;) @ConditionalOnMissingBean public Feign.Builder autoFallbackSentinelFeignBuilder() { return AutoFallbackSentinelFeign.builder(); } @Bean @ConditionalOnMissingBean public BlockExceptionHandler blockExceptionHandler(ObjectMapper objectMapper) { return new JsonBlockExceptionHandler(objectMapper); } @Bean @ConditionalOnMissingBean public RequestOriginParser requestOriginParser() { return new AllowHeaderRequestOriginParser(); } } ","permalink":"https://blog.chensoul.cc/posts/2024/01/02/til/","summary":"今天做了什么：\n雪崩问题 Spring Cloud微服务集成 Sentinel 扩展 Sentinel 集成 OpenFeign，实现自动降级 雪崩问题 1、什么是雪崩问题？\n雪崩问题（Avalanche Effect）是指在分布式系统中，当一个节点或服务出现故障或不可用时，其影响会扩散到其他节点或服务，导致级联故障的现象。这种现象类似于雪崩，一旦开始，会不断放大和蔓延，最终导致整个系统崩溃。\n雪崩问题的主要原因是系统中的节点或服务之间存在过度依赖、高度耦合，以及缺乏容错机制。当一个节点或服务出现故障时，由于其他节点或服务无法及时处理或适应，故障会不断传播，最终导致整个系统的崩溃。\n2、如何解决雪崩问题？\n超时处理：在请求其他节点或服务时，设置适当的超时时间。如果在规定的时间内未收到响应，可以认为请求失败，并进行相应的处理，如返回默认值或错误信息。超时处理可以防止因等待过长的响应时间导致的请求堆积和资源浪费。 线程隔离：通过将不同的请求在不同的线程中执行，可以避免因某个请求的执行时间过长而影响其他请求的处理。线程隔离可以通过线程池或独立的线程来实现。每个请求都在独立的线程中执行，发生故障或异常时只会影响当前请求，而不会影响整个系统的稳定性。 降级熔断：当系统压力过大或出现故障时，可以通过降级熔断机制暂时关闭或减少对某些功能或服务的请求，以保护核心功能的稳定性。例如，当请求某个服务的失败率超过阈值时，可以自动触发熔断机制，暂时停止对该服务的请求，并返回一个默认值或错误信息。 流量控制：通过实施流量控制策略，限制对系统的并发请求数量。可以使用令牌桶算法或漏桶算法等进行流量控制。这可以避免过多的请求集中在某个节点或服务上，导致其负载过重，进而引发雪崩效应。 负载均衡：使用负载均衡器将请求分发到多个节点或服务上，以均衡系统的负载。负载均衡可以基于不同的算法，如轮询、随机、加权轮询等。通过负载均衡，可以避免单一节点或服务承受过大的压力，从而减少故障和雪崩的风险。 这些方法可以单独或组合使用，具体的选择和实施取决于系统的需求和架构。此外，还需要定期进行系统性能评估和压力测试，以便及时发现和解决潜在的雪崩问题，并不断优化系统的可靠性和稳定性。\nSpring Cloud 微服务集成 Sentinel 添加 maven 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 添加配置文件：\nspring.cloud.sentinel.transport.dashboard=localhost:8080 配置文件打开 Sentinel 对 Feign 的支持：feign.sentinel.enabled=true\n加入 spring-cloud-starter-openfeign 依赖使 Sentinel starter 中的自动化配置类生效：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-openfeign\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 RestTemplate 支持 sentinel：\n@Bean @SentinelRestTemplate( blockHandler = \u0026#34;handleBlock\u0026#34;, fallback = \u0026#34;handleFallback\u0026#34;, fallbackClass = SentinelFallbackBlockHandler.class, blockHandlerClass = SentinelFallbackBlockHandler.class) public RestTemplate restTemplate() { return new RestTemplate(); } SentinelFallbackBlockHandler 类：\npublic class SentinelFallbackBlockHandler { public static ClientHttpResponse handleBlock(HttpRequest request, byte[] body, ClientHttpRequestExecution execution, BlockException exception) { return new SentinelClientHttpResponse(); } public static ClientHttpResponse handleFallback(HttpRequest request, byte[] body, ClientHttpRequestExecution execution, BlockException ex) { return new SentinelClientHttpResponse(); } } 扩展 Sentinel 集成 OpenFeign，实现自动降级 1、扩展 BlockExceptionHandler，实现 JSON 输出","title":"2024-01-02｜雪崩问题、Spring Cloud微服务集成 Sentinel"},{"content":"今天做了什么：\n重构微服务项目中使用 spring-security-oauth2 搭建 OAuth2 认证服务和资源服务的代码，减少其他模块对此的耦合度。计划将 spring-security-oauth2 迁移到 spring-security-oauth2-authorization-server 上，即使用 OAuth2.1 授权和认证。Spring Authorization Server 相关文档，可以参考 https://blog.51cto.com/u_15268610/category2。\n看 xuxiaowei-cloud master 分支源代码，整理 /login 登陆逻辑，参数：username、password、tenantId、clientId\n登陆成功\n记录登陆日志 转向 /login/success 获取客户端信息，将授权地址、校验 token 地址返回给前端 前端重定向到授权页面 授权同意，则重定向到客户端表中配置的重定向地址 /oauth2/code/{id}，并通过 code 去获取 token，最后再重定向到用户指定的回调地址 重新梳理用户中心领域模型。\n领域模型：\n客户端，对应 OAuth 中的客户端的概念。\n应用\n租户\n用户\n角色\n资源\n区域\n门店\n领域模型之间的关系说明：\n客户端和应用多对的的关系，应用和租户是多对多的关系，租户和资源是多对多的关系，应用和资源一对多的关系。为了简化操作，可以创建一个中间表保存客户端、应用、租户、资源之间的关系。 资源、用户、角色是 RBAC 模型。角色和应用是多对一的关系，租户和角色是一对多的关系，即角色是隶属于应用和租户。不太应用的不同租户下的角色不一样。 租户和区域是一对多的关系，区域和门店是一对多的关系，门店和应用是多对多的关系。 用户和租户是多对多的关系。 流程：\n登陆：使用用户名、密码、客户端 ID、租户 ID（首次登陆时为空，取用户有权限的租户中的第一个） 登陆。通过 客户端 ID、租户 ID 、用户名查询该用户的权限。 登陆之后，再选择租户进入首页。 创建客户端之后，可以绑定应用。 创建租户时，可以通过资源树（客户端+应用+资源）开通资源，可以给租户开通的应用开通门店。 ","permalink":"https://blog.chensoul.cc/posts/2023/12/28/til/","summary":"今天做了什么：\n重构微服务项目中使用 spring-security-oauth2 搭建 OAuth2 认证服务和资源服务的代码，减少其他模块对此的耦合度。计划将 spring-security-oauth2 迁移到 spring-security-oauth2-authorization-server 上，即使用 OAuth2.1 授权和认证。Spring Authorization Server 相关文档，可以参考 https://blog.51cto.com/u_15268610/category2。\n看 xuxiaowei-cloud master 分支源代码，整理 /login 登陆逻辑，参数：username、password、tenantId、clientId\n登陆成功\n记录登陆日志 转向 /login/success 获取客户端信息，将授权地址、校验 token 地址返回给前端 前端重定向到授权页面 授权同意，则重定向到客户端表中配置的重定向地址 /oauth2/code/{id}，并通过 code 去获取 token，最后再重定向到用户指定的回调地址 重新梳理用户中心领域模型。\n领域模型：\n客户端，对应 OAuth 中的客户端的概念。\n应用\n租户\n用户\n角色\n资源\n区域\n门店\n领域模型之间的关系说明：\n客户端和应用多对的的关系，应用和租户是多对多的关系，租户和资源是多对多的关系，应用和资源一对多的关系。为了简化操作，可以创建一个中间表保存客户端、应用、租户、资源之间的关系。 资源、用户、角色是 RBAC 模型。角色和应用是多对一的关系，租户和角色是一对多的关系，即角色是隶属于应用和租户。不太应用的不同租户下的角色不一样。 租户和区域是一对多的关系，区域和门店是一对多的关系，门店和应用是多对多的关系。 用户和租户是多对多的关系。 流程：\n登陆：使用用户名、密码、客户端 ID、租户 ID（首次登陆时为空，取用户有权限的租户中的第一个） 登陆。通过 客户端 ID、租户 ID 、用户名查询该用户的权限。 登陆之后，再选择租户进入首页。 创建客户端之后，可以绑定应用。 创建租户时，可以通过资源树（客户端+应用+资源）开通资源，可以给租户开通的应用开通门店。 ","title":"2023-12-28｜今天做了什么"},{"content":"今天做了什么：\n微服务项目中认证服务器配置授权码模式，并测试通过\n扩展 RedisAuthorizationCodeServices ，支持设置过期时间。\n注意：OAuth2Authentication 无法从 json 反序列化，故无法使用 JSON 反序列化类，只能使用 JDK 反序列化类。 扩展 BearerTokenExtractor，支持从 request 请求的 header 中读取 access_token\n配置 JWK token 使用时\n扩展 JwtAccessTokenConverter ，用于解析 jwks 接口返回的 json，相关说明参考 creating-the-jwk-set-endpoint JwkDefinitionSource 类中获取 jwkSetUrls 时，不支持 url 中配置服务名称，即不支持负载均衡。故，重写该类以支持通过 RestTemplate （可以注入一个支持负载均衡的 RestTemplate） 解析 jwkSetUrls 返回的 json 类型的字符串；创建了一个支持负载均衡的 TokenStore。 运行 xuxiaowei-cloud 项目时\n提示 Rollup failed to resolve import \u0026quot;@vue/shared\u0026quot;，原因：这个错误是由于无法解析到 @vue/shared 这个包导致的。@vue/shared 是 Vue 内部使用的一个共享工具库。解决方案：将 @vue/shared 添加到项目的依赖中。\nnpm install --save @vue/shared Controller 的方法上添加注解判断是否有权限，例子：@PreAuthorize(\u0026quot;hasAuthority('manage_user_authority') or #oauth2.hasScope('manage_user_authority')\u0026quot;)\nPrincipal 中的用户对象，即 UserDetails 对象不添加额外字段，只有 username，如果想获取用户信息，需要通过用户服务去查询。\n关于 OAuth2 的参考资料：\nOauth2.0搭建问题记录\nOAuth 2.0 实战\n关于 Spring Cloud 集成 OAuth2 的参考仓库：\nhttps://gitee.com/youlaitech/youlai-mall\nhttps://gitee.com/dromara/RuoYi-Cloud-Plus\nhttps://gitee.com/dromara/open-capacity-platform/\n","permalink":"https://blog.chensoul.cc/posts/2023/12/27/til/","summary":"今天做了什么：\n微服务项目中认证服务器配置授权码模式，并测试通过\n扩展 RedisAuthorizationCodeServices ，支持设置过期时间。\n注意：OAuth2Authentication 无法从 json 反序列化，故无法使用 JSON 反序列化类，只能使用 JDK 反序列化类。 扩展 BearerTokenExtractor，支持从 request 请求的 header 中读取 access_token\n配置 JWK token 使用时\n扩展 JwtAccessTokenConverter ，用于解析 jwks 接口返回的 json，相关说明参考 creating-the-jwk-set-endpoint JwkDefinitionSource 类中获取 jwkSetUrls 时，不支持 url 中配置服务名称，即不支持负载均衡。故，重写该类以支持通过 RestTemplate （可以注入一个支持负载均衡的 RestTemplate） 解析 jwkSetUrls 返回的 json 类型的字符串；创建了一个支持负载均衡的 TokenStore。 运行 xuxiaowei-cloud 项目时\n提示 Rollup failed to resolve import \u0026quot;@vue/shared\u0026quot;，原因：这个错误是由于无法解析到 @vue/shared 这个包导致的。@vue/shared 是 Vue 内部使用的一个共享工具库。解决方案：将 @vue/shared 添加到项目的依赖中。\nnpm install --save @vue/shared Controller 的方法上添加注解判断是否有权限，例子：@PreAuthorize(\u0026quot;hasAuthority('manage_user_authority') or #oauth2.hasScope('manage_user_authority')\u0026quot;)\nPrincipal 中的用户对象，即 UserDetails 对象不添加额外字段，只有 username，如果想获取用户信息，需要通过用户服务去查询。\n关于 OAuth2 的参考资料：\nOauth2.0搭建问题记录\nOAuth 2.0 实战\n关于 Spring Cloud 集成 OAuth2 的参考仓库：\nhttps://gitee.com/youlaitech/youlai-mall\nhttps://gitee.com/dromara/RuoYi-Cloud-Plus\nhttps://gitee.com/dromara/open-capacity-platform/","title":"2023-12-27｜今天做了什么"},{"content":"今天做了什么：\n我使用的 Idea 插件。\nspringdoc-openapi v1.7.0 示例\nSpring Security OAuth Boot 2 Autoconfig 转换成 maven 项目，并添加示例\nIdea 1、插件\nGenerateSerialVersionUID：自动生成 serialVersionUID\nMicroProfile Starter：创建 MicroProfile 微服务应用\nEasy Javadoc：快速生成 Javadoc\n快捷键 作用域 说明 ctrl \\ 类、方法、属性（光标放上面就行，不要双击选中！） 生成当前文档注释 ctrl \\ 选中的中文 生成选中的中文的英文命名 ctrl \\ 选中的非中文 弹框展示翻译结果 ctrl shift \\ 类 生成全部文档注释 .ignore\nMaven Helper\nMetricsReloaded\nMybatisX\nPlantUML Diagram Generator\nSave Actions Tool\nSequenceDiagram\nStringManipulation\nTranslation\nWakaTime\n2、快捷键\n多个窗口之前切换，MacOS 快捷键：Command + ~ springdoc-openapi v1.7.0 将项目中使用的 swagger doc 迁移到 springdoc-openapi v1.7.0，关于 springdoc 的使用，在 github 上创建了一个示例仓库： springdoc-examples\nSpring Security OAuth Boot 2 Autoconfig 将 Spring Security OAuth Boot 2 Autoconfig 修改成 maven 项目，并添加 samples 示例。修改后的项目地址：https://github.com/chensoul/spring-security-oauth2-boot\n","permalink":"https://blog.chensoul.cc/posts/2023/12/22/til/","summary":"今天做了什么：\n我使用的 Idea 插件。\nspringdoc-openapi v1.7.0 示例\nSpring Security OAuth Boot 2 Autoconfig 转换成 maven 项目，并添加示例\nIdea 1、插件\nGenerateSerialVersionUID：自动生成 serialVersionUID\nMicroProfile Starter：创建 MicroProfile 微服务应用\nEasy Javadoc：快速生成 Javadoc\n快捷键 作用域 说明 ctrl \\ 类、方法、属性（光标放上面就行，不要双击选中！） 生成当前文档注释 ctrl \\ 选中的中文 生成选中的中文的英文命名 ctrl \\ 选中的非中文 弹框展示翻译结果 ctrl shift \\ 类 生成全部文档注释 .ignore\nMaven Helper\nMetricsReloaded\nMybatisX\nPlantUML Diagram Generator\nSave Actions Tool\nSequenceDiagram\nStringManipulation\nTranslation\nWakaTime\n2、快捷键\n多个窗口之前切换，MacOS 快捷键：Command + ~ springdoc-openapi v1.7.0 将项目中使用的 swagger doc 迁移到 springdoc-openapi v1.7.0，关于 springdoc 的使用，在 github 上创建了一个示例仓库： springdoc-examples\nSpring Security OAuth Boot 2 Autoconfig 将 Spring Security OAuth Boot 2 Autoconfig 修改成 maven 项目，并添加 samples 示例。修改后的项目地址：https://github.com/chensoul/spring-security-oauth2-boot","title":"2023-12-22｜今天做了什么"},{"content":"Today I Learned. 今天分享内容：Spring Security 对 OAuth2 的支持\nSpring Security 提供了对 OAuth 的支持，并且有几个相关的项目可以用于实现 OAuth 功能。以下是一些常见的 Spring Security OAuth 项目及其相关信息：\nSpring Security OAuth（https://github.com/spring-attic/spring-security-oauth）：官方提供的 Spring Security OAuth 项目，为 Spring 应用程序提供了 OAuth 1.0 和 OAuth 2.0 的支持。该项目在 Spring Security 5.x 版本后已不再维护，建议使用后续提到的 Spring Authorization Server。 Spring Security 5（https://github.com/spring-attic/spring-security）：Spring Security 5.x 版本开始将 OAuth 2.0 客户端支持集成到核心库中，使得在 Spring Security 中实现 OAuth 2.0 认证变得更加简单。你可以使用 Spring Security 5.x 以及后续版本来实现 OAuth 2.0 客户端功能。 Spring Security OAuth2 Boot（https://github.com/spring-attic/spring-security-oauth2-boot），该项目是 spring-attic 组织维护的，提供了 Spring Boot 2 和旧版 Spring Security OAuth 的自动配置。该项目已经停止了活跃的开发和更新，最新的提交日期是 2022 年 5 月 20 日。 Spring Authorization Server（https://github.com/spring-projects/spring-authorization-server）：官方提供的用于构建 OAuth 2.0 授权服务器的实验性项目。它是 Spring Security 5.3 之后推出的替代方案，旨在提供更简化和灵活的 OAuth 2.0 授权服务器功能。 Authorization Server\n目前，Spring Security 不支持实现 OAuth 2.0 授权服务器。 但是，此功能可从 Spring Security OAuth 项目中获得，该项目最终将被 Spring Security 完全取代。 在此之前，您可以使用该 spring-security-oauth2-autoconfigure 模块轻松设置 OAuth 2.0 授权服务器；有关说明，请参阅其 文档。 Spring OAuth 2.0 Spring Security OAuth Boot Spring Cloud Security Spring OAuth 2.1 仓库地址 spring-security-oauth spring-security-oauth2-boot spring-cloud-security spring-authorization-server 是否更新 2022年6月1日归档 2022年5月31日归档 2022年4月4日归档 最新版本 2.5.2.RELEASE 2.6.8 2.2.5 1.2.1 授权方式 授权码 客户凭证 授权码 客户端凭据 隐式 密码 设备授权 JDK 8 支持，接口已全面废弃 1.0 之前的版本支持（0.3.0 仅支持 JDK 11） JDK 11 支持，接口已全面废弃 1.0 之前的版本支持 JDK 17 不支持 1.0 之后的版本支持 参考 https://github.com/spring-projects/spring-security/wiki/OAuth-2.0-Features-Matrix\n1、Spring Security 中 OAuth 2.0 支持的未来是什么？\nSpring Security 5.0 引入了对 OAuth 2.0 授权框架和 OpenID Connect 1.0 的新客户端支持。Spring Security 5.1 引入了新的资源服务器支持以及对不同授权类型的额外客户端支持。Spring Security 5.2延续了这一模式，为资源服务器和客户端提供了更多支持。\n2、Spring Security OAuth 2.3+ 中是否实现了新功能？\n我们将提供错误/安全修复并考虑添加较小的增强功能。我们未来的计划是将 Spring Security OAuth 中当前的所有功能构建到 Spring Security 5.x 中。在 Spring Security 达到与 Spring Security OAuth 同等的功能后，我们将继续支持错误和安全修复至少一年。\n3、Spring Boot 2.0 是否提供对 Spring Security OAuth 的支持？\nSpring Boot 2.0 已放弃对 Spring Security OAuth 的支持。但是，它在 Spring Security 5 中提供了对 OAuth 2.0 Login、OAuth 2.0 Client 和 OAuth 2.0 Resource Server 的支持。\n4、有没有办法在 Spring Boot 2.0 中集成 Spring Security OAuth？\nSpring Security OAuth Boot 2 Autoconfig项目是 Spring Boot 1.5.x 中包含的 Spring Security OAuth 自动配置的端口。如果您想在 Spring Boot 2.0 中使用 Spring Security OAuth，则必须在项目中显式包含以下依赖项：\n组ID: org.springframework.security.oauth.boot 工件ID： spring-security-oauth2-autoconfigure 我创建了一个项目 spring-security-oauth2-legacy，使用 Spring Security OAuth2 Boot 来自动装配资源服务器。目前，还在测试中。\n如果想基于 spring-authorization-server 创建认证服务器和资源服务器，可以参考 github 上这个仓库：xuxiaowei-cloud。\n其 main 分支基于 JDK 8/11、Spring Boot 2.7.x、OAuth 2.1、Vite 4、Vue 3、Element Plus 的微服务。支持支付宝、钉钉、码云、QQ、微信、企业微信、微博等第三方登录。包含基于 GitLab Runner 的 kubernetes（k8s）、Docker、Shell 等 CI/CD 流水线进行自动构建、制作 Docker 镜像、发布。永久免费开源。\n其archive/OAuth2.0 分支是基于 spring-security-oauth2-boot 实现的，可以参考代码。\n","permalink":"https://blog.chensoul.cc/posts/2023/12/21/til/","summary":"Today I Learned. 今天分享内容：Spring Security 对 OAuth2 的支持\nSpring Security 提供了对 OAuth 的支持，并且有几个相关的项目可以用于实现 OAuth 功能。以下是一些常见的 Spring Security OAuth 项目及其相关信息：\nSpring Security OAuth（https://github.com/spring-attic/spring-security-oauth）：官方提供的 Spring Security OAuth 项目，为 Spring 应用程序提供了 OAuth 1.0 和 OAuth 2.0 的支持。该项目在 Spring Security 5.x 版本后已不再维护，建议使用后续提到的 Spring Authorization Server。 Spring Security 5（https://github.com/spring-attic/spring-security）：Spring Security 5.x 版本开始将 OAuth 2.0 客户端支持集成到核心库中，使得在 Spring Security 中实现 OAuth 2.0 认证变得更加简单。你可以使用 Spring Security 5.x 以及后续版本来实现 OAuth 2.0 客户端功能。 Spring Security OAuth2 Boot（https://github.com/spring-attic/spring-security-oauth2-boot），该项目是 spring-attic 组织维护的，提供了 Spring Boot 2 和旧版 Spring Security OAuth 的自动配置。该项目已经停止了活跃的开发和更新，最新的提交日期是 2022 年 5 月 20 日。 Spring Authorization Server（https://github.com/spring-projects/spring-authorization-server）：官方提供的用于构建 OAuth 2.0 授权服务器的实验性项目。它是 Spring Security 5.3 之后推出的替代方案，旨在提供更简化和灵活的 OAuth 2.0 授权服务器功能。 Authorization Server\n目前，Spring Security 不支持实现 OAuth 2.","title":"2023-12-21｜Spring Security对OAuth2的支持及实现方式"},{"content":"Today I Learned. 今天分享内容：Maven配置继承和生命周期、源码运行Nacos 2.3.0控制台\nMaven 相关 Maven配置继承 以下是一些常见的POM节点，在子项目中可以继承或覆盖父项目的配置：\ngroupId（项目组ID）：如果在子项目中未定义groupId，则将继承父项目的groupId。\nversion（项目版本）：如果在子项目中未定义version，则将继承父项目的version。\nproperties（属性）：子项目可以继承父项目的属性定义，并在子项目中使用相同的属性。\ndependencies（依赖项）：子项目可以继承父项目的依赖项配置，包括依赖的groupId、artifactId和version等信息。\ndependencyManagement（依赖管理）：在父项目的dependencyManagement节点中定义的依赖版本可以被子项目继承和使用。\nbuild（构建配置）：子项目可以继承父项目的构建配置，包括插件配置、构建目录、资源目录等。子项目可以覆盖或添加额外的构建配置。\nreporting（报告配置）：子项目可以继承父项目的报告配置，包括报告插件的配置信息。\nrepositories（仓库配置）：子项目可以继承父项目的仓库配置，用于从指定的仓库解析依赖。\nscm（版本控制配置）：子项目可以继承父项目的 scm 节点中的配置，包括版本控制系统的 URL、连接器、标签等信息。\nissueManagement（问题管理配置）：子项目可以继承父项目的 issueManagement 节点中的配置，包括问题跟踪系统的 URL、连接器等信息。\norganization（组织配置）：子项目可以继承父项目的 organization 节点中的配置，包括组织的名称、URL 等信息。\ndevelopers（开发者配置）：子项目可以继承父项目的 developers 节点中的配置，包括开发者的姓名、邮箱等信息。\nlicenses（许可证配置）：子项目可以继承父项目的 licenses 节点中的配置，包括许可证的名称、URL、分发方式等信息。\ninceptionYear和url这两个节点在 Maven 的 POM 文件中无法被子项目继承。\ninceptionYear：这个节点用于指定项目的初始年份。它通常用于提供项目的创建或开始日期，但它不会被子项目继承。每个子项目需要在自己的 POM 文件中显式定义自己的inceptionYear。 url：这个节点用于指定项目的URL地址，例如项目的主页或版本控制仓库的URL。与inceptionYear类似，url节点也不会被子项目继承。每个子项目需要在自己的 POM 文件中显式定义自己的url。 这些节点通常是项目特定的信息，不具备被继承的属性，因此每个子项目都需要自行定义这些节点，以提供自己独特的项目起始年份和URL地址。\nMaven的生命周期 Maven的标准生命周期包括三个主要的生命周期：\nClean生命周期：用于清理项目构建产生的输出，包括删除生成的目录和文件。 clean：清理项目，删除生成的目录和文件。 Default生命周期：用于构建项目的核心生命周期，涵盖了项目的编译、测试、打包、部署等主要阶段。 validate：验证项目是否正确且所有必要信息可用。 compile：编译项目的源代码。 test：运行项目的单元测试。 package：将编译后的代码打包成可分发的格式，例如JAR、WAR。 install：将打包的项目安装到本地仓库，供其他项目使用。 deploy：将最终的包复制到远程仓库，供其他开发人员和项目使用。 Site生命周期：用于生成项目的站点文档。 site：生成项目的站点文档。 site-deploy：将生成的站点文档部署到远程服务器。 完整的生命周期：\nvalidate：验证项目是否正确且所有必要信息可用。 initialize：初始化构建环境，例如设置构建属性和加载父POM。 generate-sources：生成项目的源代码，例如通过处理注解或其他生成代码的工具。 process-sources：处理项目的源代码，例如对源代码进行过滤或转换。 generate-resources：生成项目的资源文件，例如拷贝资源文件到目标目录。 process-resources：处理项目的资源文件，例如过滤资源文件的占位符。 compile：编译项目的源代码，将源代码编译为字节码文件（.class文件）。 process-classes：对编译后的类文件进行额外的处理，例如生成额外的资源文件。 generate-test-sources：生成项目的测试源代码，例如通过处理注解或其他生成代码的工具。 process-test-sources：处理项目的测试源代码，例如对测试源代码进行过滤或转换。 generate-test-resources：生成项目的测试资源文件，例如拷贝测试资源文件到目标目录。 process-test-resources：处理项目的测试资源文件，例如过滤测试资源文件的占位符。 test-compile：编译项目的测试源代码，将测试源代码编译为字节码文件。 process-test-classes：对编译后的测试类文件进行额外的处理。 test：运行项目的单元测试。 prepare-package：准备打包阶段的相关工作，例如生成额外的文件或资源。 package：将项目打包成可分发的格式，例如JAR、WAR等。 pre-integration-test：在集成测试之前执行的一些准备工作。 integration-test：运行项目的集成测试。 post-integration-test：在集成测试之后执行的一些清理工作。 verify：验证项目的完整性，例如对生成的报告进行检查。 install：将项目的构件安装到本地仓库，供本地其他项目使用。 deploy：将项目的构件复制到远程仓库，供其他开发人员和项目使用。 maven-compiler-plugin 问题 github action 的机器人将 maven-compiler-plugin 版本升级到 3.12.0 ，运行 test 时出现异常：\nbasedir /Users/chensoul/workspace/IdeaProjects/cocktail/cocktail-cloud/cocktail/cocktail-oauth2/target/generated-test-sources/test-annotations does not exist 将版本降到 3.12.0，就正常。\nGitHub 上类似的问题：\nhttps://github.com/apache/maven-compiler-plugin/pull/191 源码运行 Nacos 2.3.0 1、下载源代码\ngit clone git@github.com:alibaba/nacos.git 2、拷贝 console 模块里面的 java 和 resources 目录和 pom.xml 代码到自己的项目里面\n3、console 模块 pom.xml 中有部分依赖最新版本没有发布到中央仓库，可以手动部署到自己的私有仓库里面\ngit checkout master mvn deploy -DskipTests=true 4、修改 pom.xml ，主要有以下几个改动：\n修改 nacos.version 版本为 2.3.0 修改 nacos 相关依赖的 groupId 为 com.alibaba.nacos 修改 nacos-default-plugin-impl 为 nacos-default-plugin-all \u0026lt;properties\u0026gt; \u0026lt;nacos.version\u0026gt;2.3.0\u0026lt;/nacos.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-sys\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-naming\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-default-plugin-all\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.nacos\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nacos-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${nacos.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 5、修改 application.properties 配置文件，配置数据库。取消以下几行的注释，并修改数据库配置\nspring.sql.init.platform=mysql db.num=1 db.url.0=jdbc:mysql://${MYSQL_HOST:localhost}:${MYSQL_PORT:3306}/nacos_2.2.4?characterEncoding=utf8\u0026amp;connectTimeout=1000\u0026amp;socketTimeout=3000\u0026amp;autoReconnect=true\u0026amp;useUnicode=true\u0026amp;useSSL=false\u0026amp;serverTimezone=UTC db.user=${MYSQL_USER:root} db.password=${MYSQL_PASS:123456} 6、修改启动类，设置单机模式启动\n修改 @SpringBootApplication 注解为 @SpringBootConfiguration 在 main 方法里添加一行代码：System.setProperty(Constants.STANDALONE_MODE_PROPERTY_NAME, \u0026quot;true\u0026quot;); 修改 derby.log 文件的路径 @SpringBootConfiguration @ComponentScan(basePackages = \u0026#34;com.alibaba.nacos\u0026#34;, excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = {NacosTypeExcludeFilter.class}), @Filter(type = FilterType.CUSTOM, classes = {TypeExcludeFilter.class}), @Filter(type = FilterType.CUSTOM, classes = {AutoConfigurationExcludeFilter.class})}) @ServletComponentScan @EnableScheduling public class Nacos { public static void main(String[] args) { // 通过环境变量的形式 设置 单机启动 System.setProperty(\u0026#34;nacos.standalone\u0026#34;, \u0026#34;true\u0026#34;); // 修改derby.log文件的路径 System.setProperty(\u0026#34;derby.stream.error.file\u0026#34;, System.getProperty(\u0026#34;java.io.tmpdir\u0026#34;) + \u0026#34;/derby.log\u0026#34;); SpringApplication.run(Nacos.class, args); } } ","permalink":"https://blog.chensoul.cc/posts/2023/12/20/til/","summary":"Today I Learned. 今天分享内容：Maven配置继承和生命周期、源码运行Nacos 2.3.0控制台\nMaven 相关 Maven配置继承 以下是一些常见的POM节点，在子项目中可以继承或覆盖父项目的配置：\ngroupId（项目组ID）：如果在子项目中未定义groupId，则将继承父项目的groupId。\nversion（项目版本）：如果在子项目中未定义version，则将继承父项目的version。\nproperties（属性）：子项目可以继承父项目的属性定义，并在子项目中使用相同的属性。\ndependencies（依赖项）：子项目可以继承父项目的依赖项配置，包括依赖的groupId、artifactId和version等信息。\ndependencyManagement（依赖管理）：在父项目的dependencyManagement节点中定义的依赖版本可以被子项目继承和使用。\nbuild（构建配置）：子项目可以继承父项目的构建配置，包括插件配置、构建目录、资源目录等。子项目可以覆盖或添加额外的构建配置。\nreporting（报告配置）：子项目可以继承父项目的报告配置，包括报告插件的配置信息。\nrepositories（仓库配置）：子项目可以继承父项目的仓库配置，用于从指定的仓库解析依赖。\nscm（版本控制配置）：子项目可以继承父项目的 scm 节点中的配置，包括版本控制系统的 URL、连接器、标签等信息。\nissueManagement（问题管理配置）：子项目可以继承父项目的 issueManagement 节点中的配置，包括问题跟踪系统的 URL、连接器等信息。\norganization（组织配置）：子项目可以继承父项目的 organization 节点中的配置，包括组织的名称、URL 等信息。\ndevelopers（开发者配置）：子项目可以继承父项目的 developers 节点中的配置，包括开发者的姓名、邮箱等信息。\nlicenses（许可证配置）：子项目可以继承父项目的 licenses 节点中的配置，包括许可证的名称、URL、分发方式等信息。\ninceptionYear和url这两个节点在 Maven 的 POM 文件中无法被子项目继承。\ninceptionYear：这个节点用于指定项目的初始年份。它通常用于提供项目的创建或开始日期，但它不会被子项目继承。每个子项目需要在自己的 POM 文件中显式定义自己的inceptionYear。 url：这个节点用于指定项目的URL地址，例如项目的主页或版本控制仓库的URL。与inceptionYear类似，url节点也不会被子项目继承。每个子项目需要在自己的 POM 文件中显式定义自己的url。 这些节点通常是项目特定的信息，不具备被继承的属性，因此每个子项目都需要自行定义这些节点，以提供自己独特的项目起始年份和URL地址。\nMaven的生命周期 Maven的标准生命周期包括三个主要的生命周期：\nClean生命周期：用于清理项目构建产生的输出，包括删除生成的目录和文件。 clean：清理项目，删除生成的目录和文件。 Default生命周期：用于构建项目的核心生命周期，涵盖了项目的编译、测试、打包、部署等主要阶段。 validate：验证项目是否正确且所有必要信息可用。 compile：编译项目的源代码。 test：运行项目的单元测试。 package：将编译后的代码打包成可分发的格式，例如JAR、WAR。 install：将打包的项目安装到本地仓库，供其他项目使用。 deploy：将最终的包复制到远程仓库，供其他开发人员和项目使用。 Site生命周期：用于生成项目的站点文档。 site：生成项目的站点文档。 site-deploy：将生成的站点文档部署到远程服务器。 完整的生命周期：\nvalidate：验证项目是否正确且所有必要信息可用。 initialize：初始化构建环境，例如设置构建属性和加载父POM。 generate-sources：生成项目的源代码，例如通过处理注解或其他生成代码的工具。 process-sources：处理项目的源代码，例如对源代码进行过滤或转换。 generate-resources：生成项目的资源文件，例如拷贝资源文件到目标目录。 process-resources：处理项目的资源文件，例如过滤资源文件的占位符。 compile：编译项目的源代码，将源代码编译为字节码文件（.class文件）。 process-classes：对编译后的类文件进行额外的处理，例如生成额外的资源文件。 generate-test-sources：生成项目的测试源代码，例如通过处理注解或其他生成代码的工具。 process-test-sources：处理项目的测试源代码，例如对测试源代码进行过滤或转换。 generate-test-resources：生成项目的测试资源文件，例如拷贝测试资源文件到目标目录。 process-test-resources：处理项目的测试资源文件，例如过滤测试资源文件的占位符。 test-compile：编译项目的测试源代码，将测试源代码编译为字节码文件。 process-test-classes：对编译后的测试类文件进行额外的处理。 test：运行项目的单元测试。 prepare-package：准备打包阶段的相关工作，例如生成额外的文件或资源。 package：将项目打包成可分发的格式，例如JAR、WAR等。 pre-integration-test：在集成测试之前执行的一些准备工作。 integration-test：运行项目的集成测试。 post-integration-test：在集成测试之后执行的一些清理工作。 verify：验证项目的完整性，例如对生成的报告进行检查。 install：将项目的构件安装到本地仓库，供本地其他项目使用。 deploy：将项目的构件复制到远程仓库，供其他开发人员和项目使用。 maven-compiler-plugin 问题 github action 的机器人将 maven-compiler-plugin 版本升级到 3.12.0 ，运行 test 时出现异常：\nbasedir /Users/chensoul/workspace/IdeaProjects/cocktail/cocktail-cloud/cocktail/cocktail-oauth2/target/generated-test-sources/test-annotations does not exist 将版本降到 3.","title":"2023-12-20｜Maven配置继承和生命周期、源码运行Nacos 2.3.0控制台"},{"content":"Today I Learned. 今天分享内容：Spring Security OAuth2 配置JWT、Github Actions配置代码扫描，另外，修改了 spring-security-oauth2-legacy 仓库，支持授权认证中心的多种配置方式（jdbc、内存、redis、jwt）、资源中心的多种配置方式（jwt、jdbc、redis、remote、jwk-set-uri）。\nSpring Security OAuth2 配置JWT 使用 Spring Security 实现OAuth2 配置 JWT 非对称加密时， JwtAccessTokenConverter 设置生成私钥签名和公钥验证器（可省略）。\n@Bean public JwtAccessTokenConverter jwtAccessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); // 设置私钥签名 converter.setSigner(new RsaSigner((RSAPrivateKey) new RSA(\u0026#34;privateKey\u0026#34;, null).getPrivateKey())); // 设置公钥验证器，可省略 converter.setVerifier(new RsaVerifier((RSAPublicKey) new RSA(null, \u0026#34;publicKey\u0026#34;).getPublicKey())); return jwtAccessTokenConverter; } 注意：这里使用了 Hutool 的 RSA 从字符串生成 PrivateKey 和 PublicKey\n去掉对 Hutool 的依赖，则可以使用自己实现的 RSAUtil 类：\npublic class RSAUtil { public static final String ALGORITHM_KEY = \u0026#34;RSA\u0026#34;; @SneakyThrows public static PrivateKey getPrivateKeyFromString(String privateKeyStr) { byte[] privateKeyBytes = Base64.getDecoder().decode(privateKeyStr.replaceAll(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;)); PKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(privateKeyBytes); KeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM_KEY); return keyFactory.generatePrivate(keySpec); } @SneakyThrows public static PublicKey getPublicKeyFromString(String publicKeyStr) { byte[] publicKeyBytes = Base64.getDecoder().decode(publicKeyStr.replaceAll(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;)); X509EncodedKeySpec keySpec = new X509EncodedKeySpec(publicKeyBytes); KeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM_KEY); return keyFactory.generatePublic(keySpec); } } 然后将上面代码修改为：\n@Bean public JwtAccessTokenConverter jwtAccessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); //非对称加密 String privateKey = \u0026#34;\u0026#34;; String publicKey = \u0026#34;\u0026#34;; converter.setSigner(new RsaSigner((RSAPrivateKey) RSAUtil.getPrivateKeyFromString(privateKey))); // 可省略公钥 converter.setVerifier(new RsaVerifier((RSAPublicKey) RSAUtil.getPublicKeyFromString(publicKey))); return converter; } 在排查错误的过程中，查看 converter.setSigningKey() 方法，new RsaSigner(String sshKey) 构造方法内调用了 RsaKeyHelper 的 parseKeyPair 方法，该方法需要传入的字符串是 \u0026ldquo;\u0026mdash;\u0026ndash;BEGIN RSA PRIVATE KEY\u0026rdquo; 开头\n而下面代码使用 keytool 生成 JKS 文件然后导出的私钥\u0026quot;\u0026mdash;\u0026ndash;BEGIN PRIVATE KEY\u0026quot; 开头。\n生成 JKS 文件 keytool -genkeypair -alias myalias -storetype PKCS12 -keyalg RSA -keypass mypass -keystore mykeystore.jks -storepass mypass -validity 3650 导出公钥 # 保存为 public.cer 文件： keytool -exportcert -alias myalias -storepass mypass -keystore mykeystore.jks -file public.cer # 保存为 public.key 文件 keytool -list -rfc --keystore mykeystore.jks -storepass mypass | openssl x509 -inform pem -pubkey \u0026gt; public.key 导出私钥，将其保存为 private.key 文件： keytool -importkeystore -srckeystore mykeystore.jks -srcstorepass mypass -destkeystore private.p12 -deststoretype PKCS12 -deststorepass mypass -destkeypass mypass openssl pkcs12 -in private.p12 -nodes -nocerts -out private.key 于是，找到一个 RSA 的仓库 https://github.com/xuxiaowei-com-cn/RSA，Fork 之后，对代码做了一些修改：\n修改代码包名为我的域名 com.chensoul，以便能够部署到 sonatype 仓库。 去掉 Apache Common Codec 依赖 修改 pom.xml 中仓库信息，去掉注释 Github Actions配置代码扫描 提交代码到仓库，发现 Github Actions 中有个 Workflow codeql-analysis.yml 没有执行，于是在仓库中启用 Action，并且修改 codeql-analysis.yml 中 github/codeql-action/autobuild 版本为 v2。于是，该 workflow 可以正常执行。\n参考 Github Actions — Scan Code，启用 Code scanning alerts ，发现有一个代码扫描警告：\n于是，参照上面说明，修改代码，再次提交代码，该警告自动关闭。\n干脆把 Dependabot alerts 也启用了，并中配置页面启用相关配置：\n点击 .github/dependabot.yml ，修改 package-ecosystem 值为 maven。因为当前仓库是 maven 构建，所以这里设置为 maven。\n保存并提交修改。机器人扫描出五个版本需要升级，并自动创建了五个 Pull Request。\n在仓库的 Security 页面，点击左侧的 Code scanning\n点击 Add tool，可以添加更多代码扫描工具，总共有 70 个 扫描工具可以选择，如：Semgrep、SonarQube、pmd 等等。\n","permalink":"https://blog.chensoul.cc/posts/2023/12/19/til/","summary":"Today I Learned. 今天分享内容：Spring Security OAuth2 配置JWT、Github Actions配置代码扫描，另外，修改了 spring-security-oauth2-legacy 仓库，支持授权认证中心的多种配置方式（jdbc、内存、redis、jwt）、资源中心的多种配置方式（jwt、jdbc、redis、remote、jwk-set-uri）。\nSpring Security OAuth2 配置JWT 使用 Spring Security 实现OAuth2 配置 JWT 非对称加密时， JwtAccessTokenConverter 设置生成私钥签名和公钥验证器（可省略）。\n@Bean public JwtAccessTokenConverter jwtAccessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); // 设置私钥签名 converter.setSigner(new RsaSigner((RSAPrivateKey) new RSA(\u0026#34;privateKey\u0026#34;, null).getPrivateKey())); // 设置公钥验证器，可省略 converter.setVerifier(new RsaVerifier((RSAPublicKey) new RSA(null, \u0026#34;publicKey\u0026#34;).getPublicKey())); return jwtAccessTokenConverter; } 注意：这里使用了 Hutool 的 RSA 从字符串生成 PrivateKey 和 PublicKey\n去掉对 Hutool 的依赖，则可以使用自己实现的 RSAUtil 类：\npublic class RSAUtil { public static final String ALGORITHM_KEY = \u0026#34;RSA\u0026#34;; @SneakyThrows public static PrivateKey getPrivateKeyFromString(String privateKeyStr) { byte[] privateKeyBytes = Base64.getDecoder().decode(privateKeyStr.replaceAll(\u0026#34;\\n\u0026#34;, \u0026#34;\u0026#34;)); PKCS8EncodedKeySpec keySpec = new PKCS8EncodedKeySpec(privateKeyBytes); KeyFactory keyFactory = KeyFactory.getInstance(ALGORITHM_KEY); return keyFactory.generatePrivate(keySpec); } @SneakyThrows public static PublicKey getPublicKeyFromString(String publicKeyStr) { byte[] publicKeyBytes = Base64.","title":"2023-12-19｜Spring Security OAuth2配置JWT、Github Actions配置代码扫描"},{"content":"Today I Learned. 今天分享内容：使用Spring Security实现OAuth2授权和认证。\n最近在开发 Spring Cloud 微服务时，需要对 OAuth2 的异常处理进行定制，从网上搜到一个 github 仓库：oauth2。这篇仓库的代码实现了 OAuth2 的四种授权模式、I18N 国际化、异常处理、JWT Token，我 fork 了一份代码，做了一些改动，去掉了 webflux、eureka 相关代码。\n代码仓库地址：https://github.com/chensoul/spring-security-oauth2-legacy，相关依赖的版本：\nspring-boot: 2.7.18 org.springframework.security.oauth:spring-security-oauth2-autoconfigure: 2.6.8 org.springframework.security.oauth:spring-security-oauth2: 2.5.2.RELEASE org.springframework.security:spring-security-jwt 1.1.1.RELEASE 特性 统一异常处理 参考spring security的 ExceptionTranslationFilter 类\n异常处理类 AccessDeniedHandler AuthenticationEntryPoint jwt key生成 生成 JKS 文件 keytool -genkeypair -alias myalias -storetype PKCS12 -keyalg RSA -keypass mypass -keystore mykeystore.jks -storepass mypass -validity 3650 导出公钥 # 保存为 public.cer 文件： keytool -exportcert -alias myalias -storepass mypass -keystore mykeystore.jks -file public.cer # 保存为 public.key 文件 keytool -list -rfc --keystore mykeystore.jks -storepass mypass | openssl x509 -inform pem -pubkey \u0026gt; public.key 导出私钥，将其保存为 private.key 文件： keytool -importkeystore -srckeystore mykeystore.jks -srcstorepass mypass -destkeystore private.p12 -deststoretype PKCS12 -deststorepass mypass -destkeypass mypass openssl pkcs12 -in private.p12 -nodes -nocerts -out private.key I18N国际化 参考 LocaleConfiguration 类 支持 @Inner 注解实现内部接口不用认证 参考以下类：\nInner InnerAspect FeignOAuth2RequestInterceptor ResourceServerConfig PermitUrlProperties OAuth 2.0授权模式 密码模式（resource owner password credentials） 授权码模式（authorization code） 简化模式（implicit） 客户端模式（client credentials） 密码模式（resource owner password credentials） 这种模式是最不推荐的，因为client可能存了用户密码 这种模式主要用来做遗留项目升级为oauth2的适配方案 当然如果client是自家的应用，也是可以 支持refresh token 授权码模式（authorization code） 这种模式算是正宗的oauth2的授权模式 设计了auth code，通过这个code再获取token 支持refresh token 简化模式（implicit） 这种模式比授权码模式少了code环节，回调url直接携带token 这种模式的使用场景是基于浏览器的应用 这种模式基于安全性考虑，建议把token时效设置短一些 不支持refresh token 客户端模式（client credentials） 这种模式直接根据client的id和密钥即可获取token，无需用户参与 这种模式比较合适消费api的后端服务，比如拉取一组用户信息等 不支持refresh token，主要是没有必要 关于refresh token refresh token的初衷主要是为了用户体验不想用户重复输入账号密码来换取新token，因而设计了refresh token用于换取新token 这种模式由于没有用户参与，而且也不需要用户账号密码，仅仅根据自己的id和密钥就可以换取新token，因而没必要refresh token 授权接口及相关参数 授权模式 请求路径 请求方法 请求头 请求参数 用户名密码(password) /oauth/token post Content-Type:application/x-www-form-urlencoded grant_type:passwordusername:userpassword:123456scope:serverclient_id:clientclient_secret:secret 客户端凭证(client_credentials) /oauth/token post Content-Type:application/x-www-form-urlencoded grant_type:client_credentialsscope:userinfo resourceclient_id:clientclient_secret:secret 客户端授权码(authorization_code) /oauth/authorize get Content-Type:application/x-www-form-urlencoded response_type=code\u0026amp;scope=server\u0026amp;client_id=client\u0026amp;redirect_uri=https://www.taobao.com 客户端授权码(authorization_code) /oauth/authorize get Content-Type:application/x-www-form-urlencoded response_type:authorization_codecode:gE3Ekaredirect_uri:https://www.jd.comscope:server 简化模式(implicit) /oauth/authorize get Content-Type:application/x-www-form-urlencoded response_type:tokenclient_id:clientredirect_uri:https://www.jd.comscope:server state:123456 小结 密码模式（resource owner password credentials）(为遗留系统设计)(支持refresh token) 授权码模式（authorization code）(正宗方式)(支持refresh token) 简化模式（implicit）(为web浏览器应用设计)(不支持refresh token) 客户端模式（client credentials）(为后台api服务消费者设计)(不支持refresh token) 参考资料 spring-security-oauth-samples 官方schema.sql ","permalink":"https://blog.chensoul.cc/posts/2023/12/18/til/","summary":"Today I Learned. 今天分享内容：使用Spring Security实现OAuth2授权和认证。\n最近在开发 Spring Cloud 微服务时，需要对 OAuth2 的异常处理进行定制，从网上搜到一个 github 仓库：oauth2。这篇仓库的代码实现了 OAuth2 的四种授权模式、I18N 国际化、异常处理、JWT Token，我 fork 了一份代码，做了一些改动，去掉了 webflux、eureka 相关代码。\n代码仓库地址：https://github.com/chensoul/spring-security-oauth2-legacy，相关依赖的版本：\nspring-boot: 2.7.18 org.springframework.security.oauth:spring-security-oauth2-autoconfigure: 2.6.8 org.springframework.security.oauth:spring-security-oauth2: 2.5.2.RELEASE org.springframework.security:spring-security-jwt 1.1.1.RELEASE 特性 统一异常处理 参考spring security的 ExceptionTranslationFilter 类\n异常处理类 AccessDeniedHandler AuthenticationEntryPoint jwt key生成 生成 JKS 文件 keytool -genkeypair -alias myalias -storetype PKCS12 -keyalg RSA -keypass mypass -keystore mykeystore.jks -storepass mypass -validity 3650 导出公钥 # 保存为 public.cer 文件： keytool -exportcert -alias myalias -storepass mypass -keystore mykeystore.jks -file public.cer # 保存为 public.key 文件 keytool -list -rfc --keystore mykeystore.jks -storepass mypass | openssl x509 -inform pem -pubkey \u0026gt; public.key 导出私钥，将其保存为 private.key 文件： keytool -importkeystore -srckeystore mykeystore.","title":"2023-12-18｜使用Spring Security实现OAuth2授权和认证"},{"content":"Today I Learned. 今天分享内容：JNDI InitialContext源码分析、ClassLoader加载机制。\nJNDI InitialContext 源码分析 JNDI包结构 javax.naming\nContext InitialContext Name CompositeName CompoundName NameImpl NameParser NamingEnumeration Referenceable RefAddr BinaryRefAddr StringRefAddr NameClassPair Binding Reference LinkRef javax.naming.directory\nAttribute\nBasicAttribute Attributes\nBasicAttributes DirContext\nInitialDirContext ModificationItem\nSearchControls\nSearchResult\njavax.naming.spi\nNamingManager DirectoryManager ObjectFactory DirObjectFactory ObjectFactoryBuilder StateFactory DirStateFactory InitialContextFactory InitialContextFactoryBuilder Resolver ContinuationContext ContinuationDirContext ResolveResult InitialContext 构造方法 InitialContext的初始化有几种方式：\n通过构造方法 通过 InitialContextFactory#getInitialContext 通过协议转换创建 InitialContext.getURLOrDefaultInitCtx(String name) 一个 JNDI 示例：\npublic class DNSClient { public static void main(String[] args) { Hashtable\u0026lt;String, String\u0026gt; env = new Hashtable\u0026lt;\u0026gt;(); env.put(Context.INITIAL_CONTEXT_FACTORY, \u0026#34;com.sun.jndi.dns.DnsContextFactory\u0026#34;); env.put(Context.PROVIDER_URL, \u0026#34;dns://114.114.114.114\u0026#34;); try { DirContext ctx = new InitialDirContext(env); Attributes res = ctx.getAttributes(\u0026#34;example.com\u0026#34;, new String[]{\u0026#34;A\u0026#34;}); System.out.println(res); } catch (NamingException e) { e.printStackTrace(); } } } InitialDirContext 构造方法初始化过程：\n调用 new InitialContext(Hashtable\u0026lt;?,?\u0026gt; environment)\n如果 environment 不为空，则克隆一个\n调用 init(environment)\n调用 ResourceManager.getInitialEnvironment(environment) 获取初始化的环境变量\n如果入参为空，则 new 一个 Hashtable ，大小 11\nJNDI 有7个预定义的变量，key 值如下\njava.naming.factory.initial java.naming.factory.object java.naming.factory.state java.naming.factory.url.pkgs java.naming.provider.url java.naming.dns.url java.naming.factory.control 如果定义了 java.naming.applet，则调用 AppletParameter 获取变量的值；否则从 System Properties 中获取\n如果定义了 com.sun.naming.disable.app.resource.files，且该变量的值为 true，即禁用应用的资源文件，则返回；否则调用 ResourceManager.getApplicationResources() 读取应用资源文件（即 jndi.properties）定义的变量调用 mergeTables 方法合并到 environment\n通过 classloader 读取应用资源即 jndi.properties 文件内容，可能会读取到多个，读取到之后合并到 environment 通过 IO 读取 JavaHome 的 lib 目录下的 jndi.properties 文件内容，然后合并到 environment mergeTables 合并逻辑： 变量新的 environment 的 key，如果旧的 environment对应 key 的值为空，则使用新的值；如果不为空，并且 key 是 JNDI 预定义的 java.naming.factory.object、java.naming.factory.url.pkgs、java.naming.factory.state、java.naming.factory.control，则使用冒号连接新旧的值。相当于则几个值的属性可以配置多个值。 如果 java.naming.factory.initial 不为空，则调用 getDefaultInitCtx() 初始化默认的 Context\ngotDefault 变量控制只能初始化一次\n调用 NamingManager.getInitialContext(myProps) 获取默认的 Context\n如果 InitialContextFactoryBuilder 不为空，则使用 InitialContextFactoryBuilder 创建 InitialContextFactory；否则，使用反射创建 InitialContextFactory\n获取 ClassLoader 使用的是 VersionHelper 工具栏的 getContextClassLoader 方法 先获取当前线程的 ClassLoader，如果为空，再获取 SystemClassLoader 调用 InitialContextFactory 的 getInitialContext(env) 创建 Context\n说明：\n1、读取或者合并 environment 的顺序\n程序设置 -\u0026gt; Applet -\u0026gt; System Properties -\u0026gt; 应用的 jndi.properties -\u0026gt; JavaHome 的 jndi.properties 2、VersionHelper 工具类有读取 System Properties（使用 Java Security 的 AccessController ） 、获取 ClassLoader、反射的方法\nVersionHelper是抽象的单例类，定义为抽象类的好处是可以将方法和实现进行分离。\npublic abstract class VersionHelper { private static VersionHelper helper = null; VersionHelper() {} // Disallow anyone from creating one of these. static { helper = new VersionHelper12(); } public static VersionHelper getVersionHelper() { return helper; } } 3、ResourceManager.getApplicationResources() 使用了缓存和同步。缓存使用的是 WeakHashMap\nWeakHashMap 是 Java 中的一种特殊类型的 Map 实现，它使用弱引用（Weak Reference）来存储键对象。在 WeakHashMap 中，当键对象没有被其他强引用所引用时，它们可以被垃圾回收器回收，即使它们存在于 WeakHashMap 中。\n// WeakHashMap\u0026lt;Class | ClassLoader, Hashtable\u0026gt; private static final WeakHashMap\u0026lt;Object, Hashtable\u0026lt;? super String, Object\u0026gt;\u0026gt; propertiesCache = new WeakHashMap\u0026lt;\u0026gt;(11); 需要注意的是，WeakHashMap 的性能可能会受到影响，因为它需要在垃圾回收时清理无效的键值对。此外，由于键对象的弱引用特性，可能会导致一些与预期不符的行为，因此在使用 WeakHashMap 时需要仔细考虑其适用性和潜在的影响。\n读写 propertiesCache 时，对 propertiesCache 对象添加 synchronized 关键字\nprivate static Hashtable\u0026lt;? super String, Object\u0026gt; getProviderResource(Object obj)throws NamingException{ if (obj == null) { return (new Hashtable\u0026lt;\u0026gt;(1)); } synchronized (propertiesCache) { Class\u0026lt;?\u0026gt; c = obj.getClass(); Hashtable\u0026lt;? super String, Object\u0026gt; props = propertiesCache.get(c); if (props != null) { return props; } props = new Properties(); InputStream istream = helper.getResourceAsStream(c, PROVIDER_RESOURCE_FILE_NAME); if (istream != null) { try { ((Properties)props).load(istream); } catch (IOException e) { NamingException ne = new ConfigurationException( \u0026#34;Error reading provider resource file for \u0026#34; + c); ne.setRootCause(e); throw ne; } } propertiesCache.put(c, props); return props; } } WeakHashMap 是非线程安全的，它不是设计用于在多线程环境下进行并发访问的。如果多个线程同时对 WeakHashMap 进行修改操作，可能会导致不一致的结果或抛出异常。\n如果需要在多线程环境中使用 WeakHashMap，可以考虑以下两种方式：\n使用同步机制：您可以使用 synchronized 关键字或其他同步机制（如 ReentrantLock）来保护对 WeakHashMap 的访问。通过确保只有一个线程可以同时修改 WeakHashMap，可以避免并发访问的问题。 使用线程安全的替代类：如果需要在多线程环境中使用并发访问的 Map，可以考虑使用线程安全的实现，如 ConcurrentHashMap。 4、JNDI 还使用了工厂模式和构造者模式。相关类：InitialContextFactory、InitialContextFactoryBuilder，则两个类的方法参数都是使用的 Hashtable\u0026lt;?,?\u0026gt; environment，这样可以传入多个参数。JNDI 有定义 spi 包，但是却没有使用Java 的 ServiceLoader 类实现 SPI。原因是 JNDI 是 Java 1.3 引入的，而 ServiceLoader 是在 Java 1.6 引入的。\nContext 初始化 InitialContext 实现了 Context 接口，其内部有一个 Context 引用，表示默认的 Context。Context 接口定义的方法都和命名有关，每个命名都有一个名称，通过这个名称获取 Context 时，可能会获取默认的 Context ，也可能获取自定义的 Context 。\n代码如下：\nprotected Context getURLOrDefaultInitCtx(String name) throws NamingException { if (NamingManager.hasInitialContextFactoryBuilder()) { return getDefaultInitCtx(); } String scheme = getURLScheme(name); if (scheme != null) { Context ctx = NamingManager.getURLContext(scheme, myProps); if (ctx != null) { return ctx; } } return getDefaultInitCtx(); } 1、如果设置了InitialContextFactoryBuilder，则直接返回默认的 Context\n2、如果名称中有 schema，则调用 NamingManager.getURLContext(scheme, myProps) 获取 Context。例如：java:comp/env/jdbc/UserPlatformDB\n调用 getURLObject 方法 返回对象 通过 ResourceManager 获取 ObjectFactory 读取 java.naming.factory.url.pkgs 值作为包名，如果值为空，则使用 com.sun.jndi.url；否则将该值使用冒号拼接上 com.sun.jndi.url 类名前缀为 \u0026quot;.\u0026quot; + scheme + \u0026quot;.\u0026quot; + scheme + \u0026quot;URLContextFactory\u0026quot; 使用冒号分隔符遍历包名，将包名加上类名，得到全类名的 URLContextFactory，然后通过反射加载类，直到得到一个不为空的 factory，并放入二级缓存中（WeakHashMap\u0026lt;ClassLoader, Map\u0026lt;String, List\u0026lt;NamedWeakReference\u0026lt;Object\u0026gt;\u0026gt;\u0026gt;\u0026gt;）。 例如，对于 java:comp/env/jdbc/UserPlatformDB，如果没有指定 java.naming.factory.url.pkgs，则得到的包名为：com.sun.jndi.url.java.javaURLContextFactory 如果 factory 不为空，则调用 factory.getObjectInstance(urlInfo, name, nameCtx, environment) 返回对象 如果返回的对象是 Context，则返回 3、返回默认的 Context\nJava 类加载机制 Java的ClassLoader（类加载器）机制是Java虚拟机（JVM）用于加载Java类的一种机制。它负责在运行时查找、加载和链接Java类，并生成对应的Class对象。\nClassLoader 机制的主要目标是实现Java的动态扩展性和代码的隔离性。它允许开发人员加载来自不同来源的类，例如本地文件系统、网络、JAR文件等，并将它们组织成一个类层次结构。\nClassLoader 类结构 ClassLoader 类继承结构：\nSecureClassLoader URLClassLoader FactoryURLClassLoader AppClassLoader： ExtClassLoader： 常见的ClassLoader包括：\nBootstrap ClassLoader：也称为原生类加载器，它是JVM的一部分并且是使用 native 代码编写，负责加载JVM运行时，如java.lang.Object。Bootstrap ClassLoader 是所有 ClassLoader 的父类。 Extension ClassLoader：ExtClassLoader，用于加载Java的扩展类库，位于jre/lib/ext目录中 或者由 java.ext.dirs 指定目录下的JAR文件。 System ClassLoader：AppClassLoader，也称为应用程序类加载器，加载用户自定义的类和第三方类库。 AppClassLoader是默认的类加载器，如果类加载时我们不指定类加载器的情况下，默认会使用AppClassLoader加载类，ClassLoader.getSystemClassLoader()返回的系统类加载器也是AppClassLoader。\nJava中的ClassLoader是一个层次结构，由多个ClassLoader组成。每个ClassLoader都有一个父ClassLoader，除了顶层的原生类加载器（bootstrap class loader）之外。当需要加载一个类时，ClassLoader会首先尝试委托给其父ClassLoader进行加载。只有当父ClassLoader无法加载时，ClassLoader才会尝试自己加载。\nClassLoader 如何工作 类加载器是 Java 运行时环境的一部分。当 JVM 请求一个类时，类加载器会尝试定位该类，并使用完全限定的类名将类定义加载到运行时中。\njava.lang.ClassLoader.loadClass() 方法负责将类定义加载到运行时。它尝试根据完全限定名称加载类。\n如果该类尚未加载，它将请求委托给父类加载器。这个过程递归地发生。\n最终，如果父类加载器找不到该类，则子类将调用 java.net.URLClassLoader.findClass() 方法在文件系统本身中查找类。\n如果最后一个子类加载器也无法加载该类，则会抛出 java.lang.NoClassDefFoundError 或 java.lang.ClassNotFoundException。\n让我们看一下抛出 ClassNotFoundException 时的输出示例：\njava.lang.ClassNotFoundException: at java.net.URLClassLoader.findClass(URLClassLoader.java:381) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at java.lang.Class.forName0(Native Method) at java.lang.Class.forName(Class.java:348) 如果我们从调用 java.lang.Class.forName() 开始查看错误日志，我们可以看到它首先尝试通过父类加载器加载该类，然后 java.net.URLClassLoader.findClass() 来加载该类。当它仍然找不到该类时，它会抛出 ClassNotFoundException。\nClassLoader 三个特性 双亲委派模型\n类加载器遵循委托模型，在请求查找类或资源时，ClassLoader 实例会将类或资源的搜索委托给父类加载器。\n假设我们有一个将应用程序类加载到 JVM 中的请求。系统类加载器首先将该类的加载委托给其父扩展类加载器，后者又将其委托给引导类加载器。\n仅当引导程序和扩展类加载器加载类失败时，系统类加载器才会尝试加载类本身。\n可见性\n子类加载器对其父类加载器加载的类是可见的。\n例如，系统类加载器加载的类可以看到扩展和引导类加载器加载的类，但反之则不然。\n为了说明这一点，如果类 A 由应用程序类加载器加载，类 B 由扩展类加载器加载，则就应用程序类加载器加载的其他类而言，A 类和 B 类都是可见的。\n然而，B 类是唯一对扩展类加载器加载的其他类可见的类。\n唯一性\n由于委托模型的结果，很容易确保唯一的类，因为我们总是尝试向上委托。如果父类加载器无法找到该类，只有当前实例才会尝试自行查找。\nClassLoader 源码 1、loadClass() 方法\npublic Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { 该方法负责加载给定名称参数的类。 name 参数指的是完全限定的类名。\nJava虚拟机调用 loadClass() 方法来解析类引用，并将 resolve 设置为true。然而，并不总是需要解析一个类。如果我们只需要判断类是否存在，那么 resolve 参数设置为 false。\n该方法充当类加载器的入口点。\n我们可以尝试 从java.lang.ClassLoader 的源码中了解 loadClass() 方法的内部工作原理：\nprotected Class\u0026lt;?\u0026gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class\u0026lt;?\u0026gt; c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } } 该方法的默认实现按以下顺序搜索类：\n调用 findLoadedClass(String) 方法以查看该类是否已加载。 调用父类加载器上的 loadClass(String) 方法。 调用 findClass(String) 方法来查找该类。 2、defineClass() 方法\nprotected final Class\u0026lt;?\u0026gt; defineClass( String name, byte[] b, int off, int len) throws ClassFormatError 该方法负责将字节数组转换为类的实例。在使用该类之前，我们需要定义它。如果数据不包含有效的类，则会抛出 ClassFormatError。\n此外，我们无法重写此方法，因为它被标记为最终方法。\n3、findClass() 方法\nprotected Class\u0026lt;?\u0026gt; findClass(String name) throws ClassNotFoundException 此方法查找以完全限定名称作为参数的类。我们需要在遵循加载类的委托模型的自定义类加载器实现中重写此方法。\n此外，如果父类加载器找不到所请求的类，loadClass() 会调用此方法。\n如果类加载器的父级没有找到该类，则默认实现会抛出 ClassNotFoundException。\n4、getParent() 方法\npublic final ClassLoader getParent() 该方法返回委托的父类加载器。某些实现使用 null 来表示引导类加载器。\n5、getResource() 方法\npublic URL getResource(String name) 此方法尝试查找具有给定名称的资源。\n它首先将资源委托给父类加载器。如果 parent 为null，则查找虚拟机内置的类加载器的路径。如果失败，该方法将调用 findResource(String) 来查找资源。指定为输入的资源名称可以是相对于类路径的，也可以是绝对的。\n它返回一个用于读取资源的 URL 对象，如果找不到资源或调用者没有足够的权限来返回资源，则返回 null。\n需要注意的是，Java 从类路径加载资源。\n最后，Java 中的资源加载被认为是与位置无关的，因为只要设置环境来查找资源，代码在哪里运行并不重要。\nContext Classloaders 一般来说，上下文类加载器为 J2SE 中引入的类加载委托方案提供了一种替代方法。\n正如我们之前了解到的，JVM 中的类加载器遵循分层模型，因此除了引导类加载器之外，每个类加载器都有一个父类加载器。\n然而，有时当 JVM 核心类需要动态加载应用程序开发人员提供的类或资源时，我们可能会遇到问题。\n例如，在 JNDI 中，核心功能是由 rt.jar 中的引导类实现的。但这些 JNDI 类可能会加载由独立供应商实现的 JNDI 提供程序（部署在应用程序类路径中）。这种情况需要引导类加载器（父类加载器）来加载应用程序加载器（子类加载器）可见的类。\nJ2SE 委托在这里不起作用，为了解决这个问题，我们需要找到类加载的替代方法。这可以使用线程上下文加载器来实现。\njava.lang.Thread 类有一个方法 getContextClassLoader()，它返回特定线程的 Context ClassLoader。 Context ClassLoader 是线程的创建者在加载资源和类时提供的。如果未设置该值，则默认为父线程的 Context ClassLoader。\n正如前面在 JNDI 源码分析中提到的，在 JNDI 中，获取 ClassLoader 的代码在 VersionHelper12 类的 getContextClassLoader 方法中。\nfinal class VersionHelper12 extends VersionHelper { ClassLoader getContextClassLoader() { return AccessController.doPrivileged( new PrivilegedAction\u0026lt;ClassLoader\u0026gt;() { public ClassLoader run() { ClassLoader loader = Thread.currentThread().getContextClassLoader(); if (loader == null) { // Don\u0026#39;t use bootstrap class loader directly! loader = ClassLoader.getSystemClassLoader(); } return loader; } } ); } } 参考 ClassLoader\nClass Loaders in Java\n","permalink":"https://blog.chensoul.cc/posts/2023/12/15/til/","summary":"Today I Learned. 今天分享内容：JNDI InitialContext源码分析、ClassLoader加载机制。\nJNDI InitialContext 源码分析 JNDI包结构 javax.naming\nContext InitialContext Name CompositeName CompoundName NameImpl NameParser NamingEnumeration Referenceable RefAddr BinaryRefAddr StringRefAddr NameClassPair Binding Reference LinkRef javax.naming.directory\nAttribute\nBasicAttribute Attributes\nBasicAttributes DirContext\nInitialDirContext ModificationItem\nSearchControls\nSearchResult\njavax.naming.spi\nNamingManager DirectoryManager ObjectFactory DirObjectFactory ObjectFactoryBuilder StateFactory DirStateFactory InitialContextFactory InitialContextFactoryBuilder Resolver ContinuationContext ContinuationDirContext ResolveResult InitialContext 构造方法 InitialContext的初始化有几种方式：\n通过构造方法 通过 InitialContextFactory#getInitialContext 通过协议转换创建 InitialContext.getURLOrDefaultInitCtx(String name) 一个 JNDI 示例：\npublic class DNSClient { public static void main(String[] args) { Hashtable\u0026lt;String, String\u0026gt; env = new Hashtable\u0026lt;\u0026gt;(); env.put(Context.INITIAL_CONTEXT_FACTORY, \u0026#34;com.sun.jndi.dns.DnsContextFactory\u0026#34;); env.put(Context.PROVIDER_URL, \u0026#34;dns://114.114.114.114\u0026#34;); try { DirContext ctx = new InitialDirContext(env); Attributes res = ctx.getAttributes(\u0026#34;example.com\u0026#34;, new String[]{\u0026#34;A\u0026#34;}); System.out.println(res); } catch (NamingException e) { e.","title":"2023-12-15｜JNDI InitialContext源码分析、ClassLoader加载机制"},{"content":"Today I Learned. 今天分享内容：购买新的 VPS 服务器、最近在做什么。\n购买新的 VPS 服务器 今天看到搬瓦工上的 VPS 还有一个月到期，该 VPS 配置是 40 GB SSD、2 GB RAM、2 TB Bandwidth、3x Intel Xeon CPU、1 Gigabit Network，一年费用是 99 美元。\n在中文博客圈微信群里面看到 CloudCone 最近在做 CloudCone 2023 年圣诞节活动。\nCloudCone 成立于 2017 年，美国注册公司 (怀俄明州 2017-000753144)。主营美国洛杉矶 MultaCom 机房的云服务器 / VPS、独立服务器、电子邮件托管等业务。VPS 基于 KVM 虚拟，采用自行研发的控制面板。其所在的 MultaCom 机房采用动态路由网络，会根据不同网络状态调整线路，很多地区的电信网络会走 CN2 线路，因此延迟和稳定性在非高峰时段都较为优秀。同时该主机商提供了按秒计费、随删随用、定期备份服务。支持支付宝、Paypal、信用卡等方式付款。\nCloudCone 2023 年圣诞节 VPS 优惠促销活动。美国西海岸洛杉矶 MultaCom 机房，千兆带宽，1 个 IPv4 地址，3 个 IPv6 地址，基于 KVM 虚拟，SSD Cached RAID 10 存储。\n活动地址：https://hello.cloudcone.com/2023-christmas-vps-sale\nCPU 内存 硬盘（SSD） 流量 带宽 价格 购买地址 1 核 0.5G 30G 3T 1Gbps $9.5/年 点击购买 2 核 1G 45G 3T 1Gbps $15/年 点击购买 2 核 1G 50G 3T 1Gbps $16.5/年 点击购买 2 核 2G 100G 6T 1Gbps $26/年 点击购买 2 核 2G 105G 6T 1Gbps $29/年 点击购买 4 核 4G 205G 8T 1Gbps $48.5/年 点击购买 4 核 4G 210G 8T 1Gbps $54/年 点击购买 6 核 8G 400G 8T 1Gbps $93/年 点击购买 6 核 8G 410G 8T 1Gbps $104/年 点击购买 8 核 16G 850G 10T 1Gbps $188/年 点击购买 8 核 16G 850G 10T 1Gbps $210/年 点击购买 16 核 32G 1024G 10T 1Gbps $340/年 点击购买 16 核 32G 1TB 10T 1Gbps $390/年 点击购买 于是买了一个 4 核 4 GB 内存 205 GB 硬盘的 VPS。配置比搬瓦工的 VPS 高了一倍，价格却便宜了一半。瞬间觉得 CloudCone 真香！\n接下来的工作就是将原来 VPS 上的服务迁移到新的 VPS 上面。新 VPS 的设置可以参考我之前的一篇博客 我的 VPS 服务部署记录。\n今天还做了什么 更新博客 我的 VPS 服务部署记录 最近在做什么 最近在看 小马哥的 Java 项目实战营，看到了 \u0026ldquo;01 JavaEE 单体架构\u0026rdquo; 的第 11 节，需要整理笔记，加深理解。总共涉及到的知识点：\nJNDI JDBC JPA 数据校验 事务 Servlet 配置管理和 Java Logging JMX Maven \u0026ndash; EOF\n","permalink":"https://blog.chensoul.cc/posts/2023/12/14/til/","summary":"Today I Learned. 今天分享内容：购买新的 VPS 服务器、最近在做什么。\n购买新的 VPS 服务器 今天看到搬瓦工上的 VPS 还有一个月到期，该 VPS 配置是 40 GB SSD、2 GB RAM、2 TB Bandwidth、3x Intel Xeon CPU、1 Gigabit Network，一年费用是 99 美元。\n在中文博客圈微信群里面看到 CloudCone 最近在做 CloudCone 2023 年圣诞节活动。\nCloudCone 成立于 2017 年，美国注册公司 (怀俄明州 2017-000753144)。主营美国洛杉矶 MultaCom 机房的云服务器 / VPS、独立服务器、电子邮件托管等业务。VPS 基于 KVM 虚拟，采用自行研发的控制面板。其所在的 MultaCom 机房采用动态路由网络，会根据不同网络状态调整线路，很多地区的电信网络会走 CN2 线路，因此延迟和稳定性在非高峰时段都较为优秀。同时该主机商提供了按秒计费、随删随用、定期备份服务。支持支付宝、Paypal、信用卡等方式付款。\nCloudCone 2023 年圣诞节 VPS 优惠促销活动。美国西海岸洛杉矶 MultaCom 机房，千兆带宽，1 个 IPv4 地址，3 个 IPv6 地址，基于 KVM 虚拟，SSD Cached RAID 10 存储。\n活动地址：https://hello.cloudcone.com/2023-christmas-vps-sale\nCPU 内存 硬盘（SSD） 流量 带宽 价格 购买地址 1 核 0.5G 30G 3T 1Gbps $9.5/年 点击购买 2 核 1G 45G 3T 1Gbps $15/年 点击购买 2 核 1G 50G 3T 1Gbps $16.","title":"2023-12-14｜购买新的VPS服务器、最近在做什么"},{"content":"最近在一些开源项目中看到了 MicroProfile ，于是在网上查阅了相关资料加深对 MicroProfile 的理解，并做了笔记形成此文。\nMicroProfile MicroProfile是一个开放的企业级Java微服务框架，旨在简化和标准化基于微服务架构的应用程序开发。它是由Eclipse Foundation主导的一个开源项目，致力于提供轻量级、可移植和可互操作的Java微服务规范和实现。\nMicroProfile的目标是为Java开发人员提供一个规范集合，使他们能够更轻松地构建和部署云原生应用程序。它结合了Java EE、Jakarta EE和其他相关规范，为开发人员提供了一组核心功能和扩展，以支持构建可伸缩、弹性和高性能的微服务应用程序。\nMicroProfile提供了一系列的规范，包括：\nMicroProfile Config MicroProfile JWT RBAC MicroProfile Health MicroProfile Fault Tolerance MicroProfile Metrics MicroProfile OpenAPI MicroProfile OpenTracing MicroProfile REST Client MicroProfile Context Propagation MicroProfile Reactive Streams Operators MicroProfile Reactive Messaging MicroProfile GraphQL MicroProfile Long Running Actions MicroProfile Telemetry MicroProfile 实现：\nPayara Micro：是一个用于容器化Jakarta EE应用部署的轻量级中间件平台，不需要安装、配置或重写代码，可以快速部署 WildFly by Redhat：是一个轻量级、模块化的微服务框架，集中、简单、以用户为中心，实现了Jakarta EE和Eclipse MicroProfile的最新企业Java标准。 Quarkus by RedHat：为GraalVM和OpenJDK HotSpot构建的Kubernetes Native Java堆栈，由最佳的Java库和标准精心打造。 Apache TomEE：这是Apache Tomcat Java企业版，它结合了几个Java企业项目，包括Apache OpenEJB、Apache OpenJPA、Apache OpenWebBeans、Apache MyFaces和其他许多项目。 Hammock：这是一个基于CDI的bootstrapping Java企业微服务框架，由于其灵活性和简单性，用于构建应用程序 Openliberty：是一个开源的轻量级Java EE微服务框架，用于构建快速高效的云原生Java微服务应用，只运行所需的服务，同时考虑最新的Eclipse MicroProfile标准 Helidon by Oracle：这是一个Java库的集合，用于编写在快速的Helidon Reactive WebServer上运行的Java微服务，这是一个由Netty驱动的Web核心，同时支持MicroProfile及其标准规范。 KumuluzEE：是一个轻量级框架，用于使用标准的Java/JavaEE/JakartaEE/EE4J技术和API开发微服务，可选择扩展，如使用Node.js、Go和其他语言，并将现有应用程序迁移到云原生架构和微服务，以便更容易地进行云原生微服务开发。 Launcher by Fujitsu：它由富士通公司开发，是一个支持某些MicroProfile规范的Java EE微服务框架，可以将应用捆绑到über-jar/fat文件（JAR文件，包含其所有需要的依赖项） ThornTail (过时的)：是一个Java企业级微服务框架，它只将需要的和指定的包捆绑到一个JAR文件中，并有足够的运行时间来运行它们 MicroProfile发展历史 Infoq 上有一段介绍：\n2016 年年中，作为对 Oracle 在发布 Java EE 8 方面停滞不前的直接回应，社区发起了两个新的倡议，也就是MicroProfile和 Java EE Guardians（现在被称为Jakarta EE Ambassadors）。Java 社区认为，随着用于构建微服务应用的 web 服务技术的出现，企业级 Java 已经落后于时代了。\nMicroProfile 倡议是在2016年6月27日Red Hat的DevNation会议上发起的，它是由 IBM、Red Hat、Tomitribe、Payara 等厂商协作创建的，旨在为企业级 Java 提供微服务。MicroProfile 1.0的发布是在 JavaOne 2016 上宣布的，它包含了三个基于 JSR 的 API，这些 API 被视为创建微服务的最低限度要求，即JSR-346：上下文和依赖注入（CDI）、JSR-353：JSON 处理的 Java API（JSON-P）以及JSR-339：RESTful Web 服务的 Java API（JAX-RS）。\n到 2018 年 2 月MicroProfile 1.3发布的时候，已经创建了八个基于社区的 API，以补充最初的三个基于 JSR 的 API，用来构建更加健壮的基于微服务的应用。随着MicroProfile 2.0的发布，增加了第四个基于 JSR 的 API，即JSR-367：JSON 绑定的 Java API（JSON-B）。\n原定于 2020 年 6 月发布的 MicroProfile 4.0被推迟了，以便于按照 Eclipse 基金会的授权成立MicroProfile工作组。该工作组定义了MicroProfile规范流程和正式的指导委员会，该委员会由各组织和 Java 用户组（Java User Group，JUG）组成，即亚特兰大JUG、IBM, Jelastic、Red Hat和Tomitribe。预计其他的组织和 JUG 会在 2021 年加入。MicroProfile 工作组在 2020 年 12 月 23 日发布了 MicroProfile 4.0，其特性是对12个核心API进行更新并与Jakarta EE 8保持一致。\nMicroProfile 的创始厂商提供了自己的微服务框架，分别是Open Liberty（IBM）、WildFly Swarm/Thorntail（Red Hat）、TomEE（Tomitribe 和Payara Micro（Payara），它们最终都支持了 MicroProfile 倡议。\n在 2018 年的年中，Red Hat 将 WildFly Swarm（这是 Red Hat 的核心应用服务器WildFly的扩展）重命名为Thorntail，从而为它的微服务框架提供自己的标识。但是，不到一年之后，Red Hat 发布了Quarkus，这是一个“为 OpenJDK HotSpot 和 GraalVM 量身定做的 Kubernetes 原生 Java 栈，基于最优秀的 Java 库和标准精心打造”。Quarkus 被称为“超音速亚原子的 Java”，在 Java 社区迅速流行了起来，以至于 Red Hat宣布Thorntail在2020年7月寿终正寝。Quarkus 加入了相对较新的框架Micronaut和Helidon的行列，这两个框架都是在此之前不到一年前引入 Java 社区的。除了 Micronaut 之外，所有这些基于微服务的框架都支持 MicroProfile 倡议。\nMicroProfile的发展历史可以追溯到2016年。以下是MicroProfile的关键里程碑和发展阶段：\n2016年6月 - 由Red Hat、IBM、Tomitribe、Payara和LJC（London Java Community）等公司和组织共同发起了MicroProfile项目。旨在创建一个开放的、供应商中立的Java微服务规范。 2016年9月 - MicroProfile 1.0发布，包括Java API for RESTful Web Services（JAX-RS）、Java API for JSON Processing（JSON-P）、Java API for WebSocket（WebSocket）等规范。 2017年5月 - MicroProfile 1.1发布，引入Config API规范，用于外部配置的管理。 2017年9月 - MicroProfile 1.2发布，添加了Health Check API规范，用于检查应用程序的健康状态。 2018年2月 - MicroProfile 1.3发布，引入了OpenAPI规范（以前称为Swagger），用于API文档和可视化。 2018年5月 - MicroProfile 2.0发布，升级了基础规范版本，并添加了Fault Tolerance API规范，用于容错和弹性。 2018年11月 - MicroProfile 2.1发布，增加了Metrics API规范，用于应用程序的性能监控和指标收集。 2019年3月 - MicroProfile 2.2发布，引入了JWT RBAC（Role-Based Access Control）规范，用于身份验证和授权。 2019年11月 - MicroProfile 3.0发布，升级了基础规范版本，支持Java EE 8和Jakarta EE规范。 2020年2月 - MicroProfile 3.1发布，升级了基础规范版本，并增加了其他改进和修复。 2021年5月 - MicroProfile 4.0发布，升级了基础规范版本，并引入了重大改进和新功能，如Context Propagation、Reactive Messaging等。 MicroProfile Config MicroProfile Config是MicroProfile的一个重要特性，它提供了一种解决方案，可以将配置从微服务中外部化。这使得应用和微服务可以在多个环境中运行，无需修改或重新打包。配置数据可以动态变化，应用需要能够在不重新启动服务器的情况下访问最新的配置信息。\nMicroProfile Config允许从不同的位置和不同的格式获取配置数据，如系统属性、系统环境变量、.properties、.xml和数据源等，这些配置位置被称为ConfigSources。\n它提供了一种方式，可以从许多不同的ConfigSources聚合配置，并呈现这些配置的单一、统一的视图。MicroProfile Config提供了两种获取配置属性的方式：编程方式和通过上下文和依赖注入（CDI）。\n在编程方式中，你首先获取包含所有可以访问的属性的Config对象，然后通过getValue(String propertyName, Class\u0026lt;?\u0026gt; propertyValueType)查找单个属性。使用CDI，可以直接将配置属性值注入到应用中，无需应用代码来检索它们。\n此外，还可以根据MicroProfile Config的规定创建自定义的ConfigSource。通过自定义ConfigSource，可以读取额外的配置值，并将它们以定义的顺序添加到Config实例中。这允许覆盖来自其他源的值或回退到其他值。\n参考文章 https://microprofile.io/\nMicroProfile 6.1\nMicroProfile 是什么？\nEclipse MicroProfile 简介\n什么是Eclipse MicroProfile？\nSpring Boot与Eclipse MicroProfile比较\nMicroProfile 对微服务框架的影响 | InfoQ 圆桌\nMicroProfile 编程模型支持\n学习如何使用MicroProfile\n使用 Quarkus 和 MicroProfile 实现微服务特性\nMicroProfile 云原生微服务开发编程模型\n使用 MicroProfile、ConfigMaps、Secrets 实现外部化应用配置\nEclipse MicroProfile 企业级微服务实用指南\n亚信Web应用中间件（FlyingServer）通过Eclipse MicroProfile功能测评\n微服务框架：如果不用 Spring Boot，还可以选择谁？\n“Azure 上的 Eclipse MicroProfile”文档\nJBoss 4.2. MicroProfile 配置开发\nQUARKUS - MICROPROFILE 健康检查\n","permalink":"https://blog.chensoul.cc/posts/2023/12/14/all-things-about-microprofile/","summary":"最近在一些开源项目中看到了 MicroProfile ，于是在网上查阅了相关资料加深对 MicroProfile 的理解，并做了笔记形成此文。\nMicroProfile MicroProfile是一个开放的企业级Java微服务框架，旨在简化和标准化基于微服务架构的应用程序开发。它是由Eclipse Foundation主导的一个开源项目，致力于提供轻量级、可移植和可互操作的Java微服务规范和实现。\nMicroProfile的目标是为Java开发人员提供一个规范集合，使他们能够更轻松地构建和部署云原生应用程序。它结合了Java EE、Jakarta EE和其他相关规范，为开发人员提供了一组核心功能和扩展，以支持构建可伸缩、弹性和高性能的微服务应用程序。\nMicroProfile提供了一系列的规范，包括：\nMicroProfile Config MicroProfile JWT RBAC MicroProfile Health MicroProfile Fault Tolerance MicroProfile Metrics MicroProfile OpenAPI MicroProfile OpenTracing MicroProfile REST Client MicroProfile Context Propagation MicroProfile Reactive Streams Operators MicroProfile Reactive Messaging MicroProfile GraphQL MicroProfile Long Running Actions MicroProfile Telemetry MicroProfile 实现：\nPayara Micro：是一个用于容器化Jakarta EE应用部署的轻量级中间件平台，不需要安装、配置或重写代码，可以快速部署 WildFly by Redhat：是一个轻量级、模块化的微服务框架，集中、简单、以用户为中心，实现了Jakarta EE和Eclipse MicroProfile的最新企业Java标准。 Quarkus by RedHat：为GraalVM和OpenJDK HotSpot构建的Kubernetes Native Java堆栈，由最佳的Java库和标准精心打造。 Apache TomEE：这是Apache Tomcat Java企业版，它结合了几个Java企业项目，包括Apache OpenEJB、Apache OpenJPA、Apache OpenWebBeans、Apache MyFaces和其他许多项目。 Hammock：这是一个基于CDI的bootstrapping Java企业微服务框架，由于其灵活性和简单性，用于构建应用程序 Openliberty：是一个开源的轻量级Java EE微服务框架，用于构建快速高效的云原生Java微服务应用，只运行所需的服务，同时考虑最新的Eclipse MicroProfile标准 Helidon by Oracle：这是一个Java库的集合，用于编写在快速的Helidon Reactive WebServer上运行的Java微服务，这是一个由Netty驱动的Web核心，同时支持MicroProfile及其标准规范。 KumuluzEE：是一个轻量级框架，用于使用标准的Java/JavaEE/JakartaEE/EE4J技术和API开发微服务，可选择扩展，如使用Node.js、Go和其他语言，并将现有应用程序迁移到云原生架构和微服务，以便更容易地进行云原生微服务开发。 Launcher by Fujitsu：它由富士通公司开发，是一个支持某些MicroProfile规范的Java EE微服务框架，可以将应用捆绑到über-jar/fat文件（JAR文件，包含其所有需要的依赖项） ThornTail (过时的)：是一个Java企业级微服务框架，它只将需要的和指定的包捆绑到一个JAR文件中，并有足够的运行时间来运行它们 MicroProfile发展历史 Infoq 上有一段介绍：\n2016 年年中，作为对 Oracle 在发布 Java EE 8 方面停滞不前的直接回应，社区发起了两个新的倡议，也就是MicroProfile和 Java EE Guardians（现在被称为Jakarta EE Ambassadors）。Java 社区认为，随着用于构建微服务应用的 web 服务技术的出现，企业级 Java 已经落后于时代了。","title":"All things about MicroProfile"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Twitter》设计 Twitter。\nLet’s design a Twitter-like social networking service. Users of the service will be able to post tweets, follow other people, and favorite tweets. Difficulty Level: Medium\n让我们设计一个类似 Twitter 的社交网络服务。该服务的用户将能够发布推文、关注其他人以及喜欢的推文。难度级别：中等\n1. What is Twitter? 1.什么是推特？\nTwitter is an online social networking service where users post and read short 140-character messages called “tweets.” Registered users can post and read tweets, but those who are not registered can only read them. Users access Twitter through their website interface, SMS, or mobile app.\nTwitter 是一种在线社交网络服务，用户可以在其中发布和阅读称为“推文”的 140 个字符的简短消息。注册用户可以发布和阅读推文，但未注册的用户只能阅读推文。用户通过网站界面、短信或移动应用程序访问 Twitter。\n2. Requirements and Goals of the System 系统的要求和目标 We will be designing a simpler version of Twitter with the following requirements:\n我们将设计一个更简单的 Twitter 版本，并满足以下要求：\nFunctional Requirements\n功能要求\nUsers should be able to post new tweets.\n用户应该能够发布新的推文。\nA user should be able to follow other users.\n用户应该能够关注其他用户。\nUsers should be able to mark tweets as favorites.\n用户应该能够将推文标记为收藏夹。\nThe service should be able to create and display a user’s timeline consisting of top tweets from all the people the user follows.\n该服务应该能够创建并显示用户的时间线，其中包含来自以下位置的热门推文：用户关注的所有人员。\nTweets can contain photos and videos.\n推文可以包含照片和视频。\nNon-functional Requirements\n非功能性需求\nOur service needs to be highly available.\n我们的服务需要高度可用。\nAcceptable latency of the system is 200ms for timeline generation.\n时间线生成系统可接受的延迟为 200 毫秒。\nConsistency can take a hit (in the interest of availability); if a user doesn’t see a tweet for a while, it should be fine.\n一致性可能会受到影响（为了可用性）；如果用户没有看到某条推文同时，应该没问题。\nExtended Requirements\n扩展要求\nSearching for tweets.\n正在搜索推文。\nReplying to a tweet.\n回复推文。\nTrending topics – current hot topics/searches.\n热门话题 – 当前的热门话题/搜索。\nTagging other users.\n标记其他用户。\nTweet Notification.\n推文通知。\nWho to follow? Suggestions?\n跟随谁？建议？\nMoments.\n时刻。\n3. Capacity Estimation and Constraints 容量估计和约束 Let’s assume we have one billion total users with 200 million daily active users (DAU). Also assume we have 100 million new tweets every day and on average each user follows 200 people.\n假设我们的总用户数为 10 亿，其中每日活跃用户 (DAU) 为 2 亿。还假设我们每天有 1 亿条新推文，平均每个用户关注 200 人。\nHow many favorites per day? If, on average, each user favorites five tweets per day we will have: 200M users * 5 favorites =\u0026gt; 1B favorites\n每天有多少个收藏夹？如果平均每个用户每天收藏 5 条推文，我们将拥有：2 亿用户 * 5 个收藏 =\u0026gt; 1B 个收藏\nHow many total tweet-views will our system generate? Let’s assume on average a user visits their timeline two times a day and visits five other people’s pages. On each page if a user sees 20 tweets, then our system will generate 28B/day total tweet-views:\n我们的系统总共会产生多少推文浏览量？假设用户平均每天访问自己的时间线两次，并访问其他五个人的页面。如果用户在每个页面上看到 20 条推文，那么我们的系统将生成 28B/天的总推文浏览量：\n200M DAU * ((2 + 5) * 20 tweets) =\u0026gt; 28B/day\nStorage Estimates Let’s say each tweet has 140 characters and we need two bytes to store a character without compression. Let’s assume we need 30 bytes to store metadata with each tweet (like ID, timestamp, user ID, etc.). Total storage we would need:\n存储估算 假设每条推文有 140 个字符，我们需要两个字节来存储一个字符而不进行压缩。假设我们需要 30 个字节来存储每条推文的元数据（如 ID、时间戳、用户 ID 等）。我们需要的总存储空间：\n100M * (280 + 30) bytes =\u0026gt; 30GB/day\nWhat would our storage needs be for five years? How much storage we would need for users’ data, follows, favorites? We will leave this for the exercise.\n五年内我们的存储需求是多少？我们需要多少存储空间来存储用户数据、关注数据、收藏夹？我们将把它留给练习。\nNot all tweets will have media, let’s assume that on average every fifth tweet has a photo and every tenth has a video. Let’s also assume on average a photo is 200KB and a video is 2MB. This will lead us to have 24TB of new media every day.\n并非所有推文都会有媒体，我们假设平均每五条推文有一张照片，每十分之一有一个视频。我们还假设平均一张照片为 200KB，一段视频为 2MB。这将使我们每天拥有 24TB 的新媒体。\n(100M/5 photos * 200KB) + (100M/10 videos * 2MB) ~= 24TB/day\nBandwidth Estimates Since total ingress is 24TB per day, this would translate into 290MB/sec.\n带宽估计 由于总入口量为每天 24TB，这将转化为 290MB/秒。\nRemember that we have 28B tweet views per day. We must show the photo of every tweet (if it has a photo), but let’s assume that the users watch every 3rd video they see in their timeline. So, total egress will be:\n请记住，我们每天的推文浏览量为 28B。我们必须显示每条推文的照片（如果它有照片），但我们假设用户观看他们在时间线中看到的每第三个视频。因此，总出口将为：\n4. System APIs 4. 系统API\nOnce we’ve finalized the requirements, it’s always a good idea to define the system APIs. This should explicitly state what is expected from the system.\n一旦我们最终确定了需求，定义系统 API 总是一个好主意。这应该明确说明系统的期望。\nWe can have SOAP or REST APIs to expose the functionality of our service. Following could be the definition of the API for posting a new tweet:\n我们可以使用 SOAP 或 REST API 来公开我们服务的功能。以下是用于发布新推文的 API 的定义：\ntweet(api_dev_key, tweet_data, tweet_location, user_location, media_ids, maximum_results_to_return) Parameters: 参数：\napi_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota. tweet_data (string): The text of the tweet, typically up to 140 characters. tweet_location (string): Optional location (longitude, latitude) this Tweet refers to. user_location (string): Optional location (longitude, latitude) of the user adding the tweet.\napi_dev_key (string): 注册账户的API开发者密钥。除其他外，这将用于根据分配的配额限制用户。 tweet_data（字符串）：推文的文本，通常最多 140 个字符。 tweet_location（字符串）：此推文所指的可选位置（经度、纬度）。 user_location（字符串）：添加推文的用户的可选位置（经度、纬度）。\nmedia_ids (number[]): Optional list of media_ids to be associated with the Tweet. (All the media photo, video, etc. need to be uploaded separately).\nmedia_ids (number[])：与推文关联的可选 media_ids 列表。 （所有媒体照片、视频等需单独上传）。\nReturns: (string) A successful post will return the URL to access that tweet. Otherwise, an appropriate HTTP error is returned.\n返回：（字符串）成功发布的帖子将返回用于访问该推文的 URL。否则，将返回适当的 HTTP 错误。\n5. High Level System Design 高层系统设计 We need a system that can efficiently store all the new tweets, 100M/86400s =\u0026gt; 1150 tweets per second and read 28B/86400s =\u0026gt; 325K tweets per second. It is clear from the requirements that this will be a read-heavy system.\n我们需要一个能够高效存储所有新推文的系统，每秒 100M/86400s =\u0026gt; 1150 条推文，每秒读取 28B/86400s =\u0026gt; 325K 条推文。从需求中可以清楚地看出，这将是一个读取繁重的系统。\nAt a high level, we need multiple application servers to serve all these requests with load balancers in front of them for traffic distributions. On the backend, we need an efficient database that can store all the new tweets and can support a huge number of reads. We also need some file storage to store photos and videos.\n在较高层面上，我们需要多个应用程序服务器来服务所有这些请求，并在它们前面提供负载均衡器以进行流量分配。在后端，我们需要一个高效的数据库，能够存储所有新的推文，并且能够支持海量的读取。我们还需要一些文件存储来存储照片和视频。\nAlthough our expected daily write load is 100 million and read load is 28 billion tweets. This means on average our system will receive around 1160 new tweets and 325K read requests per second. This traffic will be distributed unevenly throughout the day, though, at peak time we should expect at least a few thousand write requests and around 1M read requests per second. We should keep this in mind while designing the architecture of our system.\n尽管我们预计每日写入负载为 1 亿条推文，读取负载为 280 亿条推文。这意味着我们的系统平均每秒将收到大约 1160 条新推文和 325K 读取请求。不过，该流量在一天中的分布不均匀，但在高峰时段，我们预计每秒至少有几千个写入请求和大约 100 万个读取请求。我们在设计系统架构时应该牢记这一点。\n6. Database Schema 数据库架构 We need to store data about users, their tweets, their favorite tweets, and people they follow.\n我们需要存储有关用户、他们的推文、他们最喜欢的推文以及他们关注的人的数据。\nFor choosing between SQL and NoSQL databases to store the above schema, please see ‘Database schema’ under Designing Instagram.\n要在 SQL 和 NoSQL 数据库之间进行选择来存储上述架构，请参阅设计 Instagram 下的“数据库架构”。\n7. Data Sharding 7.数据分片\nSince we have a huge number of new tweets every day and our read load is extremely high too, we need to distribute our data onto multiple machines such that we can read/write it efficiently. We have many options to shard our data; let’s go through them one by one:\n由于我们每天都会有大量的新推文，并且读取负载也非常高，因此我们需要将数据分发到多台机器上，以便能够高效地读/写。我们有很多选择来分片我们的数据；让我们一一分析一下：\nSharding based on UserID: We can try storing all the data of a user on one server. While storing, we can pass the UserID to our hash function that will map the user to a database server where we will store all of the user’s tweets, favorites, follows, etc. While querying for tweets/follows/favorites of a user, we can ask our hash function where can we find the data of a user and then read it from there. This approach has a couple of issues:\n基于UserID的分片：我们可以尝试将一个用户的所有数据存储在一台服务器上。在存储时，我们可以将 UserID 传递给我们的哈希函数，该函数将用户映射到数据库服务器，我们将在其中存储用户的所有推文、收藏夹、关注等。在查询用户的推文/关注/收藏夹时，我们可以询问我们的哈希函数在哪里可以找到用户的数据，然后从那里读取它。这种方法有几个问题：\nWhat if a user becomes hot? There could be a lot of queries on the server holding the user. This high load will affect the performance of our service.\n如果用户变得热门怎么办？持有用户的服务器上可能有很多查询。这种高负载会影响我们服务的性能。\nOver time some users can end up storing a lot of tweets or having a lot of follows compared to others. Maintaining a uniform distribution of growing user data is quite difficult.\n随着时间的推移，与其他用户相比，一些用户最终可能会存储大量推文或拥有大量关注者。保持不断增长的用户数据的均匀分布是相当困难的。\nTo recover from these situations either we have to repartition/redistribute our data or use consistent hashing.\n为了从这些情况中恢复，我们必须重新分区/重新分布我们的数据或使用一致的散列。\nSharding based on TweetID: Our hash function will map each TweetID to a random server where we will store that Tweet. To search for tweets, we have to query all servers, and each server will return a set of tweets. A centralized server will aggregate these results to return them to the user. Let’s look into timeline generation example; here are the number of steps our system has to perform to generate a user’s timeline:\n基于 TweetID 的分片：我们的哈希函数会将每个 TweetID 映射到一个随机服务器，我们将在其中存储该推文。要搜索推文，我们必须查询所有服务器，每个服务器都会返回一组推文。中央服务器将汇总这些结果并将其返回给用户。让我们看一下时间线生成示例；以下是我们的系统生成用户时间线必须执行的步骤数：\nOur application (app) server will find all the people the user follows.\n我们的应用程序（app）服务器将找到用户关注的所有人员。\nApp server will send the query to all database servers to find tweets from these people.\n应用服务器会将查询发送到所有数据库服务器以查找这些人的推文。\nEach database server will find the tweets for each user, sort them by recency and return the top tweets.\n每个数据库服务器都会找到每个用户的推文，按新近度对它们进行排序并返回顶部推文。\nApp server will merge all the results and sort them again to return the top results to the user.\n应用服务器将合并所有结果并再次排序，将排名靠前的结果返回给用户。\nThis approach solves the problem of hot users, but, in contrast to sharding by UserID, we have to query all database partitions to find tweets of a user, which can result in higher latencies.\n这种方法解决了热点用户的问题，但是，与按 UserID 分片相比，我们必须查询所有数据库分区才能找到用户的推文，这可能会导致更高的延迟。\nWe can further improve our performance by introducing cache to store hot tweets in front of the database servers.\n我们可以通过在数据库服务器前面引入缓存来存储热门推文来进一步提高性能。\nSharding based on Tweet creation time: Storing tweets based on creation time will give us the advantage of fetching all the top tweets quickly and we only have to query a very small set of servers. The problem here is that the traffic load will not be distributed, e.g., while writing, all new tweets will be going to one server and the remaining servers will be sitting idle. Similarly, while reading, the server holding the latest data will have a very high load as compared to servers holding old data.\n基于推文创建时间的分片：基于创建时间存储推文将为我们提供快速获取所有热门推文的优势，并且我们只需要查询非常小的一组服务器。这里的问题是流量负载不会被分配，例如，在写入时，所有新推文将发送到一台服务器，而其余服务器将闲置。类似地，在读取时，与保存旧数据的服务器相比，保存最新数据的服务器将具有非常高的负载。\nWhat if we can combine sharding by TweedID and Tweet creation time? If we don’t store tweet creation time separately and use TweetID to reflect that, we can get benefits of both the approaches. This way it will be quite quick to find the latest Tweets. For this, we must make each TweetID universally unique in our system and each TweetID should contain a timestamp too.\n如果我们可以将 TweedID 和推文创建时间的分片结合起来会怎么样？如果我们不单独存储推文创建时间并使用 TweetID 来反映这一点，我们就可以从这两种方法中受益。这样就可以很快找到最新的推文。为此，我们必须使每个 TweetID 在我们的系统中普遍唯一，并且每个 TweetID 也应该包含一个时间戳。\nWe can use epoch time for this. Let’s say our TweetID will have two parts: the first part will be representing epoch seconds and the second part will be an auto-incrementing sequence. So, to make a new TweetID, we can take the current epoch time and append an auto-incrementing number to it. We can figure out the shard number from this TweetID and store it there.\n我们可以为此使用纪元时间。假设我们的 TweetID 将有两部分：第一部分将表示纪元秒，第二部分将是自动递增序列。因此，要创建一个新的 TweetID，我们可以获取当前纪元时间并向其附加一个自动递增的数字。我们可以从这个 TweetID 中找出分片编号并将其存储在那里。\nWhat could be the size of our TweetID? Let’s say our epoch time starts today, how many bits we would need to store the number of seconds for the next 50 years?\n我们的 TweetID 的大小是多少？假设我们的纪元时间从今天开始，我们需要多少位来存储未来 50 年的秒数？\n86400 sec/day * 365 (days a year) * 50 (years) =\u0026gt; 1.6B\nWe would need 31 bits to store this number. Since on average we are expecting 1150 new tweets per second, we can allocate 17 bits to store auto incremented sequence; this will make our TweetID 48 bits long. So, every second we can store (2^17 =\u0026gt; 130K) new tweets. We can reset our auto incrementing sequence every second. For fault tolerance and better performance, we can have two database servers to generate auto-incrementing keys for us, one generating even numbered keys and the other generating odd numbered keys.\n我们需要 31 位来存储这个数字。由于我们平均每秒预计有 1150 条新推文，因此我们可以分配 17 位来存储自动递增序列；这将使我们的 TweetID 长为 48 位。因此，每一秒我们都可以存储 (2^17 =\u0026gt; 130K) 条新推文。我们可以每秒重置自动递增序列。为了容错和更好的性能，我们可以有两台数据库服务器为我们生成自动递增键，一台生成偶数键，另一台生成奇数键。\nIf we assume our current epoch seconds are “1483228800,” our TweetID will look like this:\n如果我们假设当前的纪元秒是“1483228800”，我们的 TweetID 将如下所示：\n1483228800 000001 1483228800 000002 1483228800 000003 1483228800 000004 …\nIf we make our TweetID 64bits (8 bytes) long, we can easily store tweets for the next 100 years and also store them for mili-seconds granularity.\n如果我们将 TweetID 设为 64 位（8 字节）长，我们​​就可以轻松存储未来 100 年的推文，并以毫秒为粒度进行存储。\nIn the above approach, we still have to query all the servers for timeline generation, but our reads (and writes) will be substantially quicker.\n在上述方法中，我们仍然需要查询所有服务器以生成时间线，但我们的读取（和写入）将会快得多。\nSince we don’t have any secondary index (on creation time) this will reduce our write latency. 2. While reading, we don’t need to filter on creation-time as our primary key has epoch time included in it.\n由于我们没有任何二级索引（在创建时），这将减少我们的写入延迟。 2.在读取时，我们不需要过滤创建时间，因为我们的主键有纪元时间包含在其中。\n8. Cache 8.缓存\nWe can introduce a cache for database servers to cache hot tweets and users. We can use an off-the- shelf solution like Memcache that can store the whole tweet objects. Application servers, before hitting database, can quickly check if the cache has desired tweets. Based on clients’ usage patterns we can determine how many cache servers we need.\n我们可以为数据库服务器引入缓存来缓存热门推文和用户。我们可以使用像 Memcache 这样的现成解决方案来存储整个推文对象。应用服务器在访问数据库之前可以快速检查缓存中是否有所需的推文。根据客户的使用模式，我们可以确定需要多少个缓存服务器。\nWhich cache replacement policy would best fit our needs? When the cache is full and we want to replace a tweet with a newer/hotter tweet, how would we choose? Least Recently Used (LRU) can be a reasonable policy for our system. Under this policy, we discard the least recently viewed tweet first.\n哪种缓存替换策略最适合我们的需求？当缓存已满并且我们想用更新/更热门的推文替换一条推文时，我们会如何选择？最近最少使用（LRU）对于我们的系统来说是一个合理的策略。根据此政策，我们首先丢弃最近最少查看的推文。\nHow can we have a more intelligent cache? If we go with 80-20 rule, that is 20% of tweets generating 80% of read traffic which means that certain tweets are so popular that a majority of people read them. This dictates that we can try to cache 20% of daily read volume from each shard.\n如何才能拥有更智能的缓存呢？如果我们采用 80-20 规则，即 20% 的推文产生 80% 的阅读流量，这意味着某些推文非常受欢迎，以至于大多数人都会阅读它们。这表明我们可以尝试缓存每个分片每日读取量的 20%。\nWhat if we cache the latest data? Our service can benefit from this approach. Let’s say if 80% of our users see tweets from the past three days only; we can try to cache all the tweets from the past three days. Let’s say we have dedicated cache servers that cache all the tweets from all the users from the past three days. As estimated above, we are getting 100 million new tweets or 30GB of new data every day (without photos and videos). If we want to store all the tweets from last three days, we will need less than 100GB of memory. This data can easily fit into one server, but we should replicate it onto multiple servers to distribute all the read traffic to reduce the load on cache servers. So whenever we are generating a user’s timeline, we can ask the cache servers if they have all the recent tweets for that user. If yes, we can simply return all the data from the cache. If we don’t have enough tweets in the cache, we have to query the backend server to fetch that data. On a similar design, we can try caching photos and videos from the last three days.\n如果我们缓存最新的数据怎么办？我们的服务可以从这种方法中受益。假设我们 80% 的用户只看到过去三天的推文；我们可以尝试缓存过去三天的所有推文。假设我们有专用的缓存服务器，可以缓存过去三天所有用户的所有推文。根据上述估计，我们每天会收到 1 亿条新推文或 30GB 新数据（不包括照片和视频）。如果我们想要存储过去三天的所有推文，我们将需要不到 100GB 的内存。这些数据可以很容易地放入一台服务器中，但我们应该将其复制到多台服务器上以分配所有读取流量，从而减少缓存服务器上的负载。因此，每当我们生成用户的时间线时，我们都可以询问缓存服务器是否拥有该用户最近的所有推文。如果是，我们可以简单地从缓存中返回所有数据。如果缓存中没有足够的推文，我们必须查询后端服务器来获取该数据。在类似的设计中，我们可以尝试缓存最近三天的照片和视频。\nOur cache would be like a hash table where ‘key’ would be ‘OwnerID’ and ‘value’ would be a doubly linked list containing all the tweets from that user in the past three days. Since we want to retrieve the most recent data first, we can always insert new tweets at the head of the linked list, which means all the older tweets will be near the tail of the linked list. Therefore, we can remove tweets from the tail to make space for newer tweets.\n我们的缓存就像一个哈希表，其中“key”是“OwnerID”，“value”是一个双向链表，其中包含该用户在过去三天内的所有推文。由于我们希望首先检索最新的数据，因此我们始终可以在链表的头部插入新的推文，这意味着所有较旧的推文将位于链表的尾部附近。因此，我们可以从尾部删除推文，为新的推文腾出空间。\n9. Timeline Generation 9. 时间线生成\nFor a detailed discussion about timeline generation, take a look at Designing Facebook’s Newsfeed.\n有关时间线生成的详细讨论，请查看设计 Facebook 的新闻源。\n10. Replication and Fault Tolerance 10.复制和容错\nSince our system is read-heavy, we can have multiple secondary database servers for each DB partition. Secondary servers will be used for read traffic only. All writes will first go to the primary server and then will be replicated to secondary servers. This scheme will also give us fault tolerance, since whenever the primary server goes down we can failover to a secondary server.\n由于我们的系统是读取密集型的，因此我们可以为每个数据库分区拥有多个辅助数据库服务器。辅助服务器将仅用于读取流量。所有写入将首先发送到主服务器，然后复制到辅助服务器。该方案还为我们提供了容错能力，因为每当主服务器出现故障时，我们都可以故障转移到辅助服务器。\n11. Load Balancing 11.负载均衡\nWe can add Load balancing layer at three places in our system 1) Between Clients and Application servers 2) Between Application servers and database replication servers and 3) Between Aggregation servers and Cache server. Initially, a simple Round Robin approach can be adopted; that distributes incoming requests equally among servers. This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is that if a server is dead, LB will take it out of the rotation and will stop sending any traffic to it. A problem with Round Robin LB is that it won’t take servers\n我们可以在系统中的三个位置添加负载平衡层：1）客户端和应用程序服务器之间，2）应用程序服务器和数据库复制服务器之间，3）聚合服务器和缓存服务器之间。最初，可以采用简单的循环方法；在服务器之间平均分配传入请求。该LB实现简单，不会引入任何开销。这种方法的另一个好处是，如果服务器死机，LB 会将其从轮换中删除，并停止向其发送任何流量。循环负载均衡的一个问题是它不会占用服务器\nload into consideration. If a server is overloaded or slow, the LB will not stop sending new requests to that server. To handle this, a more intelligent LB solution can be placed that periodically queries backend server about their load and adjusts traffic based on that.\n负载考虑。如果服务器过载或速度缓慢，负载均衡器不会停止向该服务器发送新请求。为了解决这个问题，可以放置更智能的 LB 解决方案，定期查询后端服务器的负载并据此调整流量。\n12. Monitoring 12. 监控\nHaving the ability to monitor our systems is crucial. We should constantly collect data to get an instant insight into how our system is doing. We can collect following metrics/counters to get an understanding of the performance of our service:\n拥有监控我们系统的能力至关重要。我们应该不断收集数据，以便立即了解我们的系统的运行情况。我们可以收集以下指标/计数器来了解我们服务的性能：\nNew tweets per day/second, what is the daily peak?\n每天/每秒新推文，每日峰值是多少？\nTimeline delivery stats, how many tweets per day/second our service is delivering. 3. Average latency that is seen by the user to refresh timeline.\n时间轴传送统计数据，我们的服务每天/每秒传送多少条推文。 3. 用户看到的刷新时间线的平均延迟。\nBy monitoring these counters, we will realize if we need more replication, load balancing, or caching.\n通过监视这些计数器，我们将意识到是否需要更多复制、负载平衡或缓存。\n13. Extended Requirements 13.扩展要求\nHow do we serve feeds? Get all the latest tweets from the people someone follows and merge/sort them by time. Use pagination to fetch/show tweets. Only fetch top N tweets from all the people someone follows. This N will depend on the client’s Viewport, since on a mobile we show fewer tweets compared to a Web client. We can also cache next top tweets to speed things up.\n我们如何提供 Feed？获取某人关注的人的所有最新推文，并按时间对它们进行合并/排序。使用分页来获取/显示推文。只获取所有关注者的前 N ​​条推文。这个 N 将取决于客户端的视口，因为与 Web 客户端相比，我们在移动设备上显示的推文更少。我们还可以缓存下一个热门推文以加快速度。\nAlternately, we can pre-generate the feed to improve efficiency; for details please see ‘Ranking and timeline generation’ under Designing Instagram.\n或者，我们可以预先生成 feed 以提高效率；有关详细信息，请参阅“设计 Instagram”下的“排名和时间线生成”。\nRetweet: With each Tweet object in the database, we can store the ID of the original Tweet and not store any contents on this retweet object.\n转推：对于数据库中的每个推文对象，我们可以存储原始推文的 ID，并且在此转推对象上不存储任何内容。\nTrending Topics: We can cache most frequently occurring hashtags or search queries in the last N seconds and keep updating them after every M seconds. We can rank trending topics based on the frequency of tweets or search queries or retweets or likes. We can give more weight to topics which are shown to more people.\n热门主题：我们可以缓存最近 N 秒内最常出现的主题标签或搜索查询，并在每 M 秒后不断更新它们。我们可以根据推文、搜索查询、转发或点赞的频率对热门主题进行排名。我们可以更加重视向更多人展示的主题。\nWho to follow? How to give suggestions? This feature will improve user engagement. We can suggest friends of people someone follows. We can go two or three levels down to find famous people for the suggestions. We can give preference to people with more followers.\n跟随谁？如何提出建议？此功能将提高用户参与度。我们可以推荐某人关注的人的朋友。我们可以下两三层去找名人提建议。我们可以优先考虑拥有更多关注者的人。\nAs only a few suggestions can be made at any time, use Machine Learning (ML) to shuffle and re- prioritize. ML signals could include people with recently increased follow-ship, common followers if the other person is following this user, common location or interests, etc.\n由于任何时候只能提出一些建议，因此请使用机器学习 (ML) 来重新排列和重新确定优先级。机器学习信号可能包括最近关注量增加的人、共同关注者（如果其他人正在关注该用户）、共同位置或兴趣等。\nMoments: Get top news for different websites for past 1 or 2 hours, figure out related tweets, prioritize them, categorize them (news, support, financial, entertainment, etc.) using ML – supervised learning or Clustering. Then we can show these articles as trending topics in Moments.\n时刻：获取过去 1 或 2 小时内不同网站的热门新闻，找出相关推文，对它们进行优先级排序，使用 ML（监督学习或聚类）对它们进行分类（新闻、支持、金融、娱乐等）。然后我们就可以把这些文章作为朋友圈的热门话题展示出来。\nSearch: Search involves Indexing, Ranking, and Retrieval of tweets. A similar solution is discussed in our next problem Design Twitter Search.\n搜索：搜索涉及推文的索引、排名和检索。我们的下一个问题“设计 Twitter 搜索”中讨论了类似的解决方案。\n","permalink":"https://blog.chensoul.cc/posts/2023/12/14/designing-twitter/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Twitter》设计 Twitter。\nLet’s design a Twitter-like social networking service. Users of the service will be able to post tweets, follow other people, and favorite tweets. Difficulty Level: Medium\n让我们设计一个类似 Twitter 的社交网络服务。该服务的用户将能够发布推文、关注其他人以及喜欢的推文。难度级别：中等\n1. What is Twitter? 1.什么是推特？\nTwitter is an online social networking service where users post and read short 140-character messages called “tweets.” Registered users can post and read tweets, but those who are not registered can only read them. Users access Twitter through their website interface, SMS, or mobile app.\nTwitter 是一种在线社交网络服务，用户可以在其中发布和阅读称为“推文”的 140 个字符的简短消息。注册用户可以发布和阅读推文，但未注册的用户只能阅读推文。用户通过网站界面、短信或移动应用程序访问 Twitter。\n2. Requirements and Goals of the System 系统的要求和目标 We will be designing a simpler version of Twitter with the following requirements:","title":"[译]《Grokking the System Design Interview》设计Twitter"},{"content":"Today I Learned. 今天分享内容：发布到 Maven 中央仓库的第一个项目。\n最近在 Github 上创建了一个 Pom 类型的 Maven 项目 chensoul-parent，该项目主页 https://chensoul.github.io/chensoul-parent/ ，这是我的第一个发布对 Maven 中央仓库的项目。\n其主要用途是管理常用的 Maven Plugin 插件。在编写该项目的过程中，参考了一些开源项目，他们分别是：\nhttps://github.com/eclipse/microprofile Eclipse 的一套开源微服务框架实现 https://github.com/microbean/microbean-function microBean™ 的 Java 扩展 https://github.com/naturalett/maven-hello-world 一个 Maven 发布 Jar 的 hello world 的示例项目 https://github.com/eclipse-store/store Eclipse 开源的一个高性能 Java 原生持久存储。微秒响应时间。超高吞吐量。最小延迟。创建超快速内存数据库应用程序和微服务。 该项目打包之后是一个 pom 文件，任何 Maven 项目都可以继承这个项目，这样可以免去自己管理 Mave Plugin 插件的麻烦。这里面的 Mave Plugin 插件包括：\n编译 打包 发布 测试，并生成测试报告 质量检测，包括代码风格检查、漏洞检测 生成网站并发布到 github pages 发布先是使用的 Maven Release Plugin 和 Nexus Staging Maven Plugin 插件，后来觉得 Maven Release Plugin 插件做的事情太多了，不如手动执行命令，于是去掉了 Maven Release Plugin 插件。\n关于 Nexus Staging Maven Plugin 插件的使用了，起初我使用了这个仓库发布 Maven 构建的脚本 。这个脚本比较复杂，于是找到了 https://github.com/naturalett/maven-hello-world 这个仓库，其对应的博客 《Publishing Artifacts to Maven Central using GitHub Actions: A Step-by-Step Guide》，对于如何部署构建到 Maven 中央仓库、如何使用 Github Action 说的比较清楚。如果你对于如何使用这个插件，可以阅读该文章，本文不作赘述。\n我对 Github Action 的 Workflow 做过一些优化。优化后的 Workflow 文件内容如下：\nname: \u0026#34;Maven Release\u0026#34; on: workflow_dispatch: inputs: releaseVersion: description: \u0026#34;Define the RELEASE version\u0026#34; required: false default: \u0026#34;\u0026#34; developmentVersion: description: \u0026#34;Define the SNAPSHOT version\u0026#34; required: false default: \u0026#34;\u0026#34; autoReleaseAfterClose: description: \u0026#34;Auto release after close\u0026#34; required: false default: \u0026#34;false\u0026#34; jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Set up Maven Central Repository uses: actions/setup-java@v3 with: java-version: 11 distribution: \u0026#34;temurin\u0026#34; java-package: \u0026#34;jdk\u0026#34; cache: \u0026#34;maven\u0026#34; server-id: ossrh - name: Configure Git User run: | git config user.email \u0026#34;actions@github.com\u0026#34; git config user.name \u0026#34;GitHub Actions\u0026#34; echo \u0026#34;sha_short=$(git rev-parse --short HEAD)\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV - name: Import GPG Key uses: crazy-max/ghaction-import-gpg@v5.0.0 with: gpg_private_key: ${{ secrets.MAVEN_GPG_PRIVATE_KEY }} passphrase: ${{ secrets.MAVEN_GPG_PASSPHRASE }} - name: Verify Whether a Release is Ready shell: bash run: | if [ \u0026#34;${{ github.event.inputs.autoReleaseAfterClose }}\u0026#34; == \u0026#34;true\u0026#34; ] ; then echo \u0026#34;auto_release=true\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV else echo \u0026#34;auto_release=false\u0026#34; \u0026gt;\u0026gt; $GITHUB_ENV fi - name: Fetch Artifact Information shell: bash run: | # remove \u0026#39;-SNAPSHOT\u0026#39; from version echo \u0026#34;artifact_version=$(grep -m1 \u0026#39;\u0026lt;version\u0026gt;\u0026#39; pom.xml | sed \u0026#39;s/.*\u0026lt;version\u0026gt;\\([^\u0026lt;]*\\)\u0026lt;\\/version\u0026gt;.*/\\1/\u0026#39; | sed \u0026#39;s/-SNAPSHOT$//\u0026#39;)\u0026#34; \u0026gt;\u0026gt; \u0026#34;$GITHUB_ENV\u0026#34; echo \u0026#34;artifact_name=$(grep -m1 \u0026#39;\u0026lt;artifactId\u0026gt;\u0026#39; pom.xml | sed \u0026#39;s/.*\u0026lt;artifactId\u0026gt;\\([^\u0026lt;]*\\)\u0026lt;\\/artifactId\u0026gt;.*/\\1/\u0026#39;)\u0026#34; \u0026gt;\u0026gt; \u0026#34;$GITHUB_ENV\u0026#34; echo \u0026#34;artifact_packaging=$(grep -m1 \u0026#39;\u0026lt;packaging\u0026gt;\u0026#39; pom.xml | sed \u0026#39;s/.*\u0026lt;packaging\u0026gt;\\([^\u0026lt;]*\\)\u0026lt;\\/packaging\u0026gt;.*/\\1/\u0026#39;)\u0026#34; \u0026gt;\u0026gt; \u0026#34;$GITHUB_ENV\u0026#34; - name: Release With Maven run: | echo \u0026#34;${{ env.artifact_name }} ${{ env.artifact_version }} ${{ env.artifact_packaging }}\u0026#34; mvn -B -U \\ release:prepare \\ release:perform \\ -DreleaseVersion=${{ github.event.inputs.releaseVersion }} \\ -DdevelopmentVersion=${{ github.event.inputs.developmentVersion }} \\ deploy \\ -s settings.xml \\ -Prelease \\ -Dgpg.passphrase=${{ secrets.MAVEN_GPG_PASSPHRASE }} ls -al ./target/ env: OSSRH_USERNAME: ${{ secrets.OSSRH_USERNAME }} OSSRH_TOKEN: ${{ secrets.OSSRH_TOKEN }} AUTO_RELEASE_AFTER_CLOSE: ${{ env.auto_release }} - name: Upload Artifact uses: actions/upload-artifact@v3 with: name: ${{ env.artifact_name }}-${{ env.artifact_version }} path: ./target/${{ env.artifact_name }}-${{ env.artifact_version }}.${{ env.artifact_packaging }} - name: Workflow Release Notes uses: peter-evans/repository-dispatch@v2 with: event-type: github-release client-payload: \u0026#39;{\u0026#34;auto_release\u0026#34;: \u0026#34;${{ env.auto_release }}\u0026#34;, \u0026#34;artifact\u0026#34;: \u0026#34;${{ env.artifact_name }}-${{ env.artifact_version }}\u0026#34;}\u0026#39; 在 Github Action 手动执行该 Workflow 文件时，可以指定正式版本、开发版本以及是否将 Maven 构建发布到中央仓库。如果是，则会触发 github-release.yml 这个 Workflow 在该 github 仓库创建一个 Release，效果如下：\nhttps://github.com/naturalett/maven-hello-world 这个仓库使用了 settings.xml 文件用于在 Github Action 中设置用户名和密码，这不是一个很好的解决方案。\n随后，在 https://github.com/eclipse-store/store 仓库中找到了使用 Github Action 发布 Maven 构建 的一个比较简洁的实现。从该文件的注释可以看到 Github Action 官方文档有关于使用 Maven 的介绍 。\n于是，在去掉 Maven Release Plugin 之后，又把 settings.xml 文件删除了。个人觉得是否创建 Github Release 应该手动控制更好一些，于是将 github-release.yml 这个 Workflow 也从我的仓库中删除了。\n在 microprofile-config 仓库里发现了一个 dependabot.yml ，于是把这个文件加入了我的项目中。添加该文件之后，会有一个机器人每天检查项目中使用的 maven 插件版本是否是最新版本，如果不是，则会创建一个 pull request。\n更多技术内容和如此使用，请查看源码。\nMaven 项目到中央仓库流程 发布 Maven 项目到中央仓库流程：\n1. pom.xml 配置如下信息 License 信息 开发人员信息 SCM 信息 Javadoc 和 Sources 插件 Distribution 管理 设置一个 profile （可选） 以 chensoul-parent 项目为例，License 信息如下：\n\u0026lt;licenses\u0026gt; \u0026lt;license\u0026gt; \u0026lt;name\u0026gt;Apache License 2.0\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://www.apache.org/licenses/LICENSE-2.0.txt\u0026lt;/url\u0026gt; \u0026lt;comments\u0026gt;The Apache License, Version 2.0\u0026lt;/comments\u0026gt; \u0026lt;distribution\u0026gt;repo\u0026lt;/distribution\u0026gt; \u0026lt;/license\u0026gt; \u0026lt;/licenses\u0026gt; 开发人员信息：\n\u0026lt;organization\u0026gt; \u0026lt;name\u0026gt;ChenSoul™\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;https://blog.chensoul.cc/\u0026lt;/url\u0026gt; \u0026lt;/organization\u0026gt; \u0026lt;developers\u0026gt; \u0026lt;developer\u0026gt; \u0026lt;id\u0026gt;chensoul\u0026lt;/id\u0026gt; \u0026lt;name\u0026gt;chensoul\u0026lt;/name\u0026gt; \u0026lt;email\u0026gt;chensoul.eth@gmail.com\u0026lt;/email\u0026gt; \u0026lt;url\u0026gt;https://blog.chensoul.cc\u0026lt;/url\u0026gt; \u0026lt;roles\u0026gt; \u0026lt;role\u0026gt;architect\u0026lt;/role\u0026gt; \u0026lt;role\u0026gt;developer\u0026lt;/role\u0026gt; \u0026lt;/roles\u0026gt; \u0026lt;timezone\u0026gt;+8\u0026lt;/timezone\u0026gt; \u0026lt;/developer\u0026gt; \u0026lt;/developers\u0026gt; SCM 信息：\n\u0026lt;scm\u0026gt; \u0026lt;connection\u0026gt;scm:git:https://github.com/chensoul/chensoul-parent.git\u0026lt;/connection\u0026gt; \u0026lt;developerConnection\u0026gt;scm:git:https://github.com/chensoul/chensoul-parent.git\u0026lt;/developerConnection\u0026gt; \u0026lt;url\u0026gt;https://github.com/chensoul/chensoul-parent\u0026lt;/url\u0026gt; \u0026lt;tag\u0026gt;HEAD\u0026lt;/tag\u0026gt; \u0026lt;/scm\u0026gt; Javadoc 和 Sources 插件：\n\u0026lt;build\u0026gt; \u0026lt;pluginManagement\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-source-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;attach-sources\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar-no-fork\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-javadoc-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.6.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;additionalJOptions combine.children=\u0026#34;append\u0026#34;\u0026gt; \u0026lt;additionalJOption\u0026gt;-J-Dhttp.agent=maven-javadoc-plugin\u0026lt;/additionalJOption\u0026gt; \u0026lt;/additionalJOptions\u0026gt; \u0026lt;attach\u0026gt;true\u0026lt;/attach\u0026gt; \u0026lt;doclint\u0026gt;none\u0026lt;/doclint\u0026gt; \u0026lt;doctitle\u0026gt;\u0026amp;lt;a href=\u0026#34;${project.url}\u0026#34; target=\u0026#34;_top\u0026#34;\u0026amp;gt;${project.artifactId}\u0026amp;lt;/a\u0026amp;gt; ${project.version} \u0026lt;/doctitle\u0026gt; \u0026lt;docfilessubdirs\u0026gt;true\u0026lt;/docfilessubdirs\u0026gt; \u0026lt;windowtitle\u0026gt;${project.name}\u0026lt;/windowtitle\u0026gt; \u0026lt;header\u0026gt;\u0026lt;![CDATA[\u0026lt;br\u0026gt;${project.name} v${project.version}]]\u0026gt;\u0026lt;/header\u0026gt; \u0026lt;bottom\u0026gt; \u0026lt;![CDATA[Copyright \u0026amp;copy; ${project.inceptionYear}\u0026amp;ndash;{currentYear}, \u0026lt;a href=\u0026#34;${project.organization.url}\u0026#34; target=\u0026#34;_parent\u0026#34;\u0026gt;${project.organization.name}\u0026lt;/a\u0026gt;. All rights reserved.]]\u0026gt; \u0026lt;/bottom\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;attach-javadocs\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;jar\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/pluginManagement\u0026gt; \u0026lt;/build\u0026gt; Distribution 管理信息：\n\u0026lt;distributionManagement\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://s01.oss.sonatype.org/service/local/staging/deploy/maven2/\u0026lt;/url\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;snapshotRepository\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://s01.oss.sonatype.org/content/repositories/snapshots\u0026lt;/url\u0026gt; \u0026lt;uniqueVersion\u0026gt;true\u0026lt;/uniqueVersion\u0026gt; \u0026lt;/snapshotRepository\u0026gt; \u0026lt;site\u0026gt; \u0026lt;id\u0026gt;github\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://github.com/chensoul/chensoul-parent\u0026lt;/url\u0026gt; \u0026lt;/site\u0026gt; \u0026lt;/distributionManagement\u0026gt; 设置一个 profile：\n\u0026lt;profiles\u0026gt; \u0026lt;!-- mvn clean source:jar javadoc:jar deploy -DskipTests -P release --\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;release\u0026lt;/id\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!-- https://blog.sonatype.com/2010/01/how-to-generate-pgp-signatures-with-maven/--\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-gpg-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;gpgArguments\u0026gt; \u0026lt;arg\u0026gt;--pinentry-mode\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;loopback\u0026lt;/arg\u0026gt; \u0026lt;/gpgArguments\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;sign-artifacts\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;verify\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;sign\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/profile\u0026gt; 2. GPG 设置 安装 GPG 生成 key 上传 key MacOs 上操作如下：\nbrew install gpg # Generate a key gpg --gen-key # List your key gpg --list-keys # Define a key expiration : \u0026#39; Press 1 Type expire Type the expiration Months\\Years Type save \u0026#39; gpg --edit-key \u0026lt;Your Key - You Can Get From The Command Above --list-keys\u0026gt; # Distribute your public key to a key server gpg --keyserver keyserver.ubuntu.com --send-keys \u0026lt;Your Key - You Can Get From The Command Above --list-keys\u0026gt; 3. 创建 Sonatype 账号 在 Sonatype Jira 上创建用户，并提交 Issure\n在 settings.xml 中配置 Sonatype 用户名和密码以及 gpg 密钥\n\u0026lt;servers\u0026gt; \u0026lt;server\u0026gt; \u0026lt;id\u0026gt;gpg.passphrase\u0026lt;/id\u0026gt; \u0026lt;passphrase\u0026gt;xxxx\u0026lt;/passphrase\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;server\u0026gt; \u0026lt;id\u0026gt;ossrh\u0026lt;/id\u0026gt; \u0026lt;username\u0026gt;xxxx\u0026lt;/username\u0026gt; \u0026lt;password\u0026gt;xxxxx\u0026lt;/password\u0026gt; \u0026lt;/server\u0026gt; \u0026lt;/servers\u0026gt; 4. 部署 Maven deploy 命令：\nmvn clean source:jar javadoc:jar deploy -DskipTests -P release 执行成功之后，可以在下面三个仓库查看：\nSNAPSHOT artifacts Sontype Release artifacts Maven Release artifacts Maven central release 例如，如果当前项目为快照版本：1.0.35-SNAPSHOT，执行上面 deploy 命令之后，在 SNAPSHOT artifacts 可以看到上传的内容：\n如果当前项目为正式版本：1.0.35，执行上面 deploy 命令之后，可以看到输出日志：\nUploaded to ossrh: https://s01.oss.sonatype.org:443/service/local/staging/deployByRepositoryId/comchensoul-1107/com/chensoul/chensoul-parent/1.0.35/chensoul-parent-1.0.35.pom.asc (228 B at 425 B/s) [INFO] * Upload of locally staged artifacts finished. [INFO] * Closing staging repository with ID \u0026#34;comchensoul-1107\u0026#34;. Waiting for operation to complete... ................. [INFO] Remote staged 1 repositories, finished with success. [INFO] ------------------------------------------------------------------------ [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 01:15 min [INFO] Finished at: 2023-12-20T09:21:20+08:00 [INFO] ------------------------------------------------------------------------ 登陆 https://s01.oss.sonatype.org/ 之后，在 https://s01.oss.sonatype.org/#stagingRepositories 可以查看到 comchensoul-1107 这个 staging 仓库。\nstaging 意思是该仓库还不是正式仓库，在 Maven Release artifacts 还查询不到。如果想将该 staging 仓库发布到 Release 仓库，则需要点击上图中的 Release 按钮。然后等几分钟就可以中 Release 仓库看到：\nhttps://repo.maven.apache.org 、https://mvnrepository.com/ 同步有延时，还没有查询到。\n如果想在 staging 仓库关闭之后自动 Release 到正式仓库，可以使用 nexus-staging-maven-plugin 插件。在 release profile 中添加：\n\u0026lt;!-- https://itnext.io/publishing-artifacts-to-maven-central-using-github-actions-a-step-by-step-guide-fd65ef075fd4 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.sonatype.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;nexus-staging-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.13\u0026lt;/version\u0026gt; \u0026lt;extensions\u0026gt;true\u0026lt;/extensions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;serverId\u0026gt;ossrh\u0026lt;/serverId\u0026gt; \u0026lt;nexusUrl\u0026gt;https://s01.oss.sonatype.org/\u0026lt;/nexusUrl\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 然后在 deploy 命令后添加参数：\nmvn clean source:jar javadoc:jar deploy -DskipTests -P release -DautoReleaseAfterClose=true 5. 在 GitHub Actions 配置 CICD 配置一个 maven-release.yml 文件，文件内容参考如下：\n# This workflow will build a package using Maven and then publish it to GitHub packages when a release is created # For more information see: https://github.com/actions/setup-java/blob/main/docs/advanced-usage.md#apache-maven-with-a-settings-path name: Maven Release on: release: types: [created] jobs: publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Install gpg secret key run: | cat \u0026lt;(echo -e \u0026#34;${{ secrets.MAVEN_GPG_PRIVATE_KEY }}\u0026#34;) | gpg --batch --import gpg --list-secret-keys --keyid-format LONG - name: Set up Java for publishing to Maven Central Repository uses: actions/setup-java@v4 with: java-version: 8 distribution: \u0026#34;temurin\u0026#34; cache: \u0026#34;maven\u0026#34; server-id: ossrh server-username: MAVEN_USERNAME server-password: MAVEN_PASSWORD gpg-passphrase: PASSPHRASE - name: Maven Release run: mvn -ntp -B -U clean source:jar javadoc:jar deploy site scm-publish:publish-scm -P release -DautoReleaseAfterClose=true env: MAVEN_USERNAME: ${{ secrets.OSSRH_USERNAME }} MAVEN_PASSWORD: ${{ secrets.OSSRH_TOKEN }} PASSPHRASE: ${{ secrets.MAVEN_GPG_PASSPHRASE }} 需要自 GitHub Actions 的 Actions 页面配置以下 Secrets：\nOSSRH_USERNAME OSSRH_TOKEN MAVEN_GPG_PASSPHRASE MAVEN_GPG_PRIVATE_KEY 其 Maven 执行命令：\nmvn -ntp -B -U clean deploy site scm-publish:publish-scm -P release -DautoReleaseAfterClose=true 注意：这里 scm-publish 是把生成的 site 站点发布到该仓库的 gp-pages 分支\n6. 在项目里面配置 sonatype 仓库 在 pom.xml 中添加：\n\u0026lt;repositories\u0026gt; \u0026lt;!-- 如果使用浏览器访问时，需要添加 groupId 才显示内容 --\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;oss-snapshots\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://oss.sonatype.org/content/repositories/snapshots/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;repository\u0026gt; \u0026lt;id\u0026gt;oss-snapshots-s01\u0026lt;/id\u0026gt; \u0026lt;url\u0026gt;https://s01.oss.sonatype.org/content/repositories/snapshots/\u0026lt;/url\u0026gt; \u0026lt;releases\u0026gt; \u0026lt;enabled\u0026gt;false\u0026lt;/enabled\u0026gt; \u0026lt;/releases\u0026gt; \u0026lt;snapshots\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/snapshots\u0026gt; \u0026lt;/repository\u0026gt; \u0026lt;/repositories\u0026gt; \u0026ndash; EOF\n","permalink":"https://blog.chensoul.cc/posts/2023/12/13/til/","summary":"Today I Learned. 今天分享内容：发布到 Maven 中央仓库的第一个项目。\n最近在 Github 上创建了一个 Pom 类型的 Maven 项目 chensoul-parent，该项目主页 https://chensoul.github.io/chensoul-parent/ ，这是我的第一个发布对 Maven 中央仓库的项目。\n其主要用途是管理常用的 Maven Plugin 插件。在编写该项目的过程中，参考了一些开源项目，他们分别是：\nhttps://github.com/eclipse/microprofile Eclipse 的一套开源微服务框架实现 https://github.com/microbean/microbean-function microBean™ 的 Java 扩展 https://github.com/naturalett/maven-hello-world 一个 Maven 发布 Jar 的 hello world 的示例项目 https://github.com/eclipse-store/store Eclipse 开源的一个高性能 Java 原生持久存储。微秒响应时间。超高吞吐量。最小延迟。创建超快速内存数据库应用程序和微服务。 该项目打包之后是一个 pom 文件，任何 Maven 项目都可以继承这个项目，这样可以免去自己管理 Mave Plugin 插件的麻烦。这里面的 Mave Plugin 插件包括：\n编译 打包 发布 测试，并生成测试报告 质量检测，包括代码风格检查、漏洞检测 生成网站并发布到 github pages 发布先是使用的 Maven Release Plugin 和 Nexus Staging Maven Plugin 插件，后来觉得 Maven Release Plugin 插件做的事情太多了，不如手动执行命令，于是去掉了 Maven Release Plugin 插件。\n关于 Nexus Staging Maven Plugin 插件的使用了，起初我使用了这个仓库发布 Maven 构建的脚本 。这个脚本比较复杂，于是找到了 https://github.com/naturalett/maven-hello-world 这个仓库，其对应的博客 《Publishing Artifacts to Maven Central using GitHub Actions: A Step-by-Step Guide》，对于如何部署构建到 Maven 中央仓库、如何使用 Github Action 说的比较清楚。如果你对于如何使用这个插件，可以阅读该文章，本文不作赘述。","title":"2023-12-13｜发布到Maven中央仓库的第一个项目"},{"content":"Today I Learned. 今天我学了：RMI、Java漏洞安全、Semgrep漏洞检测。\nRMI 介绍 RMI（Remote Method Invocation）是Java语言提供的一种远程调用机制，用于在分布式系统中实现对象之间的远程通信。\n通过Java RMI，开发人员可以像调用本地方法一样调用远程对象的方法。RMI隐藏了底层网络通信的复杂性，使得远程方法调用过程对于开发人员来说更加简单和透明。\n发展历史 RMI（Remote Method Invocation）是Java语言提供的一种远程调用机制，它的发展历史可以追溯到上个世纪90年代。\n以下是RMI的主要发展历程：\n初期版本（Java 1.1）：RMI最早出现在Java 1.1版本中，它提供了基本的远程调用功能，允许开发人员在分布式系统中使用Java对象进行远程方法调用。这个版本的RMI还比较简单，功能相对有限。 RMI-IIOP（Java 1.2）：随着Java 1.2版本的发布，Sun Microsystems（现在的Oracle）引入了RMI-IIOP（RMI over IIOP）的概念，将RMI与CORBA（Common Object Request Broker Architecture）进行了整合。RMI-IIOP使用IIOP（Internet Inter-ORB Protocol）作为底层的通信协议，使得Java对象能够与其他编程语言的对象进行交互。 JDK 1.3和1.4的改进：在JDK 1.3和1.4版本中，RMI得到了进一步改进和增强。其中包括对Java序列化机制的改进，提供了更好的兼容性和性能。此外，还引入了Java Activation Framework（JAF），用于处理传输的数据类型。 Java 5的增强：Java 5引入了一些重要的增强功能，如注解（Annotations）和泛型（Generics）。这些功能使得RMI的使用更加便捷和灵活。 Java 8和后续版本：在Java 8及其后续版本中，RMI并没有进行大规模的改动。然而，随着Java平台的不断发展和改进，RMI仍然是Java分布式系统中常用的远程调用机制之一。 架构 RMI架构包括以下几个核心组件：\n远程接口（Remote Interface）：远程接口定义了远程对象的方法列表，客户端可以通过该接口调用远程对象的方法。远程接口必须继承java.rmi.Remote接口，并声明可以被远程调用的方法。 远程对象（Remote Object）：远程对象是实现了远程接口的Java对象。这些对象的方法可以通过RMI进行远程调用。远程对象必须继承java.rmi.server.UnicastRemoteObject类，并实现对应的远程接口。 远程注册表（Remote Registry）：远程注册表是一个中央注册表，用于存储远程对象的引用。客户端可以查询远程注册表以获取远程对象的引用，并通过引用调用远程对象的方法。远程注册表使用RMI注册表服务（rmiregistry）来实现。 Stub（存根）和Skeleton（骨架）：Stub和Skeleton是RMI的关键组件，用于在客户端和服务器之间进行通信。Stub是客户端的代理，它负责将客户端的方法调用转发到远程对象。Skeleton是服务器端的代理，它负责接收客户端的方法调用并将其转发给实际的远程对象。 RMI协议（RMI Protocol）：RMI协议定义了客户端和服务器之间的通信协议，包括请求、响应、参数传递和序列化等细节。RMI协议使用Java序列化来对对象进行编码和解码，以实现对象在网络上的传输。 RMI架构的基本工作流程如下：\n服务器端将远程对象注册到远程注册表中。 客户端从远程注册表中获取远程对象的引用。 客户端通过引用调用远程对象的方法。 客户端的方法调用被转发到服务器端的远程对象。 服务器端的远程对象执行相应的方法，并将结果返回给客户端。 客户端接收到方法的返回值。 在JDK 1.2版本（1998）之后，骨架skeleton不再被需要, 由Java的UnicastServerRef#dispatch替代；在JDK 5 （大家常说的1.5）之后，不再需要手动利用rmic命令生成静态Stub，而是会由Java自动地动态生成。这个动态生成也是我们后面JNDI注入的关键。\nRMI漏洞 RMI（Remote Method Invocation）在过去的一段时间中曾发现一些安全漏洞，这些漏洞可能会导致安全风险。以下是一些常见的RMI漏洞：\n反序列化漏洞：RMI使用Java序列化机制来在网络上传输对象。然而，如果不正确地处理反序列化过程，攻击者可能通过构造恶意序列化数据来执行远程代码。这种漏洞被广泛称为\u0026quot;Java反序列化漏洞\u0026quot;或\u0026quot;Java反序列化攻击\u0026quot;，并且不仅仅影响RMI，还可能影响其他使用Java序列化的技术。 未授权访问漏洞：RMI服务默认情况下可能没有进行适当的身份验证和授权检查。这可能导致攻击者能够未经授权地访问远程对象和调用方法，从而造成安全风险。 注册表绕过漏洞：RMI使用注册表（Registry）来存储远程对象的引用。攻击者可能通过绕过注册表或篡改注册表中的引用，来执行恶意操作或替换原始对象。 未加密的通信漏洞：如果RMI的通信过程没有适当地加密和保护，攻击者可能能够窃听、篡改或重放网络通信，从而获取敏感信息或执行中间人攻击。 为了缓解这些漏洞的风险，建议采取以下安全措施：\n及时更新和升级使用的Java运行时环境，以获取最新的安全修复程序。JDK 8u121引入了对RMI漏洞的修复。 在反序列化过程中谨慎处理输入数据，避免接受未受信任的序列化数据。 实施适当的身份验证和授权机制，确保只有经过授权的用户可以访问和调用远程对象。 使用安全协议（如SSL/TLS）对RMI通信进行加密和保护。 配置和限制RMI的网络访问，仅允许受信任的主机和端口进行通信。 对RMI注册表进行安全配置，限制对注册表的访问权限。 RMI用到的技术 Java序列化（Serialization）：RMI使用Java序列化来实现对象在网络上的传输。Java序列化机制允许将Java对象转换为字节流表示，以便在网络上进行传输。RMI使用Java序列化将方法调用和参数编码为字节流，并在客户端和服务器之间进行传输。 Java网络通信（Network Communication）：RMI使用Java的网络通信机制来在客户端和服务器之间进行远程调用的传输。RMI支持多种底层传输协议，如JRMP（Java Remote Method Protocol）和IIOP（Internet Inter-ORB Protocol）。这些协议负责将编码的方法调用和参数传输到远程对象，并将结果返回给客户端。 代理。Stub和Skeleton是RMI中的代理组件。Stub是客户端的代理，Skeleton是服务器端的代理。Stub负责将客户端的方法调用转发到远程对象，而Skeleton接收客户端的方法调用并将其转发给实际的远程对象。Stub和Skeleton处理了网络通信、参数编组和解组等细节，使得远程调用过程对开发人员透明。 Java漏洞 文章 关于Java中RMI的个人拙见\nJava JNDI其它注入点分析\nJava JNDI注入源码分析\nJava RMI反序列化\u0026amp;JNDI注入\nJNDI 注入漏洞的前世今生\n攻击Java中的JNDI、RMI、LDAP(一)\n攻击Java中的JNDI、RMI、LDAP(二)\n攻击Java中的JNDI、RMI、LDAP(三)\n攻击Java Web应用-[Java Web安全]\n视频 B站最全的Java安全学习路线 Java反序列化RMI专题-没有人比我更懂RMI 博客 https://paper.seebug.org/\nhttps://su18.org/\nhttps://www.03sec.com/\nhttps://y4er.com/\nhttps://evilpan.com/\nhttp://nekopunch.cn/\nhttps://4ra1n.github.io/\nhttps://chenlvtang.top/\nhttps://www.yulegeyu.com/\n社区 https://xz.aliyun.com/ https://web.sqlsec.com/ Semgrep semgrep 是一款由Facebook开源的白盒代码扫描工具，项目地址：https://github.com/returntocorp/semgrep，其规则编写简单，易用，扫描速度快。相较于CodeQL 而言，入门门槛较低，编写规则简单，且非常方便地接入到CI流程中。\n安装步骤 方式一、mac机器上可使用 homebrew 安装：\nbrew install semgrep 方式二、Ubuntu / Windows via WSL / Linux / macOS 也可以使用pip进行安装：\npython3 -m pip install semgrep 方式三、Docker部署:\ndocker pull returntocorp/semgrep:latest semgrep 有 Pro 版本与社区版本两个版本，使用下面命令可以登陆 Pro 版本：\nsemgrep login 根据输出访问对应的链接进行登陆。\n终端获得 token 之后，就可以安装 pro 引擎了。\nsemgrep install-semgrep-pro 安装完后可以使用 --pro 参数调用 pro 引擎。\nsemgrep --pro --config \u0026#34;p/default\u0026#34; 使用 git clone https://github.com/WebGoat/WebGoat semgrep -c p/sql-injection WebGoat -o WebGoat.json --json 说明：\n-o：输出扫描结果到文件\n--json：指定输出 json 格式文件。可以输出json格式/xml/sarif 等格式\n--config：配置扫描规则文件 官方也提供了一些规则文件，在 https://semgrep.dev/r 里可以查看各种分类的规则集。\n输出结果如下：\n┌─────────────┐ │ Scan Status │ └─────────────┘ Scanning 1048 files (only git-tracked) with 103 Code rules: CODE RULES Language Rules Files Origin Rules ────────────────────────── ─────────────────── java 16 279 Pro rules 55 js 10 82 Community 48 SUPPLY CHAIN RULES 💎 Run `semgrep ci` to find dependency vulnerabilities and advanced cross-file findings. PROGRESS ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:03 ┌──────────────┐ │ Scan Summary │ └──────────────┘ Some files were skipped or only partially analyzed. Scan was limited to files tracked by git. Scan skipped: 87 files matching .semgrepignore patterns For a full list of skipped files, run semgrep with the --verbose flag. Ran 26 rules on 361 files: 13 findings. ➜ IdeaProjects semgrep install-semgrep-pro Semgrep Pro Engine will be installed in /opt/homebrew/Cellar/semgrep/1.52.0/libexec/lib/python3.11/site-packages/semgrep/bin/semgrep-core-proprietary Downloading... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.6/159.6 MB 7.6 MB/s 0:00:00 Successfully installed Semgrep Pro Engine (version 3e84760)! 注意隐私策略 根据官方的隐私策略 Semgrep Privacy Policy - Semgrep 的相关描述。\n$ semgrep --config=myrule.yaml # → no metrics (loading rules from local file) $ semgrep --config=p/python # → metrics enabled (fetching Registry) $ semgrep login \u0026amp;\u0026amp; semgrep ci # → metrics enabled (logged in to semgrep.dev) 当仅使用本地配置文件或命令行搜索模式运行时，官方不会收集相关信息。 当使用 Registry 中的规则时，官方会收集所需数据以帮助维护人员完善规则。 当使用云平台时，官方也会收集这些数据，并且将结果存放在云平台中。 收集数据的具体内容可见：Data collected as metrics\n用户也可以通过指定 --metrics 选项来控制数据的发送。\n--metrics auto：（默认）每当从 Semgrep 注册表中提取规则时都会发送 --metrics on：每次 Semgrep 运行时都会发送 --metrics off：永远不会发送 如果有隐私考虑的话，建议离线使用规则库，并添加 --metrics off 参数。\n参考 轻量级代码审计工具: Semgrep https://github.com/chenlvtang/CodeReview-Java 使用 Semgrep 规则检测开源 CMS 系统的漏洞 \u0026ndash; EOF\n","permalink":"https://blog.chensoul.cc/posts/2023/12/12/til/","summary":"Today I Learned. 今天我学了：RMI、Java漏洞安全、Semgrep漏洞检测。\nRMI 介绍 RMI（Remote Method Invocation）是Java语言提供的一种远程调用机制，用于在分布式系统中实现对象之间的远程通信。\n通过Java RMI，开发人员可以像调用本地方法一样调用远程对象的方法。RMI隐藏了底层网络通信的复杂性，使得远程方法调用过程对于开发人员来说更加简单和透明。\n发展历史 RMI（Remote Method Invocation）是Java语言提供的一种远程调用机制，它的发展历史可以追溯到上个世纪90年代。\n以下是RMI的主要发展历程：\n初期版本（Java 1.1）：RMI最早出现在Java 1.1版本中，它提供了基本的远程调用功能，允许开发人员在分布式系统中使用Java对象进行远程方法调用。这个版本的RMI还比较简单，功能相对有限。 RMI-IIOP（Java 1.2）：随着Java 1.2版本的发布，Sun Microsystems（现在的Oracle）引入了RMI-IIOP（RMI over IIOP）的概念，将RMI与CORBA（Common Object Request Broker Architecture）进行了整合。RMI-IIOP使用IIOP（Internet Inter-ORB Protocol）作为底层的通信协议，使得Java对象能够与其他编程语言的对象进行交互。 JDK 1.3和1.4的改进：在JDK 1.3和1.4版本中，RMI得到了进一步改进和增强。其中包括对Java序列化机制的改进，提供了更好的兼容性和性能。此外，还引入了Java Activation Framework（JAF），用于处理传输的数据类型。 Java 5的增强：Java 5引入了一些重要的增强功能，如注解（Annotations）和泛型（Generics）。这些功能使得RMI的使用更加便捷和灵活。 Java 8和后续版本：在Java 8及其后续版本中，RMI并没有进行大规模的改动。然而，随着Java平台的不断发展和改进，RMI仍然是Java分布式系统中常用的远程调用机制之一。 架构 RMI架构包括以下几个核心组件：\n远程接口（Remote Interface）：远程接口定义了远程对象的方法列表，客户端可以通过该接口调用远程对象的方法。远程接口必须继承java.rmi.Remote接口，并声明可以被远程调用的方法。 远程对象（Remote Object）：远程对象是实现了远程接口的Java对象。这些对象的方法可以通过RMI进行远程调用。远程对象必须继承java.rmi.server.UnicastRemoteObject类，并实现对应的远程接口。 远程注册表（Remote Registry）：远程注册表是一个中央注册表，用于存储远程对象的引用。客户端可以查询远程注册表以获取远程对象的引用，并通过引用调用远程对象的方法。远程注册表使用RMI注册表服务（rmiregistry）来实现。 Stub（存根）和Skeleton（骨架）：Stub和Skeleton是RMI的关键组件，用于在客户端和服务器之间进行通信。Stub是客户端的代理，它负责将客户端的方法调用转发到远程对象。Skeleton是服务器端的代理，它负责接收客户端的方法调用并将其转发给实际的远程对象。 RMI协议（RMI Protocol）：RMI协议定义了客户端和服务器之间的通信协议，包括请求、响应、参数传递和序列化等细节。RMI协议使用Java序列化来对对象进行编码和解码，以实现对象在网络上的传输。 RMI架构的基本工作流程如下：\n服务器端将远程对象注册到远程注册表中。 客户端从远程注册表中获取远程对象的引用。 客户端通过引用调用远程对象的方法。 客户端的方法调用被转发到服务器端的远程对象。 服务器端的远程对象执行相应的方法，并将结果返回给客户端。 客户端接收到方法的返回值。 在JDK 1.2版本（1998）之后，骨架skeleton不再被需要, 由Java的UnicastServerRef#dispatch替代；在JDK 5 （大家常说的1.5）之后，不再需要手动利用rmic命令生成静态Stub，而是会由Java自动地动态生成。这个动态生成也是我们后面JNDI注入的关键。\nRMI漏洞 RMI（Remote Method Invocation）在过去的一段时间中曾发现一些安全漏洞，这些漏洞可能会导致安全风险。以下是一些常见的RMI漏洞：\n反序列化漏洞：RMI使用Java序列化机制来在网络上传输对象。然而，如果不正确地处理反序列化过程，攻击者可能通过构造恶意序列化数据来执行远程代码。这种漏洞被广泛称为\u0026quot;Java反序列化漏洞\u0026quot;或\u0026quot;Java反序列化攻击\u0026quot;，并且不仅仅影响RMI，还可能影响其他使用Java序列化的技术。 未授权访问漏洞：RMI服务默认情况下可能没有进行适当的身份验证和授权检查。这可能导致攻击者能够未经授权地访问远程对象和调用方法，从而造成安全风险。 注册表绕过漏洞：RMI使用注册表（Registry）来存储远程对象的引用。攻击者可能通过绕过注册表或篡改注册表中的引用，来执行恶意操作或替换原始对象。 未加密的通信漏洞：如果RMI的通信过程没有适当地加密和保护，攻击者可能能够窃听、篡改或重放网络通信，从而获取敏感信息或执行中间人攻击。 为了缓解这些漏洞的风险，建议采取以下安全措施：\n及时更新和升级使用的Java运行时环境，以获取最新的安全修复程序。JDK 8u121引入了对RMI漏洞的修复。 在反序列化过程中谨慎处理输入数据，避免接受未受信任的序列化数据。 实施适当的身份验证和授权机制，确保只有经过授权的用户可以访问和调用远程对象。 使用安全协议（如SSL/TLS）对RMI通信进行加密和保护。 配置和限制RMI的网络访问，仅允许受信任的主机和端口进行通信。 对RMI注册表进行安全配置，限制对注册表的访问权限。 RMI用到的技术 Java序列化（Serialization）：RMI使用Java序列化来实现对象在网络上的传输。Java序列化机制允许将Java对象转换为字节流表示，以便在网络上进行传输。RMI使用Java序列化将方法调用和参数编码为字节流，并在客户端和服务器之间进行传输。 Java网络通信（Network Communication）：RMI使用Java的网络通信机制来在客户端和服务器之间进行远程调用的传输。RMI支持多种底层传输协议，如JRMP（Java Remote Method Protocol）和IIOP（Internet Inter-ORB Protocol）。这些协议负责将编码的方法调用和参数传输到远程对象，并将结果返回给客户端。 代理。Stub和Skeleton是RMI中的代理组件。Stub是客户端的代理，Skeleton是服务器端的代理。Stub负责将客户端的方法调用转发到远程对象，而Skeleton接收客户端的方法调用并将其转发给实际的远程对象。Stub和Skeleton处理了网络通信、参数编组和解组等细节，使得远程调用过程对开发人员透明。 Java漏洞 文章 关于Java中RMI的个人拙见\nJava JNDI其它注入点分析\nJava JNDI注入源码分析\nJava RMI反序列化\u0026amp;JNDI注入","title":"2023-12-12｜RMI、Java漏洞安全、Semgrep漏洞检测"},{"content":"很多业务有生成唯一 ID 并作为数据库主键的需求。数据库会在这个字段上建立聚集索引（参考 MySQL InnoDB），即该字段会影响各条数据再物理存储上的顺序。\nID还要尽可能短，节省内存，让数据库索引效率更高。基本上64位整数能够满足绝大多数的场景，但是如果能做到比64位更短那就更好了。需要根据具体业务进行分析，预估出ID的最大值，这个最大值通常比64位整数的上限小很多，于是我们可以用更少的bit表示这个ID。\n查询的时候，往往有分页或者排序的需求，所以需要给每条数据添加一个时间字段，并在其上建立普通索引(Secondary Index)。但是普通索引的访问效率比聚集索引慢，如果能够让ID按照时间粗略有序，则可以省去这个时间字段。为什么不是按照时间精确有序呢？因为按照时间精确有序是做不到的，除非用一个单机算法，在分布式场景下做到精确有序性能一般很差。\n这就引出了 ID 生成的三大核心需求：\n全局唯一 按照时间粗略有序 尽可能短 下面介绍一些常用的生成 ID 的方法。\nUUID UUID 是一类算法的统称，具体有不同的实现。UUID 的优点是每台机器可以独立产生 ID，理论上保证不会重复，所以天然是分布式的；缺点是生成的 ID 太长，不仅占用内存，而且索引查询效率低。\nMongoDB 的 ObjectId 使用的就是 UUID 算法。生成的 ObjectId 占 12 个字节，由以下几个部分组成，\n4 个字节表示的 Unix timestamp 3 个字节表示的机器的 ID 2 个字节表示的进程 ID 3 个字节表示的计数器 使用数据库 可以使用数据库中的自增主键来生成ID。将ID生成的过程交给数据库管理，每个节点向数据库插入记录时，数据库会自动分配一个唯一的ID。通过使用数据库的自动递增功能，可以保证ID的唯一性和粗略有序性。\n在分布式环境下，可以使用多台数据库协同工作生成 ID。假设用 8 台MySQL服务器协同工作，第一台 MySQL 初始值是 1，每次自增 8，第二台 MySQL 初始值是 2，每次自增 8，依次类推。在数据库前面添加一个负载均衡，每来一个请求，由负载均衡随机地将请求发给 8 台 MySQL 中的任意一个，然后返回一个ID。\nFlickr就是这么做的，仅仅使用了两台 MySQL 服务器。可见这个方法虽然简单无脑，但是性能足够好。不过要注意，在 MySQL 中，不需要把所有 ID 都存下来，每台机器只需要存一个 MAX_ID 就可以了。这需要用到 MySQL 的一个 REPLACE INTO 特性。\nFlickr 的实现方式如下。\nTickets64 表结构如下：\nCREATE TABLE `Tickets64` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default \u0026#39;\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=InnoDB SELECT * from Tickets64 返回一行，如下所示：\n+-------------------+------+ | id | stub | +-------------------+------+ | 72157623227190423 | a | +-------------------+------+ 当我需要一个新的全局唯一 64 位 ID 时，我发出以下 SQL：\nREPLACE INTO Tickets64 (stub) VALUES (\u0026#39;a\u0026#39;); SELECT LAST_INSERT_ID(); 对于两台数据库服务器，分别设置表的自增值（auto_increment_increment）和偏移值（auto_increment_offset）。\nTicketServer1: auto_increment_increment = 2 auto_increment_offset = 1 TicketServer2: auto_increment_increment = 2 auto_increment_offset = 2 举例：一个数据库服务器设置：自增值为 2，起始值为 1，生成的 ID 为奇数。\nSET auto_increment_increment=2; SET auto_increment_offset=1; drop table Tickets64; CREATE TABLE `Tickets64` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default \u0026#39;\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ); SELECT AUTO_INCREMENT FROM information_schema.tables WHERE table_name=\u0026#34;Tickets64\u0026#34;; REPLACE INTO Tickets64 (stub) VALUES (\u0026#39;a\u0026#39;); SELECT LAST_INSERT_ID(); 另一个数据库服务器如何设置？：自增值为 2，起始值为 2，生成的 ID 为偶数。\nSET auto_increment_increment=2; SET auto_increment_offset=2; drop table Tickets64; CREATE TABLE `Tickets64` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default \u0026#39;\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ); SELECT AUTO_INCREMENT FROM information_schema.tables WHERE table_name=\u0026#34;Tickets64\u0026#34;; REPLACE INTO Tickets64 (stub) VALUES (\u0026#39;a\u0026#39;); SELECT LAST_INSERT_ID(); 这个方法跟单台数据库比，缺点是 ID 不是严格递增的，只是粗略递增的。不过这个问题不大，我们的目标是粗略有序，不需要严格递增。\nSnowflake算法 Twitter 开源的 Snowflake 算法。Snowflake是一种经典的分布式ID生成算法，由Twitter开发。它将64位的ID划分为不同的部分，包括时间戳、数据中心ID、机器ID和序列号。通过在不同的部分分配不同的位数，可以在分布式环境中生成唯一的ID，并且保证了ID的时间粗略有序性。\nInstagram 用了类似的方案，41 位表示时间戳，13 位表示 shard Id（一个shard Id对应一台PostgreSQL机器），最低10位表示自增 ID。这个方案用一个 PostgreSQL 集群代替了 Twitter Snowflake 集群，优点是利用了现成的 PostgreSQL。\n使用分布式锁 可以使用分布式锁来保证在生成 ID 时的互斥性，从而保证 ID 的有序性。可以使用一些分布式锁的实现，如 ZooKeeper、Redis 等，来协调各个节点的 ID 生成过程。每个节点在生成 ID 之前，首先获取分布式锁，然后按照一定规则生成 ID，释放锁后，下一个节点再获取锁生成ID。\n下面是一个基本的使用 ZooKeeper 锁生成分布式 ID 的示例：\n创建ZooKeeper客户端连接： CuratorFramework client = CuratorFrameworkFactory.newClient(\u0026#34;localhost:2181\u0026#34;, new ExponentialBackoffRetry(1000, 3)); client.start(); 创建分布式锁： InterProcessMutex lock = new InterProcessMutex(client, \u0026#34;/id_lock\u0026#34;); 获取锁并生成ID： int timeoutSeconds = 10; // 设置锁超时时间为10秒 try { if (lock.acquire(timeoutSeconds, TimeUnit.SECONDS)) { // 成功获取锁 String distributedID = generateID(); // 使用生成的ID进行业务操作 // ... } else { // 未能在超时时间内获取到锁，进行相应处理 // ... } } catch (Exception e) { // 处理异常 } finally { try { lock.release(); // 释放锁 } catch (Exception e) { // 处理异常 } } 在这个示例中，使用 Curator 框架创建了一个 ZooKeeper 客户端连接，然后创建了一个 InterProcessMutex 对象，该对象表示一个分布式锁。在获取锁之前，节点会尝试获取并持有该锁。只有一个节点可以成功获取到锁，其他节点会阻塞等待。\n获取到锁后，可以执行生成 ID 的逻辑，生成唯一的分布式 ID。\n在业务操作完成后，通过 release()方法释放锁，使其他节点可以继续获取锁并生成 ID。\n通过使用 ZooKeeper 锁，我们可以确保在分布式环境下生成的 ID 是互斥的，并且按照获取锁的顺序生成。这样可以保证生成的 ID 是有序的，并且避免了并发冲突的问题。\nRedis 本身并没有提供原生的分布式锁功能，但可以借助 Redis 的原子性操作和过期时间来实现一个简单的分布式锁，并在获取锁时生成分布式 ID。下面是一个使用 Redis 锁生成分布式 ID 的示例代码：\nimport redis.clients.jedis.Jedis; public class DistributedIdGenerator { private static final String LOCK_KEY = \u0026#34;id_lock\u0026#34;; private static final int LOCK_EXPIRATION = 10; // 锁的过期时间，单位为秒 private static final String REDIS_HOST = \u0026#34;localhost\u0026#34;; private static final int REDIS_PORT = 6379; private Jedis jedis; public DistributedIdGenerator() { jedis = new Jedis(REDIS_HOST, REDIS_PORT); } public String generateDistributedId() { // 获取分布式锁 boolean lockAcquired = acquireLock(LOCK_KEY, LOCK_EXPIRATION); if (lockAcquired) { try { // 生成ID的逻辑 String distributedId = generateId(); // 使用生成的ID进行业务操作 // ... return distributedId; } finally { // 释放分布式锁 releaseLock(LOCK_KEY); } } else { // 未能获取到分布式锁，进行相应处理 // ... return null; } } private boolean acquireLock(String lockKey, int expiration) { String result = jedis.set(lockKey, \u0026#34;locked\u0026#34;, \u0026#34;NX\u0026#34;, \u0026#34;EX\u0026#34;, expiration); return \u0026#34;OK\u0026#34;.equals(result); } private void releaseLock(String lockKey) { jedis.del(lockKey); } private String generateId() { // 生成ID的逻辑 // ... return \u0026#34;your_generated_id\u0026#34;; } } 在上述示例代码中，我们使用 Jedis 客户端连接 Redis，并定义了获取锁和释放锁的方法 acquireLock() 和 releaseLock()。在 generateDistributedId() 方法中，我们首先尝试获取分布式锁，如果成功获取到锁，则执行生成 ID 的逻辑和业务操作，并在最后释放锁。如果无法获取到锁，则可以根据实际需求进行相应处理。\n请注意，上述示例代码是一个简单的实现，仅供参考。在实际使用中，还需要考虑异常处理、分布式锁的可重入性、处理锁超时等情况，以及根据具体的需求和系统架构进行适当的调整。\n参考资料 Sharding \u0026amp; IDs at Instagram Ticket Servers: Distributed Unique Primary Keys on the Cheap Twitter Snowflake 细聊分布式ID生成方法 - 沈剑 服务化框架－分布式Unique ID的生成方法一览 - 江南白衣 生成全局唯一ID的3个思路，来自一个资深架构师的总结 分布式ID中的SnowFlake ","permalink":"https://blog.chensoul.cc/posts/2023/12/05/distributed-id-generator/","summary":"很多业务有生成唯一 ID 并作为数据库主键的需求。数据库会在这个字段上建立聚集索引（参考 MySQL InnoDB），即该字段会影响各条数据再物理存储上的顺序。\nID还要尽可能短，节省内存，让数据库索引效率更高。基本上64位整数能够满足绝大多数的场景，但是如果能做到比64位更短那就更好了。需要根据具体业务进行分析，预估出ID的最大值，这个最大值通常比64位整数的上限小很多，于是我们可以用更少的bit表示这个ID。\n查询的时候，往往有分页或者排序的需求，所以需要给每条数据添加一个时间字段，并在其上建立普通索引(Secondary Index)。但是普通索引的访问效率比聚集索引慢，如果能够让ID按照时间粗略有序，则可以省去这个时间字段。为什么不是按照时间精确有序呢？因为按照时间精确有序是做不到的，除非用一个单机算法，在分布式场景下做到精确有序性能一般很差。\n这就引出了 ID 生成的三大核心需求：\n全局唯一 按照时间粗略有序 尽可能短 下面介绍一些常用的生成 ID 的方法。\nUUID UUID 是一类算法的统称，具体有不同的实现。UUID 的优点是每台机器可以独立产生 ID，理论上保证不会重复，所以天然是分布式的；缺点是生成的 ID 太长，不仅占用内存，而且索引查询效率低。\nMongoDB 的 ObjectId 使用的就是 UUID 算法。生成的 ObjectId 占 12 个字节，由以下几个部分组成，\n4 个字节表示的 Unix timestamp 3 个字节表示的机器的 ID 2 个字节表示的进程 ID 3 个字节表示的计数器 使用数据库 可以使用数据库中的自增主键来生成ID。将ID生成的过程交给数据库管理，每个节点向数据库插入记录时，数据库会自动分配一个唯一的ID。通过使用数据库的自动递增功能，可以保证ID的唯一性和粗略有序性。\n在分布式环境下，可以使用多台数据库协同工作生成 ID。假设用 8 台MySQL服务器协同工作，第一台 MySQL 初始值是 1，每次自增 8，第二台 MySQL 初始值是 2，每次自增 8，依次类推。在数据库前面添加一个负载均衡，每来一个请求，由负载均衡随机地将请求发给 8 台 MySQL 中的任意一个，然后返回一个ID。\nFlickr就是这么做的，仅仅使用了两台 MySQL 服务器。可见这个方法虽然简单无脑，但是性能足够好。不过要注意，在 MySQL 中，不需要把所有 ID 都存下来，每台机器只需要存一个 MAX_ID 就可以了。这需要用到 MySQL 的一个 REPLACE INTO 特性。\nFlickr 的实现方式如下。\nTickets64 表结构如下：\nCREATE TABLE `Tickets64` ( `id` bigint(20) unsigned NOT NULL auto_increment, `stub` char(1) NOT NULL default \u0026#39;\u0026#39;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`) ) ENGINE=InnoDB SELECT * from Tickets64 返回一行，如下所示：","title":"如何设计一个分布式ID生成器保证ID按时间有序？"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Dropbox》设计 Dropbox。\nLet’s design a file hosting service like Dropbox or Google Drive. Cloud file storage enables users to store their data on remote servers. Usually, these servers are maintained by cloud storage providers and made available to users over a network (typically through the Internet). Users pay for their cloud data storage on a monthly basis. Similar Services: OneDrive, Google Drive Difficulty Level: Medium\n让我们设计一个文件托管服务，例如 Dropbox 或 Google Drive。云文件存储使用户能够将数据存储在远程服务器上。通常，这些服务器由云存储提供商维护，并通过网络（通常通过互联网）提供给用户。用户按月支付云数据存储费用。类似服务：OneDrive、Google Drive 难度级别：中\n1. Why Cloud Storage? 为什么选择云存储？ Cloud file storage services have become very popular recently as they simplify the storage and exchange of digital resources among multiple devices. The shift from using single personal computers to using multiple devices with different platforms and operating systems such as smartphones and tablets each with portable access from various geographical locations at any time, is believed to be accountable for the huge popularity of cloud storage services. Following are some of the top benefits of such services:\n云文件存储服务最近变得非常流行，因为它们简化了多个设备之间数字资源的存储和交换。从使用单一个人电脑到使用具有不同平台和操作系统的多个设备（例如智能手机和平板电脑）的转变，每个设备都可以随时从不同地理位置进行便携式访问，这被认为是云存储服务如此普及的原因。以下是此类服务的一些主要好处：\nAvailability: The motto of cloud storage services is to have data availability anywhere, anytime. Users can access their files/photos from any device whenever and wherever they like.\n可用性：云存储服务的座右铭是随时随地提供数据可用性。用户可以随时随地从任何设备访问他们的文件/照片。\nReliability and Durability: Another benefit of cloud storage is that it offers 100% reliability and durability of data. Cloud storage ensures that users will never lose their data by keeping multiple copies of the data stored on different geographically located servers.\n可靠性和持久性：云存储的另一个好处是它提供 100% 的数据可靠性和持久性。云存储通过将数据的多个副本存储在不同地理位置的服务器上，确保用户永远不会丢失数据。\nScalability: Users will never have to worry about getting out of storage space. With cloud storage you have unlimited storage as long as you are ready to pay for it.\n可扩展性：用户永远不必担心存储空间不足。使用云存储，只要您准备好付费，您就可以拥有无​​限的存储空间。\nIf you haven’t used dropbox.com before, we would highly recommend creating an account there and uploading/editing a file and also going through the different options their service offers. This will help you a lot in understanding this chapter.\n如果您以前没有使用过 dropbox.com，我们强烈建议您在那里创建一个帐户并上传/编辑文件，并查看他们的服务提供的不同选项。这将对你理解本章有很大帮助。\n2. Requirements and Goals of the System 系统的要求和目标 You should always clarify requirements at the beginning of the interview. Be sure to ask questions to find the exact scope of the system that the interviewer has in mind.\n您应该始终在面试开始时澄清要求。一定要通过提问来找到面试官心目中系统的确切范围。\nWhat do we wish to achieve from a Cloud Storage system? Here are the top-level requirements for our system:\n我们希望通过云存储系统实现什么目标？以下是我们系统的顶级要求：\nUsers should be able to upload and download their files/photos from any device.\n用户应该能够从任何设备上传和下载文件/照片。\nUsers should be able to share files or folders with other users.\n用户应该能够与其他用户共享文件或文件夹。\nOur service should support automatic synchronization between devices, i.e., after updating a file on one device, it should get synchronized on all devices.\n我们的服务应该支持设备之间的自动同步，即更新文件后在一台设备上，它应该在所有设备上同步。\nThe system should support storing large files up to a GB.\n系统应支持存储高达 1 GB 的大文件。\nACID-ity is required. Atomicity, Consistency, Isolation and Durability of all file operations should be guaranteed. 需要ACID。所有文件操作的原子性、一致性、隔离性和持久性应该得到保证。\nOur system should support offline editing. Users should be able to add/delete/modify files while offline, and as soon as they come online, all their changes should be synced to the remote servers and other online devices.\n我们的系统应该支持离线编辑。用户应该能够添加/删除/修改文件离线，一旦上线，所有更改都应同步到远程服务器和其他在线设备。\nExtended Requirements\n扩展要求\nThe system should support snapshotting of the data, so that users can go back to any version of the files. 系统应支持数据快照，以便用户可以返回到文件的任何版本。\n3. Some Design Considerations 一些设计考虑 We should expect huge read and write volumes.\n我们应该期待巨大的读写量。\nRead to write ratio is expected to be nearly the same.\n预计读写比率几乎相同。\nInternally, files can be stored in small parts or chunks (say 4MB); this can provide a lot of benefits i.e. all failed operations shall only be retried for smaller parts of a file. If a user fails to upload a file, then only the failing chunk will be retried.\n在内部，文件可以以小部分或块的形式存储（例如 4MB）；这可以提供很多好处是，所有失败的操作只能针对文件的较小部分重试。如果用户未能上传文件，则仅重试失败的块。\nWe can reduce the amount of data exchange by transferring updated chunks only.\n我们可以通过仅传输更新的块来减少数据交换量。\nBy removing duplicate chunks, we can save storage space and bandwidth usage.\n通过删除重复的块，我们可以节省存储空间和带宽使用。\nKeeping a local copy of the metadata (file name, size, etc.) with the client can save us a lot of round trips to the server.\n与客户端保存元数据（文件名、大小等）的本地副本可以为我们节省大量时间到服务器的往返。\nFor small changes, clients can intelligently upload the diffs instead of the whole chunk.\n对于小的更改，客户端可以智能地上传差异而不是整个块。\n4. Capacity Estimation and Constraints 容量估计和约束 Let’s assume that we have 500M total users, and 100M daily active users (DAU).\n假设我们的总用户数为 5 亿，每日活跃用户 (DAU) 为 1 亿。\nLet’s assume that on average each user connects from three different devices.\n我们假设平均每个用户从三个不同的设备进行连接。\nOn average if a user has 200 files/photos, we will have 100 billion total files.\n平均来说，如果一个用户有 200 个文件/照片，那么我们将拥有 1000 亿个文件总数。\nLet’s assume that average file size is 100KB, this would give us ten petabytes of total storage.\n假设平均文件大小为 100KB，这将为我们提供 10PB 的总存储空间。\n100B * 100KB =\u0026gt; 10PB\nLet’s also assume that we will have one million active connections per minute.\n我们还假设每分钟有 100 万个活动连接。\n5. High Level Design 高层设计 The user will specify a folder as the workspace on their device. Any file/photo/folder placed in this folder will be uploaded to the cloud, and whenever a file is modified or deleted, it will be reflected in the same way in the cloud storage. The user can specify similar workspaces on all their devices and any modification done on one device will be propagated to all other devices to have the same view of the workspace everywhere.\n用户将指定一个文件夹作为其设备上的工作区。放置在此文件夹中的任何文件/照片/文件夹都将上传到云端，并且每当修改或删除文件时，都会以相同的方式反映在云存储中。用户可以在其所有设备上指定类似的工作区，并且在一台设备上完成的任何修改都将传播到所有其他设备，以便在任何地方都具有相同的工作区视图。\nAt a high level, we need to store files and their metadata information like File Name, File Size, Directory, etc., and who this file is shared with. So, we need some servers that can help the clients to upload/download files to Cloud Storage and some servers that can facilitate updating metadata about files and users. We also need some mechanism to notify all clients whenever an update happens so they can synchronize their files.\n在较高层面上，我们需要存储文件及其元数据信息，例如文件名、文件大小、目录等，以及与谁共享该文件。因此，我们需要一些可以帮助客户端上传/下载文件到云存储的服务器，以及一些可以帮助更新有关文件和用户的元数据的服务器。我们还需要某种机制来在发生更新时通知所有客户端，以便他们可以同步其文件。\nAs shown in the diagram below, Block servers will work with the clients to upload/download files from cloud storage and Metadata servers will keep metadata of files updated in a SQL or NoSQL database. Synchronization servers will handle the workflow of notifying all clients about different changes for synchronization.\n如下图所示，块服务器将与客户端一起从云存储上传/下载文件，元数据服务器将在 SQL 或 NoSQL 数据库中更新文件的元数据。同步服务器将处理通知所有客户端有关同步的不同更改的工作流程。\nHigh level design for Dropbox\nDropbox 的高级设计\n6. Component Design 组件设计 Let’s go through the major components of our system one by one:\n让我们一一浏览一下我们系统的主要组件：\na. Client\na. 客户端\nThe Client Application monitors the workspace folder on the user’s machine and syncs all files/folders in it with the remote Cloud Storage. The client application will work with the storage servers to upload, download, and modify actual files to backend Cloud Storage. The client also interacts with the remote\n客户端应用程序监视用户计算机上的工作区文件夹，并将其中的所有文件/文件夹与远程云存储同步。客户端应用程序将与存储服务器配合，将实际文件上传、下载和修改到后端云存储。客户端还与远程进行交互\nSynchronization Service to handle any file metadata updates, e.g., change in the file name, size, modification date, etc.\n同步服务处理任何文件元数据更新，例如文件名、大小、修改日期等的更改。\nHere are some of the essential operations for the client:\n以下是客户的一些基本操作：\nUpload and download files.\n上传和下载文件。\nDetect file changes in the workspace folder.\n检测工作区文件夹中的文件更改。\nHandle conflict due to offline or concurrent updates.\n处理由于离线或并发更新而导致的冲突。\nHow do we handle file transfer efficiently? As mentioned above, we can break each file into smaller chunks so that we transfer only those chunks that are modified and not the whole file. Let’s say we divide each file into fixed sizes of 4MB chunks. We can statically calculate what could be an optimal chunk size based on 1) Storage devices we use in the cloud to optimize space utilization and input/output operations per second (IOPS) 2) Network bandwidth 3) Average file size in the storage etc. In our metadata, we should also keep a record of each file and the chunks that constitute it.\n我们如何有效地处理文件传输？如上所述，我们可以将每个文件分成更小的块，以便我们只传输那些被修改的块，而不是整个文件。假设我们将每个文件划分为固定大小的 4MB 块。我们可以根据 1) 我们在云中使用的存储设备来静态计算最佳块大小，以优化空间利用率和每秒输入/输出操作 (IOPS) 2) 网络带宽 3) 存储中的平均文件大小等。在我们的元数据中，我们还应该保留每个文件及其构成块的记录。\nShould we keep a copy of metadata with Client? Keeping a local copy of metadata not only enable us to do offline updates but also saves a lot of round trips to update remote metadata.\n我们应该与客户保留一份元数据副本吗？保留元数据的本地副本不仅使我们能够进行离线更新，而且还节省了更新远程元数据的大量往返次数。\nHow can clients efficiently listen to changes happening with other clients? One solution could be that the clients periodically check with the server if there are any changes. The problem with this approach is that we will have a delay in reflecting changes locally as clients will be checking for changes periodically compared to a server notifying whenever there is some change. If the client frequently checks the server for changes, it will not only be wasting bandwidth, as the server has to return an empty response most of the time, but will also be keeping the server busy. Pulling information in this manner is not scalable.\n客户如何有效地倾听其他客户发生的变化？一种解决方案是客户端定期检查服务器是否有任何更改。这种方法的问题在于，我们在本地反映更改时会出现延迟，因为与服务器在发生更改时通知服务器相比，客户端将定期检查更改。如果客户端频繁检查服务器是否有更改，则不仅会浪费带宽（因为服务器大多数时候必须返回空响应），而且还会使服务器保持忙碌。以这种方式拉取信息是不可扩展的。\nA solution to the above problem could be to use HTTP long polling. With long polling the client requests information from the server with the expectation that the server may not respond immediately. If the server has no new data for the client when the poll is received, instead of sending an empty response, the server holds the request open and waits for response information to become available. Once it does have new information, the server immediately sends an HTTP/S response to the client, completing the open HTTP/S Request. Upon receipt of the server response, the client can immediately issue another server request for future updates.\n解决上述问题的方法可能是使用 HTTP 长轮询。通过长轮询，客户端向服务器请求信息，并期望服务器可能不会立即响应。如果服务器在收到轮询时没有为客户端提供新数据，则服务器不会发送空响应，而是保持请求打开并等待响应信息可用。一旦有新信息，服务器立即向客户端发送 HTTP/S 响应，完成打开的 HTTP/S 请求。收到服务器响应后，客户端可以立即发出另一个服务器请求以进行将来的更新。\nBased on the above considerations, we can divide our client into following four parts:\n基于以上考虑，我们可以将客户分为以下四个部分：\nI. Internal Metadata Database will keep track of all the files, chunks, their versions, and their location in the file system.\n内部元数据数据库将跟踪所有文件、块、它们的版本以及它们在文件系统中的位置。 II. Chunker will split the files into smaller pieces called chunks. It will also be responsible for reconstructing a file from its chunks. Our chunking algorithm will detect the parts of the files that have been modified by the user and only transfer those parts to the Cloud Storage; this will save us bandwidth and synchronization time.\nChunker 会将文件分割成更小的块，称为块。它还将负责从文件块中重建文件。我们的分块算法将检测文件中已被用户修改的部分，并仅将这些部分传输到云存储；这将为我们节省带宽和同步时间。 III. Watcher will monitor the local workspace folders and notify the Indexer (discussed below) of any action performed by the users, e.g. when users create, delete, or update files or folders. Watcher also listens to any changes happening on other clients that are broadcasted by Synchronization service.\n观察者将监视本地工作区文件夹并通知索引器（如下所述）用户执行的任何操作，例如当用户创建、删除或更新文件或文件夹时。观察者还侦听同步服务广播的其他客户端上发生的任何更改。 IV. Indexer will process the events received from the Watcher and update the internal metadata database with information about the chunks of the modified files. Once the chunks are successfully submitted/downloaded to the Cloud Storage, the Indexer will communicate with the remote Synchronization Service to broadcast changes to other clients and update remote metadata database.\n索引器将处理从观察器接收到的事件，并使用有关已修改文件块的信息更新内部元数据数据库。一旦块成功提交/下载到云存储，索引器将与远程同步服务通信，以将更改广播到其他客户端并更新远程元数据数据库。 How should clients handle slow servers? Clients should exponentially back-off if the server is busy/not-responding. Meaning, if a server is too slow to respond, clients should delay their retries and this delay should increase exponentially.\n客户端应该如何处理缓慢的服务器？如果服务器繁忙/无响应，客户端应呈指数级后退。这意味着，如果服务器响应速度太慢，客户端应该延迟重试，并且这种延迟应该呈指数级增长。\nShould mobile clients sync remote changes immediately? Unlike desktop or web clients, mobile clients usually sync on demand to save user’s bandwidth and space.\n移动客户端是否应该立即同步远程更改？与桌面或 Web 客户端不同，移动客户端通常按需同步以节省用户的带宽和空间。\nb. Metadata Database\nb.元数据数据库\nThe Metadata Database is responsible for maintaining the versioning and metadata information about files/chunks, users, and workspaces. The Metadata Database can be a relational database such as MySQL, or a NoSQL database service such as DynamoDB. Regardless of the type of the database, the Synchronization Service should be able to provide a consistent view of the files using a database, especially if more than one user is working with the same file simultaneously. Since NoSQL data stores do not support ACID properties in favor of scalability and performance, we need to incorporate the support for ACID properties programmatically in the logic of our Synchronization Service in case we\n元数据数据库负责维护有关文件/块、用户和工作区的版本控制和元数据信息。元数据数据库可以是关系数据库（例如 MySQL），也可以是 NoSQL 数据库服务（例如 DynamoDB）。无论数据库的类型如何，同步服务都应该能够使用数据库提供一致的文件视图，特别是当多个用户同时使用同一文件时。由于 NoSQL 数据存储不支持 ACID 属性以支持可扩展性和性能，因此我们需要以编程方式将对 ACID 属性的支持合并到同步服务的逻辑中，以防万一\nopt for this kind of database. However, using a relational database can simplify the implementation of the Synchronization Service as they natively support ACID properties.\n选择这种数据库。但是，使用关系数据库可以简化同步服务的实现，因为它们本身支持 ACID 属性。\nThe metadata Database should be storing information about following objects:\n元数据数据库应存储有关以下对象的信息：\nChunks\n块\nFiles\n文件\nUser\n用户\nDevices\n设备\nWorkspace (sync folders)\n工作区（同步文件夹）\nc. Synchronization Service\nc. 同步服务\nThe Synchronization Service is the component that processes file updates made by a client and applies these changes to other subscribed clients. It also synchronizes clients’ local databases with the information stored in the remote Metadata DB. The Synchronization Service is the most important part of the system architecture due to its critical role in managing the metadata and synchronizing users’ files. Desktop clients communicate with the Synchronization Service to either obtain updates from the Cloud Storage or send files and updates to the Cloud Storage and, potentially, other users. If a client was offline for a period, it polls the system for new updates as soon as they come online. When the Synchronization Service receives an update request, it checks with the Metadata Database for consistency and then proceeds with the update. Subsequently, a notification is sent to all subscribed users or devices to report the file update.\n同步服务是处理客户端进行的文件更新并将这些更改应用到其他订阅客户端的组件。它还将客户端的本地数据库与远程元数据数据库中存储的信息同步。同步服务是系统架构中最重要的部分，因为它在管理元数据和同步用户文件方面发挥着关键作用。桌面客户端与同步服务进行通信，以从云存储获取更新，或将文件和更新发送到云存储以及可能的其他用户。如果客户端离线一段时间，它会在新更新上线后立即轮询系统以获取新更新。当同步服务收到更新请求时，它会检查元数据数据库的一致性，然后继续更新。随后，向所有订阅的用户或设备发送通知以报告文件更新。\nThe Synchronization Service should be designed in such a way that it transmits less data between clients and the Cloud Storage to achieve a better response time. To meet this design goal, the Synchronization Service can employ a differencing algorithm to reduce the amount of the data that needs to be synchronized. Instead of transmitting entire files from clients to the server or vice versa, we can just transmit the difference between two versions of a file. Therefore, only the part of the file that has been changed is transmitted. This also decreases bandwidth consumption and cloud data storage for the end user. As described above, we will be dividing our files into 4MB chunks and will be transferring modified chunks only. Server and clients can calculate a hash (e.g., SHA-256) to see whether to update the local copy of a chunk or not. On the server, if we already have a chunk with a similar hash (even from another user), we don’t need to create another copy, we can use the same chunk. This is discussed in detail later under Data Deduplication.\n同步服务的设计方式应使其在客户端和云存储之间传输更少的数据，以实现更好的响应时间。为了实现这一设计目标，同步服务可以采用差分算法来减少需要同步的数据量。我们可以只传输文件的两个版本之间的差异，而不是将整个文件从客户端传输到服务器，反之亦然。因此，仅传输文件中已更改的部分。这也减少了最终用户的带宽消耗和云数据存储。如上所述，我们将把文件分成 4MB 的块，并且仅传输修改后的块。服务器和客户端可以计算哈希值（例如 SHA-256）来查看是否更新块的本地副本。在服务器上，如果我们已经有一个具有相似哈希值的块（甚至来自另一个用户），我们不需要创建另一个副本，我们可以使用相同的块。稍后将在重复数据删除中详细讨论这一点。\nTo be able to provide an efficient and scalable synchronization protocol we can consider using a communication middleware between clients and the Synchronization Service. The messaging middleware should provide scalable message queuing and change notifications to support a high number of clients using pull or push strategies. This way, multiple Synchronization Service instances can receive requests from a global request Queue, and the communication middleware will be able to balance its load.\n为了能够提供高效且可扩展的同步协议，我们可以考虑在客户端和同步服务之间使用通信中间件。消息中间件应提供可扩展的消息队列和更改通知，以支持使用拉或推策略的大量客户端。这样，多个同步服务实例就可以从全局请求队列接收请求，并且通信中间件将能够平衡其负载。\nd. Message Queuing Service\nd.消息队列服务\nAn important part of our architecture is a messaging middleware that should be able to handle a substantial number of requests. A scalable Message Queuing Service that supports asynchronous message-based communication between clients and the Synchronization Service best fits the requirements of our application. The Message Queuing Service supports asynchronous and loosely coupled message-based communication between distributed components of the system. The Message Queuing Service should be able to efficiently store any number of messages in a highly available, reliable and scalable queue.\n我们架构的一个重要部分是消息传递中间件，它应该能够处理大量请求。支持客户端和同步服务之间基于异步消息的通信的可扩展消息队列服务最适合我们的应用程序的要求。消息队列服务支持系统的分布式组件之间的异步且松散耦合的基于消息的通信。消息队列服务应该能够在高度可用、可靠和可扩展的队列中有效地存储任意数量的消息。\nThe Message Queuing Service will implement two types of queues in our system. The Request Queue is a global queue and all clients will share it. Clients’ requests to update the Metadata Database will be sent to the Request Queue first, from there the Synchronization Service will take it to update metadata. The Response Queues that correspond to individual subscribed clients are responsible for delivering the update messages to each client. Since a message will be deleted from the queue once received by a client, we need to create separate Response Queues for each subscribed client to share update messages.\n消息队列服务将在我们的系统中实现两种类型的队列。请求队列是一个全局队列，所有客户端都会共享它。客户端更新元数据数据库的请求将首先发送到请求队列，同步服务将从那里接收它来更新元数据。与各个订阅客户端相对应的响应队列负责将更新消息传递给每个客户端。由于消息一旦被客户端接收到就会从队列中删除，因此我们需要为每个订阅的客户端创建单独的响应队列以共享更新消息。\ne. Cloud/Block Storage\ne.云/块存储\nCloud/Block Storage stores chunks of files uploaded by the users. Clients directly interact with the storage to send and receive objects from it. Separation of the metadata from storage enables us to use any storage either in the cloud or in-house.\n云/块存储存储用户上传的文件块。客户端直接与存储交互以发送和接收对象。将元数据与存储分离使我们能够使用云中或内部的任何存储。\nDetailed component design for Dropbox\nDropbox 的详细组件设计\n7. File Processing Workflow 文件处理工作流程 The sequence below shows the interaction between the components of the application in a scenario when Client A updates a file that is shared with Client B and C, so they should receive the update too. If the other clients are not online at the time of the update, the Message Queuing Service keeps the update notifications in separate response queues for them until they come online later.\n下面的序列显示了当客户端 A 更新与客户端 B 和 C 共享的文件时应用程序组件之间的交互，因此它们也应该收到更新。如果其他客户端在更新时未联机，则消息队列服务会将更新通知保留在单独的响应队列中，直到它们稍后联机。\nClient A uploads chunks to cloud storage.\n客户端A将块上传到云存储。\nClient A updates metadata and commits changes.\n客户端 A 更新元数据并提交更改。\nClient A gets confirmation and notifications are sent to Clients B and C about the changes. 4. Client B and C receive metadata changes and download updated chunks.\n客户 A 获得确认，并向客户 B 和 C 发送有关更改的通知。 4. 客户端 B 和 C 接收元数据更改并下载更新的块。\n8. Data Deduplication 重复数据删除 Data deduplication is a technique used for eliminating duplicate copies of data to improve storage utilization. It can also be applied to network data transfers to reduce the number of bytes that must be sent. For each new incoming chunk, we can calculate a hash of it and compare that hash with all the hashes of the existing chunks to see if we already have the same chunk present in our storage.\n重复数据删除是一种用于消除数据重复副本以提高存储利用率的技术。它还可以应用于网络数据传输，以减少必须发送的字节数。对于每个新传入的块，我们可以计算它的哈希值，并将该哈希值与现有块的所有哈希值进行比较，以查看存储中是否已经存在相同的块。\nWe can implement deduplication in two ways in our system:\n我们可以在系统中通过两种方式实现重复数据删除：\na. Post-process deduplication\na.后处理重复数据删除\nWith post-process deduplication, new chunks are first stored on the storage device and later some process analyzes the data looking for duplication. The benefit is that clients will not need to wait for the hash calculation or lookup to complete before storing the data, thereby ensuring that there is no degradation in storage performance. Drawbacks of this approach are 1) We will unnecessarily be storing duplicate data, though for a short time, 2) Duplicate data will be transferred consuming bandwidth.\n通过后处理重复数据删除，新的块首先存储在存储设备上，然后一些进程分析数据以查找重复项。这样做的好处是，客户端在存储数据之前不需要等待哈希计算或查找完成，从而确保存储性能不会下降。这种方法的缺点是 1) 我们将不必要地存储重复数据，尽管时间很短，2) 传输重复数据会消耗带宽。\nb. In-line deduplication\nb.在线重复数据删除\nAlternatively, deduplication hash calculations can be done in real-time as the clients are entering data on their device. If our system identifies a chunk that it has already stored, only a reference to the existing chunk will be added in the metadata, rather than a full copy of the chunk. This approach will give us optimal network and storage usage.\n或者，当客户端在其设备上输入数据时，可以实时完成重复数据删除哈希计算。如果我们的系统识别出它已经存储的块，则只会在元数据中添加对现有块的引用，而不是块的完整副本。这种方法将为我们提供最佳的网络和存储利用率。\n9. Metadata Partitioning 元数据分区 To scale out metadata DB, we need to partition it so that it can store information about millions of users and billions of files/chunks. We need to come up with a partitioning scheme that would divide and store our data in different DB servers.\n为了横向扩展元数据数据库，我们需要对其进行分区，以便它可以存储有关数百万用户和数十亿文件/块的信息。我们需要提出一个分区方案，将数据划分并存储在不同的数据库服务器中。\n1. Vertical Partitioning: We can partition our database in such a way that we store tables related to one particular feature on one server. For example, we can store all the user related tables in one database and all files/chunks related tables in another database. Although this approach is straightforward to implement it has some issues:\n垂直分区：我们可以对数据库进行分区，以便在一台服务器上存储与某一特定功能相关的表。例如，我们可以将所有与用户相关的表存储在一个数据库中，并将所有文件/块相关的表存储在另一个数据库中。尽管这种方法实施起来很简单，但也存在一些问题：\nWill we still have scale issues? What if we have trillions of chunks to be stored and our database cannot support storing such a huge number of records? How would we further partition such tables?\n我们还会遇到规模问题吗？如果我们有数万亿个块要存储，而我们的数据库无法支持存储如此大量的记录怎么办？我们如何进一步对这些表进行分区？\nJoining two tables in two separate databases can cause performance and consistency issues. How frequently do we have to join user and file tables?\n连接两个独立数据库中的两个表可能会导致性能和一致性问题。我们需要多久连接一次用户表和文件表？\n2. Range Based Partitioning: What if we store files/chunks in separate partitions based on the first letter of the File Path? In that case, we save all the files starting with the letter ‘A’ in one partition and those that start with the letter ‘B’ into another partition and so on. This approach is called range based partitioning. We can even combine certain less frequently occurring letters into one database partition. We should come up with this partitioning scheme statically so that we can always store/find a file in a predictable manner.\n基于范围的分区：如果我们根据文件路径的第一个字母将文件/块存储在单独的分区中会怎样？在这种情况下，我们将以字母“A”开头的所有文件保存在一个分区中，将所有以字母“B”开头的文件保存到另一个分区中，依此类推。这种方法称为基于范围的分区。我们甚至可以将某些不常出现的字母合并到一个数据库分区中。我们应该静态地提出这个分区方案，以便我们始终可以以可预测的方式存储/查找文件。\nThe main problem with this approach is that it can lead to unbalanced servers. For example, if we decide to put all files starting with the letter ‘E’ into a DB partition, and later we realize that we have too many files that start with the letter ‘E’, to such an extent that we cannot fit them into one DB partition.\n这种方法的主要问题是它可能导致服务器不平衡。例如，如果我们决定将所有以字母“E”开头的文件放入数据库分区，后来我们发现以字母“E”开头的文件太多了，以至于我们无法容纳它们到一个数据库分区。\n3. Hash-Based Partitioning: In this scheme we take a hash of the object we are storing and based on this hash we figure out the DB partition to which this object should go. In our case, we can take the\n3.基于散列的分区：在这个方案中，我们对我们存储的对象进行散列，并根据这个散列，我们计算出该对象应该进入的数据库分区。在我们的例子中，我们可以采取\nhash of the ‘FileID’ of the File object we are storing to determine the partition the file will be stored. Our hashing function will randomly distribute objects into different partitions, e.g., our hashing function can always map any ID to a number between [1…256], and this number would be the partition we will store our object.\n我们要存储的 File 对象的“FileID”的哈希值，以确定文件将存储的分区。我们的哈希函数会将对象随机分配到不同的分区中，例如，我们的哈希函数总是可以将任何 ID 映射到 [1…256] 之间的数字，而这个数字将是我们将存储对象的分区。\nThis approach can still lead to overloaded partitions, which can be solved by using Consistent Hashing.\n这种方法仍然会导致分区过载，这可以通过使用一致性哈希来解决。\n10. Caching 缓存 We can have two kinds of caches in our system. To deal with hot files/chunks we can introduce a cache for Block storage. We can use an off-the-shelf solution like Memcached that can store whole chunks with its respective IDs/Hashes and Block servers before hitting Block storage can quickly check if the cache has desired chunk. Based on clients’ usage pattern we can determine how many cache servers we need. A high-end commercial server can have 144GB of memory; one such server can cache 36K chunks.\n我们的系统中可以有两种缓存。为了处理热文件/块，我们可以引入块存储的缓存。我们可以使用像 Memcached 这样的现成解决方案，它可以存储整个块及其各自的 ID/哈希值，并且块服务器在访问块存储之前可以快速检查缓存是否有所需的块。根据客户的使用模式，我们可以确定需要多少个缓存服务器。高端商用服务器可以有144GB内存；一台这样的服务器可以缓存 36K 块。\nWhich cache replacement policy would best fit our needs? When the cache is full, and we want to replace a chunk with a newer/hotter chunk, how would we choose? Least Recently Used (LRU) can be a reasonable policy for our system. Under this policy, we discard the least recently used chunk first. Load Similarly, we can have a cache for Metadata DB.\n哪种缓存替换策略最适合我们的需求？当缓存已满时，我们想用更新/更热的块替换一个块，我们会如何选择？最近最少使用（LRU）对于我们的系统来说是一个合理的策略。根据这个策略，我们首先丢弃最近最少使用的块。加载 类似地，我们可以为元数据数据库提供缓存。\n11. Load Balancer (LB) 11.负载均衡器（LB）\nWe can add the Load balancing layer at two places in our system: 1) Between Clients and Block servers and 2) Between Clients and Metadata servers. Initially, a simple Round Robin approach can be adopted that distributes incoming requests equally among backend servers. This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is if a server is dead, LB will take it out of the rotation and will stop sending any traffic to it. A problem with Round Robin LB is, it won’t take server load into consideration. If a server is overloaded or slow, the LB will not stop sending new requests to that server. To handle this, a more intelligent LB solution can be placed that periodically queries backend server about their load and adjusts traffic based on that.\n我们可以在系统中的两个位置添加负载平衡层：1）客户端和块服务器之间以及2）客户端和元数据服务器之间。最初，可以采用简单的循环方法，在后端服务器之间平均分配传入请求。该LB实现简单，不会引入任何开销。这种方法的另一个好处是，如果服务器死机，LB 会将其从轮换中删除，并停止向其发送任何流量。循环负载均衡的一个问题是，它不会考虑服务器负载。如果服务器过载或速度缓慢，负载均衡器不会停止向该服务器发送新请求。为了解决这个问题，可以放置更智能的 LB 解决方案，定期查询后端服务器的负载并据此调整流量。\n12. Security, Permissions and File Sharing 安全、权限和文件共享 One of the primary concerns users will have while storing their files in the cloud is the privacy and security of their data, especially since in our system users can share their files with other users or even make them public to share it with everyone. To handle this, we will be storing the permissions of each file in our metadata DB to reflect what files are visible or modifiable by any user.\n用户在云中存储文件时最关心的问题之一是数据的隐私和安全，特别是因为在我们的系统中，用户可以与其他用户共享他们的文件，甚至将它们公开以与所有人共享。为了解决这个问题，我们将在元数据数据库中存储每个文件的权限，以反映哪些文件对任何用户可见或可修改。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/24/designing-dropbox/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Dropbox》设计 Dropbox。\nLet’s design a file hosting service like Dropbox or Google Drive. Cloud file storage enables users to store their data on remote servers. Usually, these servers are maintained by cloud storage providers and made available to users over a network (typically through the Internet). Users pay for their cloud data storage on a monthly basis. Similar Services: OneDrive, Google Drive Difficulty Level: Medium\n让我们设计一个文件托管服务，例如 Dropbox 或 Google Drive。云文件存储使用户能够将数据存储在远程服务器上。通常，这些服务器由云存储提供商维护，并通过网络（通常通过互联网）提供给用户。用户按月支付云数据存储费用。类似服务：OneDrive、Google Drive 难度级别：中\n1. Why Cloud Storage? 为什么选择云存储？ Cloud file storage services have become very popular recently as they simplify the storage and exchange of digital resources among multiple devices.","title":"[译]《Grokking the System Design Interview》设计Dropbox"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Facebook Messenger》设计 Facebook Messenger。\nLet’s design an instant messaging service like Facebook Messenger where users can send text messages to each other through web and mobile interfaces. 让我们设计一个像 Facebook Messenger 这样的即时消息服务，用户可以通过网络和移动界面互相发送短信。\n1. What is Facebook Messenger? 1.什么是 Facebook Messenger？\nFacebook Messenger is a software application which provides text-based instant messaging services to its users. Messenger users can chat with their Facebook friends both from cell-phones and Facebook’s website.\nFacebook Messenger 是一款为其用户提供基于文本的即时消息服务的软件应用程序。 Messenger 用户可以通过手机和 Facebook 网站与 Facebook 好友聊天。\n2. Requirements and Goals of the System 系统的要求和目标 Our Messenger should meet the following requirements:\n我们的 Messenger 应满足以下要求：\nFunctional Requirements:\n功能要求：\nMessenger should support one-on-one conversations between users.\nMessenger 应支持用户之间的一对一对话。\nMessenger should keep track of the online/offline statuses of its users.\nMessenger 应跟踪用户的在线/离线状态。\nMessenger should support persistent storage of chat history.\nMessenger应该支持聊天记录的持久存储。\nNon-functional Requirements:\n非功能性要求：\nUsers should have real-time chat experience with minimum latency.\n用户应该获得延迟最小的实时聊天体验。\nOur system should be highly consistent; users should be able to see the same chat history on all their devices.\n我们的系统应该高度一致；用户应该能够在所有内容上看到相同的聊天记录他们的设备。\nMessenger’s high availability is desirable; we can tolerate lower availability in the interest of consistency.\nMessenger 的高可用性是可取的；为了以下目的，我们可以容忍较低的可用性一致性。\nExtended Requirements:\n扩展要求：\nGroup Chats: Messenger should support multiple people talking to each other in a group.\n群组聊天：Messenger 应支持多人在群组中相互交谈。\nPush notifications: Messenger should be able to notify users of new messages when they are offline.\n推送通知：Messenger 应该能够在用户有新消息时通知他们离线。\n3. Capacity Estimation and Constraints 容量估计和约束 Let’s assume that we have 500 million daily active users and on average each user sends 40 messages daily; this gives us 20 billion messages per day.\n假设我们有 5 亿日活跃用户，平均每个用户每天发送 40 条消息；这每天给我们带来 200 亿条消息。\nStorage Estimation: Let’s assume that on average a message is 100 bytes, so to store all the messages for one day we would need 2TB of storage.\n存储估算：假设一条消息平均为 100 字节，因此要存储一天的所有消息，我们需要 2TB 的存储空间。\n20 billion messages * 100 bytes =\u0026gt; 2 TB/day\n200 亿条消息 * 100 字节 =\u0026gt; 2 TB/天\nTo store five years of chat history, we would need 3.6 petabytes of storage.\n要存储五年的聊天历史记录，我们需要 3.6 PB 的存储空间。\n2 TB * 365 days * 5 years ~= 3.6 PB\nOther than the chat messages, we would also need to store users’ information, messages’ metadata (ID, Timestamp, etc.). Not to mention, the above calculation doesn’t take data compression and replication in consideration.\n除了聊天消息之外，我们还需要存储用户信息、消息元数据（ID、时间戳等）。更不用说，上述计算没有考虑数据压缩和复制。\nBandwidth Estimation: If our service is getting 2TB of data every day, this will give us 25MB of incoming data for each second.\n带宽估计：如果我们的服务每天获取 2TB 的数据，那么每秒将为我们提供 25MB 的传入数据。\n2 TB / 86400 sec ~= 25 MB/s\nSince each incoming message needs to go out to another user, we will need the same amount of bandwidth 25MB/s for both upload and download.\n由于每条传入消息都需要发送给另一个用户，因此我们需要相同的带宽 25MB/s 来进行上传和下载。\nHigh level estimates:\n高水平估计：\nTotal messages 20 billion per day Storage for each day 2TB Storage for 5 years 3.6PB Incomming data 25MB/s Outgoing data 25MB/s\n消息总数 每天 200 亿条 每天存储 2TB 存储 5 年 3.6PB 传入数据 25MB/s 传出数据 25MB/s\n4. High Level Design 高层设计 At a high-level, we will need a chat server that will be the central piece, orchestrating all the communications between users. When a user wants to send a message to another user, they will connect to the chat server and send the message to the server; the server then passes that message to the other user and also stores it in the database.\n在高层，我们需要一个聊天服务器作为核心部分，协调用户之间的所有通信。当一个用户想要向另一个用户发送消息时，他们会连接到聊天服务器并将消息发送到服务器；然后，服务器将该消息传递给其他用户并将其存储在数据库中。\nThe detailed workflow would look like this:\n详细的工作流程如下所示：\nUser-A sends a message to User-B through the chat server.\n用户 A 通过聊天服务器向用户 B 发送消息。\nThe server receives the message and sends an acknowledgment to User-A.\n服务器接收消息并向用户 A 发送确认。\nThe server stores the message in its database and sends the message to User-B.\n服务器将消息存储在其数据库中并将消息发送给用户\nUser-B receives the message and sends the acknowledgment to the server.\n用户B 接收消息并向服务器发送确认。\nThe server notifies User-A that the message has been delivered successfully to User-B.\n服务器通知用户 A 消息已成功传递给用户 B。\n5. Detailed Component Design 详细组件设计 Let’s try to build a simple solution first where everything runs on one server. At the high level our system needs to handle the following use cases:\n让我们首先尝试构建一个简单的解决方案，其中所有内容都在一台服务器上运行。在高层，我们的系统需要处理以下用例：\nReceive incoming messages and deliver outgoing messages.\n接收传入消息并传递传出消息。\nStore and retrieve messages from the database.\n在数据库中存储和检索消息。\nKeep a record of which user is online or has gone offline, and notify all the relevant users about these status changes.\n记录哪些用户在线或离线，并通知所有相关用户这些状态变化。\nLet’s talk about these scenarios one by one:\n我们来一一谈谈这些场景：\na. Messages Handling\na.消息处理\nHow would we efficiently send/receive messages? To send messages, a user needs to connect to the server and post messages for the other users. To get a message from the server, the user has two options:\n我们如何有效地发送/接收消息？要发送消息，用户需要连接到服务器并为其他用户发布消息。要从服务器获取消息，用户有两种选择：\nPull model: Users can periodically ask the server if there are any new messages for them.\nPull模型：用户可以定期向服务器询问是否有新消息。\nPush model: Users can keep a connection open with the server and can depend upon the server to notify them whenever there are new messages.\n推送模型：用户可以与服务器保持开放的连接，并且可以依赖服务器每当有新消息时通知他们。\nIf we go with our first approach, then the server needs to keep track of messages that are still waiting to be delivered, and as soon as the receiving user connects to the server to ask for any new message, the server can return all the pending messages. To minimize latency for the user, they have to check the server quite frequently, and most of the time they will be getting an empty response if there are no pending message. This will waste a lot of resources and does not look like an efficient solution.\n如果我们采用第一种方法，那么服务器需要跟踪仍在等待传递的消息，并且一旦接收用户连接到服务器以请求任何新消息，服务器就可以返回所有待处理的消息消息。为了最大限度地减少用户的延迟，他们必须经常检查服务器，并且大多数时候，如果没有待处理的消息，他们将得到空响应。这会浪费大量资源，而且看起来并不是一个有效的解决方案。\nIf we go with our second approach, where all the active users keep a connection open with the server, then as soon as the server receives a message it can immediately pass the message to the intended user. This way, the server does not need to keep track of the pending messages, and we will have minimum latency, as the messages are delivered instantly on the opened connection.\n如果我们采用第二种方法，即所有活动用户与服务器保持打开的连接，那么一旦服务器收到消息，它就可以立即将消息传递给目标用户。这样，服务器不需要跟踪待处理的消息，并且我们将具有最小的延迟，因为消息是在打开的连接上立即传递的。\nHow will clients maintain an open connection with the server? We can use HTTP Long Polling or WebSockets. In long polling, clients can request information from the server with the expectation that the server may not respond immediately. If the server has no new data for the client when the poll is received, instead of sending an empty response, the server holds the request open and waits for\n客户端如何与服务器保持开放连接？我们可以使用 HTTP 长轮询或 WebSockets。在长轮询中，客户端可以向服务器请求信息，但期望服务器可能不会立即响应。如果服务器在收到轮询时没有为客户端提供新数据，则服务器不会发送空响应，而是保持请求打开并等待\nresponse information to become available. Once it does have new information, the server immediately sends the response to the client, completing the open request. Upon receipt of the server response, the client can immediately issue another server request for future updates. This gives a lot of improvements in latencies, throughputs, and performance. The long polling request can timeout or can receive a disconnect from the server, in that case, the client has to open a new request.\n响应信息变得可用。一旦有新信息，服务器立即将响应发送给客户端，完成打开请求。收到服务器响应后，客户端可以立即发出另一个服务器请求以进行将来的更新。这在延迟、吞吐量和性能方面带来了很大的改进。长轮询请求可能会超时或可能会收到与服务器的断开连接，在这种情况下，客户端必须打开新的请求。\nHow can the server keep track of all the opened connection to redirect messages to the users efficiently? The server can maintain a hash table, where “key” would be the UserID and “value” would be the connection object. So whenever the server receives a message for a user, it looks up that user in the hash table to find the connection object and sends the message on the open request.\n服务器如何跟踪所有打开的连接以有效地将消息重定向到用户？服务器可以维护一个哈希表，其中“key”是用户ID，“value”是连接对象。因此，每当服务器收到用户的消息时，它都会在哈希表中查找该用户以找到连接对象，并根据打开的请求发送消息。\nWhat will happen when the server receives a message for a user who has gone offline? If the receiver has disconnected, the server can notify the sender about the delivery failure. If it is a temporary disconnect, e.g., the receiver’s long-poll request just timed out, then we should expect a reconnect from the user. In that case, we can ask the sender to retry sending the message. This retry could be embedded in the client’s logic so that users don’t have to retype the message. The server can also store the message for a while and retry sending it once the receiver reconnects.\n当服务器收到用户下线的消息时会发生什么？如果接收方已断开连接，服务器可以通知发送方传送失败。如果是临时断开连接，例如接收者的长轮询请求刚刚超时，那么我们应该期望用户重新连接。在这种情况下，我们可以要求发件人重试发送消息。这种重试可以嵌入到客户端的逻辑中，这样用户就不必重新输入消息。服务器还可以将消息存储一段时间，并在接收者重新连接后重试发送。\nHow many chat servers we need? Let’s plan for 500 million connections at any time. Assuming a modern server can handle 50K concurrent connections at any time, we would need 10K such servers.\n我们需要多少个聊天服务器？随时规划5亿连接。假设现代服务器可以随时处理 50K 并发连接，我们将需要 10K 这样的服务器。\nHow do we know which server holds the connection to which user? We can introduce a software load balancer in front of our chat servers; that can map each UserID to a server to redirect the request.\n我们如何知道哪个服务器拥有与哪个用户的连接？我们可以在聊天服务器前面引入一个软件负载均衡器；它可以将每个 UserID 映射到服务器以重定向请求。\nHow should the server process a ‘deliver message’ request? The server needs to do the following things upon receiving a new message: 1) Store the message in the database 2) Send the message to the receiver and 3) Send an acknowledgment to the sender.\n服务器应该如何处理“传递消息”请求？服务器在收到新消息后需要执行以下操作： 1) 将消息存储在数据库中 2) 将消息发送给接收者 3) 向发送者发送确认。\nThe chat server will first find the server that holds the connection for the receiver and pass the message to that server to send it to the receiver. The chat server can then send the acknowledgment to the sender; we don’t need to wait for storing the message in the database (this can happen in the background). Storing the message is discussed in the next section.\n聊天服务器将首先找到为接收者保留连接的服务器，并将消息传递给该服务器以将其发送给接收者。然后聊天服务器可以将确认发送给发送者；我们不需要等待将消息存储在数据库中（这可以在后台发生）。下一节将讨论存储消息。\nHow does the messenger maintain the sequencing of the messages? We can store a timestamp with each message, which is the time the message is received by the server. This will still not ensure correct ordering of messages for clients. The scenario where the server timestamp cannot determine the exact order of messages would look like this:\n消息传递者如何保持消息的顺序？我们可以为每条消息存储一个时间戳，这是服务器接收消息的时间。这仍然不能确保客户端消息的正确排序。服务器时间戳无法确定消息的确切顺序的情况如下所示：\nUser-1 sends a message M1 to the server for User-2.\nUser-1 向 User-2 的服务器发送消息 M1。\nThe server receives M1 at T1.\n服务器在 T1 接收 M1。\nMeanwhile, User-2 sends a message M2 to the server for User-1.\n同时，User-2向User-1的服务器发送消息M2。\nThe server receives the message M2 at T2, such that T2 \u0026gt; T1.\n服务器在T2接收消息M2，使得T2\u0026gt;T1。\nThe server sends message M1 to User-2 and M2 to User-1.\n服务器将消息 M1 发送到 User-2，将 M2 发送到 User-1。\nSo User-1 will see M1 first and then M2, whereas User-2 will see M2 first and then M1.\n因此，用户 1 将首先看到 M1，然后是 M2，而用户 2 将首先看到 M2，然后是 M1。\nTo resolve this, we need to keep a sequence number with every message for each client. This sequence number will determine the exact ordering of messages for EACH user. With this solution both clients will see a different view of the message sequence, but this view will be consistent for them on all devices.\n为了解决这个问题，我们需要为每个客户端的每条消息保留一个序列号。该序列号将确定每个用户的消息的确切顺序。通过此解决方案，两个客户端都将看到消息序列的不同视图，但此视图在所有设备上都将保持一致。\nb. Storing and retrieving the messages from the database\nb.从数据库中存储和检索消息**\nWhenever the chat server receives a new message, it needs to store it in the database. To do so, we have two options:\n每当聊天服务器收到新消息时，都需要将其存储在数据库中。为此，我们有两个选择：\nStart a separate thread, which will work with the database to store the message. 2. Send an asynchronous request to the database to store the message.\n启动一个单独的线程，该线程将与数据库一起存储消息。 2. 向数据库发送异步请求来存储消息。\nWe have to keep certain things in mind while designing our database:\n在设计数据库时，我们必须记住以下几点：\nHow to efficiently work with the database connection pool.\n如何高效地使用数据库连接池。\nHow to retry failed requests.\n如何重试失败的请求。\nWhere to log those requests that failed even after some retries.\n在哪里记录那些重试后仍失败的请求。\nHow to retry these logged requests (that failed after the retry) when all the issues have resolved.\n当所有问题都解决后，如何重试这些记录的请求（重试后失败）。\nWhich storage system we should use? We need to have a database that can support a very high rate of small updates and also fetch a range of records quickly. This is required because we have a huge number of small messages that need to be inserted in the database and, while querying, a user is mostly interested in sequentially accessing the messages.\n我们应该使用哪种存储系统？我们需要一个能够支持非常高的小更新率并且能够快速获取一系列记录的数据库。这是必需的，因为我们有大量的小消息需要插入到数据库中，并且在查询时，用户最感兴趣的是顺序访问这些消息。\nWe cannot use RDBMS like MySQL or NoSQL like MongoDB because we cannot afford to read/write a row from the database every time a user receives/sends a message. This will not only make the basic operations of our service run with high latency, but also create a huge load on databases.\n我们无法使用 MySQL 等 RDBMS 或 MongoDB 等 NoSQL，因为我们无法在用户每次接收/发送消息时从数据库中读取/写入一行。这不仅会使我们服务的基本操作以高延迟运行，还会对数据库造成巨大的负载。\nBoth of our requirements can be easily met with a wide-column database solution like HBase. HBase is a column-oriented key-value NoSQL database that can store multiple values against one key into multiple columns. HBase is modeled after Google’s BigTable and runs on top of Hadoop Distributed File System (HDFS). HBase groups data together to store new data in a memory buffer and, once the buffer is full, it dumps the data to the disk. This way of storage not only helps storing a lot of small data quickly, but also fetching rows by the key or scanning ranges of rows. HBase is also an efficient database to store variably sized data, which is also required by our service.\n像 HBase 这样的宽列数据库解决方案就可以轻松满足我们的这两个要求。 HBase 是一种面向列的键值 NoSQL 数据库，可以将一个键的多个值存储到多个列中。 HBase 仿照 Google 的 BigTable 建模，并在 Hadoop 分布式文件系统 (HDFS) 之上运行。 HBase 将数据分组在一起，将新数据存储在内存缓冲区中，一旦缓冲区已满，它将数据转储到磁盘。这种存储方式不仅有助于快速存储大量小数据，而且还可以通过键或扫描行范围来获取行。 HBase也是一个高效的数据库，可以存储不同大小的数据，这也是我们的服务所需要的。\nHow should clients efficiently fetch data from the server? Clients should paginate while fetching data from the server. Page size could be different for different clients, e.g., cell phones have smaller screens, so we need a fewer number of message/conversations in the viewport.\n客户端应该如何高效地从服务器获取数据？客户端在从服务器获取数据时应该分页。对于不同的客户端，页面大小可能不同，例如，手机的屏幕较小，因此我们在视口中需要较少数量的消息/对话。\nc. Managing user’s status\nc.管理用户状态\nWe need to keep track of user’s online/offline status and notify all the relevant users whenever a status change happens. Since we are maintaining a connection object on the server for all active users, we can easily figure out the user’s current status from this. With 500M active users at any time, if we have to\n我们需要跟踪用户的在线/离线状态，并在状态发生变化时通知所有相关用户。由于我们在服务器上为所有活动用户维护一个连接对象，因此我们可以轻松地从中找出用户的当前状态。任何时候都有 5 亿活跃用户，如果我们必须的话\nbroadcast each status change to all the relevant active users, it will consume a lot of resources. We can do the following optimization around this:\n将每个状态变化广播给所有相关的活跃用户，会消耗大量资源。围绕这一点我们可以做如下优化：\nWhenever a client starts the app, it can pull the current status of all users in their friends’ list.\n每当客户端启动应用程序时，它都可以提取好友列表中所有用户的当前状态。\nWhenever a user sends a message to another user that has gone offline, we can send a failure to the sender and update the status on the client.\n每当一个用户向另一个离线的用户发送消息时，我们可以向发送者并更新客户端上的状态。\nWhenever a user comes online, the server can always broadcast that status with a delay of a few seconds to see if the user does not go offline immediately.\n每当用户上线时，服务器总是可以延迟几秒广播该状态秒查看用户是否没有立即离线。\nClient’s can pull the status from the server about those users that are being shown on the user’s viewport. This should not be a frequent operation, as the server is broadcasting the online status of users and we can live with the stale offline status of users for a while.\n客户端可以从服务器获取有关用户的状态，这些状态显示在用户的视口。这不应该是一个频繁的操作，因为服务器正在广播在线状态用户的离线状态我们可以忍受一段时间。\nWhenever the client starts a new chat with another user, we can pull the status at that time.\n每当客户端与另一个用户开始新的聊天时，我们就可以提取当时的状态。\nDetailed component design for Facebook messenger\nFacebook Messenger 的详细组件设计\nDesign Summary: Clients will open a connection to the chat server to send a message; the server will then pass it to the requested user. All the active users will keep a connection open with the server to receive messages. Whenever a new message arrives, the chat server will push it to the receiving user on the long poll request. Messages can be stored in HBase, which supports quick small updates, and range\n设计总结：客户端会打开一个到聊天服务器的连接来发送消息；然后服务器会将其传递给请求的用户。所有活动用户都将保持与服务器的连接以接收消息。每当有新消息到达时，聊天服务器都会通过长轮询请求将其推送给接收用户。消息可以存储在HBase中，支持快速小更新和范围\nbased searches. The servers can broadcast the online status of a user to other relevant users. Clients can pull status updates for users who are visible in the client’s viewport on a less frequent basis.\n基于搜索。服务器可以向其他相关用户广播用户的在线状态。客户端可以不频繁地为在客户端视口中可见的用户拉取状态更新。\n6. Data partitioning 数据分区 Since we will be storing a lot of data (3.6PB for five years), we need to distribute it onto multiple database servers. What will be our partitioning scheme?\n由于我们将存储大量数据（五年 3.6PB），因此我们需要将其分发到多个数据库服务器上。我们的分区方案是什么？\nPartitioning based on UserID: Let’s assume we partition based on the hash of the UserID so that we can keep all messages of a user on the same database. If one DB shard is 4TB, we will have “3.6PB/4TB ~= 900” shards for five years. For simplicity, let’s assume we keep 1K shards. So we will find the shard number by “hash(UserID) % 1000” and then store/retrieve the data from there. This partitioning scheme will also be very quick to fetch chat history for any user.\n基于 UserID 的分区：假设我们基于 UserID 的哈希进行分区，以便我们可以将用户的所有消息保存在同一个数据库中。如果一个数据库分片是 4TB，那么五年内我们将拥有“3.6PB/4TB ~= 900”个分片。为了简单起见，我们假设我们保留 1K 分片。因此，我们将通过“hash(UserID) % 1000”找到分片编号，然后从那里存储/检索数据。这种分区方案也可以非常快速地获取任何用户的聊天历史记录。\nIn the beginning, we can start with fewer database servers with multiple shards residing on one physical server. Since we can have multiple database instances on a server, we can easily store multiple partitions on a single server. Our hash function needs to understand this logical partitioning scheme so that it can map multiple logical partitions on one physical server.\n一开始，我们可以从较少的数据库服务器开始，在一台物理服务器上驻留多个分片。由于我们可以在一台服务器上拥有多个数据库实例，因此我们可以轻松地在一台服务器上存储多个分区。我们的哈希函数需要理解这种逻辑分区方案，以便它可以在一台物理服务器上映射多个逻辑分区。\nSince we will store an unlimited history of messages, we can start with a big number of logical partitions, which will be mapped to fewer physical servers, and as our storage demand increases, we can add more physical servers to distribute our logical partitions.\n由于我们将存储无限的消息历史记录，因此我们可以从大量逻辑分区开始，这些逻辑分区将映射到更少的物理服务器，并且随着存储需求的增加，我们可以添加更多物理服务器来分布我们的逻辑分区。\nPartitioning based on MessageID: If we store different messages of a user on separate database shards, fetching a range of messages of a chat would be very slow, so we should not adopt this scheme.\n基于MessageID的分区：如果我们将一个用户的不同消息存储在不同的数据库分片上，那么获取一段聊天的一系列消息会非常慢，所以我们不应该采用这种方案。\n7. Cache 缓存 We can cache a few recent messages (say last 15) in a few recent conversations that are visible in a user’s viewport (say last 5). Since we decided to store all of the user’s messages on one shard, cache for a user should entirely reside on one machine too.\n我们可以在用户视口中可见的一些最近对话（例如最后 5 条）中缓存一些最近的消息（例如最后 15 条）。由于我们决定将所有用户的消息存储在一个分片上，因此用户的缓存也应该完全驻留在一台机器上。\n8. Load balancing 8.负载均衡\nWe will need a load balancer in front of our chat servers; that can map each UserID to a server that holds the connection for the user and then direct the request to that server. Similarly, we would need a load balancer for our cache servers.\n我们需要在聊天服务器前面有一个负载均衡器；它可以将每个 UserID 映射到保存用户连接的服务器，然后将请求定向到该服务器。同样，我们的缓存服务器需要一个负载平衡器。\n9. Fault tolerance and Replication 容错和复制 What will happen when a chat server fails? Our chat servers are holding connections with the users. If a server goes down, should we devise a mechanism to transfer those connections to some other server? It’s extremely hard to failover TCP connections to other servers; an easier approach can be to have clients automatically reconnect if the connection is lost.\n当聊天服务器出现故障时会发生什么？我们的聊天服务器与用户保持连接。如果服务器出现故障，我们是否应该设计一种机制将这些连接转移到其他服务器？将 TCP 连接故障转移到其他服务器非常困难；一种更简单的方法是让客户端在连接丢失时自动重新连接。\nShould we store multiple copies of user messages? We cannot have only one copy of the user’s data, because if the server holding the data crashes or is down permanently, we don’t have any mechanism to\n我们应该存储用户消息的多个副本吗？我们不能只有一份用户数据的副本，因为如果保存数据的服务器崩溃或永久关闭，我们没有任何机制可以\nrecover that data. For this, either we have to store multiple copies of the data on different servers or use techniques like Reed-Solomon encoding to distribute and replicate it.\n恢复该数据。为此，我们要么必须在不同的服务器上存储数据的多个副本，要么使用 Reed-Solomon 编码等技术来分发和复制数据。\n10. Extended Requirements 扩展要求 a. Group chat\na.群聊\nWe can have separate group-chat objects in our system that can be stored on the chat servers. A group- chat object is identified by GroupChatID and will also maintain a list of people who are part of that chat. Our load balancer can direct each group chat message based on GroupChatID and the server handling that group chat can iterate through all the users of the chat to find the server handling the connection of each user to deliver the message.\n我们可以在系统中拥有单独的群聊对象，这些对象可以存储在聊天服务器上。群聊对象由 GroupChatID 标识，并且还将维护属于该聊天的人员列表。我们的负载均衡器可以根据 GroupChatID 引导每个群聊消息，并且处理该群聊的服务器可以迭代所有聊天用户，找到处理每个用户连接的服务器来传递消息。\nIn databases, we can store all the group chats in a separate table partitioned based on GroupChatID.\n在数据库中，我们可以将所有群聊存储在一个根据GroupChatID分区的单独表中。\nb. Push notifications\nb.推送通知\nIn our current design user’s can only send messages to active users and if the receiving user is offline, we send a failure to the sending user. Push notifications will enable our system to send messages to offline users.\n在我们当前的设计中，用户只能向活动用户发送消息，如果接收用户离线，我们会向发送用户发送失败消息。推送通知将使我们的系统能够向离线用户发送消息。\nFor Push notifications, each user can opt-in from their device (or a web browser) to get notifications whenever there is a new message or event. Each manufacturer maintains a set of servers that handles pushing these notifications to the user.\n对于推送通知，每个用户都可以选择从他们的设备（或网络浏览器）接收通知，只要有新消息或事件。每个制造商都维护一组服务器来处理将这些通知推送给用户。\nTo have push notifications in our system, we would need to set up a Notification server, which will take the messages for offline users and send them to the manufacture’s push notification server, which will then send them to the user’s device.\n要在我们的系统中添加推送通知，我们需要设置一个通知服务器，该服务器将获取离线用户的消息并将其发送到制造商的推送通知服务器，然后制造商的推送通知服务器将它们发送到用户的设备。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/24/designing-facebook-messenger/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Facebook Messenger》设计 Facebook Messenger。\nLet’s design an instant messaging service like Facebook Messenger where users can send text messages to each other through web and mobile interfaces. 让我们设计一个像 Facebook Messenger 这样的即时消息服务，用户可以通过网络和移动界面互相发送短信。\n1. What is Facebook Messenger? 1.什么是 Facebook Messenger？\nFacebook Messenger is a software application which provides text-based instant messaging services to its users. Messenger users can chat with their Facebook friends both from cell-phones and Facebook’s website.\nFacebook Messenger 是一款为其用户提供基于文本的即时消息服务的软件应用程序。 Messenger 用户可以通过手机和 Facebook 网站与 Facebook 好友聊天。\n2. Requirements and Goals of the System 系统的要求和目标 Our Messenger should meet the following requirements:\n我们的 Messenger 应满足以下要求：\nFunctional Requirements:","title":"[译]《Grokking the System Design Interview》设计Facebook Messenger"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Instagram》设计 Instagram。\nLet’s design a photo-sharing service like Instagram, where users can upload photos to share them with other users. Similar Services: Flickr, Picasa Difficulty Level: Medium\n让我们设计一个像 Instagram 这样的照片共享服务，用户可以上传照片与其他用户共享。类似服务：Flickr、Picasa 难度级别：中\n1. What is Instagram? 1.Instagram是什么？\nInstagram is a social networking service which enables its users to upload and share their photos and videos with other users. Instagram users can choose to share information either publicly or privately. Anything shared publicly can be seen by any other user, whereas privately shared content can only be accessed by a specified set of people. Instagram also enables its users to share through many other social networking platforms, such as Facebook, Twitter, Flickr, and Tumblr.\nInstagram 是一项社交网络服务，用户可以通过它上传照片和视频并与其他用户分享。 Instagram 用户可以选择公开或私下分享信息。任何其他用户都可以看到公开共享的任何内容，而私人共享的内容只能由指定的一组人访问。 Instagram 还允许用户通过许多其他社交网络平台进行分享，例如 Facebook、Twitter、Flickr 和 Tumblr。\nFor the sake of this exercise, we plan to design a simpler version of Instagram, where a user can share photos and can also follow other users. The ‘News Feed’ for each user will consist of top photos of all the people the user follows.\n为了这个练习，我们计划设计一个更简单的 Instagram 版本，用户可以在其中分享照片，也可以关注其他用户。每个用户的“新闻源”将包含该用户关注的所有人的热门照片。\n2. Requirements and Goals of the System 系统的要求和目标 We’ll focus on the following set of requirements while designing the Instagram:\n在设计 Instagram 时，我们将重点关注以下一组要求：\nFunctional Requirements\n功能要求\nUsers should be able to upload/download/view photos.\n用户应该能够上传/下载/查看照片。\nUsers can perform searches based on photo/video titles.\n用户可以根据照片/视频标题执行搜索。\nUsers can follow other users.\n用户可以关注其他用户。\nThe system should be able to generate and display a user’s News Feed consisting of top photos from all the people the user follows.\n系统应该能够生成并显示由热门照片组成的用户动态消息来自用户关注的所有人。\nNon-functional Requirements\n非功能性需求\nOur service needs to be highly available.\n我们的服务需要高度可用。\nThe acceptable latency of the system is 200ms for News Feed generation.\n对于 News Feed 生成，系统可接受的延迟为 200 毫秒。\nConsistency can take a hit (in the interest of availability), if a user doesn’t see a photo for a while; it should be fine.\n如果用户没有看到某个时间的照片，一致性可能会受到影响（为了可用性）尽管;应该没问题。\nThe system should be highly reliable; any uploaded photo or video should never be lost.\n系统应具有高可靠性；任何上传的照片或视频都不应丢失。\nNot in scope: Adding tags to photos, searching photos on tags, commenting on photos, tagging users to photos, who to follow, etc.\n不在范围内：为照片添加标签、在标签上搜索照片、评论照片、为照片标记用户、关注谁等。\n3. Some Design Considerations 一些设计考虑 The system would be read-heavy, so we will focus on building a system that can retrieve photos quickly.\n该系统的读取量很大，因此我们将专注于构建一个可以快速检索照片的系统。\nPractically, users can upload as many photos as they like. Efficient management of storage should be a crucial factor while designing this system.\n实际上，用户可以上传任意数量的照片。设计该系统时，有效的存储管理应该是一个关键因素。\nLow latency is expected while viewing photos.\n查看照片时预计延迟较低。\nData should be 100% reliable. If a user uploads a photo, the system will guarantee that it will never be lost.\n数据应该100%可靠。如果用户上传照片，系统将保证它会永远不会迷失。\n4. Capacity Estimation and Constraints 容量估计和约束 Let’s assume we have 500M total users, with 1M daily active users.\n假设我们有 5 亿总用户，其中每日活跃用户为 100 万。\n2M new photos every day, 23 new photos every second.\n每天 200 万张新照片，每秒 23 张新照片。\nAverage photo file size =\u0026gt; 200KB\n平均照片文件大小 =\u0026gt; 200KB\nTotal space required for 1 day of photos\n1 天照片所需的总空间\n2M * 200KB =\u0026gt; 400 GB\nTotal space required for 10 years: 400GB * 365 (days a year) * 10 (years) ~= 1425TB\n10年所需总空间：400GB * 365（一年天）* 10（年）~= 1425TB\n5. High Level System Design 高层系统设计 At a high-level, we need to support two scenarios, one to upload photos and the other to view/search photos. Our service would need some object storage servers to store photos and also some database servers to store metadata information about the photos.\n在高层，我们需要支持两种场景，一种是上传照片，另一种是查看/搜索照片。我们的服务需要一些对象存储服务器来存储照片，还需要一些数据库服务器来存储有关照片的元数据信息。\n6. Database Schema 数据库架构 Defining the DB schema in the early stages of the interview would help to understand the data flow among various components and later would guide towards data partitioning.\n在面试的早期阶段定义数据库模式将有助于理解各个组件之间的数据流，并在以后指导数据分区。\nWe need to store data about users, their uploaded photos, and people they follow. Photo table will store all data related to a photo; we need to have an index on (PhotoID, CreationDate) since we need to fetch recent photos first.\n我们需要存储有关用户、他们上传的照片以及他们关注的人的数据。照片表将存储与照片相关的所有数据；我们需要在 (PhotoID, CreationDate) 上有一个索引，因为我们需要首先获取最近的照片。\nA straightforward approach for storing the above schema would be to use an RDBMS like MySQL since we require joins. But relational databases come with their challenges, especially when we need to scale them. For details, please take a look at SQL vs. NoSQL.\n存储上述模式的一个简单方法是使用像 MySQL 这样的 RDBMS，因为我们需要连接。但关系数据库也面临着挑战，尤其是当我们需要扩展它们时。有关详细信息，请查看 SQL 与 NoSQL。\nWe can store photos in a distributed file storage like HDFS or S3.\n我们可以将照片存储在 HDFS 或 S3 等分布式文件存储中。\nWe can store the above schema in a distributed key-value store to enjoy the benefits offered by NoSQL. All the metadata related to photos can go to a table where the ‘key’ would be the ‘PhotoID’ and the ‘value’ would be an object containing PhotoLocation, UserLocation, CreationTimestamp, etc.\n我们可以将上述模式存储在分布式键值存储中，以享受 NoSQL 提供的好处。所有与照片相关的元数据都可以进入一个表，其中“键”是“PhotoID”，“值”是包含 PhotoLocation、UserLocation、CreationTimestamp 等的对象。\nWe need to store relationships between users and photos, to know who owns which photo. We also need to store the list of people a user follows. For both of these tables, we can use a wide-column datastore like Cassandra. For the ‘UserPhoto’ table, the ‘key’ would be ‘UserID’ and the ‘value’ would be the list of ‘PhotoIDs’ the user owns, stored in different columns. We will have a similar scheme for the ‘UserFollow’ table.\n我们需要存储用户和照片之间的关系，以了解谁拥有哪张照片。我们还需要存储用户关注的人员列表。对于这两个表，我们可以使用像 Cassandra 这样的宽列数据存储。对于“UserPhoto”表，“键”将是“UserID”，“值”将是用户拥有的“PhotoID”列表，存储在不同的列中。我们将为“UserFollow”表提供类似的方案。\nCassandra or key-value stores in general, always maintain a certain number of replicas to offer reliability. Also, in such data stores, deletes don’t get applied instantly, data is retained for certain days (to support undeleting) before getting removed from the system permanently.\nCassandra 或键值存储通常始终维护一定数量的副本以提供可靠性。此外，在此类数据存储中，删除不会立即应用，数据会保留一定天数（以支持取消删除），然后从系统中永久删除。\n7. Data Size Estimation 数据大小估计 Let’s estimate how much data will be going into each table and how much total storage we will need for 10 years.\n让我们估计一下每个表中将有多少数据以及 10 年需要多少总存储空间。\nUser: Assuming each “int” and “dateTime” is four bytes, each row in the User’s table will be of 68 bytes:\nUser：假设每个“int”和“dateTime”都是4个字节，则User表中的每行将有68个字节：\nUserID (4 bytes) + Name (20 bytes) + Email (32 bytes) + DateOfBirth (4 bytes) + CreationDate (4 bytes) + LastLogin (4 bytes) = 68 bytes\n用户 ID（4 字节）+ 姓名（20 字节）+ 电子邮件（32 字节）+ 出生日期（4 字节）+ 创建日期（4 字节）+ 最后登录（4 字节）= 68 字节\nIf we have 500 million users, we will need 32GB of total storage.\n如果我们有 5 亿用户，我们将需要 32GB 的总存储空间。\n500 million * 68 ~= 32GB\nPhoto: Each row in Photo’s table will be of 284 bytes:\nPhoto：Photo 表中的每一行都是 284 字节：\nPhotoID (4 bytes) + UserID (4 bytes) + PhotoPath (256 bytes) + PhotoLatitude (4 bytes) + PhotLongitude(4 bytes) + UserLatitude (4 bytes) + UserLongitude (4 bytes) + CreationDate (4 bytes) = 284 bytes\nPhotoID（4 字节）+ UserID（4 字节）+ PhotoPath（256 字节）+ PhotoLatitude（4 字节）+ PhotoLongitude（4 字节）+ UserLatitude（4 字节）+ UserLongitude（4 字节）+ CreationDate（4 字节）= 284 字节\nIf 2M new photos get uploaded every day, we will need 0.5GB of storage for one day:\n如果每天上传 200 万张新照片，我们一天需要 0.5GB 的存储空间：\n2M * 284 bytes ~= 0.5GB per day\n2M * 284 字节 ~= 0.5GB 每天\nFor 10 years we will need 1.88TB of storage.\n10 年内我们将需要 1.88TB 的存储空间。\nUserFollow: Each row in the UserFollow table will consist of 8 bytes. If we have 500 million users and on average each user follows 500 users. We would need 1.82TB of storage for the UserFollow table:\nUserFollow：UserFollow 表中的每一行由 8 个字节组成。如果我们有 5 亿用户，平均每个用户关注 500 个用户。我们需要 1.82TB 的存储空间用于 UserFollow 表：\n500 million users * 500 followers * 8 bytes ~= 1.82TB\n5 亿用户 * 500 个关注者 * 8 字节 ~= 1.82TB\nTotal space required for all tables for 10 years will be 3.7TB:\n10 年所有表所需的总空间将为 3.7TB：\n32GB + 1.88TB + 1.82TB ~= 3.7TB\n8. Component Design 组件设计 Photo uploads (or writes) can be slow as they have to go to the disk, whereas reads will be faster, especially if they are being served from cache.\n照片上传（或写入）可能会很慢，因为它们必须写入磁盘，而读取会更快，尤其是从缓存提供服务时。\nUploading users can consume all the available connections, as uploading is a slow process. This means that ‘reads’ cannot be served if the system gets busy with all the write requests. We should keep in mind that web servers have a connection limit before designing our system. If we assume that a web server can have a maximum of 500 connections at any time, then it can’t have more than 500 concurrent uploads or reads. To handle this bottleneck we can split reads and writes into separate services. We will have dedicated servers for reads and different servers for writes to ensure that uploads don’t hog the system.\n上传用户可能会消耗所有可用连接，因为上传是一个缓慢的过程。这意味着如果系统忙于处理所有写入请求，则无法提供“读取”服务。在设计我们的系统之前，我们应该记住网络服务器有连接限制。如果我们假设一个 Web 服务器在任何时候最多可以有 500 个连接，那么它的并发上传或读取就不能超过 500 个。为了解决这个瓶颈，我们可以将读取和写入拆分为单独的服务。我们将拥有专门的读取服务器和不同的写入服务器，以确保上传不会占用系统。\nSeparating photos’ read and write requests will also allow us to scale and optimize each of these operations independently.\n分离照片的读取和写入请求还将使我们能够独立扩展和优化每个操作。\n9. Reliability and Redundancy 可靠性和冗余性 Losing files is not an option for our service. Therefore, we will store multiple copies of each file so that if one storage server dies we can retrieve the photo from the other copy present on a different storage server.\n我们的服务不允许丢失文件。因此，我们将存储每个文件的多个副本，以便如果一个存储服务器出现故障，我们可以从不同存储服务器上存在的另一个副本中检索照片。\nThis same principle also applies to other components of the system. If we want to have high availability of the system, we need to have multiple replicas of services running in the system, so that if a few services die down the system still remains available and running. Redundancy removes the single point of failure in the system.\n同样的原理也适用于系统的其他组件。如果我们希望系统具有高可用性，我们需要在系统中运行多个服务副本，以便在少数服务停止运行时系统仍然保持可用并运行。冗余消除了系统中的单点故障。\nIf only one instance of a service is required to run at any point, we can run a redundant secondary copy of the service that is not serving any traffic, but it can take control after the failover when primary has a problem.\n如果某个服务在任何时候只需要运行一个实例，我们可以运行该服务的冗余辅助副本，该副本不提供任何流量，但当主服务器出现问题时，它可以在故障转移后接管控制权。\nCreating redundancy in a system can remove single points of failure and provide a backup or spare functionality if needed in a crisis. For example, if there are two instances of the same service running in production and one fails or degrades, the system can failover to the healthy copy. Failover can happen automatically or require manual intervention.\n在系统中创建冗余可以消除单点故障，并在危机中需要时提供备份或备用功能。例如，如果同一服务有两个实例在生产中运行，其中一个实例出现故障或性能下降，系统可以故障转移到正常副本。故障转移可以自动发生或需要手动干预。\n10. Data Sharding 数据分片 Let’s discuss different schemes for metadata sharding:\n让我们讨论元数据分片的不同方案：\na. Partitioning based on UserID Let’s assume we shard based on the ‘UserID’ so that we can keep all photos of a user on the same shard. If one DB shard is 1TB, we will need four shards to store 3.7TB of data. Let’s assume for better performance and scalability we keep 10 shards.\na. 基于 UserID 的分区 假设我们基于“UserID”进行分片，以便我们可以将用户的所有照片保留在同一个分片上。如果一个数据库分片为 1TB，我们将需要四个分片来存储 3.7TB 的数据。假设为了获得更好的性能和可扩展性，我们保留 10 个分片。\nSo we’ll find the shard number by UserID % 10 and then store the data there. To uniquely identify any photo in our system, we can append shard number with each PhotoID.\n因此，我们将通过 UserID % 10 找到分片编号，然后将数据存储在那里。为了唯一地标识我们系统中的任何照片，我们可以为每个 PhotoID 附加分片编号。\nHow can we generate PhotoIDs? Each DB shard can have its own auto-increment sequence for PhotoIDs and since we will append ShardID with each PhotoID, it will make it unique throughout our system.\n我们如何生成 PhotoID？每个数据库分片都可以有自己的 PhotoID 自动递增序列，并且由于我们将在每个 PhotoID 后附加 ShardID，这将使其在整个系统中是唯一的。\nWhat are the different issues with this partitioning scheme?\n这种分区方案有哪些不同的问题？\nHow would we handle hot users? Several people follow such hot users and a lot of other people see any photo they upload.\n我们如何处理热门用户？有几个人关注这些热门用户，很多其他人都会看到他们上传的任何照片。\nSome users will have a lot of photos compared to others, thus making a non-uniform distribution of storage.\n与其他用户相比，某些用户会拥有大量照片，从而导致存储分布不均匀。\nWhat if we cannot store all pictures of a user on one shard? If we distribute photos of a user onto multiple shards will it cause higher latencies?\n如果我们无法将用户的所有图片存储在一个分片上怎么办？如果我们将用户的照片分发到多个分片上会导致更高的延迟吗？\nStoring all photos of a user on one shard can cause issues like unavailability of all of the user’s data if that shard is down or higher latency if it is serving high load etc.\n将用户的所有照片存储在一个分片上可能会导致一些问题，例如，如果该分片已关闭，则所有用户的数据将不可用；如果该分片提供高负载服务，则延迟会更高等。\nb. Partitioning based on PhotoID If we can generate unique PhotoIDs first and then find a shard number through “PhotoID % 10”, the above problems will have been solved. We would not need to append ShardID with PhotoID in this case as PhotoID will itself be unique throughout the system.\nb.基于PhotoID的分区如果我们能够先生成唯一的PhotoID，然后通过“PhotoID % 10”找到分片编号，那么上述问题就迎刃而解了。在这种情况下，我们不需要将 ShardID 与 PhotoID 一起附加，因为 PhotoID 本身在整个系统中是唯一的。\nHow can we generate PhotoIDs? Here we cannot have an auto-incrementing sequence in each shard to define PhotoID because we need to know PhotoID first to find the shard where it will be stored. One solution could be that we dedicate a separate database instance to generate auto-incrementing IDs. If our PhotoID can fit into 64 bits, we can define a table containing only a 64 bit ID field. So whenever we would like to add a photo in our system, we can insert a new row in this table and take that ID to be our PhotoID of the new photo.\n我们如何生成 PhotoID？这里我们不能在每个分片中使用自动递增序列来定义 PhotoID，因为我们需要首先知道 PhotoID 才能找到存储它的分片。一种解决方案是我们专门使用一个单独的数据库实例来生成自动递增的 ID。如果我们的 PhotoID 可以容纳 64 位，我们就可以定义一个仅包含 64 位 ID 字段的表。因此，每当我们想在系统中添加照片时，我们都可以在此表中插入一个新行，并将该 ID 作为新照片的 PhotoID。\nWouldn’t this key generating DB be a single point of failure? Yes, it would be. A workaround for that could be defining two such databases with one generating even numbered IDs and the other odd numbered. For the MySQL, the following script can define such sequences:\n这个密钥生成数据库不会出现单点故障吗？是的，会的。一种解决方法是定义两个这样的数据库，其中一个生成偶数编号的 ID，另一个生成奇数编号的 ID。对于MySQL，以下脚本可以定义这样的序列：\nKeyGeneratingServer1: auto-increment-increment = 2 auto-increment-offset = 1 KeyGeneratingServer2: auto-increment-increment = 2 auto-increment-offset = 2 We can put a load balancer in front of both of these databases to round robin between them and to deal with downtime. Both these servers could be out of sync with one generating more keys than the other, but this will not cause any issue in our system. We can extend this design by defining separate ID tables for Users, Photo-Comments, or other objects present in our system.\n我们可以在这两个数据库前面放置一个负载均衡器，以在它们之间进行循环并处理停机时间。这两台服务器可能会不同步，其中一台生成的密钥多于另一台，但这不会在我们的系统中造成任何问题。我们可以通过为用户、照片评论或系统中存在的其他对象定义单独的 ID 表来扩展此设计。\nAlternately, we can implement a ‘key’ generation scheme similar to what we have discussed in Designing a URL Shortening service like TinyURL.\n或者，我们可以实现一个“密钥”生成方案，类似于我们在设计类似 TinyURL 的 URL 缩短服务中讨论的方案。\nHow can we plan for the future growth of our system? We can have a large number of logical partitions to accommodate future data growth, such that in the beginning, multiple logical partitions reside on a single physical database server. Since each database server can have multiple database instances on it, we can have separate databases for each logical partition on any server. So whenever we feel that a particular database server has a lot of data, we can migrate some logical partitions from it to another server. We can maintain a config file (or a separate database) that can map our logical partitions to database servers; this will enable us to move partitions around easily. Whenever we want to move a partition, we only have to update the config file to announce the change.\n我们如何规划系统的未来发展？我们可以拥有大量的逻辑分区来适应未来的数据增长，这样在开始时，多个逻辑分区驻留在单个物理数据库服务器上。由于每个数据库服务器上可以有多个数据库实例，因此我们可以为任何服务器上的每个逻辑分区拥有单独的数据库。因此，每当我们感觉某个特定的数据库服务器有大量数据时，我们就可以将其中的一些逻辑分区迁移到另一台服务器上。我们可以维护一个配置文件（或一个单独的数据库），它可以将我们的逻辑分区映射到数据库服务器；这将使我们能够轻松移动分区。每当我们想要移动分区时，我们只需更新配置文件即可宣布更改。\n11. Ranking and News Feed Generation 排名和动态消息生成 To create the News Feed for any given user, we need to fetch the latest, most popular and relevant photos of the people the user follows.\n要为任何给定用户创建新闻源，我们需要获取用户关注的人的最新、最受欢迎和相关的照片。\nFor simplicity, let’s assume we need to fetch top 100 photos for a user’s News Feed. Our application server will first get a list of people the user follows and then fetch metadata info of latest 100 photos from each user. In the final step, the server will submit all these photos to our ranking algorithm which will determine the top 100 photos (based on recency, likeness, etc.) and return them to the user. A possible problem with this approach would be higher latency as we have to query multiple tables and perform sorting/merging/ranking on the results. To improve the efficiency, we can pre-generate the News Feed and store it in a separate table.\n为了简单起见，我们假设我们需要获取用户动态消息中的前 100 张照片。我们的应用程序服务器将首先获取用户关注的人员列表，然后从每个用户获取最新 100 张照片的元数据信息。在最后一步中，服务器会将所有这些照片提交给我们的排名算法，该算法将确定前 100 张照片（基于新近度、相似度等）并将其返回给用户。这种方法的一个可能的问题是更高的延迟，因为我们必须查询多个表并对结果执行排序/合并/排名。为了提高效率，我们可以预先生成News Feed，并将其存储在单独的表中。\nPre-generating the News Feed: We can have dedicated servers that are continuously generating users’ News Feeds and storing them in a ‘UserNewsFeed’ table. So whenever any user needs the latest photos for their News Feed, we will simply query this table and return the results to the user.\n预生成新闻源：我们可以拥有专用服务器，不断生成用户的新闻源并将其存储在“UserNewsFeed”表中。因此，每当任何用户需要为其动态消息提供最新照片时，我们都会简单地查询此表并将结果返回给用户。\nWhenever these servers need to generate the News Feed of a user, they will first query the UserNewsFeed table to find the last time the News Feed was generated for that user. Then, new News Feed data will be generated from that time onwards (following the steps mentioned above).\n每当这些服务器需要生成用户的新闻源时，它们将首先查询 UserNewsFeed 表以查找上次为该用户生成新闻源的时间。然后，将从那时起生成新的新闻源数据（按照上述步骤）。\nWhat are the different approaches for sending News Feed contents to the users? 向用户发送动态消息内容有哪些不同的方法？\n1. Pull: Clients can pull the News Feed contents from the server on a regular basis or manually whenever they need it. Possible problems with this approach are a) New data might not be shown to the users until clients issue a pull request b) Most of the time pull requests will result in an empty response if there is no new data.\n1.拉取：客户端可以定期或在需要时手动从服务器拉取News Feed内容。这种方法可能存在的问题是：a）在客户端发出拉取请求之前，新数据可能不会显示给用户。b）大多数情况下，如果没有新数据，拉取请求将导致空响应。\n2. Push: Servers can push new data to the users as soon as it is available. To efficiently manage this, users have to maintain a Long Poll request with the server for receiving the updates. A possible problem with this approach is, a user who follows a lot of people or a celebrity user who has millions of followers; in this case, the server has to push updates quite frequently.\n2.推送：服务器可以将新数据推送给用户。为了有效地管理这一点，用户必须与服务器保持长轮询请求以接收更新。这种方法可能存在的问题是，关注很多人的用户或拥有数百万关注者的名人用户；在这种情况下，服务器必须非常频繁地推送更新。\n3. Hybrid: We can adopt a hybrid approach. We can move all the users who have a high number of follows to a pull-based model and only push data to those users who have a few hundred (or thousand) follows. Another approach could be that the server pushes updates to all the users not more than a certain frequency, letting users with a lot of follows/updates to regularly pull data.\n3.混合：我们可以采用混合的方法。我们可以将所有拥有大量关注的用户转移到基于拉动的模型，并且只将数据推送给那些拥有数百（或数千）关注的用户。另一种方法可能是服务器向所有用户推送更新的频率不超过一定频率，让关注/更新较多的用户定期拉取数据。\nFor a detailed discussion about News Feed generation, take a look at Designing Facebook’s Newsfeed.\n有关 News Feed 生成的详细讨论，请查看设计 Facebook 的 Newsfeed。\n12. News Feed Creation with Sharded Data 使用分片数据创建新闻源 One of the most important requirement to create the News Feed for any given user is to fetch the latest photos from all people the user follows. For this, we need to have a mechanism to sort photos on their time of creation. To efficiently do this, we can make photo creation time part of the PhotoID. As we will have a primary index on PhotoID, it will be quite quick to find the latest PhotoIDs.\n为任何给定用户创建新闻源的最重要要求之一是获取该用户关注的所有人的最新照片。为此，我们需要有一种机制来按照片的创建时间对其进行排序。为了有效地做到这一点，我们可以将照片创建时间作为 PhotoID 的一部分。由于我们将在 PhotoID 上建立主索引，因此可以很快找到最新的 PhotoID。\nWe can use epoch time for this. Let’s say our PhotoID will have two parts; the first part will be representing epoch time and the second part will be an auto-incrementing sequence. So to make a new PhotoID, we can take the current epoch time and append an auto-incrementing ID from our key- generating DB. We can figure out shard number from this PhotoID ( PhotoID % 10) and store the photo there.\n我们可以为此使用纪元时间。假设我们的 PhotoID 将由两部分组成：第一部分将表示纪元时间，第二部分将是自动递增序列。因此，为了创建一个新的 PhotoID，我们可以获取当前纪元时间并从我们的密钥生成数据库中附加一个自动递增的 ID。我们可以从这个 PhotoID ( PhotoID % 10) 中找出分片编号并将照片存储在那里。\nWhat could be the size of our PhotoID? Let’s say our epoch time starts today, how many bits we would need to store the number of seconds for next 50 years?\n我们的 PhotoID 的大小是多少？假设我们的纪元时间从今天开始，我们需要多少位来存储未来 50 年的秒数？\n86400 sec/day * 365 (days a year) * 50 (years) =\u0026gt; 1.6 billion seconds\n86400 秒/天 * 365（一年天）* 50（年）=\u0026gt; 16 亿秒\nWe would need 31 bits to store this number. Since on the average, we are expecting 23 new photos per second; we can allocate 9 bits to store auto incremented sequence. So every second we can store (2^9 =\u0026gt; 512) new photos. We can reset our auto incrementing sequence every second.\n我们需要 31 位来存储这个数字。因为平均而言，我们预计每秒 23 张新照片；我们可以分配9位来存储自动递增序列。所以每一秒我们都可以存储 (2^9 =\u0026gt; 512) 张新照片。我们可以每秒重置自动递增序列。\nWe will discuss more details about this technique under ‘Data Sharding’ in Designing Twitter.\n我们将在设计 Twitter 中的“数据分片”部分讨论有关此技术的更多细节。\n13. Cache and Load balancing 缓存和负载平衡 Our service would need a massive-scale photo delivery system to serve the globally distributed users. Our service should push its content closer to the user using a large number of geographically distributed photo cache servers and use CDNs (for details see Caching).\n我们的服务需要一个大规模的照片传输系统来为全球分布的用户提供服务。我们的服务应该使用大量地理分布的照片缓存服务器并使用 CDN（有关详细信息，请参阅缓存）将其内容推送到更接近用户的位置。\nWe can introduce a cache for metadata servers to cache hot database rows. We can use Memcache to cache the data and Application servers before hitting database can quickly check if the cache has desired rows. Least Recently Used (LRU) can be a reasonable cache eviction policy for our system. Under this policy, we discard the least recently viewed row first.\n我们可以为元数据服务器引入缓存来缓存热数据库行。我们可以使用 Memcache 来缓存数据，应用程序服务器在访问数据库之前可以快速检查缓存中是否有所需的行。最近最少使用（LRU）对于我们的系统来说是一个合理的缓存驱逐策略。根据此策略，我们首先丢弃最近最少查看的行。\nHow can we build more intelligent cache? If we go with 80-20 rule, i.e., 20% of daily read volume for photos is generating 80% of traffic which means that certain photos are so popular that the majority of people read them. This dictates that we can try caching 20% of daily read volume of photos and metadata.\n如何构建更加智能的缓存？如果我们遵循 80-20 规则，即每日照片阅读量的 20% 会产生 80% 的流量，这意味着某些照片非常受欢迎，以至于大多数人都会阅读它们。这表明我们可以尝试缓存每日读取量的 20% 的照片和元数据。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/24/designing-instagram/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Instagram》设计 Instagram。\nLet’s design a photo-sharing service like Instagram, where users can upload photos to share them with other users. Similar Services: Flickr, Picasa Difficulty Level: Medium\n让我们设计一个像 Instagram 这样的照片共享服务，用户可以上传照片与其他用户共享。类似服务：Flickr、Picasa 难度级别：中\n1. What is Instagram? 1.Instagram是什么？\nInstagram is a social networking service which enables its users to upload and share their photos and videos with other users. Instagram users can choose to share information either publicly or privately. Anything shared publicly can be seen by any other user, whereas privately shared content can only be accessed by a specified set of people. Instagram also enables its users to share through many other social networking platforms, such as Facebook, Twitter, Flickr, and Tumblr.","title":"[译]《Grokking the System Design Interview》设计Instagram"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Pastebin》设计 Pastebin。\nLet’s design a Pastebin like web service, where users can store plain text. Users of the service will enter a piece of text and get a randomly generated URL to access it. Similar Services: pastebin.com, pasted.co, chopapp.com Difficulty Level: Easy\n让我们设计一个类似 Pastebin 的 Web 服务，用户可以在其中存储纯文本。该服务的用户将输入一段文本并获得一个随机生成的 URL 来访问它。类似服务：pastebin.com、pasted.co、hopapp.com 难度级别：简单\n1. What is Pastebin? 1.Pastebin是什么？\nPastebin like services enable users to store plain text or images over the network (typically the Internet) and generate unique URLs to access the uploaded data. Such services are also used to share data over the network quickly, as users would just need to pass the URL to let other users see it.\nPastebin 之类的服务使用户能够通过网络（通常是互联网）存储纯文本或图像，并生成唯一的 URL 来访问上传的数据。此类服务还用于通过网络快速共享数据，因为用户只需传递 URL 即可让其他用户看到它。\nIf you haven’t used pastebin.com before, please try creating a new ‘Paste’ there and spend some time going through the different options their service offers. This will help you a lot in understanding this chapter.\n如果您以前没有使用过 pastebin.com，请尝试在那里创建一个新的“粘贴”，并花一些时间浏览他们的服务提供的不同选项。这将对你理解本章有很大帮助。\n2. Requirements and Goals of the System 系统的要求和目标 Our Pastebin service should meet the following requirements:\n我们的 Pastebin 服务应满足以下要求：\nFunctional Requirements:\n功能要求：\nUsers should be able to upload or “paste” their data and get a unique URL to access it.\n用户应该能够上传或“粘贴”他们的数据并获得唯一的 URL 来访问它。\nUsers will only be able to upload text.\n用户只能上传文本。\nData and links will expire after a specific timespan automatically; users should also be able to specify expiration time.\n数据和链接将在特定时间段后自动过期；用户还应该能够指定过期时间。\nUsers should optionally be able to pick a custom alias for their paste.\n用户应该可以选择为其粘贴选择自定义别名。\nNon-Functional Requirements:\n非功能性要求：\nThe system should be highly reliable, any data uploaded should not be lost.\n系统应高度可靠，上传的任何数据都不应丢失。\nThe system should be highly available. This is required because if our service is down, users will not be able to access their Pastes.\n系统应该是高可用的。这是必需的，因为如果我们的服务出现故障，用户将无法访问他们的粘贴。\nUsers should be able to access their Pastes in real-time with minimum latency.\n用户应该能够以最小的延迟实时访问他们的粘贴。\nPaste links should not be guessable (not predictable).\n粘贴链接不应是可猜测的（不可预测的）。\nExtended Requirements:\n扩展要求：\nAnalytics, e.g., how many times a paste was accessed?\n分析，例如粘贴被访问了多少次？\nOur service should also be accessible through REST APIs by other services.\n我们的服务还应该可以由其他服务通过 REST API 访问。\n3. Some Design Considerations 一些设计考虑 Pastebin shares some requirements with URL Shortening service, but there are some additional design considerations we should keep in mind.\nPastebin 与 URL 缩短服务有一些共同的要求，但我们还应该牢记一些额外的设计注意事项。\nWhat should be the limit on the amount of text user can paste at a time? We can limit users not to have Pastes bigger than 10MB to stop the abuse of the service.\n用户一次可以粘贴的文本量的限制应该是多少？我们可以限制用户粘贴的大小不得超过 10MB，以阻止滥用服务。\nShould we impose size limits on custom URLs? Since our service supports custom URLs, users can pick any URL that they like, but providing a custom URL is not mandatory. However, it is reasonable (and often desirable) to impose a size limit on custom URLs, so that we have a consistent URL database.\n我们应该对自定义 URL 施加大小限制吗？由于我们的服务支持自定义 URL，因此用户可以选择他们喜欢的任何 URL，但提供自定义 URL 不是强制性的。然而，对自定义 URL 施加大小限制是合理的（而且通常是可取的），这样我们就有一个一致的 URL 数据库。\n4. Capacity Estimation and Constraints 容量估计和约束 Our services will be read-heavy; there will be more read requests compared to new Pastes creation. We can assume a 5:1 ratio between read and write.\n我们的服务将需要大量阅读；与创建新的粘贴相比，将会有更多的读取请求。我们可以假设读和写之间的比例为 5:1。\nTraffic estimates: Pastebin services are not expected to have traffic similar to Twitter or Facebook, let’s assume here that we get one million new pastes added to our system every day. This leaves us with five million reads per day.\n流量估计：Pastebin 服务预计不会有类似于 Twitter 或 Facebook 的流量，我们假设每天有 100 万个新粘贴添加到我们的系统中。这使得我们每天的阅读量达到 500 万次。\nNew Pastes per second:\n每秒新粘贴数：\n1M / (24 hours * 3600 seconds) ~= 12 pastes/sec\nPaste reads per second:\n粘贴每秒读取次数：\n5M / (24 hours * 3600 seconds) ~= 58 reads/sec\nStorage estimates: Users can upload maximum 10MB of data; commonly Pastebin like services are\n存储预估：用户最多可上传10MB数据；通常类似 Pastebin 的服务是\nused to share source code, configs or logs. Such texts are not huge, so let’s assume that each paste on average contains 10KB.\n用于共享源代码、配置或日志。这些文本并不大，所以我们假设每个粘贴平均包含 10KB。\nAt this rate, we will be storing 10GB of data per day.\n按照这个速度，我们每天将存储 10GB 的数据。\n1M * 10KB =\u0026gt; 10 GB/day\nIf we want to store this data for ten years we would need the total storage capacity of 36TB.\n如果我们想存储这些数据十年，我们需要 36TB 的总存储容量。\nWith 1M pastes every day we will have 3.6 billion Pastes in 10 years. We need to generate and store keys to uniquely identify these pastes. If we use base64 encoding ([A-Z, a-z, 0-9, ., -]) we would need six letters strings:\n每天有 100 万个焊膏，10 年后我们将拥有 36 亿个焊膏。我们需要生成并存储密钥来唯一标识这些粘贴。如果我们使用 Base64 编码（[A-Z, a-z, 0-9, ., -]），我们将需要六个字母的字符串：\n64^6 ~= 68.7 billion unique strings\n64^6 ~= 687 亿个唯一字符串\nIf it takes one byte to store one character, total size required to store 3.6B keys would be:\n如果需要 1 个字节存储 1 个字符，则存储 3.6B 个密钥所需的总大小为：\n3.6B * 6 =\u0026gt; 22 GB\n22GB is negligible compared to 36TB. To keep some margin, we will assume a 70% capacity model (meaning we don’t want to use more than 70% of our total storage capacity at any point), which raises our storage needs to 51.4TB.\n与 36TB 相比，22GB 可以忽略不计。为了保留一定的余量，我们将假设 70% 的容量模型（这意味着我们在任何时候都不想使用超过总存储容量的 70%），这会将我们的存储需求提高到 51.4TB。\nBandwidth estimates: For write requests, we expect 12 new pastes per second, resulting in 120KB of ingress per second.\n带宽估计：对于写入请求，我们预计每秒 12 个新粘贴，导致每秒 120KB 的入口。\n12 * 10KB =\u0026gt; 120 KB/s\nAs for the read request, we expect 58 requests per second. Therefore, total data egress (sent to users) will be 0.6 MB/s.\n至于读取请求，我们预计每秒有 58 个请求。因此，总数据输出（发送给用户）将为 0.6 MB/s。\n58 * 10KB =\u0026gt; 0.6 MB/s\nAlthough total ingress and egress are not big, we should keep these numbers in mind while designing our service.\n尽管入口和出口总量并不大，但我们在设计服务时应该牢记这些数字。\nMemory estimates: We can cache some of the hot pastes that are frequently accessed. Following the 80-20 rule, meaning 20% of hot pastes generate 80% of traffic, we would like to cache these 20% pastes\n内存估算：我们可以缓存一些经常访问的热贴。遵循 80-20 规则，即 20% 的热门粘贴产生 80% 的流量，我们希望缓存这 20% 的粘贴\nSince we have 5M read requests per day, to cache 20% of these requests, we would need:\n由于我们每天有 500 万个读取请求，为了缓存这些请求的 20%，我们需要：\n0.2 * 5M * 10KB ~= 10 GB\n5. System APIs 系统API We can have SOAP or REST APIs to expose the functionality of our service. Following could be the definitions of the APIs to create/retrieve/delete Pastes:\n我们可以使用 SOAP 或 REST API 来公开我们服务的功能。以下是创建/检索/删除粘贴的 API 的定义：\naddPaste(api_dev_key, paste_data, custom_url=None user_name=None, paste_name=None, expire_date=None) Parameters:\n参数：\napi_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota. paste_data (string): Textual data of the paste. custom_url (string): Optional custom URL.\napi_dev_key (string): 注册账户的API开发者密钥。除其他外，这将用于根据分配的配额限制用户。 Paste_data（字符串）：粘贴的文本数据。 custom_url（字符串）：可选的自定义 URL。\nuser_name (string): Optional user name to be used to generate URL. paste_name (string): Optional name of the paste expire_date (string): Optional expiration date for the paste.\nuser_name（字符串）：用于生成 URL 的可选用户名。 Paste_name（字符串）：粘贴的可选名称 expire_date（字符串）：粘贴的可选到期日期。\nReturns: (string) A successful insertion returns the URL through which the paste can be accessed, otherwise, it will return an error code.\n返回：（字符串）成功插入将返回可访问粘贴的 URL，否则将返回错误代码。\nSimilarly, we can have retrieve and delete Paste APIs:\n同样，我们可以检索和删除粘贴 API：\ngetPaste(api_dev_key, api_paste_key) Where “api_paste_key” is a string representing the Paste Key of the paste to be retrieved. This API will return the textual data of the paste.\n其中“api_paste_key”是一个字符串，表示要检索的粘贴的粘贴密钥。该 API 将返回粘贴的文本数据。\ndeletePaste(api_dev_key, api_paste_key) A successful deletion returns ‘true’, otherwise returns ‘false’.\n成功删除返回“true”，否则返回“false”。\n6. Database Design 数据库设计 A few observations about the nature of the data we are storing:\n关于我们存储的数据的性质的一些观察：\nWe need to store billions of records.\n我们需要存储数十亿条记录。\nEach metadata object we are storing would be small (less than 100 bytes).\n我们存储的每个元数据对象都很小（小于 100 字节）。\nEach paste object we are storing can be of medium size (it can be a few MB).\n我们存储的每个粘贴对象可以是中等大小（可以是几 MB）。\nThere are no relationships between records, except if we want to store which user created what Paste.\n记录之间没有关系，除非我们想要存储哪个用户创建了哪个粘贴。\nOur service is read-heavy.\n我们的服务是重读的。\nDatabase Schema:\n数据库架构：\nWe would need two tables, one for storing information about the Pastes and the other for users’ data.\n我们需要两个表，一个用于存储有关粘贴的信息，另一个用于存储用户数据。\nHere, ‘URlHash’ is the URL equivalent of the TinyURL and ‘ContentKey’ is the object key storing the contents of the paste.\n这里，“URlHash”是相当于 TinyURL 的 URL，“ContentKey”是存储粘贴内容的对象键。\n7. High Level Design 高层设计 At a high level, we need an application layer that will serve all the read and write requests. Application layer will talk to a storage layer to store and retrieve data. We can segregate our storage layer with one database storing metadata related to each paste, users, etc., while the other storing the paste contents in some object storage (like Amazon S3). This division of data will also allow us to scale them individually.\n在较高的层面上，我们需要一个应用程序层来服务所有的读写请求。应用层将与存储层通信以存储和检索数据。我们可以将存储层隔离，一个数据库存储与每个粘贴、用户等相关的元数据，而另一个数据库将粘贴内容存储在某些对象存储（如 Amazon S3）中。这种数据划分还允许我们单独缩放它们。\n8. Component Design 组件设计 a. Application layer\na. 应用层\nOur application layer will process all incoming and outgoing requests. The application servers will be talking to the backend data store components to serve the requests.\n我们的应用程序层将处理所有传入和传出的请求。应用程序服务器将与后端数据存储组件通信以服务请求。\nHow to handle a write request? Upon receiving a write request, our application server will generate a six-letter random string, which would serve as the key of the paste (if the user has not provided a custom key). The application server will then store the contents of the paste and the generated key in the database. After the successful insertion, the server can return the key to the user. One possible problem here could be that the insertion fails because of a duplicate key. Since we are generating a random key, there is a possibility that the newly generated key could match an existing one. In that case, we should regenerate a new key and try again. We should keep retrying until we don’t see failure due to the duplicate key. We should return an error to the user if the custom key they have provided is already present in our database.\n如何处理写请求？收到写入请求后，我们的应用程序服务器将生成一个六字母的随机字符串，该字符串将用作粘贴的密钥（如果用户未提供自定义密钥）。然后应用程序服务器会将粘贴的内容和生成的密钥存储在数据库中。插入成功后，服务器可以将密钥返回给用户。这里一个可能的问题是插入由于重复的键而失败。由于我们生成随机密钥，因此新生成的密钥有可能与现有密钥匹配。在这种情况下，我们应该重新生成一个新密钥并重试。我们应该不断重试，直到看不到由于重复密钥而导致的失败。如果用户提供的自定义密钥已存在于我们的数据库中，我们应该向用户返回错误。\nAnother solution of the above problem could be to run a standalone Key Generation Service (KGS) that generates random six letters strings beforehand and stores them in a database (let’s call it key-DB). Whenever we want to store a new paste, we will just take one of the already generated keys and use it. This approach will make things quite simple and fast since we will not be worrying about duplications or collisions. KGS will make sure all the keys inserted in key-DB are unique. KGS can use two tables to store keys, one for keys that are not used yet and one for all the used keys. As soon as KGS gives some keys to an application server, it can move these to the used keys table. KGS can always keep some keys in memory so that whenever a server needs them, it can quickly provide them. As soon as KGS loads some keys in memory, it can move them to the used keys table, this way we can make sure each server gets unique keys. If KGS dies before using all the keys loaded in memory, we will be wasting those keys. We can ignore these keys given that we have a huge number of them.\n上述问题的另一个解决方案是运行一个独立的密钥生成服务（KGS），该服务预先生成随机的六个字母字符串并将它们存储在数据库中（我们称之为密钥数据库）。每当我们想要存储新的粘贴时，我们只需获取已生成的密钥之一并使用它即可。这种方法将使事情变得非常简单和快速，因为我们不会担心重复或冲突。 KGS 将确保插入 key-DB 中的所有密钥都是唯一的。 KGS 可以使用两张表来存储密钥，一张用于尚未使用的密钥，一张用于所有已使用的密钥。一旦 KGS 向应用程序服务器提供一些密钥，它就可以将这些密钥移动到已使用的密钥表中。 KGS 可以始终将一些密钥保留在内存中，以便每当服务器需要它们时，它可以快速提供它们。一旦 KGS 在内存中加载一些密钥，它就可以将它们移动到已使用的密钥表中，这样我们就可以确保每个服务器都获得唯一的密钥。如果 KGS 在使用内存中加载的所有密钥之前就死掉了，我们将浪费这些密钥。鉴于我们有大量的密钥，我们可以忽略这些密钥。\nIsn’t KGS a single point of failure? Yes, it is. To solve this, we can have a standby replica of KGS and whenever the primary server dies it can take over to generate and provide keys.\nKGS 不是单点故障吗？是的。为了解决这个问题，我们可以拥有一个 KGS 的备用副本，每当主服务器挂掉时，它就可以接管生成和提供密钥。\nCan each app server cache some keys from key-DB? Yes, this can surely speed things up. Although in this case, if the application server dies before consuming all the keys, we will end up losing those keys. This could be acceptable since we have 68B unique six letters keys, which are a lot more than we require.\n每个应用程序服务器可以缓存密钥数据库中的一些密钥吗？是的，这肯定可以加快速度。尽管在这种情况下，如果应用程序服务器在消耗所有密钥之前死亡，我们最终将丢失这些密钥。这是可以接受的，因为我们有 68B 个独特的六个字母键，这比我们需要的多得多。\nHow does it handle a paste read request? Upon receiving a read paste request, the application service layer contacts the datastore. The datastore searches for the key, and if it is found, returns the paste’s contents. Otherwise, an error code is returned.\n它如何处理粘贴读取请求？在接收到读取粘贴请求后，应用程序服务层联系数据存储。数据存储区搜索密钥，如果找到，则返回粘贴的内容。否则，返回错误代码。\nb. Datastore layer b.数据存储层\nWe can divide our datastore layer into two:\n我们可以将数据存储层分为两层：\nMetadata database: We can use a relational database like MySQL or a Distributed Key-Value store like Dynamo or Cassandra.\n元数据数据库：我们可以使用关系数据库（例如 MySQL）或分布式键值存储（例如 Dynamo 或 Cassandra）。\nObject storage: We can store our contents in an Object Storage like Amazon’s S3. Whenever we feel like hitting our full capacity on content storage, we can easily increase it by adding more servers.\n对象存储：我们可以将内容存储在对象存储中，例如 Amazon 的 S3。每当我们想要充分利用内容存储容量时，我们都可以通过添加更多服务器来轻松增加容量。\nDetailed component design for Pastebin\nPastebin 的详细组件设计\n9. Purging or DB Cleanup 清除或数据库清理 Please see Designing a URL Shortening service.\n请参阅设计 URL 缩短服务。\n10. Data Partitioning and Replication 数据分区和复制 Please see Designing a URL Shortening service.\n请参阅设计 URL 缩短服务。\n11. Cache and Load Balancer 缓存和负载均衡器 Please see Designing a URL Shortening service.\n请参阅设计 URL 缩短服务。\n12. Security and Permissions 安全和权限 Please see Designing a URL Shortening service.\n请参阅设计 URL 缩短服务。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/24/designing-pastebin/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing Pastebin》设计 Pastebin。\nLet’s design a Pastebin like web service, where users can store plain text. Users of the service will enter a piece of text and get a randomly generated URL to access it. Similar Services: pastebin.com, pasted.co, chopapp.com Difficulty Level: Easy\n让我们设计一个类似 Pastebin 的 Web 服务，用户可以在其中存储纯文本。该服务的用户将输入一段文本并获得一个随机生成的 URL 来访问它。类似服务：pastebin.com、pasted.co、hopapp.com 难度级别：简单\n1. What is Pastebin? 1.Pastebin是什么？\nPastebin like services enable users to store plain text or images over the network (typically the Internet) and generate unique URLs to access the uploaded data. Such services are also used to share data over the network quickly, as users would just need to pass the URL to let other users see it.","title":"[译]《Grokking the System Design Interview》设计Pastebin"},{"content":"这是一篇双语翻译的文章，原文出自《Grokking the System Design Interview》教程的 Domain Name System 这篇章节。\nIntroduction to Domain Name System (DNS) 域名系统 (DNS) 简介\nThe origins of DNS DNS 的起源\nLet’s consider the example of a mobile phone where a unique number is associated with each user. To make calls to friends, we can initially try to memorize some of the phone numbers. However, as the number of contacts grows, we’ll have to use a phone book to keep track of all our contacts. This way, whenever we need to make a call, we’ll refer to the phone book and dial the number we need.\n让我们考虑一个移动电话的示例，其中每个用户都有一个唯一的号码。为了给朋友打电话，我们首先可以尝试记住一些电话号码。然而，随着联系人数量的增加，我们将不得不使用电话簿来跟踪所有联系人。这样，每当我们需要打电话时，我们都会查阅电话簿并拨打我们需要的号码。\nSimilarly, computers are uniquely identified by IP addresses—for example, 104.18.2.119 is an IP address. We use IP addresses to visit a website hosted on a machine. Since humans cannot easily remember IP addresses to visit domain names (an example domain name being educative.io), we need a phone book-like repository that can maintain all mappings of domain names to IP addresses. In this chapter, we’ll see how DNS serves as the Internet’s phone book.\n同样，计算机由 IP 地址唯一标识，例如， 104.18.2.119 是一个 IP 地址。我们使用 IP 地址来访问计算机上托管的网站。由于人类无法轻易记住 IP 地址来访问域名（例如域名 eduducative.io），因此我们需要一个类似电话簿的存储库来维护域名到 IP 地址的所有映射。在本章中，我们将了解 DNS 如何充当互联网的电话簿。\nWhat is DNS? 什么是 DNS？\nThe domain name system (DNS) is the Internet’s naming service that maps human-friendly domain names to machine-readable IP addresses. The service of DNS is transparent to users. When a user enters a domain name in the browser, the browser has to translate the domain name to IP address by asking the DNS infrastructure. Once the desired IP address is obtained, the user’s request is forwarded to the destination web server.\n域名系统 (DNS) 是互联网的命名服务，它将人类友好的域名映射到机器可读的 IP 地址。 DNS服务对用户是透明的。当用户在浏览器中输入域名时，浏览器必须通过询问 DNS 基础设施将域名转换为 IP 地址。一旦获得所需的 IP 地址，用户的请求就会转发到目标 Web 服务器。\nThe slides below show the high-level flow of the working of DNS:\n下面的幻灯片显示了 DNS 工作的高级流程：\nThe entire operation is performed very quickly. Therefore, the end user experiences minimum delay. We’ll also see how browsers save some of the frequently used mappings for later use in the next lesson.\n整个操作进行得非常快。因此，最终用户体验到的延迟最小。我们还将了解浏览器如何保存一些常用的映射以供下一课稍后使用。\nImportant details 重要细节\nLet’s highlight some of the important details about DNS, some of which we’ll cover in the next lesson:\n让我们重点介绍有关 DNS 的一些重要细节，其中一些我们将在下一课中介绍：\nName servers: It’s important to understand that the DNS isn’t a single server. It’s a complete infrastructure with numerous servers. DNS servers that respond to users’ queries are called name servers.\n名称服务器：重要的是要了解 DNS 不是单个服务器。它是一个拥有大量服务器的完整基础设施。响应用户查询的 DNS 服务器称为名称服务器。\nResource records: The DNS database stores domain name to IP address mappings in the form of resource records (RR). The RR is the smallest unit of information that users request from the name servers. There are different types of RRs. The table below describes common RRs. The three important pieces of information are type, name, and value. The name and value change depending upon the type of the RR.\n资源记录：DNS 数据库以资源记录 (RR) 的形式存储域名到 IP 地址的映射。 RR 是用户从名称服务器请求的最小信息单元。 RR 有不同类型。下表描述了常见的 RR。三个重要的信息是类型、名称和值。名称和值根据 RR 的类型而变化。\nCommon Types of Resource Records 资源记录的常见类型\n**Type ** **Description ** **Name ** Value **Example (Type, Name, Value) ** A Provides the hostname to IP address mapping Hostname IP address (A, relay1.main.educative.io,104.18.2.119) NS Provides the hostname that is the authoritative DNS for a domain name Domain name Hostname (NS, educative.io, dns.educative.io) CNAME Provides the mapping from alias to canonical hostname Hostname Canonical name (CNAME, educative.io, server1.primary.educative.io) MX Provides the mapping of mail server from alias to canonical hostname Hostname Canonical name (MX, mail.educative.io, mailserver1.backup.educative.io) Caching: DNS uses caching at different layers to reduce request latency for the user. Caching plays an important role in reducing the burden on DNS infrastructure because it has to cater to the queries of the entire Internet.\n缓存：DNS 使用不同层的缓存来减少用户的请求延迟。缓存在减轻 DNS 基础设施的负担方面发挥着重要作用，因为它必须满足整个互联网的查询。\nHierarchy: DNS name servers are in a hierarchical form. The hierarchical structure allows DNS to be highly scalable because of its increasing size and query load. In the next lesson, we’ll look at how a tree-like structure is used to manage the entire DNS database.\n层次结构：DNS 名称服务器采用层次结构形式。由于其规模和查询负载不断增加，分层结构使 DNS 具有高度可扩展性。在下一课中，我们将了解如何使用树状结构来管理整个 DNS 数据库。\nLet’s explore more details of the above points in the next lesson to get more clarity.\n让我们在下一课中探讨上述要点的更多细节，以便更加清晰。\nHow the Domain Name System Works 域名系统如何运作\nThrough this lesson, we’ll answer the following questions:\n通过本课，我们将回答以下问题：\nHow is the DNS hierarchy formed using various types of DNS name servers?\n如何使用各种类型的 DNS 名称服务器形成 DNS 层次结构？\nHow is caching performed at different levels of the Internet to reduce the querying burden over the DNS infrastructure?\n如何在互联网的不同级别执行缓存以减轻 DNS 基础设施的查询负担？\nHow does the distributed nature of the DNS infrastructure help its robustness?\nDNS 基础设施的分布式特性如何有助于其稳健性？\nLet’s get started.\n让我们开始吧。\nDNS hierarchy DNS层次结构\nAs stated before, the DNS isn’t a single server that accepts requests and responds to user queries. It’s a complete infrastructure with name servers at different hierarchies.\n如前所述，DNS 不是接受请求并响应用户查询的单个服务器。它是一个完整的基础设施，具有不同层次结构的名称服务器。\nThere are mainly four types of servers in the DNS hierarchy:\nDNS 层次结构中主要有四种类型的服务器：\nDNS resolver: Resolvers initiate the querying sequence and forward requests to the other DNS name servers. Typically, DNS resolvers lie within the premise of the user’s network. However, DNS resolvers can also cater to users’ DNS queries through caching techniques, as we will see shortly. These servers can also be called local or default servers.\nDNS 解析器：解析器启动查询序列并将请求转发到其他 DNS 名称服务器。通常，DNS 解析器位于用户网络的内部。然而，DNS 解析器还可以通过缓存技术来满足用户的 DNS 查询，我们很快就会看到。这些服务器也可以称为本地或默认服务器。\nRoot-level name servers: These servers receive requests from local servers. Root name servers maintain name servers based on top-level domain names, such as .com, .edu, .us, and so on. For instance, when a user requests the IP address of educative.io, root-level name servers will return a list of top-level domain (TLD) servers that hold the IP addresses of the .io domain.\n根级名称服务器：这些服务器接收来自本地服务器的请求。根名称服务器维护基于顶级域名的名称服务器，例如 .com 、 .edu 、 .us 等。例如，当用户请求 educative.io 的 IP 地址时，根级名称服务器将返回保存 .io 域的 IP 地址的顶级域 (TLD) 服务器列表。\nTop-level domain (TLD) name servers: These servers hold the IP addresses of authoritative name servers. The querying party will get a list of IP addresses that belong to the authoritative servers of the organization.\n顶级域名 (TLD) 名称服务器：这些服务器保存权威名称服务器的 IP 地址。查询方将获得属于该组织的权威服务器的IP地址列表。\nAuthoritative name servers: These are the organization’s DNS name servers that provide the IP addresses of the web or application servers.\n权威名称服务器：这些是组织的 DNS 名称服务器，提供 Web 或应用程序服务器的 IP 地址。\nQuestion\n问题\nHow are DNS names processed? For example, will educative.io be processed from left to right or right to left?\nDNS 名称是如何处理的？例如，educative.io 是从左到右还是从右到左处理？\nUnlike UNIX files, which are processed from left to right, DNS names are processed from right to left. In the case of educative.io, the resolvers will first resolve the .io part, then educative, and so on.\n与从左到右处理的 UNIX 文件不同，DNS 名称是从右到左处理的。对于 educative.io，解析器将首先解析 .io 部分，然后解析 educative ，依此类推。\nVisually, however, the DNS hierarchy can be viewed as a tree.\n然而，从视觉上看，DNS 层次结构可以视为一棵树。\nIterative versus recursive query resolution 迭代与递归查询解析\nThere are two ways to perform a DNS query:\n有两种方法可以执行 DNS 查询：\nIterative: The local server requests the root, TLD, and the authoritative servers for the IP address.\n迭代：本地服务器向根服务器、TLD 和权威服务器请求 IP 地址。\nRecursive: The end user requests the local server. The local server further requests the root DNS name servers. The root name servers forward the requests to other name servers.\n递归：最终用户请求本地服务器。本地服务器进一步请求根 DNS 名称服务器。根名称服务器将请求转发到其他名称服务器。\nIn the following illustration (on the left), DNS query resolution is iterative from the perspective of the local/ISP server:\n在下图中（左），从本地/ISP服务器的角度来看，DNS查询解析是迭代的：\nNote: Typically, an iterative query is preferred to reduce query load on DNS infrastructure.\n注意：通常，首选迭代查询来减少 DNS 基础设施上的查询负载。\nThese days, we’ll find many third-party public DNS resolvers offered by Google, Cloudflare, OpenDNS, and many more. The interesting fact is that these public DNS servers may provide quicker responses than the local ISP DNS facilities.\n如今，我们会发现 Google、Cloudflare、OpenDNS 等提供的许多第三方公共 DNS 解析器。有趣的是，这些公共 DNS 服务器可能比本地 ISP DNS 设施提供更快的响应。\nCaching 缓存\nCaching refers to the temporary storage of frequently requested resource records. A record is a data unit within the DNS database that shows a name-to-value binding. Caching reduces response time to the user and decreases network traffic. When we use caching at different hierarchies, it can reduce a lot of querying burden on the DNS infrastructure. Caching can be implemented in the browser, operating systems, local name server within the user’s network, or the ISP’s DNS resolvers.\n缓存是指临时存储经常请求的资源记录。 记录是 DNS 数据库中的一个数据单元，显示名称到值的绑定。缓存减少了用户的响应时间并减少了网络流量。当我们在不同的层次结构中使用缓存时，它可以减轻 DNS 基础设施的大量查询负担。缓存可以在浏览器、操作系统、用户网络内的本地名称服务器或 ISP 的 DNS 解析器中实现。\nThe slideshow below demonstrates the power of caching in the DNS:\n下面的幻灯片展示了 DNS 中缓存的强大功能：\nNote: Even if there is no cache available to resolve a user’s query and it’s imperative to visit the DNS infrastructure, caching can still be beneficial. The local server or ISP DNS resolver can cache the IP addresses of TLD servers or authoritative servers and avoid requesting the root-level server.\n注意：即使没有可用的缓存来解析用户的查询并且必须访问 DNS 基础设施，缓存仍然是有益的。本地服务器或ISP DNS解析器可以缓存TLD服务器或权威服务器的IP地址，并避免请求根级服务器。\nDNS as a distributed system DNS 作为分布式系统\nAlthough the DNS hierarchy facilitates the distributed Internet that we know today, it’s a distributed system itself. The distributed nature of DNS has the following advantages:\n尽管 DNS 层次结构促进了我们今天所知的分布式互联网，但它本身就是一个分布式系统。 DNS的分布式特性具有以下优点：\nIt avoids becoming a single point of failure (SPOF).\n它避免成为单点故障 (SPOF)。\nIt achieves low query latency so users can get responses from nearby servers.\n它实现了低查询延迟，因此用户可以从附近的服务器获得响应。\nIt gets a higher degree of flexibility during maintenance and updates or upgrades. For example, if one DNS server is down or overburdened, another DNS server can respond to user queries.\n它在维护和更新或升级过程中获得更高程度的灵活性。例如，如果一台 DNS 服务器发生故障或负载过重，另一台 DNS 服务器可以响应用户查询。\nThere are 13 logical root name servers (named letter A through M) with many instances spread throughout the globe. These servers are managed by 12 different organizations.\n有 13 个逻辑根名称服务器（命名为字母 A 到 M），其中许多实例遍布全球。这些服务器由 12 个不同的组织管理。\nLet’s now go over how DNS is scalable, reliable, and consistent.\n现在让我们回顾一下 DNS 如何实现可扩展、可靠和一致。\nHighly scalable 高度可扩展\nDue to its hierarchical nature, DNS is a highly scalable system. Roughly 1,000 replicated instances of 13 root-level servers are spread throughout the world strategically to handle user queries. The working labor is divided among TLD and root servers to handle a query and, finally, the authoritative servers that are managed by the organizations themselves to make the entire system work. As shown in the DNS hierarchy tree above, different services handle different portions of the tree enabling scalability and manageability of the system.\n由于其分层性质，DNS 是一个高度可扩展的系统。 13 台根级服务器的大约 1,000 个复制实例战略性地分布在世界各地，以处理用户查询。工作劳力被分配到 TLD 和根服务器来处理查询，最后分配到由组织自己管理的权威服务器以使整个系统正常运行。如上面的 DNS 层次结构树所示，不同的服务处理树的不同部分，从而实现系统的可扩展性和可管理性。\nReliable 可靠性\nThree main reasons make the DNS a reliable system:\nDNS 成为可靠系统的三个主要原因：\nCaching: The caching is done in the browser, the operating system, and the local name server, and the ISP DNS resolvers also maintain a rich cache of frequently visited services. Even if some DNS servers are temporarily down, cached records can be served to make DNS a reliable system.\n缓存：缓存是在浏览器、操作系统和本地名称服务器中完成的，ISP DNS 解析器还维护着经常访问的服务的丰富缓存。即使某些 DNS 服务器暂时关闭，也可以提供缓存记录，使 DNS 成为一个可靠的系统。\nServer replication: DNS has replicated copies of each logical server spread systematically across the globe to entertain user requests at low latency. The redundant servers improve the reliability of the overall system.\n服务器复制：DNS 系统地复制了遍布全球的每个逻辑服务器的副本，以低延迟处理用户请求。冗余服务器提高了整个系统的可靠性。\nProtocol: Although many clients rely on the unreliable User Datagram Protocol (UDP) to request and receive DNS responses, it is important to acknowledge that UDP also offers distinct advantages. UDP is much faster and, therefore, improves DNS performance. Furthermore, Internet service’s reliability has improved since its inception, so UDP is usually favored over TCP. A DNS resolver can resend the UDP request if it didn’t get a reply to a previous one. This request-response needs just one round trip, which provides a shorter delay as compared to TCP, which needs a three-way handshake before data exchange.\n协议：尽管许多客户端依赖不可靠的用户数据报协议 (UDP) 来请求和接收 DNS 响应，但重要的是要承认 UDP 也提供了独特的优势。 UDP 速度更快，因此可以提高 DNS 性能。此外，自诞生以来，互联网服务的可靠性已得到提高，因此 UDP 通常比 TCP 更受青睐。如果 DNS 解析器没有收到前一个请求的回复，则可以重新发送 UDP 请求。这种请求-响应仅需要一次往返，与在数据交换之前需要三次握手的 TCP 相比，延迟更短。\nQuestion\n问题\nWhat happens if a network is congested? Should DNS continue using UDP?\n如果网络拥塞会发生什么？ DNS 是否应该继续使用 UDP？\nTypically, DNS uses UDP. However, DNS can use TCP when its message size exceeds the original packet size of 512 Bytes. This is because large-size packets are more prone to be damaged in congested networks. DNS always uses TCP for zone transfers.\n通常，DNS 使用 UDP。但是，当 DNS 的消息大小超过原始数据包大小 512 字节时，DNS 可以使用 TCP。这是因为大尺寸数据包在拥塞的网络中更容易被损坏。 DNS 始终使用 TCP 进行区域传输。\nSome clients prefer DNS over TCP to employ transport layer security for privacy reasons.\n出于隐私原因，某些客户端更喜欢使用 DNS 而不是 TCP 来采用传输层安全性。\nConsistent 一致性\nDNS uses various protocols to update and transfer information among replicated servers in a hierarchy. DNS compromises on strong consistency to achieve high performance because data is read frequently from DNS databases as compared to writing. However, DNS provides eventual consistency and updates records on replicated servers lazily. Typically, it can take from a few seconds up to three days to update records on the DNS servers across the Internet. The time it takes to propagate information among different DNS clusters depends on the DNS infrastructure, the size of the update, and which part of the DNS tree is being updated.\nDNS 使用各种协议在层次结构中的复制服务器之间更新和传输信息。 DNS 会在强一致性方面做出妥协以实现高性能，因为与写入相比，从 DNS 数据库中读取数据的频率更高。然而，DNS 提供最终一致性并延迟更新复制服务器上的记录。通常，更新 Internet 上 DNS 服务器上的记录可能需要几秒钟到三天的时间。在不同 DNS 集群之间传播信息所需的时间取决于 DNS 基础设施、更新的大小以及正在更新 DNS 树的哪一部分。\nConsistency can suffer because of caching too. Since authoritative servers are located within the organization, it may be possible that certain resource records are updated on the authoritative servers in case of server failures at the organization. Therefore, cached records at the default/local and ISP servers may be outdated. To mitigate this issue, each cached record comes with an expiration time called time-to-live (TTL).\n由于缓存，一致性也会受到影响。由于权威服务器位于组织内，因此在组织中的服务器发生故障的情况下，权威服务器上的某些资源记录可能会被更新。因此，默认/本地和 ISP 服务器上的缓存记录可能会过时。为了缓解此问题，每个缓存记录都带有一个称为生存时间 (TTL) 的过期时间。\nQuestion\n问题\nTo maintain high availability, should the TTL value be large or small?\n为了保持高可用性，TTL值应该大还是小？\nTo maintain high availability, the TTL value should be small. This is because if any server or cluster fails, the organization can update the resource records right away. Users will experience non-availability only for the time the TTL isn’t expired. However, if the TTL is large, the organization will update its resource records, whereas users will keep pinging the outdated server that would have crashed long ago. Companies that long for high availability maintain a TTL value as low as 120 seconds. Therefore, even in case of a failure, the maximum downtime is a few minutes.\n为了保持高可用性，TTL值应该很小。这是因为如果任何服务器或集群发生故障，组织可以立即更新资源记录。仅在 TTL 未过期期间，用户才会遇到不可用的情况。然而，如果 TTL 很大，组织将更新其资源记录，而用户将继续 ping 早就崩溃的过时服务器。渴望高可用性的公司将 TTL 值维持在低至 120 秒。因此，即使发生故障，最长停机时间也只有几分钟。\nTest it out 测试一下\nLet’s run a couple of commands. Click on the terminal to execute the following commands. Copy the following commands in the terminal to run them. Study the output of the commands:\n让我们运行几个命令。单击终端以执行以下命令。在终端中复制以下命令来运行它们。研究命令的输出：\nnslookup www.google.com dig www.google.com The following slide deck highlights some important aspects of nslookup and dig output.\n以下幻灯片重点介绍了 nslookup 和 dig 输出的一些重要方面。\nLet’s go through the meaning of the output:\n我们来看看输出的含义：\nThe nslookup output nslookup 输出\nThe Non-authoritative answer, as the name suggests, is the answer provided by a server that is not the authoritative server of Google. It isn’t in the list of authoritative nameservers that Google maintains. So, where does the answer come from? The answer is provided by second, third, and fourth-hand name servers configured to reply to our DNS query—for example, our university or office DNS resolver, our ISP nameserver, our ISP’s ISP nameserver, and so on. In short, it can be considered as a cached version of Google’s authoritative nameservers response. If we try multiple domain names, we’ll realize that we receive a cached response most of the time.\nNon-authoritative answer ，顾名思义，是由非 Google 权威服务器提供的答案。它不在 Google 维护的权威域名服务器列表中。那么，答案从何而来？答案由配置为回复我们的 DNS 查询的第二手、第三手和第四手名称服务器提供，例如，我们的大学或办公室 DNS 解析器、我们的 ISP 名称服务器、我们 ISP 的 ISP 名称服务器等。简而言之，它可以被视为 Google 权威域名服务器响应的缓存版本。如果我们尝试多个域名，我们会发现大多数时候我们都会收到缓存的响应。\nIf we run the same command multiple times, we’ll receive the same IP addresses list but in a different order each time. The reason for that is DNS is indirectly performing load balancing. It’s an important term that we’ll gain familiarity with in the coming lessons.\n如果我们多次运行相同的命令，我们将收到相同的 IP 地址列表，但每次的顺序不同。原因是 DNS 间接执行负载平衡。这是一个重要的术语，我们将在接下来的课程中熟悉它。\nThe dig output dig 输出\nThe Query time: 4 msec represents the time it takes to get a response from the DNS server. For various reasons, these numbers may be different in our case.\nQuery time: 4 msec 表示从 DNS 服务器获取响应所需的时间。由于各种原因，这些数字在我们的案例中可能有所不同。\nThe 300 value in the ANSWER SECTION represents the number of seconds the cache is maintained in the DNS resolver. This means that Google’s ADNS keeps a TTL value of five minutes (300/60 sec).\nANSWER SECTION 中的 300 值表示 DNS 解析器中维护缓存的秒数。这意味着 Google 的 ADNS 将 TTL 值保持为五分钟（300/60 秒）。\nNote: We invite you to test different services for their TTL and query times to strengthen your understanding. You may use the above terminal for this purpose.\n注意：我们邀请您测试不同服务的 TTL 和查询时间，以加深您的理解。您可以使用上述终端来实现此目的。\nQuestion\n问题\nIf we need DNS to tell us which IP to reach a website or service, how will we know the DNS resolver’s IP address? (It seems like a chicken-and-egg problem!)\n如果我们需要 DNS 告诉我们哪个 IP 可以访问网站或服务，我们如何知道 DNS 解析器的 IP 地址？ （这似乎是一个先有鸡还是先有蛋的问题！）\nEnd users’ operating systems have configuration files (/etc/resolv.conf in Linux) with the DNS resolvers’ IP addresses, which in turn obtain all information for them. (Often, DHCP provides the default DNS resolver IP address along with other configurations.) The end-systems request DNS resolves for any DNS queries. DNS resolvers have special software installed to resolve queries through the DNS infrastructure. The root server’s IP addresses are within the special software. Typically, the Berkeley Internet Name Domain (BIND) software is used on DNS resolvers. The InterNIC maintains the updated list of 13 root servers.\n最终用户的操作系统具有包含 DNS 解析器 IP 地址的配置文件（Linux 中为 /etc/resolv.conf ），而 DNS 解析器又会获取其所有信息。 （通常，DHCP 提供默认 DNS 解析器 IP 地址以及其他配置。）终端系统请求 DNS 解析任何 DNS 查询。 DNS 解析器安装了特殊软件来通过 DNS 基础设施解析查询。根服务器的IP地址位于特殊软件内。通常，伯克利互联网名称域 (BIND) 软件用于 DNS 解析器。 InterNIC 维护着 13 个根服务器的更新列表。\nSo, we break the chicken-and-egg problem by seeding each resolver with prior knowledge of root DNS servers (whose IPs rarely change).\n因此，我们通过为每个解析器提供根 DNS 服务器（其 IP 很少更改）的先验知识来解决先有鸡还是先有蛋的问题。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/17/dns/","summary":"这是一篇双语翻译的文章，原文出自《Grokking the System Design Interview》教程的 Domain Name System 这篇章节。\nIntroduction to Domain Name System (DNS) 域名系统 (DNS) 简介\nThe origins of DNS DNS 的起源\nLet’s consider the example of a mobile phone where a unique number is associated with each user. To make calls to friends, we can initially try to memorize some of the phone numbers. However, as the number of contacts grows, we’ll have to use a phone book to keep track of all our contacts. This way, whenever we need to make a call, we’ll refer to the phone book and dial the number we need.\n让我们考虑一个移动电话的示例，其中每个用户都有一个唯一的号码。为了给朋友打电话，我们首先可以尝试记住一些电话号码。然而，随着联系人数量的增加，我们将不得不使用电话簿来跟踪所有联系人。这样，每当我们需要打电话时，我们都会查阅电话簿并拨打我们需要的号码。","title":"[译]《Grokking the System Design Interview》域名系统"},{"content":"如何生成一个短网址服务，参考 Design a URL Shortening Service / TinyURL 和 Designing a URL Shortening service like TinyURL 两篇文章，整理如下笔记。\n其中主要包括以下内容：\n设计一个系统有哪些步骤 需求 预估 设计 高层次设计 API 设计 细节设计 评估 设计一个短网址服务的细节 设计步骤 Requirements 需求\n功能性需求 短 URL 生成：我们的服务应该能够为给定 URL 生成唯一的较短别名。 重定向：给定一个短链接，我们的系统应该能够将用户重定向到原始 URL。 自定义短链接：用户应该能够使用我们的系统为其 URL 生成自定义短链接。 删除：在赋予权限的情况下，用户应该能够删除我们系统生成的短链接。 更新：如果有适当的权限，用户应该能够更新与短链接关联的长 URL。 过期时间：短链接必须有一个默认的过期时间，但用户应该可以根据自己的需求设置过期时间。 分功能性需求：可用性、可靠性、扩展性、可维护性、容错性 可用性：我们的系统应该具有高可用性，因为即使是第二次停机的一小部分也会导致 URL 重定向失败。由于我们系统的域位于 URL 中，因此我们没有停机时间的优势，并且我们的设计必须灌输容错条件。 可扩展性：我们的系统应该能够随着需求的增加而水平扩展。 可读性：我们的系统生成的短链接应该易于阅读、区分和输入。 延迟：系统应以低延迟执行，以便为用户提供流畅的体验。 不可预测性：从安全角度来看，我们的系统生成的短链接应该是高度不可预测的。这确保了下一个短 URL 不会连续生成，从而消除了有人猜测我们的系统已经生成或将生成的所有短 URL 的可能性。 Estimation 估计\n流量 读写比：1:100 每月请求数：2 亿 单条记录占用空间：500B 记录保存多长时间：5 年 每日活跃用户 (DAU) ：1 亿 存储 5 年记录数：2 亿 x 5 x 12 =120 亿 总存储：120 亿 x 500B= 120 亿 x 0.5KB=6TB 带宽 每秒写请求：2 亿 / 30 /24 /60 /60 = 77次/s 写入带宽：77 x 500B =38KB/s 读带宽：38 x 100 =3.8MB/s 内存：存储的 20% 每天缓存内存：77 x 100 x 24 x 3600 x 20% x 500B = 66GB 服务器： 数据量：1亿 /8000=12500 为什么按单台服务器处理并发请求 8000 计算？ Design 设计\nHigh-Level design 高层次设计\n组件\n数据库：需要数据库来存储长 URL 和相应的短 URL 的映射。 序列器：Sequencer 将提供唯一的 ID，作为每个短 URL 生成的起点。 负载均衡：各个层的负载均衡器将确保可用服务器之间的请求平稳分配。 缓存：缓存将用于存储最频繁的短 URL 相关请求。 限流器：将使用速率限制器来避免系统被利用。 服务器：用于处理和导航服务请求以及运行应用程序逻辑。 Base-58 编码器：用于将序列器的数字输出转换为更可读和更可用的字母数字形式。 设计图\nApplication Programming Interfaces (APIs) API 设计\nREST API 创建短网址 shortURL(api_dev_key, original_url, custom_alias=None, expiry_date=None) 重定向短网址 redirectURL(api_dev_key, url_key) 删除短网址 deleteURL(api_dev_key, url_key) Detailed design 详细设计\n组件 数据库：\n存储\n用户表\nID、name URL 的映射\nID、url、createDate、expireDate、userId 选择 NoSQL：\n选择 MongoDB：\n它使用领导者-跟随者协议，使得使用副本进行大量读取成为可能。 MongoDB 确保并发写入操作的原子性，并通过针对记录重复问题返回重复键错误来避免冲突。 为什么不选择 Cassandra、Riak 和 DynamoDB 等 NoSQL 数据库？\nCassandra、Riak 和 DynamoDB 等 NoSQL 数据库在读取阶段需要读取修复，因此读取写入性能较慢。\n它们是无领导者的 NoSQL 数据库，在并发写入时提供较弱的数据一致性保证。\n序列器：\n用于生成唯一 ID 的序列器 序列器生成 64 位的整数 ID，大小限制为从 1 亿到 2^63-1，最大位数为 20 表示一个十进制数字所需的位数 log2(10) ≈ 3.32 64位数值ID中的十进制数字的总位数 64/3.32 ≈ 20 将生成的 ID 转换为 58 进制，最大位数为 11 表示一个58进制数字所需的位数 log2(58) ≈ 5.8585 64位数值ID中的58进制数字的总位数 64/5.8585 ≈ 11 生命周期 可用的 ID 数量 2^64 -10^9= 18446644 亿 可以使用多少年 18446644 亿 / 24亿=7686143363.63年 Base-58 编码器 从 64 字符（包括 A-Z、a-z、0-9、 + 和 / ）删除 6 个（+、/、0 、 O 、 I 和 l）以增强可读性 负载均衡\n本地负载均衡 客户端和应用服务器之间 应用服务器和数据库服务器之间 应用服务器和缓存服务器之间 全局负载均衡 数据库地理位置一致 如果使用数据中心，则可以在短地址中添加字符表示数据中心：http://service.com/x/short123 缓存\n限制每个用户的配额 读密集型，选择 Memcached 使用 LRU 缓存来淘汰不经常访问的网址 限流器：固定窗口计数器算法\n设计图 工作流 创建短网址\n自定义非必填，别名长度不能大于 11，不能小于 3 重定向短网址\n使用 302 重定向：可以对短网址进行统计 301 永久重定向：第一次请求拿到长链接后，下次浏览器再去请求短链的话，不会向短网址服务器请求了，而是直接从浏览器的缓存里拿，减少对服务器的压力 302 临时重定向：每次去请求短链都会去请求短网址服务器（除非响应中用 Cache-Control 或 Expired 暗示浏览器进行缓存） 删除短网址\n用户通过 Rest API 删除 用户访问过期的短网址时，删除 运行定时任务，先删数据库记录，再删缓存。如果需要再保险一点，再启用延时双删，或者直接同步数据库的 binlog 来删缓存 Evaluation 评估\n高可用 每天备份存储和缓存服务器，最好一天两次 全局服务器负载平衡来处理系统的流量。 速率限制器限制每个用户的资源分配。 扩展性 数据库的水平分片。 MongoDB - 作为 NoSQL 数据库。 基于一致性哈希的数据分布。 可读性 引入 Base-58 编码器来生成短 URL。 删除非字母数字字符。 删除相似的字符。 延迟 MongoDB 低延迟和高吞吐量。 分布式缓存，最大限度减少服务延迟。 不可预计性 ID 唯一且不可预测 参考文章 Designing a URL Shortening service like TinyURL\nDesign a URL Shortening Service / TinyURL\n后端面试之系统设计-短网址（Short URL）服务怎么设计？\n[万字长文] 系统设计之路：如何设计一个URL短链服务\n短 URL 系统是怎么设计的？ - iammutex 的回答 - 知乎\n","permalink":"https://blog.chensoul.cc/posts/2023/11/17/designing-a-url-shortening-service/","summary":"如何生成一个短网址服务，参考 Design a URL Shortening Service / TinyURL 和 Designing a URL Shortening service like TinyURL 两篇文章，整理如下笔记。\n其中主要包括以下内容：\n设计一个系统有哪些步骤 需求 预估 设计 高层次设计 API 设计 细节设计 评估 设计一个短网址服务的细节 设计步骤 Requirements 需求\n功能性需求 短 URL 生成：我们的服务应该能够为给定 URL 生成唯一的较短别名。 重定向：给定一个短链接，我们的系统应该能够将用户重定向到原始 URL。 自定义短链接：用户应该能够使用我们的系统为其 URL 生成自定义短链接。 删除：在赋予权限的情况下，用户应该能够删除我们系统生成的短链接。 更新：如果有适当的权限，用户应该能够更新与短链接关联的长 URL。 过期时间：短链接必须有一个默认的过期时间，但用户应该可以根据自己的需求设置过期时间。 分功能性需求：可用性、可靠性、扩展性、可维护性、容错性 可用性：我们的系统应该具有高可用性，因为即使是第二次停机的一小部分也会导致 URL 重定向失败。由于我们系统的域位于 URL 中，因此我们没有停机时间的优势，并且我们的设计必须灌输容错条件。 可扩展性：我们的系统应该能够随着需求的增加而水平扩展。 可读性：我们的系统生成的短链接应该易于阅读、区分和输入。 延迟：系统应以低延迟执行，以便为用户提供流畅的体验。 不可预测性：从安全角度来看，我们的系统生成的短链接应该是高度不可预测的。这确保了下一个短 URL 不会连续生成，从而消除了有人猜测我们的系统已经生成或将生成的所有短 URL 的可能性。 Estimation 估计\n流量 读写比：1:100 每月请求数：2 亿 单条记录占用空间：500B 记录保存多长时间：5 年 每日活跃用户 (DAU) ：1 亿 存储 5 年记录数：2 亿 x 5 x 12 =120 亿 总存储：120 亿 x 500B= 120 亿 x 0.5KB=6TB 带宽 每秒写请求：2 亿 / 30 /24 /60 /60 = 77次/s 写入带宽：77 x 500B =38KB/s 读带宽：38 x 100 =3.","title":"如何设计一个短网址服务"},{"content":"这是一篇双语翻译的文章，原文出自《Grokking the System Design Interview》教程的 System Design Master Template 这篇章节。\nSystem design interviews are unstructured by design. In these interviews, you are asked to take on an open-ended design problem that doesn’t have a standard solution.\n系统设计面试在设计上是非结构化的。在这些面试中，您被要求解决一个没有标准解决方案的开放式设计问题。\nThe two biggest challenges of answering a system design interview question are:\n回答系统设计面试问题的两个最大挑战是：\nTo know where to start.\n知道从哪里开始。\nTo know if you have talked about all the important parts of the system.\n了解您是否已经讨论过系统的所有重要部分。\nTo simplify this process, the course offers a comprehensive system design template that can effectively guide you in addressing any system design interview question.\n为了简化这个过程，本课程提供了一个全面的系统设计模板，可以有效地指导您解决任何系统设计面试问题。\nHave a look at the following image to understand the major components that could be part of any system design and how these components interact with each other. 查看下图，了解可能成为任何系统设计一部分的主要组件以及这些组件如何相互交互。\nWith this master template in mind, we will discuss the 18 essential system design concepts. Here is a brief description of each:\n考虑到这个主模板，我们将讨论 18 个基本的系统设计概念。以下是每项的简要说明：\n1. Domain Name System (DNS) 1.域名系统（DNS）\nThe Domain Name System (DNS) serves as a fundamental component of the internet infrastructure, translating user-friendly domain names into their corresponding IP addresses. It acts as a phonebook for the internet, enabling users to access websites and services by entering easily memorable domain names, such as www.designgurus.io, rather than the numerical IP addresses like \u0026ldquo;192.0.2.1\u0026rdquo; that computers utilize to identify each other.\n域名系统 (DNS) 是互联网基础设施的基本组成部分，它将用户友好的域名转换为其相应的 IP 地址。它充当互联网的电话簿，使用户能够通过输入易于记忆的域名（例如 www.designgurus.io）来访问网站和服务，而不是计算机用来识别彼此的数字 IP 地址（例如“192.0.2.1”） 。\nWhen you input a domain name into your web browser, the DNS is responsible for finding the associated IP address and directing your request to the appropriate server. This process commences with your computer sending a query to a recursive resolver, which then searches a series of DNS servers, beginning with the root server, followed by the Top-Level Domain (TLD) server, and ultimately the authoritative name server. Once the IP address is located, the recursive resolver returns it to your computer, allowing your browser to establish a connection with the target server and access the desired content.\n当您在网络浏览器中输入域名时，DNS 负责查找关联的 IP 地址并将您的请求定向到适当的服务器。此过程首先是您的计算机向递归解析器发送查询，然后递归解析器搜索一系列 DNS 服务器，从根服务器开始，然后是顶级域 (TLD) 服务器，最后是权威名称服务器。一旦找到 IP 地址，递归解析器会将其返回到您的计算机，从而允许您的浏览器与目标服务器建立连接并访问所需的内容。\n2. Load Balancer 2.负载均衡器\nA load balancer is a networking device or software designed to distribute incoming network traffic across multiple servers, ensuring optimal resource utilization, reduced latency, and maintained high availability. It plays a crucial role in scaling applications and efficiently managing server workloads, particularly in situations where there is a sudden surge in traffic or uneven distribution of requests among servers.\n负载均衡器是一种网络设备或软件，旨在跨多个服务器分配传入的网络流量，确保最佳的资源利用率、减少延迟并保持高可用性。它在扩展应用程序和有效管理服务器工作负载方面发挥着至关重要的作用，特别是在流量突然激增或服务器之间请求分布不均匀的情况下。\nLoad balancers employ various algorithms to determine the distribution of incoming traffic. Some common algorithms include:\n负载均衡器采用各种算法来确定传入流量的分配。一些常见的算法包括：\nRound Robin: Requests are sequentially and evenly distributed across all available servers in a cyclical manner.\n循环：请求以循环方式顺序均匀地分布在所有可用服务器上。\nLeast Connections: The load balancer assigns requests to the server with the fewest active connections, giving priority to less-busy servers.\n最少连接：负载均衡器将请求分配给活动连接最少的服务器，并优先考虑不太繁忙的服务器。\nIP Hash: The client\u0026rsquo;s IP address is hashed, and the resulting value is used to determine which server the request should be directed to. This method ensures that a specific client\u0026rsquo;s requests are consistently routed to the same server, helping maintain session persistence.\nIP 哈希：对客户端的 IP 地址进行哈希处理，结果值用于确定请求应定向到哪个服务器。此方法可确保特定客户端的请求一致路由到同一服务器，从而有助于维护会话持久性。\n3. API Gateway 3.API网关\nAn API Gateway serves as a server or service that functions as an intermediary between external clients and the internal microservices or API-based backend services of an application. It is a vital component in contemporary architectures, particularly in microservices-based systems, where it streamlines the communication process and offers a single entry point for clients to access various services.\nAPI 网关充当服务器或服务，充当外部客户端与应用程序的内部微服务或基于 API 的后端服务之间的中介。它是当代架构中的重要组成部分，特别是在基于微服务的系统中，它简化了通信流程，并为客户端访问各种服务提供了单一入口点。\nThe primary functions of an API Gateway encompass:\nAPI网关的主要功能包括：\nRequest Routing: The API Gateway directs incoming API requests from clients to the appropriate backend service or microservice, based on predefined rules and configurations.\n请求路由：API 网关根据预定义的规则和配置，将来自客户端的传入 API 请求定向到适当的后端服务或微服务。\nAuthentication and Authorization: The API Gateway manages user authentication and authorization, ensuring that only authorized clients can access the services. It verifies API keys, tokens, or other credentials before routing requests to the backend services.\n身份验证和授权：API网关管理用户身份验证和授权，确保只有授权的客户端才能访问服务。它在将请求路由到后端服务之前验证 API 密钥、令牌或其他凭据。\nRate Limiting and Throttling: To safeguard backend services from excessive load or abuse, the API Gateway enforces rate limits or throttles requests from clients according to predefined policies.\n速率限制和节流：为了保护后端服务免受过度负载或滥用，API 网关根据预定义的策略强制执行速率限制或节流来自客户端的请求。\nCaching: In order to minimize latency and backend load, the API Gateway caches frequently-used responses, serving them directly to clients without the need to query the backend services.\n缓存：为了最大程度地减少延迟和后端负载，API 网关会缓存常用的响应，将其直接提供给客户端，而无需查询后端服务。\nRequest and Response Transformation: The API Gateway can modify requests and responses, such as converting data formats, adding or removing headers, or altering query parameters, to ensure compatibility between clients and services.\n请求和响应转换：API网关可以修改请求和响应，例如转换数据格式、添加或删除标头或更改查询参数，以确保客户端和服务之间的兼容性。\n4. CDN 4.CDN\nA Content Delivery Network (CDN) is a distributed network of servers that store and deliver content, such as images, videos, stylesheets, and scripts, to users from locations that are geographically closer to them. CDNs are designed to enhance the performance, speed, and reliability of content delivery to end-users, irrespective of their location relative to the origin server. Here\u0026rsquo;s how a CDN operates:\n内容交付网络 (CDN) 是一种分布式服务器网络，用于存储并向地理位置较近的用户交付内容（例如图像、视频、样式表和脚本）。 CDN 旨在增强向最终用户交付内容的性能、速度和可靠性，无论其相对于源服务器的位置如何。 CDN 的运作方式如下：\nWhen a user requests content from a website or application, the request is directed to the nearest CDN server, also known as an edge server.\n当用户从网站或应用程序请求内容时，请求将被定向到最近的 CDN 服务器（也称为边缘服务器）。\nIf the edge server has the requested content cached, it directly serves the content to the user. This process reduces latency and improves the user experience, as the content travels a shorter distance.\n如果边缘服务器缓存了所请求的内容，则它直接向用户提供内容。由于内容传输的距离较短，因此此过程减少了延迟并改善了用户体验。\nIf the content is not cached on the edge server, the CDN retrieves it from the origin server or another nearby CDN server. Once the content is fetched, it is cached on the edge server and served to the user.\n如果内容未缓存在边缘服务器上，则 CDN 会从源服务器或其他附近的 CDN 服务器检索内容。获取内容后，它会缓存在边缘服务器上并提供给用户。\nTo ensure the content stays up-to-date, the CDN periodically checks the origin server for changes and updates its cache accordingly.\n为了确保内容保持最新，CDN 定期检查源服务器是否有更改并相应更新其缓存。\n5. Forward Proxy vs. Reverse Proxy 正向代理与反向代理 A forward proxy, also referred to as a \u0026ldquo;proxy server\u0026rdquo; or simply \u0026ldquo;proxy,\u0026rdquo; is a server positioned in front of one or more client machines, acting as an intermediary between the clients and the internet. When a client machine requests a resource on the internet, the request is initially sent to the forward proxy. The forward proxy then forwards the request to the internet on behalf of the client machine and returns the response to the client machine.\n转发代理也称为“代理服务器”或简称为“代理”，是位于一台或多台客户端计算机前面的服务器，充当客户端和互联网之间的中介。当客户端计算机请求互联网上的资源时，该请求最初被发送到转发代理。然后，转发代理代表客户端计算机将请求转发到互联网，并将响应返回到客户端计算机。\nOn the other hand, a reverse proxy is a server that sits in front of one or more web servers, serving as an intermediary between the web servers and the internet. When a client requests a resource on the internet, the request is first sent to the reverse proxy. The reverse proxy then forwards the request to one of the web servers, which returns the response to the reverse proxy. Finally, the reverse proxy returns the response to the client.\n另一方面，反向代理是位于一个或多个 Web 服务器前面的服务器，充当 Web 服务器和互联网之间的中介。当客户端请求互联网上的资源时，请求首先发送到反向代理。然后，反向代理将请求转发到其中一台 Web 服务器，该服务器将响应返回给反向代理。最后，反向代理将响应返回给客户端。\n6. Caching 缓存 Cache is a high-speed storage layer positioned between the application and the original data source, such as a database, file system, or remote web service. When an application requests data, the cache is checked first. If the data is present in the cache, it is returned to the application. If the data is not found in the cache, it is retrieved from its original source, stored in the cache for future use, and then returned to the application. In a distributed system, caching can occur in multiple locations, including the client, DNS, CDN, load balancer, API gateway, server, database, and more.\n缓存是位于应用程序和原始数据源（例如数据库、文件系统或远程 Web 服务）之间的高速存储层。当应用程序请求数据时，首先检查缓存。如果数据存在于缓存中，则将其返回给应用程序。如果在缓存中找不到数据，则会从原始来源检索该数据，将其存储在缓存中以供将来使用，然后返回给应用程序。在分布式系统中，缓存可以发生在多个位置，包括客户端、DNS、CDN、负载均衡器、API 网关、服务器、数据库等。\n7. Data Partitioning 数据分区 In a database, horizontal partitioning, often referred to as sharding, entails dividing the rows of a table into smaller tables and storing them on distinct servers or database instances. This method is employed to distribute the database load across multiple servers, thereby enhancing performance.\n在数据库中，水平分区（通常称为分片）需要将表的行划分为更小的表，并将它们存储在不同的服务器或数据库实例上。该方法用于将数据库负载分散到多个服务器上，从而提高性能。\nConversely, vertical partitioning involves splitting the columns of a table into separate tables. This technique aims to reduce the column count in a table and boost the performance of queries that only access a limited number of columns.\n相反，垂直分区涉及将表的列拆分为单独的表。该技术旨在减少表中的列数并提高仅访问有限数量列的查询的性能。\n8. Database Replication 数据库复制 Database replication is a method employed to maintain multiple copies of the same database across various servers or locations. The main objective of database replication is to enhance data availability, redundancy, and fault tolerance, ensuring the system remains operational even in the face of hardware failures or other issues.\n数据库复制是一种用于跨不同服务器或位置维护同一数据库的多个副本的方法。数据库复制的主要目标是增强数据可用性、冗余和容错能力，确保系统即使在遇到硬件故障或其他问题时也能保持运行。\nIn a replicated database configuration, one server serves as the primary (or master) database, while others act as replicas (or slaves). This process involves synchronizing data between the primary database and replicas, ensuring all possess the same up-to-date information. Database replication provides several advantages, including:\n在复制数据库配置中，一台服务器充当主（或主）数据库，而其他服务器充当副本（或从）数据库。此过程涉及在主数据库和副本之间同步数据，确保所有数据库都拥有相同的最新信息。数据库复制具有多种优势，包括：\nImproved Performance: By distributing read queries among multiple replicas, the load on the primary database can be reduced, leading to faster query response times.\n提高性能：通过在多个副本之间分配读取查询，可以减少主数据库上的负载，从而加快查询响应时间。\nHigh Availability: If the primary database experiences failure or downtime, replicas can continue to provide data, ensuring uninterrupted access to the application.\n高可用性：如果主数据库出现故障或停机，副本可以继续提供数据，确保对应用程序的不间断访问。\nEnhanced Data Protection: Maintaining multiple copies of the database across different locations helps safeguard against data loss due to hardware failures or other disasters.\n增强的数据保护：在不同位置维护数据库的多个副本有助于防止由于硬件故障或其他灾难而导致的数据丢失。\nLoad Balancing: Replicas can handle read queries, allowing for better load distribution and reducing overall stress on the primary database.\n负载平衡：副本可以处理读取查询，从而实现更好的负载分配并减少主数据库的整体压力。\n9. Distributed Messaging Systems 9.分布式消息系统\nDistributed messaging systems provide a reliable, scalable, and fault-tolerant means for exchanging messages between numerous, possibly geographically-dispersed applications, services, or components. These systems facilitate communication by decoupling sender and receiver components, enabling them to develop and function independently. Distributed messaging systems are especially valuable in large-scale or intricate systems, like those seen in microservices architectures or distributed computing environments. Examples of these systems include Apache Kafka and RabbitMQ.\n分布式消息传递系统提供了一种可靠、可扩展且容错的方式，用于在众多可能在地理上分散的应用程序、服务或组件之间交换消息。这些系统通过解耦发送器和接收器组件来促进通信，使它们能够独立开发和运行。分布式消息传递系统在大规模或复杂的系统中尤其有价值，例如微服务架构或分布式计算环境中的系统。这些系统的示例包括 Apache Kafka 和 RabbitMQ。\n10. Microservices 微服务 Microservices represent an architectural style wherein an application is organized as an assembly of small, loosely-coupled, and autonomously deployable services. Each microservice is accountable for a distinct aspect of functionality or domain within the application and communicates with other microservices via well-defined APIs. This method deviates from the conventional monolithic architecture, where an application is constructed as a single, tightly-coupled unit.\n微服务代表了一种架构风格，其中应用程序被组织为小型、松散耦合且可自主部署的服务的集合。每个微服务负责应用程序内功能或领域的不同方面，并通过定义良好的 API 与其他微服务进行通信。此方法不同于传统的整体架构，在传统的整体架构中，应用程序被构建为单个紧密耦合的单元。\nThe primary characteristics of microservices include:\n微服务的主要特征包括：\nSingle Responsibility: Adhering to the Single Responsibility Principle, each microservice focuses on a specific function or domain, making the services more straightforward to comprehend, develop, and maintain.\n单一职责：遵循单一职责原则，每个微服务都专注于特定的功能或领域，使服务更易于理解、开发和维护。\nIndependence: Microservices can be independently developed, deployed, and scaled, offering increased flexibility and agility in the development process. Teams can work on various services simultaneously without impacting the entire system.\n独立性：微服务可以独立开发、部署和扩展，从而提高开发过程的灵活性和敏捷性。团队可以同时处理各种服务，而不会影响整个系统。\nDecentralization: Typically, microservices are decentralized, with each service possessing its data and business logic. This approach fosters separation of concerns and empowers teams to make decisions and select technologies tailored to their unique requirements.\n去中心化：通常，微服务是去中心化的，每个服务都拥有自己的数据和业务逻辑。这种方法促进了关注点分离，并使团队能够做出决策并选择适合其独特需求的技术。\nCommunication: Microservices interact with each other using lightweight protocols, such as HTTP/REST, gRPC, or message queues. This fosters interoperability and facilitates the integration of new services or the replacement of existing ones.\n通信：微服务使用轻量级协议（例如 HTTP/REST、gRPC 或消息队列）相互交互。这促进了互操作性并促进新服务的集成或现有服务的替换。\nFault Tolerance: As microservices are independent, the failure of one service does not necessarily result in the collapse of the entire system, enhancing the application\u0026rsquo;s overall resiliency.\n容错性：由于微服务是独立的，一个服务的故障并不一定会导致整个系统崩溃，增强了应用程序的整体弹性。\n11. NoSQL Databases 11.NoSQL 数据库\nNoSQL databases, or “Not Only SQL” databases, are non-relational databases designed to store, manage, and retrieve unstructured or semi-structured data. They offer an alternative to traditional relational databases, which rely on structured data and predefined schemas. NoSQL databases have become popular due to their flexibility, scalability, and ability to handle large volumes of data, making them well-suited for modern applications, big data processing, and real-time analytics.\nNoSQL 数据库或“Not Only SQL”数据库是非关系数据库，旨在存储、管理和检索非结构化或半结构化数据。它们提供了传统关系数据库的替代方案，传统关系数据库依赖于结构化数据和预定义模式。 NoSQL 数据库因其灵活性、可扩展性和处理大量数据的能力而变得流行，使其非常适合现代应用程序、大数据处理和实时分析。\nNoSQL databases can be categorized into four main types:\nNoSQL 数据库可分为四种主要类型：\nDocument-Based: These databases store data in document-like structures, such as JSON or BSON. Each document is self-contained and can have its own unique structure, making them suitable for handling heterogeneous data. Examples of document-based NoSQL databases include MongoDB and Couchbase.\n基于文档：这些数据库以类似文档的结构存储数据，例如 JSON 或 BSON。每个文档都是独立的，可以有自己独特的结构，使它们适合处理异构数据。基于文档的 NoSQL 数据库的示例包括 MongoDB 和 Couchbase。\nKey-Value: These databases store data as key-value pairs, where the key acts as a unique identifier, and the value holds the associated data. Key-value databases are highly efficient for simple read and write operations, and they can be easily partitioned and scaled horizontally. Examples of key-value NoSQL databases include Redis and Amazon DynamoDB.\n键值：这些数据库将数据存储为键值对，其中键充当唯一标识符，值保存关联的数据。键值数据库对于简单的读写操作非常高效，并且可以轻松地进行分区和水平扩展。键值 NoSQL 数据库的示例包括 Redis 和 Amazon DynamoDB。\nColumn-Family: These databases store data in column families, which are groups of related columns. They are designed to handle write-heavy workloads and are highly efficient for querying data with a known row and column keys. Examples of column-family NoSQL databases include Apache Cassandra and HBase.\n列族：这些数据库将数据存储在列族中，列族是相关列的组。它们旨在处理写入繁重的工作负载，并且对于使用已知的行键和列键查询数据非常高效。列族 NoSQL 数据库的示例包括 Apache Cassandra 和 HBase。\nGraph-Based: These databases are designed for storing and querying data that has complex relationships and interconnected structures, such as social networks or recommendation systems. Graph databases use nodes, edges, and properties to represent and store data, making it easier to perform complex traversals and relationship-based queries. Examples of graph-based NoSQL databases include Neo4j and Amazon Neptune.\n基于图：这些数据库旨在存储和查询具有复杂关系和互连结构的数据，例如社交网络或推荐系统。图数据库使用节点、边和属性来表示和存储数据，从而更容易执行复杂的遍历和基于关系的查询。基于图形的 NoSQL 数据库的示例包括 Neo4j 和 Amazon Neptune。\n12. Database Index 数据库索引 Database indexes are data structures that enhance the speed and efficiency of query operations within a database. They function similarly to an index in a book, enabling the database management system (DBMS) to swiftly locate data associated with a specific value or group of values, without the need to search through every row in a table. By offering a more direct route to the desired data, indexes can considerably decrease the time required to retrieve information from a database.\n数据库索引是提高数据库内查询操作速度和效率的数据结构。它们的功能类似于书中的索引，使数据库管理系统 (DBMS) 能够快速定位与特定值或一组值关联的数据，而无需搜索表中的每一行。通过提供获取所需数据的更直接途径，索引可以大大减少从数据库检索信息所需的时间。\nIndexes are typically constructed on one or more columns of a database table. The B-tree index is the most prevalent type, organizing data in a hierarchical tree structure, which allows for rapid search, insertion, and deletion operations. Other types of indexes, such as bitmap indexes and hash indexes, exist as well, each with their particular use cases and advantages.\n索引通常构建在数据库表的一列或多列上。 B 树索引是最流行的类型，以分层树结构组织数据，允许快速搜索、插入和删除操作。还存在其他类型的索引，例如位图索引和哈希索引，每种索引都有其特定的用例和优点。\nAlthough indexes can significantly enhance query performance, they also involve certain trade-offs:\n虽然索引可以显着提高查询性能，但它们也涉及某些权衡：\nStorage Space: Indexes require additional storage space since they generate and maintain separate data structures alongside the original table data.\n存储空间：索引需要额外的存储空间，因为它们与原始表数据一起生成和维护单独的数据结构。\nWrite Performance: When data is inserted, updated, or deleted in a table, the corresponding indexes must also be updated, which may slow down write operations.\n写入性能：当在表中插入、更新或删除数据时，相应的索引也必须更新，这可能会减慢写入操作。\n13. Distributed File Systems 13.分布式文件系统\nDistributed file systems are storage systems designed to manage and grant access to files and directories across multiple servers, nodes, or machines, frequently distributed across a network. They allow users and applications to access and modify files as though they were situated on a local file system, despite the fact that the actual files may be physically located on various remote servers. Distributed file systems are commonly employed in large-scale or distributed computing environments to offer fault tolerance, high availability, and enhanced performance.\n分布式文件系统是一种存储系统，旨在管理和授予对跨多个服务器、节点或机器的文件和目录的访问权限，这些服务器、节点或机器经常分布在网络上。它们允许用户和应用程序访问和修改文件，就像它们位于本地文件系统上一样，尽管实际文件可能物理上位于各种远程服务器上。分布式文件系统通常用于大规模或分布式计算环境中，以提供容错、高可用性和增强的性能。\n14. Notification System 14.通知系统\nThese are used to send notifications or alerts to users, such as emails, push notifications, or text messages.\n它们用于向用户发送通知或警报，例如电子邮件、推送通知或短信。\n15. Full-text Search 全文检索 Full-text search allows users to search for particular words or phrases within an application or website. Upon receiving a user query, the application or website delivers the most relevant results. To accomplish this rapidly and effectively, full-text search utilizes an inverted index, a data structure that associates words or phrases with the documents where they are found. Elastic Search is an example of such systems.\n全文搜索允许用户在应用程序或网站中搜索特定单词或短语。收到用户查询后，应用程序或网站会提供最相关的结果。为了快速有效地完成此任务，全文搜索使用倒排索引，这是一种将单词或短语与找到它们的文档相关联的数据结构。 Elastic Search 就是此类系统的一个示例。\n16. Distributed Coordination Services 16.分布式协调服务\nDistributed coordination services are systems engineered to regulate and synchronize the actions of distributed applications, services, or nodes in a dependable, efficient, and fault-tolerant way. They assist in maintaining consistency, addressing distributed synchronization, and overseeing the configuration and state of diverse components in a distributed setting. Distributed coordination services are especially valuable in large-scale or intricate systems, like those encountered in microservices architectures, distributed computing environments, or clustered databases. Apache ZooKeeper, etcd, and Consul are examples of such services.\n分布式协调服务是旨在以可靠、高效和容错的方式调节和同步分布式应用程序、服务或节点的操作的系统。它们有助于维护一致性、解决分布式同步以及监督分布式环境中不同组件的配置和状态。分布式协调服务在大规模或复杂的系统中尤其有价值，例如微服务架构、分布式计算环境或集群数据库中遇到的系统。 Apache ZooKeeper、etcd 和 Consul 是此类服务的示例。\n17. Heartbeat 心跳 In a distributed environment, work/data is distributed among servers. To efficiently route requests in such a setup, servers need to know what other servers are part of the system. Furthermore, servers should know if other servers are alive and working. In a decentralized system, whenever a request arrives at a server, the server should have enough information to decide which server is responsible for entertaining that request. This makes the timely detection of server failure an important task, which also enables the system to take corrective actions and move the data/work to another healthy server and stop the environment from further deterioration.\n在分布式环境中，工作/数据分布在服务器之间。为了在这样的设置中有效地路由请求，服务器需要知道系统中还有哪些其他服务器。此外，服务器应该知道其他服务器是否处于活动状态并正在工作。在去中心化系统中，每当请求到达服务器时，服务器都应该有足够的信息来决定哪个服务器负责处理该请求。这使得及时检测服务器故障成为一项重要任务，这也使系统能够采取纠正措施并将数据/工作转移到另一台健康的服务器上，并阻止环境进一步恶化。\nTo solve this, each server periodically sends a heartbeat message to a central monitoring server or other servers in the system to show that it is still alive and functioning.\n为了解决这个问题，每个服务器定期向中央监控服务器或系统中的其他服务器发送心跳消息，以表明它仍然活着并且正在运行。\nHeartbeating is one of the mechanisms for detecting failures in a distributed system. If there is a central server, all servers periodically send a heartbeat message to it. If there is no central server, all servers randomly choose a set of servers and send them a heartbeat message every few seconds. This way, if no heartbeat message is received from a server for a while, the system can suspect that the server might have crashed. If there is no heartbeat within a configured timeout period, the system can conclude that the server is not alive anymore and stop sending requests to it and start working on its replacement.\n心跳是分布式系统中检测故障的机制之一。如果有一个中心服务器，所有服务器都会定期向它发送心跳消息。如果没有中心服务器，则所有服务器随机选择一组服务器，每隔几秒向它们发送一条心跳消息。这样，如果一段时间内没有收到服务器的心跳消息，系统就会怀疑该服务器可能已经崩溃了。如果在配置的超时时间内没有心跳，系统可以断定服务器不再活动，并停止向其发送请求并开始进行替换。\n18. Checksum 校验和 In a distributed system, while moving data between components, it is possible that the data fetched from a node may arrive corrupted. This corruption can occur because of faults in a storage device, network, software, etc. How can a distributed system ensure data integrity, so that the client receives an error instead of corrupt data?\n在分布式系统中，当在组件之间移动数据时，从节点获取的数据可能会损坏。这种损坏可能是由于存储设备、网络、软件等的故障而发生的。分布式系统如何确保数据完整性，以便客户端收到错误而不是损坏的数据？\nTo solve this, we can calculate a checksum and store it with data.\n为了解决这个问题，我们可以计算校验和并将其与数据一起存储。\nTo calculate a checksum, a cryptographic hash-function like MD5, SHA-1, SHA-256, or SHA-512 is used. The hash function takes the input data and produces a string (containing letters and numbers) of fixed length; this string is called the checksum.\n要计算校验和，需要使用MD5、SHA-1、SHA-256或SHA-512等加密哈希函数。哈希函数获取输入数据并生成固定长度的字符串（包含字母和数字）；该字符串称为校验和。\nWhen a system is storing some data, it computes a checksum of the data and stores the checksum with the data. When a client retrieves data, it verifies that the data it received from the server matches the checksum stored. If not, then the client can opt to retrieve that data from another replica.\n当系统存储某些数据时，它会计算数据的校验和并将校验和与数据一起存储。当客户端检索数据时，它会验证从服务器接收的数据是否与存储的校验和匹配。如果没有，那么客户端可以选择从另一个副本检索该数据。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/16/system-design-master-template/","summary":"这是一篇双语翻译的文章，原文出自《Grokking the System Design Interview》教程的 System Design Master Template 这篇章节。\nSystem design interviews are unstructured by design. In these interviews, you are asked to take on an open-ended design problem that doesn’t have a standard solution.\n系统设计面试在设计上是非结构化的。在这些面试中，您被要求解决一个没有标准解决方案的开放式设计问题。\nThe two biggest challenges of answering a system design interview question are:\n回答系统设计面试问题的两个最大挑战是：\nTo know where to start.\n知道从哪里开始。\nTo know if you have talked about all the important parts of the system.\n了解您是否已经讨论过系统的所有重要部分。\nTo simplify this process, the course offers a comprehensive system design template that can effectively guide you in addressing any system design interview question.\n为了简化这个过程，本课程提供了一个全面的系统设计模板，可以有效地指导您解决任何系统设计面试问题。\nHave a look at the following image to understand the major components that could be part of any system design and how these components interact with each other.","title":"[译]《Grokking the System Design Interview》系统设计主模板"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing a URL Shortening service like TinyURL》设计类似 TinyURL 的 URL 缩短服务。\nLet’s design a URL shortening service like TinyURL. This service will provide short aliases redirecting to long URLs. Similar services: bit.ly, goo.gl, qlink.me, etc.\n让我们设计一个像 TinyURL 这样的 URL 缩短服务。该服务将提供重定向到长 URL 的短别名。类似服务：bit.ly、goo.gl、qlink.me等。\nDifficulty Level: Easy\n难度级别：简单\n1.Why do we need URL shortening? 1.为什么需要URL缩短？\nURL shortening is used to create shorter aliases for long URLs. We call these shortened aliases “short links.” Users are redirected to the original URL when they hit these short links. Short links save a lot of space when displayed, printed, messaged, or tweeted. Additionally, users are less likely to mistype shorter URLs.\nURL 缩短用于为长 URL 创建较短的别名。我们将这些缩短的别名称为“短链接”。当用户点击这些短链接时，他们会被重定向到原始 URL。短链接在显示、打印、消息或推文时可以节省大量空间。此外，用户不太可能错误输入较短的 URL。\nFor example, if we shorten this page through TinyURL:\n例如，如果我们通过 TinyURL 缩短这个页面：\nhttps://www.educative.io/collection/page/5668639101419520/5649050225344512/5668600916475904/\nWe would get:\n我们会得到：\nhttp://tinyurl.com/jlg8zpc\nThe shortened URL is nearly one-third the size of the actual URL.\n缩短的 URL 大小几乎是实际 URL 的三分之一。\nURL shortening is used for optimizing links across devices, tracking individual links to analyze audience and campaign performance, and hiding affiliated original URLs.\nURL 缩短用于跨设备优化链接、跟踪单个链接以分析受众和营销活动绩效以及隐藏关联的原始 URL。\nIf you haven’t used tinyurl.com before, please try creating a new shortened URL and spend some time going through the various options their service offers. This will help you a lot in understanding this chapter.\n如果您以前没有使用过 tinyurl.com，请尝试创建一个新的缩短的 URL，并花一些时间浏览他们的服务提供的各种选项。这将对你理解本章有很大帮助。\n2.Requirements and Goals of the System 2.系统的要求和目标\nYou should always clarify requirements at the beginning of the interview. Be sure to ask questions to find the exact scope of the system that the interviewer has in mind.\n您应该始终在面试开始时澄清要求。一定要通过提问来找到面试官心目中系统的确切范围。\nOur URL shortening system should meet the following requirements:\n我们的URL缩短系统应满足以下要求：\nFunctional Requirements:\n功能要求：\nGiven a URL, our service should generate a shorter and unique alias of it. This is called a short link.\n给定一个 URL，我们的服务应该生成一个更短且唯一的别名。这称为短链接。\nWhen users access a short link, our service should redirect them to the original link.\n当用户访问短链接时，我们的服务应该将他们重定向到原始链接。\nUsers should optionally be able to pick a custom short link for their URL.\n用户应该可以选择为其 URL 选择自定义短链接。\nLinks will expire after a standard default timespan. Users should be able to specify the expiration time.\n链接将在标准默认时间跨度后过期。用户应该能够指定过期时间。\nNon-Functional Requirements:\n非功能性要求：\nThe system should be highly available. This is required because, if our service is down, all the URL redirections will start failing.\n系统应该是高可用的。这是必需的，因为如果我们的服务出现故障，所有 URL 重定向都将开始失败。\nURL redirection should happen in real-time with minimal latency.\nURL 重定向应该以最小的延迟实时发生。\nShortened links should not be guessable (not predictable).\n缩短的链接不应该是可猜测的（不可预测的）。\nExtended Requirements:\n扩展要求：\nAnalytics; e.g., how many times a redirection happened?\n分析；例如，重定向发生了多少次？\nOur service should also be accessible through REST APIs by other services.\n我们的服务还应该可以由其他服务通过 REST API 访问。\n3. Capacity Estimation and Constraints 容量估计和约束 Our system will be read-heavy. There will be lots of redirection requests compared to new URL shortenings. Let’s assume 100:1 ratio between read and write.\n我们的系统读取量很大。与新的 URL 缩短相比，将会有大量的重定向请求。假设读写比率为 100:1。\nTraffic estimates: Assuming, we will have 500M new URL shortenings per month, with 100:1 read/write ratio, we can expect 50B redirections during the same period:\n流量估计：假设我们每月有 500M 新的 URL 缩短，读/写比为 100:1，我们可以预期同期有 50B 的重定向：\n100 * 500M =\u0026gt; 50B\nWhat would be Queries Per Second (QPS) for our system? New URLs shortenings per second:\n我们系统的每秒查询数 (QPS) 是多少？每秒新缩短的 URL：\n500 million / (30 days * 24 hours * 3600 seconds) = ~200 URLs/s\nConsidering 100:1 read/write ratio, URLs redirections per second will be:\n考虑到 100:1 的读/写比率，每秒 URL 重定向将为：\n100 * 200 URLs/s = 20K/s\nStorage estimates: Let’s assume we store every URL shortening request (and associated shortened link) for 5 years. Since we expect to have 500M new URLs every month, the total number of objects we expect to store will be 30 billion:\n存储估计：假设我们将每个 URL 缩短请求（以及相关的缩短链接）存储 5 年。由于我们预计每月会有 5 亿个新 URL，因此我们预计存储的对象总数将为 300 亿个：\n500 million * 5 years * 12 months = 30 billion\nLet’s assume that each stored object will be approximately 500 bytes (just a ballpark estimate–we will dig into it later). We will need 15TB of total storage:\n我们假设每个存储的对象大约有 500 字节（只是一个大概的估计——我们稍后会深入研究）。我们需要 15TB 的总存储空间：\n30 billion * 500 bytes = 15 TB\nBandwidth estimates: For write requests, since we expect 200 new URLs every second, total incoming data for our service will be 100KB per second:\n带宽估计：对于写入请求，由于我们预计每秒有 200 个新 URL，因此我们服务的总传入数据将为每秒 100KB：\n200 * 500 bytes = 100 KB/s\nFor read requests, since every second we expect ~20K URLs redirections, total outgoing data for our service would be 10MB per second:\n对于读取请求，由于我们预计每秒约有 20K 个 URL 重定向，因此我们服务的总传出数据将为每秒 10MB：\n20K * 500 bytes = ~10 MB/s\nMemory estimates: If we want to cache some of the hot URLs that are frequently accessed, how much memory will we need to store them? If we follow the 80-20 rule, meaning 20% of URLs generate 80% of traffic, we would like to cache these 20% hot URLs.\n内存估算：如果我们要缓存一些经常访问的热门 URL，我们需要多少内存来存储它们？如果我们遵循 80-20 规则，即 20% 的 URL 产生 80% 的流量，我们希望缓存这 20% 的热门 URL。\nSince we have 20K requests per second, we will be getting 1.7 billion requests per day:\n由于我们每秒有 20K 个请求，因此我们每天将收到 17 亿个请求：\n20K * 3600 seconds * 24 hours = ~1.7 billion\nTo cache 20% of these requests, we will need 170GB of memory.\n要缓存其中 20% 的请求，我们需要 170GB 内存。\n0.2 * 1.7 billion * 500 bytes = ~170GB\nOne thing to note here is that since there will be a lot of duplicate requests (of the same URL), therefore, our actual memory usage will be less than 170GB.\n这里需要注意的一点是，由于会有很多重复请求（同一 URL），因此，我们的实际内存使用量将小于 170GB。\nHigh level estimates: Assuming 500 million new URLs per month and 100:1 read:write ratio, following is the summary of the high level estimates for our service:\n高水平估计：假设每月有 5 亿个新 URL 和 100:1 的读：写比率，以下是我们服务的高水平估计的摘要：\nNew URLs 200/s URL redirections 20K/s Incoming data 100KB/s Outgoing data 10MB/s Storage for 5 years 15TB Memory for cache 170GB 4. System APIs 系统API Once we’ve finalized the requirements, it’s always a good idea to define the system APIs. This should explicitly state what is expected from the system.\n一旦我们最终确定了需求，定义系统 API 总是一个好主意。这应该明确说明系统的期望。\nWe can have SOAP or REST APIs to expose the functionality of our service. Following could be the definitions of the APIs for creating and deleting URLs:\n我们可以使用 SOAP 或 REST API 来公开我们服务的功能。以下是用于创建和删除 URL 的 API 的定义：\ncreateURL(api_dev_key, original_url, custom_alias=None, user_name=None, expire_date=None) Parameters:\n参数：\napi_dev_key (string): The API developer key of a registered account. This will be used to, among other things, throttle users based on their allocated quota.\napi_dev_key (string): 注册账户的API开发者密钥。除其他外，这将用于根据分配的配额限制用户。\noriginal_url (string): Original URL to be shortened.\ncustom_alias（字符串）：URL 的可选自定义键。\ncustom_alias (string): Optional custom key for the URL.\nOriginal_url（字符串）：要缩短的原始 URL。\nuser_name (string): Optional user name to be used in encoding.\nuser_name（字符串）：编码中使用的可选用户名。\nexpire_date (string): Optional expiration date for the shortened URL.\nexpire_date（字符串）：缩短的 URL 的可选到期日期。\nReturns: (string) A successful insertion returns the shortened URL; otherwise, it returns an error code.\n返回：（字符串）成功插入返回缩短的 URL；否则，它返回一个错误代码。\ndeleteURL(api_dev_key, url_key) Where “url_key” is a string representing the shortened URL to be retrieved. A successful deletion returns ‘URL Removed’.\n其中“url_key”是表示要检索的缩短 URL 的字符串。成功删除将返回“URL 已删除”。\nHow do we detect and prevent abuse? A malicious user can put us out of business by consuming all URL keys in the current design. To prevent abuse, we can limit users via their api_dev_key. Each api_dev_key can be limited to a certain number of URL creations and redirections per some time period (which may be set to a different duration per developer key).\n我们如何发现并防止滥用行为？ 恶意用户可以通过消耗当前设计中的所有 URL 密钥来使我们破产。为了防止滥用，我们可以通过 api_dev_key 限制用户。每个 api_dev_key 可以限制为在某个时间段内一定数量的 URL 创建和重定向（可以将每个开发人员密钥设置为不同的持续时间）。\n5. Database Design 数据库设计 Defining the DB schema in the early stages of the interview would help to understand the data flow among various components and later would guide towards data partitioning.\n在面试的早期阶段定义数据库模式将有助于理解各个组件之间的数据流，并在以后指导数据分区。\nA few observations about the nature of the data we will store:\n关于我们将存储的数据的性质的一些观察：\nWe need to store billions of records.\n我们需要存储数十亿条记录。\nEach object we store is small (less than 1K).\n我们存储的每个对象都很小（小于 1K）。\nThere are no relationships between records—other than storing which user created a URL.\n除了存储哪个用户创建了 URL 之外，记录之间没有任何关系。\nOur service is read-heavy.\n我们的服务是重读的。\nDatabase Schema:\n数据库架构：\nWe would need two tables: one for storing information about the URL mappings, and one for the user’s data who created the short link.\n我们需要两张表：一张用于存储有关 URL 映射的信息，一张用于创建短链接的用户数据。\nWhat kind of database should we use? Since we anticipate storing billions of rows, and we don’t need to use relationships between objects – a NoSQL key-value store like DynamoDB, Cassandra or Riak is a better choice. A NoSQL choice would also be easier to scale. Please see SQL vs NoSQL for more details.\n我们应该使用什么样的数据库？由于我们预计存储数十亿行，并且不需要使用对象之间的关系 - DynamoDB、Cassandra 或 Riak 等 NoSQL 键值存储是更好的选择。 NoSQL 选择也更容易扩展。请参阅 SQL 与 NoSQL 了解更多详细信息。\n6. Basic System Design and Algorithm 基本系统设计和算法 The problem we are solving here is, how to generate a short and unique key for a given URL.\n我们这里要解决的问题是，如何为给定的 URL 生成一个简短且唯一的密钥。\nIn the TinyURL example in Section 1, the shortened URL is “http://tinyurl.com/jlg8zpc”. The last six characters of this URL is the short key we want to generate. We’ll explore two solutions here:\n在第 1 节的 TinyURL 示例中，缩短的 URL 是“http://tinyurl.com/jlg8zpc”。该URL的最后六个字符是我们要生成的短密钥。我们将在这里探索两种解决方案：\na. Encoding actual URL\na. 对实际 URL 进行编码\nWe can compute a unique hash (e.g., MD5 or SHA256, etc.) of the given URL. The hash can then be encoded for displaying. This encoding could be base36 ([a-z ,0-9]) or base62 ([A-Z, a-z, 0-9]) and if we add ‘-’ and ‘.’ we can use base64 encoding. A reasonable question would be, what should be the length of the short key? 6, 8 or 10 characters.\n我们可以计算给定 URL 的唯一哈希值（例如 MD5 或 SHA256 等）。然后可以对散列进行编码以供显示。该编码可以是base36（[a-z，0-9]）或base62（[A-Z，a-z，0-9]），如果我们添加“-”和“.”，我们可以使用base64编码。一个合理的问题是，短密钥的长度应该是多少？ 6、8 或 10 个字符。\nUsing base64 encoding, a 6 letter long key would result in 64^6 = ~68.7 billion possible strings Using base64 encoding, an 8 letter long key would result in 64^8 = ~281 trillion possible strings\n使用 Base64 编码，6 个字母长的密钥将产生 64^6 = ~687 亿个可能的字符串，使用 Base64 编码，8 个字母长的密钥将产生 64^8 = ~281 万亿个可能的字符串\nWith 68.7B unique strings, let’s assume six letter keys would suffice for our system.\n对于 68.7B 的唯一字符串，我们假设六个字母键足以满足我们的系统。\nIf we use the MD5 algorithm as our hash function, it’ll produce a 128-bit hash value. After base64 encoding, we’ll get a string having more than 21 characters (since each base64 character encodes 6 bits of the hash value). Since we only have space for 8 characters per short key, how will we choose our key then? We can take the first 6 (or 8) letters for the key. This could result in key duplication though, upon which we can choose some other characters out of the encoding string or swap some characters.\n如果我们使用 MD5 算法作为哈希函数，它将产生一个 128 位的哈希值。经过base64编码后，我们将得到一个超过21个字符的字符串（因为每个 base64 字符编码哈希值的6位）。由于每个短密钥只有 8 个字符的空间，那么我们将如何选择我们的密钥呢？我们可以取前 6 个（或 8 个）字母作为密钥。但这可能会导致密钥重复，因此我们可以从编码字符串中选择一些其他字符或交换一些字符。\nWhat are different issues with our solution? We have the following couple of problems with our encoding scheme:\n我们的解决方案有哪些不同的问题？我们的编码方案存在以下几个问题：\nIf multiple users enter the same URL, they can get the same shortened URL, which is not acceptable.\n如果多个用户输入相同的 URL，他们可以获得相同的缩短的 URL，这是不可接受的。\nWhat if parts of the URL are URL-encoded? e.g., http://www.educative.io/distributed.php?id=design, and http://www.educative.io/distributed.php%3Fid%3Ddesign are identical except for the URL encoding.\n如果 URL 的一部分是 URL 编码的怎么办？例如，http://www.eduative.io/distributed.php?id=design 和 http://www.educative.io/distributed.php%3Fid%3Ddesign 除了 URL 编码之外，完全相同。\nWorkaround for the issues: We can append an increasing sequence number to each input URL to make it unique, and then generate a hash of it. We don’t need to store this sequence number in the databases, though. Possible problems with this approach could be an ever-increasing sequence number. Can it overflow? Appending an increasing sequence number will also impact the performance of the service.\n问题的解决方法：我们可以将递增的序列号附加到每个输入 URL 以使其唯一，然后生成它的哈希值。不过，我们不需要将此序列号存储在数据库中。这种方法可能出现的问题是序列号不断增加。能溢出吗？附加递增的序列号也会影响服务的性能。\nAnother solution could be to append user id (which should be unique) to the input URL. However, if the user has not signed in, we would have to ask the user to choose a uniqueness key. Even after this, if we have a conflict, we have to keep generating a key until we get a unique one.\n另一种解决方案是将用户 ID（应该是唯一的）附加到输入 URL。但是，如果用户尚未登录，我们将不得不要求用户选择唯一性密钥。即使在此之后，如果出现冲突，我们也必须继续生成密钥，直到获得唯一的密钥。\nb. Generating keys offline\nb.离线生成密钥\nWe can have a standalone Key Generation Service (KGS) that generates random six letter strings beforehand and stores them in a database (let’s call it key-DB). Whenever we want to shorten a URL, we will just take one of the already-generated keys and use it. This approach will make things quite simple and fast. Not only are we not encoding the URL, but we won’t have to worry about duplications or collisions. KGS will make sure all the keys inserted into key-DB are unique\n我们可以拥有一个独立的密钥生成服务（KGS），它预先生成随机的六个字母字符串并将它们存储在数据库中（我们称之为密钥数据库）。每当我们想要缩短 URL 时，我们只需获取已生成的密钥之一并使用它即可。这种方法将使事情变得非常简单和快速。我们不仅不对 URL 进行编码，而且不必担心重复或冲突。 KGS 将确保插入 key-DB 的所有密钥都是唯一的\nCan concurrency cause problems? As soon as a key is used, it should be marked in the database to ensure it doesn’t get used again. If there are multiple servers reading keys concurrently, we might get a scenario where two or more servers try to read the same key from the database. How can we solve this concurrency problem?\n并发会导致问题吗？密钥一旦使用，就应该在数据库中进行标记，以确保它不会被再次使用。如果有多个服务器同时读取密钥，我们可能会遇到两个或多个服务器尝试从数据库读取相同密钥的情况。我们如何解决这个并发问题呢？\nServers can use KGS to read/mark keys in the database. KGS can use two tables to store keys: one for keys that are not used yet, and one for all the used keys. As soon as KGS gives keys to one of the servers, it can move them to the used keys table. KGS can always keep some keys in memory so that it can quickly provide them whenever a server needs them.\n服务器可以使用 KGS 读取/标记数据库中的密钥。 KGS 可以使用两张表来存储密钥：一张用于尚未使用的密钥，一张用于所有已使用的密钥。一旦 KGS 向其中一台服务器提供密钥，它就可以将它们移动到已使用的密钥表中。 KGS 可以始终将一些密钥保留在内存中，以便在服务器需要时可以快速提供它们。\nFor simplicity, as soon as KGS loads some keys in memory, it can move them to the used keys table. This ensures each server gets unique keys. If KGS dies before assigning all the loaded keys to some server, we will be wasting those keys–which is acceptable, given the huge number of keys we have.\n为简单起见，一旦 KGS 将某些密钥加载到内存中，它就可以将它们移动到已使用的密钥表中。这确保每个服务器获得唯一的密钥。如果 KGS 在将所有加载的密钥分配给某个服务器之前就死掉了，我们将浪费这些密钥——考虑到我们拥有大量的密钥，这是可以接受的。\nKGS also has to make sure not to give the same key to multiple servers. For that, it must synchronize (or get a lock on) the data structure holding the keys before removing keys from it and giving them to a server\nKGS 还必须确保不要将相同的密钥提供给多个服务器。为此，它必须同步（或锁定）保存密钥的数据结构，然后再从中删除密钥并将其提供给服务器\nWhat would be the key-DB size? With base64 encoding, we can generate 68.7B unique six letters keys. If we need one byte to store one alpha-numeric character, we can store all these keys in:\n密钥数据库的大小是多少？通过 base64 编码，我们可以生成 68.7B 唯一的六个字母密钥。如果我们需要一个字节来存储一个字母数字字符，我们可以将所有这些键存储在：\n6 (characters per key) * 68.7B (unique keys) = 412 GB.\nIsn’t KGS a single point of failure? Yes, it is. To solve this, we can have a standby replica of KGS. Whenever the primary server dies, the standby server can take over to generate and provide keys.\nKGS 不是单点故障吗？是的。为了解决这个问题，我们可以拥有一个 KGS 的备用副本。每当主服务器挂掉时，备用服务器就可以接管并生成和提供密钥。\nCan each app server cache some keys from key-DB? Yes, this can surely speed things up. Although in this case, if the application server dies before consuming all the keys, we will end up losing those keys. This can be acceptable since we have 68B unique six letter keys.\n每个应用程序服务器可以缓存密钥数据库中的一些密钥吗？是的，这肯定可以加快速度。尽管在这种情况下，如果应用程序服务器在消耗所有密钥之前死亡，我们最终将丢失这些密钥。这是可以接受的，因为我们有 68B 独特的六字母键。\nHow would we perform a key lookup? We can look up the key in our database or key-value store to get the full URL. If it’s present, issue an “HTTP 302 Redirect” status back to the browser, passing the stored URL in the “Location” field of the request. If that key is not present in our system, issue an “HTTP 404 Not Found” status or redirect the user back to the homepage.\n我们如何执行键查找？我们可以在数据库或键值存储中查找键来获取完整的 URL。如果存在，则向浏览器发出“HTTP 302 重定向”状态，并在请求的“位置”字段中传递存储的 URL。如果我们的系统中不存在该密钥，请发出“HTTP 404 Not Found”状态或将用户重定向回主页。\nShould we impose size limits on custom aliases? Our service supports custom aliases. Users can pick any ‘key’ they like, but providing a custom alias is not mandatory. However, it is reasonable (and often desirable) to impose a size limit on a custom alias to ensure we have a consistent URL database. Let’s assume users can specify a maximum of 16 characters per customer key (as reflected in the above database schema).\n我们应该对自定义别名施加大小限制吗？我们的服务支持自定义别名。用户可以选择他们喜欢的任何“键”，但提供自定义别名不是强制性的。然而，对自定义别名施加大小限制以确保我们拥有一致的 URL 数据库是合理的（并且通常是可取的）。假设用户可以为每个客户密钥指定最多 16 个字符（如上面的数据库架构所示）。\nHigh level system design for URL shortening\nURL 缩短的高级系统设计\n7. Data Partitioning and Replication 数据分区和复制 To scale out our DB, we need to partition it so that it can store information about billions of URLs. We need to come up with a partitioning scheme that would divide and store our data to different DB servers.\n为了扩展我们的数据库，我们需要对其进行分区，以便它可以存储有关数十亿个 URL 的信息。我们需要提出一个分区方案，将数据划分并存储到不同的数据库服务器。\na. Range Based Partitioning: We can store URLs in separate partitions based on the first letter of the URL or the hash key. Hence we save all the URLs starting with letter ‘A’ in one partition, save those that start with letter ‘B’ in another partition and so on. This approach is called range-based partitioning. We can even combine certain less frequently occurring letters into one database partition. We should come up with a static partitioning scheme so that we can always store/find a file in a predictable manner.\na.基于范围的分区： 我们可以根据 URL 的首字母或哈希键将 URL 存储在单独的分区中。因此，我们将所有以字母“A”开头的 URL 保存在一个分区中，将那些以字母“B”开头的 URL 保存在另一个分区中，依此类推。这种方法称为基于范围的分区。我们甚至可以将某些不常出现的字母合并到一个数据库分区中。我们应该提出一个静态分区方案，以便我们始终可以以可预测的方式存储/查找文件。\nThe main problem with this approach is that it can lead to unbalanced servers. For example: we decide to put all URLs starting with letter ‘E’ into a DB partition, but later we realize that we have too many URLs that start with letter ‘E’.\n这种方法的主要问题是它可能导致服务器不平衡。例如：我们决定将所有以字母“E”开头的 URL 放入数据库分区，但后来我们意识到以字母“E”开头的 URL 太多了。\nb. Hash-Based Partitioning: In this scheme, we take a hash of the object we are storing. We then calculate which partition to use based upon the hash. In our case, we can take the hash of the ‘key’ or the actual URL to determine the partition in which we store the data object.\nb.基于哈希的分区： 在此方案中，我们采用所存储对象的哈希值。然后我们根据哈希计算要使用哪个分区。在我们的例子中，我们可以采用“键”的哈希值或实际 URL 来确定存储数据对象的分区。\nOur hashing function will randomly distribute URLs into different partitions (e.g., our hashing function can always map any key to a number between [1…256]), and this number would represent the partition in which we store our object.\n我们的哈希函数会将 URL 随机分布到不同的分区中（例如，我们的哈希函数始终可以将任何键映射到 [1…256] 之间的数字），并且该数字将代表我们存储对象的分区。\nThis approach can still lead to overloaded partitions, which can be solved by using Consistent Hashing.\n这种方法仍然会导致分区过载，这可以通过使用一致性哈希来解决。\n8. Cache 缓存 We can cache URLs that are frequently accessed. We can use some off-the-shelf solution like Memcache, which can store full URLs with their respective hashes. The application servers, before hitting backend storage, can quickly check if the cache has the desired URL.\n我们可以缓存经常访问的URL。我们可以使用一些现成的解决方案，例如 Memcache，它可以存储完整的 URL 及其各自的哈希值。应用程序服务器在访问后端存储之前，可以快速检查缓存中是否有所需的 URL。\nHow much cache should we have? We can start with 20% of daily traffic and, based on clients’ usage pattern, we can adjust how many cache servers we need. As estimated above, we need 170GB memory to cache 20% of daily traffic. Since a modern-day server can have 256GB memory, we can easily fit all the cache into one machine. Alternatively, we can use a couple of smaller servers to store all these hot URLs.\n我们应该有多少缓存？我们可以从每日流量的 20% 开始，根据客户的使用模式，我们可以调整我们需要的缓存服务器数量。根据上面的估计，我们需要 170GB 内存来缓存 20% 的日常流量。由于现代服务器可以拥有 256GB 内存，因此我们可以轻松地将所有缓存安装到一台机器中。或者，我们可以使用几个较小的服务器来存储所有这些热门 URL。\nWhich cache eviction policy would best fit our needs? When the cache is full, and we want to replace a link with a newer/hotter URL, how would we choose? Least Recently Used (LRU) can be a reasonable policy for our system. Under this policy, we discard the least recently used URL first. We can use a Linked Hash Map or a similar data structure to store our URLs and Hashes, which will also keep track of the URLs that have been accessed recently.\n哪种缓存驱逐策略最适合我们的需求？当缓存已满，并且我们想用更新/更热门的 URL 替换链接时，我们会如何选择？最近最少使用（LRU）对于我们的系统来说是一个合理的策略。根据此策略，我们首先丢弃最近最少使用的 URL。我们可以使用链接哈希映射或类似的数据结构来存储我们的 URL 和哈希，它还将跟踪最近访问过的 URL。\nTo further increase the efficiency, we can replicate our caching servers to distribute load between them.\n为了进一步提高效率，我们可以复制缓存服务器以在它们之间分配负载。\nHow can each cache replica be updated? Whenever there is a cache miss, our servers would be hitting a backend database. Whenever this happens, we can update the cache and pass the new entry to all the cache replicas. Each replica can update their cache by adding the new entry. If a replica already has that entry, it can simply ignore it.\n如何更新每个缓存副本？每当出现缓存未命中时，我们的服务器就会访问后端数据库。每当发生这种情况时，我们都可以更新缓存并将新条目传递给所有缓存副本。每个副本都可以通过添加新条目来更新其缓存。如果副本已经具有该条目，则可以简单地忽略它。\n9. Load Balancer (LB) 9.负载均衡器（LB）\nRequest flow for accessing a shortened URL\n访问缩短的 URL 的请求流程\nWe can add a Load balancing layer at three places in our system:\n我们可以在系统中的三个位置添加负载均衡层：\nBetween Clients and Application servers\n客户端和应用服务器之间\nBetween Application Servers and database servers\n应用服务器和数据库服务器之间\nBetween Application Servers and Cache servers\n应用服务器和缓存服务器之间\nInitially, we could use a simple Round Robin approach that distributes incoming requests equally among backend servers. This LB is simple to implement and does not introduce any overhead. Another benefit of this approach is that if a server is dead, LB will take it out of the rotation and will stop sending any traffic to it.\n最初，我们可以使用简单的循环方法，在后端服务器之间平均分配传入请求。该LB实现简单，不会引入任何开销。这种方法的另一个好处是，如果服务器死机，LB 会将其从轮换中删除，并停止向其发送任何流量。\nA problem with Round Robin LB is that server load is not taken into consideration. If a server is overloaded or slow, the LB will not stop sending new requests to that server. To handle this, a more intelligent LB solution can be placed that periodically queries the backend server about its load and adjusts traffic based on that.\n循环负载均衡的一个问题是没有考虑服务器负载。如果服务器过载或速度缓慢，负载均衡器不会停止向该服务器发送新请求。为了解决这个问题，可以采用更智能的负载均衡解决方案，定期查询后端服务器的负载情况，并据此调整流量。\n10. Purging or DB cleanup 清除或数据库清理 Should entries stick around forever or should they be purged? If a user-specified expiration time is reached, what should happen to the link?\n条目应该永远保留还是应该被清除？如果达到了用户指定的过期时间，链接会发生什么情况？\nIf we chose to actively search for expired links to remove them, it would put a lot of pressure on our database. Instead, we can slowly remove expired links and do a lazy cleanup. Our service will make sure that only expired links will be deleted, although some expired links can live longer but will never be returned to users.\n如果我们选择主动搜索过期链接来删除它们，这会给我们的数据库带来很大的压力。相反，我们可以慢慢删除过期链接并进行惰性清理。我们的服务将确保只删除过期的链接，尽管有些过期的链接可以存在更长的时间，但永远不会返回给用户。\nWhenever a user tries to access an expired link, we can delete the link and return an error to the user.\n每当用户尝试访问过期链接时，我们可以删除该链接并向用户返回错误。\nA separate Cleanup service can run periodically to remove expired links from our storage and cache. This service should be very lightweight and can be scheduled to run only when the user traffic is expected to be low.\n可以定期运行单独的清理服务，以从我们的存储和缓存中删除过期的链接。该服务应该非常轻量级，并且可以安排仅在预计用户流量较低时运行。\nWe can have a default expiration time for each link (e.g., two years).\n我们可以为每个链接设置一个默认的过期时间（例如两年）。\nAfter removing an expired link, we can put the key back in the key-DB to be reused.\n删除过期链接后，我们可以将密钥放回到密钥数据库中以供重复使用。\nShould we remove links that haven’t been visited in some length of time, say six months? This could be tricky. Since storage is getting cheap, we can decide to keep links forever.\n我们是否应该删除一段时间内（例如六个月）未访问过的链接？这可能会很棘手。由于存储变得越来越便宜，我们可以决定永远保留链接。\nDetailed component design for URL shortening\nURL缩短的详细组件设计\n11. Telemetry 遥测 How many times a short URL has been used, what were user locations, etc.? How would we store these statistics? If it is part of a DB row that gets updated on each view, what will happen when a popular URL is slammed with a large number of concurrent requests?\n短 URL 使用了多少次，用户位置是什么，等等？我们如何存储这些统计数据？如果它是在每个视图上更新的数据库行的一部分，那么当流行的 URL 受到大量并发请求的冲击时会发生什么？\nSome statistics worth tracking: country of the visitor, date and time of access, web page that refers the click, browser, or platform from where the page was accessed.\n一些值得跟踪的统计数据：访问者所在的国家/地区、访问日期和时间、引用点击的网页、浏览器或访问页面的平台。\n12. Security and Permissions 安全和权限 Can users create private URLs or allow a particular set of users to access a URL?\n用户能否创建私有 URL 或允许特定用户组访问 URL？\nWe can store permission level (public/private) with each URL in the database. We can also create a separate table to store UserIDs that have permission to see a specific URL. If a user does not have permission and tries to access a URL, we can send an error (HTTP 401) back. Given that we are storing our data in a NoSQL wide-column database like Cassandra, the key for the table storing permissions would be the ‘Hash’ (or the KGS generated ‘key’). The columns will store the UserIDs of those users that have permissions to see the URL.\n我们可以在数据库中存储每个 URL 的权限级别（公共/私有）。我们还可以创建一个单独的表来存储有权查看特定 URL 的 UserID。如果用户没有权限并尝试访问 URL，我们可以发回错误 (HTTP 401)。鉴于我们将数据存储在像 Cassandra 这样的 NoSQL 宽列数据库中，表存储权限的密钥将是“哈希”（或 KGS 生成的“密钥”）。这些列将存储有权查看 URL 的用户的 UserID。\n参考文章\nDesigning a URL Shortening service like TinyURL Design a URL Shortening Service / TinyURL ","permalink":"https://blog.chensoul.cc/posts/2023/11/16/designing-a-url-shortening-service/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《Designing a URL Shortening service like TinyURL》设计类似 TinyURL 的 URL 缩短服务。\nLet’s design a URL shortening service like TinyURL. This service will provide short aliases redirecting to long URLs. Similar services: bit.ly, goo.gl, qlink.me, etc.\n让我们设计一个像 TinyURL 这样的 URL 缩短服务。该服务将提供重定向到长 URL 的短别名。类似服务：bit.ly、goo.gl、qlink.me等。\nDifficulty Level: Easy\n难度级别：简单\n1.Why do we need URL shortening? 1.为什么需要URL缩短？\nURL shortening is used to create shorter aliases for long URLs. We call these shortened aliases “short links.” Users are redirected to the original URL when they hit these short links. Short links save a lot of space when displayed, printed, messaged, or tweeted. Additionally, users are less likely to mistype shorter URLs.","title":"[译]《Grokking the System Design Interview》设计类似 TinyURL 的 URL 缩短服务"},{"content":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《System Design Interviews: A step by step guide》系统设计访谈：分步指南。\nA lot of software engineers struggle with system design interviews (SDIs) primarily because of three reasons:\n许多软件工程师在系统设计面试（SDI）中遇到困难，主要是因为以下三个原因：\nThe unstructured nature of SDIs, where they are asked to work on an open-ended design problem that doesn’t have a standard answer.\nSDI 的非结构化性质，要求他们解决没有标准答案的开放式设计问题。\nTheir lack of experience in developing large scale systems.\n他们缺乏开发大型系统的经验。\nThey did not prepare for SDIs.\n他们没有为 SDI 做好准备。\nLike coding interviews, candidates who haven’t put a conscious effort to prepare for SDIs, mostly perform poorly especially at top companies like Google, Facebook, Amazon, Microsoft, etc. In these companies, candidates who don’t perform above average, have a limited chance to get an offer. On the other hand, a good performance always results in a better offer (higher position and salary), since it shows the candidate’s ability to handle a complex system.\n与编码面试一样，没有刻意准备 SDI 的候选人大多表现不佳，尤其是在 Google、Facebook、亚马逊、微软等顶级公司。在这些公司中，表现不高于平均水平的候选人获得报价的机会有限。另一方面，良好的表现总是会带来更好的工作机会（更高的职位和薪水），因为它显示了候选人处理复杂系统的能力。\nIn this course, we’ll follow a step by step approach to solve multiple design problems. First, let’s go through these steps:\n在本课程中，我们将遵循逐步的方法来解决多个设计问题。首先，让我们完成以下步骤：\nStep 1: Requirements clarifications 步骤 1：需求澄清\nIt is always a good idea to ask questions about the exact scope of the problem we are solving. Design questions are mostly open-ended, and they don’t have ONE correct answer, that’s why clarifying ambiguities early in the interview becomes critical. Candidates who spend enough time to define the end goals of the system always have a better chance to be successful in the interview. Also, since we only have 35-40 minutes to design a (supposedly) large system, we should clarify what parts of the system we will be focusing on.\n询问我们正在解决的问题的确切范围总是一个好主意。设计问题大多是开放式的，并且没有一个正确的答案，这就是为什么在面试初期澄清歧义变得至关重要。花足够时间来定义系统最终目标的候选人总是有更好的机会在面试中取得成功。另外，由于我们只有 35-40 分钟的时间来设计一个（据称）大型系统，因此我们应该明确我们将重点关注系统的哪些部分。\nLet’s expand this with an actual example of designing a Twitter-like service. Here are some questions for designing Twitter that should be answered before moving on to the next steps:\n让我们通过设计类似 Twitter 的服务的实际示例来扩展这一点。以下是设计 Twitter 时应回答的一些问题，然后再继续下一步：\nWill users of our service be able to post tweets and follow other people?\n我们服务的用户能够发布推文并关注其他人吗？\nShould we also design to create and display the user’s timeline?\n我们还应该设计创建和显示用户的时间线吗？\nWill tweets contain photos and videos?\n推文会包含照片和视频吗？\nAre we focusing on the backend only or are we developing the front-end too?\n我们只关注后端还是也开发前端？\nWill users be able to search tweets?\n用户能够搜索推文吗？\nDo we need to display hot trending topics?\n我们需要展示热门话题吗？\nWill there be any push notification for new (or important) tweets?\n新的（或重要的）推文会有推送通知吗？\nAll such question will determine how our end design will look like.\n所有这些问题将决定我们的最终设计会是什么样子。\nStep 2: System interface definition 步骤2 ：系统接口定义\nDefine what APIs are expected from the system. This will not only establish the exact contract expected from the system, but will also ensure if we haven’t gotten any requirements wrong. Some examples for our Twitter-like service will be:\n定义系统期望提供哪些 API。这不仅可以建立系统所期望的准确合同，而且还可以确保我们没有错误地提出任何要求。我们类似 Twitter 的服务的一些示例如下：\npostTweet(user_id, tweet_data, tweet_location, user_location, timestamp, ...) generateTimeline(user_id, current_time, user_location, ...) markTweetFavorite(user_id, tweet_id, timestamp, ...) Step 3: Back-of-the-envelope estimation 步骤 3：粗略估计\nIt is always a good idea to estimate the scale of the system we’re going to design. This will also help later when we will be focusing on scaling, partitioning, load balancing and caching.\n估计我们要设计的系统的规模总是一个好主意。当我们稍后关注扩展、分区、负载平衡和缓存时，这也会有所帮助。\nWhat scale is expected from the system (e.g., number of new tweets, number of tweet views, number of timeline generations per sec., etc.)?\n系统的预期规模是多少（例如，新推文数量、推文浏览量、每秒生成的时间线数量等）？\nHow much storage will we need? We will have different numbers if users can have photos and videos in their tweets.\n我们需要多少存储空间？如果用户的推文中可以包含照片和视频，我们将得到不同的数字。\nWhat network bandwidth usage are we expecting? This will be crucial in deciding how we will manage traffic and balance load between servers.\n我们期望使用多少网络带宽？这对于决定我们如何管理流量和平衡服务器之间的负载至关重要。\nStep 4: Defining data model 步骤 4：定义数据模型\nDefining the data model early will clarify how data will flow among different components of the system. Later, it will guide towards data partitioning and management. The candidate should be able to identify various entities of the system, how they will interact with each other, and different aspect of data management like storage, transportation, encryption, etc. Here are some entities for our Twitter- like service:\n尽早定义数据模型将阐明数据如何在系统的不同组件之间流动。稍后，它将指导数据分区和管理。考生应该能够识别系统的各种实体，它们如何相互交互，以及数据管理的不同方面，如存储、传输、加密等。以下是我们类似 Twitter 服务的一些实体：\nUser: UserID, Name, Email, DoB, CreationDate, LastLogin, etc.\nTweet: TweetID, Content, TweetLocation, NumberOfLikes, TimeStamp, etc.\nUserFollow: UserID1, UserID2\nFavoriteTweets: UserID, TweetID, TimeStamp\nWhich database system should we use? Will NoSQL like Cassandra best fit our needs, or should we use a MySQL-like solution? What kind of block storage should we use to store photos and videos?\n我们应该使用哪种数据库系统？像 Cassandra 这样的 NoSQL 是否最适合我们的需求，或者我们应该使用类似 MySQL 的解决方案？我们应该使用什么样的块存储来存储照片和视频？\nStep 5: High-level design 步骤 5：高层设计\nDraw a block diagram with 5-6 boxes representing the core components of our system. We should identify enough components that are needed to solve the actual problem from end-to-end.\n绘制一个框图，其中 5-6 个方框代表我们系统的核心组件。我们应该确定端到端解决实际问题所需的足够组件。\nFor Twitter, at a high-level, we will need multiple application servers to serve all the read/write requests with load balancers in front of them for traffic distributions. If we’re assuming that we will have a lot more read traffic (as compared to write), we can decide to have separate servers for handling these scenarios. On the backend, we need an efficient database that can store all the tweets and can support a huge number of reads. We will also need a distributed file storage system for storing photos and videos.\n对于 Twitter，在较高层面上，我们需要多个应用程序服务器来服务所有读/写请求，并在它们前面提供负载均衡器以进行流量分配。如果我们假设我们将有更多的读取流量（与写入相比），我们可以决定使用单独的服务器来处理这些场景。在后端，我们需要一个高效的数据库来存储所有的推文，并且可以支持海量读取。我们还需要一个分布式文件存储系统来存储照片和视频。\nStep 6: Detailed design 步骤 6：详细设计\nDig deeper into two or three components; interviewer’s feedback should always guide us what parts of the system need further discussion. We should be able to present different approaches, their pros and cons, and explain why we will prefer one approach on the other. Remember there is no single answer, the only important thing is to consider tradeoffs between different options while keeping system constraints in mind.\n深入挖掘两个或三个组件；面试官的反馈应该始终指导我们系统的哪些部分需要进一步讨论。我们应该能够展示不同的方法及其优缺点，并解释为什么我们更喜欢一种方法而不是另一种方法。请记住，没有单一的答案，唯一重要的是考虑不同选项之间的权衡，同时牢记系统约束。\nSince we will be storing a massive amount of data, how should we partition our data to distribute it to multiple databases? Should we try to store all the data of a user on the same database? What issue could it cause?\n由于我们将存储大量数据，我们应该如何对数据进行分区以将其分布到多个数据库？我们是否应该尝试将用户的所有数据存储在同一个数据库中？它可能会导致什么问题？\nHow will we handle hot users who tweet a lot or follow lots of people?\n我们将如何处理经常发推文或关注很多人的热门用户？\nSince users’ timeline will contain the most recent (and relevant) tweets, should we try to store our data in such a way that is optimized for scanning the latest tweets?\n由于用户的时间线将包含最新的（和相关的）推文，我们是否应该尝试存储我们的数据是否以针对扫描最新推文进行优化的方式？\nHow much and at which layer should we introduce cache to speed things up?\n我们应该在多大程度上以及在哪一层引入缓存来加快速度？\nWhat components need better load balancing?\n哪些组件需要更好的负载平衡？\nStep 7: Identifying and resolving bottlenecks 步骤 7：识别并解决瓶颈\nTry to discuss as many bottlenecks as possible and different approaches to mitigate them.\n尝试讨论尽可能多的瓶颈以及缓解瓶颈的不同方法。\nIs there any single point of failure in our system? What are we doing to mitigate it?\n我们的系统中是否存在单点故障？我们正在采取什么措施来缓解这种情况？\nDo we have enough replicas of the data so that if we lose a few servers we can still serve our users?\n我们是否有足够的数据副本，以便在失去一些服务器时我们仍然可以为我们的服务提供服务用户？\nSimilarly, do we have enough copies of different services running such that a few failures will not cause total system shutdown?\n同样，我们是否有足够的运行不同服务的副本，以便少数故障会发生不会导致整个系统关闭吗？\nHow are we monitoring the performance of our service? Do we get alerts whenever critical components fail or their performance degrades?\n我们如何监控我们的服务表现？我们是否会在关键时刻收到警报组件出现故障或性能下降？\nSummary 概括\nIn short, preparation and being organized during the interview are the keys to be successful in system design interviews. The above-mentioned steps should guide you to remain on track and cover all the different aspects while designing a system.\n简而言之，面试过程中的准备和组织是系统设计面试成功的关键。上述步骤应指导您在设计系统时保持正轨并涵盖所有不同方面。\nLet’s apply the above guidelines to design a few systems that are asked in SDIs.\n让我们应用上述指南来设计 SDI 中要求的一些系统。\n参考文章：\nhttps://www.designgurus.io/course-play/grokking-the-system-design-interview/doc/638c0b5aac93e7ae59a1af63 ","permalink":"https://blog.chensoul.cc/posts/2023/11/16/sdi-a-step-by-step-guide/","summary":"这是一篇双语翻译的文章，原文出自 grok_system_design_interview.pdf 的一篇文章《System Design Interviews: A step by step guide》系统设计访谈：分步指南。\nA lot of software engineers struggle with system design interviews (SDIs) primarily because of three reasons:\n许多软件工程师在系统设计面试（SDI）中遇到困难，主要是因为以下三个原因：\nThe unstructured nature of SDIs, where they are asked to work on an open-ended design problem that doesn’t have a standard answer.\nSDI 的非结构化性质，要求他们解决没有标准答案的开放式设计问题。\nTheir lack of experience in developing large scale systems.\n他们缺乏开发大型系统的经验。\nThey did not prepare for SDIs.\n他们没有为 SDI 做好准备。\nLike coding interviews, candidates who haven’t put a conscious effort to prepare for SDIs, mostly perform poorly especially at top companies like Google, Facebook, Amazon, Microsoft, etc. In these companies, candidates who don’t perform above average, have a limited chance to get an offer.","title":"[译]《Grokking the System Design Interview》系统设计访谈：分步指南"},{"content":"什么是分布式系统？ 分布式系统是指由多个独立的计算机节点（或服务器）通过网络相互连接和协作，共同完成某个任务或提供某个服务的系统。在分布式系统中，各个节点可以同时进行计算、存储和通信，并通过消息传递等方式进行协调和同步。\n分布式系统的设计目标是提高系统的性能、可靠性和可扩展性，同时减少单点故障和提高系统的容错性。通过将任务和数据分布到多个节点上，分布式系统可以实现更高的并行性和处理能力。此外，分布式系统还可以提供更好的负载均衡，以应对不断增长的工作负载。\n分布式系统的主要特征 分布式系统具有以下主要特征：\n分布性：分布式系统中的计算机节点分布在不同的物理或逻辑位置上，可以是同一局域网内的多台机器，也可以是分布在全球不同地区的服务器。 并行性：分布式系统中的节点可以同时进行计算和处理任务，从而实现并行处理和提高系统的性能。并行性可以通过将任务划分为子任务，并在不同节点上并行执行来实现。 通信：分布式系统通过网络进行节点之间的通信和数据传输，以实现协作和信息交换。节点之间的通信可以通过消息传递、远程过程调用（RPC）或分布式共享内存等方式实现。 缺乏全局时钟：由于节点之间的通信延迟和不可靠性，分布式系统往往无法依赖全局时钟来进行同步。因此，分布式系统需要采用一些分布式算法来实现一致性和协调，如分布式锁、一致性协议等。 容错性：分布式系统需要具备容错机制，以应对节点故障、网络故障或其他异常情况。容错性的实现通常包括备份和冗余，例如使用冗余节点、数据复制和副本机制，以确保系统的可用性和数据的完整性。 可扩展性：分布式系统应具备良好的可扩展性，即能够方便地扩展节点数量和处理能力，以适应不断增长的工作负载。可扩展性的实现可能包括水平扩展、垂直扩展、负载均衡等技术手段。 不确定性：由于节点之间的通信延迟和不可靠性，分布式系统中的操作可能存在不确定性。例如，消息传递可能会有延迟，网络可能会发生分区，导致节点之间的信息不一致。因此，分布式系统需要考虑和处理这种不确定性情况。 这些特征使得分布式系统能够实现高性能、高可用性和可扩展性，但也带来了挑战，如一致性问题、并发控制、故障处理等。因此，在设计和开发分布式系统时，需要考虑这些特征，并选择合适的技术和算法来解决相关问题。\n分布式系统面临的问题 分布式系统面临的问题包括以下几个方面：\n一致性问题：在分布式系统中，数据的复制和同步是一个挑战。节点之间的数据复制可能存在延迟和不一致性，需要采用合适的复制策略和同步机制，如主从复制、多主复制、一致性哈希等。 并发控制：在分布式系统中，多个节点同时对共享资源进行读写操作可能导致并发冲突和数据不一致。并发控制机制，如分布式锁、版本控制、乐观并发控制等，用于确保对共享资源的访问是安全和有序的。 故障处理和容错性：分布式系统中的节点可能会发生故障，如节点崩溃、网络分区等，这可能导致数据丢失或系统不可用。为了保证系统的可用性和数据的完整性，需要采用故障检测和恢复机制，如心跳检测、故障转移、数据备份等。 分布式系统的可扩展性：随着用户和数据量的增长，分布式系统需要能够方便地扩展节点数量和处理能力。设计和实现具有良好可扩展性的分布式系统需要考虑负载均衡、数据分片、分布式缓存等技术手段。 监控和管理：在分布式系统中，由于节点数量众多，监控和管理变得更加复杂。需要建立有效的监控系统来收集和分析系统的运行状态和性能指标，并采用自动化的管理工具来管理节点、配置和部署系统。 衡量分布式系统的指标 衡量分布式系统性能和质量的指标可以包括以下几个方面：\n可用性：指系统处于正常运行状态的时间比例。如果用户无法访问系统，则称系统不可用。通常以百分比（如99.9%）表示。较高的可用性意味着系统更可靠，用户能够更稳定地访问和使用系统。\n从技术角度来看，可用性主要与容错性有关。因为故障发生的概率随着组件数量的增加而增加，系统应该能够进行补偿，以确保随着组件数量的增加，系统的可靠性不会降低。\n容错性是指系统在发生故障时仍能以明确定义的方式继续运行的能力。\n**可扩展性：衡量分布式系统在面对不断增长的工作负载时，能够方便地扩展节点数量和处理能力的能力。**可扩展性可以包括水平扩展（增加节点数量）和垂直扩展（增加节点的处理能力）。\n**一致性：表示分布式系统中的数据副本在不同节点之间保持一致的程度。**较高的一致性意味着系统中的数据在不同节点上的访问结果是相同的，而较低的一致性可能导致数据不一致的情况。\n**可靠性：表示分布式系统在面对节点故障、网络故障或其他异常情况时能够继续正常运行的能力。**可靠性通常与容错性相关，包括故障检测、故障转移、数据备份等机制。\n性能：是指计算机系统在使用的时间和资源相对于所完成的有用工作量来衡量的特征。\n吞吐量：表示分布式系统在单位时间内能够处理的请求或事务数量。吞吐量越高，系统的处理能力越强，能够更高效地处理用户请求和数据处理任务。 响应时间：表示分布式系统对于用户请求的响应速度。较低的响应时间意味着系统能够更快地响应用户请求，提供更好的用户体验。 并发性能：衡量系统在处理并发请求时的能力。较好的并发性能意味着系统能够同时处理多个请求，并保持较低的响应时间和高吞吐量。 总结 任何计算机系统都需要完成两个基本任务：\n存储 计算 随着任务规模变大：\n1、使用单台计算机，硬件升级，成本过高 2、使用多台计算机，使用中档、大众化的硬件，成本降低 使用多台计算机存在如下特征：\n分布性。计算机节点分布在不同的位置。 并行性。计算机节点可以同时进行计算和处理任务。 可扩展性：可以添加节点，提高处理能力。 不确定性。由于节点之间通信有延迟或者存在故障，会导致消息传递有延迟、节点信息存在不一致 使用多台计算机面临的问题：\n节点的数量。\n数量变多，增加系统故障概率，可能导致数据丢失或系统不可用。 数量变多，并行读写数据，会导致并发冲突和数据不一致。 节点之间的距离。\n每个节点的时钟不同步，会导致网络延迟 节点之间数据需要复制和同步，会导致数据不一致性。 节点之间距离变远，会降低某些操作的性能。 所以，分布式系统要提供以下能力：\n可用性。 可扩展性。可以增加节点数量和提高节点处理能力。 一致性。提高数据一致性。 可靠性。系统故障时，仍然能正常运行。 性能。 ","permalink":"https://blog.chensoul.cc/posts/2023/11/14/distributed-system-basic/","summary":"什么是分布式系统？ 分布式系统是指由多个独立的计算机节点（或服务器）通过网络相互连接和协作，共同完成某个任务或提供某个服务的系统。在分布式系统中，各个节点可以同时进行计算、存储和通信，并通过消息传递等方式进行协调和同步。\n分布式系统的设计目标是提高系统的性能、可靠性和可扩展性，同时减少单点故障和提高系统的容错性。通过将任务和数据分布到多个节点上，分布式系统可以实现更高的并行性和处理能力。此外，分布式系统还可以提供更好的负载均衡，以应对不断增长的工作负载。\n分布式系统的主要特征 分布式系统具有以下主要特征：\n分布性：分布式系统中的计算机节点分布在不同的物理或逻辑位置上，可以是同一局域网内的多台机器，也可以是分布在全球不同地区的服务器。 并行性：分布式系统中的节点可以同时进行计算和处理任务，从而实现并行处理和提高系统的性能。并行性可以通过将任务划分为子任务，并在不同节点上并行执行来实现。 通信：分布式系统通过网络进行节点之间的通信和数据传输，以实现协作和信息交换。节点之间的通信可以通过消息传递、远程过程调用（RPC）或分布式共享内存等方式实现。 缺乏全局时钟：由于节点之间的通信延迟和不可靠性，分布式系统往往无法依赖全局时钟来进行同步。因此，分布式系统需要采用一些分布式算法来实现一致性和协调，如分布式锁、一致性协议等。 容错性：分布式系统需要具备容错机制，以应对节点故障、网络故障或其他异常情况。容错性的实现通常包括备份和冗余，例如使用冗余节点、数据复制和副本机制，以确保系统的可用性和数据的完整性。 可扩展性：分布式系统应具备良好的可扩展性，即能够方便地扩展节点数量和处理能力，以适应不断增长的工作负载。可扩展性的实现可能包括水平扩展、垂直扩展、负载均衡等技术手段。 不确定性：由于节点之间的通信延迟和不可靠性，分布式系统中的操作可能存在不确定性。例如，消息传递可能会有延迟，网络可能会发生分区，导致节点之间的信息不一致。因此，分布式系统需要考虑和处理这种不确定性情况。 这些特征使得分布式系统能够实现高性能、高可用性和可扩展性，但也带来了挑战，如一致性问题、并发控制、故障处理等。因此，在设计和开发分布式系统时，需要考虑这些特征，并选择合适的技术和算法来解决相关问题。\n分布式系统面临的问题 分布式系统面临的问题包括以下几个方面：\n一致性问题：在分布式系统中，数据的复制和同步是一个挑战。节点之间的数据复制可能存在延迟和不一致性，需要采用合适的复制策略和同步机制，如主从复制、多主复制、一致性哈希等。 并发控制：在分布式系统中，多个节点同时对共享资源进行读写操作可能导致并发冲突和数据不一致。并发控制机制，如分布式锁、版本控制、乐观并发控制等，用于确保对共享资源的访问是安全和有序的。 故障处理和容错性：分布式系统中的节点可能会发生故障，如节点崩溃、网络分区等，这可能导致数据丢失或系统不可用。为了保证系统的可用性和数据的完整性，需要采用故障检测和恢复机制，如心跳检测、故障转移、数据备份等。 分布式系统的可扩展性：随着用户和数据量的增长，分布式系统需要能够方便地扩展节点数量和处理能力。设计和实现具有良好可扩展性的分布式系统需要考虑负载均衡、数据分片、分布式缓存等技术手段。 监控和管理：在分布式系统中，由于节点数量众多，监控和管理变得更加复杂。需要建立有效的监控系统来收集和分析系统的运行状态和性能指标，并采用自动化的管理工具来管理节点、配置和部署系统。 衡量分布式系统的指标 衡量分布式系统性能和质量的指标可以包括以下几个方面：\n可用性：指系统处于正常运行状态的时间比例。如果用户无法访问系统，则称系统不可用。通常以百分比（如99.9%）表示。较高的可用性意味着系统更可靠，用户能够更稳定地访问和使用系统。\n从技术角度来看，可用性主要与容错性有关。因为故障发生的概率随着组件数量的增加而增加，系统应该能够进行补偿，以确保随着组件数量的增加，系统的可靠性不会降低。\n容错性是指系统在发生故障时仍能以明确定义的方式继续运行的能力。\n**可扩展性：衡量分布式系统在面对不断增长的工作负载时，能够方便地扩展节点数量和处理能力的能力。**可扩展性可以包括水平扩展（增加节点数量）和垂直扩展（增加节点的处理能力）。\n**一致性：表示分布式系统中的数据副本在不同节点之间保持一致的程度。**较高的一致性意味着系统中的数据在不同节点上的访问结果是相同的，而较低的一致性可能导致数据不一致的情况。\n**可靠性：表示分布式系统在面对节点故障、网络故障或其他异常情况时能够继续正常运行的能力。**可靠性通常与容错性相关，包括故障检测、故障转移、数据备份等机制。\n性能：是指计算机系统在使用的时间和资源相对于所完成的有用工作量来衡量的特征。\n吞吐量：表示分布式系统在单位时间内能够处理的请求或事务数量。吞吐量越高，系统的处理能力越强，能够更高效地处理用户请求和数据处理任务。 响应时间：表示分布式系统对于用户请求的响应速度。较低的响应时间意味着系统能够更快地响应用户请求，提供更好的用户体验。 并发性能：衡量系统在处理并发请求时的能力。较好的并发性能意味着系统能够同时处理多个请求，并保持较低的响应时间和高吞吐量。 总结 任何计算机系统都需要完成两个基本任务：\n存储 计算 随着任务规模变大：\n1、使用单台计算机，硬件升级，成本过高 2、使用多台计算机，使用中档、大众化的硬件，成本降低 使用多台计算机存在如下特征：\n分布性。计算机节点分布在不同的位置。 并行性。计算机节点可以同时进行计算和处理任务。 可扩展性：可以添加节点，提高处理能力。 不确定性。由于节点之间通信有延迟或者存在故障，会导致消息传递有延迟、节点信息存在不一致 使用多台计算机面临的问题：\n节点的数量。\n数量变多，增加系统故障概率，可能导致数据丢失或系统不可用。 数量变多，并行读写数据，会导致并发冲突和数据不一致。 节点之间的距离。\n每个节点的时钟不同步，会导致网络延迟 节点之间数据需要复制和同步，会导致数据不一致性。 节点之间距离变远，会降低某些操作的性能。 所以，分布式系统要提供以下能力：\n可用性。 可扩展性。可以增加节点数量和提高节点处理能力。 一致性。提高数据一致性。 可靠性。系统故障时，仍然能正常运行。 性能。 ","title":"分布式基础知识"},{"content":"我一直在思考分布式系统工程师在工作中学到的教训。我们大部分的教导都来自于在生产环境中犯过的错误留下的伤痕。这些伤痕固然是有用的提醒，但让更多的工程师能够完整地保留手指会更好。\n新的系统工程师在自我学习中会遇到分布式计算的谬论和CAP定理。但这些都是抽象的概念，缺乏针对经验不足的工程师直接可行的建议。让人惊讶的是，新工程师在开始工作时所了解到的背景信息是如此之少。\n下面是我作为一名分布式系统工程师学到的一些经验教训，值得告诉新工程师。其中一些经验是微妙的，一些是令人惊讶的，但没有一条是有争议的。这个列表是为了引导新的分布式系统工程师思考他们所从事领域的问题，虽然不是全面的，但是是一个很好的开始。\n这个列表最糟糕的特点是它主要关注技术问题，很少讨论工程师可能遇到的社交问题。由于分布式系统需要更多的机器和资本，它们的工程师往往需要与更多的团队和更大的组织合作。社交问题通常是任何软件开发者工作中最困难的部分，也许对于分布式系统的开发来说尤其如此。\n我们的背景、教育和经验使我们倾向于采用技术解决方案，即使社交解决方案可能更高效、更令人满意。让我们试着纠正这一点。与计算机相比，人们并不那么挑剔，即使他们的接口没有那么标准化。\n好了，我们开始吧。\n分布式系统是不同的，因为它们经常失败。 当被问及是什么将分布式系统与软件工程的其他领域区分开来时，这位新工程师经常引用延迟，认为这是使分布式计算变得困难的原因。\n但他们错了。分布式系统工程的区别在于失败的概率，更糟糕的是，部分失败的概率。如果格式良好的互斥锁解锁失败并出现错误，我们可以假设该过程不稳定并使其崩溃。但是，分布式互斥锁解锁的失败必须内置到锁定协议中。\n没有从事过分布式计算的系统工程师会想出一些想法，比如“好吧，它只是将写入发送到两台机器”或“它会不断重试写入，直到它成功”。这些工程师还没有完全接受（尽管他们通常在理智上认识到）网络系统比只存在于一台机器上的系统更容易失败，而且故障往往是部分的而不是全部的。\n其中一个写入可能会成功，而另一个写入失败，那么现在我们如何获得一致的数据视图呢？这些部分故障更难推理。\n交换机故障、垃圾回收暂停导致领导者“消失”、套接字写操作似乎成功但实际上在另一台机器上失败、一台机器上的慢速磁盘驱动引起整个集群中的通信协议变慢等等。从本地内存读取比通过几个交换机读取更稳定。。\n为失败而设计！\n编写健壮的分布式系统比编写健壮的单机系统成本更高。 与单机解决方案相比，创建强大的分布式解决方案需要更多的资金，因为只有许多计算机才会发生故障。虚拟机和云技术使分布式系统工程更便宜，但不像能够在您已经拥有的计算机上进行设计、实施和测试那样便宜。并且存在难以在单台机器上复制的故障条件。\n无论是因为它们只发生在比共享机器上可以容纳的数据集大小大得多的数据集上，还是在数据中心的网络条件下，分布式系统往往需要实际的（而不是模拟的）分发来清除它们的错误。当然，模拟非常有用。\n健壮的开源分布式系统远不如健壮的单机系统常见。长时间运行多台机器的成本是开源社区的负担。业余爱好者和业余爱好者是开源软件的引擎，他们没有可用的财务资源来探索或解决分布式系统将遇到的许多问题。业余爱好者在空闲时间使用他们已经拥有的机器编写开源代码以取乐。\n要找到愿意启动、维护和支付一堆机器的开源开发人员要困难得多。\n为公司实体工作的工程师已经填补了部分空缺。但是，其组织的优先级可能与组织的优先级不一致。\n虽然开源社区中的一些人已经意识到了这个问题，但它还没有得到解决。这很难。\n协调非常困难。 尽可能避免协调机器。这通常被描述为“水平可伸缩性”。水平可扩展性的真正诀窍是独立性——能够将数据传送到机器上，从而将这些机器之间的通信和共识保持在最低限度。每当两台机器必须就某件事达成一致时，服务就会变得更难实现。\n信息的传播速度是有上限的，网络通信比你想象的要脆弱，你对什么是共识的想法可能是错误的。在这里，了解 Two Generals 和 拜占庭将军 的问题很有用。（哦，Paxos真的很难实现；这不是脾气暴躁的老工程师认为他们比你更了解。）\n如果你能把你的问题放在内存中，那可能是微不足道的。 对于分布式系统工程师来说，一台机器的本地问题很容易解决。当数据距离几个开关而不是几个指针取消引用时，弄清楚如何快速处理数据会更难。在分布式系统中，自计算机科学开始以来就记录的陈旧效率技巧不再适用。\n对于在单台机器上运行的算法，有大量的文献和实现，因为大部分计算都是在单一的、不协调的机器上完成的。对于分布式系统来说，存在的数量要少得多。\n“很慢”是你调试过的最难的问题。 “速度慢”可能意味着执行用户请求所涉及的一个或多个系统速度较慢。这可能意味着跨多台计算机的转换管道的一个或多个部分速度较慢。“它很慢”很难，部分原因是问题陈述没有提供很多关于缺陷位置的线索。部分故障，即那些没有出现在你通常查找的图表上的故障，潜伏在一个黑暗的角落里。\n而且，在退化变得非常明显之前，您将无法获得那么多的资源（时间、金钱和工具）来解决它。Dapper 和 Zipkin 的出现是有原因的。\n**在整个系统中实现反压机制。**反压是服务系统向请求系统发出故障信号，并由请求系统处理这些故障以防止自身和服务系统过载。设计反压意味着在负载过重和系统故障时限制资源使用。这是创建健壮的分布式系统的基本构建块之一。\n实现反压通常涉及以下两种方式之一：要么将新消息丢弃，要么在资源受限或发生故障时将错误返回给用户（并在两种情况下增加指标）。对于与其他系统的连接和请求，超时和指数退避也是至关重要的。\n如果没有反压机制，可能会发生级联故障或意外消息丢失。当一个系统无法处理另一个系统的故障时，它倾向于将故障传播给依赖它的另一个系统。\n寻找实现部分可用性的方法。 部分可用性是指即使系统的某些部分发生故障，仍能返回一些结果。\n搜索是一个理想的案例来探讨这个问题。搜索系统在结果质量和用户等待时间之间进行权衡。一个典型的搜索系统会设置一个时间限制，如果在搜索所有文档之前超过了时间限制，它会返回已经收集到的结果。这使得搜索在面对间歇性减速和错误时更容易扩展，因为这些故障被视为无法搜索所有文档的情况。系统允许返回部分结果给用户，并增加了其弹性。\n再以Web应用程序中的私密消息功能为例。无论你做什么，私密消息的存储机器都可能同时宕机，用户会注意到这一点。那么在这个系统中，我们希望出现什么样的部分故障呢？\n这需要一些思考。一般来说，人们对于无法使用私密消息功能（或许是其他一些用户也无法使用）会更容忍，而对于所有用户中有一些消息丢失则更为不满意。如果服务过载或其中一台机器故障，只让一小部分用户无法使用比让更大比例的用户丢失数据更可取。除此之外，我们可能不希望一个无关的功能（比如公共图片上传）受到影响，只因为私密消息功能出现问题。我们愿意付出多少努力来保持这些故障域的独立？\n能够在部分可用性中识别这些权衡是很有帮助的。\n指标是完成工作的唯一途径。 公开指标（如延迟百分比、特定操作的计数器增加、变化速率等）是弥合您对系统在生产环境中所做的假设与实际情况之间差距的唯一途径。了解系统在第20天的行为与第15天的行为有何不同，是成功工程和失败巫术之间的区别。当然，指标是了解问题和行为的必要手段，但并不足以知道接下来该做什么。\n稍微提一下日志记录。日志文件是很有用的，但它们往往会欺骗人。例如，很常见的情况是几个错误类别的日志记录占据了日志文件的很大比例，但实际上在请求中的比例非常低。因为在大多数情况下记录成功是多余的（并且在大多数情况下会耗尽磁盘空间），而且工程师经常错误地猜测哪些错误类别是有用的，所以日志文件中充斥着各种奇怪的信息。最好以一种假设有人会阅读日志但没有看过代码的方式进行日志记录。\n我见过很多次由于另一位工程师（或者我自己）过于强调日志中的一些奇怪现象而导致故障延长，而没有先将其与指标进行对比。我还见过另一位工程师（或者我自己）从少数几行日志中推断出整套失败行为的情况。但请注意：a) 我们之所以记住这些成功案例，是因为它们非常罕见；b) 除非指标或实验证实了故事，否则你并不是福尔摩斯（Sherlock）。\n使用百分位数而不是平均值。 在绝大多数分布式系统中，百分位数（50th、99th、99.9th、99.99th）比平均值更准确、更有信息量。使用平均值假设正在评估的指标遵循正态分布曲线，但在实践中，这只适用于少数工程师关心的指标。 \u0026ldquo;平均延迟\u0026rdquo; 是一个常见的报告指标，但我从未见过一个延迟遵循正态分布曲线的分布式系统。如果指标不遵循正态分布曲线，平均值就没有意义，会导致错误的决策和理解。通过使用百分位数来避免这个陷阱。默认使用百分位数，你将更好地了解用户真正看待你的系统的方式。\n学会估算你的容量。 因此，你将会知道一天有多少秒。知道你需要多少台机器来执行一个任务是一个持久系统和一个在工作开始3个月后需要被替换的系统之间的区别。或者更糟糕的是，在你完成将其投入生产之前就需要被替换。\n以推文为例。在一台普通的机器上，你可以将多少个推文ID存放在内存中? 嗯，到2012年底，一台典型的机器有24 GB的内存，你需要4-5 GB的开销来运行操作系统，另外还需要至少几个GB来处理请求，而一个推文ID占用8个字节。这是你可能会进行的粗略计算。Jeff Dean的《每个人都应该知道的数字》幻灯片是一个很好的期望设定工具。\n特性标志（Feature flags）是基础设施推出的方式。 特性标志是产品工程师在系统中推出新功能的常用方式。特性标志通常与前端A/B测试相关联，用于向部分用户展示新的设计或功能。但它们也是替换基础设施的强大方式。\n很多项目因为选择了“大切换”或一系列“大切换”，然后由于发现了太晚的错误而被迫回滚，从而导致失败。通过使用特性标志，你将增强对项目的信心并减轻失败的成本。\n假设你要从单一数据库迁移到一个隐藏了新存储解决方案细节的服务。使用特性标志，你可以逐步将写操作转移到新服务，与对旧数据库的写操作并行进行，以确保其写路径的正确性和速度足够快。在写路径达到100%并将数据回填到服务的数据存储完成后，你可以使用单独的特性标志开始从该服务读取，而不在用户响应中使用该数据，以检查性能问题。另一个特性标志可以用于比较从旧系统和新系统读取的数据。最后一个标志可以用于逐步增加从新系统进行“真实”读取操作。\n通过将部署拆分为多个步骤，并通过特性标志提供快速和部分反应，你可以更容易地在扩展过程中发现错误和性能问题，而不是在“一次性发布”时发现。如果出现问题，你只需立即将特性标志设置降低到较低（可能是零）的设置。通过调整速率，你可以在不同的流量量级下进行调试和实验，知道任何问题都不会造成灾难。使用特性标志，你还可以选择其他迁移策略，例如基于每个用户的方式将请求转移到新系统，以提供对新系统的更好洞察。当你的新服务仍在原型阶段时，你可以将特性标志设置为较低，以减少新系统的资源消耗。\n现在，特性标志对于经典训练的开发人员或新工程师来说可能听起来像是一堆条件语句的可怕混乱。而使用特性标志意味着接受多个基础设施和数据版本是一种常态，而不是罕见情况。这是一个深刻的教训。在单机系统中有效的方法在面对分布式问题时有时会失败。\n特性标志最好被理解为一种权衡，以在代码和一个系统中交换局部复杂性，以获得全局的简单性和弹性。\n**明智地选择ID空间。 **你为系统选择的ID空间将塑造你的系统。\n要获取数据所需的ID数量越多，就越有选择将数据进行分区的选项。要获取数据所需的ID数量越少，消费你的系统输出就越容易。\n以Twitter API的第一个版本为例。所有获取、创建和删除推文的操作都是基于每个推文的单个数字ID进行的。推文ID是一个简单的64位数字，不与任何其他数据相关联。随着推文数量的增加，人们意识到，如果将同一用户的所有推文存储在同一台机器上，可以有效地构建用户的推文时间线和其他用户订阅的时间线。\n但公共API要求每个推文只能通过推文ID进行访问。要按用户对推文进行分区，需要构建一个查找服务，它知道哪个用户拥有哪个推文ID。如果必要，这是可行的，但成本不可忽视。\n另一种选择是在任何推文查找时要求用户ID，并且最初只是使用推文ID进行存储，直到用户分区存储上线。另一种选择是在推文ID本身中包含用户ID，这样做的代价是推文ID不再具有k-sortable和数字的特性。\n要注意在ID中明确和隐含地编码了哪种类型的信息。客户端可能利用ID的结构来去匿名化私人数据，以意想不到的方式爬取你的系统（自增ID通常是一个痛点），或进行其他一系列攻击。\n利用数据局部性。 将数据的处理和缓存与其持久存储保持靠近，处理效率更高，同时保持缓存一致性和快速性更容易。与指针解引用和fread（3）相比，网络故障和延迟更多。\n当然，数据局部性意味着在空间上靠近，但也意味着在时间上靠近。如果多个用户几乎同时进行相同的昂贵请求，也许可以将它们的请求合并为一个请求。如果在相近的时间内发出了多个相同类型的数据请求，可以将它们合并为一个更大的请求。这样做通常可以降低通信开销并更容易进行故障管理。\n**将缓存数据写回持久存储是不好的。 **这种情况在比想象中更多的系统中发生。尤其是那些最初由缺乏分布式系统经验的人设计的系统。你将继承许多具有此缺陷的系统。如果实施者谈到“俄罗斯套娃缓存”，你很有可能遇到非常明显的错误。这个条目本可以从列表中省略，但我对此特别痛恨。这种缺陷的常见表现是用户信息（例如屏幕名称、电子邮件和哈希密码）神秘地恢复到先前的值。\n计算机的能力超乎你的想象。 现在的现场存在很多关于机器能力的错误信息，这些信息来自于没有太多经验的从业者。\n在2012年底，轻型Web服务器拥有6个或更多处理器，24GB内存和比你能使用的更多磁盘空间。在现代语言运行时环境中，一个相对复杂的CRUD应用程序在单个机器上可以在几百毫秒内轻松处理数千个请求每秒。这还只是下限。在大多数情况下，每台机器每秒处理数百个请求并不值得夸耀。\n获得更高的性能并不难，尤其是如果你愿意对应用程序进行性能分析，并根据测量结果引入效率。\n**利用CAP定理对系统进行批判。 **CAP定理不能用作构建系统的基础。它不是一个可以作为第一原则并从中推导出一个可行系统的定理。它的适用范围过于广泛，可能的解决方案空间也过于宽泛。\n然而，CAP定理非常适合用于对分布式系统设计进行批判，并理解需要做出的权衡。通过对系统设计进行迭代，考虑CAP对其子系统施加的约束，最终可以得到更好的设计。作业中，将CAP定理的约束应用于俄罗斯套娃缓存的实际实现。\n最后需要注意的是：在一致性（C）、可用性（A）和分区容忍性（P）中，不能选择CA。\n**提取服务。 **这里的\u0026quot;服务\u0026quot;指的是\u0026quot;一个包含高级逻辑的分布式系统，通常具有请求-响应式的API\u0026quot;。要留意那些如果存在于一个单独的服务中而不是你的系统中，将更容易进行的代码更改。\n提取出一个服务提供了封装的好处，通常与创建库相提并论。然而，提取出一个服务改进了创建库的方式，因为它允许更快、更容易地部署变更，而不像升级客户系统中的库那样麻烦。（当然，如果提取出的服务难以部署，那么客户系统将变得更容易部署。）这种便利是由于较小、提取出的服务中的代码和操作依赖较少，并且其创建的严格边界使得很难\u0026quot;走捷径\u0026quot;，而库则允许这种走捷径。这些走捷径通常会使迁移内部或客户系统到新版本变得更加困难。\n当存在多个客户系统时，使用服务的协调成本也比使用共享库要低得多。即使不需要进行API更改，升级库也需要协调每个客户系统的部署。如果部署次序颠倒，可能会导致数据损坏（而且很难预测这种情况），这使得升级库变得更加困难。如果客户系统由不同的维护者负责，升级库的社交协调成本也比部署服务更高。让其他人意识到并愿意升级是非常困难的，因为他们的优先事项可能与你的不一致。\n典型的服务使用案例是隐藏一个将要进行变更的存储层。提取出的服务具有更方便且表面积更小的API，与其前端的存储层相比。通过提取服务，客户系统无需了解迁移到新的存储系统或格式的复杂性，只需要评估新服务中肯定会发现的与新存储布局相关的错误。\n在执行此操作时，需要考虑许多操作和社交问题。在这里无法对它们进行充分阐述。需要撰写另一篇文章对此进行详细说明。\n我对我的审稿人Bill de hÓra、Coda Hale、JD Maturen、Micaela McDonald和Ted Nyman表示衷心感谢。你们的见解和关心是无价的。\n更新（2016-08-15）：我为每个部分添加了永久链接，并对协调、数据本地性、功能标志和背压等部分的文本进行了一些清理。\n原文链接：Notes on Distributed Systems for Young Bloods\n","permalink":"https://blog.chensoul.cc/posts/2023/11/10/notes-on-distributed-systems-for-young-bloods/","summary":"我一直在思考分布式系统工程师在工作中学到的教训。我们大部分的教导都来自于在生产环境中犯过的错误留下的伤痕。这些伤痕固然是有用的提醒，但让更多的工程师能够完整地保留手指会更好。\n新的系统工程师在自我学习中会遇到分布式计算的谬论和CAP定理。但这些都是抽象的概念，缺乏针对经验不足的工程师直接可行的建议。让人惊讶的是，新工程师在开始工作时所了解到的背景信息是如此之少。\n下面是我作为一名分布式系统工程师学到的一些经验教训，值得告诉新工程师。其中一些经验是微妙的，一些是令人惊讶的，但没有一条是有争议的。这个列表是为了引导新的分布式系统工程师思考他们所从事领域的问题，虽然不是全面的，但是是一个很好的开始。\n这个列表最糟糕的特点是它主要关注技术问题，很少讨论工程师可能遇到的社交问题。由于分布式系统需要更多的机器和资本，它们的工程师往往需要与更多的团队和更大的组织合作。社交问题通常是任何软件开发者工作中最困难的部分，也许对于分布式系统的开发来说尤其如此。\n我们的背景、教育和经验使我们倾向于采用技术解决方案，即使社交解决方案可能更高效、更令人满意。让我们试着纠正这一点。与计算机相比，人们并不那么挑剔，即使他们的接口没有那么标准化。\n好了，我们开始吧。\n分布式系统是不同的，因为它们经常失败。 当被问及是什么将分布式系统与软件工程的其他领域区分开来时，这位新工程师经常引用延迟，认为这是使分布式计算变得困难的原因。\n但他们错了。分布式系统工程的区别在于失败的概率，更糟糕的是，部分失败的概率。如果格式良好的互斥锁解锁失败并出现错误，我们可以假设该过程不稳定并使其崩溃。但是，分布式互斥锁解锁的失败必须内置到锁定协议中。\n没有从事过分布式计算的系统工程师会想出一些想法，比如“好吧，它只是将写入发送到两台机器”或“它会不断重试写入，直到它成功”。这些工程师还没有完全接受（尽管他们通常在理智上认识到）网络系统比只存在于一台机器上的系统更容易失败，而且故障往往是部分的而不是全部的。\n其中一个写入可能会成功，而另一个写入失败，那么现在我们如何获得一致的数据视图呢？这些部分故障更难推理。\n交换机故障、垃圾回收暂停导致领导者“消失”、套接字写操作似乎成功但实际上在另一台机器上失败、一台机器上的慢速磁盘驱动引起整个集群中的通信协议变慢等等。从本地内存读取比通过几个交换机读取更稳定。。\n为失败而设计！\n编写健壮的分布式系统比编写健壮的单机系统成本更高。 与单机解决方案相比，创建强大的分布式解决方案需要更多的资金，因为只有许多计算机才会发生故障。虚拟机和云技术使分布式系统工程更便宜，但不像能够在您已经拥有的计算机上进行设计、实施和测试那样便宜。并且存在难以在单台机器上复制的故障条件。\n无论是因为它们只发生在比共享机器上可以容纳的数据集大小大得多的数据集上，还是在数据中心的网络条件下，分布式系统往往需要实际的（而不是模拟的）分发来清除它们的错误。当然，模拟非常有用。\n健壮的开源分布式系统远不如健壮的单机系统常见。长时间运行多台机器的成本是开源社区的负担。业余爱好者和业余爱好者是开源软件的引擎，他们没有可用的财务资源来探索或解决分布式系统将遇到的许多问题。业余爱好者在空闲时间使用他们已经拥有的机器编写开源代码以取乐。\n要找到愿意启动、维护和支付一堆机器的开源开发人员要困难得多。\n为公司实体工作的工程师已经填补了部分空缺。但是，其组织的优先级可能与组织的优先级不一致。\n虽然开源社区中的一些人已经意识到了这个问题，但它还没有得到解决。这很难。\n协调非常困难。 尽可能避免协调机器。这通常被描述为“水平可伸缩性”。水平可扩展性的真正诀窍是独立性——能够将数据传送到机器上，从而将这些机器之间的通信和共识保持在最低限度。每当两台机器必须就某件事达成一致时，服务就会变得更难实现。\n信息的传播速度是有上限的，网络通信比你想象的要脆弱，你对什么是共识的想法可能是错误的。在这里，了解 Two Generals 和 拜占庭将军 的问题很有用。（哦，Paxos真的很难实现；这不是脾气暴躁的老工程师认为他们比你更了解。）\n如果你能把你的问题放在内存中，那可能是微不足道的。 对于分布式系统工程师来说，一台机器的本地问题很容易解决。当数据距离几个开关而不是几个指针取消引用时，弄清楚如何快速处理数据会更难。在分布式系统中，自计算机科学开始以来就记录的陈旧效率技巧不再适用。\n对于在单台机器上运行的算法，有大量的文献和实现，因为大部分计算都是在单一的、不协调的机器上完成的。对于分布式系统来说，存在的数量要少得多。\n“很慢”是你调试过的最难的问题。 “速度慢”可能意味着执行用户请求所涉及的一个或多个系统速度较慢。这可能意味着跨多台计算机的转换管道的一个或多个部分速度较慢。“它很慢”很难，部分原因是问题陈述没有提供很多关于缺陷位置的线索。部分故障，即那些没有出现在你通常查找的图表上的故障，潜伏在一个黑暗的角落里。\n而且，在退化变得非常明显之前，您将无法获得那么多的资源（时间、金钱和工具）来解决它。Dapper 和 Zipkin 的出现是有原因的。\n**在整个系统中实现反压机制。**反压是服务系统向请求系统发出故障信号，并由请求系统处理这些故障以防止自身和服务系统过载。设计反压意味着在负载过重和系统故障时限制资源使用。这是创建健壮的分布式系统的基本构建块之一。\n实现反压通常涉及以下两种方式之一：要么将新消息丢弃，要么在资源受限或发生故障时将错误返回给用户（并在两种情况下增加指标）。对于与其他系统的连接和请求，超时和指数退避也是至关重要的。\n如果没有反压机制，可能会发生级联故障或意外消息丢失。当一个系统无法处理另一个系统的故障时，它倾向于将故障传播给依赖它的另一个系统。\n寻找实现部分可用性的方法。 部分可用性是指即使系统的某些部分发生故障，仍能返回一些结果。\n搜索是一个理想的案例来探讨这个问题。搜索系统在结果质量和用户等待时间之间进行权衡。一个典型的搜索系统会设置一个时间限制，如果在搜索所有文档之前超过了时间限制，它会返回已经收集到的结果。这使得搜索在面对间歇性减速和错误时更容易扩展，因为这些故障被视为无法搜索所有文档的情况。系统允许返回部分结果给用户，并增加了其弹性。\n再以Web应用程序中的私密消息功能为例。无论你做什么，私密消息的存储机器都可能同时宕机，用户会注意到这一点。那么在这个系统中，我们希望出现什么样的部分故障呢？\n这需要一些思考。一般来说，人们对于无法使用私密消息功能（或许是其他一些用户也无法使用）会更容忍，而对于所有用户中有一些消息丢失则更为不满意。如果服务过载或其中一台机器故障，只让一小部分用户无法使用比让更大比例的用户丢失数据更可取。除此之外，我们可能不希望一个无关的功能（比如公共图片上传）受到影响，只因为私密消息功能出现问题。我们愿意付出多少努力来保持这些故障域的独立？\n能够在部分可用性中识别这些权衡是很有帮助的。\n指标是完成工作的唯一途径。 公开指标（如延迟百分比、特定操作的计数器增加、变化速率等）是弥合您对系统在生产环境中所做的假设与实际情况之间差距的唯一途径。了解系统在第20天的行为与第15天的行为有何不同，是成功工程和失败巫术之间的区别。当然，指标是了解问题和行为的必要手段，但并不足以知道接下来该做什么。\n稍微提一下日志记录。日志文件是很有用的，但它们往往会欺骗人。例如，很常见的情况是几个错误类别的日志记录占据了日志文件的很大比例，但实际上在请求中的比例非常低。因为在大多数情况下记录成功是多余的（并且在大多数情况下会耗尽磁盘空间），而且工程师经常错误地猜测哪些错误类别是有用的，所以日志文件中充斥着各种奇怪的信息。最好以一种假设有人会阅读日志但没有看过代码的方式进行日志记录。\n我见过很多次由于另一位工程师（或者我自己）过于强调日志中的一些奇怪现象而导致故障延长，而没有先将其与指标进行对比。我还见过另一位工程师（或者我自己）从少数几行日志中推断出整套失败行为的情况。但请注意：a) 我们之所以记住这些成功案例，是因为它们非常罕见；b) 除非指标或实验证实了故事，否则你并不是福尔摩斯（Sherlock）。\n使用百分位数而不是平均值。 在绝大多数分布式系统中，百分位数（50th、99th、99.9th、99.99th）比平均值更准确、更有信息量。使用平均值假设正在评估的指标遵循正态分布曲线，但在实践中，这只适用于少数工程师关心的指标。 \u0026ldquo;平均延迟\u0026rdquo; 是一个常见的报告指标，但我从未见过一个延迟遵循正态分布曲线的分布式系统。如果指标不遵循正态分布曲线，平均值就没有意义，会导致错误的决策和理解。通过使用百分位数来避免这个陷阱。默认使用百分位数，你将更好地了解用户真正看待你的系统的方式。\n学会估算你的容量。 因此，你将会知道一天有多少秒。知道你需要多少台机器来执行一个任务是一个持久系统和一个在工作开始3个月后需要被替换的系统之间的区别。或者更糟糕的是，在你完成将其投入生产之前就需要被替换。\n以推文为例。在一台普通的机器上，你可以将多少个推文ID存放在内存中? 嗯，到2012年底，一台典型的机器有24 GB的内存，你需要4-5 GB的开销来运行操作系统，另外还需要至少几个GB来处理请求，而一个推文ID占用8个字节。这是你可能会进行的粗略计算。Jeff Dean的《每个人都应该知道的数字》幻灯片是一个很好的期望设定工具。\n特性标志（Feature flags）是基础设施推出的方式。 特性标志是产品工程师在系统中推出新功能的常用方式。特性标志通常与前端A/B测试相关联，用于向部分用户展示新的设计或功能。但它们也是替换基础设施的强大方式。\n很多项目因为选择了“大切换”或一系列“大切换”，然后由于发现了太晚的错误而被迫回滚，从而导致失败。通过使用特性标志，你将增强对项目的信心并减轻失败的成本。\n假设你要从单一数据库迁移到一个隐藏了新存储解决方案细节的服务。使用特性标志，你可以逐步将写操作转移到新服务，与对旧数据库的写操作并行进行，以确保其写路径的正确性和速度足够快。在写路径达到100%并将数据回填到服务的数据存储完成后，你可以使用单独的特性标志开始从该服务读取，而不在用户响应中使用该数据，以检查性能问题。另一个特性标志可以用于比较从旧系统和新系统读取的数据。最后一个标志可以用于逐步增加从新系统进行“真实”读取操作。\n通过将部署拆分为多个步骤，并通过特性标志提供快速和部分反应，你可以更容易地在扩展过程中发现错误和性能问题，而不是在“一次性发布”时发现。如果出现问题，你只需立即将特性标志设置降低到较低（可能是零）的设置。通过调整速率，你可以在不同的流量量级下进行调试和实验，知道任何问题都不会造成灾难。使用特性标志，你还可以选择其他迁移策略，例如基于每个用户的方式将请求转移到新系统，以提供对新系统的更好洞察。当你的新服务仍在原型阶段时，你可以将特性标志设置为较低，以减少新系统的资源消耗。\n现在，特性标志对于经典训练的开发人员或新工程师来说可能听起来像是一堆条件语句的可怕混乱。而使用特性标志意味着接受多个基础设施和数据版本是一种常态，而不是罕见情况。这是一个深刻的教训。在单机系统中有效的方法在面对分布式问题时有时会失败。\n特性标志最好被理解为一种权衡，以在代码和一个系统中交换局部复杂性，以获得全局的简单性和弹性。\n**明智地选择ID空间。 **你为系统选择的ID空间将塑造你的系统。\n要获取数据所需的ID数量越多，就越有选择将数据进行分区的选项。要获取数据所需的ID数量越少，消费你的系统输出就越容易。\n以Twitter API的第一个版本为例。所有获取、创建和删除推文的操作都是基于每个推文的单个数字ID进行的。推文ID是一个简单的64位数字，不与任何其他数据相关联。随着推文数量的增加，人们意识到，如果将同一用户的所有推文存储在同一台机器上，可以有效地构建用户的推文时间线和其他用户订阅的时间线。\n但公共API要求每个推文只能通过推文ID进行访问。要按用户对推文进行分区，需要构建一个查找服务，它知道哪个用户拥有哪个推文ID。如果必要，这是可行的，但成本不可忽视。\n另一种选择是在任何推文查找时要求用户ID，并且最初只是使用推文ID进行存储，直到用户分区存储上线。另一种选择是在推文ID本身中包含用户ID，这样做的代价是推文ID不再具有k-sortable和数字的特性。\n要注意在ID中明确和隐含地编码了哪种类型的信息。客户端可能利用ID的结构来去匿名化私人数据，以意想不到的方式爬取你的系统（自增ID通常是一个痛点），或进行其他一系列攻击。\n利用数据局部性。 将数据的处理和缓存与其持久存储保持靠近，处理效率更高，同时保持缓存一致性和快速性更容易。与指针解引用和fread（3）相比，网络故障和延迟更多。\n当然，数据局部性意味着在空间上靠近，但也意味着在时间上靠近。如果多个用户几乎同时进行相同的昂贵请求，也许可以将它们的请求合并为一个请求。如果在相近的时间内发出了多个相同类型的数据请求，可以将它们合并为一个更大的请求。这样做通常可以降低通信开销并更容易进行故障管理。\n**将缓存数据写回持久存储是不好的。 **这种情况在比想象中更多的系统中发生。尤其是那些最初由缺乏分布式系统经验的人设计的系统。你将继承许多具有此缺陷的系统。如果实施者谈到“俄罗斯套娃缓存”，你很有可能遇到非常明显的错误。这个条目本可以从列表中省略，但我对此特别痛恨。这种缺陷的常见表现是用户信息（例如屏幕名称、电子邮件和哈希密码）神秘地恢复到先前的值。\n计算机的能力超乎你的想象。 现在的现场存在很多关于机器能力的错误信息，这些信息来自于没有太多经验的从业者。\n在2012年底，轻型Web服务器拥有6个或更多处理器，24GB内存和比你能使用的更多磁盘空间。在现代语言运行时环境中，一个相对复杂的CRUD应用程序在单个机器上可以在几百毫秒内轻松处理数千个请求每秒。这还只是下限。在大多数情况下，每台机器每秒处理数百个请求并不值得夸耀。\n获得更高的性能并不难，尤其是如果你愿意对应用程序进行性能分析，并根据测量结果引入效率。\n**利用CAP定理对系统进行批判。 **CAP定理不能用作构建系统的基础。它不是一个可以作为第一原则并从中推导出一个可行系统的定理。它的适用范围过于广泛，可能的解决方案空间也过于宽泛。\n然而，CAP定理非常适合用于对分布式系统设计进行批判，并理解需要做出的权衡。通过对系统设计进行迭代，考虑CAP对其子系统施加的约束，最终可以得到更好的设计。作业中，将CAP定理的约束应用于俄罗斯套娃缓存的实际实现。\n最后需要注意的是：在一致性（C）、可用性（A）和分区容忍性（P）中，不能选择CA。\n**提取服务。 **这里的\u0026quot;服务\u0026quot;指的是\u0026quot;一个包含高级逻辑的分布式系统，通常具有请求-响应式的API\u0026quot;。要留意那些如果存在于一个单独的服务中而不是你的系统中，将更容易进行的代码更改。\n提取出一个服务提供了封装的好处，通常与创建库相提并论。然而，提取出一个服务改进了创建库的方式，因为它允许更快、更容易地部署变更，而不像升级客户系统中的库那样麻烦。（当然，如果提取出的服务难以部署，那么客户系统将变得更容易部署。）这种便利是由于较小、提取出的服务中的代码和操作依赖较少，并且其创建的严格边界使得很难\u0026quot;走捷径\u0026quot;，而库则允许这种走捷径。这些走捷径通常会使迁移内部或客户系统到新版本变得更加困难。\n当存在多个客户系统时，使用服务的协调成本也比使用共享库要低得多。即使不需要进行API更改，升级库也需要协调每个客户系统的部署。如果部署次序颠倒，可能会导致数据损坏（而且很难预测这种情况），这使得升级库变得更加困难。如果客户系统由不同的维护者负责，升级库的社交协调成本也比部署服务更高。让其他人意识到并愿意升级是非常困难的，因为他们的优先事项可能与你的不一致。\n典型的服务使用案例是隐藏一个将要进行变更的存储层。提取出的服务具有更方便且表面积更小的API，与其前端的存储层相比。通过提取服务，客户系统无需了解迁移到新的存储系统或格式的复杂性，只需要评估新服务中肯定会发现的与新存储布局相关的错误。\n在执行此操作时，需要考虑许多操作和社交问题。在这里无法对它们进行充分阐述。需要撰写另一篇文章对此进行详细说明。\n我对我的审稿人Bill de hÓra、Coda Hale、JD Maturen、Micaela McDonald和Ted Nyman表示衷心感谢。你们的见解和关心是无价的。","title":"[译]给年轻的工程师们的关于分布式系统的一些笔记"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者Mikito Takada撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n6. 进一步阅读和附录 如果您已经做到了这一点，谢谢您。\n如果您喜欢这本书，请在 Github（或 Twitter）上关注我。我很高兴看到我产生了某种积极的影响。 “创造的价值比你获取的价值更多”等等。\n非常感谢：logpath、alexras、globalcitizen、graue、frankshearar、roryokane、jpfuentes2、eeror、cmeiklejohn、stevenproctor eos2102 和 steveloughran 的帮助！当然，任何错误和遗漏都是我的错！\n值得注意的是，我关于最终一致性的章节相当以伯克利为中心；我想改变这一点。我还跳过了一个重要的时间用例：一致的快照。我还应该扩展几个主题：即，对安全性和活性属性的明确讨论以及对一致性哈希的更详细讨论。不过，我要去《Strange Loop 2013》了，所以无论如何。\n如果这本书有第六章，它可能是关于如何利用和处理大量数据的。似乎最常见的“大数据”计算类型是通过单个简单程序传递大型数据集的计算。我不确定后续章节会是什么（也许是高性能计算，因为当前的重点是可行性），但我可能会在几年后知道。\n有关分布式系统的书籍 Distributed Algorithms (Lynch) 这可能是最常推荐的分布式算法书籍。我也推荐它，但有一个警告。它非常全面，但是是为研究生读者编写的，因此在了解从业者最感兴趣的内容之前，您将花费大量时间阅读同步系统和共享内存算法。\nIntroduction to Reliable and Secure Distributed Programming (Cachin, Guerraoui \u0026amp; Rodrigues) 对于一个修炼者来说，这是一件有趣的事。它很短并且充满了实际的算法实现。\nReplication: Theory and Practice 如果您对复制感兴趣，这本书非常棒。关于复制的章节主要基于对本书有趣部分以及最近阅读的内容的综合。\nDistributed Systems: An Algorithmic Approach (Ghosh) Introduction to Distributed Algorithms (Tel) Transactional Information Systems: Theory, Algorithms, and the Practice of Concurrency Control and Recovery (Weikum \u0026amp; Vossen) 本书介绍的是传统的交易信息系统，例如：本地 RDBMS。最后有两章介绍分布式事务，但本书的重点是事务处理。\nTransaction Processing: Concepts and Techniques by Gray and Reuter 经典之作。我发现 Weikum \u0026amp; Vossen 更更新。\n开创性论文 每年，Edsger W. Dijkstra 分布式计算奖都会颁发给有关分布式计算原理的杰出论文。查看完整列表的链接，其中包括经典内容，例如：\n\u0026ldquo;Time, Clocks and Ordering of Events in a Distributed System\u0026rdquo; - Leslie Lamport \u0026ldquo;Impossibility of Distributed Consensus With One Faulty Process\u0026rdquo; - Fisher, Lynch, Patterson \u0026ldquo;Unreliable failure detectors and reliable distributed systems\u0026rdquo; - Chandra and Toueg Microsoft 学术搜索有一个分布式和并行计算领域的顶级出版物列表，按引用次数排序 - 这可能是一个有趣的列表，可以浏览更多经典著作。\n以下是一些额外的推荐论文列表：\nNancy Lynch\u0026rsquo;s recommended reading list from her course on Distributed systems. NoSQL Summer paper list - a curated list of papers related to this buzzword. A Quora question on seminal papers in distributed systems. 系统 The Google File System - Ghemawat, Gobioff and Leung MapReduce: Simplified Data Processing on Large Clusters - Dean and Ghemawat Dynamo: Amazon’s Highly Available Key-value Store - DeCandia et al. Bigtable: A Distributed Storage System for Structured Data - Chang et al. The Chubby Lock Service for Loosely-Coupled Distributed Systems - Burrows ZooKeeper: Wait-free coordination for Internet-scale systems - Hunt, Konar, Junqueira, Reed, 2010 ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-06/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者Mikito Takada撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n6. 进一步阅读和附录 如果您已经做到了这一点，谢谢您。\n如果您喜欢这本书，请在 Github（或 Twitter）上关注我。我很高兴看到我产生了某种积极的影响。 “创造的价值比你获取的价值更多”等等。\n非常感谢：logpath、alexras、globalcitizen、graue、frankshearar、roryokane、jpfuentes2、eeror、cmeiklejohn、stevenproctor eos2102 和 steveloughran 的帮助！当然，任何错误和遗漏都是我的错！\n值得注意的是，我关于最终一致性的章节相当以伯克利为中心；我想改变这一点。我还跳过了一个重要的时间用例：一致的快照。我还应该扩展几个主题：即，对安全性和活性属性的明确讨论以及对一致性哈希的更详细讨论。不过，我要去《Strange Loop 2013》了，所以无论如何。\n如果这本书有第六章，它可能是关于如何利用和处理大量数据的。似乎最常见的“大数据”计算类型是通过单个简单程序传递大型数据集的计算。我不确定后续章节会是什么（也许是高性能计算，因为当前的重点是可行性），但我可能会在几年后知道。\n有关分布式系统的书籍 Distributed Algorithms (Lynch) 这可能是最常推荐的分布式算法书籍。我也推荐它，但有一个警告。它非常全面，但是是为研究生读者编写的，因此在了解从业者最感兴趣的内容之前，您将花费大量时间阅读同步系统和共享内存算法。\nIntroduction to Reliable and Secure Distributed Programming (Cachin, Guerraoui \u0026amp; Rodrigues) 对于一个修炼者来说，这是一件有趣的事。它很短并且充满了实际的算法实现。\nReplication: Theory and Practice 如果您对复制感兴趣，这本书非常棒。关于复制的章节主要基于对本书有趣部分以及最近阅读的内容的综合。\nDistributed Systems: An Algorithmic Approach (Ghosh) Introduction to Distributed Algorithms (Tel) Transactional Information Systems: Theory, Algorithms, and the Practice of Concurrency Control and Recovery (Weikum \u0026amp; Vossen) 本书介绍的是传统的交易信息系统，例如：本地 RDBMS。最后有两章介绍分布式事务，但本书的重点是事务处理。\nTransaction Processing: Concepts and Techniques by Gray and Reuter 经典之作。我发现 Weikum \u0026amp; Vossen 更更新。\n开创性论文 每年，Edsger W. Dijkstra 分布式计算奖都会颁发给有关分布式计算原理的杰出论文。查看完整列表的链接，其中包括经典内容，例如：\n\u0026ldquo;Time, Clocks and Ordering of Events in a Distributed System\u0026rdquo; - Leslie Lamport \u0026ldquo;Impossibility of Distributed Consensus With One Faulty Process\u0026rdquo; - Fisher, Lynch, Patterson \u0026ldquo;Unreliable failure detectors and reliable distributed systems\u0026rdquo; - Chandra and Toueg Microsoft 学术搜索有一个分布式和并行计算领域的顶级出版物列表，按引用次数排序 - 这可能是一个有趣的列表，可以浏览更多经典著作。","title":"[译]《分布式系统：为了乐趣和利益》6.进一步阅读和附录"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n5. 复制：弱一致性模型协议 现在，我们已经研究了一些可以在越来越现实的故障情况下实施单副本一致性的协议，让我们转向当我们放弃单副本一致性的要求时所打开的选择世界。\n总的来说，很难找到一个单一的维度来定义或描述允许副本发散的协议。大多数这样的协议都具有高可用性，关键问题更多地在于最终用户是否发现这些保证、抽象和 API 对他们的目的有用，尽管在节点和/或网络故障发生时副本可能发散。\n为什么弱一致性系统没有更受欢迎呢？\n正如我在介绍中所述，我认为分布式编程很大程度上涉及处理分布的两个结果所带来的影响：\n信息以光速传播； 独立的事物独立地发生故障。 由于信息传输速度受限，节点以不同且独特的方式体验世界。在单个节点上进行计算很容易，因为一切都按照可预测的全局总序发生。在分布式系统上进行计算很困难，因为没有全局总序。\n长期以来（例如几十年的研究时间），我们通过引入全局总序来解决这个问题。我已经讨论了许多实现强一致性的方法，通过在没有自然总序的情况下以容错方式创建顺序的方法。\n当然，问题在于强制执行顺序是昂贵的。这在大规模的互联网系统中特别突出，因为系统需要保持可用性。强一致性的系统不像分布式系统那样运行，而是像单个系统，这对于分区期间的可用性是不利的。\n此外，对于每个操作，通常需要联系大多数节点，而且通常不止一次（正如您在关于 2PC 的讨论中所看到的）。这在需要在地理上分布以为全球用户提供足够性能的系统中尤其困难。\n因此，默认情况下像单个系统一样运行可能并不理想。\n也许我们希望拥有一种可以编写不使用昂贵协调的代码，但仍返回一个“可用”值的系统。我们将允许不同的副本彼此发散-既为了保持效率，也为了容忍分区-然后尝试以某种方式处理这种发散。\n最终一致性表达了这个想法：节点在一段时间内可以相互发散，但最终它们将达成一致的值。\n在提供最终一致性的系统集合中，有两种类型的系统设计：\n带有概率保证的最终一致性。这种类型的系统可以在以后的某个时间点检测到冲突的写操作，但不能保证结果与某个正确的顺序执行等效。换句话说，冲突的更新有时会导致将较新的值覆盖为较旧的值，并且在正常操作（或分区）期间可能会出现一些异常情况。\n近年来，最有影响力的提供单副本一致性的系统设计是亚马逊的 Dynamo，我将以它作为提供带有概率保证的最终一致性系统示例进行讨论。\n带有强保证的最终一致性。这种类型的系统保证最终结果会收敛到一个共同的值，该值等同于某个正确的顺序执行。换句话说，这样的系统不会产生任何异常结果；在没有任何协调的情况下，您可以构建相同服务的副本，并且这些副本可以以任何模式进行通信并以任何顺序接收更新，只要它们都看到相同的信息，它们最终会就最终结果达成一致。\nCRDT（收敛复制数据类型）是一种数据类型，它保证在网络延迟、分区和消息重排序的情况下收敛到相同的值。它们可以被证明是收敛的，但可以实现为 CRDT 的数据类型是有限的。\nCALM（一致性作为逻辑单调性）猜想是相同原则的另一种表达方式：它将逻辑单调性与收敛等同起来。如果我们可以得出某个东西在逻辑上是单调的，那么在没有协调的情况下运行它也是安全的。收敛分析-特别是在 Bloom 编程语言中的应用-可用于指导程序员在何时何地使用强一致性系统的协调技术以及在何时可以安全地执行无需协调的操作。\n协调不同的操作指令 不强制执行单副本一致性的系统是什么样子呢？让我们通过几个例子来更具体地了解。\n也许最明显的非强制执行单副本一致性系统的特征是它们允许副本彼此发散。这意味着没有严格定义的通信模式：副本可以相互分离，但仍然保持可用并接受写操作。\n让我们想象一个由三个副本组成的系统，每个副本彼此分离。例如，这些副本可能位于不同的数据中心，并因某种原因无法通信。在分离期间，每个副本仍然可用，可以接受一些客户端的读写操作：\n[Clients] - \u0026gt; [A] --- Partition --- [Clients] - \u0026gt; [B] --- Partition --- [Clients] - \u0026gt; [C] 一段时间后，分区会修复并且副本服务器会交换信息。他们从不同的客户那里收到了不同的更新，并且彼此存在分歧，因此需要进行某种协调。我们希望所有的副本都收敛到相同的结果。\n[A] \\ --\u0026gt; [merge] [B] / | | [C] ----[merge]---\u0026gt; result 考虑具有弱一致性保证的系统的另一种方法是想象一组客户端按某种顺序向两个副本发送消息。由于没有强制执行单一总顺序的协调协议，因此消息可以在两个副本上以不同的顺序传递：\n[Clients] --\u0026gt; [A] 1, 2, 3 [Clients] --\u0026gt; [B] 2, 3, 1 从本质上讲，这就是我们需要协调协议的原因。例如，假设我们尝试连接一个字符串，消息 1、2 和 3 中的操作为：\n1: { operation: concat(\u0026#39;Hello \u0026#39;) } 2: { operation: concat(\u0026#39;World\u0026#39;) } 3: { operation: concat(\u0026#39;!\u0026#39;) } 然后，如果没有协调，A 将产生“Hello World!”，B 将产生“World!Hello”。\nA: concat(concat(concat(\u0026#39;\u0026#39;, \u0026#39;Hello \u0026#39;), \u0026#39;World\u0026#39;), \u0026#39;!\u0026#39;) = \u0026#39;Hello World!\u0026#39; B: concat(concat(concat(\u0026#39;\u0026#39;, \u0026#39;World\u0026#39;), \u0026#39;!\u0026#39;), \u0026#39;Hello \u0026#39;) = \u0026#39;World!Hello \u0026#39; 这当然是不正确的。同样，我们希望副本收敛到相同的结果。\n记住这两个例子，让我们首先看看亚马逊的 Dynamo 来建立基线，然后讨论一些构建具有弱一致性保证的系统的新方法，例如 CRDT 和 CALM 定理。\nAmazon\u0026rsquo;s Dynamo 亚马逊的 Dynamo 系统设计（2007 年）可能是最著名的提供弱一致性保证但高可用性的系统。它是许多其他实际系统的基础，包括 LinkedIn 的 Voldemort、Facebook 的 Cassandra 和 Basho 的 Riak。\nDynamo 是一个最终一致性且高可用的键值存储系统。键值存储类似于一个大的哈希表：客户端可以使用 set(key, value)设置值，并通过键使用 get(key)检索值。Dynamo 集群由 N 个对等节点组成；每个节点负责存储一组键。\nDynamo 优先保证可用性而不是一致性；它不保证单副本一致性。相反，当写入值时，副本可能会发散；当读取一个键时，在将值返回给客户端之前，会有一个读取协调阶段，尝试解决副本之间的差异。\n对于亚马逊的许多功能而言，避免停机比确保数据完全一致更为重要，因为停机可能导致业务损失和信誉损失。此外，如果数据并不是特别重要，那么弱一致性系统可以以比传统关系型数据库更低的成本提供更好的性能和更高的可用性。\n由于 Dynamo 是一个完整的系统设计，除了核心复制任务之外，还有许多不同的部分需要考虑。下面的图示了一些任务，特别是写入如何路由到节点并写入多个副本。\n[ Client ] | ( Mapping keys to nodes ) | V [ Node A ] | \\ ( Synchronous replication task: minimum durability ) | \\ [ Node B] [ Node C ] A | ( Conflict detection; asynchronous replication task: ensuring that partitioned / recovered nodes recover ) | V [ Node D] 在了解最初如何接受写入之后，我们将了解如何检测冲突以及异步副本同步任务。由于高可用性设计，节点可能暂时不可用（宕机或分区），因此需要执行此任务。副本同步任务确保节点即使在发生故障后也能相当快地赶上。\n一致的散列 无论我们是读还是写，首先需要做的就是找到数据在系统上的位置。这需要某种类型的键到节点映射。\n在 Dynamo 中，键使用称为一致性哈希的哈希技术（我不会详细讨论）映射到节点。主要思想是，通过客户端上的简单计算，可以将密钥映射到负责它的一组节点。这意味着客户端可以定位密钥，而无需向系统查询每个密钥的位置；这可以节省系统资源，因为散列通常比执行远程过程调用更快。\n部分法定人数 一旦我们知道密钥应该存储在哪里，我们就需要做一些工作来保存该值。这是一个同步任务；我们立即将值写入多个节点的原因是为了提供更高级别的持久性（例如，防止节点立即发生故障）。\n就像 Paxos 或 Raft 一样，Dynamo 使用仲裁进行复制。然而，Dynamo 的法定人数是草率（部分）法定人数，而不是严格（多数）法定人数。\n非正式地，严格法定人数系统是指具有法定人数系统中任意两个法定人数（集合）重叠的属性的法定人数系统。在接受更新之前要求多数投票支持更新可以保证只接受单个历史记录，因为每个多数仲裁必须在至少一个节点中重叠。例如，这就是 Paxos 所依赖的属性。\n部分法定人数不具备该属性；这意味着不需要多数，并且法定人数的不同子集可能包含相同数据的不同版本。用户可以选择要写入和读取的节点数量：\n用户可以选择写入成功所需的 W-of-N 节点数量；和 用户可以指定读取期间要联系的节点数 (R-of-N)。 W 和 R 指定写入或读取需要涉及的节点数。写入更多节点会使写入速度稍慢，但会增加值不丢失的概率；从更多节点读取会增加读取的值是最新的概率。\n通常的建议是 R + W \u0026gt; N ，因为这意味着读取和写入仲裁在一个节点中重叠 - 使得返回过时值的可能性较小。典型的配置是 N = 3 （例如每个值总共三个副本）；这意味着用户可以选择：\nR = 1, W = 3; R = 2, W = 2 or R = 3, W = 1 更一般地说，再次假设 R + W \u0026gt; N ：\nR = 1, W = N: 读取快，写入慢 R = N, W = 1: 写入速度快，读取速度慢 R = N/2 and W = N/2 + 1: 对两者都有利 N 很少超过 3，因为保留大量数据的许多副本会变得昂贵！\n正如我之前提到的，Dynamo 纸启发了许多其他类似的设计。它们都使用相同的基于部分仲裁的复制方法，但 N、W 和 R 的默认值不同：\nBasho\u0026rsquo;s Riak (N = 3, R = 2, W = 2 default) Linkedin\u0026rsquo;s Voldemort (N = 2 or 3, R = 1, W = 1 default) Apache\u0026rsquo;s Cassandra (N = 3, R = 1, W = 1 default) 还有一个细节：发送读或写请求时，是要求所有 N 个节点响应（Riak），还是仅要求满足最小值的多个节点（例如 R 或 W；Voldemort）。\n“send-to-all”方法速度更快，对延迟不太敏感（因为它只等待 N 中最快的 R 或 W 节点），但效率也较低，而“send-tominimum”方法对延迟更敏感。延迟（因为与单个节点通信的延迟会延迟操作），而且效率更高（总体上消息/连接更少）。\n当读取和写入仲裁重叠时会发生什么，例如（ R + W \u0026gt; N ）？具体来说，人们经常声称这会导致“强一致性”。\nR + W \u0026gt; N 等同于“强一致性”吗？ No\n这并不是完全错误的： R + W \u0026gt; N 可以检测读/写冲突的系统，因为任何读仲裁和任何写仲裁共享一个成员。例如。两个仲裁中至少有一个节点：\n1 2 N/2+1 N/2+2 N [...] [R] [R + W] [W] [...] 这确保了先前的写操作将被后续的读取操作看到。然而，这仅在 N 中的节点永不改变的情况下成立。因此，Dynamo 并不符合这个要求，因为在 Dynamo 中，如果节点失败，集群成员资格可能会发生变化。\nDynamo 被设计为始终可写。它具有处理节点故障的机制，即在原始服务器宕机时，将一个不相关的服务器添加到负责某些键的节点集合中。这意味着法定人数不再保证始终重叠。即使 R = W = N 也不符合条件，因为尽管法定人数的大小等于 N，但在故障期间，这些法定人数中的节点可以发生变化。具体而言，在分区期间，如果无法达到足够数量的节点，Dynamo 将从不相关但可访问的节点中添加新节点到法定人数中。\n此外，Dynamo 不以强一致性模型所强制的方式处理分区：即在分区的两侧都允许写操作，这意味着系统在某些时间内不作为单一副本运行。因此，将 R + W \u0026gt; N 称为\u0026quot;强一致性\u0026quot;是具有误导性的；这个保证仅仅是概率性的，而不是强一致性所指的意思。\n冲突检测和读取修复 为了解决允许副本发散的系统必须有一种方法来最终协调两个不同的值，通常会通过补充一些元数据来跟踪数据的因果历史。当客户端从系统中读取数据时，必须保留元数据信息，并在写入数据库时返回相应的元数据值。\n我们已经介绍了一种用于实现这一目的的方法：向量时钟可以用于表示值的历史。实际上，这就是原始的 Dynamo 设计用于检测冲突的方法。\n然而，使用向量时钟并不是唯一的选择。通过查看系统跟踪的元数据，您可以推断出许多实际系统设计的工作方式。\n没有元数据。当系统不跟踪元数据，仅返回值（例如通过客户端 API）时，它实际上无法对并发写入执行任何特殊操作。一个常见的规则是最后写入者获胜：换句话说，如果两个写入者同时写入，只有最慢的写入者的值被保留。\n时间戳。通常，具有较高时间戳值的值获胜。然而，如果时间没有被精确同步，许多奇怪的事情可能发生，其中来自具有故障或快速时钟的系统的旧数据覆盖了较新的值。Facebook 的 Cassandra 是 Dynamo 的一个变种，它使用时间戳而不是向量时钟。\n版本号。版本号可以避免使用时间戳时的一些问题。需要注意的是，当存在多个可能的历史时，可以准确跟踪因果关系的最小机制是向量时钟，而不是版本号。\n向量时钟。使用向量时钟，可以检测并发和过时的更新。然后可以执行读修复操作，尽管在某些情况下（并发更改），我们需要要求客户端选择一个值。这是因为如果更改是并发的，并且我们对数据没有更多了解（就像简单的键值存储一样），那么询问比任意丢弃数据更好。\n在读取值时，客户端联系 N 个节点中的 R 个节点，并请求它们为某个键提供最新的值。它接收所有的响应，丢弃严格较旧的值（使用向量时钟值来检测）。如果只有一个唯一的向量时钟+值对，则返回该值。如果有多个并发编辑的向量时钟+值对（例如不可比较），则返回所有这些值。\n显然，从上述内容可以看出，读修复可能会返回多个值。这意味着客户端/应用程序开发人员必须根据特定用例的标准偶尔处理这些情况，并选择一个值。\n此外，实际向量时钟系统的一个关键组成部分是不能让时钟无限增长-因此需要定期以安全的方式回收时钟，以在容错性和存储需求之间保持平衡。\n副本同步：gossip 和 Merkle 树 在 Dynamo 系统设计中，考虑到节点故障和网络分区的容错性，需要一种处理节点重新加入集群的方式，无论是在被分区后还是在替换或部分恢复失败的节点之后。\n副本同步用于在故障后使节点保持最新状态，并定期使副本之间同步。\n八卦（Gossip）是一种用于同步副本的概率性技术。通信模式（例如哪个节点与哪个节点联系）不是预先确定的。相反，节点具有尝试相互同步的概率 p。每隔 t 秒，每个节点选择一个节点进行通信。这提供了除同步任务（例如部分法定人数写入）之外的另一种机制，使副本保持最新。\n八卦具有可扩展性，没有单点故障，但只能提供概率性的保证。\n为了使副本同步过程中的信息交换更高效，Dynamo 使用一种称为 Merkle 树的技术，我将不详细介绍。关键思想是数据存储可以在多个不同的粒度级别上进行哈希：表示整个内容的哈希，一半的键，四分之一的键等等。\n通过保持这种相当细粒度的哈希，节点可以比朴素技术更高效地比较其数据存储内容。一旦节点确定了哪些键具有不同的值，它们会交换必要的信息以使副本保持最新。\nDynamo 实践：概率有界陈旧性 (PBS) 这基本上涵盖了 Dynamo 系统的设计：\n一致性哈希用于确定键的存放位置 部分法定人数用于读取和写入 通过向量时钟进行冲突检测和读修复 通过八卦进行副本同步 我们如何描述这样一个系统的行为？Bailis 等人（2012 年）的一篇相对较新的论文描述了一种称为 PBS（概率有界陈旧度）的方法，该方法使用模拟和从真实系统收集的数据来描述这样一个系统的预期行为。\nPBS 通过使用反熵（gossip）速率、网络延迟和本地处理延迟的信息来估计不一致程度，从而估计读取的一致性水平的预期值。它已经在 Cassandra 中实现，在其他消息上附加了计时信息，并基于此信息的样本在蒙特卡洛模拟中计算出一个估计值。\n根据该论文，在正常运行期间，最终一致性的数据存储通常更快，并且可以在几十到几百毫秒内读取一致的状态。下表描述了从 LinkedIn（SSD 和 15k RPM 磁盘）和 Yammer 的实证计时数据中，以不同的 R 和 W 设置下，以 99.9%的一致性读取概率所需的时间：\n例如，在 Yammer 案例中，从 R=1 、 W=1 到 R=2 、 W=1 将不一致窗口从 1352 毫秒减少到 202 毫秒- 同时保持读取延迟（32.6 毫秒）低于最快的严格仲裁（ R=3 、 W=1 ；219.27 毫秒）。\n有关更多详细信息，请查看 PBS 网站和相关论文。\n无序编程 让我们回顾一下我们希望解决的情况的示例。第一个场景包括三个不同的服务器在分区后，当分区恢复时，我们希望这些服务器收敛到相同的值。亚马逊的 Dynamo 通过从 N 个节点中读取 R 个节点，然后执行读取协调操作来实现这一点。\n在第二个示例中，我们考虑了一个更具体的操作：字符串连接。事实证明，没有已知的技术可以使字符串连接的结果达到相同的值，而不需要对操作进行排序（例如，不需要昂贵的协调）。然而，有些操作可以以任何顺序安全地应用，而简单的寄存器则无法做到这一点。正如 Pat Helland 所写：\n……操作中心的工作可以通过正确的操作和正确的语义变得可交换，而简单的读取/写入语义则不适合可交换性。\n例如，考虑一个实现简单会计系统的系统，其中借记和贷记操作以两种不同的方式实现：\n使用具有读取和写入操作的寄存器 使用具有本地借记和贷记操作的整数数据类型 后一种实现对数据类型的内部有更多了解，因此它可以在操作被重新排序的情况下保留操作的意图。借记或贷记可以以任何顺序应用，最终结果是相同的：\n100 + credit(10) + credit(20) = 130 and 100 + credit(20) + credit(10) = 130 但是，写入固定值不能按任何顺序完成：如果重新排序写入，则其中一个写入将覆盖另一个：\n100 + write(110) + write(130) = 130 but 100 + write(130) + write(110) = 110 让我们采用本章开头的示例，但使用不同的操作。在这种情况下，客户端将消息发送到两个节点，这两个节点以不同的顺序查看操作：\n[Clients] --\u0026gt; [A] 1, 2, 3 [Clients] --\u0026gt; [B] 2, 3, 1 假设我们正在寻找一组整数的最大值（例如 MAX()），而不是字符串连接。消息 1、2 和 3 是：\n1: { operation: max(previous, 3) } 2: { operation: max(previous, 5) } 3: { operation: max(previous, 7) } 那么，如果没有协调，A 和 B 都会收敛到 7，例如：\nA: max(max(max(0, 3), 5), 7) = 7 B: max(max(max(0, 5), 7), 3) = 7 在这两种情况下，两个副本都会以不同的顺序看到更新，但是无论顺序如何，我们都能够以具有相同结果的方式合并结果。由于我们使用了合并过程 ( max )，两种情况下的结果都会收敛到相同的答案。\n编写适用于所有数据类型的合并过程可能是不可能的。在 Dynamo 中，值是一个二进制 blob，因此最好的办法就是公开它并要求应用程序处理每个冲突。\n但是，如果我们知道数据属于更具体的类型，则处理此类冲突就成为可能。 CRDT 是一种数据结构，旨在提供始终收敛的数据类型，只要它们看到相同的操作集（以任何顺序）。\nCRDT：聚合复制数据类型 CRDT（收敛复制数据类型）利用有关特定数据类型上特定操作的交换性和关联性的知识。\n为了在副本仅偶尔通信的环境中使一组操作收敛于相同的值，这些操作需要与顺序无关并且对（消息）复制/重新传递不敏感。因此，他们的操作需要是：\n关联 ( a+(b+c)=(a+b)+c )，因此分组并不重要 可交换 ( a+b=b+a )，因此应用程序的顺序并不重要 幂等 ( a+a=a )，因此重复并不重要 原来这些结构在数学中已经被称为\u0026quot;join\u0026quot;或\u0026quot;meet\u0026quot;半格。\n格是一个具有明确的顶部（最小上界）和明确的底部（最大下界）的偏序集合。半格类似于格，但只有一个明确的顶部或底部。\u0026ldquo;join\u0026quot;半格具有明确的顶部（最小上界），而\u0026quot;meet\u0026quot;半格具有明确的底部（最大下界）。\n任何可以表示为半格的数据类型都可以实现为保证收敛的数据结构。例如，计算一组值的最大值(max())将始终返回相同的结果，无论接收值的顺序如何，只要所有值最终都被接收到，因为最大值(max())操作是可结合的、可交换的和幂等的。\n例如，下面是两个格的示例：一个用于表示集合，其中合并操作符是 union(items)；另一个用于表示严格递增的整数计数器，其中合并操作符是 max(values)：\n{ a, b, c } 7 / | \\ / \\ {a, b} {b,c} {a,c} 5 7 | \\ / | / / | \\ {a} {b} {c} 3 5 7 使用可以表示为半格的数据类型，您可以让副本以任何模式进行通信并以任何顺序接收更新，只要它们都看到相同的信息，它们最终就会就最终结果达成一致。这是一个强大的属性，只要满足先决条件，就可以得到保证。\n然而，将数据类型表示为半格通常需要一定程度的解释。许多数据类型的操作实际上与顺序无关。例如，将项目添加到集合中是关联的、可交换的和幂等的。但是，如果我们还允许从集合中删除项目，那么我们需要某种方法来解决冲突的操作，例如 add(A) 和 remove(A) 。如果本地副本从未添加过某个元素，那么删除该元素意味着什么？该分辨率必须以与顺序无关的方式指定，并且有几种不同的选择和不同的权衡。\n这意味着一些熟悉的数据类型具有更专业的实现，例如 CRDT，它们会进行不同的权衡，以便以与顺序无关的方式解决冲突。与仅处理寄存器（例如，从系统角度来看是不透明 blob 的值）的键值存储不同，使用 CRDT 的人必须使用正确的数据类型以避免异常。\n指定为 CRDT 的不同数据类型的一些示例包括：\n计数器\n仅增长计数器（合并 = max(值)；有效负载 = 单个整数） 正负计数器（由两个增长计数器组成，一个用于增量，另一个用于减量） 寄存器\n最后写入获胜 -register（时间戳或版本号；merge = max(ts)；payload = blob） 多值寄存器（矢量时钟；合并=两者兼而有之） 集合\n仅增长集（合并 = union(items)；有效负载 = 设置；不删除） 两相集合（由两个集合组成，一个用于添加，另一个用于删除；元素可以添加一次，删除一次） 独特集（两相集的优化版本） 最后一次写入获胜设置（合并 = max(ts)；有效负载 = 设置） 正负组（每组项目包含一个 PN 计数器） 观察-移除集 图形和文本序列（参见论文）\n为了确保无异常操作，您需要为您的特定应用程序找到正确的数据类型 - 例如，如果您知道您只会删除一个项目一次，那么两阶段集就可以工作；如果您只将项目添加到集合中并且从不删除它们，那么仅增长集合就可以了。\n并非所有数据结构都有 CRDT 的实现，但在 Shapiro 等人最近（2011 年）的调查论文中，有布尔值、计数器、集合、寄存器和图形的 CRDT 实现。\n有趣的是，寄存器实现直接与键值存储使用的实现相对应：最后写入获胜寄存器使用时间戳或某些等效项，并且简单地收敛到最大时间戳值；多值寄存器对应于保留、公开和协调并发更改的 Dynamo 策略。有关详细信息，我建议您查看本章延伸阅读部分中的论文。\nCALM 定理 您提到的 CRDT 数据结构是基于一种认识，即可表示为半格的数据结构是收敛的。但是，编程不仅仅涉及状态的演化，除非您只是在实现一个数据存储。\n显然，无序性是任何收敛计算的重要属性：如果数据项接收的顺序影响计算的结果，那么没有办法在不保证顺序的情况下执行计算。\n然而，在许多编程模型中，语句的顺序并不起重要作用。例如，在 MapReduce 模型中，Map 和 Reduce 任务都被指定为无状态的元组处理任务，需要在数据集上运行。关于如何以及以什么顺序将数据路由到任务的具体决策并没有明确指定，而是由批处理作业调度器负责将任务安排在集群上运行。\n类似地，在 SQL 中，我们只指定查询，而不指定查询的执行方式。查询只是任务的声明性描述，查询优化器负责找出执行查询的高效方式（跨多个机器、数据库和表）。\n当然，这些编程模型并不像通用编程语言那样自由。MapReduce 任务需要在无环数据流程序中表达为无状态任务；SQL 语句可以执行相当复杂的计算，但很多东西很难用它来表达。\n然而，从这两个示例可以清楚地看出，有许多种数据处理任务可以在声明性语言中表达，而不需要明确指定执行顺序。表达所需结果的编程模型，同时将语句的确切顺序交给优化器决定，往往具有无序性的语义。这意味着这样的程序可能可以在没有协调的情况下执行，因为它们依赖于接收到的输入，而不一定依赖于输入的特定顺序。\n关键点是这样的程序可能可以在没有协调的情况下安全地执行。如果没有明确的规则来描述什么可以在没有协调的情况下执行，什么不能，在保证结果正确的前提下，我们无法实现一个程序。\n这就是 CALM 定理的内容。CALM 定理基于对逻辑单调性和有用的最终一致性形式（如收敛性）之间关系的认识。它声明逻辑上单调的程序保证最终一致。\n因此，如果我们知道某个计算在逻辑上是单调的，那么我们知道它也可以在没有协调的情况下安全地执行。\n为了更好地理解这一点，我们需要将单调逻辑（或单调计算）与非单调逻辑（或非单调计算）进行对比。\n单调性 如果句子 φ 是一组前提 Γ 的结论，那么它也可以从任何扩展 Γ 的前提集 Δ 中推断出来。 大多数标准逻辑框架都是单调的：在诸如一阶逻辑的框架中进行的任何推理，一旦经过演绎验证，就不会被新信息无效。非单调逻辑是一种不具备这一属性的系统，换句话说，某些结论可能会被学习新知识所否定。\n在人工智能领域，非单调逻辑与可废弃推理相关联，即利用部分信息进行的断言可以被学习新知识所否定。例如，如果我们得知 Tweety 是一只鸟，我们会认为 Tweety 可以飞；但是如果我们后来得知 Tweety 是一只企鹅，那么我们就我明白您提到的 CALM 定理和单调性的概念。CALM 定理指出，在逻辑上单调的计算最终将达到一致状态。单调性是一个重要的特性，它表示当我们获得更多的信息时，我们的结论不会被否定。\n在编程中，特定的编程模型可能是单调的，这意味着我们可以在没有协调的情况下安全地执行这些模型中的计算。例如，关系代数和 Datalog 是两种具有单调性的编程模型。\n在关系代数和 Datalog 中，使用一组基本操作符进行的计算被认为是单调的，例如选择、投影、自然连接、交叉乘积、并集和递归 Datalog（不包含否定）。而使用更高级的操作符（否定、集合差、除法、全称量化、聚合）会引入非单调性。\n这意味着在这些系统中使用许多操作符（例如 map、filter、join、union、intersection）的计算在逻辑上是单调的，因此可以在没有协调的情况下安全运行。而使用否定和聚合的表达式则不适合在没有协调的情况下运行。\n确定计算是否单调并不容易，特别是对于传统的编程语言，其中顺序、选择和迭代是核心。因此，为了能够测试单调性并进行静态分析，需要不同类型的编程语言，这就是为什么设计了 Bloom 语言的原因。\n总而言之，单调性在分布式系统中的执行是重要的，因为它可以减少协调的需要，并提高系统的性能。通过使用单调性进行静态分析，我们可以确定哪些部分的计算是单调的，并可以在没有协调的情况下运行，从而实现更高效、更可扩展的计算模型。\n非单一性有什么好处？ 单调性和非单调性之间的区别很有趣。例如，将两个数字相加是单调的，但计算包含数字的两个节点的聚合不是单调的。它们之间的区别在于一个是计算（将两个数字相加），而另一个是断言（计算聚合）。\n计算和断言在本质上有所不同。计算是指执行计算或进行操作以获得结果的过程，它是通过遵循特定的规则和算法来进行的。计算是确定性的，给定相同的输入和操作，它总是会产生相同的输出。例如，将两个数字相加所遵循的加法规则是确定的，因此计算的结果总是一致的。\n相反，断言是关于陈述或命题真实性的主张。它表达了对某个事实或知识的主观断定。断言是基于可用证据或假设的，并且可以根据不同的上下文或视角而变化。例如，关于\u0026quot;披萨是蔬菜\u0026quot;的陈述是一个断言，根据所约定的\u0026quot;蔬菜\u0026quot;的定义，可以评估其真实性或虚假性。\n当推理关于断言时，涉及到各种假设和上下文。对于这个问题\u0026quot;披萨是蔬菜吗？\u0026quot;，我们需要考虑何时可以推断某个命题的真实性或虚假性。\n有几种合理的回答，每个回答对应着对我们拥有的信息和我们应该如何处理它的不同假设。在不同的上下文中，我们接受了不同的答案。\n在日常推理中，我们使用所谓的\u0026quot;开放世界假设\u0026rdquo;：我们假设我们并不知道一切，因此不能根据缺乏知识来得出结论。也就是说，任何陈述都可能为真、为假或未知。根据开放世界假设，我们不会从缺乏知识中得出否定的结论，而是持开放的态度，接受陈述可能为未知的可能性。\nOWA + | OWA + Monotonic logic | Non-monotonic logic Can derive P(true) | Can assert P(true) | Cannot assert P(true) Can derive P(false) | Can assert P(false) | Cannot assert P(true) Cannot derive P(true) | Unknown | Unknown or P(false) 在进行开放世界假设时，我们只能安全地断言我们可以从已知信息中推导出的内容。我们假设对世界的信息是不完全的。\n首先，让我们看看我们知道推理是单调的情况。在这种情况下，我们拥有的任何（可能不完整的）知识都不会因为学习新知识而失效。因此，如果我们可以基于某种推理（例如，“含有两汤匙番茄酱的物品是蔬菜”和“比萨含有两汤匙番茄酱”）推断某个陈述为真，那么我们可以得出“比萨是蔬菜”的结论。同样，如果我们可以推断某个陈述为假，也是一样的。\n然而，如果我们无法推导出任何结论 - 例如，我们掌握的知识集合只包含顾客信息，而没有关于比萨或蔬菜的任何信息 - 那么根据开放世界假设，我们必须说我们无法得出任何结论。\n对于非单调知识，我们现在所知道的任何内容都有可能被否定。因此，即使我们可以从当前所知的内容中推导出真或假，我们也不能安全地得出任何结论。\n然而，在数据库上下文中，以及在许多计算机科学应用中，我们更倾向于得出更明确的结论。这意味着采用了所谓的封闭世界假设：即不能显示为真的任何内容都被认为是假的。这意味着不需要明确声明为假。换句话说，我们假设拥有的事实数据库是完整（最小的），因此可以假设其中没有的任何内容都是假的。\n例如，在封闭世界假设下，如果我们的数据库中没有旧金山到赫尔辛基之间的航班信息，那么我们可以安全地得出结论说不存在这样的航班。\n我们需要另外一件事才能够做出明确的断言：逻辑封装。封装是一种推测的形式化规则。域封装假设已知实体就是全部实体。为了得出明确的结论，我们需要假设所知的实体就是全部实体。\nCWA + | CWA + Circumscription + | Circumscription + Monotonic logic | Non-monotonic logic Can derive P(true) | Can assert P(true) | Can assert P(true) Can derive P(false) | Can assert P(false) | Can assert P(false) Cannot derive P(true) | Can assert P(false) | Can assert P(false) or P(false) 特别是，非单调推理需要这个假设。只有在我们假设拥有完整信息的情况下，我们才能做出自信的断言，因为额外的信息可能会否定我们的断言。\n这在实践中意味着什么呢？首先，单调逻辑可以在能够推导出一个句子为真（或假）时得出确定的结论。其次，非单调逻辑需要额外的假设：已知实体就是全部实体。\n那么为什么表面上等价的两个操作会有所不同呢？为什么加法是单调的，而在两个节点上进行聚合计算却不是？因为聚合计算不仅计算总和，还断言它已经看到了所有的值。而要保证这一点，需要在节点之间进行协调，确保执行计算的节点确实在系统中看到了所有的值。\n因此，为了处理非单调性，需要使用分布式协调来确保只有在了解所有信息之后才进行断言，或者在断言中附带警告，即结论可能在以后被否定。\n处理非单调性对于表达能力非常重要。这归结为能够表达非单调的事物；例如，能够说某一列的总和是 X 是很好的。系统必须检测到这种计算需要全局协调边界，以确保我们已经看到了所有的实体。\n纯粹的单调系统很少见。似乎大多数应用程序在拥有不完整数据时也是基于封闭世界假设运行的，而我们人类对此也没有意见。当一个数据库告诉你旧金山和赫尔辛基之间没有直达航班时，你可能会把它理解为“根据这个数据库，不存在直达航班”，但你并不排除现实中可能仍然存在这样一种航班的可能性。\n事实上，只有在复制品出现分歧时（例如在分区期间或由于正常操作期间的延迟），这个问题才变得有趣。那时就需要更具体的考虑：答案是基于当前节点还是基于整个系统。\n此外，由于非单调性是通过做出断言来引起的，许多计算似乎可以进行很长时间，只有在将某个结果或断言传递给第三方系统或最终用户时才应用协调。当然，并不需要在系统内的每个读写操作都强制执行总序，如果这些读写操作只是长时间运行计算的一部分，那么这是没有必要的。\n布隆语言 Bloom 语言是一种旨在利用 CALM 定理的语言。它是一种 Ruby DSL，其形式基础是一种称为 Dedalus 的时序逻辑编程语言。\n在 Bloom 中，每个节点都有一个由集合和格组成的数据库。程序被表示为与集合（事实集）和格（CRDT）交互的无序语句集。默认情况下，语句是与顺序无关的，但也可以编写非单调函数。\n请访问 Bloom 网站和教程，了解有关 Bloom 的更多信息。\n进一步阅读 CALM 定理、汇合分析和 Bloom Joe Hellerstein 的演讲@RICON 2012 很好地介绍了该主题，Neil Conway 的演讲@Basho 也是如此。特别是对于 Bloom，请参阅 Peter Alvaro 的 talk@Microsoft。\nThe Declarative Imperative: Experiences and Conjectures in Distributed Logic - Hellerstein, 2010 Consistency Analysis in Bloom: a CALM and Collected Approach - Alvaro et al., 2011 Logic and Lattices for Distributed Programming - Conway et al., 2012 Dedalus: Datalog in Time and Space - Alvaro et al., 2011 CRDTs CRDT Marc Shapiro\u0026rsquo;s talk @ Microsoft is a good starting point for understanding CRDT\u0026rsquo;s.\nCRDTs: Consistency Without Concurrency Control - Letitia et al., 2009 A comprehensive study of Convergent and Commutative Replicated Data Types, Shapiro et al., 2011 An Optimized conflict-free Replicated Set - Bieniusa et al., 2012 Dynamo; PBS；乐观复制 Dynamo: Amazon’s Highly Available Key-value Store - DeCandia et al., 2007 PNUTS: Yahoo!\u0026rsquo;s Hosted Data Serving Platform - Cooper et al., 2008 The Bayou Architecture: Support for Data Sharing among Mobile Users - Demers et al. 1994 Probabilistically Bound Staleness for Practical Partial Quorums - Bailis et al., 2012 Eventual Consistency Today: Limitations, Extensions, and Beyond - Bailis \u0026amp; Ghodsi, 2013 Optimistic replication - Saito \u0026amp; Shapiro, 2005 ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-05/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n5. 复制：弱一致性模型协议 现在，我们已经研究了一些可以在越来越现实的故障情况下实施单副本一致性的协议，让我们转向当我们放弃单副本一致性的要求时所打开的选择世界。\n总的来说，很难找到一个单一的维度来定义或描述允许副本发散的协议。大多数这样的协议都具有高可用性，关键问题更多地在于最终用户是否发现这些保证、抽象和 API 对他们的目的有用，尽管在节点和/或网络故障发生时副本可能发散。\n为什么弱一致性系统没有更受欢迎呢？\n正如我在介绍中所述，我认为分布式编程很大程度上涉及处理分布的两个结果所带来的影响：\n信息以光速传播； 独立的事物独立地发生故障。 由于信息传输速度受限，节点以不同且独特的方式体验世界。在单个节点上进行计算很容易，因为一切都按照可预测的全局总序发生。在分布式系统上进行计算很困难，因为没有全局总序。\n长期以来（例如几十年的研究时间），我们通过引入全局总序来解决这个问题。我已经讨论了许多实现强一致性的方法，通过在没有自然总序的情况下以容错方式创建顺序的方法。\n当然，问题在于强制执行顺序是昂贵的。这在大规模的互联网系统中特别突出，因为系统需要保持可用性。强一致性的系统不像分布式系统那样运行，而是像单个系统，这对于分区期间的可用性是不利的。\n此外，对于每个操作，通常需要联系大多数节点，而且通常不止一次（正如您在关于 2PC 的讨论中所看到的）。这在需要在地理上分布以为全球用户提供足够性能的系统中尤其困难。\n因此，默认情况下像单个系统一样运行可能并不理想。\n也许我们希望拥有一种可以编写不使用昂贵协调的代码，但仍返回一个“可用”值的系统。我们将允许不同的副本彼此发散-既为了保持效率，也为了容忍分区-然后尝试以某种方式处理这种发散。\n最终一致性表达了这个想法：节点在一段时间内可以相互发散，但最终它们将达成一致的值。\n在提供最终一致性的系统集合中，有两种类型的系统设计：\n带有概率保证的最终一致性。这种类型的系统可以在以后的某个时间点检测到冲突的写操作，但不能保证结果与某个正确的顺序执行等效。换句话说，冲突的更新有时会导致将较新的值覆盖为较旧的值，并且在正常操作（或分区）期间可能会出现一些异常情况。\n近年来，最有影响力的提供单副本一致性的系统设计是亚马逊的 Dynamo，我将以它作为提供带有概率保证的最终一致性系统示例进行讨论。\n带有强保证的最终一致性。这种类型的系统保证最终结果会收敛到一个共同的值，该值等同于某个正确的顺序执行。换句话说，这样的系统不会产生任何异常结果；在没有任何协调的情况下，您可以构建相同服务的副本，并且这些副本可以以任何模式进行通信并以任何顺序接收更新，只要它们都看到相同的信息，它们最终会就最终结果达成一致。\nCRDT（收敛复制数据类型）是一种数据类型，它保证在网络延迟、分区和消息重排序的情况下收敛到相同的值。它们可以被证明是收敛的，但可以实现为 CRDT 的数据类型是有限的。\nCALM（一致性作为逻辑单调性）猜想是相同原则的另一种表达方式：它将逻辑单调性与收敛等同起来。如果我们可以得出某个东西在逻辑上是单调的，那么在没有协调的情况下运行它也是安全的。收敛分析-特别是在 Bloom 编程语言中的应用-可用于指导程序员在何时何地使用强一致性系统的协调技术以及在何时可以安全地执行无需协调的操作。\n协调不同的操作指令 不强制执行单副本一致性的系统是什么样子呢？让我们通过几个例子来更具体地了解。\n也许最明显的非强制执行单副本一致性系统的特征是它们允许副本彼此发散。这意味着没有严格定义的通信模式：副本可以相互分离，但仍然保持可用并接受写操作。\n让我们想象一个由三个副本组成的系统，每个副本彼此分离。例如，这些副本可能位于不同的数据中心，并因某种原因无法通信。在分离期间，每个副本仍然可用，可以接受一些客户端的读写操作：\n[Clients] - \u0026gt; [A] --- Partition --- [Clients] - \u0026gt; [B] --- Partition --- [Clients] - \u0026gt; [C] 一段时间后，分区会修复并且副本服务器会交换信息。他们从不同的客户那里收到了不同的更新，并且彼此存在分歧，因此需要进行某种协调。我们希望所有的副本都收敛到相同的结果。\n[A] \\ --\u0026gt; [merge] [B] / | | [C] ----[merge]---\u0026gt; result 考虑具有弱一致性保证的系统的另一种方法是想象一组客户端按某种顺序向两个副本发送消息。由于没有强制执行单一总顺序的协调协议，因此消息可以在两个副本上以不同的顺序传递：\n[Clients] --\u0026gt; [A] 1, 2, 3 [Clients] --\u0026gt; [B] 2, 3, 1 从本质上讲，这就是我们需要协调协议的原因。例如，假设我们尝试连接一个字符串，消息 1、2 和 3 中的操作为：\n1: { operation: concat(\u0026#39;Hello \u0026#39;) } 2: { operation: concat(\u0026#39;World\u0026#39;) } 3: { operation: concat(\u0026#39;!","title":"[译]《分布式系统：为了乐趣和利益》5.复制：弱一致性模型协议"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n4. 复制 复制问题是分布式系统中的众多问题之一。与诸如领导者选举、故障检测、互斥、共识和全局快照等其他问题相比，我选择关注复制问题，因为这通常是人们最感兴趣的部分。并行数据库在复制特性方面的差异化就是一个例子。此外，复制为许多子问题提供了一个上下文，例如领导者选举、故障检测、共识和原子广播。\n复制是一个组通信问题。什么样的安排和通信模式能够满足我们所期望的性能和可用性特性？在面对网络分区和同时节点故障的情况下，我们如何确保容错性、耐久性和非发散性？\n同样，有许多方法可以解决复制问题。我在这里采用的方法只是看一下具有复制功能的系统可能具有的高级模式。从可视化的角度来看，有助于将讨论集中在整体模式上，而不是具体涉及的消息传递。我在这里的目标是探索设计空间，而不是解释每个算法的具体细节。\n让我们首先定义一下复制是什么样子。我们假设我们有一些初始数据库，并且客户端发出请求来改变数据库的状态。\n这种安排和通信模式可以分为几个阶段：\n（请求）客户端向服务器发送请求 （同步）进行复制的同步部分 （响应）将响应返回给客户端 （异步）进行复制的异步部分 根据这些阶段，我们可以创建不同的通信模式。我们选择的模式将对性能和可用性产生影响，具体取决于所选择的算法。\n同步复制 第一个模式是同步复制（也称为主动复制、急切复制、推送复制或悲观复制）。让我们画出它的示意图：\n在这里，我们可以看到三个明显的阶段：首先，客户端发送请求。接下来，我们所称的同步复制的部分发生。这个术语指的是客户端被阻塞 - 等待系统的回复。\n在同步阶段期间，第一个服务器会联系其他两个服务器，并等待收到所有其他服务器的回复。最后，它向客户端发送一个响应，告知其结果（例如成功或失败）。\n这一切似乎很简单。在不讨论同步阶段算法的细节的情况下，我们能从这个特定的通信模式安排中得出什么结论呢？首先，注意这是一种 N-对-N 的写入方式：在返回响应之前，它必须被系统中的每个服务器看到并确认。\n从性能的角度来看，这意味着系统的速度将取决于其中最慢的服务器。该系统还对网络延迟的变化非常敏感，因为它要求在继续之前每个服务器都必须回复。\n考虑到 N-对-N 的方式，系统无法容忍任何服务器的丢失。当一个服务器丢失时，系统无法再写入所有节点，因此无法继续进行。在这种设计中，它可能能够对数据提供只读访问，但在节点故障后不允许进行修改。\n这种安排可以提供非常强大的耐久性保证：当返回响应时，客户端可以确信所有 N 个服务器都已接收、存储和确认了请求。为了丢失一个已接受的更新，所有 N 个副本都需要丢失，这是一个非常好的保证。\n异步复制 让我们将其与第二种模式进行对比 - 异步复制（也称为被动复制、拉式复制或惰性复制）。正如您可能已经猜到的，这与同步复制相反：\n在这种情况下，主节点（也称为领导者或协调者）立即向客户端返回响应。它最多只会在本地存储更新，但不会同步执行任何重要工作，客户端也不需要等待更多的服务器之间的通信轮次。\n在稍后的阶段，复制任务的异步部分发生。在这里，主节点使用某种通信模式联系其他服务器，并更新它们的数据副本。具体的实现取决于所使用的算法。\n在不涉及算法细节的情况下，我们对这种具体的安排能得出什么结论呢？嗯，这是一种写 1-对-N 的方式：立即返回响应，更新传播在稍后发生。\n从性能的角度来看，这意味着系统很快：客户端不需要额外花费时间等待系统内部完成工作。系统对网络延迟更具容忍性，因为内部延迟的波动不会导致客户端需要额外等待。\n这种安排只能提供弱的或概率性的耐久性保证。如果没有出现问题，数据最终会复制到所有 N 台机器上。然而，如果在此之前包含数据的唯一服务器丢失，数据将永久丢失。\n考虑到 1-对-N 的方式，只要至少有一个节点正常运行，系统就可以保持可用性（理论上至少如此，但实际上负载可能会太高）。这种纯粹的惰性方式不提供耐久性或一致性保证；你可以向系统写入数据，但如果发生任何故障，不能保证能够读取你所写入的内容。\n最后值得注意的是，被动复制无法确保系统中的所有节点始终包含相同的状态。如果在多个位置接受写入操作，并且不要求这些节点同步一致，那么就会存在发散的风险：不同位置的读取可能返回不同的结果（特别是在节点故障和恢复后），并且无法强制执行全局约束（需要与所有人通信）。\n我没有详细讨论读取（而不是写入）时的通信模式，因为读取模式实际上是根据写入模式来确定的：在读取过程中，你希望与尽可能少的节点进行联系。我们将在仲裁机制的背景下进一步讨论这个问题。\n我们只讨论了两种基本的安排，并没有涉及具体的算法。然而，我们已经能够了解可能的通信模式以及它们的性能、耐久性保证和可用性特性的一些信息。\n主要复制方法概述 在讨论了同步和异步复制这两种基本复制方法之后，让我们来看一下主要的复制算法。\n有很多不同的方式来对复制技术进行分类。在同步与异步之后，我想引入的第二个区别是：\n防止发散的复制方法（单副本系统）和 存在发散风险的复制方法（多主系统） 第一组方法具有“行为像单一系统”的特性。特别是在部分故障发生时，系统确保只有一个副本处于活动状态。此外，系统确保副本始终保持一致。这被称为共识问题。\n当多个进程（或计算机）就某个值达成共识时，它们实现了共识。更具体地说：\n一致性：每个正确的进程必须就同一个值达成一致。 完整性：每个正确的进程最多决定一个值，并且如果它决定了某个值，则该值必须由某个进程提出。 终止性：所有进程最终都会达成决策。 有效性：如果所有正确的进程提议相同的值 V，则所有正确的进程都决定 V。 互斥、领导者选举、组播和原子广播都是共识问题的更一般实例。维护单一副本一致性的复制系统需要以某种方式解决共识问题。 维护单一副本一致性的复制算法包括：\n1n 消息（异步主/备份） 2n 消息（同步主/备份） 4n 消息（两阶段提交，多 Paxos） 6n 消息（三阶段提交，带有重复领导者选举的 Paxos） 这些算法在容错性方面有所不同（例如，它们可以容忍的故障类型）。我根据算法执行期间交换的消息数量进行了简单的分类，因为我认为尝试回答“通过增加消息交换我们得到了什么？”这个问题很有趣。\n下面的图表，改编自 Google 的 Ryan Barret，描述了不同选项的一些方面：\n上述图表中的一致性、延迟、吞吐量、数据丢失和故障转移特性实际上可以追溯到两种不同的复制方法：同步复制（例如，在响应之前等待）和异步复制。当您等待时，性能会变差，但可以获得更强的保证。在讨论分区（和延迟）容忍性时，2PC 和仲裁系统之间的吞吐量差异将变得明显。\n在该图表中，强制弱（/最终）一致性的算法被归类为一类（\u0026ldquo;gossip\u0026rdquo;）。然而，我将更详细地讨论弱一致性的复制方法 - gossip 和（部分）仲裁系统。\u0026ldquo;事务\u0026quot;行实际上更多地涉及全局谓词评估，而在具有弱一致性的系统中不支持（尽管可以支持本地谓词评估）。\n值得注意的是，强制弱一致性要求的系统拥有较少的通用算法，而更多的是可以选择性应用的技术。由于不强制单副本一致性的系统可以像由多个节点组成的分布式系统一样自由操作，因此修复的目标较少，重点更多地放在为人们提供一种推理系统特性的方式上。\n例如：\n以客户为中心的一致性模型试图提供更可理解的一致性保证，同时允许发散。 CRDTs（收敛且可交换的复制数据类型）利用某些状态和基于操作的数据类型的半格特性（结合律、交换律、幂等性）。 收敛分析（如 Bloom 语言中的分析）利用关于计算单调性的信息来最大程度地利用无序性。 PBS（概率有界陈旧度）使用模拟和从现实系统收集的信息来表征部分仲裁系统的预期行为。 接下来，我将稍微介绍所有这些内容，首先让我们来看一下维护单副本一致性的复制算法。 主/备份复制 主/备份复制（也称为主副本复制、主从复制或日志传送）可能是最常用的复制方法和最基本的算法。所有更新都在主节点上执行，并通过网络将操作日志（或更改）发送到备份副本。有两种变体：\n异步主/备份复制 同步主/备份复制 同步版本需要两个消息（\u0026ldquo;更新\u0026rdquo; + \u0026ldquo;确认接收\u0026rdquo;），而异步版本只需要一个消息（\u0026ldquo;更新\u0026rdquo;）就可以运行。\n主/备份复制非常常见。例如，默认情况下，MySQL 复制使用异步变体。MongoDB 也使用主/备份复制（并附带一些故障转移的额外过程）。所有操作都在一个主服务器上执行，它将它们序列化到本地日志，然后异步地复制到备份服务器。\n正如我们在异步复制的背景下讨论过的那样，任何异步复制算法只能提供弱持久性保证。在 MySQL 复制中，这表现为复制延迟：异步备份始终至少落后于主节点一个操作。如果主节点失败，则尚未发送到备份的更新将丢失。\n同步主/备份复制的变体确保在返回给客户端之前已将写操作存储在其他节点上，但需要等待其他副本的响应。然而，值得注意的是，即使这个变体也只能提供弱保证。考虑以下简单的故障场景：\n主节点接收到写操作并将其发送到备份副本。 备份副本持久化并确认写操作。 然后主节点在发送确认给客户端之前失败。 现在客户端假设提交失败，但备份副本已经提交了它；如果将备份副本提升为主节点，那将是错误的。可能需要手动清理来调和失败的主节点或不一致的备份。\n当然，我在这里进行了简化。尽管所有主/备份复制算法都遵循相同的一般消息模式，但它们在故障转移、副本长时间离线等方面的处理方式有所不同。然而，在这种方案中，无法对主节点的不适时故障具有弹性。\n在基于日志传送/主/备份的方案中，关键在于它们只能提供尽力而为的保证（例如，如果节点在不适时故障，可能会出现丢失更新或不正确更新的情况）。此外，主/备份方案容易出现分裂脑（split-brain）问题，即由于临时网络问题导致切换到备份，使得主节点和备份同时处于活动状态。\n为了防止不适时故障导致一致性保证被违反，我们需要增加另一轮消息交换，这将得到两阶段提交协议（2PC）。\n两阶段提交（2PC） 两阶段提交（2PC）是许多经典关系数据库中使用的协议。例如，MySQL Cluster（不要与常规 MySQL 混淆）使用 2PC 提供同步复制。下图说明了消息流：\n[ Coordinator ] -\u0026gt; OK to commit? [ Peers ] \u0026lt;- Yes / No [ Coordinator ] -\u0026gt; Commit / Rollback [ Peers ] \u0026lt;- ACK 在第一阶段（投票阶段）中，协调者将更新发送给所有参与者。每个参与者处理更新并投票决定是否提交或中止。当投票决定提交时，参与者将更新存储在临时区域（预写日志）中。在第二阶段完成之前，更新被视为临时的。\n在第二阶段（决策阶段）中，协调者决定最终结果并通知每个参与者。如果所有参与者都投票决定提交，那么更新将从临时区域中取出并变为永久性。\n在提交变为永久性之前引入第二阶段是有用的，因为它允许系统在节点故障时回滚更新。相比之下，在主/备份（\u0026ldquo;1PC\u0026rdquo;）中，没有回滚操作的步骤，因此在一些节点上失败而在其他节点上成功的操作可能导致副本发散。\n两阶段提交容易受到阻塞的影响，因为单个节点故障（参与者或协调者）会阻塞进展，直到节点恢复。在第二阶段期间，由于其他节点被告知系统状态，因此通常可以进行恢复。请注意，两阶段提交假设每个节点的稳定存储数据永远不会丢失，并且没有节点永久崩溃。如果稳定存储中的数据在崩溃时损坏，仍然可能发生数据丢失。\n有关节点故障期间的恢复程序的详细信息非常复杂，所以我不会详细介绍。主要任务包括确保写入磁盘是持久的（例如，刷新到磁盘而不是缓存）以及确保进行正确的恢复决策（例如，了解轮次的结果，然后本地重新执行或撤消更新）。\n正如我们在有关 CAP 的章节中了解到的那样，两阶段提交是 CA（一致性和可用性）的，而不是分区容忍性。两阶段提交所涉及的故障模型不包括网络分区；从一个节点故障中恢复的规定方法是等待网络分区恢复。没有安全的方式来提升新的协调者如果一个失败；相反，需要手动干预。两阶段提交对延迟也非常敏感，因为它是一个写 N-of-N 的方法，在最慢的节点确认之前无法进行写入。\n两阶段提交在性能和容错性之间取得了很好的平衡，这就是为什么它在关系数据库中非常流行的原因。然而，较新的系统通常使用具有分区容忍性的共识算法，因为这种算法可以提供从临时网络分区自动恢复以及更优雅地处理节点之间延迟增加的能力。\n让我们接下来看一下分区容忍的共识算法。\n分区容忍共识算法 分区容忍的共识算法是我们在维护单副本一致性方面所能达到的最高容错算法。还有一类更进一步的容错算法：能够容忍任意（拜占庭）故障的算法；这些故障包括以恶意方式运作的节点。这类算法在商业系统中很少使用，因为它们的运行成本更高，实现起来更复杂，因此我将不对其进行介绍。\n当涉及到分区容忍的共识算法时，最著名的算法是 Paxos 算法。然而，Paxos 算法以其难以实现和解释而闻名，因此我将重点介绍 Raft 算法，这是一种较新的（约于 2013 年初）旨在易于教学和实现的算法。让我们首先看一下网络分区以及分区容忍的共识算法的一般特点。\n什么是网络分区？ 网络分区是指网络链路对一个或多个节点的故障。节点本身继续保持活动状态，甚至可以接收来自网络分区一侧的客户端请求。正如我们之前在讨论 CAP 定理时了解到的那样，网络分区确实会发生，而不是所有系统都能优雅地处理它们。\n网络分区很棘手，因为在网络分区期间，无法区分远程节点的故障和节点的不可访问性。如果发生网络分区但没有节点故障，那么系统将分为两个同时活动的分区。下面的两个图示展示了网络分区如何与节点故障类似。\n两个节点的系统，一个是故障，一个是网络分区：\n具有 3 个节点的系统，出现故障与网络分区：\n强制执行单副本一致性的系统必须有一种方法来打破对称性，否则它将分裂为两个独立的系统，这些系统可能会发散，并且无法再保持单副本的幻象。\n对于强制执行单副本一致性的系统来说，网络分区容忍要求在网络分区期间，只有系统的一个分区保持活动状态，因为在网络分区期间无法防止发散（例如，CAP 定理）的发生。\n多数决定 这就是为什么分区容忍的共识算法依赖多数投票。要求大多数节点（而不是全部节点，如 2PC 中的情况）对更新达成一致意见，可以容忍少数节点故障、运行缓慢或由于网络分区而无法访问的情况。只要有（N/2 + 1）个或更多的节点正常运行并可访问，系统就可以继续运行。\n分区容忍的共识算法使用奇数个节点（例如 3、5 或 7）。如果只有两个节点，发生故障后就无法形成明确的多数。例如，如果节点数为三，那么系统可以容忍一个节点故障；如果有五个节点，那么系统可以容忍两个节点故障。\n当发生网络分区时，不同分区的行为是不对称的。一个分区将包含大多数节点，而少数分区将停止处理操作，以防止在网络分区期间发生发散，但是多数分区可以保持活动状态。这确保只有系统状态的单个副本保持活动。\n多数投票也有助于容忍不同意见：如果发生干扰或故障，节点可能会投票出现不同的结果。然而，由于只能有一个多数决策，临时的不一致最多只能阻塞协议的继续进行（放弃活性），但不能违反单副本一致性准则（安全性属性）。\n角色 系统可以采用两种方式进行结构化：所有节点可以具有相同的责任，或者节点可以具有独立的、不同的角色。\n复制的共识算法通常选择为每个节点分配不同的角色。拥有单个固定的领导者或主服务器是一种优化，可以使系统更高效，因为我们知道所有的更新都必须通过该服务器进行。非领导者节点只需将其请求转发给领导者。\n需要注意的是，拥有不同的角色并不意味着系统无法从领导者（或任何其他角色）的故障中恢复。即使在正常操作期间角色是固定的，也并不意味着在故障发生后不能通过重新分配角色（例如通过领导者选举阶段）来恢复。节点可以重复使用领导者选举的结果，直到发生节点故障和/或网络分区。\nPaxos 和 Raft 都使用了不同的节点角色。特别是，它们都有一个领导者节点（Paxos 中称为\u0026quot;proposer\u0026rdquo;），负责在正常操作期间进行协调。在正常操作期间，其余的节点是跟随者（Paxos 中的\u0026quot;acceptors\u0026quot;或\u0026quot;voters\u0026quot;）。\n纪元 每个正常运行期间在 Paxos 和 Raft 中被称为一个时代（在 Raft 中称为\u0026quot;term\u0026quot;）。在每个时代中，只有一个节点被指定为领导者（类似的系统在日本被用于天皇继位时更换年号）。\n选举成功后，同一领导者将协调工作直到时代结束。如 Raft 论文中所示的图表，有些选举可能会失败，导致时代立即结束。\n时代充当逻辑时钟的作用，允许其他节点识别过时节点开始通信的时间。那些被划分或处于停止运行状态的节点将具有较小的时代编号，其命令将被忽略。\n通过决斗更换领导者 在正常运行期间，具有分区容错性的共识算法相对较简单。正如之前所看到的，如果我们不关心容错性，可以使用两阶段提交（2PC）。大部分复杂性实际上是由于确保一旦达成共识决策，它将不会丢失，并且协议能够处理由于网络或节点故障而引起的领导者更改。\n所有节点最初都是跟随者；在开始时选举一个节点成为领导者。在正常运行期间，领导者会发送心跳信号，以便跟随者可以检测到领导者是否失效或分区。\n当节点检测到领导者变为无响应状态（或在初始情况下没有领导者存在），它将切换到一个中间状态（在 Raft 中称为\u0026quot;candidate\u0026quot;），此时它会将时代/轮次值增加一，并发起领导者选举并竞争成为新的领导者。\n为了当选为领导者，一个节点必须获得大多数的选票。一种分配选票的方法是简单地按照先到先得的原则进行分配；这样，最终会选出一个领导者。在尝试当选时添加随机的等待时间可以减少同时尝试当选的节点数量。\n一个纪元内的编号提案 在每个时期，领导者每次都会提出一个值进行投票。在每个时期内，每个提案都使用唯一的严格递增的编号进行编号。追随者（投票者/接受者）接受他们收到的针对特定提案编号的第一个提案。\n正常运行期 在正常运行期间，所有提案都通过领导者节点进行处理。当客户端提交一个提案（例如更新操作）时，领导者会联系配额中的所有节点。如果没有竞争性的提案存在（基于跟随者的响应），领导者提出该值。如果大多数跟随者接受该值，那么该值被视为已接受。\n由于可能有另一个节点也在尝试充当领导者，我们需要确保一旦一个提案被接受，其值就不能改变。否则，已经被接受的提案可能会被竞争对手领导者撤销。Lamport 将此规定为：\nP2：如果选择了一个值为 v 的提案，那么被选择的每个更高编号的提案都具有值 v。\n确保该属性成立要求跟随者和提议者都受到算法的约束，不能改变已被大多数接受的值。注意，“值永远不会改变”是指协议的单个执行（或运行/实例/决策）的值。典型的复制算法将运行多个算法的执行，但大多数关于算法的讨论都集中在单个运行上，以保持简单。我们希望防止决策历史被修改或覆盖。\n为了强制执行这个属性，提议者必须首先向跟随者询问它们（最高编号的）已接受的提案和值。如果提议者发现已经存在一个提案，那么它必须简单地完成该协议的执行，而不是提出自己的提案。Lamport 将此规定为：\nP2b. 如果选择了一个值为 v 的提案，那么由任何提议者发出的每个更高编号的提案都具有值 v。\n更具体地说：\nP2c. 对于任何 v 和 n，如果一个值为 v 且编号为 n 的提案被发出（由领导者），那么存在一个由大多数接受者（跟随者）组成的集合 S，其中要么（a）S 中的没有接受任何编号小于 n 的提案的接受者，要么（b）v 是 S 中的跟随者接受的所有编号小于 n 的提案中最高编号提案的值。\n这是 Paxos 算法以及从中衍生的算法的核心。要提出的值直到协议的第二阶段才会被选择。为了确保安全性（例如 P2c 中的 b 条款），提议者有时必须简单地重传先前做出的决策，直到达到一个他们知道可以自由提出自己的提案值的点（例如 P2c 中的 a 条款）。\n如果存在多个先前的提案，则提议的是最高编号的提案值。只有在没有竞争性提案的情况下，提议者才可以尝试施加自己的值。\n为了确保在提议者询问每个接受者其最新值之间不会出现竞争性提案，提议者要求跟随者不接受低于当前提案编号的提案。\n将这些部分整合在一起，使用 Paxos 达成决策需要两轮通信：\n[ Proposer ] -\u0026gt; Prepare(n) [ Followers ] \u0026lt;- Promise(n; previous proposal number and previous value if accepted a proposal in the past) [ Proposer ] -\u0026gt; AcceptRequest(n, own value or the value [ Followers ] associated with the highest proposal number reported by the followers) \u0026lt;- Accepted(n, value) 准备阶段允许提议者了解任何竞争或先前的提案。第二阶段是提出新值或先前接受的值的阶段。在某些情况下，比如同时存在两个提议者（竞争），消息丢失，或者大多数节点发生故障时，没有提案被大多数接受。但这是可以接受的，因为关于提出哪个值的决策规则会趋向于收敛到一个值（上一次尝试中具有最高提案编号的值）。\n的确，根据 FLP 不可能性结果，这是我们能做到的最好的：解决共识问题的算法在消息传递的界限不满足时，必须在安全性和活性之间做出权衡。Paxos 放弃了活性：它可能不得不无限期地延迟决策，直到没有竞争的领导者，并且大多数节点接受提案。这比违反安全性保证要好。\n当然，实现这个算法要比听起来的要困难得多。即使在专家的手中，许多小问题加在一起也会形成相当大量的代码。这些问题包括：\n实际优化： 通过领导租约（而不是心跳）避免重复的领导者选举 在处于稳定状态且领导者身份不变的情况下避免重复的提出消息 确保跟随者和提议者不会丢失稳定存储中的项目，并且稳定存储中的结果不会被细微损坏（例如磁盘损坏） 以安全方式启用群集成员资格的更改（例如，基本的 Paxos 依赖于大多数节点总是在一个节点中相交，如果成员资格可以任意更改，则不成立） 在崩溃、磁盘丢失或新节点供应时以安全高效的方式使新副本保持最新 在一段合理的时间后对保证安全性所需的数据进行快照和垃圾回收的程序（例如，平衡存储需求和容错需求） Google 的《Paxos Made Live》论文详细介绍了其中的一些挑战。 分区容忍共识算法：Paxos、Raft、ZAB 希望这些信息让你对容错共识算法的工作原理有了一定的了解。我鼓励你阅读进一步阅读部分中的其中一篇论文，以更好地了解不同算法的具体细节。\nPaxos：Paxos 是编写强一致性容错复制系统时最重要的算法之一。它被广泛应用于谷歌的许多系统中，包括 BigTable/Megastore 使用的 Chubby 锁管理器、Google 文件系统以及 Spanner。\nPaxos 的名称来自希腊岛屿帕克索斯，最初由 Leslie Lamport 在 1998 年的一篇名为《兼职议会》的论文中提出。人们通常认为 Paxos 的实现很困难，因此有一系列来自在分布式系统领域具有相当经验的公司的论文，进一步解释了实际细节（请参阅进一步阅读部分）。你可能会想阅读 Lamport 在此问题上的评论（链接 1 和链接 2）。\n这些问题主要与 Paxos 被描述为一轮共识决策相关，但实际的工作实施通常希望能够高效地运行多轮共识。这导致了许多对核心协议的扩展的开发，任何想构建基于 Paxos 的系统的人都需要理解这些扩展。此外，还存在其他实际挑战，例如如何实现集群成员资格的变更。\nZAB：ZAB（Zookeeper Atomic Broadcast）协议在 Apache Zookeeper 中使用。Zookeeper 是一个为分布式系统提供协调原语的系统，许多以 Hadoop 为中心的分布式系统用于协调（例如 HBase、Storm、Kafka）。Zookeeper 基本上是开源社区对 Chubby 的实现。从技术上讲，原子广播是一个与纯共识不同的问题，但它仍属于确保强一致性的容错算法的范畴。\nRaft：Raft 是这类算法的最新成员（于 2013 年提出）。它的设计目标是比 Paxos 更容易教授，同时提供相同的保证。特别是，该算法的不同部分更清晰地分离，论文还描述了一种集群成员资格变更的机制。最近，etcd 在受到 ZooKeeper 的启发下开始采用 Raft。\n强一致性的复制方法 在本章中，我们研究了强一致性的复制方法。从同步工作和异步工作的对比开始，逐步介绍了能够容忍越来越复杂故障的算法。以下是每个算法的一些关键特点：\n主/备份\n单个固定的主节点 复制日志，从节点不参与执行操作 没有对复制延迟设置界限 不具备容错性，不支持分区容忍性 手动/临时故障转移，不具备容错性，热备份 2PC（两阶段提交）\n全体投票：提交或中止 静态主节点 2PC 无法在协调者和节点在提交期间同时发生故障时生存 不具备容错性，对尾延迟敏感 Paxos\n多数派投票 动态主节点 作为协议的一部分，能够容忍 n/2-1 同时发生的故障 对尾延迟不太敏感 进一步阅读 主备和 2PC Replication techniques for availability - Robbert van Renesse \u0026amp; Rachid Guerraoui, 2010 Concurrency Control and Recovery in Database Systems Paxos The Part-Time Parliament - Leslie Lamport Paxos Made Simple - Leslie Lamport, 2001 Paxos Made Live - An Engineering Perspective - Chandra et al Paxos Made Practical - Mazieres, 2007 Revisiting the Paxos Algorithm - Lynch et al How to build a highly available system with consensus - Butler Lampson Reconfiguring a State Machine - Lamport et al - changing cluster membership Implementing Fault-Tolerant Services Using the State Machine Approach: a Tutorial - Fred Schneider Raft and ZAB In Search of an Understandable Consensus Algorithm, Diego Ongaro, John Ousterhout, 2013 Raft Lecture - User Study A simple totally ordered broadcast protocol - Junqueira, Reed, 2008 ZooKeeper Atomic Broadcast - Reed, 2011 ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-04/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n4. 复制 复制问题是分布式系统中的众多问题之一。与诸如领导者选举、故障检测、互斥、共识和全局快照等其他问题相比，我选择关注复制问题，因为这通常是人们最感兴趣的部分。并行数据库在复制特性方面的差异化就是一个例子。此外，复制为许多子问题提供了一个上下文，例如领导者选举、故障检测、共识和原子广播。\n复制是一个组通信问题。什么样的安排和通信模式能够满足我们所期望的性能和可用性特性？在面对网络分区和同时节点故障的情况下，我们如何确保容错性、耐久性和非发散性？\n同样，有许多方法可以解决复制问题。我在这里采用的方法只是看一下具有复制功能的系统可能具有的高级模式。从可视化的角度来看，有助于将讨论集中在整体模式上，而不是具体涉及的消息传递。我在这里的目标是探索设计空间，而不是解释每个算法的具体细节。\n让我们首先定义一下复制是什么样子。我们假设我们有一些初始数据库，并且客户端发出请求来改变数据库的状态。\n这种安排和通信模式可以分为几个阶段：\n（请求）客户端向服务器发送请求 （同步）进行复制的同步部分 （响应）将响应返回给客户端 （异步）进行复制的异步部分 根据这些阶段，我们可以创建不同的通信模式。我们选择的模式将对性能和可用性产生影响，具体取决于所选择的算法。\n同步复制 第一个模式是同步复制（也称为主动复制、急切复制、推送复制或悲观复制）。让我们画出它的示意图：\n在这里，我们可以看到三个明显的阶段：首先，客户端发送请求。接下来，我们所称的同步复制的部分发生。这个术语指的是客户端被阻塞 - 等待系统的回复。\n在同步阶段期间，第一个服务器会联系其他两个服务器，并等待收到所有其他服务器的回复。最后，它向客户端发送一个响应，告知其结果（例如成功或失败）。\n这一切似乎很简单。在不讨论同步阶段算法的细节的情况下，我们能从这个特定的通信模式安排中得出什么结论呢？首先，注意这是一种 N-对-N 的写入方式：在返回响应之前，它必须被系统中的每个服务器看到并确认。\n从性能的角度来看，这意味着系统的速度将取决于其中最慢的服务器。该系统还对网络延迟的变化非常敏感，因为它要求在继续之前每个服务器都必须回复。\n考虑到 N-对-N 的方式，系统无法容忍任何服务器的丢失。当一个服务器丢失时，系统无法再写入所有节点，因此无法继续进行。在这种设计中，它可能能够对数据提供只读访问，但在节点故障后不允许进行修改。\n这种安排可以提供非常强大的耐久性保证：当返回响应时，客户端可以确信所有 N 个服务器都已接收、存储和确认了请求。为了丢失一个已接受的更新，所有 N 个副本都需要丢失，这是一个非常好的保证。\n异步复制 让我们将其与第二种模式进行对比 - 异步复制（也称为被动复制、拉式复制或惰性复制）。正如您可能已经猜到的，这与同步复制相反：\n在这种情况下，主节点（也称为领导者或协调者）立即向客户端返回响应。它最多只会在本地存储更新，但不会同步执行任何重要工作，客户端也不需要等待更多的服务器之间的通信轮次。\n在稍后的阶段，复制任务的异步部分发生。在这里，主节点使用某种通信模式联系其他服务器，并更新它们的数据副本。具体的实现取决于所使用的算法。\n在不涉及算法细节的情况下，我们对这种具体的安排能得出什么结论呢？嗯，这是一种写 1-对-N 的方式：立即返回响应，更新传播在稍后发生。\n从性能的角度来看，这意味着系统很快：客户端不需要额外花费时间等待系统内部完成工作。系统对网络延迟更具容忍性，因为内部延迟的波动不会导致客户端需要额外等待。\n这种安排只能提供弱的或概率性的耐久性保证。如果没有出现问题，数据最终会复制到所有 N 台机器上。然而，如果在此之前包含数据的唯一服务器丢失，数据将永久丢失。\n考虑到 1-对-N 的方式，只要至少有一个节点正常运行，系统就可以保持可用性（理论上至少如此，但实际上负载可能会太高）。这种纯粹的惰性方式不提供耐久性或一致性保证；你可以向系统写入数据，但如果发生任何故障，不能保证能够读取你所写入的内容。\n最后值得注意的是，被动复制无法确保系统中的所有节点始终包含相同的状态。如果在多个位置接受写入操作，并且不要求这些节点同步一致，那么就会存在发散的风险：不同位置的读取可能返回不同的结果（特别是在节点故障和恢复后），并且无法强制执行全局约束（需要与所有人通信）。\n我没有详细讨论读取（而不是写入）时的通信模式，因为读取模式实际上是根据写入模式来确定的：在读取过程中，你希望与尽可能少的节点进行联系。我们将在仲裁机制的背景下进一步讨论这个问题。\n我们只讨论了两种基本的安排，并没有涉及具体的算法。然而，我们已经能够了解可能的通信模式以及它们的性能、耐久性保证和可用性特性的一些信息。\n主要复制方法概述 在讨论了同步和异步复制这两种基本复制方法之后，让我们来看一下主要的复制算法。\n有很多不同的方式来对复制技术进行分类。在同步与异步之后，我想引入的第二个区别是：\n防止发散的复制方法（单副本系统）和 存在发散风险的复制方法（多主系统） 第一组方法具有“行为像单一系统”的特性。特别是在部分故障发生时，系统确保只有一个副本处于活动状态。此外，系统确保副本始终保持一致。这被称为共识问题。\n当多个进程（或计算机）就某个值达成共识时，它们实现了共识。更具体地说：\n一致性：每个正确的进程必须就同一个值达成一致。 完整性：每个正确的进程最多决定一个值，并且如果它决定了某个值，则该值必须由某个进程提出。 终止性：所有进程最终都会达成决策。 有效性：如果所有正确的进程提议相同的值 V，则所有正确的进程都决定 V。 互斥、领导者选举、组播和原子广播都是共识问题的更一般实例。维护单一副本一致性的复制系统需要以某种方式解决共识问题。 维护单一副本一致性的复制算法包括：\n1n 消息（异步主/备份） 2n 消息（同步主/备份） 4n 消息（两阶段提交，多 Paxos） 6n 消息（三阶段提交，带有重复领导者选举的 Paxos） 这些算法在容错性方面有所不同（例如，它们可以容忍的故障类型）。我根据算法执行期间交换的消息数量进行了简单的分类，因为我认为尝试回答“通过增加消息交换我们得到了什么？”这个问题很有趣。\n下面的图表，改编自 Google 的 Ryan Barret，描述了不同选项的一些方面：\n上述图表中的一致性、延迟、吞吐量、数据丢失和故障转移特性实际上可以追溯到两种不同的复制方法：同步复制（例如，在响应之前等待）和异步复制。当您等待时，性能会变差，但可以获得更强的保证。在讨论分区（和延迟）容忍性时，2PC 和仲裁系统之间的吞吐量差异将变得明显。\n在该图表中，强制弱（/最终）一致性的算法被归类为一类（\u0026ldquo;gossip\u0026rdquo;）。然而，我将更详细地讨论弱一致性的复制方法 - gossip 和（部分）仲裁系统。\u0026ldquo;事务\u0026quot;行实际上更多地涉及全局谓词评估，而在具有弱一致性的系统中不支持（尽管可以支持本地谓词评估）。","title":"[译]《分布式系统：为了乐趣和利益》4.复制"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n3. 时间及顺序 什么是顺序，为什么它很重要？\n你说的“什么是顺序”是什么意思？\n我的意思是，为什么我们对顺序如此着迷？为什么我们关心 A 是否发生在 B 之前？为什么我们不关心其他属性，比如“颜色”？\n好吧，我的疯狂朋友，让我们回到分布式系统的定义来回答这个问题。\n你可能还记得，我将分布式编程描述为使用多台计算机解决单台计算机可以解决的同一个问题的艺术。\n事实上，这正是对顺序如此着迷的核心所在。任何只能一次执行一项任务的系统都会创建操作的总体顺序。就像人们通过一扇门一样，每个操作都有明确定义的前任和后继。这基本上是我们努力保留的编程模型。\n传统的模型是：一个程序，一个进程，一个在一个 CPU 上运行的内存空间。操作系统抽象了可能存在多个 CPU 和多个程序的事实，以及计算机内存实际上是多个程序共享的。我并不是说线程编程和事件驱动编程不存在；只是它们是“一个/一个/一个”模型之上的特殊抽象。程序被编写成按照一定顺序执行：从上往下执行。\n顺序作为一种属性受到了如此多的关注，是因为定义“正确性”的最简单方法是说“它的工作方式与单台计算机上的工作方式相同”。而通常这意味着 a）我们运行相同的操作，b）我们按照相同的顺序运行它们 - 即使有多台计算机。\n保持顺序（如单个系统定义的顺序）的分布式系统的优点在于它们是通用的。你不需要关心操作是什么，因为它们将与在单台计算机上完全相同的方式执行。这很棒，因为你知道无论操作是什么，你都可以使用相同的系统。\n实际上，分布式程序在多个节点上运行，具有多个 CPU 和多个操作流。你仍然可以分配一个总体顺序，但这需要准确的时钟或某种形式的通信。你可以使用完全准确的时钟为每个操作标记时间戳，然后利用它来确定总体顺序。或者你可以使用某种通信系统，使得可以分配类似总体顺序的连续编号。\n全序和偏序 在分布式系统中，自然状态是偏序。网络和独立节点都不对相对顺序做出任何保证，但在每个节点上，你可以观察到一个局部顺序。\n总序是一种二元关系，它为某个集合中的每个元素定义了一个顺序。\n当两个不同的元素可比较时，其中一个大于另一个。在偏序集中，某些元素对不可比较，因此偏序并不指定每个项目的确切顺序。\n总序和偏序都是传递性和反对称性的。对于集合 X 中的所有 a、b 和 c，以下陈述在总序和偏序中都成立：\nIf a ≤ b and b ≤ a then a = b (antisymmetry); If a ≤ b and b ≤ c then a ≤ c (transitivity); 然而，总序是完全的：\na ≤ b or b ≤ a (totality) for all a, b in X 而偏序是自反的：\na ≤ a (reflexivity) for all a in X 注意，全序性蕴含自反性；因此，偏序是总序的一种较弱的变体。在偏序中的某些元素上，全序性不成立 - 换句话说，其中一些元素不可比较。\nGit 分支是偏序的一个例子。正如你可能知道的，Git 版本控制系统允许你从单个基础分支（例如主分支）创建多个分支。每个分支表示基于共同祖先的源代码更改历史：\n[ branch A (1,2,0)] [ master (3,0,0) ] [ branch B (1,0,2) ] [ branch A (1,1,0)] [ master (2,0,0) ] [ branch B (1,0,1) ] \\ [ master (1,0,0) ] / 分支 A 和分支 B 是从一个共同的祖先派生出来的，但它们之间没有确定的顺序：它们代表不同的历史，不能简化为单一的线性历史而不经过额外的工作（合并）。当然，你可以按某种任意顺序放置所有提交（例如，首先按祖先排序，然后按照 A 在 B 之前或 B 在 A 之前的顺序排序），但这会通过强制存在不存在的总序来丢失信息。\n在由一个节点组成的系统中，总序是必然产生的：指令在单个程序中以特定的可观察顺序执行，消息以特定的顺序处理。我们已经依赖于这个总序 - 它使程序的执行可预测。在分布式系统中可以维护这种顺序，但代价很大：通信是昂贵的，时间同步是困难且脆弱的。\n时间是什么？ 时间是一种秩序的来源，它允许我们定义操作的顺序，而这个顺序也有人们可以理解的解释（秒、分钟、天等）。\n从某种意义上说，时间就像任何其他整数计数器一样。它只是因为太重要，以至于大多数计算机都有一个专用的时间传感器，也称为时钟。它非常重要，以至于我们已经找出了如何使用一些不完善的物理系统（从蜡烛到铯原子）合成同一个计数器的近似值。我所说的“合成”，是指我们可以通过某些物理属性在物理上相距较远的地方近似计算整数计数器的值，而不需要直接进行通信。\n时间戳实际上是一个简写值，用于表示从宇宙起源到当前时刻的世界状态 - 如果某个事物发生在特定的时间戳上，那么它可能受到之前发生的一切事物的影响。这个想法可以推广为一个因果时钟，它明确跟踪原因（依赖关系），而不仅仅假设前一个时间戳之前的一切都是相关的。当然，通常的假设是我们只关心特定系统的状态，而不是整个世界。\n假设时间在任何地方以相同的速度流逝 - 这是一个很大的假设，我一会儿会回到这个问题上 - 时间和时间戳在程序中使用时有几种有用的解释。这三种解释分别是：\n顺序\n持续时间\n解释\n顺序。当我说时间是秩序的来源时，我的意思是：\n我们可以将时间戳附加到无序事件上以对它们进行排序。 我们可以使用时间戳来强制执行操作的特定顺序或消息的传递（例如，如果操作到达的顺序错误，则延迟该操作）。 我们可以使用时间戳的值来确定某件事在时间上是否发生在另一件事之前。 解释 - 时间作为可普遍比较的值。时间戳的绝对值可以解释为日期，对人类来说很有用。通过日志文件中停机开始的时间戳，你可以知道那是上个星期六，当时有一场雷暴。\n持续时间 - 以时间为单位测量的持续时间与现实世界有一定的关系。算法通常不关心时钟的绝对值或其作为日期的解释，但它们可能使用持续时间进行某些判断。特别是，等待的时间长度可以提供有关系统是否分区或仅遇到高延迟的线索。\n由于分布式系统的特性，其组件的行为并不可预测。它们不保证任何特定的顺序、前进速度或无延迟。每个节点都有一些局部顺序 - 因为执行是（大致上）顺序执行的 - 但这些局部顺序彼此独立。\n强加（或假设）顺序是减少可能执行和可能发生情况空间的一种方式。当事物可以以任何顺序发生时，人们很难推理事物 - 要考虑的排列组合太多了。\n时间在任何地方都以相同的速度前进吗？ 我们每个人都根据自己的个人经验对时间有一种直观的概念。不幸的是，这种直观的时间观念更容易想象出完全顺序而不是部分顺序。我们更容易想象事物一个接一个地发生的顺序，而不是同时发生。对于消息的单一顺序进行推理比推理以不同顺序和不同延迟到达的消息更容易。\n然而，在实施分布式系统时，我们希望避免对时间和顺序做出强烈的假设，因为假设越强，系统对于“时间传感器”或内部时钟的问题就越脆弱。此外，强加一种顺序是有代价的。我们能够容忍的时间非确定性越多，就越能充分利用分布式计算的优势。\n对于“时间是否在任何地方以相同的速率流逝”的问题，有三种常见的回答。它们分别是：\n“全局时钟”：是的 “本地时钟”：不是，但是 “无时钟”：不是！ 这些大致对应于我在第二章中提到的三种时间假设：同步系统模型具有全局时钟，部分同步模型具有本地时钟，在异步系统模型中根本不能使用时钟。让我们更详细地看看这些。\n具有“全球时钟”假设的时间 全球时钟假设是存在一个完全精确的全球时钟，并且每个人都可以使用该时钟。这就是我们思考时间的方式，因为在人类互动中，时间上的微小差异并不重要。\n全局时钟基本上是总序的来源（即使这些节点从未进行过通信，也能精确确定所有节点上每个操作的顺序）。\n然而，这是对世界的理想化观点：实际上，时钟同步只能以有限的精度进行。这受限于商品计算机时钟的准确性不足，受限于使用诸如 NTP 的时钟同步协议时的延迟，以及基本上受限于时空的本质。\n假设分布式节点上的时钟完全同步意味着假设时钟从相同的值开始，永远不会漂移。这是一个很好的假设，因为你可以自由使用时间戳来确定全局总序 - 以时钟漂移为界限，而不是延迟 - 但这是一个非平凡的操作挑战和潜在的异常源。存在许多不同的情况，其中简单的故障 - 比如用户意外更改机器上的本地时间，或者过时的机器加入集群，或者同步的时钟以稍微不同的速率漂移等等 - 可能会导致难以追踪的异常。\n尽管如此，有一些现实世界的系统做出了这种假设。Facebook 的 Cassandra 就是一个假设时钟同步的系统示例。它使用时间戳来解决写入冲突 - 具有较新时间戳的写入操作获胜。这意味着如果时钟漂移，新数据可能会被旧数据忽略或覆盖；同样，这是一个操作上的挑战（据我所听说的，人们对此非常清楚）。另一个有趣的例子是 Google 的 Spanner：该论文描述了他们的 TrueTime API，它同步时间但也估计最坏情况下的时钟漂移。\n“本地时钟”假设的时间 第二个也许更合理的假设是每台机器都有自己的时钟，但没有全局时钟。这意味着您无法使用本地时钟来确定远程时间戳是发生在本地时间戳之前还是之后；换句话说，您无法有意义地比较两台不同机器的时间戳。\n本地时钟假设更接近于现实世界。它建立了一个部分顺序：每个系统上的事件被排序，但通过仅使用时钟无法对跨系统的事件进行排序。\n然而，在单个机器上，您可以使用时间戳对事件进行排序；只要小心不允许时钟跳动，您可以在单个机器上使用超时。当然，在由最终用户控制的机器上，这可能假设得太多了：例如，用户在使用操作系统的日期控件查找日期时可能会意外更改日期为其他值。\n在实际的分布式系统中，仅依靠本地时钟来对跨不同机器的事件进行排序可能导致不一致性，并且在实现对系统状态的全局视图方面存在挑战。为了解决这些问题并在系统间建立事件的部分顺序，使用各种同步机制和算法，例如逻辑时钟或向量时钟。这些机制通常利用节点之间的消息交换和协调来实现对分布式系统的一致视图。\n“无时钟”假设的时间 最后，还有逻辑时间的概念。在这种情况下，我们根本不使用时钟，而是以某种其他方式跟踪因果关系。请记住，时间戳只是对该时刻之前世界状态的一种简写 - 因此，我们可以使用计数器和通信来确定某个事件是在另一个事件之前、之后还是同时发生。\n通过这种方式，我们可以确定不同机器之间事件的顺序，但无法对时间间隔进行任何说明，也无法使用超时（因为我们假设没有\u0026quot;时间传感器\u0026quot;）。这是一个部分顺序：在单个系统上，可以使用计数器而无需通信来对事件进行排序，但在系统间对事件进行排序则需要进行消息交换。\n在分布式系统中，Lamport 关于时间、时钟和事件排序的论文是最被引用的之一。向量时钟是该概念的推广（我将更详细地介绍它），它是一种在不使用时钟的情况下跟踪因果关系的方法。Cassandra 的近亲产品 Riak（Basho）和 Voldemort（Linkedin）使用向量时钟而不是假设节点具有完全准确的全局时钟。这使得这些系统能够避免之前提到的时钟准确性问题。\n当不使用时钟时，跨远程机器对事件进行排序的最大精度受到通信延迟的限制。\n分布式系统中的时间是如何使用的？ 时间的好处在于：\n定义系统中的顺序（无需通信）：时间可以在系统中定义事件的顺序，即使没有直接的通信。通过时间戳或逻辑时钟，可以将事件按照它们发生的顺序进行排序。 为算法定义边界条件：时间可以用来划定算法的边界条件，特别是区分“高延迟”和“服务器或网络连接断开”。这是非常重要的应用场景；在大多数现实世界的系统中，超时用于确定远程机器是否失败，或者它是否仅仅是遇到了高网络延迟。用于进行此类判断的算法称为故障检测器（failure detectors）。 在分布式系统中，事件的顺序非常重要，因为许多分布式系统的性质是通过操作/事件的顺序来定义的：\n正确性取决于（对事件顺序的）正确一致性，例如在分布式数据库中的可串行化性。 当资源争用发生时，顺序可以用作决定性因素，例如如果有两个对于一个小部件的订单，可以满足第一个订单并取消第二个订单。 全局时钟将允许在两台不同的机器上的操作进行排序，而无需这两台机器直接通信。没有全局时钟，我们需要通过通信来确定顺序。\n因此，时间在分布式系统中具有重要的作用，可以帮助实现事件的顺序确定、算法的边界条件划定以及故障检测等关键功能。\n矢量时钟（因果顺序的时间） 之前我们讨论了分布式系统中时间进展速率的不同假设。假设我们无法实现准确的时钟同步，或者以系统不对时间同步问题敏感为目标，我们如何对事件进行排序呢？\nLamport 时钟和向量时钟是替代物理时钟的解决方案，它们依靠计数器和通信来确定分布式系统中事件的顺序。这些时钟提供了一个可在不同节点之间进行比较的计数器。\nLamport 时钟很简单。每个进程使用以下规则来维护一个计数器：\n每当进程执行工作时，增加计数器的值。 每当进程发送消息时，将计数器的值包含在消息中。 当接收到消息时，将计数器设置为max(local_counter, received_counter) + 1。 以下是用代码表达的示例：\nfunction LamportClock() { this.value = 1; } LamportClock.prototype.get = function () { return this.value; }; LamportClock.prototype.increment = function () { this.value++; }; LamportClock.prototype.merge = function (other) { this.value = Math.max(this.value, other.value) + 1; }; Lamport 时钟允许在系统之间比较计数器，但有一个限制：Lamport 时钟定义了一个偏序关系。如果 timestamp(a) \u0026lt; timestamp(b)：\na 可能在 b 之前发生，或者 a 与 b 不可比较 这被称为时钟一致性条件：如果一个事件在另一个事件之前发生，则该事件的逻辑时钟在其他事件之前。如果 a 和 b 来自同一因果历史，例如两个时间戳值都来自同一个进程，或者 b 是对 a 发送的消息的响应，那么我们知道 a 在 b 之前发生。\n直观上讲，这是因为 Lamport 时钟只能携带关于一个时间线/历史的信息；因此，将从未相互通信的系统的 Lamport 时间戳进行比较可能导致并发事件在没有顺序关系的情况下被排序。\n想象一个系统，在初始阶段之后分为两个永不相互通信的独立子系统。\n对于每个独立系统中的所有事件，如果 a 在 b 之前发生，则 ts(a) \u0026lt; ts(b)；但是，如果你从不同的独立系统中选择两个事件（即彼此无因果关系的事件），则无法对它们的相对顺序做出有意义的判断。虽然系统的每个部分已经为事件分配了时间戳，但这些时间戳之间没有关联。即使两个事件无关，它们可能看起来是有序的。\n然而，从单台机器的角度来看，仍然有一个有用的性质：以 ts(a)发送的任何消息都会收到一个 ts(b) \u0026gt; ts(a)的响应。\n向量时钟是 Lamport 时钟的扩展，它维护了一个包含 N 个逻辑时钟（每个节点一个）的数组[t1, t2, \u0026hellip;]。每个节点在每个内部事件中不是递增一个公共计数器，而是递增向量中表示该节点的逻辑时钟的值。因此，更新规则如下：\n当一个进程执行工作时，增加向量中节点的逻辑时钟值。\n当一个进程发送消息时，包括完整的逻辑时钟向量。\n当接收到一条消息时：\n将向量中的每个元素更新为本地和接收到的值的最大值。\n增加表示当前节点的逻辑时钟值的向量中的元素。\n以下是相应的代码实现：\nfunction VectorClock(value) { // expressed as a hash keyed by node id: e.g. { node1: 1, node2: 3 } this.value = value || {}; } VectorClock.prototype.get = function () { return this.value; }; VectorClock.prototype.increment = function (nodeId) { if (typeof this.value[nodeId] == \u0026#34;undefined\u0026#34;) { this.value[nodeId] = 1; } else { this.value[nodeId]++; } }; VectorClock.prototype.merge = function (other) { var result = {}, last, a = this.value, b = other.value; // This filters out duplicate keys in the hash Object.keys(a) .concat(b) .sort() .filter(function (key) { var isDuplicate = key == last; last = key; return !isDuplicate; }) .forEach(function (key) { result[key] = Math.max(a[key] || 0, b[key] || 0); }); this.value = result; }; 此图（来源）显示了矢量时钟：\n每个节点（A、B、C）都跟踪向量时钟。随着事件发生，它们会被标记上当前向量时钟的值。通过检查向量时钟，例如{ A: 2, B: 4, C: 1 }，我们可以准确地确定（可能）影响该事件的消息。\n向量时钟的问题主要在于它们需要每个节点一个条目，这意味着对于大型系统来说，它们可能会变得非常庞大。为了减小向量时钟的大小，已经应用了各种技术（例如定期进行垃圾回收，或通过限制大小来降低准确性）。\n我们已经看过如何在没有物理时钟的情况下跟踪顺序和因果关系。现在，让我们看看如何使用时间持续期进行截止。\n故障检测器（截止时间） 如我之前所述，等待的时间量可以提供关于系统是分区还是仅遇到高延迟的线索。在这种情况下，我们不需要假设一个完全准确的全局时钟，只需要有一个足够可靠的本地时钟即可。\n给定在一个节点上运行的程序，它如何判断远程节点是否失败？在没有准确信息的情况下，我们可以推断在经过一段合理的时间后，无响应的远程节点已经失败。\n但是，什么是“合理的时间”？这取决于本地和远程节点之间的延迟。与其明确地指定具有特定值的算法（在某些情况下不可避免地是错误的），最好处理一个合适的抽象概念。\n故障检测器是一种用于抽象化准确计时假设的方法。故障检测器使用心跳消息和定时器实现。进程交换心跳消息。如果在超时之前未收到消息响应，则进程怀疑其他进程。\n基于超时的故障检测器存在过于激进（宣布节点失败）或过于保守（需要很长时间才能检测到崩溃）的风险。故障检测器需要多准确才能使用？\nChandra 等人（1996）在解决共识问题的背景下讨论了故障检测器，这是一个特别相关的问题，因为它是大多数复制问题的基础，其中副本需要在具有延迟和网络分区的环境中达成一致。\n他们使用两个属性来描述故障检测器：完整性和准确性：\n强完整性。每个崩溃的进程最终被每个正确的进程怀疑。 弱完整性。每个崩溃的进程最终被某个正确的进程怀疑。 强准确性。没有正确的进程被怀疑。 弱准确性。某个正确的进程从未被怀疑。 完整性比准确性更容易实现；事实上，所有重要的故障检测器都可以达到它 - 你所需要做的就是不永远等待来怀疑某人。Chandra 等人指出，具有弱完整性的故障检测器可以转化为具有强完整性的故障检测器（通过广播有关被怀疑进程的信息），从而使我们可以集中关注准确性属性的范围。\n除非您能够假设消息延迟存在硬上限，否则很难避免错误地怀疑非故障进程。这个假设可以在同步系统模型中进行 - 因此，在这种系统中，故障检测器可以是强准确的。在不对消息延迟施加硬限制的系统模型下，故障检测最多只能是最终准确的。\nChandra 等人表明，即使是非常弱的故障检测器 - 最终弱故障检测器 ⋄W（最终弱准确性+弱完整性） - 也可以用于解决共识问题。下面的图表（来自论文）说明了系统模型和问题可解性之间的关系：\n正如您上面所看到的，在异步系统中，如果没有故障检测器（或对时间边界的强假设，例如同步系统模型），就无法确定远程节点是崩溃了还是仅仅遇到了高延迟。对于任何追求单一副本一致性的系统来说，这种区分是重要的：故障节点可以被忽略，因为它们不会导致数据的分歧，但分区节点则不能被安全地忽略。\n如何实现故障检测器呢？从概念上讲，一个简单的故障检测器并没有太多复杂的内容，它只是在超时后检测到失败。最有趣的部分涉及如何判断远程节点是否失败。\n理想情况下，我们希望故障检测器能够自适应不断变化的网络条件，并避免将超时值硬编码到其中。例如，Cassandra 使用了一种称为累积故障检测器的方法，它会输出一个怀疑级别（介于 0 和 1 之间的值），而不是二进制的“上”或“下”判断。这使得使用故障检测器的应用程序可以根据准确性和早期检测之间的权衡做出自己的决策。\n累积故障检测器的实现方式可以根据具体的算法和系统需求而有所不同。它通常基于心跳机制，使用心跳消息和定时器来检测节点的存活状态。具体的实现可能涉及超时时间的选择、可疑级别的计算方法以及如何根据累积的信息进行判断等。\n通过使用累积故障检测器或类似的方法，可以使故障检测器能够根据网络条件的变化进行动态调整，并提供更灵活的判断结果，以满足系统的需求。这样的故障检测器可以帮助系统在异步环境中实现更可靠的一致性。\n时间、顺序和表现 之前，我提到了需要为顺序付出代价，您想知道这是什么意思？\n如果您正在编写一个分布式系统，那么您可能拥有多台计算机。在这种情况下，对于事件的自然（也是现实）观点是部分顺序而不是总顺序。您可以将部分顺序转化为总顺序，但这需要通信、等待，并且会施加限制，限制了在任何特定时间点上可以工作的计算机数量。\n所有时钟都只是近似值，受网络延迟（逻辑时间）或物理限制。即使在多个节点之间保持一个简单的整数计数器同步也是一个挑战。\n尽管时间和顺序经常一起讨论，但时间本身并不是一个非常有用的属性。算法关心的不是时间，而是更抽象的属性：\n事件的因果顺序 故障检测（例如，消息传递的上界近似） 一致快照（例如，在某个时间点上检查系统状态的能力；此处不讨论） 强制施加总顺序是可能的，但代价很高。这要求您以最常见（最低）的速度进行操作。通常，确保事件按某种定义的顺序传递的最简单方法是指定一个单一（瓶颈）节点，所有操作都通过该节点进行。\n时间/顺序/同步真的是必需的吗？这取决于情况。在某些用例中，我们希望每个中间操作将系统从一个一致状态移动到另一个一致状态。例如，在许多情况下，我们希望数据库的响应表示所有可用的信息，并且希望避免处理系统可能返回不一致结果的问题。\n但在其他情况下，我们可能不需要那么多的时间/顺序/同步。例如，如果您正在运行一个长时间运行的计算，并且在最后阶段之前并不关心系统的操作，那么只要能够保证答案正确，就不需要太多的同步。\n同步通常被作为一种粗糙的工具应用于所有操作，而实际上只有一部分情况对最终结果真正重要。何时需要顺序来保证正确性？CALM 定理提供了一个答案，我将在最后一章中讨论。\n在其他情况下，接受只表示最佳已知估计的答案是可以接受的，也就是说，它只基于系统中包含的总信息的一个子集。特别是在网络分区期间，可能需要使用系统的部分来回答查询。在其他用例中，最终用户实际上无法区分相对较新且可以廉价获取的答案与保证正确且计算成本高昂的答案。例如，Twitter 用户 X 的关注者数量是 X 还是 X+1？或者对于某个查询，电影 A、B 和 C 是否是绝对最佳的答案？进行更便宜、基本正确的“尽力而为”可能是可以接受的。\n在接下来的两章中，我们将研究容错强一致性系统的复制——这些系统在提供强保证的同时，对故障具有越来越强的韧性。这些系统提供了第一种情况的解决方案：当您需要保证正确性并愿意为此付出代价时。然后，我们将讨论具有弱一致性保证的系统，这些系统可以在分区的情况下保持可用，但只能给出之力求最佳的答案。\n进一步阅读 兰波特时钟，矢量时钟 Time, Clocks and Ordering of Events in a Distributed System - Leslie Lamport, 1978 故障检测 Unreliable failure detectors and reliable distributed systems - Chandra and Toueg Latency- and Bandwidth-Minimizing Optimal Failure Detectors - So \u0026amp; Sirer, 2007 The failure detector abstraction, Freiling, Guerraoui \u0026amp; Kuznetsov, 2011 快照 Consistent global states of distributed systems: Fundamental concepts and mechanisms, Ozalp Babaogly and Keith Marzullo, 1993 Distributed snapshots: Determining global states of distributed systems, K. Mani Chandy and Leslie Lamport, 1985 因果关系 Detecting Causal Relationships in Distributed Computations: In Search of the Holy Grail - Schwarz \u0026amp; Mattern, 1994 Understanding the Limitations of Causally and Totally Ordered Communication - Cheriton \u0026amp; Skeen, 1993 ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-03/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n3. 时间及顺序 什么是顺序，为什么它很重要？\n你说的“什么是顺序”是什么意思？\n我的意思是，为什么我们对顺序如此着迷？为什么我们关心 A 是否发生在 B 之前？为什么我们不关心其他属性，比如“颜色”？\n好吧，我的疯狂朋友，让我们回到分布式系统的定义来回答这个问题。\n你可能还记得，我将分布式编程描述为使用多台计算机解决单台计算机可以解决的同一个问题的艺术。\n事实上，这正是对顺序如此着迷的核心所在。任何只能一次执行一项任务的系统都会创建操作的总体顺序。就像人们通过一扇门一样，每个操作都有明确定义的前任和后继。这基本上是我们努力保留的编程模型。\n传统的模型是：一个程序，一个进程，一个在一个 CPU 上运行的内存空间。操作系统抽象了可能存在多个 CPU 和多个程序的事实，以及计算机内存实际上是多个程序共享的。我并不是说线程编程和事件驱动编程不存在；只是它们是“一个/一个/一个”模型之上的特殊抽象。程序被编写成按照一定顺序执行：从上往下执行。\n顺序作为一种属性受到了如此多的关注，是因为定义“正确性”的最简单方法是说“它的工作方式与单台计算机上的工作方式相同”。而通常这意味着 a）我们运行相同的操作，b）我们按照相同的顺序运行它们 - 即使有多台计算机。\n保持顺序（如单个系统定义的顺序）的分布式系统的优点在于它们是通用的。你不需要关心操作是什么，因为它们将与在单台计算机上完全相同的方式执行。这很棒，因为你知道无论操作是什么，你都可以使用相同的系统。\n实际上，分布式程序在多个节点上运行，具有多个 CPU 和多个操作流。你仍然可以分配一个总体顺序，但这需要准确的时钟或某种形式的通信。你可以使用完全准确的时钟为每个操作标记时间戳，然后利用它来确定总体顺序。或者你可以使用某种通信系统，使得可以分配类似总体顺序的连续编号。\n全序和偏序 在分布式系统中，自然状态是偏序。网络和独立节点都不对相对顺序做出任何保证，但在每个节点上，你可以观察到一个局部顺序。\n总序是一种二元关系，它为某个集合中的每个元素定义了一个顺序。\n当两个不同的元素可比较时，其中一个大于另一个。在偏序集中，某些元素对不可比较，因此偏序并不指定每个项目的确切顺序。\n总序和偏序都是传递性和反对称性的。对于集合 X 中的所有 a、b 和 c，以下陈述在总序和偏序中都成立：\nIf a ≤ b and b ≤ a then a = b (antisymmetry); If a ≤ b and b ≤ c then a ≤ c (transitivity); 然而，总序是完全的：\na ≤ b or b ≤ a (totality) for all a, b in X 而偏序是自反的：\na ≤ a (reflexivity) for all a in X 注意，全序性蕴含自反性；因此，偏序是总序的一种较弱的变体。在偏序中的某些元素上，全序性不成立 - 换句话说，其中一些元素不可比较。","title":"[译]《分布式系统：为了乐趣和利益》3.时间及顺序"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n2. 抽象层次的上下 在本章中，我们将在抽象层次之间穿梭，探讨一些不可能性结果（CAP 和 FLP），然后出于性能考虑回归到更低层次。\n如果你有进行过编程，抽象层次的概念可能对你来说很熟悉。你总是在某个抽象层次上进行工作，通过某个 API 与较低层次的接口进行交互，并可能为用户提供一些更高层次的 API 或用户界面。计算机网络的七层 OSI 模型就是一个很好的例子。\n分布式编程很大程度上涉及处理分布的后果（显而易见！）。也就是说，我们面临着现实中存在许多节点的现实和我们希望系统“像一个单一系统一样工作”的愿望之间存在着紧张关系。这意味着需要找到一个良好的抽象，平衡可能性、可理解性和性能。\n当我们说 X 比 Y 更抽象时，我们是指 X 没有引入任何与 Y 根本不同的新内容。事实上，X 可能会去除 Y 的某些方面或以更易于处理的方式呈现它们。其次，X 在某种意义上比 Y 更容易理解，假设 X 从 Y 中去除的内容对于当前问题并不重要。\n如尼采所写：\n每个概念都是通过我们将不相等的事物等同起来形成的。没有一片叶子完全等同于另一片叶子，概念“叶子”是通过对这些个体差异进行任意抽象而形成的，通过遗忘区别；现在它产生了一个想法，即在自然界中可能存在除了叶子之外的东西，这些东西将是“叶子”的一种原始形式 - 所有叶子都已经被编织、标记、复制、着色、卷曲和绘制，但是由于技术不熟练，没有一份副本能够成为原始形式的正确、可靠和忠实的图像。\n抽象本质上是虚构的。每种情况都是独特的，每个节点也是如此。但是抽象使得世界变得可管理：简化的问题陈述 - 不受现实约束 - 更易于分析，并且只要我们没有忽略任何重要的东西，解决方案就是广泛适用的。\n事实上，如果我们保留下来的东西是重要的，那么我们可以得出的结果就会具有广泛的适用性。这就是为什么不可能性结果如此重要：它们采用了问题的最简单可能的表述，并证明在一些约束或假设条件下无法解决该问题。\n所有的抽象都会忽略一些与现实独特的东西，以便将它们等同起来。关键是要摆脱一切非必要的东西。你如何知道什么是必要的？嗯，你可能事先不知道。\n每次我们在系统规范中排除系统的某个方面时，我们都存在引入错误和/或性能问题的风险。这就是为什么有时我们需要朝着相反的方向前进，并有选择性地引入一些真实硬件和现实世界问题的方面。重新引入一些特定的硬件特性（例如物理顺序性）或其他物理特性可能足以获得足够好的性能的系统。\n系统模型 在分布式系统中，分布是一个关键特性。具体而言，分布式系统中的程序具有以下特点：\n在独立节点上并发运行\u0026hellip; 通过可能引入非确定性和消息丢失的网络连接\u0026hellip; 没有共享内存或共享时钟。 这有许多含义：\n每个节点并发执行程序。 知识是局部的：节点仅能快速访问本地状态，对于全局状态的任何信息都可能过时。 节点可以独立发生故障并进行恢复。 消息可能会延迟或丢失（与节点故障无关；很难区分网络故障和节点故障）。 而且节点之间的时钟不同步（本地时间戳与全局实际时间顺序不对应，很难观察到）。 系统模型列举了与特定系统设计相关的许多假设。\n系统模型是关于实现分布式系统的环境和设施的一组假设。\n系统模型在其对环境和设施的假设方面存在差异。这些假设包括：\n节点的能力和故障方式 通信链路的操作方式以及可能的故障方式 整个系统的属性，例如有关时间和顺序的假设 健壮的系统模型是对假设最弱的模型：针对这种系统编写的任何算法都对不同的环境非常容忍，因为它有非常少且非常弱的假设。\n另一方面，我们可以通过进行强假设来创建一个易于推理的系统模型。例如，假设节点不会发生故障意味着我们的算法不需要处理节点故障。然而，这样的系统模型是不现实的，因此在实践中很难应用。\n让我们更详细地看一下节点、链路、时间和顺序的属性。\n我们系统模型中的节点 节点作为计算和存储的主机。它们具有以下特点：\n能够执行程序。 能够将数据存储到易失性内存（在故障时可能丢失）和稳定状态（在故障后可以读取）。 时钟（可以被假设为准确或不准确）。 节点执行确定性算法：局部计算、计算后的本地状态和发送的消息是根据接收到的消息和接收消息时的本地状态唯一确定的。\n有许多可能的故障模型描述了节点可能发生的故障方式。在实践中，大多数系统假设使用崩溃恢复故障模型：也就是说，节点只能通过崩溃来发生故障，并且可以在稍后某个时间点（可能）进行恢复。\n另一种选择是假设节点可以以任意方式发生故障。这被称为拜占庭容错。拜占庭故障在实际的商业系统中很少处理，因为对任意故障具有弹性的算法运行成本更高，实现更复杂。在这里我不会讨论拜占庭容错。\n我们系统模型中的通信链路 通信链接将各个节点彼此连接，并允许消息在任意方向上发送。许多讨论分布式算法的书籍假设每对节点之间都有独立的链接，这些链接为消息提供了先进先出（FIFO）的顺序，只能传递已发送的消息，并且已发送的消息可能会丢失。\n某些算法假设网络是可靠的：消息永远不会丢失，也不会无限期地延迟。这在某些实际情况下可能是合理的假设，但一般来说，更倾向于将网络视为不可靠的，可能会发生消息丢失和延迟的情况。\n当网络发生故障而节点本身仍可运行时，就会发生网络分区。在这种情况下，消息可能会丢失或延迟，直到网络分区被修复。分区的节点可能对某些客户端是可访问的，因此必须与崩溃的节点进行不同处理。下图说明了节点故障和网络分区的区别：\n通常很少对通信链接做进一步的假设。我们可以假设链接只能单向工作，或者可以为不同的链接引入不同的通信成本（例如由于物理距离引起的延迟）。然而，在商业环境中，除了长距离链接（广域网延迟）之外，这些很少是关注的问题，因此我在这里不会讨论它们；成本和拓扑的更详细模型可以在复杂性的代价下实现更好的优化。\n时间/顺序假设 物理分布的一个结果是每个节点以独特的方式体验世界。这是无法避免的，因为信息只能以光速传播。如果节点之间的距离不同，那么从一个节点发送到其他节点的任何消息都会在其他节点以不同的时间到达，并有可能以不同的顺序到达。\n时间假设是捕捉我们在多大程度上考虑这个现实的便捷方式。主要的两种选择是：\n同步系统模型。进程以同步方式执行；消息传输延迟有已知的上界；每个进程具有准确的时钟。 异步系统模型。没有时间假设 - 例如进程以独立的速率执行；消息传输延迟没有上界；没有可靠的时钟存在。 同步系统模型对时间和顺序施加了许多限制。它基本上假设节点有相同的体验：发送的消息总是在特定的最大传输延迟内接收，并且进程以同步方式执行。这很方便，因为它允许您作为系统设计者对时间和顺序做出假设，而异步系统模型则不允许。\n异步性是一种非假设：它只是假设您不能依赖于时间（或“时间传感器”）。\n在同步系统模型中解决问题更容易，因为对执行速度、最大消息传输延迟和时钟准确性的假设有助于解决问题，您可以根据这些假设进行推断，并假设不方便的故障场景从不发生。\n当然，假设同步系统模型并不特别现实。现实世界的网络会出现故障，并且消息延迟没有固定的上限。现实世界的系统最多是部分同步的：它们可能会偶尔正确工作并提供一些上限，但也会有消息无限期延迟和时钟不同步的时候。我在这里不会详细讨论同步系统的算法，但您可能会在许多其他入门书籍中遇到它们，因为它们在分析上更容易（但不现实）。\n共识问题 在接下来的文本中，我们将改变系统模型的参数。接下来，我们将探讨两个系统属性的变化对系统设计选择的影响：\n是否将网络分区包含在故障模型中。 同步与异步的时间假设。 我们将通过讨论两个不可能性结果（FLP 和 CAP）来说明这些影响。\n当然，为了进行讨论，我们还需要引入一个需要解决的问题。我将讨论的问题是共识问题。\n如果多台计算机（或节点）达成共识，则它们都同意某个值。更正式地说：\n一致性：每个正确的进程必须就同一个值达成一致。 完整性：每个正确的进程最多决定一个值，如果它决定了某个值，则该值必须由某个进程提议。 终止性：所有进程最终都会达成决策。 有效性：如果所有正确的进程提议相同的值 V，则所有正确的进程决定的值必须为 V。 共识问题是许多商业分布式系统的核心。毕竟，我们希望在不必处理分布的后果（例如节点之间的分歧/偏离）的情况下获得分布式系统的可靠性和性能，而解决共识问题使得解决一些相关的更高级问题成为可能，例如原子广播和原子提交。\n两个不可能的结果 第一个不可能性结果是 FLP 不可能性结果，它是一个与设计分布式算法相关的不可能性结果，对分布式算法设计者尤为重要。第二个结果是 CAP 定理，它是一个相关的结果，更与实践者相关，即需要在不同系统设计之间进行选择但不直接涉及算法设计的人。\nFLP 不可能结果 FLP 不可能性结果（以其作者 Fischer、Lynch 和 Patterson 命名）只做简要概述，尽管在学术界被认为更为重要。FLP 不可能性结果考察了异步系统模型下的共识问题（严格来说是协议问题，它是共识问题的一种非常弱的形式）。假设节点只能通过崩溃来失败，网络是可靠的，并且异步系统模型的典型时序假设成立，例如消息延迟没有上界。\n在这些假设下，FLP 结果表明：“在一个异步系统中，不存在解决共识问题的（确定性）算法，即使消息永远不会丢失，最多只有一个进程可能失败，并且只能通过崩溃（停止执行）来失败。”\n这个结果意味着在一个非常简化的系统模型下，没有办法解决共识问题，而且解决方案可能被无限延迟。论证是，如果这样的算法存在，那么可以设计一种执行该算法的方式，其中通过延迟消息传递，它将保持未决状态（\u0026ldquo;bivalent\u0026rdquo;）的时间可以是任意长的，而这在异步系统模型中是允许的。因此，这样的算法是不可能存在的。\n这个不可能性结果很重要，因为它强调了在异步系统模型下的一个权衡：解决共识问题的算法必须在消息传递的界限不满足时放弃安全性或活性。\n这个洞察对于设计算法的人们特别重要，因为它对我们所知道的在异步系统模型中可解决的问题施加了严格限制。CAP 定理是一个相关的定理，对从业者更为相关：它做出稍微不同的假设（网络故障而不是节点故障），并对从业者在系统设计之间的选择有更明确的影响。\nCAP 定理 CAP 定理最初是由计算机科学家 Eric Brewer 提出的一个猜想。它是一种流行且相当有用的思考系统设计中所作出的保证之间权衡的方式。实际上，它还被 Gilbert 和 Lynch 进行了形式化证明，并且与某个特定讨论站点认为的不同，Nathan Marz 并没有揭穿它。\n该定理指出，在以下三个属性中：\n一致性（Consistency）：所有节点在同一时间看到相同的数据。 可用性（Availability）：节点故障不会阻止存活节点继续运行。 分区容忍性（Partition tolerance）：尽管由于网络和/或节点故障导致消息丢失，系统仍然可以继续运行。 只能同时满足其中两个属性。我们甚至可以将其绘制为一个漂亮的图表，从三个属性中选择两个，可以得到对应于不同交叉点的三种不同类型的系统：\n请注意，该定理指出中间部分（同时具有三个属性）是不可实现的。然后我们可以得到三种不同的系统类型：\nCA（一致性 + 可用性）。例如，完全严格的法定人数协议，如两阶段提交协议。 CP（一致性 + 分区容忍性）。例如，多数法定人数协议，在这种协议中，少数分区是不可用的，比如 Paxos 协议。 AP（可用性 + 分区容忍性）。例如，使用冲突解决的协议，如 Dynamo 协议。 CA 和 CP 系统设计都提供相同的一致性模型：强一致性。唯一的区别在于，CA 系统无法容忍任何节点故障；CP 系统可以容忍在非拜占庭故障模型中给定 2f+1 个节点的情况下最多 f 个故障（换句话说，只要多数 f+1 个节点保持运行，它就可以容忍少数 f 个节点的故障）。原因很简单：\nCA 系统不区分节点故障和网络故障，因此必须停止在任何地方接受写操作，以避免引入分歧（多个副本）。它无法判断远程节点是停机还是仅仅是网络连接断开：因此，唯一安全的做法是停止接受写操作。 CP 系统通过对分区的两侧施加不对称行为来防止分歧（例如保持单一副本一致性）。它只保留多数分区，并要求少数分区不可用（例如停止接受写操作），这保持了一定程度的可用性（多数分区）并确保了单一副本一致性。 我将在后面关于复制的章节中详细讨论这个问题，当我讨论 Paxos 时会更详细地讨论。重要的是，CP 系统将网络分区纳入其故障模型，并使用像 Paxos、Raft 或 viewstamped replication 这样的算法区分多数分区和少数分区。CA 系统不具备分区感知能力，并且在历史上更常见：它们通常使用两阶段提交算法，在传统的分布式关系数据库中很常见。\n假设发生分区，该定理就会简化为可用性和一致性之间的二选一。\n首先，早期分布式关系数据库系统中使用的许多系统设计没有考虑到分区容忍性（例如，它们是 CA 设计）。在现代系统中，分区容忍性是一个重要的属性，因为如果系统在地理上分布（正如许多大型系统所做的那样），网络分区变得更加常见。\n其次，在网络分区期间，强一致性和高可用性之间存在紧张关系。CAP 定理说明了在强一致性保证和分布式计算之间的权衡。\n从某种意义上说，承诺一个由不可预测网络连接的独立节点组成的分布式系统“行为与非分布式系统不可区分”是相当困难的。\n我将在稍后关于复制的章节中详细讨论这个问题，当我讨论 Paxos 时会更详细地讨论。重要的是，CP 系统将网络分区纳入其故障模型，并使用像 Paxos、Raft 或 viewstamped replication 这样的算法区分多数分区和少数分区。CA 系统不具备分区感知能力，并且在历史上更常见：它们通常使用两阶段提交算法，在传统的分布式关系数据库中很常见。\n假设发生分区，该定理就会简化为可用性和一致性之间的二选一。\n请注意，CAP 定理实际上提供了四个结论。这些结论强调了在分布式系统中的权衡和挑战，并提醒系统设计人员需要根据应用程序的需求做出合适的选择。\n强一致性保证要求在分区期间放弃可用性。这是因为在两个无法互相通信的副本之间继续接受写操作时，无法防止它们发生差异。\n如何解决这个问题？可以通过加强假设（假设没有分区）或降低保证来解决。一致性可以与可用性（以及与离线可访问性和低延迟相关的功能）进行权衡。如果将\u0026quot;一致性\u0026quot;定义为\u0026quot;所有节点同时看到相同的数据\u0026quot;的要求之下，那么我们可以同时实现可用性和某种（较弱的）一致性保证。\n第三，强一致性和性能在正常操作中存在紧张关系。\n强一致性/单副本一致性要求节点在每个操作上进行通信和达成一致。这导致在正常操作期间出现高延迟。\n如果你可以接受除经典一致性模型之外的一致性模型，即允许副本滞后或发生差异，那么你可以在正常操作期间降低延迟，并在分区的情况下保持可用性。\n当涉及的消息和节点较少时，操作可以更快地完成。但唯一的方法是放松保证：让一些节点更少地被访问，这意味着节点可能包含旧数据。\n这也可能导致异常情况的发生。你不能再保证获得最新的值。根据所做的保证类型，你可能读取到比预期更旧的值，甚至可能丢失一些更新。\n第四，并且间接地，如果我们不想在网络分区期间放弃可用性，那么我们需要探索除强一致性之外的其他一致性模型是否适用于我们的目的。\n例如，即使用户数据在多个数据中心进行了地理复制，而这两个数据中心之间的连接暂时中断，在许多情况下我们仍然希望允许用户使用网站/服务。这意味着稍后需要协调两个不同的数据集，这既是技术上的挑战，也是业务风险。但通常情况下，技术挑战和业务风险是可以管理的，因此提供高可用性更可取。\n一致性和可用性并不是二元选择，除非你将自己限制在强一致性上。但强一致性只是一种一致性模型：在这种模型中，为了防止数据的多个副本同时活跃，你必须放弃可用性。正如Brewer 本人指出的那样，“3 选 2”解释是误导性的。\n如果你从这次讨论中只得到一个观点，那就是\u0026quot;一致性\u0026quot;不是一个单一、明确的属性。请记住：\nACID consistency != CAP consistency != Oatmeal consistency\n相反，一致性模型是数据存储为使用它的程序提供的任何保证。\n一致性模型是程序员和系统之间的契约，系统保证如果程序员遵循一些特定规则，对数据存储的操作结果将是可预测的。\nCAP 中的\u0026quot;C\u0026quot;代表\u0026quot;强一致性\u0026quot;，但\u0026quot;一致性\u0026quot;并不等同于\u0026quot;强一致性\u0026quot;。\n让我们来看一些替代的一致性模型。\n强一致性与其他一致性模型 一致性模型可以分为两类：强一致性模型和弱一致性模型：\n强一致性模型（能够维护单个副本）\n线性一致性（Linearizable consistency） 顺序一致性（Sequential consistency） 弱一致性模型（不是强一致性）\n以客户端为中心的一致性模型（Client-centric consistency models） 因果一致性（Causal consistency）：最强的一致性模型 最终一致性模型（Eventual consistency models） 强一致性模型保证了更新的表面顺序和可见性与非复制系统等效。而弱一致性模型则不提供这样的保证。\n请注意，这并不是一个详尽无遗的列表。再次强调，一致性模型只是程序员和系统之间的任意契约，因此可以是几乎任何形式。\n强一致性模型 强一致性模型进一步可以分为两种相似但稍有不同的一致性模型：\n线性一致性（Linearizable consistency）：在线性一致性下，所有操作似乎以与全局实时操作顺序一致的顺序原子地执行。（Herlihy 和 Wing，1991 年） 顺序一致性（Sequential consistency）：在顺序一致性下，所有操作似乎以某个与各个节点所见的顺序一致且在所有节点上相等的顺序原子地执行。（Lamport，1979 年） 关键的区别在于，线性一致性要求操作产生效果的顺序与实际实时操作顺序相等。而顺序一致性允许对操作进行重新排序，只要在每个节点上观察到的顺序保持一致即可。只有当能够观察到系统中所有的输入和时间时，才能区分这两种模型；从客户端与节点交互的角度来看，两者是等价的。\n这种差异似乎微不足道，但值得注意的是，顺序一致性不具备组合性。\n强一致性模型允许程序员将单个服务器替换为分布式节点集群，而不会遇到任何问题。\n与保证强一致性的系统相比，所有其他一致性模型都存在异常行为，因为它们的行为与非复制系统有所区别。但通常这些异常行为是可以接受的，要么是因为我们不关心偶尔出现的问题，要么是因为我们编写了能够处理发生一致性问题的代码。\n值得注意的是，对于弱一致性模型，实际上没有普遍适用的分类方法，因为“不是强一致性模型”（例如“在某种程度上与非复制系统有所区别”）可以是几乎任何形式。\n以客户为中心的一致性模型 以客户端为中心的一致性模型是一种涉及客户端或会话概念的一致性模型。例如，以客户端为中心的一致性模型可能保证客户端永远不会看到数据项的旧版本。通常，这是通过在客户端库中构建额外的缓存来实现的，因此，如果客户端切换到包含旧数据的副本节点，客户端库会返回其缓存的值，而不是副本中的旧值。\n如果客户端所在的副本节点不包含最新版本的数据，客户端仍然可能看到旧版本的数据，但它们永远不会看到旧值重新出现的异常情况（例如，因为它们连接到了不同的副本）。请注意，有许多以客户端为中心的一致性模型存在。\n最终一致性 最终一致性模型表示，如果停止更改值，那么在一段不确定的时间后，所有副本将达成相同的值。这意味着在此之前，副本之间的结果以某种不确定的方式不一致。由于它是平凡可满足的（仅具备活性属性），如果没有补充信息，它就是没有用处的。\n仅仅说某个东西是最终一致性的，就像说“人最终会死亡”一样。这是一个非常弱的约束条件，我们可能希望对两个方面进行更具体的描述：\n首先，\u0026ldquo;最终\u0026quot;是多久的时间？有一个严格的下限或者至少对系统收敛到相同值通常需要多长时间的一些概念将是有用的。\n其次，副本如何达成一致的值？一个始终返回\u0026quot;42\u0026quot;的系统是最终一致性的：所有副本都同意相同的值。但它不会收敛到一个有用的值，因为它只会持续返回相同的固定值。相反，我们希望对方法有更好的理解。例如，一种决策方法是始终选择具有最大时间戳的值。\n因此，当供应商提到\u0026quot;最终一致性\u0026quot;时，他们指的是一些更具体的术语，例如\u0026quot;最终谁写入的优先，同时读取最新观察到的值\u0026quot;的一致性。\u0026ldquo;如何？\u0026ldquo;很重要，因为糟糕的方法可能导致写入丢失，例如如果一个节点上的时钟设置不正确并且使用时间戳。\n我将在弱一致性模型的复制方法章节中更详细地研究这两个问题。\nFurther reading 进一步阅读 Brewer\u0026rsquo;s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services - Gilbert \u0026amp; Lynch, 2002 Impossibility of distributed consensus with one faulty process - Fischer, Lynch and Patterson, 1985 Perspectives on the CAP Theorem - Gilbert \u0026amp; Lynch, 2012 CAP Twelve Years Later: How the \u0026ldquo;Rules\u0026rdquo; Have Changed - Brewer, 2012 Uniform consensus is harder than consensus - Charron-Bost \u0026amp; Schiper, 2000 Replicated Data Consistency Explained Through Baseball - Terry, 2011 Life Beyond Distributed Transactions: an Apostate\u0026rsquo;s Opinion - Helland, 2007 If you have too much data, then \u0026lsquo;good enough\u0026rsquo; is good enough - Helland, 2011 Building on Quicksand - Helland \u0026amp; Campbell, 2009 ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-02/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n2. 抽象层次的上下 在本章中，我们将在抽象层次之间穿梭，探讨一些不可能性结果（CAP 和 FLP），然后出于性能考虑回归到更低层次。\n如果你有进行过编程，抽象层次的概念可能对你来说很熟悉。你总是在某个抽象层次上进行工作，通过某个 API 与较低层次的接口进行交互，并可能为用户提供一些更高层次的 API 或用户界面。计算机网络的七层 OSI 模型就是一个很好的例子。\n分布式编程很大程度上涉及处理分布的后果（显而易见！）。也就是说，我们面临着现实中存在许多节点的现实和我们希望系统“像一个单一系统一样工作”的愿望之间存在着紧张关系。这意味着需要找到一个良好的抽象，平衡可能性、可理解性和性能。\n当我们说 X 比 Y 更抽象时，我们是指 X 没有引入任何与 Y 根本不同的新内容。事实上，X 可能会去除 Y 的某些方面或以更易于处理的方式呈现它们。其次，X 在某种意义上比 Y 更容易理解，假设 X 从 Y 中去除的内容对于当前问题并不重要。\n如尼采所写：\n每个概念都是通过我们将不相等的事物等同起来形成的。没有一片叶子完全等同于另一片叶子，概念“叶子”是通过对这些个体差异进行任意抽象而形成的，通过遗忘区别；现在它产生了一个想法，即在自然界中可能存在除了叶子之外的东西，这些东西将是“叶子”的一种原始形式 - 所有叶子都已经被编织、标记、复制、着色、卷曲和绘制，但是由于技术不熟练，没有一份副本能够成为原始形式的正确、可靠和忠实的图像。\n抽象本质上是虚构的。每种情况都是独特的，每个节点也是如此。但是抽象使得世界变得可管理：简化的问题陈述 - 不受现实约束 - 更易于分析，并且只要我们没有忽略任何重要的东西，解决方案就是广泛适用的。\n事实上，如果我们保留下来的东西是重要的，那么我们可以得出的结果就会具有广泛的适用性。这就是为什么不可能性结果如此重要：它们采用了问题的最简单可能的表述，并证明在一些约束或假设条件下无法解决该问题。\n所有的抽象都会忽略一些与现实独特的东西，以便将它们等同起来。关键是要摆脱一切非必要的东西。你如何知道什么是必要的？嗯，你可能事先不知道。\n每次我们在系统规范中排除系统的某个方面时，我们都存在引入错误和/或性能问题的风险。这就是为什么有时我们需要朝着相反的方向前进，并有选择性地引入一些真实硬件和现实世界问题的方面。重新引入一些特定的硬件特性（例如物理顺序性）或其他物理特性可能足以获得足够好的性能的系统。\n系统模型 在分布式系统中，分布是一个关键特性。具体而言，分布式系统中的程序具有以下特点：\n在独立节点上并发运行\u0026hellip; 通过可能引入非确定性和消息丢失的网络连接\u0026hellip; 没有共享内存或共享时钟。 这有许多含义：\n每个节点并发执行程序。 知识是局部的：节点仅能快速访问本地状态，对于全局状态的任何信息都可能过时。 节点可以独立发生故障并进行恢复。 消息可能会延迟或丢失（与节点故障无关；很难区分网络故障和节点故障）。 而且节点之间的时钟不同步（本地时间戳与全局实际时间顺序不对应，很难观察到）。 系统模型列举了与特定系统设计相关的许多假设。\n系统模型是关于实现分布式系统的环境和设施的一组假设。\n系统模型在其对环境和设施的假设方面存在差异。这些假设包括：\n节点的能力和故障方式 通信链路的操作方式以及可能的故障方式 整个系统的属性，例如有关时间和顺序的假设 健壮的系统模型是对假设最弱的模型：针对这种系统编写的任何算法都对不同的环境非常容忍，因为它有非常少且非常弱的假设。\n另一方面，我们可以通过进行强假设来创建一个易于推理的系统模型。例如，假设节点不会发生故障意味着我们的算法不需要处理节点故障。然而，这样的系统模型是不现实的，因此在实践中很难应用。\n让我们更详细地看一下节点、链路、时间和顺序的属性。\n我们系统模型中的节点 节点作为计算和存储的主机。它们具有以下特点：\n能够执行程序。 能够将数据存储到易失性内存（在故障时可能丢失）和稳定状态（在故障后可以读取）。 时钟（可以被假设为准确或不准确）。 节点执行确定性算法：局部计算、计算后的本地状态和发送的消息是根据接收到的消息和接收消息时的本地状态唯一确定的。\n有许多可能的故障模型描述了节点可能发生的故障方式。在实践中，大多数系统假设使用崩溃恢复故障模型：也就是说，节点只能通过崩溃来发生故障，并且可以在稍后某个时间点（可能）进行恢复。\n另一种选择是假设节点可以以任意方式发生故障。这被称为拜占庭容错。拜占庭故障在实际的商业系统中很少处理，因为对任意故障具有弹性的算法运行成本更高，实现更复杂。在这里我不会讨论拜占庭容错。\n我们系统模型中的通信链路 通信链接将各个节点彼此连接，并允许消息在任意方向上发送。许多讨论分布式算法的书籍假设每对节点之间都有独立的链接，这些链接为消息提供了先进先出（FIFO）的顺序，只能传递已发送的消息，并且已发送的消息可能会丢失。\n某些算法假设网络是可靠的：消息永远不会丢失，也不会无限期地延迟。这在某些实际情况下可能是合理的假设，但一般来说，更倾向于将网络视为不可靠的，可能会发生消息丢失和延迟的情况。\n当网络发生故障而节点本身仍可运行时，就会发生网络分区。在这种情况下，消息可能会丢失或延迟，直到网络分区被修复。分区的节点可能对某些客户端是可访问的，因此必须与崩溃的节点进行不同处理。下图说明了节点故障和网络分区的区别：\n通常很少对通信链接做进一步的假设。我们可以假设链接只能单向工作，或者可以为不同的链接引入不同的通信成本（例如由于物理距离引起的延迟）。然而，在商业环境中，除了长距离链接（广域网延迟）之外，这些很少是关注的问题，因此我在这里不会讨论它们；成本和拓扑的更详细模型可以在复杂性的代价下实现更好的优化。\n时间/顺序假设 物理分布的一个结果是每个节点以独特的方式体验世界。这是无法避免的，因为信息只能以光速传播。如果节点之间的距离不同，那么从一个节点发送到其他节点的任何消息都会在其他节点以不同的时间到达，并有可能以不同的顺序到达。\n时间假设是捕捉我们在多大程度上考虑这个现实的便捷方式。主要的两种选择是：\n同步系统模型。进程以同步方式执行；消息传输延迟有已知的上界；每个进程具有准确的时钟。 异步系统模型。没有时间假设 - 例如进程以独立的速率执行；消息传输延迟没有上界；没有可靠的时钟存在。 同步系统模型对时间和顺序施加了许多限制。它基本上假设节点有相同的体验：发送的消息总是在特定的最大传输延迟内接收，并且进程以同步方式执行。这很方便，因为它允许您作为系统设计者对时间和顺序做出假设，而异步系统模型则不允许。\n异步性是一种非假设：它只是假设您不能依赖于时间（或“时间传感器”）。","title":"[译]《分布式系统：为了乐趣和利益》2.抽象层次的上下"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n1. 高层分布式系统 分布式编程是利用多台计算机解决在单台计算机上可以解决的相同问题的一种技术。\n任何计算机系统都需要完成两个基本任务：\n存储 计算 分布式编程是一种艺术，通过利用多台计算机解决在单台计算机上可以解决的相同问题，通常是因为该问题已经超出了单台计算机的处理能力。\n实际上，并没有强制要求我们使用分布式系统。如果拥有无限的资金和无限的研发时间，我们就不需要分布式系统。所有的计算和存储可以在一个魔盒上完成，这是一台单一的、极其快速和可靠的系统，你可以支付给别人来为你设计。\n然而，很少有人拥有无限的资源。因此，他们必须在现实世界的成本效益曲线上找到合适的位置。在小规模情况下，升级硬件是一种可行的策略。然而，随着问题规模的增加，你会达到一个阶段，在这个阶段，要么不存在可以让你在单个节点上解决问题的硬件升级，要么成本过高。在这一点上，我欢迎你进入分布式系统的世界。\n当前的现实是，只要通过容错软件将维护成本控制在较低水平，中档、大众化硬件提供了最佳的性价比。\n计算主要受益于高端硬件，尤其是在能够通过内部内存访问取代缓慢的网络访问时。在需要节点间大量通信的任务中，高端硬件的性能优势有限。\n正如 Barroso、Clidaras 和 Hölzle 的上图所示，假设所有节点都采用统一的内存访问模式，高端硬件和商用硬件之间的性能差距会随着集群规模的扩大而缩小。\n理想情况下，添加一台新的机器将线性增加系统的性能和容量。但是，现实情况并非如此，因为由于存在独立的计算机，会产生一些开销。数据需要在计算机之间进行复制，计算任务需要进行协调等等。 这就是为什么值得研究分布式算法的原因——它们提供了针对特定问题的高效解决方案，以及关于可能性、正确实现的最低成本以及不可能性的指导。\n这段文字的重点是在一个平凡但商业相关的环境中，即数据中心的分布式编程和系统。例如，我不会讨论由于具有异乎寻常的网络配置或在共享内存设置中出现的专门问题。此外，重点是探索系统设计空间，而不是优化任何特定设计——后者是一个更专门的文本主题。\n我们想要实现的目标：可扩展性和其他好的东西 从我看来，一切都始于处理规模的需求。\n在小规模下，大多数事情都是微不足道的，而同样的问题一旦超过一定的大小、容量或其他物理限制，就会变得更加困难。举起一块巧克力很容易，但举起一座山就很困难。数一下房间里有多少人很容易，但数一下国家里有多少人就很难。\n所以一切都始于规模——可扩展性。非正式地说，在一个可扩展的系统中，当我们从小规模向大规模过渡时，事情不应该逐渐变得更糟。以下是另一种定义：\n可扩展性是指系统、网络或进程处理不断增长的工作负载的能力，或者说它能够被扩大以适应这种增长的能力。\n什么是在增长呢？嗯，你可以用几乎任何方式来衡量增长（人数、用电量等）。但有三个特别有趣的方面值得关注：\n规模可扩展性：增加更多节点应该使系统线性加快；增加数据集的大小不应增加延迟。 地理可扩展性：应该可以利用多个数据中心来缩短响应用户查询所需的时间，同时以某种合理的方式处理跨数据中心的延迟。 管理可扩展性：添加更多节点不应增加系统的管理成本（例如管理员与机器的比率）。 当然，在真实的系统中，增长同时发生在多个不同的轴上；每个指标仅反映增长的某些方面。\n可扩展的系统是一种随着规模的增加而持续满足用户需求的系统。有两个特别相关的方面——性能和可用性——可以通过多种方式来衡量。\n性能（和延迟） 性能是指计算机系统在使用的时间和资源相对于所完成的有用工作量来衡量的特征。\n根据具体情况，这可能涉及实现以下一项或多项：\n对于给定的工作，响应时间短/延迟低 高吞吐量（处理工作率） 计算资源利用率低 针对任何这些结果进行优化都需要权衡。例如，系统可以通过处理更大批量的工作来实现更高的吞吐量，从而减少操作开销。由于批处理，权衡将是个别工作的响应时间更长。\n我发现低延迟（实现较短的响应时间）是性能中最有趣的方面，因为它与物理（而不是财务）限制密切相关。使用财务资源来解决延迟问题比性能的其他方面更难。\n对于延迟有很多非常具体的定义，但我真的很喜欢这个词的词源所唤起的想法：\n延迟是指潜伏状态，延迟的或在某事物开始和发生之间的一段时间。\n“潜在的”是什么意思？\n潜在的是指某物存在或出现，但被隐藏、隐蔽或处于不活动状态。它描述了一种存在却不容易察觉或可见的状态，但它仍以隐藏或潜在的形式存在。\n这个定义非常酷，因为它强调了延迟是指某件事发生到它产生影响或变得可见之间的时间。\n例如，假设您感染了一种空气传播的病毒，该病毒会将人变成僵尸。潜伏期是指从你被感染到变成僵尸之间的时间。这就是潜伏期：已经发生的事情被隐藏起来的时间。\n让我们假设我们的分布式系统只执行一项高级任务：给定一个查询，它会获取系统中的所有数据并计算一个结果。换句话说，将分布式系统视为一个数据存储，能够对其当前内容运行单个确定性计算（函数）：\nresult = query(all data in the system) 那么，对延迟来说重要的不是旧数据的数量，而是新数据在系统中“生效”的速度。例如，延迟可以根据写入对读者可见所需的时间来衡量。\n基于这个定义的另一个关键点是，如果什么都没有发生，就没有“潜伏期”。数据不改变的系统不会（或不应该）存在延迟问题。\n在分布式系统中，存在一个无法克服的最小延迟：光速限制了信息传输的速度，而硬件组件每个操作都会产生一定的最小延迟成本（例如内存、硬盘以及 CPU）。\n最小延迟对查询的影响程度取决于这些查询的性质以及信息需要传输的物理距离。\n可用性（和容错） 可扩展系统的第二个方面是可用性。\n可用性是指系统处于正常运行状态的时间比例。如果用户无法访问系统，则称系统不可用。\n分布式系统使我们能够实现在单一系统上很难实现的理想特性。例如，单个机器无法容忍任何故障，因为它要么发生故障，要么正常运行。\n分布式系统可以采用一堆不可靠的组件，并在它们之上构建一个可靠的系统。\n没有冗余的系统只能达到其底层组件的可用性。而具备冗余的系统可以容忍部分故障，从而提高可用性。 值得注意的是，“冗余”可以在不同层面上有不同的含义，比如组件、服务器、数据中心等。\n从公式上讲，可用性为： Availability = uptime / (uptime + downtime) 。\n从技术角度来看，可用性主要与容错性有关。因为故障发生的概率随着组件数量的增加而增加，系统应该能够进行补偿，以确保随着组件数量的增加，系统的可靠性不会降低。\n例如：\n可用性 ％ 90%（“一个九”） 一个多月了 99%（“两个九”） 少于 4 天 99.9%（“三个九”） 不到 9 小时 99.99%（“四个九”） 不到一个小时 99.999%（“五个九”） 〜5 分钟 99.9999%（“六个九”） 〜 31 秒 可用性在某种意义上比运行时间更广泛，因为服务的可用性还可能受到网络中断或公司破产等因素的影响（这些因素与容错性并不直接相关，但仍会影响系统的可用性）。但是，如果没有了解系统的每一个具体方面，我们能做的最好的就是设计容错性。\n容错是什么意思？\n容错性是指系统在发生故障时仍能以明确定义的方式继续运行的能力。\n容错性归结为以下几点：首先定义您所预期的故障，然后设计一个能够容忍这些故障的系统或算法。您无法容忍您未考虑到的故障。\n是什么阻碍我们取得美好的成果？ 分布式系统受到两个物理因素的约束：\n节点数量（随着所需存储和计算能力的增加而增加） 节点之间的距离（信息最多以光速传播） 在这些限制下工作：\n独立节点数量的增加会增加系统故障的概率（降低可用性并增加管理成本）。 独立节点数量的增加可能会增加节点之间的通信需求（随着规模的增加导致性能下降）。 地理距离的增加会增加远程节点之间通信的最小延迟（降低某些操作的性能）。 在系统设计选项中，除了物理约束之外，还存在与性能、可用性和可理解性相关的考虑因素。\n性能和可用性取决于系统提供的外部保证。可以将这些保证视为系统的服务级别协议（SLA）：如果写入数据，我能多快在其他地方访问它？数据写入后，对持久性有何保证？如果要求系统运行计算，结果将多快返回？当组件发生故障或停止运行时，对系统会产生什么影响？\n还有一个标准，虽然没有明确提到但隐含其中：可理解性。所做的保证有多容易理解？当然，对于可理解性没有简单的度量标准。\n在我很想将“可理解性”归类为物理限制之下。毕竟，对于我们人类来说，理解涉及比我们的手指数量更多的运动物体的任何事物都很困难。这就是错误和异常之间的区别-错误是不正确的行为，而异常是意外的行为。如果你更聪明，你会预料到异常的发生。\n抽象和模型 这时候抽象和模型就发挥作用了。抽象通过去除与解决问题无关的现实世界方面，使事物更易于管理。模型以准确的方式描述了分布式系统的关键属性。在下一章中，我将讨论许多种类型的模型，例如：\n系统模型（异步/同步） 故障模型（崩溃-故障、分区、拜占庭） 一致性模型（强、最终） 一个良好的抽象使得与系统的工作更易于理解，同时捕捉到与特定目的相关的因素。\n现实中存在许多节点，而我们希望系统“像一个单一系统一样工作”的愿望之间存在一种紧张关系。通常，最熟悉的模型（例如，在分布式系统上实现共享内存抽象）成本太高。\n一个系统提供的保证越低，它就有更大的自由度和潜在的性能优势，但同时也可能更难推理。人们更擅长推理像一个单一系统一样工作的系统，而不是一组节点。\n通过暴露系统内部更多的细节，通常可以提高性能。例如，在列存储中，用户可以（在某种程度上）推理系统内的键值对的局部性，并因此做出影响典型查询性能的决策。隐藏这些细节的系统更易于理解（因为它们更像单个单元，需要考虑的细节更少），而暴露更多真实世界细节的系统可能更具性能（因为它们更接近真实情况）。\n编写像单一系统一样工作的分布式系统面临着几种类型的故障困难。网络延迟和网络分区（例如，某些节点之间的完全网络故障）意味着系统有时需要在发生这些故障时做出艰难的选择，是更好地保持可用性但失去一些无法强制执行的关键保证，还是保守行事并在这些故障发生时拒绝客户端。\nCAP 定理 - 我将在下一章中讨论它 - 捕捉到了这些紧张关系。最理想的系统最终既满足程序员的需求（清晰的语义），又满足业务需求（可用性/一致性/延迟）。\n设计技术：分区和复制 数据集在多个节点之间的分布方式非常重要。为了进行任何计算，我们需要定位数据，然后对其进行操作。\n“分而治之” - 我的意思是，分区和复制。\n下面的图片说明了这两者之间的区别：分区数据（下方的 A 和 B）被分成独立的集合，而复制数据（下方的 C）则被复制到多个位置。\n这是解决涉及分布式计算的任何问题的关键。当然，关键在于选择适合您具体实现的正确技术；有许多实现复制和分区的算法，每种算法都有不同的限制和优势，需要根据您的设计目标进行评估。\n分区 分区是将数据集划分为较小的独立集合；这用于减少数据集增长的影响，因为每个分区都是数据的子集。\n分区通过限制要检查的数据量并将相关数据定位在同一分区中来提高性能。 分区通过允许分区单独失败，增加了需要失败的节点数量，从而提高了可用性，降低了牺牲可用性的风险。 分区也非常依赖于具体应用程序，所以在不了解具体情况的情况下很难做出详细说明。这就是为什么大多数文本，包括本文，都将重点放在复制上。\n分区主要是根据您认为主要访问模式将是什么来定义分区，并处理由于存在独立分区而带来的限制（例如，跨分区的访问效率低下，增长速度不同等）的问题。\n复制 复制是将相同的数据复制到多台机器上的过程；这样可以让更多的服务器参与计算。\n让我不太准确地引用 Homer J. Simpson：\n为了复制！生活中所有问题的起因和解决之道。\n复制 - 复制或再现某个东西 - 是我们对抗延迟的主要方式。\n复制通过使额外的计算能力和带宽适用于数据的新副本来提高性能。 复制通过创建数据的额外副本，增加了需要失败的节点数量，从而提高了可用性。 复制是提供额外带宽和在关键位置进行缓存的方式。它还涉及按照某种一致性模型以某种方式保持一致性。\n复制使我们能够实现可扩展性、性能和容错性。担心可用性丧失或性能降低？复制数据以避免瓶颈或单点故障。计算速度慢？将计算复制到多个系统上。I/O 速度慢？将数据复制到本地缓存以减少延迟，或者复制到多台机器上以增加吞吐量。\n复制也是许多问题的根源，因为现在在多台机器上必须保持数据同步的独立副本存在 - 这意味着确保复制遵循一致性模型。\n一致性模型的选择非常关键：一个良好的一致性模型为程序员提供清晰的语义（换句话说，它所保证的属性易于推理），并满足高可用性或强一致性等业务/设计目标。\n对于复制，只有一种一致性模型 - 强一致性 - 允许您像没有复制基础数据一样进行编程。其他一致性模型向程序员暴露了一些复制的内部细节。然而，较弱的一致性模型可以提供较低的延迟和更高的可用性 - 并不一定更难理解，只是不同而已。\n进一步阅读 The Datacenter as a Computer - An Introduction to the Design of Warehouse-Scale Machines Fallacies of Distributed Computing Notes on Distributed Systems for Young Bloods ","permalink":"https://blog.chensoul.cc/posts/2023/11/10/distributed-systems-01/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者 Mikito Takada 撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n1. 高层分布式系统 分布式编程是利用多台计算机解决在单台计算机上可以解决的相同问题的一种技术。\n任何计算机系统都需要完成两个基本任务：\n存储 计算 分布式编程是一种艺术，通过利用多台计算机解决在单台计算机上可以解决的相同问题，通常是因为该问题已经超出了单台计算机的处理能力。\n实际上，并没有强制要求我们使用分布式系统。如果拥有无限的资金和无限的研发时间，我们就不需要分布式系统。所有的计算和存储可以在一个魔盒上完成，这是一台单一的、极其快速和可靠的系统，你可以支付给别人来为你设计。\n然而，很少有人拥有无限的资源。因此，他们必须在现实世界的成本效益曲线上找到合适的位置。在小规模情况下，升级硬件是一种可行的策略。然而，随着问题规模的增加，你会达到一个阶段，在这个阶段，要么不存在可以让你在单个节点上解决问题的硬件升级，要么成本过高。在这一点上，我欢迎你进入分布式系统的世界。\n当前的现实是，只要通过容错软件将维护成本控制在较低水平，中档、大众化硬件提供了最佳的性价比。\n计算主要受益于高端硬件，尤其是在能够通过内部内存访问取代缓慢的网络访问时。在需要节点间大量通信的任务中，高端硬件的性能优势有限。\n正如 Barroso、Clidaras 和 Hölzle 的上图所示，假设所有节点都采用统一的内存访问模式，高端硬件和商用硬件之间的性能差距会随着集群规模的扩大而缩小。\n理想情况下，添加一台新的机器将线性增加系统的性能和容量。但是，现实情况并非如此，因为由于存在独立的计算机，会产生一些开销。数据需要在计算机之间进行复制，计算任务需要进行协调等等。 这就是为什么值得研究分布式算法的原因——它们提供了针对特定问题的高效解决方案，以及关于可能性、正确实现的最低成本以及不可能性的指导。\n这段文字的重点是在一个平凡但商业相关的环境中，即数据中心的分布式编程和系统。例如，我不会讨论由于具有异乎寻常的网络配置或在共享内存设置中出现的专门问题。此外，重点是探索系统设计空间，而不是优化任何特定设计——后者是一个更专门的文本主题。\n我们想要实现的目标：可扩展性和其他好的东西 从我看来，一切都始于处理规模的需求。\n在小规模下，大多数事情都是微不足道的，而同样的问题一旦超过一定的大小、容量或其他物理限制，就会变得更加困难。举起一块巧克力很容易，但举起一座山就很困难。数一下房间里有多少人很容易，但数一下国家里有多少人就很难。\n所以一切都始于规模——可扩展性。非正式地说，在一个可扩展的系统中，当我们从小规模向大规模过渡时，事情不应该逐渐变得更糟。以下是另一种定义：\n可扩展性是指系统、网络或进程处理不断增长的工作负载的能力，或者说它能够被扩大以适应这种增长的能力。\n什么是在增长呢？嗯，你可以用几乎任何方式来衡量增长（人数、用电量等）。但有三个特别有趣的方面值得关注：\n规模可扩展性：增加更多节点应该使系统线性加快；增加数据集的大小不应增加延迟。 地理可扩展性：应该可以利用多个数据中心来缩短响应用户查询所需的时间，同时以某种合理的方式处理跨数据中心的延迟。 管理可扩展性：添加更多节点不应增加系统的管理成本（例如管理员与机器的比率）。 当然，在真实的系统中，增长同时发生在多个不同的轴上；每个指标仅反映增长的某些方面。\n可扩展的系统是一种随着规模的增加而持续满足用户需求的系统。有两个特别相关的方面——性能和可用性——可以通过多种方式来衡量。\n性能（和延迟） 性能是指计算机系统在使用的时间和资源相对于所完成的有用工作量来衡量的特征。\n根据具体情况，这可能涉及实现以下一项或多项：\n对于给定的工作，响应时间短/延迟低 高吞吐量（处理工作率） 计算资源利用率低 针对任何这些结果进行优化都需要权衡。例如，系统可以通过处理更大批量的工作来实现更高的吞吐量，从而减少操作开销。由于批处理，权衡将是个别工作的响应时间更长。\n我发现低延迟（实现较短的响应时间）是性能中最有趣的方面，因为它与物理（而不是财务）限制密切相关。使用财务资源来解决延迟问题比性能的其他方面更难。\n对于延迟有很多非常具体的定义，但我真的很喜欢这个词的词源所唤起的想法：\n延迟是指潜伏状态，延迟的或在某事物开始和发生之间的一段时间。\n“潜在的”是什么意思？\n潜在的是指某物存在或出现，但被隐藏、隐蔽或处于不活动状态。它描述了一种存在却不容易察觉或可见的状态，但它仍以隐藏或潜在的形式存在。\n这个定义非常酷，因为它强调了延迟是指某件事发生到它产生影响或变得可见之间的时间。\n例如，假设您感染了一种空气传播的病毒，该病毒会将人变成僵尸。潜伏期是指从你被感染到变成僵尸之间的时间。这就是潜伏期：已经发生的事情被隐藏起来的时间。\n让我们假设我们的分布式系统只执行一项高级任务：给定一个查询，它会获取系统中的所有数据并计算一个结果。换句话说，将分布式系统视为一个数据存储，能够对其当前内容运行单个确定性计算（函数）：\nresult = query(all data in the system) 那么，对延迟来说重要的不是旧数据的数量，而是新数据在系统中“生效”的速度。例如，延迟可以根据写入对读者可见所需的时间来衡量。\n基于这个定义的另一个关键点是，如果什么都没有发生，就没有“潜伏期”。数据不改变的系统不会（或不应该）存在延迟问题。\n在分布式系统中，存在一个无法克服的最小延迟：光速限制了信息传输的速度，而硬件组件每个操作都会产生一定的最小延迟成本（例如内存、硬盘以及 CPU）。\n最小延迟对查询的影响程度取决于这些查询的性质以及信息需要传输的物理距离。\n可用性（和容错） 可扩展系统的第二个方面是可用性。\n可用性是指系统处于正常运行状态的时间比例。如果用户无法访问系统，则称系统不可用。\n分布式系统使我们能够实现在单一系统上很难实现的理想特性。例如，单个机器无法容忍任何故障，因为它要么发生故障，要么正常运行。\n分布式系统可以采用一堆不可靠的组件，并在它们之上构建一个可靠的系统。\n没有冗余的系统只能达到其底层组件的可用性。而具备冗余的系统可以容忍部分故障，从而提高可用性。 值得注意的是，“冗余”可以在不同层面上有不同的含义，比如组件、服务器、数据中心等。\n从公式上讲，可用性为： Availability = uptime / (uptime + downtime) 。\n从技术角度来看，可用性主要与容错性有关。因为故障发生的概率随着组件数量的增加而增加，系统应该能够进行补偿，以确保随着组件数量的增加，系统的可靠性不会降低。\n例如：\n可用性 ％ 90%（“一个九”） 一个多月了 99%（“两个九”） 少于 4 天 99.9%（“三个九”） 不到 9 小时 99.","title":"[译]《分布式系统：为了乐趣和利益》1.高层分布式系统"},{"content":" 《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者Mikito Takada撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n介绍 我想要一本能够汇集许多最新分布式系统（例如 Amazon 的 Dynamo、Google 的 BigTable 和 MapReduce、Apache 的 Hadoop 等系统）背后的思想的文本。\n在本文中，我试图提供更易于理解的分布式系统介绍。对我来说，这意味着两件事：介绍您需要的关键概念，以便您可以愉快地阅读更严肃的文本，并提供足够详细的叙述，以便您了解正在发生的事情的要点，而不会陷入困境关于细节。现在是 2013 年，您已经有了互联网，您可以有选择地阅读更多您认为最感兴趣的主题。\n在我看来，分布式编程的大部分内容都是关于处理分布式的两个后果的影响：\n信息以光速传播 独立的事物会独立失败 换句话说，分布式编程的核心是处理距离（废话！）并且拥有不止一件事（废话！）。这些约束定义了可能的系统设计空间，我希望读完本文后您将更好地了解距离、时间和一致性模型如何相互作用。\n本文重点介绍理解数据中心商业系统所需的分布式编程和系统概念。试图涵盖一切将是疯狂的。您将学习许多关键协议和算法（例如，涵盖该学科中许多被引用次数最多的论文），包括一些尚未进入大学教科书的最终一致性的令人兴奋的新方法 - 例如 CRDT和 CALM 定理。\n我希望你喜欢它！如果您想表达感谢，请在 Github（或 Twitter）上关注我。如果发现错误，请在 Github 上提交拉取请求。\n1. 基础知识 第一章通过介绍一些重要的术语和概念，从高层次上介绍了分布式系统。它涵盖了高级别目标，例如可扩展性、可用性、性能、延迟和容错；这些是如何难以实现的，以及抽象和模型以及分区和复制如何发挥作用。\n2. 抽象层次的上下 第二章更深入地探讨抽象和不可能性的结果。它以尼采的名言开始，然后介绍系统模型以及典型系统模型中所做的许多假设。然后讨论了 CAP 定理并总结了 FLP 不可能性结果。然后转向 CAP 定理的含义，其中之一是人们应该探索其他一致性模型。然后讨论了许多一致性模型。\n3. 时间及顺序 理解分布式系统的一个重要部分是理解时间和顺序。如果我们无法理解和建模时间，我们的系统就会失败。第三章讨论时间和顺序、时钟以及时间、顺序和时钟的各种用途（例如矢量时钟和故障检测器）。\n4. 复制：防止发散 第四章介绍了复制问题以及执行该问题的两种基本方法。事实证明，大多数相关特征都可以通过这个简单的表征来讨论。然后，从最低容错（2PC）到Paxos讨论了维持单副本一致性的复制方法。\n5. 复制：接受分歧 第五章讨论了具有弱一致性保证的复制。它引入了一个基本的协调场景，其中分区副本尝试达成一致。然后，它讨论了 Amazon 的 Dynamo 作为具有弱一致性保证的系统设计的示例。最后，讨论了无序编程的两个观点：CRDT 和 CALM 定理。\nAppendix 附录 附录包含进一步阅读的建议。\n","permalink":"https://blog.chensoul.cc/posts/2023/11/09/distributed-systems-intro/","summary":"《分布式系统：为了乐趣和利益》是一本广受欢迎的资源，用于理解和学习分布式系统。该书由作者Mikito Takada撰写，介绍了构建分布式系统的基本概念、原则和挑战。\n这本书涵盖了与分布式系统相关的广泛主题，包括网络、容错性、一致性模型、分布式算法、可扩展性等等。它旨在以清晰易懂的方式解释复杂的概念，适合初学者和有经验的分布式系统从业者阅读。\n在整本书中，作者提供了各种实际案例和案例研究，以说明分布式系统的实际应用和实践方面。它还强调了构建分布式系统涉及的权衡和设计考虑，帮助读者全面理解这个主题。\n《分布式系统：为了乐趣和利益》作为开源资源，可以免费在线获取，非常适合任何对学习分布式系统感兴趣的人。\n原文链接：Distributed systems: for fun and profit\n介绍 我想要一本能够汇集许多最新分布式系统（例如 Amazon 的 Dynamo、Google 的 BigTable 和 MapReduce、Apache 的 Hadoop 等系统）背后的思想的文本。\n在本文中，我试图提供更易于理解的分布式系统介绍。对我来说，这意味着两件事：介绍您需要的关键概念，以便您可以愉快地阅读更严肃的文本，并提供足够详细的叙述，以便您了解正在发生的事情的要点，而不会陷入困境关于细节。现在是 2013 年，您已经有了互联网，您可以有选择地阅读更多您认为最感兴趣的主题。\n在我看来，分布式编程的大部分内容都是关于处理分布式的两个后果的影响：\n信息以光速传播 独立的事物会独立失败 换句话说，分布式编程的核心是处理距离（废话！）并且拥有不止一件事（废话！）。这些约束定义了可能的系统设计空间，我希望读完本文后您将更好地了解距离、时间和一致性模型如何相互作用。\n本文重点介绍理解数据中心商业系统所需的分布式编程和系统概念。试图涵盖一切将是疯狂的。您将学习许多关键协议和算法（例如，涵盖该学科中许多被引用次数最多的论文），包括一些尚未进入大学教科书的最终一致性的令人兴奋的新方法 - 例如 CRDT和 CALM 定理。\n我希望你喜欢它！如果您想表达感谢，请在 Github（或 Twitter）上关注我。如果发现错误，请在 Github 上提交拉取请求。\n1. 基础知识 第一章通过介绍一些重要的术语和概念，从高层次上介绍了分布式系统。它涵盖了高级别目标，例如可扩展性、可用性、性能、延迟和容错；这些是如何难以实现的，以及抽象和模型以及分区和复制如何发挥作用。\n2. 抽象层次的上下 第二章更深入地探讨抽象和不可能性的结果。它以尼采的名言开始，然后介绍系统模型以及典型系统模型中所做的许多假设。然后讨论了 CAP 定理并总结了 FLP 不可能性结果。然后转向 CAP 定理的含义，其中之一是人们应该探索其他一致性模型。然后讨论了许多一致性模型。\n3. 时间及顺序 理解分布式系统的一个重要部分是理解时间和顺序。如果我们无法理解和建模时间，我们的系统就会失败。第三章讨论时间和顺序、时钟以及时间、顺序和时钟的各种用途（例如矢量时钟和故障检测器）。\n4. 复制：防止发散 第四章介绍了复制问题以及执行该问题的两种基本方法。事实证明，大多数相关特征都可以通过这个简单的表征来讨论。然后，从最低容错（2PC）到Paxos讨论了维持单副本一致性的复制方法。\n5. 复制：接受分歧 第五章讨论了具有弱一致性保证的复制。它引入了一个基本的协调场景，其中分区副本尝试达成一致。然后，它讨论了 Amazon 的 Dynamo 作为具有弱一致性保证的系统设计的示例。最后，讨论了无序编程的两个观点：CRDT 和 CALM 定理。\nAppendix 附录 附录包含进一步阅读的建议。","title":"[译]《分布式系统：为了乐趣和利益》介绍"},{"content":"JHipster 是一个开发平台，可以快速生成，开发和部署现代 Web 应用程序+微服务架构。\nJHipster 或者称 Java Hipster，是一个应用代码产生器，能够创建 Spring Boot/Spring Cloud + React/VueJs/AngularJS 的应用。使用 JHipster，首先你要配置好 Java 、Git 以及 Maven 或者 Gradle 的环境，然后通过 NodeJs 管理工具安装 JHipster 。\n介绍 JHipster 官网： https://www.jhipster.tech/ ，截止本文发布时，最新版本为 8.0.0 。\nJHipster 客户端使用到的技术栈有：\n服务端使用的技术栈有：\n支持以下部署方式：\nJHipster 提供了一个 CLI 工具 generator-jhipster 和在线网站 https://start.jhipster.tech/ ，来创建应用。generator-jhipster 支持本地安装和 docker 安装两种方式。另外，还有一个轻量级的定制工具 jhipseter-lite 可以更细力度的定制。\nJHipster Pro 是一个 JHipster 国内落地方案，符合国情的代码生成器解决方案，支持 MyBatis、SMS、OSS。当前最新版本对应 JHipster 官方版本：v7.1.0，网站最近一次跟新是在 2021 年 8 月份。\n安装 generator-jhipster 前提条件安装 Java 和 NodeJs，然后通过 npm 或者 yarn 安装 generator-jhipster。以下是通过 npm 安装：\nnpm install -g generator-jhipster 查看版本：\n$ npx jhipster --version 8.0.0-rc.1 另外，可以在 docker 里面安装：\ndocker image pull jhipster/jhipster docker container run --name jhipster -v ~/jhipster:/home/jhipster/app -v ~/.m2:/home/jhipster/.m2 -p 8080:8080 -p 9000:9000 -p 3001:3001 -d -t jhipster/jhipster docker container exec -it jhipster bash 创建应用 为了方便研究代码，可以使用不同技术分多次创建应用。\n首先，创建一个最小化的简单应用：\nmkdir jhipster-simple-demo 转到该目录：\ncd jhipster-simple-demo/ 要生成您的应用程序，请输入：\njhipster 接下来根据你的需求来进行选择，比如，我需要创建一个最小化的单体应用，则选择如下：\n单体应用 使用 Gatling 测试框架 不使用 Spring WebFlux 使用 HTTP Session Authentication 认证 不使用数据库 不使用缓存 使用 Maven 使用 OpenAPI-generator 不生成前端客户端 使用国际化 对应使用 maven 的项目，如下方式启动应用：\n./mvnw #或者 ./mvnw spring-boot:run 不出意外的话，就可以看到项目顺利的跑起来了。可以在浏览器中输入 http://127.0.0.1:8080 查看应用的运行情况。 默认的登录用户名和密码都是 admin。\n如果你选择了数据库或者缓存，则需要使用 docker 启动容器。\n比如，启动 mysql：\ndocker compose -f src/main/docker/mysql.yml up -d 启动 redis：\ndocker compose -f src/main/docker/redis.yml up -d Maven 插件 1、Maven 离线编译方法 参考文章 https://xdcsy.github.io/Text/Section0038.xhtml 。\n./mvnw dependency:go-offline 2、jib-maven-plugin jib-maven-plugin 是一个用于构建和推送 Docker 镜像的 Maven 插件。它可以简化将应用程序打包为 Docker 镜像并将其推送到容器注册表的过程。\n相关示例，可以参考 https://github.com/GoogleContainerTools/jib/tree/master/examples 。\n3、spring-boot-maven-plugin \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-boot.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;mainClass\u0026gt;${start-class}\u0026lt;/mainClass\u0026gt; \u0026lt;!-- Enable the line below to have remote debugging of your application on port 5005 \u0026lt;jvmArguments\u0026gt;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005\u0026lt;/jvmArguments\u0026gt; --\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 运行命令：\n./mvnw -Dspring-boot.run.jvmArguments=\u0026#34;-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:8000\u0026#34; 4、maven-javadoc-plugin maven-javadoc-plugin 是一个用于生成 Java 代码的 Javadoc 文档的 Maven 插件。它可以根据代码中的注释自动生成详细的 API 文档，并支持定制化配置。\n批处理模式下生成 Java 文档：\n./mvnw javadoc:javadoc -B 解释一下每个部分的含义：\n./mvnw：这是 Maven Wrapper 的脚本，它允许你在没有全局 Maven 安装的情况下运行 Maven 命令。./mvnw是用于 Unix/Linux 系统的脚本，如果你在 Windows 系统上运行，请使用mvnw（无前缀的点和斜杠）。 -ntp：这是--no-transfer-progress的缩写，它禁用传输进度的显示。这样做可以减少输出，使命令执行过程更加简洁。 javadoc:javadoc：这是 Maven 插件的目标，用于生成 Javadoc 文档。通过执行此目标，Maven 将处理项目源代码并生成相应的 Javadoc 文档。 --batch-mode：这是指定 Maven 在批处理模式下运行的选项。批处理模式禁用交互式模式，使得 Maven 命令不会要求用户输入。 5、maven-enforcer-plugin maven-enforcer-plugin 是一个用于强制执行 Maven 构建规则的插件。它可以帮助团队确保项目的构建符合特定的要求和规范。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-enforcer-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.4.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;enforce-versions\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;enforce\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;enforce-dependencyConvergence\u0026lt;/id\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;rules\u0026gt; \u0026lt;DependencyConvergence/\u0026gt; \u0026lt;/rules\u0026gt; \u0026lt;fail\u0026gt;false\u0026lt;/fail\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;enforce\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;rules\u0026gt; \u0026lt;requireMavenVersion\u0026gt; \u0026lt;message\u0026gt;You are running an older version of Maven. JHipster requires at least Maven 3.2.5\u0026lt;/message\u0026gt; \u0026lt;version\u0026gt;[3.2.5,)\u0026lt;/version\u0026gt; \u0026lt;/requireMavenVersion\u0026gt; \u0026lt;requireJavaVersion\u0026gt; \u0026lt;message\u0026gt;You are running an incompatible version of Java. JHipster supports JDK 17 to 21.\u0026lt;/message\u0026gt; \u0026lt;version\u0026gt;[17,18),[18,19),[19,20),[20,21),[21,22)\u0026lt;/version\u0026gt; \u0026lt;/requireJavaVersion\u0026gt; \u0026lt;/rules\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 6、spotless-maven-plugin spotless-maven-plugin 是一个用于在 Maven 构建过程中执行代码格式化的插件。它可以帮助团队保持一致的代码风格，并自动修复格式错误。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.diffplug.spotless\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spotless-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.40.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;java\u0026gt; \u0026lt;!-- \u0026lt;removeUnusedImports/\u0026gt; --\u0026gt; \u0026lt;/java\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;spotless\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;process-sources\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;apply\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 7、modernizer-maven-plugin modernizer-maven-plugin 是一个用于在 Maven 构建过程中执行代码现代化分析的插件。它可以帮助团队识别过时的代码和使用不推荐的 API，以便进行更新和修复。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.gaul\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;modernizer-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;modernizer\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;modernizer\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;javaVersion\u0026gt;17\u0026lt;/javaVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 8、sonar-maven-plugin sonar-maven-plugin 是一个用于与 SonarQube 集成的 Maven 插件。SonarQube 是一个用于静态代码分析、代码质量管理和持续集成的开源平台。sonar-maven-plugin 可以将 Maven 项目的代码和分析结果上传到 SonarQube 服务器，并生成详细的代码质量报告。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.sonarsource.scanner.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;sonar-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.10.0.2594\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; 启动 docker 容器：\ndocker compose -f src/main/docker/sonar.yml up -d 运行：\n./mvnw -Pprod clean verify sonar:sonar -Dsonar.login=admin -Dsonar.password=admin 再次运行：\n./mvnw initialize sonar:sonar -Dsonar.login=admin -Dsonar.password=admin Sonar 的配置文件 sonar-project.properties 是通过 maven 插件加载的。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;properties-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${properties-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;initialize\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;read-project-properties\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;files\u0026gt; \u0026lt;file\u0026gt;sonar-project.properties\u0026lt;/file\u0026gt; \u0026lt;/files\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 9、jacoco-maven-plugin jacoco-maven-plugin 是一个用于在 Maven 项目中生成代码覆盖率报告的插件。它使用 JaCoCo（Java Code Coverage）工具来分析项目的测试覆盖率，并生成详细的报告，帮助开发团队评估测试的有效性和代码质量。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.jacoco\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jacoco-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jacoco-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;pre-unit-tests\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;prepare-agent\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!-- Ensures that the code coverage report for unit tests is created after unit tests have been run --\u0026gt; \u0026lt;id\u0026gt;post-unit-test\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;report\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;pre-integration-tests\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;prepare-agent-integration\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;!-- Ensures that the code coverage report for integration tests is created after integration tests have been run --\u0026gt; \u0026lt;id\u0026gt;post-integration-tests\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;post-integration-test\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;report-integration\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 10、openapi-generator-maven-plugin 用于根据 OpenAPI 规范（以前称为 Swagger 规范）生成客户端代码或服务器端框架。\n\u0026lt;plugin\u0026gt; \u0026lt;!-- Plugin that provides API-first development using openapi-generator-cli to generate Spring-MVC endpoint stubs at compile time from an OpenAPI definition file --\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;openapi-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${openapi-generator-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;generate\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/swagger/api.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;apiPackage\u0026gt;com.mycompany.myapp.web.api\u0026lt;/apiPackage\u0026gt; \u0026lt;modelPackage\u0026gt;com.mycompany.myapp.service.api.dto\u0026lt;/modelPackage\u0026gt; \u0026lt;supportingFilesToGenerate\u0026gt;ApiUtil.java\u0026lt;/supportingFilesToGenerate\u0026gt; \u0026lt;skipValidateSpec\u0026gt;false\u0026lt;/skipValidateSpec\u0026gt; \u0026lt;configOptions\u0026gt; \u0026lt;delegatePattern\u0026gt;true\u0026lt;/delegatePattern\u0026gt; \u0026lt;title\u0026gt;jhipster-sample-application\u0026lt;/title\u0026gt; \u0026lt;useSpringBoot3\u0026gt;true\u0026lt;/useSpringBoot3\u0026gt; \u0026lt;/configOptions\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 11、frontend-maven-plugin frontend-maven-plugin 是一个 Maven 插件，用于在构建过程中执行前端相关的任务，例如安装依赖、运行构建脚本、打包前端资源等。它可以将前端开发与后端构建过程无缝集成，简化了多模块项目的构建和部署。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.github.eirslett\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;frontend-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${frontend-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;installDirectory\u0026gt;target\u0026lt;/installDirectory\u0026gt; \u0026lt;nodeVersion\u0026gt;${node.version}\u0026lt;/nodeVersion\u0026gt; \u0026lt;npmVersion\u0026gt;${npm.version}\u0026lt;/npmVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 12、git-commit-id-maven-plugin git-commit-id-maven-plugin 是一个 Maven 插件，用于从 Git 代码库中获取当前构建的 Git 提交信息，并将其注入到构建过程中，例如生成的类文件或资源文件中。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.github.git-commit-id\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;git-commit-id-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${git-commit-id-maven-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;revision\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;failOnNoGitDirectory\u0026gt;false\u0026lt;/failOnNoGitDirectory\u0026gt; \u0026lt;failOnUnableToExtractRepoInfo\u0026gt;false\u0026lt;/failOnUnableToExtractRepoInfo\u0026gt; \u0026lt;generateGitPropertiesFile\u0026gt;true\u0026lt;/generateGitPropertiesFile\u0026gt; \u0026lt;includeOnlyProperties\u0026gt; \u0026lt;includeOnlyProperty\u0026gt;^git.commit.id.abbrev$\u0026lt;/includeOnlyProperty\u0026gt; \u0026lt;includeOnlyProperty\u0026gt;^git.commit.id.describe$\u0026lt;/includeOnlyProperty\u0026gt; \u0026lt;includeOnlyProperty\u0026gt;^git.branch$\u0026lt;/includeOnlyProperty\u0026gt; \u0026lt;/includeOnlyProperties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; spring boot 加载 git.properties 文件\n@Configuration class GitInfoConfiguration { @Bean public PropertySourcesPlaceholderConfigurer placeholderConfigurer() { PropertySourcesPlaceholderConfigurer propsConfig = new PropertySourcesPlaceholderConfigurer(); propsConfig.setLocation(new ClassPathResource(\u0026#34;git.properties\u0026#34;)); propsConfig.setIgnoreResourceNotFound(true); propsConfig.setIgnoreUnresolvablePlaceholders(true); return propsConfig; } } 13、maven-checkstyle-plugin maven-checkstyle-plugin 是一个用于在 Maven 项目中执行代码风格检查的插件。它可以帮助团队在开发过程中维持一致的代码风格，并提供静态代码分析的功能。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-checkstyle-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${maven-checkstyle-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;configLocation\u0026gt;checkstyle.xml\u0026lt;/configLocation\u0026gt; \u0026lt;includeTestSourceDirectory\u0026gt;true\u0026lt;/includeTestSourceDirectory\u0026gt; \u0026lt;consoleOutput\u0026gt;true\u0026lt;/consoleOutput\u0026gt; \u0026lt;failsOnError\u0026gt;true\u0026lt;/failsOnError\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;validate\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;validate\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;check\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 生成 site：\n\u0026lt;reporting\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-checkstyle-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/reporting\u0026gt; 13、maven-failsafe-plugin maven-failsafe-plugin 是一个用于在 Maven 项目中运行集成测试的插件。它提供了一种便捷的方式来执行和验证项目中的集成测试。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-failsafe-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${failsafe-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- Due to spring-boot repackage, without adding this property test classes are not found See https://github.com/spring-projects/spring-boot/issues/6254 --\u0026gt; \u0026lt;classesDirectory\u0026gt;${project.build.outputDirectory}\u0026lt;/classesDirectory\u0026gt; \u0026lt;!-- Force alphabetical order to have a reproducible build --\u0026gt; \u0026lt;runOrder\u0026gt;alphabetical\u0026lt;/runOrder\u0026gt; \u0026lt;includes\u0026gt; \u0026lt;include\u0026gt;**/*IT*\u0026lt;/include\u0026gt; \u0026lt;include\u0026gt;**/*CucumberTest*\u0026lt;/include\u0026gt; \u0026lt;/includes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;integration-test\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;integration-test\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;verify\u0026lt;/id\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;verify\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 14、maven-surefire-plugin maven-surefire-plugin 是一个用于在 Maven 项目中运行单元测试的插件。它提供了执行和管理单元测试的功能，并生成测试报告。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${surefire-plugin.version}\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- Force alphabetical order to have a reproducible build --\u0026gt; \u0026lt;runOrder\u0026gt;alphabetical\u0026lt;/runOrder\u0026gt; \u0026lt;excludes\u0026gt; \u0026lt;exclude\u0026gt;**/*IT*\u0026lt;/exclude\u0026gt; \u0026lt;exclude\u0026gt;**/*CucumberTest*\u0026lt;/exclude\u0026gt; \u0026lt;/excludes\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; Docker src/main/docker 中有一些常见应用的 docker-compoe 编排文件。这些文件有以下特点：\n有的提供了健康检查 容器端口只映射到 127.0.0.1 mysql mysql.yml\n# This configuration is intended for development purpose, it\u0026#39;s **your** responsibility to harden it for production name: jhipstersampleapplication services: mysql: image: mysql:8.1.0 volumes: - ./config/mysql:/etc/mysql/conf.d # - ~/volumes/jhipster/jhipsterSampleApplication/mysql/:/var/lib/mysql/ environment: - MYSQL_ALLOW_EMPTY_PASSWORD=yes - MYSQL_DATABASE=jhipstersampleapplication # If you want to expose these ports outside your dev PC, # remove the \u0026#34;127.0.0.1:\u0026#34; prefix ports: - 127.0.0.1:3306:3306 command: mysqld --lower_case_table_names=1 --skip-ssl --character_set_server=utf8mb4 --explicit_defaults_for_timestamp healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;mysql\u0026#34;, \u0026#34;-e\u0026#34;, \u0026#34;SHOW DATABASES;\u0026#34;] interval: 5s timeout: 5s retries: 10 postgresql # This configuration is intended for development purpose, it\u0026#39;s **your** responsibility to harden it for production name: jhipstersampleapplication services: postgresql: image: postgres:16.0 # volumes: # - ~/volumes/jhipster/jhipsterSampleApplication/postgresql/:/var/lib/postgresql/data/ environment: - POSTGRES_USER=jhipsterSampleApplication - POSTGRES_PASSWORD= - POSTGRES_HOST_AUTH_METHOD=trust healthcheck: test: [\u0026#34;CMD-SHELL\u0026#34;, \u0026#34;pg_isready -U $${POSTGRES_USER}\u0026#34;] interval: 5s timeout: 5s retries: 10 # If you want to expose these ports outside your dev PC, # remove the \u0026#34;127.0.0.1:\u0026#34; prefix ports: - 127.0.0.1:5432:5432 redis redis.yml\n# This configuration is intended for development purpose, it\u0026#39;s **your** responsibility to harden it for production name: jhipstersampleapplication services: redis: image: redis:7.2.1 # If you want to expose these ports outside your dev PC, # remove the \u0026#34;127.0.0.1:\u0026#34; prefix ports: - 127.0.0.1:6379:6379 sonar sonar.yml\n# This configuration is intended for development purpose, it\u0026#39;s **your** responsibility to harden it for production name: jhipstersampleapplication services: sonar: container_name: sonarqube image: sonarqube:10.2.1-community platform: linux/x86_64 # Forced authentication redirect for UI is turned off for out of the box experience while trying out SonarQube # For real use cases delete SONAR_FORCEAUTHENTICATION variable or set SONAR_FORCEAUTHENTICATION=true environment: - SONAR_FORCEAUTHENTICATION=false # If you want to expose these ports outside your dev PC, # remove the \u0026#34;127.0.0.1:\u0026#34; prefix ports: - 127.0.0.1:9001:9000 - 127.0.0.1:9000:9000 swagger-editor # This configuration is intended for development purpose, it\u0026#39;s **your** responsibility to harden it for production name: jhipstersampleapplication services: swagger-editor: image: swaggerapi/swagger-editor:latest ports: - 127.0.0.1:7742:8080 ","permalink":"https://blog.chensoul.cc/posts/2023/11/02/jhipster-intro/","summary":"JHipster 是一个开发平台，可以快速生成，开发和部署现代 Web 应用程序+微服务架构。\nJHipster 或者称 Java Hipster，是一个应用代码产生器，能够创建 Spring Boot/Spring Cloud + React/VueJs/AngularJS 的应用。使用 JHipster，首先你要配置好 Java 、Git 以及 Maven 或者 Gradle 的环境，然后通过 NodeJs 管理工具安装 JHipster 。\n介绍 JHipster 官网： https://www.jhipster.tech/ ，截止本文发布时，最新版本为 8.0.0 。\nJHipster 客户端使用到的技术栈有：\n服务端使用的技术栈有：\n支持以下部署方式：\nJHipster 提供了一个 CLI 工具 generator-jhipster 和在线网站 https://start.jhipster.tech/ ，来创建应用。generator-jhipster 支持本地安装和 docker 安装两种方式。另外，还有一个轻量级的定制工具 jhipseter-lite 可以更细力度的定制。\nJHipster Pro 是一个 JHipster 国内落地方案，符合国情的代码生成器解决方案，支持 MyBatis、SMS、OSS。当前最新版本对应 JHipster 官方版本：v7.1.0，网站最近一次跟新是在 2021 年 8 月份。\n安装 generator-jhipster 前提条件安装 Java 和 NodeJs，然后通过 npm 或者 yarn 安装 generator-jhipster。以下是通过 npm 安装：\nnpm install -g generator-jhipster 查看版本：\n$ npx jhipster --version 8.0.0-rc.1 另外，可以在 docker 里面安装：\ndocker image pull jhipster/jhipster docker container run --name jhipster -v ~/jhipster:/home/jhipster/app -v ~/.","title":"JHipster安装和介绍"},{"content":"本文主要介绍 Circuit Breaker 断路器模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 断路器模式（Circuit Breaker Pattern）是一种在分布式系统中处理故障和提高系统可靠性的设计模式。它的主要目标是防止故障的传递，并在故障发生时提供优雅的故障处理机制。\n在一个分布式系统中，不可避免地会出现许多外部依赖，如数据库、网络服务等。这些外部依赖可能会发生故障、延迟或不可用的情况。如果没有适当的措施，这些故障可能会导致整个系统的性能下降，甚至系统崩溃。\n断路器模式通过在应用程序和外部依赖之间引入一个断路器接口来解决这个问题。断路器接口充当一个中间层，监视对外部依赖的调用。当外部依赖发生故障时，断路器可以迅速地中断对外部依赖的调用，避免资源的浪费和故障的传递。\n除了断路器接口之外，断路器模式还涉及以下几个重要的知识点：\n故障阈值（Failure Threshold）：断路器模式通过设置故障阈值来判断服务的健康状态。当服务的失败次数达到或超过故障阈值时，断路器会打开，阻止对服务的进一步调用。 回退响应（Fallback Response）：当断路器打开时，可以为调用方提供回退响应。回退响应是一个预定义的响应，用于代替无法正常调用的服务的响应。回退响应可以是事先定义好的静态响应，或者是通过调用备用服务来获取的响应。 断路器状态（Circuit Breaker State）：断路器可以处于不同的状态，如关闭（Closed）、打开（Open）和半开（Half-Open）。初始状态通常是关闭状态，表示服务正常可用。当服务的失败次数达到故障阈值时，断路器会打开，阻止对服务的进一步调用。在一定时间后，断路器会进入半开状态，允许发起一次测试调用。如果测试调用成功，断路器将重新关闭；如果测试调用仍然失败，断路器将重新打开。 断路器的自动恢复（Automatic Recovery）：断路器模式通常具有自动恢复功能。在断路器打开的状态下，一段时间过去后，断路器会尝试重新关闭，以允许对服务的正常调用。自动恢复可以防止长时间的服务中断，提供给服务一个机会来恢复正常运行。 健康检查（Health Check）：断路器模式可以通过定期的健康检查来监控服务的状态。健康检查可以是定期发送心跳请求或执行一些特定的健康检查操作。通过健康检查，可以及时发现服务的故障或不可用状态，并相应地打开断路器。 示例 首先，您需要创建一个监控服务类，它将使用断路器来包装远程服务的调用。以下是一个示例监控服务类的代码：\npublic class MonitoringService { private final CircuitBreaker delayedService; private final CircuitBreaker quickService; public MonitoringService(CircuitBreaker delayedService, CircuitBreaker quickService) { this.delayedService = delayedService; this.quickService = quickService; } public String localResourceResponse() { return \u0026#34;Local Service is working\u0026#34;; } public String delayedServiceResponse() { try { return this.delayedService.attemptRequest(); } catch (RemoteServiceException e) { return e.getMessage(); } } public String quickServiceResponse() { try { return this.quickService.attemptRequest(); } catch (RemoteServiceException e) { return e.getMessage(); } } } 在上述代码中，MonitoringService 类接受两个断路器对象作为参数，分别用于包装延迟服务和快速服务的远程调用。它还包含一个用于获取本地资源的方法。\n接下来，您需要创建一个默认的断路器实现类，实现 CircuitBreaker 接口，并根据需要自定义逻辑。\npublic interface CircuitBreaker { void recordSuccess(); void recordFailure(String response); void evaluateState(); } CircuitBreaker接口定义了三个方法：\nrecordSuccess(): 当依赖的服务调用成功时调用该方法，用于记录成功的事件。 recordFailure(String response): 当依赖的服务调用失败时调用该方法，用于记录失败的事件。方法接受一个响应字符串作为参数。 evaluateState(): 该方法用于评估当前断路器的状态。根据预定义的条件，如故障阈值、故障计数和最后故障时间等，判断是否需要改变断路器的状态。 以下是一个示例的默认断路器实现类的代码：\npublic class DefaultCircuitBreaker implements CircuitBreaker { private final long timeout; private final long retryTimePeriod; private final RemoteService service; private long lastFailureTime; private String lastFailureResponse; private int failureCount; private final int failureThreshold; private State state; private final long futureTime = 1000 * 1000 * 1000 * 1000; public DefaultCircuitBreaker(RemoteService serviceToCall, long timeout, int failureThreshold, long retryTimePeriod) { this.service = serviceToCall; this.state = State.CLOSED; this.failureThreshold = failureThreshold; this.timeout = timeout; this.retryTimePeriod = retryTimePeriod; this.lastFailureTime = System.nanoTime() + futureTime; this.failureCount = 0; } @Override public void recordSuccess() { this.failureCount = 0; this.lastFailureTime = System.nanoTime() + futureTime; this.state = State.CLOSED; } @Override public void recordFailure(String response) { failureCount = failureCount + 1; this.lastFailureTime = System.nanoTime(); this.lastFailureResponse = response; } protected void evaluateState() { if (failureCount \u0026gt;= failureThreshold) { if ((System.nanoTime() - lastFailureTime) \u0026gt; retryTimePeriod) { state = State.HALF_OPEN; } else { state = State.OPEN; } } else { state = State.CLOSED; } } @Override public String getState() { evaluateState(); return state.name(); } @Override public void setState(State state) { this.state = state; switch (state) { case OPEN: this.failureCount = failureThreshold; break; case HALF_OPEN: this.failureCount = 0; break; case CLOSED: this.failureCount = 0; this.lastFailureTime = System.nanoTime() + futureTime; break; } } @Override public String attemptRequest() throws RemoteServiceException { if (state == State.OPEN) { return lastFailureResponse; } try { // Simulate the remote service call return service.call(); } catch (RemoteServiceException e) { recordFailure(e.getMessage()); throw e; } } } 上述代码中的 DefaultCircuitBreaker 类是一个默认的断路器实现类。它包含了记录成功和失败的方法，评估当前状态的方法，获取当前状态的方法，以及尝试发起请求的方法。根据状态，它可以控制是否允许请求通过或返回上一次的失败响应。\n最后，您可以使用以下代码示例来演示如何使用断路器：\n@Slf4j public class App { private static final Logger LOGGER = LoggerFactory.getLogger(App.class); /** * Program entry point. * * @param args command line args */ public static void main(String[] args) { var serverStartTime = System.nanoTime(); var delayedService = new DelayedRemoteService(serverStartTime, 5); var delayedServiceCircuitBreaker = new DefaultCircuitBreaker(delayedService, 3000, 2, 2000 * 1000 * 1000); var quickService = new QuickRemoteService(); var quickServiceCircuitBreaker = new DefaultCircuitBreaker(quickService, 3000, 2, 2000 * 1000 * 1000); // 创建一个可以进行本地和远程调用的监控服务对象 var monitoringService = new MonitoringService(delayedServiceCircuitBreaker, quickServiceCircuitBreaker); // 获取本地资源 LOGGER.info(monitoringService.localResourceResponse()); // 从延迟服务中获取响应 2 次，以满足失败阈值 LOGGER.info(monitoringService.delayedServiceResponse()); LOGGER.info(monitoringService.delayedServiceResponse()); // 在超过故障阈值限制后获取延迟服务断路器的当前状态 // 现在是打开状态 LOGGER.info(delayedServiceCircuitBreaker.getState()); // 同时，延迟服务宕机，从健康快速服务获取响应 LOGGER.info(monitoringService.quickServiceResponse()); LOGGER.info(quickServiceCircuitBreaker.getState()); // 等待延迟的服务响应 try { LOGGER.info(\u0026#34;Waiting for delayed service to become responsive\u0026#34;); Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } // 检查延时断路器的状态，应该是HALF_OPEN LOGGER.info(delayedServiceCircuitBreaker.getState()); // 从延迟服务中获取响应，现在应该是健康的 LOGGER.info(monitoringService.delayedServiceResponse()); // 获取成功响应后，它的状态应该是关闭。 LOGGER.info(delayedServiceCircuitBreaker.getState()); } } 类图 适用场景 断路器模式在分布式系统和微服务架构中有许多常见的应用场景。以下是一些常见的应用场景：\n外部依赖调用：在使用外部服务或资源时，例如数据库、网络服务、API调用等，断路器模式可以用来处理外部依赖的故障。它可以防止故障的传递，减少对故障依赖的调用，并提供故障处理机制。 限流和熔断：断路器模式可以用于实现限流和熔断机制，以保护系统免受外部依赖的过载或故障。它可以监控请求的频率和响应时间，并在达到阈值时阻止对外部依赖的调用，以避免系统崩溃。 降级和容错：在面对外部依赖故障时，断路器模式可以提供降级和容错机制。它可以切换到备用逻辑或服务，以提供基本的功能或默认值，保持系统的部分可用性。 重试和恢复：断路器模式可以用于实现故障重试和恢复机制。当外部依赖发生故障时，断路器可以尝试重新连接或重新调用依赖，以尽快恢复正常操作。 监控和报告：断路器模式通常与监控和报告机制结合使用，以提供对系统状态和故障的可视化和警报。它可以记录故障信息、请求统计、错误率等指标，帮助开发人员和运维团队监控系统健康状况。 总之，断路器模式适用于任何可能遇到外部依赖故障的场景。它可以提供故障隔离、弹性和自愈能力，提高系统的可用性、可靠性和性能。\nFAQ 再提供一个使用断路器模式的例子？ 当涉及到使用断路器模式的例子时，一个常见的应用场景是在微服务架构中保护对其他服务的调用。以下是一个简单的示例：\n假设我们有一个电子商务应用程序，它包含订单服务和库存服务。订单服务负责处理用户的订单，而库存服务则负责管理产品的库存信息。为了保护订单服务对库存服务的调用，我们可以使用断路器模式。\npublic class OrderService { private CircuitBreaker circuitBreaker; private InventoryService inventoryService; public OrderService() { // 初始化断路器 circuitBreaker = new CircuitBreaker(); // 初始化库存服务 inventoryService = new InventoryService(); } public void placeOrder(Order order) { try { // 检查断路器状态 if (circuitBreaker.isClosed()) { // 调用库存服务检查库存 boolean hasStock = inventoryService.checkStock(order.getProduct()); if (hasStock) { // 执行订单处理逻辑 // ... // 订单处理成功，记录成功事件 circuitBreaker.recordSuccess(); } else { // 库存不足，记录失败事件 circuitBreaker.recordFailure(\u0026#34;Insufficient stock\u0026#34;); throw new RuntimeException(\u0026#34;Insufficient stock\u0026#34;); } } else { // 断路器打开，执行回退逻辑 throw new RuntimeException(\u0026#34;Order service is currently unavailable. Please try again later.\u0026#34;); } } catch (Exception e) { // 处理异常情况，记录失败事件 circuitBreaker.recordFailure(e.getMessage()); throw e; } } } 在上述例子中，OrderService类是订单服务的实现。它通过使用CircuitBreaker类来保护对库存服务的调用。在placeOrder()方法中，首先检查断路器的状态。如果断路器处于关闭状态（即可用状态），则调用库存服务的checkStock()方法来检查产品的库存情况。如果库存足够，订单处理成功，并记录成功事件；如果库存不足，订单处理失败，并记录失败事件。\n如果断路器处于打开状态，说明库存服务不可用，此时将执行回退逻辑，抛出异常或提供相应的回退响应。无论是执行回退逻辑还是处理异常情况，都需要记录失败事件。\n通过使用断路器模式，我们可以保护订单服务免受库存服务故障的影响。断路器会监控库存服务的健康状态，并在故障发生时打开断路器，阻止对库存服务的进一步调用。这样，即使库存服务不可用，订单服务仍然能够提供恰当的响应，并避免因连锁故障而导致整个系统崩溃。\n如何优化断路器模式的代码？ 当编写断路器模式的代码时，可以进行一些优化和改进。以下是一些可能的优化方法：\n使用现有的库或框架：断路器模式是一个常见的设计模式，许多流行的Java库和框架已经提供了断路器实现，例如 Netflix的Hystrix、Resilience4j等。使用这些库可以减少您自己编写和维护断路器代码的工作量，并且它们通常具有更多的功能和配置选项。 超时设置：在断路器模式中，设置适当的超时时间非常重要。您可以使用Java的Future、CompletableFuture或第三方库来实现调用的超时控制。确保在超过超时时间后，取消或中断正在进行的请求，并记录为失败。 错误计数器和重置策略：根据失败计数器和重置策略，您可以更准确地确定何时打开、关闭或半开断路器。考虑使用滑动窗口或滑动时间窗口来计算错误计数，并根据预定义的规则进行状态转换。 熔断指标和监控：在大型应用程序中，了解断路器的使用情况和性能指标非常重要。您可以使用指标收集库（例如Micrometer）和监控系统（例如Prometheus、Grafana）来收集和可视化断路器的指标数据，以便进行监控和故障排除。 异步支持：如果您的应用程序需要进行大量的并发请求，考虑使用异步编程模型（例如Java的CompletableFuture、响应式编程库等）。这样可以更好地利用资源，并提高应用程序的吞吐量和性能。 你能推荐一些常用的断路器模式的Java库吗？ 当涉及到断路器模式的Java库时，以下是一些常用的选择：\nNetflix Hystrix：Hystrix是一个广泛使用的断路器库，为分布式系统提供故障容错和弹性功能。它具有自适应的断路器逻辑、请求超时、线程池隔离、回退逻辑等功能。然而，请注意，Netflix宣布停止Hystrix的维护和开发，推荐使用Resilience4j或其他替代库。 Resilience4j：Resilience4j是一个轻量级的断路器和弹性库，专为Java 8+应用程序设计。它提供了断路器、限流、重试、超时等功能，并与Java函数式编程风格很好地配合。Resilience4j还与Spring Boot集成得很好，可以轻松地在Spring应用程序中使用。 Sentinel：Sentinel是阿里巴巴开源的一款弹性流控框架，它提供了断路器、流量控制、熔断降级等功能。Sentinel支持针对流量实时监控和规则配置，可以帮助您保护应用程序免受异常流量和故障的影响。 Akka Circuit Breaker：Akka是一个用于构建高并发和分布式应用程序的工具包，其中包含了一个名为Circuit Breaker的模块。Akka的Circuit Breaker模块提供了断路器功能，并与Akka的Actor模型和消息传递机制集成得很好。 Spring Cloud Circuit Breaker：Spring Cloud Circuit Breaker是Spring Cloud生态系统的一部分，它提供了与多个断路器实现（如Hystrix、Resilience4j、Sentinel等）的集成。因此，您可以根据需要选择合适的断路器实现，并在Spring应用程序中使用它们。 Spring Cloud Circuit Breaker如何实现断路器模式？ Spring Cloud Circuit Breaker是Spring Cloud提供的一个模块，用于实现断路器模式。它基于抽象的CircuitBreaker接口，并提供了与不同断路器实现的集成。\nSpring Cloud Circuit Breaker通过与各种断路器实现（如Netflix Hystrix、Resilience4j、Sentinel等）的整合，为开发人员提供了一致的编程模型和API，以便在微服务架构中实现断路器模式。\n以下是使用Spring Cloud Circuit Breaker实现断路器模式的一般步骤：\n添加依赖：在项目的构建文件中，添加Spring Cloud Circuit Breaker相应的依赖，例如使用Netflix Hystrix： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-circuitbreaker-hystrix\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 创建断路器方法：在需要保护的方法上，使用@CircuitBreaker注解标记该方法，指定断路器的名称。例如： import org.springframework.cloud.circuitbreaker.annotation.CircuitBreaker; @CircuitBreaker(name = \u0026#34;myCircuitBreaker\u0026#34;) public String performRemoteCall() { // 远程服务调用逻辑 // ... } 配置断路器属性：可以通过配置文件（如application.properties或application.yml）来设置断路器的属性，如超时时间、故障阈值等。例如： spring: cloud: circuitbreaker: enabled: true default-config: timeout: 1000 circuit-breaker: request-volume-threshold: 10 failure-ratio: 0.5 wait-duration-in-open-state: 5000 处理回退逻辑：可以通过在方法上定义一个备用方法（fallback method）来指定在断路器打开时执行的回退逻辑。可以使用@Fallback注解标记该备用方法。例如： import org.springframework.cloud.circuitbreaker.annotation.Fallback; @Fallback(fallbackMethod = \u0026#34;fallbackMethod\u0026#34;) public String performRemoteCall() { // 远程服务调用逻辑 // ... } public String fallbackMethod(Exception e) { // 回退逻辑 // ... } 通过上述步骤，Spring Cloud Circuit Breaker会根据断路器的配置和状态来保护被@CircuitBreaker注解标记的方法。当方法调用发生故障或超过阈值时，断路器将打开，并执行备用方法。备用方法可以提供一个预定义的响应或执行一些回退逻辑，以确保系统的稳定性。\n需要注意的是，具体的配置和用法可能因使用的断路器实现（如Hystrix、Resilience4j等）而有所差异。因此，建议参考Spring Cloud Circuit Breaker的官方文档和相关示例，以了解更多关于特定断路器实现的详细信息和用法。\nSpring Cloud Circuit Breaker和常规的断路器实现的区别？ Spring Cloud Circuit Breaker 是基于 Spring Cloud 的断路器模块，提供了对断路器模式的支持。它与常规的断路器实现（如 Hystrix、Resilience4j 等）相比，有以下几个区别：\n统一的抽象接口：Spring Cloud Circuit Breaker 提供了一个统一的抽象接口，即 CircuitBreaker 接口，用于定义断路器的行为和状态。这个接口使得可以在不同的断路器实现之间进行切换和替换，而不需要更改应用程序的代码。\n以下是 CircuitBreaker 接口的定义：\npublic interface CircuitBreaker { String getId(); \u0026lt;T\u0026gt; T run(Supplier\u0026lt;T\u0026gt; toRun); \u0026lt;T\u0026gt; T runCallable(Callable\u0026lt;T\u0026gt; toRun) throws Exception; void reset(); CircuitBreaker.State getState(); default boolean isOpen() { return getState() == CircuitBreaker.State.OPEN; } default boolean isClosed() { return getState() == CircuitBreaker.State.CLOSED; } default boolean isHalfOpen() { return getState() == CircuitBreaker.State.HALF_OPEN; } enum State { CLOSED, OPEN, HALF_OPEN } } CircuitBreaker 接口定义了以下方法：\ngetId()：获取断路器的唯一标识符。 run(Supplier\u0026lt;T\u0026gt; toRun)：运行一个带有返回值的操作（通过 Supplier 提供），并返回操作的结果。如果断路器处于打开状态，将会触发断路器打开的逻辑。 runCallable(Callable\u0026lt;T\u0026gt; toRun)：运行一个带有返回值的操作（通过 Callable 提供），并返回操作的结果。与 run(Supplier\u0026lt;T\u0026gt; toRun) 类似，如果断路器处于打开状态，将会触发断路器打开的逻辑。 reset()：重置断路器的状态。将断路器状态重置为关闭状态。 getState()：获取断路器的当前状态，返回一个 CircuitBreaker.State 枚举值，表示关闭状态、打开状态或半开状态。 isOpen()、isClosed()、isHalfOpen()：这些方法是对状态的便捷判断方法，用于判断断路器当前的状态。 多个断路器实现的支持：Spring Cloud Circuit Breaker 支持多个断路器实现，如 Hystrix、Resilience4j、Sentinel 等。这样，开发人员可以根据实际需求和偏好选择适合的断路器实现。\n与 Spring Cloud 整合：Spring Cloud Circuit Breaker 与 Spring Cloud 生态系统无缝集成，可以与其他 Spring Cloud 组件（如服务注册与发现、负载均衡等）一起使用。它可以通过注解或编程方式与 Spring Boot 应用程序集成，简化了断路器的配置和使用。\n可插拔的实现：Spring Cloud Circuit Breaker 的设计允许开发人员进行自定义的断路器实现。通过实现 CircuitBreakerFactory 接口，可以创建自定义的断路器实例，并将其集成到 Spring Cloud Circuit Breaker 中。\n总的来说，Spring Cloud Circuit Breaker 提供了一种更灵活、可扩展和与 Spring Cloud 集成的方式来实现断路器模式。它使得开发人员可以选择适合自己项目需求的断路器实现，并能够与其他 Spring Cloud 组件无缝协作。\n参考资料 Understanding Circuit Breaker Patter Martin Fowler on Circuit Breaker Fault tolerance in a high volume, distributed system Circuit Breaker pattern ","permalink":"https://blog.chensoul.cc/posts/2023/10/26/java-design-patterns-circuit-breaker/","summary":"本文主要介绍 Circuit Breaker 断路器模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 断路器模式（Circuit Breaker Pattern）是一种在分布式系统中处理故障和提高系统可靠性的设计模式。它的主要目标是防止故障的传递，并在故障发生时提供优雅的故障处理机制。\n在一个分布式系统中，不可避免地会出现许多外部依赖，如数据库、网络服务等。这些外部依赖可能会发生故障、延迟或不可用的情况。如果没有适当的措施，这些故障可能会导致整个系统的性能下降，甚至系统崩溃。\n断路器模式通过在应用程序和外部依赖之间引入一个断路器接口来解决这个问题。断路器接口充当一个中间层，监视对外部依赖的调用。当外部依赖发生故障时，断路器可以迅速地中断对外部依赖的调用，避免资源的浪费和故障的传递。\n除了断路器接口之外，断路器模式还涉及以下几个重要的知识点：\n故障阈值（Failure Threshold）：断路器模式通过设置故障阈值来判断服务的健康状态。当服务的失败次数达到或超过故障阈值时，断路器会打开，阻止对服务的进一步调用。 回退响应（Fallback Response）：当断路器打开时，可以为调用方提供回退响应。回退响应是一个预定义的响应，用于代替无法正常调用的服务的响应。回退响应可以是事先定义好的静态响应，或者是通过调用备用服务来获取的响应。 断路器状态（Circuit Breaker State）：断路器可以处于不同的状态，如关闭（Closed）、打开（Open）和半开（Half-Open）。初始状态通常是关闭状态，表示服务正常可用。当服务的失败次数达到故障阈值时，断路器会打开，阻止对服务的进一步调用。在一定时间后，断路器会进入半开状态，允许发起一次测试调用。如果测试调用成功，断路器将重新关闭；如果测试调用仍然失败，断路器将重新打开。 断路器的自动恢复（Automatic Recovery）：断路器模式通常具有自动恢复功能。在断路器打开的状态下，一段时间过去后，断路器会尝试重新关闭，以允许对服务的正常调用。自动恢复可以防止长时间的服务中断，提供给服务一个机会来恢复正常运行。 健康检查（Health Check）：断路器模式可以通过定期的健康检查来监控服务的状态。健康检查可以是定期发送心跳请求或执行一些特定的健康检查操作。通过健康检查，可以及时发现服务的故障或不可用状态，并相应地打开断路器。 示例 首先，您需要创建一个监控服务类，它将使用断路器来包装远程服务的调用。以下是一个示例监控服务类的代码：\npublic class MonitoringService { private final CircuitBreaker delayedService; private final CircuitBreaker quickService; public MonitoringService(CircuitBreaker delayedService, CircuitBreaker quickService) { this.delayedService = delayedService; this.quickService = quickService; } public String localResourceResponse() { return \u0026#34;Local Service is working\u0026#34;; } public String delayedServiceResponse() { try { return this.delayedService.attemptRequest(); } catch (RemoteServiceException e) { return e.getMessage(); } } public String quickServiceResponse() { try { return this.quickService.attemptRequest(); } catch (RemoteServiceException e) { return e.getMessage(); } } } 在上述代码中，MonitoringService 类接受两个断路器对象作为参数，分别用于包装延迟服务和快速服务的远程调用。它还包含一个用于获取本地资源的方法。","title":"Java设计模式：Circuit Breaker"},{"content":"本文主要介绍 Chain 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n目的 通过给多个对象一个处理请求的机会，避免请求的发送者和它的接收者耦合。串联接收对象并在链条中传递请求直到一个对象处理它。\n介绍 责任链模式（Chain of Responsibility Pattern）是一种行为型设计模式，它允许多个对象按照顺序处理请求，直到其中一个对象能够处理该请求为止。该模式将请求发送者和接收者解耦，使多个对象都有机会处理请求，同时避免请求发送者与接收者之间的直接耦合。\n在责任链模式中，通常会构建一个处理请求的链条，链条上的每个对象都有一个指向下一个对象的引用。当请求到达链条的起点时，它会依次经过链条上的每个对象，直到找到能够处理请求的对象为止。每个对象都可以决定是否处理请求，或者将请求传递给下一个对象。\n以下是责任链模式的几个关键角色：\n抽象处理器（Handler）：定义处理请求的接口，并包含一个指向下一个处理器的引用。通常会提供一个处理请求的方法。 具体处理器（ConcreteHandler）：实现抽象处理器的接口，具体处理请求的逻辑。如果自己无法处理请求，则将请求传递给下一个处理器。 客户端（Client）：创建责任链，并将请求发送给链条的起点。 下面是一个示例，说明如何使用责任链模式处理请求：\n// 抽象处理器 public abstract class Handler { protected Handler nextHandler; public void setNextHandler(Handler nextHandler) { this.nextHandler = nextHandler; } public abstract void handleRequest(Request request); } // 具体处理器 public class ConcreteHandler1 extends Handler { @Override public void handleRequest(Request request) { if (满足处理条件) { // 处理请求的逻辑 } else if (nextHandler != null) { // 将请求传递给下一个处理器 nextHandler.handleRequest(request); } } } // 具体处理器2和具体处理器3的定义与具体处理器1类似 // 客户端 public class Client { public static void main(String[] args) { Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handler3 = new ConcreteHandler3(); // 构建责任链 handler1.setNextHandler(handler2); handler2.setNextHandler(handler3); // 创建请求 Request request = new Request(); // 发送请求给责任链的起点 handler1.handleRequest(request); } } 在上述示例中，抽象处理器（Handler）定义了处理请求的接口，并包含一个指向下一个处理器的引用。具体处理器（ConcreteHandler）继承自抽象处理器，实现了处理请求的逻辑，如果自己无法处理请求，则将请求传递给下一个处理器。客户端（Client）创建了具体处理器的实例，并构建了责任链，然后将请求发送给责任链的起点。\n责任链模式的优点包括：\n解耦请求发送者和接收者，让多个对象都有机会处理请求。 灵活性高，可以动态地改变责任链的结构和顺序。 可以简化对象之间的交互，每个对象只需要关注自己的处理逻辑。 然而，责任链模式也有一些注意事项：\n需要注意链条的构建顺序，确保请求可以被正确地处理。 如果责任链过长或处理逻辑复杂，可能会影响性能。 请求可能无法被处理，需要在设计中考虑默认处理或异常处理机制。 适用场景 责任链模式在以下几种应用场景中经常被使用：\n请求处理链：当一个请求需要经过多个处理器进行处理，并且每个处理器都有可能处理该请求或将其传递给下一个处理器时，可以使用责任链模式。例如，Web开发中的请求处理、日志记录系统中的日志处理等。 异常处理：在处理异常时，可以使用责任链模式来处理不同类型的异常。每个处理器负责处理一种类型的异常，如果无法处理，则将异常传递给下一个处理器。这样可以实现异常处理的灵活性和可扩展性。 权限验证：在一个系统中，可以使用责任链模式来进行权限验证。每个处理器可以验证某个特定权限，如果无法验证，则将验证请求传递给下一个处理器。这样可以实现权限验证的灵活组合和动态调整。 日志记录：在日志记录系统中，可以使用责任链模式来处理不同级别的日志信息。每个处理器负责记录特定级别的日志，如果无法处理，则将日志传递给下一个处理器。这样可以实现日志记录的分级和灵活配置。 缓存处理：在缓存系统中，可以使用责任链模式来处理缓存读取请求。每个处理器可以根据一定的策略判断是否命中缓存，如果未命中则将请求传递给下一个处理器。这样可以实现缓存的层级和灵活的缓存策略。 数据验证器（Data Validator）：在数据验证过程中，可以使用责任链模式来对数据进行不同类型的验证。每个验证器负责验证特定的数据规则，如果无法验证，则将验证请求传递给下一个验证器。这样可以实现数据验证的分步处理和灵活的验证规则组合。 需要注意的是，责任链模式适用于处理请求的场景，其中每个处理器都有可能处理请求或将其传递给下一个处理器。在选择使用责任链模式时，需确保请求能够被正确处理，并且链条的构建顺序是合理的，避免出现死循环或请求无法被处理的情况。\n举例 这段代码展示了一个简单的泛型责任链模式实现，其中包括Handler接口和Pipeline类。\npublic interface Handler\u0026lt;I, O\u0026gt; { O process(I input); } public class Pipeline\u0026lt;I, O\u0026gt; { private final Handler\u0026lt;I, O\u0026gt; currentHandler; public Pipeline(Handler\u0026lt;I, O\u0026gt; currentHandler) { this.currentHandler = currentHandler; } public \u0026lt;K\u0026gt; Pipeline\u0026lt;I, K\u0026gt; addHandler(Handler\u0026lt;O, K\u0026gt; newHandler) { return new Pipeline\u0026lt;\u0026gt;(input -\u0026gt; newHandler.process(currentHandler.process(input))); } public O execute(I input) { return currentHandler.process(input); } } 在上述代码中，Handler接口定义了一个处理输入类型为I，输出类型为O的操作。它包含一个process方法，用于执行处理逻辑。\nPipeline类是一个泛型类，它接受输入类型I和输出类型O。在构造函数中，通过传入一个初始的currentHandler，创建一个责任链的起点。\nPipeline类提供了addHandler方法，用于添加新的处理器到责任链中。该方法接受一个实现了Handler接口的newHandler，并返回一个新的Pipeline对象，新的责任链包括之前的处理器和新的处理器。\nexecute方法用于执行整个责任链。它接受输入参数input，并通过调用当前处理器的process方法，依次执行责任链中的每个处理器，并返回最终的输出结果。\n使用这个简单的泛型责任链模式，你可以根据具体的业务需求创建不同类型的处理器，并通过addHandler方法将它们连接在一起，形成一个处理流程。然后，你可以使用execute方法将输入数据传入责任链中，依次经过每个处理器进行处理，最终得到输出结果。\n假设我们有一个处理器链，用于处理字符串的转换操作：\npublic class StringToUpperHandler implements Handler\u0026lt;String, String\u0026gt; { @Override public String process(String input) { return input.toUpperCase(); } } public class StringTrimHandler implements Handler\u0026lt;String, String\u0026gt; { @Override public String process(String input) { return input.trim(); } } public class StringReverseHandler implements Handler\u0026lt;String, String\u0026gt; { @Override public String process(String input) { return new StringBuilder(input).reverse().toString(); } } 现在，我们可以使用这些处理器来创建一个处理流程，并执行输入字符串的转换操作：\npublic class Main { public static void main(String[] args) { // 创建处理器和处理流程 Handler\u0026lt;String, String\u0026gt; toUpperHandler = new StringToUpperHandler(); Handler\u0026lt;String, String\u0026gt; trimHandler = new StringTrimHandler(); Handler\u0026lt;String, String\u0026gt; reverseHandler = new StringReverseHandler(); Pipeline\u0026lt;String, String\u0026gt; pipeline = new Pipeline\u0026lt;\u0026gt;(toUpperHandler) .addHandler(trimHandler) .addHandler(reverseHandler); // 执行处理流程 String input = \u0026#34; Hello, World! \u0026#34;; String output = pipeline.execute(input); System.out.println(\u0026#34;Output: \u0026#34; + output); } } 在上述示例中，我们创建了三个处理器：StringToUpperHandler、StringTrimHandler和StringReverseHandler，它们分别用于将字符串转换为大写、去除空格和反转字符串。\n然后，我们使用这些处理器创建了一个处理流程，通过调用addHandler方法将它们逐步链接在一起，形成一个处理器链。\n最后，我们执行处理流程，将输入字符串\u0026quot; Hello, World! \u0026quot;传入execute方法中。该输入字符串首先经过toUpperHandler处理器处理，然后传递给trimHandler进行处理，最后传递给reverseHandler进行处理。处理完成后，得到最终的输出结果。\n在本例中，输出结果为\u0026quot;!DLROW ,OLLEH\u0026quot;，这是通过依次应用处理器链中的每个处理器对输入字符串进行转换而得到的。\nJava中的例子 java.util.logging.Logger#log() Apache Commons Chain javax.servlet.Filter#doFilter() ","permalink":"https://blog.chensoul.cc/posts/2023/10/16/java-design-patterns-chain/","summary":"本文主要介绍 Chain 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n目的 通过给多个对象一个处理请求的机会，避免请求的发送者和它的接收者耦合。串联接收对象并在链条中传递请求直到一个对象处理它。\n介绍 责任链模式（Chain of Responsibility Pattern）是一种行为型设计模式，它允许多个对象按照顺序处理请求，直到其中一个对象能够处理该请求为止。该模式将请求发送者和接收者解耦，使多个对象都有机会处理请求，同时避免请求发送者与接收者之间的直接耦合。\n在责任链模式中，通常会构建一个处理请求的链条，链条上的每个对象都有一个指向下一个对象的引用。当请求到达链条的起点时，它会依次经过链条上的每个对象，直到找到能够处理请求的对象为止。每个对象都可以决定是否处理请求，或者将请求传递给下一个对象。\n以下是责任链模式的几个关键角色：\n抽象处理器（Handler）：定义处理请求的接口，并包含一个指向下一个处理器的引用。通常会提供一个处理请求的方法。 具体处理器（ConcreteHandler）：实现抽象处理器的接口，具体处理请求的逻辑。如果自己无法处理请求，则将请求传递给下一个处理器。 客户端（Client）：创建责任链，并将请求发送给链条的起点。 下面是一个示例，说明如何使用责任链模式处理请求：\n// 抽象处理器 public abstract class Handler { protected Handler nextHandler; public void setNextHandler(Handler nextHandler) { this.nextHandler = nextHandler; } public abstract void handleRequest(Request request); } // 具体处理器 public class ConcreteHandler1 extends Handler { @Override public void handleRequest(Request request) { if (满足处理条件) { // 处理请求的逻辑 } else if (nextHandler != null) { // 将请求传递给下一个处理器 nextHandler.handleRequest(request); } } } // 具体处理器2和具体处理器3的定义与具体处理器1类似 // 客户端 public class Client { public static void main(String[] args) { Handler handler1 = new ConcreteHandler1(); Handler handler2 = new ConcreteHandler2(); Handler handler3 = new ConcreteHandler3(); // 构建责任链 handler1.","title":"Java设计模式：Chain"},{"content":"本文主要介绍 Callback 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 回调（Callback）是一种设计模式，在这种模式中，一个可执行的代码被作为参数传递给其他代码，接收方的代码可以在适当的时候调用它。\n在真实世界的例子中，当我们需要在任务完成时被通知时，我们可以将一个回调方法传递给调用者，并等待它调用以通知我们。简单地说，回调是一个传递给调用者的方法，在定义的时刻被调用。\n维基百科说\n在计算机编程中，回调又被称为“稍后调用”函数，可以是任何可执行的代码用来作为参数传递给其他代码；其它代码被期望在给定时间内调用回调方法。\n代码 回调是一个只有一个方法的简单接口。\npublic interface Callback { void call(); } 下面我们定义一个任务它将在任务执行完成后执行回调。\npublic abstract class Task { final void executeWith(Callback callback) { execute(); Optional.ofNullable(callback).ifPresent(Callback::call); } public abstract void execute(); } public final class SimpleTask extends Task { private static final Logger LOGGER = getLogger(SimpleTask.class); @Override public void execute() { LOGGER.info(\u0026#34;Perform some important activity and after call the callback method.\u0026#34;); } } 最后这里是我们如何执行一个任务然后接收一个回调当它完成时。\nvar task = new SimpleTask(); task.executeWith(() -\u0026gt; LOGGER.info(\u0026#34;I\u0026#39;m done now.\u0026#34;)); 类图 适用场景 回调模式适用于以下场景：\n异步操作：当需要在异步操作完成后执行某些操作时，可以使用回调模式。例如，在网络请求中，可以传递一个回调函数，在请求完成后调用该函数处理响应数据。 事件处理：当需要对事件进行响应和处理时，可以使用回调模式。例如，在图形界面开发中，可以注册某个控件的回调函数，以便在用户触发事件时执行相应的操作。 插件扩展：当需要为应用程序提供扩展性，允许第三方插件在特定事件发生时进行自定义操作时，可以使用回调模式。例如，游戏引擎中的事件系统允许开发者注册回调函数以响应游戏中的特定事件。 回调链：当需要按特定顺序执行多个回调函数，并将前一个回调函数的结果传递给下一个回调函数时，可以使用回调模式。这种情况下，回调函数形成了一个回调链。 模板方法模式：回调模式常与模板方法模式结合使用。模板方法模式定义了一个算法的骨架，而具体的步骤由子类实现。可以使用回调模式将子类中的具体步骤作为回调函数传递给模板方法。 总的来说，回调模式适用于需要在特定事件发生后执行某些操作的情况，以及需要实现解耦和灵活性的场景。它提供了一种在代码间通信的方式，使得代码可以更加模块化和可复用。\nJava 例子 CyclicBarrier 构造函数可以接受回调，该回调将在每次障碍被触发时触发。 FAQ 回调模式如何实现解耦和灵活性？ 回调模式通过将一个可执行的代码块（回调函数）作为参数传递给其他代码，实现了解耦和灵活性。\n解耦性：回调模式可以将调用方与被调用方解耦，使它们之间的关系更加松散。调用方只需要知道回调函数的接口，而不需要了解具体的实现细节。被调用方在特定的时机调用回调函数，而不需要知道调用方的具体实现。这种解耦性使得系统中的不同部分可以独立地进行修改和扩展，而不会对彼此产生过多的依赖。\n灵活性：回调模式提供了一种灵活的扩展机制。通过传递不同的回调函数，可以改变程序的行为或逻辑，而不需要修改原有的代码。这种灵活性使得系统可以适应不同的需求和变化，而不需要进行大规模的修改或重构。同时，回调模式也允许在运行时动态地修改回调函数，从而实现更高级的动态行为。\n通过使用回调模式，系统的不同部分可以相互独立地演化和扩展，而不会引入过多的紧耦合关系。这使得代码更加模块化、可复用和可维护。此外，回调模式还可以提高代码的可测试性，因为可以使用模拟或替代的回调函数来进行单元测试。\n总而言之，回调模式通过解耦和灵活性的特性，帮助提高了代码的可维护性、可扩展性和可测试性，使系统更加灵活和适应变化。\n回调模式和事件驱动模式有什么区别？ 回调模式和事件驱动模式是两种常见的设计模式，它们在某些方面有相似之处，但也存在一些区别。\n回调模式：\n在回调模式中，一个可执行的代码块（回调函数）被传递给其他代码，以便在特定事件发生时被调用。 回调函数通常由调用方提供，用于定义在特定事件发生时应该执行的操作。 回调模式用于实现解耦和灵活性，允许不同模块之间通过回调函数进行通信，但不依赖于具体的实现细节。 事件驱动模式：\n事件驱动模式是一种编程范式，其中系统的行为和控制是由事件的发生和处理驱动的。 在事件驱动模式中，组件（如控件、对象等）可以产生事件，并将其发送到事件处理程序进行处理。 事件处理程序是事先定义好的，用于响应特定类型的事件。 事件驱动模式通常涉及事件的发布、订阅和分发机制，以便将事件路由到正确的处理程序。 区别：\n角色和通信方式：在回调模式中，回调函数是被调用方提供给调用方的，通过函数参数进行传递。而在事件驱动模式中，组件产生事件并将其发送给事件处理程序进行处理。 控制流：在回调模式中，调用方主动调用回调函数来传递控制权，以响应特定事件。而在事件驱动模式中，控制流是由事件的发生和处理驱动的，事件处理程序被动地等待事件的发生。 灵活性和扩展性：回调模式更加灵活，因为可以将不同的回调函数传递给相同的调用方，从而改变其行为。而事件驱动模式更加适用于大型系统，因为可以通过添加、移除或替换事件处理程序来扩展系统的功能。 通信机制：回调模式通常使用函数参数进行通信，而事件驱动模式通常使用发布-订阅或观察者模式来实现事件的传递和处理。 需要注意的是，回调模式和事件驱动模式并不是互斥的，它们可以同时存在于一个系统中，相互配合使用来实现不同的需求。\n回调模式和观察者模式有什么区别？ 回调模式和观察者模式是两种常见的设计模式，它们在某些方面有相似之处，但也存在一些区别。\n回调模式：\n在回调模式中，一个可执行的代码块（回调函数）被传递给其他代码，以便在特定事件发生时被调用。 回调函数通常由调用方提供，用于定义在特定事件发生时应该执行的操作。 回调模式用于实现解耦和灵活性，允许不同模块之间通过回调函数进行通信，但不依赖于具体的实现细节。 观察者模式：\n观察者模式是一种发布-订阅模式，用于在对象之间建立一对多的依赖关系。当一个对象的状态发生变化时，它会通知所有依赖于它的观察者对象。 观察者模式通常由一个主题（被观察者）和多个观察者组成。主题维护观察者列表，并在状态变化时通知观察者。 观察者模式用于实现对象之间的松耦合，使得主题和观察者可以独立变化，而不会相互影响。 区别：\n角色和通信方式：在回调模式中，回调函数是被调用方提供给调用方的，通过函数参数进行传递。而在观察者模式中，主题通常维护观察者列表，并通过通知方法将状态变化信息传递给观察者。 控制流：在回调模式中，调用方主动调用回调函数来传递控制权，以响应特定事件。而在观察者模式中，主题对象在状态变化时被动地通知观察者，并由观察者决定如何处理通知。 关注点：回调模式更关注于事件发生后的回调操作。观察者模式更关注于主题和观察者之间的状态变化通知和处理。 依赖关系：在回调模式中，调用方和被调用方之间存在直接依赖关系，因为回调函数是由调用方提供的。而在观察者模式中，主题和观察者之间松耦合，它们只通过接口进行通信，不直接依赖于具体的实现。 需要注意的是，回调模式和观察者模式可以根据具体的应用场景进行选择和组合使用。在某些情况下，它们可以互为补充，实现更灵活和可扩展的系统设计。\n使用回调模式，会存在内存泄露吗？ 在 Java 中使用回调模式时，也存在潜在的内存泄漏问题。内存泄漏可能发生在以下情况下：\n长期持有回调对象：如果一个对象持有一个回调对象的引用，并且该回调对象的生命周期比持有对象更长，那么即使持有对象不再使用，回调对象仍然保持对其的引用，从而导致内存泄漏。 匿名内部类回调：当使用匿名内部类作为回调对象时，如果匿名内部类引用了外部类的实例，且该实例的生命周期比回调对象更长，那么即使外部类实例不再需要，回调对象仍然保持对其的引用，导致内存泄漏。 使用回调模式，如何避免内存泄露？ 以下是一些常见的方法来避免内存泄漏：\n及时释放对象引用：确保在不再需要对象时，显式地将其引用设置为 null。这样可以使垃圾回收器能够回收对象所占用的内存。 SomeObject obj = new SomeObject(); // 使用obj对象... obj = null; // 不再需要obj对象时，将其引用设置为null 避免长期持有对象引用：当一个对象持有另一个对象的引用时，确保持有引用的对象的生命周期不比被引用对象更长。在不再需要持有对象时，及时将其引用设置为 null。 public class SomeClass { private Callback callback; public void setCallback(Callback callback) { this.callback = callback; } public void doSomething() { // 使用callback对象... callback = null; // 不再需要callback对象时，将其引用设置为null } } 使用弱引用或软引用：对于某些情况下，当对象不再被强引用引用时，希望能够被垃圾回收，可以使用弱引用（WeakReference）或软引用（SoftReference）来持有对象。这样，在内存不足时，垃圾回收器可以回收这些对象。 SomeObject obj = new SomeObject(); WeakReference\u0026lt;SomeObject\u0026gt; weakRef = new WeakReference\u0026lt;\u0026gt;(obj); // 使用weakRef对象... obj = null; // 不再需要obj对象时，将其引用设置为null // 在适当的时机，检查弱引用是否还持有对象 if (weakRef.get() == null) { // 对象已被垃圾回收 } 避免匿名内部类引用外部对象：在使用匿名内部类时，避免在内部类中引用外部类的实例，或者使用静态内部类来避免该问题。如果匿名内部类引用了外部类实例，并且外部类实例的生命周期比内部类更长，就会导致内存泄漏。 public class SomeClass { public void doSomething() { final SomeObject obj = new SomeObject(); Runnable runnable = new Runnable() { @Override public void run() { // 使用obj对象... } }; // 使用runnable对象... } } 在上述示例中，匿名内部类引用了外部类的SomeObject实例obj。如果在run()方法中持续引用了obj，那么即使doSomething()方法执行完毕，obj仍然无法被垃圾回收。为避免该问题，可以将SomeObject声明为final，或者使用静态内部类。\n1、在 Java 中，将SomeObject声明为final可以帮助避免匿名内部类引起的内存泄漏问题。\n当内部类引用外部类的实例时，如果外部类的实例不再需要，但内部类仍然持有对外部类实例的引用，就可能导致内存泄漏。\n当将SomeObject声明为final时，编译器会确保在匿名内部类中使用的外部类实例不可变。这意味着在编译时，编译器会将对外部类实例的引用复制给内部类的成员变量，并且该引用在整个内部类的生命周期中保持不变。\n由于引用是不可变的，因此不会出现外部类实例被内部类持有，从而导致外部类实例无法被垃圾回收的情况。一旦外部类实例不再被引用，即使匿名内部类仍然存在，外部类实例也可以被垃圾回收器回收。\n通过将SomeObject声明为final，可以确保在匿名内部类中对外部类实例的引用是安全的，不会导致内存泄漏问题。这是因为编译器在编译时会生成正确的代码，确保内部类不会持有外部类实例的引用超过其生命周期。\n需要注意的是，虽然使用final修饰外部类引用可以帮助避免内存泄漏问题，但这并不是解决所有可能导致内存泄漏的情况的通用解决方案。在处理回调或内部类时，还需要仔细考虑对象引用的生命周期，并采取适当的措施来避免潜在的内存泄漏。\n2、使用静态内部类可以帮助避免内部类引起的内存泄漏问题。\n静态内部类与外部类之间的引用是相互独立的，这意味着静态内部类不会隐式地持有对外部类实例的引用。\n当内部类是静态内部类时，它不会隐式地持有对外部类实例的引用。这意味着即使外部类实例不再被引用，静态内部类仍然可以独立存在，而不会阻止外部类实例被垃圾回收。\n由于静态内部类不持有对外部类实例的引用，因此在外部类实例不再需要时，可以安全地将其设置为 null，并允许垃圾回收器回收内存。\n以下是使用静态内部类的示例：\npublic class SomeClass { private static class CallbackImpl implements Callback { // 实现回调接口的方法 } public void doSomething() { Callback callback = new CallbackImpl(); // 使用callback对象... callback = null; // 不再需要callback对象时，将其引用设置为null } } 在上述示例中，CallbackImpl是静态内部类，它实现了Callback接口。在doSomething()方法中，我们创建了CallbackImpl的实例，并使用它进行回调操作。当不再需要callback对象时，将其引用设置为 null，以允许垃圾回收器回收内存。\n使用静态内部类可以有效地避免内存泄漏问题，因为它们不会持有对外部类实例的引用，从而使得外部类实例可以在不再需要时被垃圾回收。这使得静态内部类成为一种常见的处理回调或复杂逻辑的有效方式。\n","permalink":"https://blog.chensoul.cc/posts/2023/10/13/java-design-patterns-callback/","summary":"本文主要介绍 Callback 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 回调（Callback）是一种设计模式，在这种模式中，一个可执行的代码被作为参数传递给其他代码，接收方的代码可以在适当的时候调用它。\n在真实世界的例子中，当我们需要在任务完成时被通知时，我们可以将一个回调方法传递给调用者，并等待它调用以通知我们。简单地说，回调是一个传递给调用者的方法，在定义的时刻被调用。\n维基百科说\n在计算机编程中，回调又被称为“稍后调用”函数，可以是任何可执行的代码用来作为参数传递给其他代码；其它代码被期望在给定时间内调用回调方法。\n代码 回调是一个只有一个方法的简单接口。\npublic interface Callback { void call(); } 下面我们定义一个任务它将在任务执行完成后执行回调。\npublic abstract class Task { final void executeWith(Callback callback) { execute(); Optional.ofNullable(callback).ifPresent(Callback::call); } public abstract void execute(); } public final class SimpleTask extends Task { private static final Logger LOGGER = getLogger(SimpleTask.class); @Override public void execute() { LOGGER.info(\u0026#34;Perform some important activity and after call the callback method.\u0026#34;); } } 最后这里是我们如何执行一个任务然后接收一个回调当它完成时。\nvar task = new SimpleTask(); task.executeWith(() -\u0026gt; LOGGER.info(\u0026#34;I\u0026#39;m done now.\u0026#34;)); 类图 适用场景 回调模式适用于以下场景：\n异步操作：当需要在异步操作完成后执行某些操作时，可以使用回调模式。例如，在网络请求中，可以传递一个回调函数，在请求完成后调用该函数处理响应数据。 事件处理：当需要对事件进行响应和处理时，可以使用回调模式。例如，在图形界面开发中，可以注册某个控件的回调函数，以便在用户触发事件时执行相应的操作。 插件扩展：当需要为应用程序提供扩展性，允许第三方插件在特定事件发生时进行自定义操作时，可以使用回调模式。例如，游戏引擎中的事件系统允许开发者注册回调函数以响应游戏中的特定事件。 回调链：当需要按特定顺序执行多个回调函数，并将前一个回调函数的结果传递给下一个回调函数时，可以使用回调模式。这种情况下，回调函数形成了一个回调链。 模板方法模式：回调模式常与模板方法模式结合使用。模板方法模式定义了一个算法的骨架，而具体的步骤由子类实现。可以使用回调模式将子类中的具体步骤作为回调函数传递给模板方法。 总的来说，回调模式适用于需要在特定事件发生后执行某些操作的情况，以及需要实现解耦和灵活性的场景。它提供了一种在代码间通信的方式，使得代码可以更加模块化和可复用。\nJava 例子 CyclicBarrier 构造函数可以接受回调，该回调将在每次障碍被触发时触发。 FAQ 回调模式如何实现解耦和灵活性？ 回调模式通过将一个可执行的代码块（回调函数）作为参数传递给其他代码，实现了解耦和灵活性。\n解耦性：回调模式可以将调用方与被调用方解耦，使它们之间的关系更加松散。调用方只需要知道回调函数的接口，而不需要了解具体的实现细节。被调用方在特定的时机调用回调函数，而不需要知道调用方的具体实现。这种解耦性使得系统中的不同部分可以独立地进行修改和扩展，而不会对彼此产生过多的依赖。\n灵活性：回调模式提供了一种灵活的扩展机制。通过传递不同的回调函数，可以改变程序的行为或逻辑，而不需要修改原有的代码。这种灵活性使得系统可以适应不同的需求和变化，而不需要进行大规模的修改或重构。同时，回调模式也允许在运行时动态地修改回调函数，从而实现更高级的动态行为。","title":"Java设计模式：Callback"},{"content":"Spring Boot 3.0 于 2022 年 11 月正式发布，包含一些新功能和改进。这是继大约 4.5 年前发布 Spring Boot 2.0 后 Spring Boot 的第一个主要版本。它也是第一个支持 Spring Framework 6.0 的 Spring Boot GA 版本。作为开发人员，我们需要了解这些更新，才能顺利使用 Spring Boot。毫无疑问，新版本中最大的转变之一是放弃了对旧版本 Java 的支持。\n在本文中，我们将讨论“Spring Boot 3 和 Spring 6 中的新功能”。\nSpring 3.0 版本有哪些主要亮点？ Spring 3.0 版本的亮点包括：\nJava 17 基线 支持 Jakarta EE 10 和 EE 9 基线 支持使用 GraalVM 生成本机映像，取代实验性 Spring Native 项目 通过测微计和测微计追踪提高了可观测性 谁可以真正使用 Spring Boot 3？ 如前所述，Spring Boot 3.0 最大的转变是忽略了对旧版本 Java 的支持。是的，我们至少需要 Java 17 才能使用 Spring Boot 3.0。因此，在使用 Spring Boot 3.0 之前必须具备 JDK 17 环境。\nSpring Boot 3 和 Spring 6 有哪些新功能？ 这里需要注意的重要一点是 Spring Boot 3.0 构建于 Spring Framework 6 之上并需要 Spring Framework 6。因此，如果您的 pom.xml 指向 Spring Boot 版本 3.0.0，它将自动下载 Spring Framework 6 所需的依赖项。因此，默认情况下，您在使用 Spring Boot 3.0 时将使用 Spring Framework 6。请访问单独的文章了解 Spring Framework 6.0 中的新功能。这里只讨论 Spring Boot 3 中的新功能。\nJava 17 基线和 Java 19 支持 我们需要 Java 17 作为最低版本才能与 Spring 3.0 配合使用。如果您当前使用的是 Java 8、Java 11 或 Java 14 等较低版本，则需要先将 JDK 升级到 JDK 17，然后再开始使用 Spring Boot 3.0 开发应用程序。目前 Java 的最新版本是 JDK 19。不过，Spring Boot 3.0 也运行良好，并且已经在 JDK 19 上进行了测试。\n您还可以阅读：Java 17 特性。\n第三方库升级 由于 Java EE 已更改为 Jakarta EE，Spring Boot 3.0 也将所有依赖项的 API 从 Java EE 迁移到 Jakarta EE API。因此，以“javax”开头的包名称需要相应地更改为“jakarta”。 例如，一些常用的包将被更改如下：\njavax.persistence.* -\u0026gt; jakarta.persistence.* javax.validation.* -\u0026gt; jakarta.validation.* javax.servlet.* -\u0026gt; jakarta.servlet.* javax.annotation.* -\u0026gt; jakarta.annotation.* javax.transaction.* -\u0026gt; jakarta.transaction.* 注意：请注意，javax.sql._ 和 javax.crypto._ 等包不会更改为“jakarta.*”，因为它们是 Java 17 JDK 的一部分，而不是 Java EE 的一部分。只有属于 Java EE 的那些包才会更改为 Jakarta EE。\n只要有可能，我们都会选择 Jakarta EE 10 兼容的依赖项，包括：\nJakarta Activation 2.1 Jakarta JMS 3.1 Jakarta JSON 2.1 Jakarta JSON Bind 3.0 Jakarta Mail 2.1 Jakarta Persistence 3.1 Jakarta Servlet 6.0 Jakarta Servlet JSP JSTL 3.0 Jakarta Transaction 2.0 Jakarta Validation 3.0 Jakarta WebSocket 2.1 Jakarta WS RS 3.1 Jakarta XML SOAP 3.0 Jakarta XML WS 4.0 随着 Spring 框架升级到版本 6，其他 Spring 项目也在这个版本中升级，它们是： Spring AMQP 3.0. Spring Batch 5.0. Spring Data 2022.0. Spring GraphQL 1.1. Spring HATEOAS 2.0. Spring Integration 6.0. Spring Kafka 3.0. Spring LDAP 3.0. Spring REST Docs 3.0. Spring Retry 2.0. Spring Security 6.0 (see also what’s new). Spring Session 3.0 Spring WS 4.0. 第三方 jar 的最新稳定版本也会尽可能升级。一些常用的依赖项升级包括： Couchbase Client 3.4 Ehcache 3.10 Elasticsearch Client 8.5 Flyway 9 Groovy 4.0 Hibernate 6.1 Hibernate Validator 8.0 Jackson 2.14 Jersey 3.1 Jetty 11 jOOQ 3.16 Kotlin 1.7.20 Liquibase 4.13 Lettuce 6.2 Log4j 2.18 Logback 1.4 Micrometer 1.10 Micrometer Tracing 1.0 Neo4j Java Driver 5.2 Netty 4.1.77.Final OkHttp 4.10 R2DBC 1.0 Reactor 2022.0 SLF4J 2.0 SnakeYAML 1.32 Tomcat 10 Thymeleaf 3.1.0.M2 Undertow 2.2.20.Final GraalVM 本机映像支持 GraalVM Native Images 提供了一种部署和运行 Java 应用程序的新方法。与 Java 虚拟机相比，本机映像可以以更小的内存占用和更快的启动时间运行。\nGraalVM 是一种高性能 JDK，旨在加快用 Java 和其他 JVM 语言编写的应用程序的执行速度，同时还为 JavaScript、Python 和许多其他流行语言提供运行时。 GraalVM 提供了两种运行 Java 应用程序的方法：在带有 Graal 即时 (JIT) 编译器的 HotSpot JVM 上或作为提前 (AOT) 编译的本机可执行文件。\nGraalVM 本机映像是独立的可执行文件，可以通过提前处理已编译的 Java 应用程序来生成。原生映像通常比 JVM 映像具有更小的内存占用并且启动速度更快。它们非常适合使用容器映像部署的应用程序。 GraalVM Native Image 是一个完整的、特定于平台的可执行文件。我们不需要提供 Java 虚拟机来运行本机映像。\n如果您想了解更多信息并尝试使用 GraalVM，您可以继续阅读有关“GraalVM Native Image Support”的官方文档。\n通过测微计和测微计追踪提高可观测性 可观察性是从外部观察正在运行的系统的内部状态的能力。换句话说，“通过检查系统的输出，您可以在多大程度上了解系统的内部结构”。它由日志记录、指标和跟踪三大支柱组成。对于指标和跟踪，Spring Boot 使用 Micrometer Observation。要创建您自己的观察（这将产生指标和跟踪），您可以注入 ObservationRegistry。\nSpring Boot 3.0 支持 Micrometer 1.10 中引入的新观察 API。新的 ObservationRegistry 界面可用于创建观察结果，为指标和跟踪提供单一 API。 Spring Boot 现在会自动为您配置 ObservationRegistry 实例。下面的代码片段演示了 ObervationRegistry 的概念。 @Component public class MyCustomObservation { private final ObservationRegistry observationRegistry; public MyCustomObservation(ObservationRegistry observationRegistry) { this.observationRegistry = observationRegistry; } public void doSomething() { Observation.createNotStarted(\u0026#34;doSomething\u0026#34;, this.observationRegistry) .lowCardinalityKeyValue(\u0026#34;locale\u0026#34;, \u0026#34;en-US\u0026#34;) .highCardinalityKeyValue(\u0026#34;userId\u0026#34;, \u0026#34;42\u0026#34;) .observe(() -\u0026gt; { // Execute business logic here }); } } Spring Boot 现在会自动为您配置 Micrometer Tracing。这包括对 Brave、OpenTelemetry、Zipkin 和 Wavefront 的支持。 Spring Cloud Sleuth 在新版本中被 Micrometer Tracing Framework 取代。 使用 Spring Boot 3.0 的 Spring Security UserDetailsService 示例 此外，我们还有一篇单独的文章作为 Spring Security UserDetailsS​​ervice 使用 Spring Boot 3 的示例，该文章完全使用 Spring Boot 3.0 并遵循 Spring 官方文档提供的分步指南进行开发。此外，您可以阅读《Spring Boot 3.0 迁移指南》来彻底了解迁移过程。\n这是目前的功能列表。显然，还有更多。我们将不时更新文章。\n有关 Spring Boot 的其他教程，您可以访问 Spring Boot 教程页面。\nSpring Boot 3 和 Spring 6 版本如何互连？ 如上所述，Spring Boot 3.0 构建在 Spring Framework 6.0 之上。两者的发布之间有一周的间隔。 Spring Framework 6.0.0 比 Spring Boot 3.0 发布早一周发布。换句话说，Spring Framework 6.0.0 是 Spring Boot 3.0 的基础。此外，如果您的 pom.xml 指向 Spring Boot 版本 3.0.0，它将自动下载 Spring Framework 6 所需的依赖项。因此，默认情况下，您在使用 Spring Boot 3.0 时将使用 Spring Framework 6。\n虽然提前（AOT）和 GraalVM 是 Spring Framework 6.0 的新功能，但如果没有完整的 Spring Boot 堆栈，它们就没有用。它们在基于 Spring 的独立应用程序中还不够好。\n下一个版本 Spring Framework 6.1 GA 将于明年即 2023 年 11 月发布。另一方面，到 2023 年 11 月，Spring Boot 将有两个版本，即 Spring Boot 3.0 和 3.1。这意味着 Spring Framework 将有每年发布一个版本，而 Spring boot 每年发布两个版本，并支持最新的 JDK 版本。按照 JDK 的常规发布，JDK 21(LTS) 将于 2023 年 9 月发布，即 Spring Framework 6.1 GA 发布之前。\nFAQ Spring Boot 3 可以与 Java 11 一起使用吗？ 一点也不。 Spring Boot 3.0.0 需要 JDK 17 作为最低版本才能使用。 Spring Boot 3.0 发布文档中明确提到了这一点。如果您想使用低于 Java 17 的 Java 版本，则必须使用 Spring Boot 2.0。\nSpring Boot 3 支持 Java 8 吗？ 根本不需要。为了使用 Spring Boot 3，您的系统中必须至少安装 Java 17。不仅安装了，您的代码还必须使用 JDK 17 进行编译。使用 JDK 17 或更高版本编译的代码将仅被 Spring Boot 3 接受。\n原文链接：https://javatechonline.com/new-features-in-spring-boot-3-and-spring-6/\n","permalink":"https://blog.chensoul.cc/posts/2023/10/13/new-features-in-spring-boot-3-and-spring-6/","summary":"Spring Boot 3.0 于 2022 年 11 月正式发布，包含一些新功能和改进。这是继大约 4.5 年前发布 Spring Boot 2.0 后 Spring Boot 的第一个主要版本。它也是第一个支持 Spring Framework 6.0 的 Spring Boot GA 版本。作为开发人员，我们需要了解这些更新，才能顺利使用 Spring Boot。毫无疑问，新版本中最大的转变之一是放弃了对旧版本 Java 的支持。\n在本文中，我们将讨论“Spring Boot 3 和 Spring 6 中的新功能”。\nSpring 3.0 版本有哪些主要亮点？ Spring 3.0 版本的亮点包括：\nJava 17 基线 支持 Jakarta EE 10 和 EE 9 基线 支持使用 GraalVM 生成本机映像，取代实验性 Spring Native 项目 通过测微计和测微计追踪提高了可观测性 谁可以真正使用 Spring Boot 3？ 如前所述，Spring Boot 3.0 最大的转变是忽略了对旧版本 Java 的支持。是的，我们至少需要 Java 17 才能使用 Spring Boot 3.0。因此，在使用 Spring Boot 3.0 之前必须具备 JDK 17 环境。\nSpring Boot 3 和 Spring 6 有哪些新功能？ 这里需要注意的重要一点是 Spring Boot 3.0 构建于 Spring Framework 6 之上并需要 Spring Framework 6。因此，如果您的 pom.","title":"[译]Spring Boot3和Spring6中的新特性"},{"content":"HTTP 是每个 Web 开发人员都应该了解的协议，因为它为整个 Web 提供动力。了解 HTTP 当然可以帮助您开发更好的应用程序。\n在本文中，我将讨论 HTTP 是什么、它是如何产生的、它今天的状况以及我们是如何走到这一步的\n什么是 HTTP？ 首先，什么是 HTTP？ HTTP 是基于 TCP/IP 的应用层通信协议，它标准化了客户端和服务器之间的通信方式。它定义了如何通过互联网请求和传输内容。通过应用层协议，我的意思是它只是一个标准化主机（客户端和服务器）通信方式的抽象层。 HTTP 本身依赖于 TCP/IP 来获取客户端和服务器之间的请求和响应。\n默认情况下，使用 TCP 端口 80，但也可以使用其他端口。然而，HTTPS 使用端口 443。\nHTTP/0.9 - One Liner (1991) HTTP 的第一个有记录的版本是 1991 年提出的 HTTP/0.9。它是有史以来最简单的协议；有一个名为 GET 的方法。如果客户端必须访问服务器上的某个网页，它会发出如下所示的简单请求\nGET /index.html 服务器的响应如下所示\n(response body) (connection closed) 也就是说，服务器将收到请求，回复 HTML 作为响应，一旦内容传输完毕，连接就会关闭。有\n无标题 GET 是唯一允许的方法 响应必须是 HTML 正如您所看到的，该协议实际上只不过是未来的踏脚石。\nHTTP/1.0 - 1996 1996 年，HTTP 的下一个版本（即 HTTP/1.0）得到了发展，比原始版本有了很大的改进。与仅针对 HTML 响应设计的 HTTP/0.9 不同，HTTP/1.0 现在也可以处理其他响应格式，即图像、视频文件、纯文本或任何其他内容类型。它添加了更多方法（即 POST 和 HEAD）、更改了请求/响应格式、将 HTTP 标头添加到请求和响应中、添加了状态代码来标识响应、引入了字符集支持、多部分类型、授权、缓存、内容编码等都包括在内。\n以下是示例 HTTP/1.0 请求和响应的样子：\nGET / HTTP/1.0 Host: cs.fyi User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) Accept: */* 正如您所看到的，除了请求之外，客户端还发送了它的个人信息、所需的响应类型等。而在 HTTP/0.9 中，客户端永远无法发送此类信息，因为没有标头。\n对上述请求的响应示例可能如下所示\nHTTP/1.0 200 OK Content-Type: text/plain Content-Length: 137582 Expires: Thu, 05 Dec 1997 16:00:00 GMT Last-Modified: Wed, 5 August 1996 15:55:28 GMT Server: Apache 0.84 (response body) (connection closed) 响应的开头是 HTTP/1.0（HTTP 后跟版本号），然后是状态代码 200，后跟原因短语（或者状态代码的描述，如果您愿意的话）。\n在此较新版本中，请求和响应标头仍保留为 ASCII 编码，但响应正文可以是任何类型，即图像、视频、HTML、纯文本或任何其他内容类型。因此，现在服务器可以向客户端发送任何内容类型；推出后不久，HTTP 中的“超文本”一词就变得用词不当。 HMTP 或超媒体传输协议可能更有意义，但我想，我们终生都坚持这个名字。\nHTTP/1.0 的主要缺点之一是每个连接不能有多个请求。也就是说，每当客户端需要从服务器获取某些内容时，它都必须打开一个新的 TCP 连接，并且在满足该单个请求后，连接将被关闭。对于任何下一个要求，都必须建立在新的连接上。为什么不好？\n好吧，假设您访问的网页包含 10 个图像、5 个样式表和 5 个 JavaScript 文件，总共有 20 个项目需要在向该网页发出请求时获取。由于服务器在满足请求后立即关闭连接，因此将存在一系列 20 个单独的连接，其中每个项目都将在其单独的连接上一个接一个地提供服务。\n如此大量的连接会导致严重的性能损失，因为由于三向握手和慢启动，需要新的 TCP 连接会造成显着的性能损失。\n三方握手 三向握手最简单的形式是，所有 TCP 连接都以三向握手开始，其中客户端和服务器在开始共享应用程序数据之前共享一系列数据包。\nSYN - 客户端选取一个随机数（假设为 x）并将其发送到服务器。 SYN ACK - 服务器通过将 ACK 数据包发送回客户端来确认请求，该数据包由随机数组成，假设服务器拾取 y 和数字 x+1，其中 x 是客户端发送的数字 ACK - 客户端递增从服务器接收到的数字 y，并发送回带有数字 y+1 的 ACK 数据包 一旦三向握手完成，客户端和服务器之间的数据共享就可以开始。应该注意的是，客户端可以在发送最后一个 ACK​​ 数据包后立即开始发送应用程序数据，但服务器仍然必须等待收到 ACK 数据包才能满足请求。\n然而，HTTP/1.0 的一些实现试图通过引入一个名为 Connection: keep-alive 的新标头来克服这个问题，该标头旨在告诉服务器“嘿服务器，不要关闭此连接，我再次需要它”。但它仍然没有得到广泛的支持，问题仍然存在。\n除了无连接之外，HTTP 也是一种无状态协议，即服务器不维护有关客户端的信息，因此每个请求都必须具有服务器自己完成请求所需的信息，而不与任何旧协议有任何关联。要求。因此，这火上浇油，即除了客户端必须打开大量连接之外，它还必须在线路上发送一些冗余数据，从而导致带宽使用量增加。\nHTTP/1.1 - 1997 HTTP/1.0 仅仅 3 年后，下一个版本即 HTTP/1.1 于 1999 年发布；比前身做了很多改进。相对于 HTTP/1.0 的主要改进包括\n添加了新的 HTTP 方法，其中引入了 PUT、PATCH、OPTIONS、DELETE\n主机名标识 在 HTTP/1.0 中，主机标头不是必需的，但 HTTP/1.1 使其成为必需的。\n持久连接 如上所述，在 HTTP/1.0 中，每个连接只有一个请求，一旦请求完成，连接就会关闭，这会导致严重的性能影响和延迟问题。 HTTP/1.1 引入了持久连接，即连接默认情况下不会关闭，而是保持打开状态，从而允许多个连续请求。要关闭连接，请求头 Connection: close 必须可用。\n客户端通常在最后一个请求中发送此标头以安全地关闭连接。\n管道化 它还引入了对管道化的支持，客户端可以在同一连接上向服务器发送多个请求，而无需等待服务器的响应，并且服务器必须按照接收请求的顺序发送响应。但是，您可能会问，客户端如何知道这是第一个响应下载完成并且下一个响应内容开始的点！\n好吧，为了解决这个问题，必须存在 Content-Length 标头，客户端可以使用它来识别响应结束的位置，并且可以开始等待下一个响应。\n应该注意的是，为了从持久连接或管道中受益，Content-Length 标头必须在响应上可用，因为这会让客户端知道传输何时完成并且可以发送下一个请求（以正常的顺序方式）发送请求）或开始等待下一个响应（当启用管道时）。\n但这种方法仍然存在一个问题。也就是说，如果数据是动态的并且服务器无法事先找到内容长度怎么办？那么在这种情况下，您真的无法从持久连接中受益，不是吗？！为了解决这个问题，HTTP/1.1 引入了分块编码。在这种情况下，服务器可能会省略内容长度以支持分块编码（稍后会详细介绍）。但是，如果它们都不可用，则必须在请求结束时关闭连接。\n分块传输 在动态内容的情况下，当服务器在传输开始时无法真正找出 Content-Length 时，它可能会开始分块（逐块）发送内容，并在发送时为每个块添加 Content-Length 。当所有块都发送完毕（即整个传输已完成）时，它会发送一个空块（即 Content-Length 设置为零的块），以便识别传输已完成的客户端。\n为了通知客户端有关分块传输的信息，服务器包含标头 Transfer-Encoding: chunked\n与仅具有基本身份验证的 HTTP/1.0 不同，HTTP/1.1 包括摘要和代理身份验证\n缓存\n字节范围\n字符集\n语言谈判\n客户端 cookie\n增强的压缩支持\n新的状态代码\n更多\n我不会在这篇文章中详细介绍 HTTP/1.1 的所有功能，因为它本身就是一个主题，您已经可以找到很多相关内容。我建议您阅读的这样一份文档是 HTTP/1.0 和 HTTP/1.1 之间的关键差异，这里是优秀者的原始 RFC 链接。\nHTTP/1.1 于 1999 年推出，多年来一直是一个标准。尽管如此，它比它的前身有了很大的改进；随着网络每天都在变化，它开始显示出它的年龄。如今加载网页比以往更加消耗资源。如今，一个简单的网页必须打开 30 多个连接。那么 HTTP/1.1 有持久连接，那为什么有这么多连接呢？你说！原因是，在 HTTP/1.1 中，任何时刻只能有一个未完成的连接。\nHTTP/1.1 试图通过引入管道来解决这个问题，但它并没有完全解决这个问题，因为队头阻塞，缓慢或繁重的请求可能会阻塞后面的请求，一旦请求卡在管道中，它就会被阻塞。必须等待下一个请求得到满足。\n为了克服 HTTP/1.1 的这些缺点，开发人员开始实施解决方法，例如使用 spritesheet、CSS 中的编码图像、单个庞大的 CSS/Javascript 文件、域分片等。\nSPDY-2009 谷歌继续尝试替代协议，以提高网络速度并提高网络安全性，同时减少网页延迟。 2009 年，他们宣布了 SPDY。\nSPDY 是 Google 的商标，而不是缩写词。\n可以看出，如果我们不断增加带宽，网络性能一开始会有所提高，但到了某个阶段，性能增益就不会太大了。但如果你对延迟也采取同样的做法，即如果我们不断降低延迟，那么性能就会持续提升。这是 SPDY 背后性能增益的核心思想，减少延迟以提高网络性能。\n对于那些不知道区别的人来说，延迟是延迟，即数据在源和目的地之间传输所需的时间（以毫秒为单位），而带宽是每秒传输的数据量（每秒比特数）。\nSPDY 的功能包括多路复用、压缩、优先级、安全性等。我不打算详细介绍 SPDY，因为当我们在下一节中深入了解 HTTP/2 的本质时，您就会明白了。据说 HTTP/2 主要是受到 SPDY 的启发。\nSPDY 并没有真正尝试取代 HTTP；而是它是 HTTP 上的转换层，存在于应用程序层并在将请求发送到线路之前对其进行修改。它开始成为事实上的标准，大多数浏览器开始实现它。\n2015 年，在 Google，他们不想有两个相互竞争的标准，因此决定将其合并到 HTTP 中，同时诞生了 HTTP/2 并弃用了 SPDY。\nHTTP/2 - 2015 到现在为止，您必须确信为什么我们需要对 HTTP 协议进行另一次修订。 HTTP/2 专为低延迟内容传输而设计。与旧版本 HTTP/1.1 的主要功能或区别包括\n二进制而不是文本 多路复用 - 单个连接上的多个异步 HTTP 请求 使用 HPACK 进行标头压缩 服务器推送 - 单个请求的多个响应 请求优先级 安全 1. 二进制协议 HTTP/2 倾向于通过使其成为二进制协议来解决 HTTP/1.x 中存在的延迟增加的问题。作为一种二进制协议，它更容易解析，但与 HTTP/1.x 不同，它不再是人眼可读的。 HTTP/2 的主要构建块是帧和流\n帧和流 HTTP 消息现在由一个或多个帧组成。有一个用于元数据的 HEADERS 帧和用于有效负载的 DATA 帧，并且存在多种其他类型的帧（HEADERS、DATA、RST_STREAM、SETTINGS、PRIORITY 等），您可以通过 HTTP/2 规范进行检查。\n每个 HTTP/2 请求和响应都会被赋予一个唯一的流 ID，并被分为帧。帧只不过是二进制数据。帧的集合称为流。每个帧都有一个流 ID，用于标识其所属的流，并且每个帧都有一个公共标头。另外，除了流 ID 是唯一的之外，值得一提的是，客户端发起的任何请求都使用奇数，而服务器响应的流 ID 则为偶数。\n除了 HEADERS 和 DATA 之外，我认为这里值得一提的另一种帧类型是 RST_STREAM，它是一种特殊的帧类型，用于中止某些流，即客户端可以发送此帧以让服务器知道我不需要此流不再了。在 HTTP/1.1 中，使服务器停止向客户端发送响应的唯一方法是关闭连接，这会导致延迟增加，因为必须为任何连续请求打开新连接。\n在 HTTP/2 中，客户端可以使用 RST_STREAM 并停止接收特定流，同时连接仍处于打开状态并且其他流仍将在播放中。\n2. 多路复用 由于 HTTP/2 现在是一个二进制协议，并且正如我上面所说，它使用帧和流来进行请求和响应，因此一旦打开 TCP 连接，所有流都将通过同一连接异步发送，而无需打开任何其他连接。反过来，服务器以相同的异步方式响应，即响应没有顺序，客户端使用分配的流 ID 来标识特定数据包所属的流。\n这也解决了 HTTP/1.x 中存在的队头阻塞问题，即客户端不必等待需要时间的请求，而其他请求仍将得到处理。\n3. 报头压缩 它是单独 RFC 的一部分，专门用于优化发送的标头。其本质是，当我们不断地从同一个客户端访问服务器时，我们会在标头中一遍又一遍地发送大量冗余数据，有时可能会有 cookie 增加标头大小，从而导致带宽使用和延迟增加。为了克服这个问题，HTTP/2 引入了标头压缩。\n与请求和响应不同，标头不会以 gzip 或 compress 等格式压缩，但标头压缩有不同的机制，即使用霍夫曼代码对文字值进行编码，标头表由客户端和服务器以及客户端维护服务器在后续请求中省略任何重复的标头（例如用户代理等），并使用两者维护的标头表引用它们。当我们谈论标头时，让我在这里补充一点，标头仍然与 HTTP/1.1 中的相同，除了添加一些伪标头，即 :method 、 :scheme 、 :host 和 :path\n4. 服务器推送 服务器推送是 HTTP/2 的另一个巨大功能，服务器知道客户端将请求某个资源，可以将其推送给客户端，甚至无需客户端请求。例如，假设浏览器加载网页，它会解析整个页面以找出必须从服务器加载的远程内容，然后向服务器发送后续请求以获取该内容。\n服务器推送允许服务器通过推送它知道客户端将需要的数据来减少往返次数。其工作原理是，服务器发送一个名为 PUSH_PROMISE 的特殊帧，通知客户端：“嘿，我即将将此资源发送给您！别向我要。” PUSH_PROMISE 帧与导致推送发生的流相关联，它包含承诺的流 ID，即服务器将在其上发送要推送的资源的流。\n5. 请求优先级 客户端可以通过在打开流的 HEADERS 帧中包含优先级信息来为流分配优先级。在任何其他时间，客户端都可以发送 PRIORITY 帧来更改流的优先级。\n没有任何优先级信息，服务器异步处理请求，即没有任何顺序。如果为流分配了优先级，则服务器根据此优先级信息决定需要分配多少资源来处理哪个请求。\n6. 安全 关于是否应该对 HTTP/2 强制执行安全性（通过 TLS）进行了广泛的讨论。最终决定不强制执行。然而，大多数供应商表示，他们仅在通过 TLS 使用 HTTP/2 时才支持 HTTP/2。因此，尽管 HTTP/2 不要求按规范进行加密，但无论如何它在默认情况下已成为强制性的。排除了这一点，HTTP/2 在通过 TLS 实现时确实提出了一些要求，即必须使用 TLS 版本 1.2 或更高版本，必须有一定水平的最小密钥大小，需要临时密钥等。\n原文链接：https://cs.fyi/guide/http-in-depth\n","permalink":"https://blog.chensoul.cc/posts/2023/10/12/http-in-depth/","summary":"HTTP 是每个 Web 开发人员都应该了解的协议，因为它为整个 Web 提供动力。了解 HTTP 当然可以帮助您开发更好的应用程序。\n在本文中，我将讨论 HTTP 是什么、它是如何产生的、它今天的状况以及我们是如何走到这一步的\n什么是 HTTP？ 首先，什么是 HTTP？ HTTP 是基于 TCP/IP 的应用层通信协议，它标准化了客户端和服务器之间的通信方式。它定义了如何通过互联网请求和传输内容。通过应用层协议，我的意思是它只是一个标准化主机（客户端和服务器）通信方式的抽象层。 HTTP 本身依赖于 TCP/IP 来获取客户端和服务器之间的请求和响应。\n默认情况下，使用 TCP 端口 80，但也可以使用其他端口。然而，HTTPS 使用端口 443。\nHTTP/0.9 - One Liner (1991) HTTP 的第一个有记录的版本是 1991 年提出的 HTTP/0.9。它是有史以来最简单的协议；有一个名为 GET 的方法。如果客户端必须访问服务器上的某个网页，它会发出如下所示的简单请求\nGET /index.html 服务器的响应如下所示\n(response body) (connection closed) 也就是说，服务器将收到请求，回复 HTML 作为响应，一旦内容传输完毕，连接就会关闭。有\n无标题 GET 是唯一允许的方法 响应必须是 HTML 正如您所看到的，该协议实际上只不过是未来的踏脚石。\nHTTP/1.0 - 1996 1996 年，HTTP 的下一个版本（即 HTTP/1.0）得到了发展，比原始版本有了很大的改进。与仅针对 HTML 响应设计的 HTTP/0.9 不同，HTTP/1.0 现在也可以处理其他响应格式，即图像、视频文件、纯文本或任何其他内容类型。它添加了更多方法（即 POST 和 HEAD）、更改了请求/响应格式、将 HTTP 标头添加到请求和响应中、添加了状态代码来标识响应、引入了字符集支持、多部分类型、授权、缓存、内容编码等都包括在内。\n以下是示例 HTTP/1.0 请求和响应的样子：\nGET / HTTP/1.0 Host: cs.fyi User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) Accept: */* 正如您所看到的，除了请求之外，客户端还发送了它的个人信息、所需的响应类型等。而在 HTTP/0.9 中，客户端永远无法发送此类信息，因为没有标头。\n对上述请求的响应示例可能如下所示\nHTTP/1.0 200 OK Content-Type: text/plain Content-Length: 137582 Expires: Thu, 05 Dec 1997 16:00:00 GMT Last-Modified: Wed, 5 August 1996 15:55:28 GMT Server: Apache 0.","title":"[译]关于 HTTP 您需要了解的一切"},{"content":"前端学习路线图:\nInternet： HTTP DNS HTML Basic Semantic HTML Forms and Validations Accessibility SEO CSS Basic Layout Responsive Design JavaScript Baisc DOM Fetch API / Ajax Package Manager npm pnpm yarn Framework Angular Vue.js React Svelte Solid JS Qwik Writing CSS Tailwind Radix UI Shadcn UI CSS Architecture BEM CSS Preprocessors SASS PostCSS Build Module Bundlers parcel Rollup Webpack esbuild Vite Task Runners npm scripts Linters and Formatters Prettier ESLint Test Vitest Jest Playwirte Cypress Authentication Strategies JWT OAuth SSO Basic Auth Session Auth Web Security Basics CORS HTTPS CSP OWASP Security Risks Web Components HTML Templates Custom Elements Shadow DOM Type Checkers TypeScript Server Side Rendering(SSR) Svelte Svelte Kit Vue.js Nuxt.js Angular Universal React Next.js Remix GraphQL Apollo Relay Modern Static Site Generators Vuepress Jekyll Hugo Nuxt.js Astro Eleventy Next.js Remix Progressive Web App Mobel Applications React Native Flutter Ionic NativeScript Desktop Applications Bonus Content ","permalink":"https://blog.chensoul.cc/posts/2023/10/12/frontend-roadmap/","summary":"前端学习路线图:\nInternet： HTTP DNS HTML Basic Semantic HTML Forms and Validations Accessibility SEO CSS Basic Layout Responsive Design JavaScript Baisc DOM Fetch API / Ajax Package Manager npm pnpm yarn Framework Angular Vue.js React Svelte Solid JS Qwik Writing CSS Tailwind Radix UI Shadcn UI CSS Architecture BEM CSS Preprocessors SASS PostCSS Build Module Bundlers parcel Rollup Webpack esbuild Vite Task Runners npm scripts Linters and Formatters Prettier ESLint Test Vitest Jest Playwirte Cypress Authentication Strategies JWT OAuth SSO Basic Auth Session Auth Web Security Basics CORS HTTPS CSP OWASP Security Risks Web Components HTML Templates Custom Elements Shadow DOM Type Checkers TypeScript Server Side Rendering(SSR) Svelte Svelte Kit Vue.","title":"前端学习路线图"},{"content":"欢迎来到 Git 面试准备指南，我们将在这里向初学者和经验丰富的专业人士讨论最常见的 Git 面试问题。无论您是准备参加 DevOps 或测试面试，还是希望提高 Git 技能，此资源都可以通过深入研究一些与 Git 基本概念和实践相关的最常见面试问题来帮助您。\n我们将涵盖所有重要主题，例如分支、存储库管理、处理合并冲突和协作工作流程。通过探索这些问题，您将更深入地了解 Git 的版本控制系统，并更好地应对开发项目中的现实挑战。\n1.什么是版本控制系统？ 版本控制系统 (VCS) 是一种帮助跟踪和管理文件和代码随时间变化的软件。它允许多人协作处理一个项目，跟踪修订，并在需要时轻松恢复到以前的版本。\n版本控制系统主要分为三种类型：\n本地版本控制系统 (LVCS)：在 LVCS 中，版本控制数据库存储在本地计算机上。更改和修订在位于用户计算机上的本地存储库中进行跟踪。但此类系统缺乏协作功能，不利于团队开发。 集中版本控制系统 (CVCS)：在 CVCS 中，版本控制数据库存储在中央服务器上。用户可以从服务器检出文件、进行更改并将其提交回服务器。这允许多个用户在同一项目上进行协作，并提供对存储库的集中控制。然而，CVCS 的一个缺点是，如果中央服务器出现故障，协作者将无法执行某些操作，直到服务器恢复为止。 分布式版本控制系统 (DVCS)：在 DVCS 中，每个用户都有一个包含整个版本历史记录的本地存储库。这意味着每个用户都拥有项目存储库的完整副本，包括所有分支和修订。用户可以在本地存储库上独立工作，并与其他存储库同步更改。 DVCS 为分布式和分散式工作流程提供更好的支持，允许用户离线工作并更有效地协作。 2. Git 中的 Origin 是什么？ 在 Git 中，“origin”是指我们从中克隆的远程存储库。当我们从远程服务器克隆存储库时，Git 会自动创建一个名为“origin”的远程引用，该引用指向原始远程存储库。\n默认情况下，当我们克隆存储库时，Git 会设置“来源”并将其与我们克隆的原始存储库关联起来。我们可以通过运行命令“git remote -v”来验证这一点。此命令显示与本地存储库关联的远程存储库列表及其 URL。\ngit remote -v origin https://github.com/lokeshgupta1981/Spring-Boot3-Demos.git (fetch) origin https://github.com/lokeshgupta1981/Spring-Boot3-Demos.git (push) 请注意，“origin”只是一个未硬编码的别名，可以使用以下命令提示符进行更改：\ngit remote rename origin newName 3.我们如何在 Git 中配置全局用户名和电子邮件？ 设置全局一致的用户名和电子邮件地址非常重要，因为 Git 使用此信息将提交与正确的作者关联起来。它有助于识别每个提交的人员，并允许在项目内进行适当的协作和归属。\n要在 Git 中配置全局用户名和电子邮件，我们可以使用以下命令：\ngit config --global user.name \u0026#34;MyName\u0026#34; git config --global user.email \u0026#34;myname@gmail.com\u0026#34; 这些命令将全局设置用户名和电子邮件，这意味着它们将用于您计算机上的所有 Git 存储库，除非在存储库级别覆盖。\n您可以通过运行以下命令来验证更改。这些命令将分别显示配置的用户名和电子邮件。\ngit config --global user.name # Prints \u0026#39;lokeshgupta1981\u0026#39; git config --global user.email # Prints \u0026#39;howtodoinjava@gmail.com\u0026#39; 4. Git 中的“暂存区”是什么意思？ Git 中的“暂存区域”也称为“索引”，是一个中间区域，在将文件提交到 Git 存储库之前，在此区域准备对文件的更改。\n当我们对项目文件进行更改时，Git 提供了一个两步过程来提交这些更改。暂存区域充当工作目录（进行修改的位置）和存储库（存储提交的位置 =\u0026gt; .git 文件夹）之间的桥梁。\n通过使用暂存区，我们可以将不相关的更改分离到多个提交中，或者有选择地包含特定修改而排除其他修改。它提供了一个在变更成为项目历史的一部分之前审查和完善我们的变更的机会。\n5. Git 中的分叉、分支和克隆之间的区别？ 分叉、分支和克隆都是 Git 操作，在版本控制工作流程中具有不同的用途。在深入研究之前，让我们先对它们进行比较。\n以下是 Git 中分叉、分支和克隆的表格比较：\n特征 分叉 分枝 克隆 目的 在您的 GitHub 帐户上创建远程存储库的副本。 在 Git 存储库中创建单独的开发线。 在您的计算机上创建 Git 存储库的本地副本。 所有权 创建一个由您拥有的完全独立的存储库。 在同一存储库中，分支归原始存储库所有。 本地副本；所有权没有变化。 起源 源自远程存储库，通常位于 GitHub 上。 源自现有的本地或远程存储库。 源自现有的远程或本地存储库。 改变可见性 在创建拉取请求之前，在分叉中所做的更改独立于原始存储库。 在分支中所做的更改将被隔离，直到您将它们合并回主分支。 在将更改推送到远程存储库之前，更改都是本地的。 用例 通常用于为开源项目做出贡献或创建单独的副本供个人使用。 用于协作环境中的功能开发、错误修复和隔离更改。 用于处理存储库的本地副本，通常用于个人开发。 分叉 分叉是一个与远程存储库相关的概念，特别是在 GitHub、GitLab 和 Bitbucket 等平台上。分叉在我们自己的帐户中创建原始存储库的副本。\n要在 GitHub（或类似平台）上分叉存储库，通常在存储库页面上有一个“分叉”按钮。单击此按钮将在您的 GitHub 帐户中创建原始存储库的分支。\n当我们想要为开源项目做出贡献或创建我们自己的独立项目版本时，通常会使用分叉。分叉存储库与原始存储库分开，允许我们进行更改、实验和提交拉取请求，而不会影响原始项目。\n分枝 分支允许在存储库中创建单独的开发线。它使我们能够彼此独立地处理不同的功能、错误修复或实验。\n要在 Git 中创建分支，我们使用以下命令：\ngit branch \u0026lt;branch_name\u0026gt; 通过创建分支，我们实质上创建了一个新的时间线，我们可以在不影响主分支（通常称为“master”或“main”）的情况下进行更改。一旦我们对分支中所做的更改感到满意，我们就可以将分支合并回主分支以合并更改。\n分支是协作开发的强大工具，使多个开发人员能够同时处理不同的任务，同时保持干净且有组织的提交历史记录。\n克隆 克隆创建远程存储库的本地副本。当我们克隆存储库时，我们会将整个项目的历史记录、文件和分支下载到本地计算机。\n要将远程存储库克隆到本地计算机，我们使用以下命令：\ngit clone \u0026lt;repository_url\u0026gt; 克隆在本地存储库和远程存储库之间建立连接，使我们能够获取更新、推送更改以及与其他人协作。当我们想要开始使用现有存储库时，通常会进行克隆。\n6. 什么是 Git Stash？ 在 Git 中，“存储”功能允许我们临时保存对工作目录所做的更改，而无需提交它们。它提供了一种存储我们的修改并切换到不同分支或应用其他操作的方法，而无需提交不完整或实验性更改。\n存储存储在本地，不会推送到远程存储库，这使得它们适合个人工作流程组织和实验。\ngit stash 命令用于创建和管理存储。以下是与 Git stash 相关的一些常见用例和命令：\nCreating a stash git stash save \u0026#34;Stash message\u0026#34; 此命令将我们的修改保存在新的存储中，并带有描述存储的可选消息。 Git 将从我们的工作目录中恢复更改，使其保持干净。\nViewing stashes git stash list 此命令显示您已创建的存储的列表，以及它们的存储引用和消息。\nApplying a stash git stash apply stash@{n} // n in [0.....P] 此命令将特定存储中的更改应用到当前分支。 stash@{n} 指的是列表中的存储引用。默认情况下，它适用于最新的存储。\nApplying and removing a stash git stash pop stash@{n} 此命令应用特定存储中的更改，并一步将其从存储列表中删除。它相当于应用存储然后使用 git stash drop 将其删除。\nApplying a stash to a different branch git stash branch branch-name stash@{n} 此命令创建一个新分支 ( new-branch-name ) 并将特定存储中的更改应用到该分支。这是切换到新分支并一步应用隐藏的更改的便捷方法。\nDiscarding a stash git stash drop stash@{n} 此命令从存储列表中删除特定存储，而不应用其更改。\n当我们正在处理某件事但需要切换到不同的任务或分支时，Git stash 非常有用。它允许我们暂时保存更改、切换上下文，然后返回到保存的状态以继续我们上次中断的地方。\n7. ‘git fetch’ 和 ‘git pull’ 有什么区别？ git fetch 和 git pull 都用于从远程存储库获取更改并将其合并到本地存储库中。然而，它们在处理获取的更改和更新本地分支的方式上有所不同。\n以下是 git fetch 和 git pull 之间的主要区别：\ngit fetch git 获取 从远程存储库检索最新更改，包括新分支、提交和标签，而不自动将它们合并到当前分支中。 更新远程跟踪分支（例如 origin/master ）以反映远程存储库的状态。 不修改您的本地分支或工作目录。 允许我们在手动合并之前检查和审查获取的更改，从而提供决定如何集成更改的机会。 要从远程存储库获取最新更改，我们使用以下命令：\ngit fetch origin git pull 执行 git fetch ，然后将获取的更改自动合并到当前分支中。 更新远程跟踪分支和本地分支，合并获取的更改。 如果当前分支有本地修改， git pull 会尝试自动合并更改。如果存在冲突，则需要手动解决。 自动更新您的工作目录以反映合并的更改。 要从远程存储库中提取最新更改，我们使用以下命令：\ngit pull git fetch 和 git pull 之间的选择取决于我们的工作流程以及我们想要对集成更改进行控制的级别。\n如果我们想在合并之前查看更改并对集成过程有更多的控制， git fetch 是合适的。 如果我们更喜欢更自动化的方法并且对自动合并更改有信心， git pull 可能会更方便。 8. 解释一下 Git checkout、rebase 和 merge？ 这是 Git 中的三个重要命令，用于管理分支并将更改从一个分支合并到另一个分支。\ngit 命令 目的 常见用例 checkout 切换到不同的分支或提交，使其成为当前工作分支/提交。 – 分支的创建和切换 - 检查特定提交以进行检查或测试 rebase 将更改从一个分支重新应用到另一分支。通常用于维护线性提交历史记录。 – 将功能分支集成到主分支中 – 维护干净、线性的提交历史记录 merge 将一个分支的更改合并到另一个分支。保留提交，创建合并提交。 – 将功能分支集成到主分支中 – 合并多个贡献者的更改 让我们逐一解释一下：\ngit checkout git checkout 用于在项目的不同分支或版本之间切换。\n要切换到另一个分支，我们使用以下命令：\ngit checkout \u0026lt;branch-name\u0026gt; 当您运行 git checkout \u0026lt;branch-name\u0026gt; 时，它会更新您的工作目录以匹配指定分支的内容。 您还可以使用 git checkout 切换到特定的提交或标记，从而允许您查看历史记录中特定状态的项目。 此外， git checkout -b \u0026lt;new-branch-name\u0026gt; 创建一个新分支并在单个命令中切换到它。 git rebase git rebase 用于将一个分支的更改集成到另一个分支，通常用于将功能分支的更改合并到主分支中。\n假设我们有两个分支：源分支（我们称之为“feature”）和目标分支（通常是“master”或“main”）。 “feature”分支包含一些更改，我们希望将这些更改合并到“master”分支中。但是，我们不想执行标准合并，因为我们想维护线性提交历史记录。\n首先，您需要确保您位于目标分支（git checkout master）。在这种情况下，它将是 master，然后，启动 rebase 命令，指定要 rebase 到当前分支（目标分支）的源分支。\ngit rebase feature 当您运行 git rebase \u0026lt;target-branch\u0026gt; 时，Git 会识别当前分支和目标分支的共同祖先，然后将当前分支的提交重新应用到目标分支之上。 Rebase 通过按顺序放置提交来允许线性历史记录，使其看起来好像更改是直接在目标分支之上进行的。 这可以帮助维护干净的提交历史记录，特别是在处理长期存在的功能分支时。 git merge git merge 将不同分支的更改合并到当前分支中。\n要将分支的更改合并到目标分支，我们使用以下命令（在 git checkout 之后）：\ngit merge \u0026lt;source-branch\u0026gt; 当您运行 git merge \u0026lt;source-branch\u0026gt; 时，Git 会创建一个新的提交，将源分支中的更改合并到当前分支中。 合并提交保留了两个分支的历史记录，包括它们分歧的点。 默认情况下，如果可能，Git 会执行“快进”合并，这意味着它将当前分支指针向前移动到源分支的提交，而不创建额外的合并提交。 但是，如果由于不同的更改而无法进行快进合并，Git 会执行“递归”或“非快进”合并，创建一个新的合并提交。 9. “gitcherry-pick”命令的用途是什么？ “gitcherry-pick”命令用于将特定提交从一个分支应用到另一个分支。它允许我们选择单独的提交并将它们应用到不同的分支，将它们的更改合并到目标分支中。\n以下是我们如何使用 git cherry-pick 命令：\n识别提交：确定要应用于另一个分支的提交。您可以找到提交哈希或使用其他 Git 命令（例如 git log 或 gitk ）来可视化提交历史记录。 切换到目标分支：确保您位于要应用所选提交的分支上。您可以使用 git checkout 切换到目标分支。 运行 git cherry-pick ：执行 git cherry-pick 命令，后跟要应用的提交的提交哈希值。例如： git cherry-pick \u0026lt;commit-hash\u0026gt; 需要注意的是， git cherry-pick 会复制选定的提交并将它们作为新提交应用到目标分支上。这意味着新提交将具有不同的提交哈希值，因为它们是单独的副本，而不是原始提交的直接传输。\n10. 解释 Git 重置和恢复 在 Git 中，重置和恢复是撤消更改的两种不同方法。它们用于纠正错误、撤消提交或将存储库恢复到以前的状态。\nAction Git Reset Git Revert 目的 将 HEAD 和分支指针移动到指定的提交。 创建一个新的提交来撤消特定提交所做的更改。 常见用例 – 在推送到远程存储库之前在本地撤消提交 – 重组提交历史 – 从暂存区删除更改 – 安全撤消提交而不更改提交历史记录 – 协作代码修正 git reset git reset 将当前分支指针移动到特定提交，从而有效地将分支重置为该提交。\n#Let\u0026#39;s say we have a commit history like this: A - B - C - D (master) #To Perform a hard reset to move the branch pointer to commit B, discarding changes in C and D. git reset --hard B 复位命令有三种模式：软复位、混合复位和硬复位。\n软重置 ( git reset --soft ) 将分支指针移动到指定的提交，同时保持暂存区域和工作目录中的更改不变。它允许您“撤消”提交并根据先前的状态进行其他修改。 混合重置（默认行为， git reset --mixed ）将分支指针移动到指定的提交，重置暂存区域，但保留工作目录中的更改。它“取消暂存”更改，允许您在提交之前修改并再次暂存它们。 硬重置 ( git reset --hard ) 将分支指针移动到指定的提交，丢弃暂存区域和工作目录中的任何更改。它完全删除更改，将分支和整个存储库恢复到指定提交的状态。 git revert git revert 创建一个新的提交，撤消先前提交中所做的更改。它提供了一种安全的方式来撤消提交而不更改提交历史记录。\ngit revert C # This command will Create a new commit that undoes the changes in commit C. git revert 创建新的提交来反转指定提交引入的更改，而不是修改或删除现有提交。每个恢复提交都专门用于撤消特定提交的更改，确保提交历史记录保持完整。\n11.“.gitignore”文件的用途是什么？ .gitignore 文件指定不应提交到存储库的有意未跟踪的文件和目录。它允许我们定义 Git 在跟踪更改和暂存文件时应忽略的文件和目录名称模式。\n使用“.gitignore”文件的一些常见用例和好处包括：\n忽略构建工件，例如编译的二进制文件、目标文件、日志文件或临时文件。 忽略单独管理的依赖项或库。在存储库中包含这些依赖项是不必要的，并且可能会导致存储库臃肿。 忽略包含 API 密钥、数据库凭据或特定于环境的设置等敏感信息的配置文件。 忽略与其他团队成员无关的个人开发环境文件，例如项目设置、编辑器备份文件或缓存文件。 以下是包含 3 个条目的 .gitignore 文件的示例：\n# Ignore build artifacts *.exe *.o *.log # Ignore dependency directories /node_modules /vendor # Ignore sensitive configuration files config.ini secrets.json 12. Git reflog 和 log 有什么区别？ git log 主要用于查看特定分支或提交的提交历史记录，而 git reflog 更专注于跟踪整个存储库中的引用移动，这使得它对于恢复和提交特别有用。调试目的。\n方面 git log git reflog 目的 显示分支的提交历史记录。 显示存储库的参考日志。 常见用例 – 回顾项目历史 –检查提交消息和随时间所做的更改。 –恢复丢失的提交或分支 – 调试和了解存储库中的更改。 git log git log 命令提供存储库中按时间顺序提交的列表，显示提交哈希、作者、日期和提交消息等详细信息。默认情况下，它显示当前分支的提交历史记录，从最近的提交开始并按时间倒退。各种选项和标志允许自定义，例如按作者、日期范围或分支进行过滤。\n# To see the commit history for the current branch git log 要以紧凑的一行格式显示提交历史记录，我们使用以下命令：\ngit log --oneline git reflog 另一方面， git reflog 给出了引用（分支或标签）更新和修改提交指针的其他操作的详细日志。\n# To view the reflog for the repository git reflog 与 git log 不同，引用日志记录影响提交历史记录的分支移动和操作，即使不创建新的提交也是如此。它是恢复丢失的提交或可能被意外删除或移动的分支的宝贵工具，在发生错误或不可预见的事件时充当安全网。\n13.“git bisect”命令的用途是什么？ git bisect 命令通过提交历史记录执行二分搜索，以识别引入错误或导致回归的特定提交。它通过有效地缩小要调查的提交范围，有助于隔离和查明负责特定问题的提交。\n以下是 git bisect 工作原理的概述：\n识别已知的好的和坏的提交：首先识别项目历史记录中的两个提交：一个代表已知的良好状态（不存在错误或问题的提交），另一个代表已知的坏状态（不存在 bug 或问题的提交）存在错误或问题）。 开始二等分过程：使用 git bisect start 开始二等分过程。使用 git bisect good \u0026lt;commit\u0026gt; 指定已知良好状态的提交哈希，使用 git bisect bad \u0026lt;commit\u0026gt; 指定已知不良状态的提交哈希。 Git 将在已知的好状态和坏状态之间创建一系列提交。 git bisect start git bisect good \u0026lt;good_commit_hash\u0026gt; git bisect bad \u0026lt;bad_commit_hash\u0026gt; 14. 我们如何在 Git 中将多个提交压缩为单个提交？ 为了在 Git 中将多个提交压缩为单个提交，我们可以使用交互式变基功能。确保我们位于包含我们想要压缩的提交的分支上。\n运行以下命令启动交互式变基：\ngit rebase -i HEAD~n 将 n 替换为我们想要压缩的提交数。例如，如果我们想压缩最后 3 次提交，请使用 HEAD~3 。\n将打开一个交互式文本编辑器，显示我们在上一步中指定的提交列表。每个提交前面都会有“pick”一词。\n要压缩提交，请将除第一个提交之外的所有提交的“pick”更改为“squash”（或“s”）。将第一个提交保留为“pick”，因为它将是生成的提交消息。如果需要，您还可以通过移动文本编辑器中的行来重新排列提交的顺序。\n保存并退出文本编辑器。 将打开另一个文本编辑器，允许您修改提交消息。您可以合并压缩提交的提交消息或写入新消息。根据需要编辑消息，保存并退出编辑器。 Git 将执行变基，将提交压缩为单个提交。 如果变基成功，您将看到一条消息，表明变基已完成。 如果存在任何冲突，Git 将停止 rebase 过程并允许我们解决它们。解决冲突后，使用 git rebase --continue 继续变基过程。 如有必要，将更改推送到远程存储库。 警告：压缩提交时要小心，因为它会重写历史。如果提交已经被推送到共享存储库并且其他人已经基于这些提交进行了工作，通常不建议压缩它们，因为这可能会导致其他团队成员发生冲突。\n15、如何判断某个分支是否已经合并到 Master 中？ 要识别某个分支是否已合并到 Git 中的 master 分支中，我们可以运行以下命令：\ngit checkout master 然后运行以下命令，将 \u0026lt;branch_name\u0026gt; 替换为我们要检查的分支名称：\ngit branch --merged \u0026lt;branch_name\u0026gt; 如果分支已合并到 master 中，它将出现在运行此命令后显示的分支列表中。 如果分支尚未合并到 master 中，它将不会出现在合并分支列表中。 或者，我们可以使用以下命令来查看合并分支的简明视图：\ngit branch --merged 此命令将列出已合并到当前分支的所有分支，在本例中为 master 。\n16. 什么是 Git 存储库？如何初始化 Git 存储库？ Git 存储库是 Git 跟踪和管理一组文件和目录更改的存储位置。它包含对文件所做的所有更改的完整历史记录，使我们能够跟踪和恢复更改、与其他人协作以及维护项目的不同版本。\n要初始化目录中的 Git 存储库，我们可以使用 git init 命令。我们是这样做的：\ncd /path/to/your/local-repo-path git init 此命令在当前目录中初始化一个空的 Git 存储库。 Git 创建一个隐藏的 .git 目录，其中存储所有存储库数据，包括提交历史记录和配置。\n17. 如何显示版本库的当前状态，包括修改的文件和分支信息？ 要显示存储库的当前状态，包括修改的文件和分支信息，我们可以使用 git status 命令。\ngit status # Sample Output Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: spring-boot-actuator-example/pom.xml modified: spring-boot-actuator-example/src/main/java/com/howtodoinjava/demo/SimpleRestController.java modified: spring-boot-actuator-example/src/main/resources/application.properties modified: spring-webflux-demo/src/test/java/com/howtodoinjava/demo/EmployeeControllerTest.java no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 此命令将显示我们的存储库当前状态的摘要。它将向我们显示以下信息：\n我们当前所在的分支。 未跟踪的文件（Git 当前未跟踪的文件）。 已修改的文件（已修改但未暂存的文件）。 暂存文件（已修改并暂存以供下一次提交的文件）。 分支状态（例如，“您的分支已更新为‘origin/master’”）。 18. 如何连接本地仓库到远程仓库？ 要将本地存储库连接到远程存储库，我们需要将远程 URL 添加到本地 Git 存储库。此远程 URL 指向我们要存储和同步代码的远程存储库的位置（例如，在 GitHub、GitLab 或 Bitbucket 上）。\ngit remote add origin \u0026lt;remote_url\u0026gt; 此命令添加一个名为“origin”的远程（如果愿意，我们可以选择不同的名称）并将其与指定的远程 URL 关联。\n19. 如何列出已有的分行？如何创建新分支？ 要列出现有分支，我们可以使用“gitbranch”命令。它显示存储库中所有分支的列表，并突出显示当前分支。\ngit branch 要创建新分支，我们可以使用以下命令：\ngit branch \u0026lt;branch-name\u0026gt; 20. 如何切换到特定分支？ 我们可以使用以下命令切换到特定分支：\ngit checkout \u0026lt;branch-name\u0026gt; 21. 如何将不同分支的更改合并到当前分支？ 确保我们位于要合并更改的分支（例如 main 分支）后，使用 merge 命令将指定分支的更改合并到当前分支。\ngit checkout \u0026lt; main-branch \u0026gt; git merge \u0026lt;branch-name\u0026gt; 22.如何删除 Git 中的分支？ 要删除分支，我们可以传递 -d 标志。\ngit branch -d \u0026lt;branch-name\u0026gt; 23. 如何将文件添加到暂存区？ 要将文件添加到暂存区，我们使用 git add 命令：\ngit add \u0026lt;file\u0026gt; 为了轻松地将所有文件添加到暂存区域，我们可以使用“.”。而不是特定的文件：\ngit add . 24. 如何使用描述性消息在暂存区提交更改？ 将文件添加到暂存区域后，我们可以使用以下命令提交更改：\ngit commit -m \u0026#34;message\u0026#34;. 将“消息”替换为总结更改的描述性消息。\n25. 如何将提交的更改推送到远程存储库？ 要将提交的更改推送到远程存储库，我们使用以下命令：\ngit push \u0026lt;remote-name\u0026gt; \u0026lt;branch-name\u0026gt; 26. 如何撤消 Git 中的最后一次提交？ 要撤消最后一次提交，同时将更改保留为未提交的修改，我们可以使用以下命令：\ngit reset HEAD~1 这会将 HEAD 指针向后移动一次提交。更改仍将在您的工作目录中，允许我们修改它们或进行新的提交。\n27. 什么是合并冲突，如何解决？ 当 Git 由于同一行代码上的修改冲突而无法自动合并来自不同分支的更改时，就会发生合并冲突。\n要解决合并冲突，我们需要手动编辑冲突文件，以选择所需的更改。解决冲突后，我们可以添加并提交更改以完成合并。\n28. 如何从远程存储库中提取更改？ 要从 Git 中的远程存储库提取更改，我们可以使用 git pull 命令。 git pull 命令从远程存储库获取最新更改并将它们合并到我们的本地分支中。\ngit pull origin \u0026lt;branch-name\u0026gt; 例如，如果我们想从 master 分支中提取更改，我们可以使用 git pull origin master 。如果我们克隆存储库，默认远程名称通常为 origin ，但如果您自定义它，它可能会有所不同。\n如果有任何冲突，Git 会通知我们，我们需要手动解决冲突。如果合并成功，我们的本地分支将使用远程存储库中的最新更改进行更新。\n在拉取更改之前，建议提交或存储本地更改以避免冲突。如果您有未提交的更改，Git 可能会拒绝拉取，直到您提交或存储它们。\n29. 如何显示两次提交之间的差异？ 要显示两个 Git 提交之间的差异，可以使用以下命令：\ngit diff \u0026lt;commit1\u0026gt; \u0026lt;commit2\u0026gt; 30. 如何在 Git 中恢复提交？ 要恢复提交并创建一个撤消更改的新提交，我们可以使用以下命令：\ngit revert \u0026lt;commit-hash\u0026gt; 将 替换为您要恢复的提交哈希。 Git 将创建一个新的提交来撤消在指定提交中所做的更改。\n31.如何查看 Git 中的提交历史记录？ Git 中的每个分支都维护自己的提交历史记录。要访问和查看与特定分支关联的提交，我们可以使用以下命令：\ngit log branch-name 以下是使用“git log”的不同场景：\n不指定分支名称：“git log”显示当前签出的分支的提交历史记录。如果没有签出分支，它会显示整个存储库的提交历史记录。 使用特定分支名称：“git log ”显示指定分支的提交历史记录，包括其父分支共享的任何提交。 32. 如何取消暂存文件？ 要在 Git 中取消暂存文件，我们可以使用以下命令：\ngit reset HEAD -- path/to/file 与递归使用“git add”类似，您可以按目录取消暂存文件或执行批量取消暂存操作。要立即取消所有内容，请从存储库的根目录运行以下命令：\ngit reset HEAD -- . 33. 如何从远程存储库中删除文件？ 要从远程存储库中删除文件，可以使用以下命令：\ngit rm \u0026lt;file\u0026gt; 这将从工作目录和 Git 存储库中删除该文件。删除文件后，您需要提交并推送更改以更新远程存储库。\n结论 总之，这份关于常见 Git 面试问题和答案的综合指南对 Git 版本控制系统中的基本概念和实践进行了彻底的探索。\n通过深入研究存储库管理、分支、合并、解决冲突和协作工作流程等主题，您可以对 Git 的关键方面有深入的了解。\n快乐学习！\n原文链接：Git Interview Questions for DevOps and Testers ","permalink":"https://blog.chensoul.cc/posts/2023/10/12/git-interview-questions/","summary":"欢迎来到 Git 面试准备指南，我们将在这里向初学者和经验丰富的专业人士讨论最常见的 Git 面试问题。无论您是准备参加 DevOps 或测试面试，还是希望提高 Git 技能，此资源都可以通过深入研究一些与 Git 基本概念和实践相关的最常见面试问题来帮助您。\n我们将涵盖所有重要主题，例如分支、存储库管理、处理合并冲突和协作工作流程。通过探索这些问题，您将更深入地了解 Git 的版本控制系统，并更好地应对开发项目中的现实挑战。\n1.什么是版本控制系统？ 版本控制系统 (VCS) 是一种帮助跟踪和管理文件和代码随时间变化的软件。它允许多人协作处理一个项目，跟踪修订，并在需要时轻松恢复到以前的版本。\n版本控制系统主要分为三种类型：\n本地版本控制系统 (LVCS)：在 LVCS 中，版本控制数据库存储在本地计算机上。更改和修订在位于用户计算机上的本地存储库中进行跟踪。但此类系统缺乏协作功能，不利于团队开发。 集中版本控制系统 (CVCS)：在 CVCS 中，版本控制数据库存储在中央服务器上。用户可以从服务器检出文件、进行更改并将其提交回服务器。这允许多个用户在同一项目上进行协作，并提供对存储库的集中控制。然而，CVCS 的一个缺点是，如果中央服务器出现故障，协作者将无法执行某些操作，直到服务器恢复为止。 分布式版本控制系统 (DVCS)：在 DVCS 中，每个用户都有一个包含整个版本历史记录的本地存储库。这意味着每个用户都拥有项目存储库的完整副本，包括所有分支和修订。用户可以在本地存储库上独立工作，并与其他存储库同步更改。 DVCS 为分布式和分散式工作流程提供更好的支持，允许用户离线工作并更有效地协作。 2. Git 中的 Origin 是什么？ 在 Git 中，“origin”是指我们从中克隆的远程存储库。当我们从远程服务器克隆存储库时，Git 会自动创建一个名为“origin”的远程引用，该引用指向原始远程存储库。\n默认情况下，当我们克隆存储库时，Git 会设置“来源”并将其与我们克隆的原始存储库关联起来。我们可以通过运行命令“git remote -v”来验证这一点。此命令显示与本地存储库关联的远程存储库列表及其 URL。\ngit remote -v origin https://github.com/lokeshgupta1981/Spring-Boot3-Demos.git (fetch) origin https://github.com/lokeshgupta1981/Spring-Boot3-Demos.git (push) 请注意，“origin”只是一个未硬编码的别名，可以使用以下命令提示符进行更改：\ngit remote rename origin newName 3.我们如何在 Git 中配置全局用户名和电子邮件？ 设置全局一致的用户名和电子邮件地址非常重要，因为 Git 使用此信息将提交与正确的作者关联起来。它有助于识别每个提交的人员，并允许在项目内进行适当的协作和归属。\n要在 Git 中配置全局用户名和电子邮件，我们可以使用以下命令：\ngit config --global user.name \u0026#34;MyName\u0026#34; git config --global user.email \u0026#34;myname@gmail.com\u0026#34; 这些命令将全局设置用户名和电子邮件，这意味着它们将用于您计算机上的所有 Git 存储库，除非在存储库级别覆盖。\n您可以通过运行以下命令来验证更改。这些命令将分别显示配置的用户名和电子邮件。\ngit config --global user.name # Prints \u0026#39;lokeshgupta1981\u0026#39; git config --global user.email # Prints \u0026#39;howtodoinjava@gmail.com\u0026#39; 4.","title":"[译]DevOps 和测试人员的 Git 面试问题"},{"content":"本面试准备指南将讨论一些常见的 Spring Security 面试问题。无论您是准备面试还是只是想增强对 Spring Security 的了解，这些问题都将帮助您理解关键概念并指导您设计常见安全问题的解决方案。\n1. Spring Security 的核心特性是什么？ Spring Security 提供的两个最突出的功能是身份验证和授权。这些功能在确保应用程序的安全性方面发挥着至关重要的作用。然而，Spring Security 超越了身份验证和授权，还提供了额外的功能来防止漏洞利用并与其他框架集成。\n1.1.验证 身份验证是验证尝试访问应用程序的用户身份的过程。 Spring Security 提供多种身份验证方法（基于表单的身份验证、HTTP 基本身份验证、OAuth2、Siteminder、OpenID Connect、LDAP、JDBC 等），允许应用程序使用各种方法对用户进行身份验证。\n它还支持自定义，当默认选项不满足要求时，可以实现自定义的身份验证机制。\n1.2.授权 授权是向经过身份验证的用户或实体授予许可或权利的过程。用户或实体成功通过身份验证后，授权将决定他们可以在应用程序中访问哪些操作或资源。 Spring Security 为开发人员提供了多种方法来实现授权并控制用户对应用程序不同部分的访问。以下是一些常见的方法：\n基于 Web URL 的授权：可以根据特定的 URL 或 URL 模式实施访问控制，规范哪些用户可以访问某些资源。 方法级授权：如果需要，甚至可以对 Java Bean 中的方法进行访问控制，从而在方法级提供细粒度的授权。 域实例级授权：Spring Security 提供了控制对特定域实例的访问的能力，允许基于某些实体的所有权或关联进行授权。 1.3.防止漏洞利用 Spring Security 提供了多种功能来防范常见的 Web 应用程序安全漏洞。一些显着的功能包括：\n跨站请求伪造 (CSRF) 保护：Spring Security 会自动将 CSRF 令牌添加到表单和 AJAX 请求中，从而防止 CSRF 攻击。 跨站脚本 (XSS) 保护：Spring Security 支持输出编码，并提供实用程序通过清理用户输入来防止 XSS 攻击。 点击劫持保护：Spring Security 包括 X-Frame-Options 支持，以防止点击劫持攻击。 1.4.集成 Spring Security 与其他框架和库无缝集成，以增强应用程序的安全性。一些关键的集成是：\nSpring MVC：Spring Security 与 Spring MVC 集成，为 Web 应用程序提供无缝的安全功能。它可以安全地处理请求、身份验证、授权并防止常见的 Web 漏洞。 Spring Data：Spring Security 与 Spring Data 集成，以便在查询中引用当前用户。这种集成确保可以根据身份验证和授权规则轻松访问和过滤用户特定的数据。 Jackson：Jackson 的支持可以实现 Spring Security 相关类的高效序列化和反序列化，特别是在使用分布式会话或 Spring Session 等框架时，从而提高效率和可扩展性。 密码学：Spring Security 与各种密码库和算法集成，以提供敏感信息的安全存储和传输。这种集成包括密码散列、加密和安全通信协议等功能，以保护数据的机密性和完整性。 有关 Spring Security 功能的更详细信息，请参阅官方文档。\n2.解释一下 Spring Security 的核心组件？ 当谈到 Spring Security 时，几个核心组件在为 Java 应用程序提供安全功能方面发挥着至关重要的作用。这些组件协同工作以确保强大的身份验证、授权和其他安全功能。\n2.1.委托过滤代理 DelegatingFilterProxy是 Spring 框架提供的一个特殊的 Servlet Filter。它充当处理安全相关请求的入口点。当收到请求时，DelegatingFilterProxy 将请求委托给 Spring FilterChainProxy bean 进行进一步处理（springSecurityFilterChain bean）。 FilterChainProxy 利用SecurityFilterChain 来确定为当前请求调用的适当的过滤器集。\n2.2.过滤器链代理 FilterChainProxy 根据传入请求的 URL 模式和定义的安全配置确定要应用哪些过滤器。它根据配置的安全规则评估请求并选择适当的过滤器链（使用@EnableWebSecurity， FilterChainProxy 自动创建为 bean。它包装实际的安全过滤器链并充当处理请求的委托）。\n2.3.安全过滤链 当收到请求时，FilterChainProxy 会找到相应的 SecurityFilterChain 并执行该链中的过滤器列表。每个过滤器根据应用程序的安全配置执行其指定的任务。过滤器可以修改请求、执行身份验证检查、验证权限或处理与会话相关的操作。\nSpring Security 中的一些重要安全过滤器包括：\nUsernamePasswordAuthenticationFilter：此过滤器通过拦截登录请求并根据用户提供的凭据对用户进行身份验证来处理基于表单的身份验证。 BasicAuthenticationFilter：此过滤器处理基本身份验证，用户在 HTTP 标头中以用户名和密码的形式提供凭据。 RememberMeAuthenticationFilter：此过滤器启用 Remember-Me 功能，允许用户使用存储在 cookie 中的持久令牌自动登录。 LogoutFilter：此过滤器处理注销过程、使用户会话无效、清除身份验证详细信息以及执行其他操作（例如重定向到特定注销页面）。 ExceptionTranslationFilter：此过滤器捕获请求处理期间引发的任何身份验证或访问相关的异常，并将其转换为有意义的响应，例如重定向到登录页面或返回禁止的响应。 一旦请求到达SecurityFilterChain内注册的过滤器，相应的过滤器就会将请求委托给其他 bean 来执行相应的任务。例如，AuthenticationProcessingFilter 准备 Authentication 实例并将其委托给 AuthenticationManager 进行身份验证流程。\n2.4.认证管理器 AuthenticationManager 负责对用户进行身份验证。它有一个名为 authenticate () 的方法，该方法将 Authentication 实例作为参数。 authenticate () 方法负责验证所提供的凭据（在 AuthenticationProvider 的适当实现的帮助下），并在身份验证成功时返回经过身份验证的 Authentication 对象。\n默认情况下，Spring Security 提供了一个名为 ProviderManager 的 AuthenticationManager 接口的实现。 ProviderManager 将身份验证过程委托给 AuthenticationProvider 实例列表。\n2.5.认证提供者 AuthenticationProvider 负责验证特定类型的凭证或身份验证机制。它定义了针对特定源（例如用户数据库、外部身份验证服务或任何其他自定义身份验证机制）执行身份验证的合同。\n当应用程序中使用多种身份验证机制时，可以配置多个 AuthenticationProvider 实例来单独处理每种机制。\n更多信息请参考官方文档。\n3. Spring Security 如何处理用户认证？ 在较高级别上，Spring Security 通过一系列步骤处理用户身份验证。大多数步骤对于各种身份验证都是通用的，但很少有身份验证流程需要特定步骤。\n以下步骤演示了基于表单登录的身份验证，其中用户在请求中输入用户名/密码组合。\n用户尝试访问受保护的资源或发起登录请求，该请求被 Spring Security 拦截，并将我们重定向到登录页面。 身份验证过滤器 UsernamePasswordAuthenticationFilter 负责从请求中捕获用户的凭据（通常为每个对 /login 发出的请求调用 UsernamePasswordAuthenticationFilter ）。 UsernamePasswordAuthenticationFilter 提取用户名和密码并创建一个 Authentication 对象（来自 UsernamePasswordAuthenticationToken 的实例）。 然后将 Authentication 对象传递给 AuthenticationManager。 AuthenticationManager 将身份验证过程委托给一个或多个 AuthenticationProvider。 AuthenticationProvider 使用具有方法 loadUserByUsername(username) 的 UserDetailsS​​ervice bean 验证凭据。它返回包含用户数据的 UserDetails 对象。如果没有找到具有给定用户名的用户，则抛出 UsernameNotFoundException 。 如果身份验证成功，则将包含经过身份验证的用户信息的 Authentication 对象返回到 AuthenticationManager。 AuthenticationManager 将经过身份验证的 Authentication 对象存储在 SecurityContext 中。 安全上下文通常存储在线程局部变量中，使其可以在整个应用程序中访问。 用户经过身份验证后，Spring Security 允许用户访问请求的资源或继续执行请求的操作。 4. AuthenticationManager 如何确定合适的 AuthenticationProvider？ 在身份验证过程中，AuthenticationManager 接收代表用户凭据的 Authentication 对象。 AuthenticationManager 循环访问每个 AuthenticationProvider 并调用它们的 supports(Class\u0026lt;?\u0026gt; authentication) 方法来确定提供程序是否支持特定类型的 Authentication 对象。每个 AuthenticationProvider 都实现此方法，并且通常检查提供程序是否可以根据身份验证对象的类处理身份验证请求。\n这是 ProviderManager 源代码中的代码片段，它是 AuthenticationManager 的默认实现：\npublic Authentication authenticate(Authentication authentication) throws AuthenticationException { Class\u0026lt;? extends Authentication\u0026gt; toTest = authentication.getClass(); // ....... for (AuthenticationProvider provider : getProviders()) { if (!provider.supports(toTest)) { continue; } // ...... } 一旦找到支持给定身份验证对象的 AuthenticationProvider，AuthenticationManager 就会调用提供程序的 authenticate(Authentication authentication) 方法。此方法执行特定于该提供程序的身份验证逻辑，例如根据用户数据库或外部身份验证服务验证凭据。\n5. Spring Security 如何处理用户授权？ 在较高的层面上，Spring Security 通过一个涉及多个组件协同工作的过程来处理用户授权。\n以下是该过程的概述。\n一旦请求通过身份验证，就会进入授权阶段。 FilterChainProxy 调用过滤器链中适当的授权过滤器。 AuthorizationFilter 从 SecurityContextHolder 检索 Authentication 对象。然后，它将授权过程委托给 AuthorizationManager，后者负责根据配置的访问控制规则和权限做出最终的授权决策。 AuthorizationManager 取代 AccessDecisionManager 和 AccessDecisionVoter。 AuthorizationFilter 使用 Authentication 对象和 HTTP 请求构造Supplier 对象。然后将此供应商传递给RequestMatcherDelegatingAuthorizationManager 的 check () 方法，这是 Spring Security 使用的默认AuthorizationManager。 RequestMatcherDelegatingAuthorizationManager 根据配置的 RequestMatcher 实例评估提供的 Supplier ，以确定请求的资源是否与任何指定的访问控制规则匹配。 RequestMatcherDelegatingAuthorizationManager 的 check 方法返回一个 AuthorizationDecision 对象。如果授权决策是 false ，表示访问被拒绝，则会抛出异常（通常是 403 Access Denied 异常）。 另一方面，如果授权决策是 true ，表示授予访问权限，则过滤器链将继续执行，直到到达 DispatcherServlet。链中的每个过滤器执行其指定的任务，例如请求预处理、安全检查或任何其他自定义功能。 6.什么是密码编码器？默认编码器是什么？ PasswordEncoder 是一个用于使用 encode() 和 matches() 方法对密码进行编码和验证的接口。它负责获取用户的密码，应用单向哈希算法，并安全地存储哈希密码。当用户尝试登录时，输入的密码会使用相同的算法再次进行哈希处理，并将生成的哈希值与存储的哈希密码进行比较以进行身份 ​​ 验证。\n默认密码编码器是 BCryptPasswordEncoder。 BCrypt 是一种广泛使用的安全哈希算法，它结合了加盐和成本因素，以防止各种类型的攻击，包括暴力攻击。 BCryptPasswordEncoder 是密码存储的不错选择，因为它提供了高级别的安全性。\n@Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } 对于自定义要求，我们还可以配置自定义密码编码器。\n实现 PasswordEncoder 接口 创建一个实现 PasswordEncoder 接口的类。此类将提供编码和验证密码的实现。\npublic class CustomPasswordEncoder implements PasswordEncoder { @Override public String encode(CharSequence rawPassword) // Implement your password encoding logic here // Return the encoded password as a String } @Override public boolean matches(CharSequence rawPassword, String encodedPassword) { // Implement your password verification logic here // Compare the rawPassword with the encodedPassword and return true or false } } 配置自定义密码编码器 在 Spring Security 配置中，我们可以通过定义 PasswordEncoder bean 来指定自定义密码编码器的使用。 Spring Security 将使用这个 bean 进行密码编码和验证。\n@Configuration @EnableWebSecurity public class SecurityConfig { @Bean public PasswordEncoder passwordEncoder() { return new CustomPasswordEncoder(); } // Other security configuration code } 7. 如何在非 Spring boot 应用程序中启用 Spring 安全性？ 当谈到在非 Spring Boot 应用程序中启用 Spring Security 时，我们可以采取几种方法。让我们探讨两种标准方法：\n基于 Java 的配置 基于 XML 的配置 使用 AbstractSecurityWebApplicationInitializer 进行基于 Java 的配置 在 Java 配置中，我们可以通过扩展 AbstractSecurityWebApplicationInitializer 类并选择性地重写其方法来配置 DelegatingFilterProxy 并将其与 springSecurityFilterChain bean 关联来启用 Spring Security。它避免在 web.xml 文件中写入 servlet-filter 配置。\n我们可以在 SecurityConfig.java 中定义自定义安全 bean。\npublic class SpringSecurityInitializer extends AbstractSecurityWebApplicationInitializer { public SpringSecurityInitializer() { super(SecurityConfig.class); } } 基于 XML 的配置 在 XML 配置中，我们需要显式定义 DelegatingFilterProxy bean 并使用过滤器名称将其映射到 springSecurityFilterChain bean。此链接通常在 web.xml 文件中完成：\n\u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;springSecurityFilterChain\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.DelegatingFilterProxy\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;springSecurityFilterChain\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;dispatcher\u0026gt;ERROR\u0026lt;/dispatcher\u0026gt; \u0026lt;dispatcher\u0026gt;REQUEST\u0026lt;/dispatcher\u0026gt; \u0026lt;/filter-mapping\u0026gt; 8. 如何在 Spring boot 应用程序中启用 Spring 安全性？ 如果我们使用 Spring Boot，启用 Spring Security 就非常简单。我们需要做的就是将 Spring Security starter 添加到项目的依赖项中，默认情况下自动配置将可用。这是因为当 Spring Security 位于类路径中时，WebSecurityEnablerConfiguration 会自动为我们激活 @EnableWebSecurity 注解。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 9. Spring Security 中@EnableWebSecurity 的用途是什么？ @EnableWebSecurity 注解用于启用应用程序的 Web 安全性。当此注释添加到配置类时，表示该类将提供必要的配置和设置来保护 Web 应用程序。\n在非 Spring boot 应用程序中，@EnableWebSecurity 注释除了提供开发人员编写的自定义配置 bean 之外，还会隐式执行以下任务。\n创建 Spring Security 过滤器链：它初始化并配置负责处理传入请求和应用安全措施的过滤器链。 配置安全上下文：它设置用于处理身份验证和授权的安全上下文。安全上下文保存有关当前经过身份验证的用户及其授予的权限的信息。 在 Spring boot 应用程序中，使用 @EnableWebSecurity 注释是可选的。 Spring boot 安全自动配置提供了与使用@EnableWebSecurity 注释几乎相同的功能。\n当在 Spring boot 应用程序中使用 @EnableWebSecurity 时，默认的自动配置会后退，并提供的配置优先。\n@Configuration @EnableWebSecurity public class SecurityConfig { @Bean public WebSecurityCustomizer webSecurityCustomizer() { return (web) -\u0026gt; web.ignoring() .requestMatchers(\u0026#34;/resources/**\u0026#34;); } @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests() .requestMatchers(\u0026#34;/public/**\u0026#34;).permitAll() .anyRequest().hasRole(\u0026#34;USER\u0026#34;) .and() .formLogin().permitAll(); return http.build(); } // Possibly more bean methods ... } 10. Spring Security 中的角色和权限有什么区别？ 在 Spring Security 中，角色和权限都用于定义和管理用户权限。然而，两者之间有一个微妙的区别：\n角色：角色代表广泛的权限类别或权限组。它通常用于将相关权限分组在一起。可以将角色分配给用户，并且用户可以拥有多个角色。例如，角色可以是“管理员”、“用户”或“管理员”。角色通常用于高级访问控制决策。 权限：权限也称为权限或特权，表示用户可以拥有的特定权限。它定义了细粒度的访问控制级别。权限直接或通过角色授予用户。例如，权限可以是“READ_DATA”、“WRITE_DATA”或“DELETE_DATA”。权威机构用于精确的访问控制决策。 11.如何使用注解实现方法安全？ 除了 URL 级别的安全性之外，Spring Security 还支持方法级别的安全性。要在 Spring Security 中使用注解实现方法级安全性，我们可以使用@EnableMethodSecurity 注解任何@Configuration 类。\n@Configuration @EnableWebSecurity @EnableMethodSecurity public class SecurityConfig { //.. } 现在我们可以通过@Secured、@PreAuthorize、@PostAuthorize、@PreFilter 和@PostFilter 注解来授权方法调用，包括输入参数和返回值。\n在以下示例中， deleteProduct 方法使用 @PreAuthorize 注释进行保护，表达式 hasRole('ADMIN') 确保只有具有“ADMIN”角色的用户才能调用此方法。\n@PreAuthorize(\u0026#34;hasRole(\u0026#39;ADMIN\u0026#39;)\u0026#34;) public void deleteProduct(Long productId) { // Method logic for deleting a product } 默认情况下，Spring boot 中方法安全性是禁用的。\n12.什么是基本身份验证？如何实施？ 基本身份验证是一种简单的身份验证机制，其中客户端在每个请求的 HTTP 标头中包含用户名和密码（凭据以“ username:password ”格式发送，然后在包含之前进行 Base64 编码在 Authorization 标头中）。然后，服务器验证凭据，如果正确，则授予对所请求资源的访问权限。\n为了在 Spring Security 中启用基本身份验证，我们使用 *httpBasic*() 方法。\n@Bean public SecurityFilterChain securityFilterChain (HttpSecurity http) throws Exception { http.authorizeHttpRequests() .anyRequest().authenticated() .and() .httpBasic(); return http.build(); } 13.什么是 JWT 认证？如何实施？ JWT（JSON Web Token）身份验证是一种流行的身份验证机制，它使用基于 JSON 的令牌在各方之间安全地传输身份验证和授权信息。它支持无状态身份验证，并且无需在服务器端存储会话。\n要在 Spring Security 中实现 JWT 身份验证，我们可以按照以下步骤操作：\n包含必要的依赖项： spring-security-jwt 和用于 JWT 处理的库（例如 jjwt ）。 实现 JWT 令牌提供程序：创建一个负责生成 JWT 令牌的类。此类应包含用于创建和签署 JWT、设置声明以及指定过期时间的方法。 实现 JWT 身份验证过滤器：创建自定义过滤器来拦截传入请求，从请求标头中提取 JWT 令牌并对其进行验证。此过滤器应使用 JWT 令牌提供程序来验证令牌的签名并提取必要的用户详细信息。 使用 Spring Security 配置 JWT 身份验证过滤器：我们应该配置 JWT 身份验证过滤器以用于处理身份验证请求 实现用户详细信息服务：创建一个用户详细信息服务，根据 JWT 令牌中存储的信息检索用户的详细信息。该服务负责从用户存储库或任何其他数据源获取用户详细信息。 有关实现细节的更多信息，请阅读 Spring Security 中的 JWT 身份验证一文。\n14. 如何实现 OAuth2 安全性？ OAuth2 是一个授权框架，允许应用程序获得对用户帐户的有限访问权限。它涉及多个组件，包括授权服务器和资源服务器。授权服务器处理身份验证并颁发访问令牌，而资源服务器托管受保护的资源并验证访问令牌。\n要实现 OAuth2 安全性，您需要配置授权服务器和资源服务器。\n授权服务器 授权服务器负责对用户进行身份验证并颁发访问令牌。在 Spring Security 中，我们可以使用 AuthorizationServerConfigurerAdapter 类来配置授权服务器。\n以下类设置授权服务器，定义安全约束，并配置可以访问服务器的客户端以获取访问令牌以进行身份 ​​ 验证和授权。\n@Configuration @EnableAuthorizationServer public class OAuth2AuthorizationServer extends AuthorizationServerConfigurerAdapter { @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public void configure(AuthorizationServerSecurityConfigurer security) throws Exception { security .tokenKeyAccess(\u0026#34;permitAll()\u0026#34;) .checkTokenAccess(\u0026#34;isAuthenticated()\u0026#34;); .allowFormAuthenticationForClients(); } @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory() .withClient(\u0026#34;client-id\u0026#34;) .secret(\u0026#34;client-secret\u0026#34;) .authorizedGrantTypes(\u0026#34;authorization_code\u0026#34;, \u0026#34;password\u0026#34;, \u0026#34;refresh_token\u0026#34;) .scopes(\u0026#34;read\u0026#34;, \u0026#34;write\u0026#34;) .accessTokenValiditySeconds(3600) .refreshTokenValiditySeconds(86400); } } 资源服务器 资源服务器托管受保护的资源并验证访问令牌。在 Spring Security 中，我们可以使用 ResourceServerConfigurerAdapter 类来配置资源服务器。\n在以下示例中，OAuth2ResourceServerConfig 通过指定不同 API 端点的访问规则来配置资源服务器。它允许不受限制地访问公共资源，同时要求对私人访问进行身份验证。\n@Configuration @EnableResourceServer public class OAuth2ResourceServerConfig extends ResourceServerConfigurerAdapter { @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/api/public/**\u0026#34;).permitAll() .antMatchers(\u0026#34;/api/private/**\u0026#34;).authenticated(); } } 资源服务器需要验证访问令牌，以确保它是由受信任的授权服务器颁发的，并且没有过期或被篡改。\n一种常见的方法是使用 Spring Security 提供的 RemoteTokenServices 类。资源服务器向授权服务器的 /oauth/check_token 端点发出请求，并将访问令牌作为参数传递。\n@Bean public ResourceServerTokenServices tokenService() { RemoteTokenServices tokenServices = new RemoteTokenServices(); tokenServices.setClientId(\u0026#34;client-id\u0026#34;); tokenServices.setClientSecret(\u0026#34;client-secret\u0026#34;); tokenServices.setCheckTokenEndpointUrl(\u0026#34;http://localhost:8080/oauth/check_token\u0026#34;); return tokenServices; } 15. Spring Security 中的 CSRF 保护是什么？如何实施？ CSRF（跨站点请求伪造）保护是一种安全机制，可防止攻击者利用用户和网站之间的信任。它可以防范 CSRF 攻击，即攻击者在用户不知情或未同意的情况下诱骗用户的浏览器在网站上执行不需要的操作。\n要在 Spring Security 中实现 CSRF 保护，我们可以按照以下步骤操作：\n在客户端代码（通常采用 HTML 表单）中，向应用程序端点发出请求时，将 CSRF 令牌作为隐藏字段或请求标头包含在内。 在服务器端，配置 Spring Security 以期望并验证传入请求中的 CSRF 令牌。 默认情况下，Spring Security 自动启用 CSRF 保护。它将 CSRF 令牌添加到表单中并将其包含在后续请求中。\n我们可以使用 csrf() 方法在 Spring Security 中配置/自定义 CSRF 保护。\n@Configuration public class SecurityWithCsrfCookieConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http .csrf() .csrfTokenRepository(CookieCsrfTokenRepository.withHttpOnlyFalse()); return http.build(); } } 在上面的示例中，我们将 CSRF 保护配置为使用 CookieCsrfTokenRepository 并通过设置 withHttpOnlyFalse() 确保 JavaScript 可以访问 CSRF 令牌。我们可以根据我们的需求选择不同的 CsrfTokenRepository 实现。\n16. 什么是 CORS 以及 Spring Security 中如何处理它？ CORS（跨源资源共享）是 Web 浏览器强制执行的一种安全机制，用于限制跨源 HTTP 请求。它允许服务器指定允许哪些源（域）访问其资源。\n在 Spring Security 中，有两种方法可以在我们的应用程序中配置 CORS：\n全局配置 我们可以通过创建 CorsConfigurationSource 类的 bean 来全局配置 CORS 支持。在此示例中，我们将 CORS 策略配置为允许来自指定源（本例中为 http://localhost:8081 ）的跨源请求。\n@Bean public CorsConfigurationSource corsConfigurationSource() { CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedHeader(\u0026#34;*\u0026#34;); config.addAllowedMethod(\u0026#34;*\u0026#34;); config.addAllowedOrigin(\u0026#34;http://localhost:8081\u0026#34;); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); return source; } 处理程序方法特定的配置 如果我们只需要特定端点的 CORS，我们可以在方法级别使用 @CrossOrigin 注释。这允许我们指定允许的源、HTTP 方法和其他配置。\n在此示例中， /api/resource 端点仅允许使用指定 HTTP 方法来自 http://example.com 的跨源请求。\n@RestController public class MyController { @GetMapping(\u0026#34;/api/resource\u0026#34;) @CrossOrigin(origins = \u0026#34;http://example.com\u0026#34;, methods = {RequestMethod.GET, RequestMethod.POST}) public String getResource() { //... } } 17.解释一下基于会话的身份验证？ 基于会话的身份验证是 Web 应用程序中管理用户身份验证的常用方法。它涉及使用会话和 cookie 来维护身份验证状态并识别经过身份验证的用户。\n基于会话的身份验证的工作原理如下：\n用户身份验证：当用户使用有效凭据登录应用程序时，服务器会验证凭据并为用户创建新会话。会话通常由唯一的会话 ID 组成。 会话创建：服务器将用户的会话 ID 存储在会话存储（例如内存或数据库）中，并将其与用户的身份验证详细信息和任何相关会话数据（例如用户角色、权限）相关联。 会话 ID 存储：服务器将会话 ID 作为 cookie 或响应负载的一部分发送回客户端。客户端的 Web 浏览器存储此会话 ID。 后续请求：客户端的 Web 浏览器自动将会话 ID 包含在后续请求的请求标头（通常作为 cookie）中。这允许服务器识别用户的会话并检索相关的身份验证详细信息。 会话验证：服务器收到请求后，会验证会话 ID，以确保其真实性和完整性。它检查会话是否存在并且仍然有效（例如，未过期或无效）。如果会话有效，服务器将认为用户已通过身份验证并继续处理请求。 会话过期：会话通常有一个过期时间，以确保安全性和管理服务器资源。一旦会话过期，用户需要通过重新登录来重新进行身份验证。 注销：当用户注销时，服务器会通过将会话从会话存储中删除来使其无效。客户端的 Web 浏览器还会删除会话 ID cookie。 18. 如何防止暴力破解？ 防止暴力攻击涉及实施一些措施，使攻击者难以通过重复登录尝试猜测有效凭据。\n以下是我们可以用来降低暴力攻击风险的一些策略：\n帐户锁定：实施帐户锁定机制，在一定次数的登录尝试失败后临时锁定用户帐户。这可以阻止攻击者不断猜测密码。帐户被锁定后，用户可以收到通知或获得安全解锁帐户的方法，例如通过密码重置过程或联系客户支持。 速率限制：应用速率限制技术来限制特定时间范围内的登录尝试次数。这可以防止攻击者快速连续发出多个登录请求。实施速率限制可以减慢攻击过程并降低其效率，从而帮助减轻暴力攻击。 CAPTCHA 或 reCAPTCHA：将 CAPTCHA（区分计算机和人类的完全自动化公共图灵测试）或 reCAPTCHA 挑战集成到您的登录表单中。这些挑战要求用户解决谜题或输入扭曲图像中显示的字符，这有助于确保登录尝试是由人类用户而不是自动脚本进行的。 双因素身份验证 (2FA)：实施双因素身份验证以添加额外的安全层。使用 2FA，除了用户名和密码之外，用户还需要提供第二种形式的身份验证，例如发送到其移动设备的唯一代码。即使攻击者设法获得有效凭据，这也大大降低了暴力攻击成功的风险。 19. Spring Security 中如何处理注销？ 在基于会话的身份验证中，注销涉及销毁会话对象并删除用户浏览器中的会话 cookie。这可以通过配置 HttpSecurity 来实现，如下所示：\nhttp // Other security configurations... .logout() .invalidateHttpSession(true) // Invalidate the user\u0026#39;s HttpSession .deleteCookies(\u0026#34;JSESSIONID\u0026#34;) // Remove the session cookie .logoutSuccessUrl(\u0026#34;/login?logout\u0026#34;) // Redirect to the logout success URL .permitAll(); // Allow anyone to access the logout URL 20. 迁移过程中如何支持多个密码编码器？ 要在 Spring Security 迁移期间支持多个密码编码器，您可以使用 Spring Security 提供的 DelegatingPasswordEncoder。 DelegatingPasswordEncoder 允许您配置多个密码编码器，并将每个编码器与标识符或“id”相关联。\n@Bean public PasswordEncoder passwordEncoder() { Map\u0026lt;String, PasswordEncoder\u0026gt; encoders = new HashMap\u0026lt;\u0026gt;(); encoders.put(\u0026#34;bcrypt\u0026#34;, new BCryptPasswordEncoder()); encoders.put(\u0026#34;custom\u0026#34;, new CustomPasswordEncoder()); // Replace with your custom encoder return new DelegatingPasswordEncoder(\u0026#34;bcrypt\u0026#34;, encoders); } 在上面的例子中，我们配置了两个密码编码器：\nBCryptPasswordEncoder CustomPasswordEncoder DelegatingPasswordEncoder 使用默认编码器 ID（“bcrypt”）和编码器映射进行初始化。在身份验证过程中，Spring Security 将根据编码密码的前缀或提供的编码器 ID 确定适当的编码器。\n21.保护 REST-API 的最佳实践？ 实施 REST API 安全性涉及多种注意事项，以保护 API 免受未经授权的访问并确保数据完整性。\n身份验证：实施安全的身份验证机制来验证发出 API 请求的客户端的身份。常见方法包括基于令牌的身份验证（例如 JWT）、OAuth 2.0 或 API 密钥。选择适合应用程序要求的身份验证方法并将其集成到 API 端点中。 授权：定义访问控制规则以确定每个经过身份验证的客户端可以访问哪些操作或资源。使用基于角色或基于权限的授权机制对 API 端点实施限制。 Spring Security 提供了诸如 @PreAuthorize 或 @RolesAllowed 之类的注释来在方法或端点级别配置授权规则。 安全传输层：通过强制执行 HTTPS 确保客户端和 API 服务器之间的安全通信。这对客户端和服务器之间交换的数据进行加密，防止其被窃听和篡改。配置您的服务器以使用 SSL/TLS 证书并为所有 API 端点启用 HTTPS。 输入验证：验证和清理用户输入，以防止常见的安全漏洞，例如 SQL 注入、跨站点脚本 (XSS) 或其他注入攻击。应用输入验证技术和框架来清理和验证用户提供的数据，以降低安全漏洞的风险。 速率限制：实施速率限制机制以防止滥用并确保 API 资源的公平使用。定义特定时间段内每个客户端或每个 API 端点允许的请求数量的限制。这有助于防止 DoS（拒绝服务）攻击并确保 API 的可用性和性能。 日志记录和监控：当我们必须解决不明显且难以重现的问题时，日志记录和监控有助于在雨天进行调试。 22. Spring Security 如何与 Mobile App Security 配合使用？ Spring Security 能够与移动应用程序安全性无缝集成，提供强大的身份验证和授权功能。\n一种流行的方法是基于令牌的安全性，其中移动应用程序向服务器发送身份验证请求并获取令牌（例如 JWT）作为响应。随后，该令牌将包含在所有后续 API 请求中，以用作授权机制。\n结论 这本常见 Spring Security 面试问题和答案的综合指南探讨了身份验证、授权和 Spring Security 的各种组件等关键概念。我们深入研究了密码编码、请求匹配、方法安全注释以及与其他框架的集成等主题。通过熟悉这些面试问题及其答案，您可以在面试期间自信地处理 Spring Security 相关的讨论。\n快乐学习！\n原文链接：Spring Security Interview Questions\n","permalink":"https://blog.chensoul.cc/posts/2023/10/12/spring-security-interview-questions/","summary":"本面试准备指南将讨论一些常见的 Spring Security 面试问题。无论您是准备面试还是只是想增强对 Spring Security 的了解，这些问题都将帮助您理解关键概念并指导您设计常见安全问题的解决方案。\n1. Spring Security 的核心特性是什么？ Spring Security 提供的两个最突出的功能是身份验证和授权。这些功能在确保应用程序的安全性方面发挥着至关重要的作用。然而，Spring Security 超越了身份验证和授权，还提供了额外的功能来防止漏洞利用并与其他框架集成。\n1.1.验证 身份验证是验证尝试访问应用程序的用户身份的过程。 Spring Security 提供多种身份验证方法（基于表单的身份验证、HTTP 基本身份验证、OAuth2、Siteminder、OpenID Connect、LDAP、JDBC 等），允许应用程序使用各种方法对用户进行身份验证。\n它还支持自定义，当默认选项不满足要求时，可以实现自定义的身份验证机制。\n1.2.授权 授权是向经过身份验证的用户或实体授予许可或权利的过程。用户或实体成功通过身份验证后，授权将决定他们可以在应用程序中访问哪些操作或资源。 Spring Security 为开发人员提供了多种方法来实现授权并控制用户对应用程序不同部分的访问。以下是一些常见的方法：\n基于 Web URL 的授权：可以根据特定的 URL 或 URL 模式实施访问控制，规范哪些用户可以访问某些资源。 方法级授权：如果需要，甚至可以对 Java Bean 中的方法进行访问控制，从而在方法级提供细粒度的授权。 域实例级授权：Spring Security 提供了控制对特定域实例的访问的能力，允许基于某些实体的所有权或关联进行授权。 1.3.防止漏洞利用 Spring Security 提供了多种功能来防范常见的 Web 应用程序安全漏洞。一些显着的功能包括：\n跨站请求伪造 (CSRF) 保护：Spring Security 会自动将 CSRF 令牌添加到表单和 AJAX 请求中，从而防止 CSRF 攻击。 跨站脚本 (XSS) 保护：Spring Security 支持输出编码，并提供实用程序通过清理用户输入来防止 XSS 攻击。 点击劫持保护：Spring Security 包括 X-Frame-Options 支持，以防止点击劫持攻击。 1.4.集成 Spring Security 与其他框架和库无缝集成，以增强应用程序的安全性。一些关键的集成是：\nSpring MVC：Spring Security 与 Spring MVC 集成，为 Web 应用程序提供无缝的安全功能。它可以安全地处理请求、身份验证、授权并防止常见的 Web 漏洞。 Spring Data：Spring Security 与 Spring Data 集成，以便在查询中引用当前用户。这种集成确保可以根据身份验证和授权规则轻松访问和过滤用户特定的数据。 Jackson：Jackson 的支持可以实现 Spring Security 相关类的高效序列化和反序列化，特别是在使用分布式会话或 Spring Session 等框架时，从而提高效率和可扩展性。 密码学：Spring Security 与各种密码库和算法集成，以提供敏感信息的安全存储和传输。这种集成包括密码散列、加密和安全通信协议等功能，以保护数据的机密性和完整性。 有关 Spring Security 功能的更详细信息，请参阅官方文档。","title":"[译]Spring Security 面试问题"},{"content":"本文主要介绍 Caching 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 缓存模式（Caching Pattern）是一种设计模式，旨在通过在资源使用后将其保留在某个快速访问的存储中，并在需要时重新使用资源，以避免昂贵的资源重新获取。\n缓存模式的目的是减少重复获取、初始化和释放同一资源所带来的不必要性能开销。通过将资源保留在缓存中，可以避免再次获取资源，从而提高系统的响应速度和性能。\n在缓存模式中，当需要访问资源时，首先检查缓存中是否存在该资源的副本。如果缓存中存在资源，则直接从缓存中获取并返回给调用方。如果缓存中不存在资源，则需要从原始数据源或其他途径获取资源，并将其存储在缓存中，以供后续使用。\n缓存模式适用于那些需要频繁访问、计算成本较高的资源的情况，例如数据库查询、网络请求、文件读写等。通过使用缓存模式，可以显著提升系统的性能和响应速度，减少对原始数据源的访问次数，从而降低系统的负载。\n关于缓存模式的更多信息和实现方式，您可以参考以下资源：\nWrite-Through, Write-Around, Write-Back: Cache Explained：对缓存模式进行了详细解释和说明，提供了不同的缓存策略和实现方式。 Read-Through, Write-Through, Write-Behind, and Refresh-Ahead Caching：介绍了不同类型的缓存操作和策略，包括读取、写入、刷新等。 Cache-Aside Pattern：介绍了缓存模式中的一种常见实现方式，即\u0026quot;Cache-Aside\u0026quot;模式，包括其工作原理和使用方法。 实现策略 缓存模式有多种常见的实现策略，以下是其中一些常见的实现策略：\n写入穿透（Write-Through）：当从数据源获取数据时，将数据同时写入缓存。这样，在下一次需要相同数据时，可以从缓存中获取，避免再次访问数据源。写入穿透策略确保缓存中始终保持最新的数据。 写入回写（Write-Back）：在数据发生变化时，首先将数据写入缓存，然后再定期将缓存中的数据批量写回到数据源。写入回写策略可以减少对数据源的频繁写入操作，提高性能。 写入旁路（Write-Around）：将写操作直接发送到数据源，而不是通过缓存。这样可以避免将不经常访问的数据写入缓存，从而节省缓存空间。只有当数据被读取时，才会将其放入缓存。 刷新预取（Refresh-Ahead）：在缓存中存储数据的同时，预先获取和更新与当前数据相关的其他数据。这样，当需要访问相关数据时，可以直接从缓存中获取，减少等待时间。 最近最少使用（Least Recently Used, LRU）：根据数据的访问频率和时间进行缓存淘汰。当缓存空间不足时，优先淘汰最近最少被访问的数据，以保留最常用的数据。 固定时间过期（Time-To-Live, TTL）：为缓存中的每个数据项设置一个固定的过期时间。一旦数据项超过过期时间，将被视为过期并从缓存中移除。 异步刷新（Asynchronous Refresh）：在数据过期或无效时，通过异步方式从数据源获取新数据并更新缓存。这样可以避免阻塞调用方，提高系统的响应速度。 缓存框架 当涉及到缓存框架或工具时，有几个常见且广泛使用的选项可以考虑。以下是其中一些常见的缓存框架或工具：\nEhcache: Ehcache 是一个流行的开源 Java 缓存框架，提供了各种缓存策略和功能，包括内存缓存、磁盘缓存、分布式缓存等。它易于使用且性能优秀，可以轻松集成到 Java 应用程序中。 Redis: Redis 是一个开源的高性能内存数据结构存储系统，也可以用作缓存。它支持多种数据结构和丰富的缓存功能，如数据过期、持久化、分布式缓存等。Redis 可以作为独立的缓存服务器，也可以与应用程序集成使用。 Memcached: Memcached 是一个简单而高效的分布式内存对象缓存系统。它以键值对的形式存储数据，并提供了分布式缓存的支持。Memcached 适用于高并发环境下的缓存需求，可以减轻后端数据库的压力。 Caffeine: Caffeine 是一个基于 Java 的高性能缓存库，专注于提供快速的缓存访问和高效的内存管理。它支持各种缓存策略和功能，并提供了线程安全和异步加载等特性。 Hazelcast: Hazelcast 是一个开源的分布式数据存储和计算平台，其中包括了分布式缓存的功能。它提供了高可用性和可扩展性，并支持多种缓存策略和分布式缓存模式。 Guava Cache: Guava Cache 是 Google 的 Guava 库中提供的一个本地缓存实现。它提供了简单易用的 API，支持各种缓存策略和功能，如过期时间、最大缓存大小、缓存统计等。 Apache Ignite: Apache Ignite 是一个内存计算平台，提供了分布式缓存和计算能力。它可以作为一个分布式缓存存储数据，并支持 SQL 查询、分布式计算、流处理等功能。 Couchbase: Couchbase 是一个面向企业应用的 NoSQL 数据库和缓存平台。它提供了可扩展的内存缓存功能，并支持数据持久化和分布式缓存集群。 Aerospike: Aerospike 是一个高性能的 NoSQL 数据库和缓存平台，专注于提供低延迟和高吞吐量的数据访问。它支持内存和闪存存储，并具有分布式缓存的功能。 Oracle Coherence: Oracle Coherence 是一个企业级的分布式缓存和数据网格解决方案。它提供了高可用性、可扩展性和事务支持，并支持多种缓存策略和数据复制模式。 ","permalink":"https://blog.chensoul.cc/posts/2023/09/25/java-design-patterns-cahcing/","summary":"本文主要介绍 Caching 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 缓存模式（Caching Pattern）是一种设计模式，旨在通过在资源使用后将其保留在某个快速访问的存储中，并在需要时重新使用资源，以避免昂贵的资源重新获取。\n缓存模式的目的是减少重复获取、初始化和释放同一资源所带来的不必要性能开销。通过将资源保留在缓存中，可以避免再次获取资源，从而提高系统的响应速度和性能。\n在缓存模式中，当需要访问资源时，首先检查缓存中是否存在该资源的副本。如果缓存中存在资源，则直接从缓存中获取并返回给调用方。如果缓存中不存在资源，则需要从原始数据源或其他途径获取资源，并将其存储在缓存中，以供后续使用。\n缓存模式适用于那些需要频繁访问、计算成本较高的资源的情况，例如数据库查询、网络请求、文件读写等。通过使用缓存模式，可以显著提升系统的性能和响应速度，减少对原始数据源的访问次数，从而降低系统的负载。\n关于缓存模式的更多信息和实现方式，您可以参考以下资源：\nWrite-Through, Write-Around, Write-Back: Cache Explained：对缓存模式进行了详细解释和说明，提供了不同的缓存策略和实现方式。 Read-Through, Write-Through, Write-Behind, and Refresh-Ahead Caching：介绍了不同类型的缓存操作和策略，包括读取、写入、刷新等。 Cache-Aside Pattern：介绍了缓存模式中的一种常见实现方式，即\u0026quot;Cache-Aside\u0026quot;模式，包括其工作原理和使用方法。 实现策略 缓存模式有多种常见的实现策略，以下是其中一些常见的实现策略：\n写入穿透（Write-Through）：当从数据源获取数据时，将数据同时写入缓存。这样，在下一次需要相同数据时，可以从缓存中获取，避免再次访问数据源。写入穿透策略确保缓存中始终保持最新的数据。 写入回写（Write-Back）：在数据发生变化时，首先将数据写入缓存，然后再定期将缓存中的数据批量写回到数据源。写入回写策略可以减少对数据源的频繁写入操作，提高性能。 写入旁路（Write-Around）：将写操作直接发送到数据源，而不是通过缓存。这样可以避免将不经常访问的数据写入缓存，从而节省缓存空间。只有当数据被读取时，才会将其放入缓存。 刷新预取（Refresh-Ahead）：在缓存中存储数据的同时，预先获取和更新与当前数据相关的其他数据。这样，当需要访问相关数据时，可以直接从缓存中获取，减少等待时间。 最近最少使用（Least Recently Used, LRU）：根据数据的访问频率和时间进行缓存淘汰。当缓存空间不足时，优先淘汰最近最少被访问的数据，以保留最常用的数据。 固定时间过期（Time-To-Live, TTL）：为缓存中的每个数据项设置一个固定的过期时间。一旦数据项超过过期时间，将被视为过期并从缓存中移除。 异步刷新（Asynchronous Refresh）：在数据过期或无效时，通过异步方式从数据源获取新数据并更新缓存。这样可以避免阻塞调用方，提高系统的响应速度。 缓存框架 当涉及到缓存框架或工具时，有几个常见且广泛使用的选项可以考虑。以下是其中一些常见的缓存框架或工具：\nEhcache: Ehcache 是一个流行的开源 Java 缓存框架，提供了各种缓存策略和功能，包括内存缓存、磁盘缓存、分布式缓存等。它易于使用且性能优秀，可以轻松集成到 Java 应用程序中。 Redis: Redis 是一个开源的高性能内存数据结构存储系统，也可以用作缓存。它支持多种数据结构和丰富的缓存功能，如数据过期、持久化、分布式缓存等。Redis 可以作为独立的缓存服务器，也可以与应用程序集成使用。 Memcached: Memcached 是一个简单而高效的分布式内存对象缓存系统。它以键值对的形式存储数据，并提供了分布式缓存的支持。Memcached 适用于高并发环境下的缓存需求，可以减轻后端数据库的压力。 Caffeine: Caffeine 是一个基于 Java 的高性能缓存库，专注于提供快速的缓存访问和高效的内存管理。它支持各种缓存策略和功能，并提供了线程安全和异步加载等特性。 Hazelcast: Hazelcast 是一个开源的分布式数据存储和计算平台，其中包括了分布式缓存的功能。它提供了高可用性和可扩展性，并支持多种缓存策略和分布式缓存模式。 Guava Cache: Guava Cache 是 Google 的 Guava 库中提供的一个本地缓存实现。它提供了简单易用的 API，支持各种缓存策略和功能，如过期时间、最大缓存大小、缓存统计等。 Apache Ignite: Apache Ignite 是一个内存计算平台，提供了分布式缓存和计算能力。它可以作为一个分布式缓存存储数据，并支持 SQL 查询、分布式计算、流处理等功能。 Couchbase: Couchbase 是一个面向企业应用的 NoSQL 数据库和缓存平台。它提供了可扩展的内存缓存功能，并支持数据持久化和分布式缓存集群。 Aerospike: Aerospike 是一个高性能的 NoSQL 数据库和缓存平台，专注于提供低延迟和高吞吐量的数据访问。它支持内存和闪存存储，并具有分布式缓存的功能。 Oracle Coherence: Oracle Coherence 是一个企业级的分布式缓存和数据网格解决方案。它提供了高可用性、可扩展性和事务支持，并支持多种缓存策略和数据复制模式。 ","title":"Java设计模式：Caching"},{"content":"在 React 中，您可以使用多种方法来初始化一个应用程序。以下是几种常见的方法：\n使用 Create React App（CRA）。Create React App 是一个官方提供的脚手架工具，用于快速创建 React 应用程序的基本结构和配置。 使用 Vite。Vite 是一个快速、简单且现代化的前端构建工具。 create-react-app create-react-app 是一个用于快速创建 React 应用程序的命令行工具。它提供了一个简单的方式来设置和配置一个全新的 React 项目，包括构建、开发服务器和其他常见的配置。\n要使用 create-react-app 创建一个新的 React 项目，您可以按照以下步骤进行操作：\n安装 Node.js\n创建 React 应用：一旦你安装了 Node.js，你可以使用 create-react-app 工具快速创建一个新的 React 应用。\n在命令行中运行以下命令来全局安装 create-react-app：\nnpm install -g create-react-app 创建新的 React 应用：使用以下命令创建一个新的 React 应用： create-react-app my-app 提示：\nnpx 是在运行命令时临时安装和执行包的工具。这意味着您无需全局安装 create-react-app，而是在运行 npx create-react-app 命令时自动下载和使用最新版本的 create-react-app。\nnpx create-react-app my-app 这将在当前目录下创建一个名为 \u0026quot;my-app\u0026quot; 的新文件夹，并在此文件夹里做了如下工作：\n为你的应用程序安装了一些 npm 包； 写入 react 应用启动所需要的脚本文件； 创建一系列结构化的子文件夹和文件； 如果你的电脑上安装了 git 的话，顺便帮你把 git 仓库也建好。 如果你的电脑上安装了 yarn 的话，create-react-app 会默认使用 yarn 而非 npm。如果你同时安装了 yarn 和 npm，但你希望使用 npm 的话，在 create-react-app 的时候需要输入 --use-npm ：\ncreate-react-app my-app --use-npm 进入应用目录：进入新创建的应用程序目录。在命令行中运行以下命令： cd my-app 启动开发服务器：运行以下命令来启动 React 开发服务器： npm start 先前由 create-react-app 创建的脚本会启动一个地服务 localhost:3000，并打开你的默认浏览器来访问这个服务。成功启动浏览器的话，你的浏览器上会显示如下画面：\n应用结构\ncreate-react-app 提供了开发 React 应用所需的工具。它的初始文件结构如下：\nmy-app ├── README.md ├── node_modules ├── package.json ├── package-lock.json ├── .gitignore ├── public │ ├── favicon.ico │ ├── index.html │ └── manifest.json └── src ├── App.css ├── App.js ├── App.test.js ├── index.css ├── index.js ├── logo.svg └── reportWebVitals.js 各目录和文件说明：\n目录 src 是我们花费时间最多的地方，因为它是我们 React 应用源码存放的目录。\n目录 public 包含了开发应用时浏览器会读取的文件，其中最重要的就是 index.html。React 将目录 src 中的代码嵌入这个文件，从而浏览器才能运行此文件。 index.html中的有些内容关乎 create-react-app 的运作，因此除非你知道自己在做什么样的修改，否则不建议编辑这个文件。当然，你可以修改index.html中的 title 元素的内容来表现此应用程序通俗易懂的名称。\n目录 public 会在建立并部署此应用的时候更新。\n文件 package.json 包含了 Node.js/npm 为了建立该应用程序所管理着的文件信息。\n编辑 React 组件。在 src 目录中，可以找到名为 App.js 的文件。这是 React 应用的主要组件。你可以编辑该文件以添加、修改或删除组件的内容。\ncreate-react-app 添加了一些我们在项目中完全不会用到的文件。\n我们不打算写每个组件的样式表，所以首先从 App.js 的顶部删除 App.css 的导入。 我们也不打算使用 logo.svg 文件，所以也要删除这个导入。 cd src # Delete a few files rm -- App.test.js App.css logo.svg reportWebVitals.js setupTests.js # Move back up to the root of the project cd .. 修改 src/App.js 如下：\nimport \u0026#34;./App.css\u0026#34;; function App() { return ( \u0026lt;div className=\u0026#34;App\u0026#34;\u0026gt; \u0026lt;header\u0026gt; \u0026lt;p\u0026gt;Hello React\u0026lt;/p\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;/div\u0026gt; ); } export default App; 修改 src/index.js 如下：\nimport React from \u0026#34;react\u0026#34;; import ReactDOM from \u0026#34;react-dom/client\u0026#34;; import \u0026#34;./index.css\u0026#34;; import App from \u0026#34;./App\u0026#34;; const root = ReactDOM.createRoot(document.getElementById(\u0026#34;root\u0026#34;)); root.render( \u0026lt;React.StrictMode\u0026gt; \u0026lt;App /\u0026gt; \u0026lt;/React.StrictMode\u0026gt; ); 查看应用程序：在你进行编辑并保存代码后，开发服务器将自动重新加载并刷新应用程序。你可以在默认浏览器中查看更新后的应用程序。\nvite 要使用 Vite 创建一个 React 项目，可以按照以下步骤进行操作：\n确保你已经安装了 Node.js。 安装 Vite：在命令行中运行以下命令来全局安装 Vite： npm install -g create-vite 创建新的 React 项目：使用以下命令创建一个新的 React 项目： create-vite my-app-vite --template react --template react 参数告诉 Vite 使用 React 模板来创建项目。\n进入项目目录：进入新创建的项目目录。在命令行中运行以下命令： cd my-app-vite 安装依赖项：在项目目录中，运行以下命令来安装项目的依赖项： npm install 启动开发服务器：运行以下命令来启动 Vite 开发服务器： npm run dev 这将启动开发服务器并在默认浏览器中打开项目。你可以在开发服务器运行期间进行代码编辑，并实时查看项目的更改。\n编辑 React 组件：在 src 目录中，可以找到名为 App.jsx 的文件。这是 React 项目的主要组件。你可以编辑该文件以添加、修改或删除组件的内容。\n查看项目：在你进行编辑并保存代码后，开发服务器将自动重新加载并刷新项目。你可以在默认浏览器中查看更新后的项目。\ncreate-react-app 和 vite 区别 Create React App (CRA) 和 Vite 是两种常用的工具，用于创建和开发 React 应用程序，它们在一些方面有所区别。\n构建方式： Create React App：CRA 是一个用于构建 React 应用程序的脚手架工具。它使用 Webpack 作为构建工具，并配置了一组默认的构建配置，使得开发者无需手动配置即可开始开发 React 应用程序。 Vite：Vite 是一个现代化的构建工具，专为现代 Web 开发而设计。它使用 ES 模块作为开发时的构建方式，利用浏览器原生支持的模块解析功能，实现了快速的冷启动和热模块替换（HMR）。 开发体验： Create React App：CRA 提供了一个简单且一致的开发环境，使得开发者可以专注于编写 React 组件和业务逻辑。它隐藏了大部分的构建配置细节，使得开发者无需关心底层的构建配置。 Vite：Vite 在开发环境中具有出色的开发体验。它通过使用 ES 模块的直接导入，避免了传统的构建步骤，大大减少了冷启动时间，同时提供了快速的热模块替换，使得开发者能够更快地看到代码更改的效果。 构建速度： Create React App：CRA 使用 Webpack 进行构建，通常在项目较大时，构建时间会相对较长。 Vite：Vite 利用了现代浏览器对 ES 模块的原生支持，构建速度非常快，尤其在开发环境中。 配置灵活性： Create React App：CRA 提供了预定义的构建配置，对于大多数应用程序来说，这些配置已经足够。如果你需要更改构建配置，你需要使用 eject 命令将配置暴露出来，并自己进行配置。 Vite：Vite 的配置方式非常灵活，你可以根据需要自定义配置。Vite 使用了一种基于插件的方式来扩展和修改构建配置，使得配置更加直观和可维护。 综上所述，Create React App 适合那些希望快速启动 React 项目且不需要过多自定义配置的开发者。而 Vite 则适合对开发体验和构建速度有较高要求的开发者，并提供了更大的配置灵活性。选择使用哪个工具取决于你的具体需求和项目特点。\n参考文章 React 入门 ","permalink":"https://blog.chensoul.cc/posts/2023/09/22/react-create-project/","summary":"在 React 中，您可以使用多种方法来初始化一个应用程序。以下是几种常见的方法：\n使用 Create React App（CRA）。Create React App 是一个官方提供的脚手架工具，用于快速创建 React 应用程序的基本结构和配置。 使用 Vite。Vite 是一个快速、简单且现代化的前端构建工具。 create-react-app create-react-app 是一个用于快速创建 React 应用程序的命令行工具。它提供了一个简单的方式来设置和配置一个全新的 React 项目，包括构建、开发服务器和其他常见的配置。\n要使用 create-react-app 创建一个新的 React 项目，您可以按照以下步骤进行操作：\n安装 Node.js\n创建 React 应用：一旦你安装了 Node.js，你可以使用 create-react-app 工具快速创建一个新的 React 应用。\n在命令行中运行以下命令来全局安装 create-react-app：\nnpm install -g create-react-app 创建新的 React 应用：使用以下命令创建一个新的 React 应用： create-react-app my-app 提示：\nnpx 是在运行命令时临时安装和执行包的工具。这意味着您无需全局安装 create-react-app，而是在运行 npx create-react-app 命令时自动下载和使用最新版本的 create-react-app。\nnpx create-react-app my-app 这将在当前目录下创建一个名为 \u0026quot;my-app\u0026quot; 的新文件夹，并在此文件夹里做了如下工作：\n为你的应用程序安装了一些 npm 包； 写入 react 应用启动所需要的脚本文件； 创建一系列结构化的子文件夹和文件； 如果你的电脑上安装了 git 的话，顺便帮你把 git 仓库也建好。 如果你的电脑上安装了 yarn 的话，create-react-app 会默认使用 yarn 而非 npm。如果你同时安装了 yarn 和 npm，但你希望使用 npm 的话，在 create-react-app 的时候需要输入 --use-npm ：\ncreate-react-app my-app --use-npm 进入应用目录：进入新创建的应用程序目录。在命令行中运行以下命令： cd my-app 启动开发服务器：运行以下命令来启动 React 开发服务器： npm start 先前由 create-react-app 创建的脚本会启动一个地服务 localhost:3000，并打开你的默认浏览器来访问这个服务。成功启动浏览器的话，你的浏览器上会显示如下画面：","title":"React入门：初始化应用的两种方法"},{"content":"本文主要介绍 Bytecode 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 字节码设计模式是一种软件设计模式，它允许以数据驱动的方式定义和执行行为。在字节码设计模式中，行为被表示为一系列虚拟机指令，这些指令被编码为字节码，并在运行时执行。\n字节码设计模式的目的是将行为与代码分离，使得行为可以在不修改源代码的情况下进行动态调整和扩展。通过将行为以数据的形式表示，并使用字节码指令进行执行，可以实现更灵活和可配置的行为逻辑。\n下面是字节码设计模式的一些关键要点：\n指令集：字节码设计模式通过定义一组指令集来表示不同的行为。每个指令都有自己的语义和操作方式，用于执行特定的行为逻辑。 虚拟机：字节码设计模式需要一个虚拟机来执行指令集。虚拟机负责解释和执行字节码指令，并根据指令的要求进行相应的操作。 数据驱动的行为：字节码设计模式的核心思想是将行为表示为数据而不是代码。行为逻辑由字节码指令和相关数据组成，这些数据可以在运行时进行修改和配置，从而改变程序的行为。 动态性和灵活性：由于行为以数据形式存在，并且可以在运行时进行调整，字节码设计模式具有很高的动态性和灵活性。这使得开发人员可以根据需要动态地配置和修改行为，而无需修改源代码。 可重用性和扩展性：字节码设计模式提供了一种可重用和可扩展的方式来定义行为。通过定义不同的指令和指令集，可以构建具有不同行为的模块，并在不同的上下文中重复使用这些模块。 字节码设计模式在游戏开发、模拟器、脚本引擎等领域中具有广泛的应用。它使得开发人员能够以更灵活和动态的方式定义和管理程序的行为，从而提供了更高的可配置性和可扩展性。\n举例 一个常见的例子是在游戏开发中使用字节码设计模式来定义角色的行为。假设我们有一个角色类（Character），它具有各种行为，例如攻击、防御、移动等。而这些行为的具体逻辑可能会根据游戏的需求而变化。\n使用字节码设计模式，我们可以将角色的行为表示为一系列字节码指令，并通过虚拟机来执行这些指令，以实现角色的行为逻辑。\n下面是一个简化的示例：\n定义指令集： 我们定义一组指令来表示角色的行为，例如： ATTACK：进行攻击操作 DEFEND：进行防御操作 MOVE：进行移动操作 创建虚拟机： 我们创建一个虚拟机（VirtualMachine）类，它接收字节码作为输入，并执行相应的指令。虚拟机可以解释字节码指令，并根据指令的要求执行相应的行为逻辑。\n定义角色行为： 我们创建一个角色（Character）类，它包含一个字节码数组，用于表示角色的行为。例如：\nbyte[] bytecode = {ATTACK, MOVE, ATTACK, DEFEND}; 执行角色行为： 我们将角色的字节码传递给虚拟机，并执行角色的行为逻辑：\nVirtualMachine vm = new VirtualMachine(); vm.execute(bytecode); 虚拟机会解释字节码指令，并根据指令执行相应的行为。例如，当遇到 ATTACK 指令时，虚拟机会执行攻击操作；当遇到 MOVE 指令时，虚拟机会执行移动操作，依此类推。\n除了游戏开发之外，字节码设计模式还在其他领域中有一些应用。以下是一些常见的应用领域：\n脚本引擎：字节码设计模式可用于实现脚本引擎，其中脚本语言的行为逻辑被表示为字节码指令。这种设计使得脚本的执行可以更高效和灵活，同时还可以提供动态性和扩展性。 模拟器：在模拟器开发中，字节码设计模式可以用于定义和执行模拟器的指令集。模拟器可以通过解释和执行字节码指令来模拟不同的操作和行为，从而实现对特定系统或环境的模拟。 动态编程语言：一些动态编程语言（如 Python、Ruby 等）使用字节码设计模式来实现动态性和灵活性。这些语言将代码编译为字节码，并使用虚拟机来执行字节码指令，从而提供动态类型、动态绑定和运行时修改代码等特性。 JIT 编译器：即时编译器（Just-in-Time Compiler）可以使用字节码设计模式来实现代码的即时编译和优化。在运行时，即时编译器将字节码转换为本地机器码，并对代码进行优化，以提高执行效率。 领域特定语言（DSL）：字节码设计模式可以用于开发领域特定语言，其中 DSL 的行为逻辑被表示为字节码指令。这种设计使得 DSL 的执行更高效，并提供了更大的灵活性和可配置性。 需要注意的是，字节码设计模式的应用不仅限于以上领域，它可以在需要动态性、灵活性和可配置性的任何领域中发挥作用。由于字节码设计模式提供了一种将行为表示为数据的方式，使得行为可以在运行时进行调整和修改，因此在许多软件开发和系统设计的场景中都具有潜在的应用价值。\n适用场景 字节码设计模式适用于以下场景：\n动态行为需求：当系统需要在运行时动态地定义、配置或修改行为时，字节码设计模式可以提供一种灵活的方式。它允许将行为表示为字节码指令，以便在需要时进行调整和修改，而无需修改源代码。 可配置性和可扩展性要求：如果系统需要具有高度可配置和可扩展的行为逻辑，字节码设计模式可以提供一种解决方案。通过将行为表示为字节码指令和相关数据，开发人员可以轻松地定义和管理不同的行为模块，并在不同的上下文中重复使用这些模块。 脚本引擎和动态语言实现：字节码设计模式可以用于实现脚本引擎或支持动态语言的运行时环境。它可以将脚本行为表示为字节码指令，从而提供动态性、灵活性和执行效率。 模拟和仿真系统：在模拟和仿真系统中，字节码设计模式可以用于定义和执行模拟器的行为。通过使用字节码指令来表示各种操作和行为，可以实现对特定系统或环境的准确模拟。 编译器和优化器开发：字节码设计模式可用于开发编译器、优化器和即时编译器。它提供了一种将源代码转换为字节码指令，并在运行时进行优化和执行的方式，以提高程序的性能和效率。 总的来说，字节码设计模式在需要动态性、灵活性、可配置性和可扩展性的场景中都有应用价值。它可以用于开发各种类型的系统，包括游戏引擎、脚本引擎、模拟器、编译器、优化器等。\n","permalink":"https://blog.chensoul.cc/posts/2023/09/22/java-design-patterns-bytecode/","summary":"本文主要介绍 Bytecode 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 字节码设计模式是一种软件设计模式，它允许以数据驱动的方式定义和执行行为。在字节码设计模式中，行为被表示为一系列虚拟机指令，这些指令被编码为字节码，并在运行时执行。\n字节码设计模式的目的是将行为与代码分离，使得行为可以在不修改源代码的情况下进行动态调整和扩展。通过将行为以数据的形式表示，并使用字节码指令进行执行，可以实现更灵活和可配置的行为逻辑。\n下面是字节码设计模式的一些关键要点：\n指令集：字节码设计模式通过定义一组指令集来表示不同的行为。每个指令都有自己的语义和操作方式，用于执行特定的行为逻辑。 虚拟机：字节码设计模式需要一个虚拟机来执行指令集。虚拟机负责解释和执行字节码指令，并根据指令的要求进行相应的操作。 数据驱动的行为：字节码设计模式的核心思想是将行为表示为数据而不是代码。行为逻辑由字节码指令和相关数据组成，这些数据可以在运行时进行修改和配置，从而改变程序的行为。 动态性和灵活性：由于行为以数据形式存在，并且可以在运行时进行调整，字节码设计模式具有很高的动态性和灵活性。这使得开发人员可以根据需要动态地配置和修改行为，而无需修改源代码。 可重用性和扩展性：字节码设计模式提供了一种可重用和可扩展的方式来定义行为。通过定义不同的指令和指令集，可以构建具有不同行为的模块，并在不同的上下文中重复使用这些模块。 字节码设计模式在游戏开发、模拟器、脚本引擎等领域中具有广泛的应用。它使得开发人员能够以更灵活和动态的方式定义和管理程序的行为，从而提供了更高的可配置性和可扩展性。\n举例 一个常见的例子是在游戏开发中使用字节码设计模式来定义角色的行为。假设我们有一个角色类（Character），它具有各种行为，例如攻击、防御、移动等。而这些行为的具体逻辑可能会根据游戏的需求而变化。\n使用字节码设计模式，我们可以将角色的行为表示为一系列字节码指令，并通过虚拟机来执行这些指令，以实现角色的行为逻辑。\n下面是一个简化的示例：\n定义指令集： 我们定义一组指令来表示角色的行为，例如： ATTACK：进行攻击操作 DEFEND：进行防御操作 MOVE：进行移动操作 创建虚拟机： 我们创建一个虚拟机（VirtualMachine）类，它接收字节码作为输入，并执行相应的指令。虚拟机可以解释字节码指令，并根据指令的要求执行相应的行为逻辑。\n定义角色行为： 我们创建一个角色（Character）类，它包含一个字节码数组，用于表示角色的行为。例如：\nbyte[] bytecode = {ATTACK, MOVE, ATTACK, DEFEND}; 执行角色行为： 我们将角色的字节码传递给虚拟机，并执行角色的行为逻辑：\nVirtualMachine vm = new VirtualMachine(); vm.execute(bytecode); 虚拟机会解释字节码指令，并根据指令执行相应的行为。例如，当遇到 ATTACK 指令时，虚拟机会执行攻击操作；当遇到 MOVE 指令时，虚拟机会执行移动操作，依此类推。\n除了游戏开发之外，字节码设计模式还在其他领域中有一些应用。以下是一些常见的应用领域：\n脚本引擎：字节码设计模式可用于实现脚本引擎，其中脚本语言的行为逻辑被表示为字节码指令。这种设计使得脚本的执行可以更高效和灵活，同时还可以提供动态性和扩展性。 模拟器：在模拟器开发中，字节码设计模式可以用于定义和执行模拟器的指令集。模拟器可以通过解释和执行字节码指令来模拟不同的操作和行为，从而实现对特定系统或环境的模拟。 动态编程语言：一些动态编程语言（如 Python、Ruby 等）使用字节码设计模式来实现动态性和灵活性。这些语言将代码编译为字节码，并使用虚拟机来执行字节码指令，从而提供动态类型、动态绑定和运行时修改代码等特性。 JIT 编译器：即时编译器（Just-in-Time Compiler）可以使用字节码设计模式来实现代码的即时编译和优化。在运行时，即时编译器将字节码转换为本地机器码，并对代码进行优化，以提高执行效率。 领域特定语言（DSL）：字节码设计模式可以用于开发领域特定语言，其中 DSL 的行为逻辑被表示为字节码指令。这种设计使得 DSL 的执行更高效，并提供了更大的灵活性和可配置性。 需要注意的是，字节码设计模式的应用不仅限于以上领域，它可以在需要动态性、灵活性和可配置性的任何领域中发挥作用。由于字节码设计模式提供了一种将行为表示为数据的方式，使得行为可以在运行时进行调整和修改，因此在许多软件开发和系统设计的场景中都具有潜在的应用价值。\n适用场景 字节码设计模式适用于以下场景：\n动态行为需求：当系统需要在运行时动态地定义、配置或修改行为时，字节码设计模式可以提供一种灵活的方式。它允许将行为表示为字节码指令，以便在需要时进行调整和修改，而无需修改源代码。 可配置性和可扩展性要求：如果系统需要具有高度可配置和可扩展的行为逻辑，字节码设计模式可以提供一种解决方案。通过将行为表示为字节码指令和相关数据，开发人员可以轻松地定义和管理不同的行为模块，并在不同的上下文中重复使用这些模块。 脚本引擎和动态语言实现：字节码设计模式可以用于实现脚本引擎或支持动态语言的运行时环境。它可以将脚本行为表示为字节码指令，从而提供动态性、灵活性和执行效率。 模拟和仿真系统：在模拟和仿真系统中，字节码设计模式可以用于定义和执行模拟器的行为。通过使用字节码指令来表示各种操作和行为，可以实现对特定系统或环境的准确模拟。 编译器和优化器开发：字节码设计模式可用于开发编译器、优化器和即时编译器。它提供了一种将源代码转换为字节码指令，并在运行时进行优化和执行的方式，以提高程序的性能和效率。 总的来说，字节码设计模式在需要动态性、灵活性、可配置性和可扩展性的场景中都有应用价值。它可以用于开发各种类型的系统，包括游戏引擎、脚本引擎、模拟器、编译器、优化器等。","title":"Java设计模式：Bytecode"},{"content":"如果您快速搜索如何使用 JSON Web Tokens 在 Spring Boot 中保护 REST API，您会发现很多相同的结果。这些结果包含一种方法，该方法涉及编写自定义过滤器链并引入第三方库来编码和解码 JWT。\n在看完这些令人费解且令人困惑的教程后，我说必须有一种更简单的方法来做到这一点。我做了任何直接接触 Spring Security 团队的人都会做的事情，我向他们寻求帮助。他们告诉我，Spring Security 确实使用 oAuth2 资源服务器内置了对 JWT 的支持。\n在本教程中，您将学习如何使用 JSON Web Tokens (JWT) 和 Spring Security 来保护您的 API。我并不是说这种方法无论如何都很容易，但对我来说，它比其他选择更有意义。\nGithub 存储库\n应用架构 在我们开始编写一些代码之前，我想确保我们对于我们正在构建的内容都达成共识。在下面的示例中，您有一个客户端应用程序，它可以是一个简单的命令行应用程序、一个用 Angular 或 Vue 等编写的完整前端应用程序，或者系统中的其他一些服务。\n该客户端应用程序将调用使用 Spring Boot 编写的服务器应用程序，该应用程序通过 REST API 公开数据。在下面的示例中，它是一个整体，但如果您有分布式架构，则同样适用。当前有 3 个 REST 控制器公开资源产品、订单和客户。\n您要做的是保护所有资源，以便当客户端调用 REST API 时，客户端将收到 401（未经授权），这意味着客户端请求尚未完成，因为它缺少所请求资源的有效身份验证凭据。\nJSON 网络令牌 (JWT) JSON Web 令牌是一种开放方法，用于在两方之间安全地表示声明。 JWT 是一组声明（JSON 属性-值对），它们共同构成一个 JSON 对象。它由三部分组成：\nHeader: 由两个属性组成：{ \u0026ldquo;alg\u0026rdquo;: \u0026ldquo;HS256\u0026rdquo;, \u0026ldquo;typ\u0026rdquo;: \u0026ldquo;JWT\u0026rdquo; }。 alg 是用于加密 JWT 的算法。 Payload: 这是存储要发送的数据的地方；该数据存储为 JSON 属性-值对。 Signature: 这是通过加密创建的，使用标头中指定的算法：（i）base64Url 编码的标头，（ii）base64Url 编码的有效负载，以及（iii）秘密（或私钥）： HMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret|privateKey) 最终的 JWT 由三部分组成。每个都是 base64Url 编码的，并且与下一个之间用点分隔。有关更多详细信息，请参阅 openid.net 和 jwt.io 网站。\n您将引入一个新的身份验证控制器，客户端可以使用其身份验证凭据（用户名 + 密码）向该控制器发出请求，并且当成功通过身份验证时，服务将返回 JWT。\n然后，客户端将存储 JWT，并且每个后续请求将通过 Authorization 标头传递它。当服务器应用程序收到带有 JWT 的请求时，它将验证它是否是有效令牌，如果是，则允许请求继续。\n入门 首先，您将前往 start.spring.io 并创建一个新项目。填写项目的元数据并添加以下依赖项：\nSpring Web oAuth2 Resource Server oAuth2 Spring Configuration Processor 这将在您的 pom.xml 中生成以下依赖项\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2-resource-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-configuration-processor\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; 我知道你在想什么，Spring Security 怎么样？如果您深入研究 spring-boot-starter-oauth2-resource-server ，您会发现它包含 Spring Security Starter，其中包含您需要的一切。\nREST API 您需要做的第一件事是创建一个您想要保护的 REST API。出于演示目的并保持简单，使用返回字符串的单个方法在 controller 包中创建 HomeController 。请求映射处理程序方法可以接受一系列参数，其中之一是 java.security.Principal 。这将允许您打印出当前经过身份验证的用户的用户名。\nSpring Security 采用默认安全的安全方法。这意味着，如果您启动应用程序并尝试访问 http://localhost:8080，您将被重定向到登录页面。如果您想登录，可以输入用户名 user ，密码将生成并应在控制台输出中列出。\n@RestController public class HomeController { @GetMapping public String home(Principal principal) { return \u0026#34;Hello, \u0026#34; + principal.getName(); } } SPRING 安全配置 默认的安全配置足以让您启动并运行，但您需要提供自己的安全配置来满足应用程序的需求。过去，您可以扩展 WebSecurityConfigurerAdapter ，但这在 Spring Security 5.7.x 中已被弃用。如果您有兴趣了解有关此更改的更多信息，可以查看本教程。\n首先，在 config 包中创建一个名为 SecurityConfig 的新类。该类将具有以下配置：\n@Configuration @EnableWebSecurity public class SecurityConfig { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { return http .csrf(csrf -\u0026gt; csrf.disable()) // (1) .authorizeRequests( auth -\u0026gt; auth .anyRequest().authenticated() // (2) ) .sessionManagement(session -\u0026gt; session.sessionCreationPolicy(SessionCreationPolicy.STATELESS)) // (3) .httpBasic(Customizer.withDefaults()) // (4) .build(); } } 禁用跨站点请求伪造 (CSRF) 应针对应用程序中的任何请求对用户进行身份验证。 Spring Security 永远不会创建 HttpSession，也永远不会使用它来获取安全上下文。 Spring Security 的 HTTP 基本身份验证支持默认启用。但是，一旦提供任何基于 servlet 的配置，就必须显式提供 HTTP Basic。 ⚠️ 警告：在启用会话管理的同时，切勿禁用 CSRF 保护！这样做会使您面临跨站点请求伪造攻击。\n现在您已经有了自定义安全配置，您需要一个不是 Spring Boot 提供的默认用户的用户。以下配置将使用 NoOpPasswordEncoder 创建内存中用户。这是一个密码编码器，不执行任何操作，对于测试很有用，但不应在生产中使用。\n@Bean public InMemoryUserDetailsManager users() { return new InMemoryUserDetailsManager( User.withUsername(\u0026#34;dvega\u0026#34;) .password(\u0026#34;{noop}password\u0026#34;) .authorities(\u0026#34;read\u0026#34;) .build() ); } 配置新用户后，您应该能够重新启动应用程序并访问 http://localhost:8080。您将看到一个对话框，要求输入用户名和密码，如果一切正常，您应该能够使用 dvega + password 登录。\nOAUTH 2.0 资源服务器 如果您看过我之前的教程，那么您到目前为止所做的一切应该很熟悉，但我知道这不是您来这里的目的。 Spring Security 支持使用两种形式的 OAuth 2.0 不记名令牌保护端点：\nJWT Opaque Tokens 在应用程序将其权限管理委托给授权服务器（例如，Okta 或 Spring 授权服务器）的情况下，这非常方便。资源服务器可以咨询该授权服务器来授权请求 ​​。\n在本教程中，您将使用自签名 JWT，这将无需引入授权服务器。虽然这适用于本示例，但您的应用程序要求可能有所不同，因此什么时候不再接受使用自签名 JWT？我也向 Spring Security 团队提出了这个问题，并得到了一些非常好的答案。\n当您达到无法接受自签名 JWT 的权衡时。一个例子可能是您想要引入刷新令牌的时刻。\n我想补充一点，当您拥有多个服务或者您希望能够强化安全性时，不同的授权服务器更有意义（隔离像身份验证这样重要的东西可以提供价值，因为攻击面减少了）\n我们可能会花很多时间讨论授权和资源服务器。为了让本教程围绕这个主题，我将给您留下一些非常好的资源，我建议您在有时间时阅读它们。\nOAuth2 Resource Server OAuth2 Resource Server JWT Spring Authorization Server OAUTH 2 资源服务器配置 现在您已经知道什么是资源服务器以及它的用途，您需要配置一个。您可以通过设置 .oauth2ResourceServer() 在安全配置中执行此操作。这可以是自定义资源服务器配置器，或者您可以使用 Spring 提供的 OAuth2ResourceServerConfigurer 类。\nOAuth2ResourceServerConfigurer 是 OAuth 2.0 资源服务器支持的 AbstractHttpConfigurer 。默认情况下，这会连接一个 BearerTokenAuthenticationFilter ，它可用于解析对承载令牌的请求并进行身份验证尝试。\n该配置类有以下可用选项：\naccessDeniedHandler - 自定义处理拒绝访问错误的方式。 authenticationEntryPoint - 自定义如何处理身份验证失败。 bearerTokenResolver - 自定义如何从请求中解析承载令牌。 jwt(Customizer) - 启用 Jwt 编码的不记名令牌支持。 opaqueToken(Customizer) -启用不透明的不记名令牌支持。 您将使用 JWT，因此配置选项可以使用方法引用，并且看起来像 OAuth2ResourceServerConfigurer::jwt\n@Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { return http .csrf(csrf -\u0026gt; csrf.disable()) .authorizeRequests( auth -\u0026gt; auth .anyRequest().authenticated() ) .oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt) .sessionManagement(session -\u0026gt; session.sessionCreationPolicy(SessionCreationPolicy.STATELESS)) .httpBasic(withDefaults()) .build(); } 当您使用 JWT 定制器时，您需要提供以下其中一项：\n通过 OAuth2ResourceServerConfigurer.JwtConfigurer.jwkSetUri 提供 Jwk Set Uri 通过 OAuth2ResourceServerConfigurer.JwtConfigurer.decoder 提供 JwtDecoder 实例 公开 JwtDecoder bean。 如果您尝试运行该应用程序而不提供上述选项之一，您将收到以下错误：\nDescription: Parameter 0 of method setFilterChains in org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration required a bean of type \u0026#39;org.springframework.security.oauth2.jwt.JwtDecoder\u0026#39; that could not be found. Action: Consider defining a bean of type \u0026#39;org.springframework.security.oauth2.jwt.JwtDecoder\u0026#39; in your configuration. 签署 JSON 网络令牌 下一步是创建一个新的 JwtDecoder bean，但我认为我们需要讨论一下我们将在这里做什么。正如您之前了解到的，JWT 由 3 个部分组成：标头、有效负载和签名。签名是通过加密标头+有效负载和秘密（或私钥）来创建的。\nJWT 可以使用对称密钥（共享密钥）或非对称密钥（私有-公共对的私有密钥）进行加密。\n对称密钥：相同的密钥用于加密（创建 JWT 时）和解密（MobileTogether Server 使用该密钥来验证 JWT）。对称密钥（也称为共享密钥）作为设置存储在 MobileTogether Server 中。有关使用对称密钥的详细信息，请参阅对称密钥：共享密钥。 非对称密钥：加密（私钥）和解密（公钥）使用不同的密钥。公钥作为设置存储在 MobileTogether 服务器中，以便可以验证 JWT。有关对 JWT 使用非对称加密的信息，请参阅非对称密钥：公钥。 每种方法都有优点/缺点，但通常建议您使用非对称密钥，因此这就是您在此处采用的方法。\n公钥和私钥 您将创建一个公钥/私钥对。您可以通过代码来完成此操作，但我认为如果您在这里手动执行此操作可能会更有意义。我将在 /src/main/rescurces/certs 下的新文件夹中创建它们。我将使用默认安装在 macOS 上的 OpenSSL，但您应该能够在您使用的任何操作系统上安装它。\n通常情况下，您可以运行前两个命令。第三条命令的原因是私钥需要采用 PEM 编码的 PKCS#8 格式。切换到该 certs 目录并分别运行以下每个命令。\n# create rsa key pair openssl genrsa -out keypair.pem 2048 # extract public key openssl rsa -in keypair.pem -pubout -out public.pem # create private key in PKCS#8 format openssl pkcs8 -topk8 -inform PEM -outform PEM -nocrypt -in keypair.pem -out private.pem 如果一切运行没有错误并且您同时拥有公钥和私钥，则可以删除 keypair.pem\nJWTDECODER 公钥和私钥就位后，您可以将注意力集中到定义 JwtDecoder bean 上。首先，在 config 包中创建一个名为 RsaKeyProperties 的新记录类，这将用于外部化公钥和私钥。\n@ConfigurationProperties(prefix = \u0026#34;rsa\u0026#34;) public record RsaKeyProperties(RSAPublicKey publicKey, RSAPrivateKey privateKey) { } 如果您运行构建并打开 application.properties ，您应该获得私钥和公钥配置的 IntelliSense。添加以下配置，以便您的应用程序可以找到您的密钥。\nrsa.private-key=classpath:certs/private.pem rsa.public-key=classpath:certs/public.pem 接下来，您需要在主类上启用配置属性：\n@SpringBootApplication @EnableConfigurationProperties(RsaKeyProperties.class) public class JwtDemoApplication { public static void main(String[] args) { SpringApplication.run(JwtDemoApplication.class, args); } } 回到 SecurityConfig ，您可以获取自动装配的实例：\n@Configuration @EnableWebSecurity public class SecurityConfig { private final RsaKeyProperties rsaKeys; public SecurityConfig(RsaKeyProperties rsaKeys) { this.rsaKeys = rsaKeys; } 现在您可以使用公钥创建 JwtDecoder 。这是您通常需要引入第三方库的事情，但您不需要这样做。资源服务器为您带来的依赖项之一是 ``spring-security-oauth2-jose`，它包含一个名为 Nimbus Jose JWT 的库。您可以使用刚刚创建的公钥返回 Nimbus JWT 解码器。\n@Bean JwtDecoder jwtDecoder() { return NimbusJwtDecoder.withPublicKey(rsaKeys.publicKey()).build(); } 此时，您应该能够运行该应用程序而不会出现任何错误。\n身份验证控制器和令牌服务 您已准备好密钥并定义了解码器，这是一种破译 JWT 的方法。如果您还记得之前的架构图，用户将需要使用用户名和密码登录。如果他们通过身份验证，您将生成一个新的 JSON Web 令牌并将其在响应中发回。\n为此，您首先需要创建一个 JwtEncoder 类型的 bean，并且可以在 SecurityConfig 中执行此操作。编码器将用于将我们之前了解的签名编码为令牌，并使用我们的私钥对其进行签名。\n@Bean JwtEncoder jwtEncoder() { JWK jwk = new RSAKey.Builder(rsaKeys.publicKey()).privateKey(rsaKeys.privateKey()).build(); JWKSource\u0026lt;SecurityContext\u0026gt; jwks = new ImmutableJWKSet\u0026lt;\u0026gt;(new JWKSet(jwk)); return new NimbusJwtEncoder(jwks); } 您可以直接在身份验证控制器中使用编码器，但我觉得您应该将其提取到服务层。在名为 service 的新包中创建一个名为 TokenService 的新类，该类将使用新的 JwtEncoder 生成令牌。在以下示例中，令牌将在 1 小时后过期，但您可以调整它以满足您的需要。\n@Service public class TokenService { private final JwtEncoder encoder; public TokenService(JwtEncoder encoder) { this.encoder = encoder; } public String generateToken(Authentication authentication) { Instant now = Instant.now(); String scope = authentication.getAuthorities().stream() .map(GrantedAuthority::getAuthority) .collect(Collectors.joining(\u0026#34; \u0026#34;)); JwtClaimsSet claims = JwtClaimsSet.builder() .issuer(\u0026#34;self\u0026#34;) .issuedAt(now) .expiresAt(now.plus(1, ChronoUnit.HOURS)) .subject(authentication.getName()) .claim(\u0026#34;scope\u0026#34;, scope) .build(); return this.encoder.encode(JwtEncoderParameters.from(claims)).getTokenValue(); } } 接下来在 controller 包中创建一个名为 AuthController 的新控制器。这将包含一个 POST 方法，该方法将使用新的令牌服务为经过身份验证的用户生成令牌。正如您所看到的，有一些用于调试目的的日志记录，以便在开发中您将看到用户请求 JWT 和创建的令牌。\n@RestController public class AuthController { private static final Logger LOG = LoggerFactory.getLogger(AuthController.class); private final TokenService tokenService; public AuthController(TokenService tokenService) { this.tokenService = tokenService; } @PostMapping(\u0026#34;/token\u0026#34;) public String token(Authentication authentication) { LOG.debug(\u0026#34;Token requested for user: \u0026#39;{}\u0026#39;\u0026#34;, authentication.getName()); String token = tokenService.generateToken(authentication); LOG.debug(\u0026#34;Token granted: {}\u0026#34;, token); return token; } } 如果一切都正确完成，您应该能够毫无错误地启动您的应用程序。\nSPRING 安全测试 这样，您应该使用 JWT 保护您的根路径。现在您只需要测试一下即可。\n手动测试 您可以通过多种方法手动测试这一点，但在本教程中，我将向您展示 2.\nPostman\n测试这一点的一个简单方法是使用 Postman 等工具。如果您向令牌端点创建新的 POST 请求，您可以从“授权”选项卡中选择“基本身份验证”并输入您的凭据。如果一切正常，您将在响应中返回生成的 JWT。\n复制 JWT 并为 http://localhost:8080 创建新的 GET 请求。转到“授权”选项卡并选择“承载令牌”并粘贴生成的令牌。如果您发送请求，您应该取回从 HomeController 中的 home 方法返回的字符串。\n命令行\n我非常喜欢命令行和 httpie 工具。它简化了在终端中测试 API 的命令的编写。您可以使用以下命令使用您的凭据向令牌端点发送请求：\nhttp POST :8080/token --auth dvega:password -v -v 参数将打印请求和响应\n响应将包含生成的 JWT 令牌。如果您在没有授权标头或没有正确令牌的情况下向根路径发出请求，您将收到 401（拒绝）响应。但是，如果您以正确的格式包含 Authorization 标头，您将获得从 HomeController 中的 home 方法返回的字符串。\nhttp :8080 \u0026#39;Authorization: Bearer JWT_TOKEN_HERE\u0026#39; 自动化测试 手动测试很棒，因为您可以看到一切都按预期运行。但是，您将需要一些适当的自动化测试，以便在进行更改时您可以确信没有任何内容破坏现有功能。我不会对此进行过多讨论，但我想为您提供一个简单的示例来说明如何编写此类测试。\n当您引入资源服务器时，有一个依赖项没有引入，那就是 spring-security-test 。在编写任何与安全相关的测试之前，您需要将其添加到您的 pom.xml 中。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 当您编写仅关注 Web 层配置的切片测试时，服务类将不会添加到应用程序上下文中。为了使一切正常工作，您需要手动导入 SercurityConfig 和 TokenService 类。这些测试应该是不言自明的，但如果您希望我进行这些测试，请联系我并告诉我。\n@WebMvcTest({HomeController.class, AuthController.class}) @Import({SecurityConfig.class, TokenService.class}) class HomeControllerTest { @Autowired MockMvc mvc; @Test void rootWhenUnauthenticatedThen401() throws Exception { this.mvc.perform(get(\u0026#34;/\u0026#34;)) .andExpect(status().isUnauthorized()); } @Test void rootWhenAuthenticatedThenSaysHelloUser() throws Exception { MvcResult result = this.mvc.perform(post(\u0026#34;/token\u0026#34;) .with(httpBasic(\u0026#34;dvega\u0026#34;, \u0026#34;password\u0026#34;))) .andExpect(status().isOk()) .andReturn(); String token = result.getResponse().getContentAsString(); this.mvc.perform(get(\u0026#34;/\u0026#34;) .header(\u0026#34;Authorization\u0026#34;, \u0026#34;Bearer \u0026#34; + token)) .andExpect(content().string(\u0026#34;Hello, dvega\u0026#34;)); } @Test @WithMockUser public void rootWithMockUserStatusIsOK() throws Exception { this.mvc.perform(get(\u0026#34;/\u0026#34;)).andExpect(status().isOk()); } } 结论 当我开始创建本教程时，我的全部目标是让您知道有一种更简单的方法可以使用 JWT 来保护您的 API。我希望现在您知道 Spring Security 使用 oAuth2 资源服务器内置了对 JSON Web 令牌的支持，您可以在下一个项目中使用它。这只是如何在 Spring Boot 应用程序中使用 JWT 的起跑线，绝不是终点线。如果您对具体配置有疑问，请与我联系。\n我感到非常幸运，能够在 VMware 这样的公司工作，并且能够接触到一些非常聪明的人。当您与一群总是愿意分享知识和提供帮助的优秀人士一起工作时，这种访问就意味着更重要。我要特别感谢以下帮助我将这些内容整合在一起的人：\nSteve Riesenberg Rob Winch Josh Cummings Toshiaki Maki ","permalink":"https://blog.chensoul.cc/posts/2023/09/19/spring-security-jwt/","summary":"如果您快速搜索如何使用 JSON Web Tokens 在 Spring Boot 中保护 REST API，您会发现很多相同的结果。这些结果包含一种方法，该方法涉及编写自定义过滤器链并引入第三方库来编码和解码 JWT。\n在看完这些令人费解且令人困惑的教程后，我说必须有一种更简单的方法来做到这一点。我做了任何直接接触 Spring Security 团队的人都会做的事情，我向他们寻求帮助。他们告诉我，Spring Security 确实使用 oAuth2 资源服务器内置了对 JWT 的支持。\n在本教程中，您将学习如何使用 JSON Web Tokens (JWT) 和 Spring Security 来保护您的 API。我并不是说这种方法无论如何都很容易，但对我来说，它比其他选择更有意义。\nGithub 存储库\n应用架构 在我们开始编写一些代码之前，我想确保我们对于我们正在构建的内容都达成共识。在下面的示例中，您有一个客户端应用程序，它可以是一个简单的命令行应用程序、一个用 Angular 或 Vue 等编写的完整前端应用程序，或者系统中的其他一些服务。\n该客户端应用程序将调用使用 Spring Boot 编写的服务器应用程序，该应用程序通过 REST API 公开数据。在下面的示例中，它是一个整体，但如果您有分布式架构，则同样适用。当前有 3 个 REST 控制器公开资源产品、订单和客户。\n您要做的是保护所有资源，以便当客户端调用 REST API 时，客户端将收到 401（未经授权），这意味着客户端请求尚未完成，因为它缺少所请求资源的有效身份验证凭据。\nJSON 网络令牌 (JWT) JSON Web 令牌是一种开放方法，用于在两方之间安全地表示声明。 JWT 是一组声明（JSON 属性-值对），它们共同构成一个 JSON 对象。它由三部分组成：\nHeader: 由两个属性组成：{ \u0026ldquo;alg\u0026rdquo;: \u0026ldquo;HS256\u0026rdquo;, \u0026ldquo;typ\u0026rdquo;: \u0026ldquo;JWT\u0026rdquo; }。 alg 是用于加密 JWT 的算法。 Payload: 这是存储要发送的数据的地方；该数据存储为 JSON 属性-值对。 Signature: 这是通过加密创建的，使用标头中指定的算法：（i）base64Url 编码的标头，（ii）base64Url 编码的有效负载，以及（iii）秘密（或私钥）： HMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret|privateKey) 最终的 JWT 由三部分组成。每个都是 base64Url 编码的，并且与下一个之间用点分隔。有关更多详细信息，请参阅 openid.net 和 jwt.io 网站。","title":"[译]SPRING BOOT JWT - 如何使用 SPRING SECURITY 和 JSON WEB 令牌保护您的 REST API"},{"content":"免责声明：Spring Security 5+ 已发布 OAuth JWT 支持。建议使用最新版本的 OAuth 来支持 JWT，而不是使用自定义安全性或过滤器。\nSpring 被认为是 Java 生态系统中值得信赖的框架，并且被广泛使用。将 Spring 称为框架不再有效，因为它更多的是涵盖各种框架的总括术语。其中一个框架是 Spring Security，它是一个功能强大且可定制的身份验证和授权框架。它被认为是保护基于 Spring 的应用程序的事实标准，因此，如果您希望实现 Spring JWT 令牌解决方案，那么将其基于 Spring Security 是有意义的。\n尽管它很受欢迎，但我必须承认，当涉及到单页应用程序时，Spring 的配置并不简单和直接。我怀疑原因是它更多地是作为一个面向应用程序的 MVC 框架开始的，其中网页渲染发生在服务器端，并且通信是基于会话的。\n如果后端基于 Java 和 Spring，那么使用 Spring Security 和 JWT 进行身份验证/授权并将其配置为无状态通信是有意义的。虽然有很多文章解释了这是如何完成的，但对我来说，第一次设置它仍然令人沮丧，我必须阅读并总结来自多个来源的信息。这就是我决定编写这个 Spring Security 教程的原因，我将在其中尝试总结并涵盖您在配置过程中可能遇到的所有必需的微妙细节和缺陷。\n术语定义 在深入探讨技术细节之前，我想明确定义 Spring Security 上下文中使用的术语，以确保我们都使用相同的语言。 这些是我们需要解决的术语：\nAuthentication 验证是指根据提供的凭据验证用户身份的过程。一个常见的示例是在登录网站时输入用户名和密码。您可以将其视为对“您是谁？”这个问题的答案。 Authorization 授权是指假设用户已成功通过身份验证，则确定用户是否具有执行特定操作或读取特定数据的适当权限的过程。您可以将其视为“用户可以执行/阅读此操作吗？”问题的答案。 Principle 原则是指当前经过身份验证的用户。 Granted authority 授予权限是指经过认证的用户的权限。 Role 角色是指经过身份验证的用户的一组权限。 创建基本的 Spring 应用程序 在开始配置 Spring Security 框架之前，让我们创建一个基本的 Spring Web 应用程序。为此，我们可以使用 Spring Initializr 并生成一个模板项目。对于一个简单的 Web 应用程序，只需要 Spring Web 框架依赖就足够了：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 创建项目后，我们可以向其中添加一个简单的 REST 控制器，如下所示：\n@RestController @RequestMapping(\u0026#34;hello\u0026#34;) public class HelloRestController { @GetMapping(\u0026#34;user\u0026#34;) public String helloUser() { return \u0026#34;Hello User\u0026#34;; } @GetMapping(\u0026#34;admin\u0026#34;) public String helloAdmin() { return \u0026#34;Hello Admin\u0026#34;; } } 之后，如果我们构建并运行该项目，我们可以在 Web 浏览器中访问以下 URL：\nhttp://localhost:8080/hello/user 将返回字符串 Hello User 。 http://localhost:8080/hello/admin 将返回字符串 Hello Admin 。 现在，我们可以将 Spring Security 框架添加到我们的项目中，我们可以通过将以下依赖项添加到 pom.xml 文件中来完成此操作：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 在我们提供相应的配置之前，添加其他 Spring 框架依赖项通常不会立即对应用程序产生影响，但 Spring Security 的不同之处在于它确实会立即产生影响，这通常会让新用户感到困惑。添加后，如果我们重建并运行项目，然后尝试访问上述 URL 之一而不是查看结果，我们将被重定向到 http://localhost:8080/login 。这是默认行为，因为 Spring Security 框架要求对所有 URL 进行开箱即用的身份验证。\n为了通过身份验证，我们可以使用默认用户名 user 并在控制台中找到自动生成的密码：\nUsing generated security password: 1fc15145-dfee-4bec-a009-e32ca21c77ce 请记住，每次重新运行应用程序时密码都会更改。如果我们想改变这种行为并使密码静态，我们可以将以下配置添加到我们的 application.properties 文件中：\nspring.security.user.password=Test12345_ 现在，如果我们在登录表单中输入凭据，我们将被重定向回我们的 URL，我们将看到正确的结果。请注意，开箱即用的身份验证过程是基于会话的，如果我们想注销，可以访问以下 URL： http://localhost:8080/logout\n这种开箱即用的行为对于具有基于会话身份验证的经典 MVC Web 应用程序可能很有用，但对于单页应用程序来说，它通常没有用，因为在大多数用例中，我们有客户端渲染和基于 JWT 的无状态身份验证。在这种情况下，我们将不得不大量定制 Spring Security 框架，我们将在本文的其余部分中进行此操作。\n例如，我们将实现一个经典的书店 Web 应用程序，并创建一个后端，该后端将提供用于创建作者和书籍的 CRUD API 以及用于用户管理和身份验证的 API。\nSpring Security 架构概述 在开始自定义配置之前，我们首先讨论一下 Spring Security 身份验证在幕后是如何工作的。\n下图展示了流程并显示了如何处理身份验证请求：\n现在，让我们将此图分解为多个组件并分别讨论每个组件。\nSpring Security 过滤器链 当您将 Spring Security 框架添加到应用程序时，它会自动注册一个过滤器链来拦截所有传入请求。该链由各种过滤器组成，每个过滤器处理一个特定的用例。\n例如：\n根据配置检查请求的 URL 是否可公开访问。 如果是基于会话的身份验证，请检查用户是否已在当前会话中通过身份验证。 检查用户是否有权执行请求的操作，等等。 我想提到的一个重要细节是 Spring Security 过滤器以最低顺序注册，并且是第一个被调用的过滤器。对于某些用例，如果您想将自定义过滤器放在它们前面，则需要在它们的顺序中添加填充。这可以通过以下配置来完成：\nspring.security.filter.order=10 一旦我们将此配置添加到 application.properties 文件中，我们将在 Spring Security 过滤器前面留有 10 个自定义过滤器的空间。\n认证管理器 您可以将 AuthenticationManager 视为一个协调器，您可以在其中注册多个提供程序，并且根据请求类型，它将向正确的提供程序发送身份验证请求。\n认证提供者 AuthenticationProvider 处理特定类型的身份验证。它的接口只公开两个函数：\nauthenticate 对请求执行身份验证。 supports 检查此提供程序是否支持指定的身份验证类型。 我们在示例项目中使用的接口的一个重要实现是 DaoAuthenticationProvider ，它从 UserDetailsService 检索用户详细信息。\nUserDetailsService 用户详情服务 UserDetailsService 在 Spring 文档中被描述为加载用户特定数据的核心接口。\n在大多数用例中，身份验证提供程序根据数据库中的凭据提取用户身份信息，然后执行验证。由于这个用例非常常见，Spring 开发人员决定将其提取为一个单独的接口，公开单个函数：\nloadUserByUsername 接受用户名作为参数并返回用户身份对象。 使用 JWT 和 Spring Security 进行身份验证 在讨论了 Spring Security 框架的内部结构之后，让我们将其配置为使用 JWT 令牌进行无状态身份验证。\n要自定义 Spring Security 以供 JWT 使用，我们需要在类路径中使用 @EnableWebSecurity 注释来注释的配置类。此外，为了简化定制过程，框架公开了一个 WebSecurityConfigurerAdapter 类。我们将扩展此适配器并覆盖其两个功能，以便：\n使用正确的提供程序配置身份验证管理器 配置网络安全（公共 URL、私有 URL、授权等） @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // TODO configure authentication manager } @Override protected void configure(HttpSecurity http) throws Exception { // TODO configure web security } } 在我们的示例应用程序中，我们将用户身份存储在 MongoDB 数据库的 users 集合中。这些身份由 User 实体映射，它们的 CRUD 操作由 UserRepo Spring Data 存储库定义。\n现在，当我们接受身份验证请求时，我们需要使用提供的凭据从数据库中检索正确的身份，然后进行验证。为此，我们需要实现 UserDetailsService 接口，其定义如下：\npublic interface UserDetailsService { UserDetails loadUserByUsername(String username) throws UsernameNotFoundException; } 在这里，我们可以看到需要返回实现 UserDetails 接口的对象，并且我们的 User 实体实现了它（有关实现的详细信息，请参阅示例项目的存储库）。考虑到它仅公开单函数原型，我们可以将其视为函数式接口，并以 lambda 表达式的形式提供实现。\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { private final UserRepo userRepo; public SecurityConfig(UserRepo userRepo) { this.userRepo = userRepo; } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(username -\u0026gt; userRepo .findByUsername(username) .orElseThrow( () -\u0026gt; new UsernameNotFoundException( format(\u0026#34;User: %s, not found\u0026#34;, username) ) )); } // Details omitted for brevity } 在这里， auth.userDetailsService 函数调用将使用我们的 UserDetailsService 接口实现来启动 DaoAuthenticationProvider 实例，并将其注册到身份验证管理器中。\n除了身份验证提供程序之外，我们还需要使用正确的密码编码架构来配置身份验证管理器，该架构将用于凭据验证。为此，我们需要将 PasswordEncoder 接口的首选实现公开为 bean。\n在我们的示例项目中，我们将使用 bcrypt 密码哈希算法。\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { private final UserRepo userRepo; public SecurityConfig(UserRepo userRepo) { this.userRepo = userRepo; } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(username -\u0026gt; userRepo .findByUsername(username) .orElseThrow( () -\u0026gt; new UsernameNotFoundException( format(\u0026#34;User: %s, not found\u0026#34;, username) ) )); } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } // Details omitted for brevity } 配置身份验证管理器后，我们现在需要配置 Web 安全性。我们正在实现 REST API，需要使用 JWT 令牌进行无状态身份验证；因此，我们需要设置以下选项：\n启用 CORS 并禁用 CSRF。 将会话管理设置为无状态。 设置未授权请求异常处理程序。 设置端点的权限。 添加 JWT 令牌过滤器。 该配置的实现方式如下：\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { private final UserRepo userRepo; private final JwtTokenFilter jwtTokenFilter; public SecurityConfig(UserRepo userRepo, JwtTokenFilter jwtTokenFilter) { this.userRepo = userRepo; this.jwtTokenFilter = jwtTokenFilter; } // Details omitted for brevity @Override protected void configure(HttpSecurity http) throws Exception { // Enable CORS and disable CSRF http = http.cors().and().csrf().disable(); // Set session management to stateless http = http .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and(); // Set unauthorized requests exception handler http = http .exceptionHandling() .authenticationEntryPoint( (request, response, ex) -\u0026gt; { response.sendError( HttpServletResponse.SC_UNAUTHORIZED, ex.getMessage() ); } ) .and(); // Set permissions on endpoints http.authorizeRequests() // Our public endpoints .antMatchers(\u0026#34;/api/public/**\u0026#34;).permitAll() .antMatchers(HttpMethod.GET, \u0026#34;/api/author/**\u0026#34;).permitAll() .antMatchers(HttpMethod.POST, \u0026#34;/api/author/search\u0026#34;).permitAll() .antMatchers(HttpMethod.GET, \u0026#34;/api/book/**\u0026#34;).permitAll() .antMatchers(HttpMethod.POST, \u0026#34;/api/book/search\u0026#34;).permitAll() // Our private endpoints .anyRequest().authenticated(); // Add JWT token filter http.addFilterBefore( jwtTokenFilter, UsernamePasswordAuthenticationFilter.class ); } // Used by Spring Security if CORS is enabled. @Bean public CorsFilter corsFilter() { UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); CorsConfiguration config = new CorsConfiguration(); config.setAllowCredentials(true); config.addAllowedOrigin(\u0026#34;*\u0026#34;); config.addAllowedHeader(\u0026#34;*\u0026#34;); config.addAllowedMethod(\u0026#34;*\u0026#34;); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, config); return new CorsFilter(source); } } 请注意，我们在 Spring Security 内部 UsernamePasswordAuthenticationFilter 之前添加了 JwtTokenFilter 。我们这样做是因为此时我们需要访问用户身份来执行身份验证/授权，并且其提取发生在基于提供的 JWT 令牌的 JWT 令牌过滤器内。其实现方式如下：\n@Component public class JwtTokenFilter extends OncePerRequestFilter { private final JwtTokenUtil jwtTokenUtil; private final UserRepo userRepo; public JwtTokenFilter(JwtTokenUtil jwtTokenUtil, UserRepo userRepo) { this.jwtTokenUtil = jwtTokenUtil; this.userRepo = userRepo; } @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException { // Get authorization header and validate final String header = request.getHeader(HttpHeaders.AUTHORIZATION); if (isEmpty(header) || !header.startsWith(\u0026#34;Bearer \u0026#34;)) { chain.doFilter(request, response); return; } // Get jwt token and validate final String token = header.split(\u0026#34; \u0026#34;)[1].trim(); if (!jwtTokenUtil.validate(token)) { chain.doFilter(request, response); return; } // Get user identity and set it on the spring security context UserDetails userDetails = userRepo .findByUsername(jwtTokenUtil.getUsername(token)) .orElse(null); UsernamePasswordAuthenticationToken authentication = new UsernamePasswordAuthenticationToken( userDetails, null, userDetails == null ? List.of() : userDetails.getAuthorities() ); authentication.setDetails( new WebAuthenticationDetailsSource().buildDetails(request) ); SecurityContextHolder.getContext().setAuthentication(authentication); chain.doFilter(request, response); } } 在实现我们的登录 API 功能之前，我们还需要执行一步 - 我们需要访问身份验证管理器。默认情况下，它不可公开访问，我们需要在配置类中将其显式公开为 bean。 这可以按如下方式完成：\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { // Details omitted for brevity @Override @Bean public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } 现在，我们准备好实现我们的登录 API 函数：\n@Api(tags = \u0026#34;Authentication\u0026#34;) @RestController @RequestMapping(path = \u0026#34;api/public\u0026#34;) public class AuthApi { private final AuthenticationManager authenticationManager; private final JwtTokenUtil jwtTokenUtil; private final UserViewMapper userViewMapper; public AuthApi(AuthenticationManager authenticationManager, JwtTokenUtil jwtTokenUtil, UserViewMapper userViewMapper) { this.authenticationManager = authenticationManager; this.jwtTokenUtil = jwtTokenUtil; this.userViewMapper = userViewMapper; } @PostMapping(\u0026#34;login\u0026#34;) public ResponseEntity\u0026lt;UserView\u0026gt; login(@RequestBody @Valid AuthRequest request) { try { Authentication authenticate = authenticationManager .authenticate( new UsernamePasswordAuthenticationToken( request.getUsername(), request.getPassword() ) ); User user = (User) authenticate.getPrincipal(); return ResponseEntity.ok() .header( HttpHeaders.AUTHORIZATION, jwtTokenUtil.generateAccessToken(user) ) .body(userViewMapper.toUserView(user)); } catch (BadCredentialsException ex) { return ResponseEntity.status(HttpStatus.UNAUTHORIZED).build(); } } } 在这里，我们使用身份验证管理器验证提供的凭据，如果成功，我们将生成 JWT 令牌并将其作为响应标头与响应正文中的用户身份信息一起返回。\n使用 Spring Security 进行 JWT 授权 在上一节中，我们设置了 Spring JWT 身份验证过程并配置了公共/私有 URL。对于简单的应用程序来说，这可能已经足够了，但对于大多数实际用例，我们始终需要为用户提供基于角色的访问策略。在本章中，我们将解决这个问题并使用 Spring Security 框架建立基于角色的授权模式。\n在我们的示例应用程序中，我们定义了以下三个角色：\nUSER_ADMIN 允许我们管理应用程序用户。 AUTHOR_ADMIN 允许我们管理作者。 BOOK_ADMIN 允许我们管理书籍。 现在，我们需要将它们应用到相应的 URL：\napi/public 可公开访问。 api/admin/user 可以访问具有 USER_ADMIN 角色的用户。 api/author 可以访问具有 AUTHOR_ADMIN 角色的用户。 api/book 可以访问具有 BOOK_ADMIN 角色的用户。 Spring Security 框架为我们提供了两种设置授权模式的选项：\n基于 URL 的配置 基于注释的配置 首先，让我们看看基于 URL 的配置是如何工作的。它可以应用到 Web 安全配置中，如下所示：\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { // Details omitted for brevity @Override protected void configure(HttpSecurity http) throws Exception { // Enable CORS and disable CSRF http = http.cors().and().csrf().disable(); // Set session management to stateless http = http .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and(); // Set unauthorized requests exception handler http = http .exceptionHandling() .authenticationEntryPoint( (request, response, ex) -\u0026gt; { response.sendError( HttpServletResponse.SC_UNAUTHORIZED, ex.getMessage() ); } ) .and(); // Set permissions on endpoints http.authorizeRequests() // Our public endpoints .antMatchers(\u0026#34;/api/public/**\u0026#34;).permitAll() .antMatchers(HttpMethod.GET, \u0026#34;/api/author/**\u0026#34;).permitAll() .antMatchers(HttpMethod.POST, \u0026#34;/api/author/search\u0026#34;).permitAll() .antMatchers(HttpMethod.GET, \u0026#34;/api/book/**\u0026#34;).permitAll() .antMatchers(HttpMethod.POST, \u0026#34;/api/book/search\u0026#34;).permitAll() // Our private endpoints .antMatchers(\u0026#34;/api/admin/user/**\u0026#34;).hasRole(Role.USER_ADMIN) .antMatchers(\u0026#34;/api/author/**\u0026#34;).hasRole(Role.AUTHOR_ADMIN) .antMatchers(\u0026#34;/api/book/**\u0026#34;).hasRole(Role.BOOK_ADMIN) .anyRequest().authenticated(); // Add JWT token filter http.addFilterBefore( jwtTokenFilter, UsernamePasswordAuthenticationFilter.class ); } // Details omitted for brevity } 正如您所看到的，这种方法简单明了，但有一个缺点。我们的应用程序中的授权模式可能很复杂，如果我们在一个地方定义所有规则，它将变得非常大、复杂且难以阅读。因此，我通常更喜欢使用基于注释的配置。\nSpring Security 框架为 Web 安全定义了以下注释：\n@PreAuthorize 支持 Spring 表达式语言，用于在执行方法之前提供基于表达式的访问控制。 @PostAuthorize 支持 Spring 表达式语言，用于在执行方法后提供基于表达式的访问控制（提供访问方法结果的能力）。 @PreFilter 支持 Spring 表达式语言，用于在根据我们定义的自定义安全规则执行方法之前过滤集合或数组。 @PostFilter 支持 Spring 表达式语言，用于根据我们定义的自定义安全规则过滤执行方法后返回的集合或数组（提供访问方法结果的能力）。 @Secured 不支持 Spring 表达式语言，用于指定方法上的角色列表。 @RolesAllowed 不支持 Spring 表达式语言，是 JSR 250 中 @Secured 注释的等效注释。 这些注释默认情况下处于禁用状态，可以在我们的应用程序中启用，如下所示：\n@EnableWebSecurity @EnableGlobalMethodSecurity( securedEnabled = true, jsr250Enabled = true, prePostEnabled = true ) public class SecurityConfig extends WebSecurityConfigurerAdapter { // Details omitted for brevity } securedEnabled = true 启用 @Secured 注释。 jsr250Enabled = true 启用 @RolesAllowed 注释。 prePostEnabled = true 启用 @PreAuthorize 、 @PostAuthorize 、 @PreFilter 、 @PostFilter 注释。\n启用它们后，我们可以在 API 端点上强制执行基于角色的访问策略，如下所示：\n@Api(tags = \u0026#34;UserAdmin\u0026#34;) @RestController @RequestMapping(path = \u0026#34;api/admin/user\u0026#34;) @RolesAllowed(Role.USER_ADMIN) public class UserAdminApi { // Details omitted for brevity } @Api(tags = \u0026#34;Author\u0026#34;) @RestController @RequestMapping(path = \u0026#34;api/author\u0026#34;) public class AuthorApi { // Details omitted for brevity @RolesAllowed(Role.AUTHOR_ADMIN) @PostMapping public void create() { } @RolesAllowed(Role.AUTHOR_ADMIN) @PutMapping(\u0026#34;{id}\u0026#34;) public void edit() { } @RolesAllowed(Role.AUTHOR_ADMIN) @DeleteMapping(\u0026#34;{id}\u0026#34;) public void delete() { } @GetMapping(\u0026#34;{id}\u0026#34;) public void get() { } @GetMapping(\u0026#34;{id}/book\u0026#34;) public void getBooks() { } @PostMapping(\u0026#34;search\u0026#34;) public void search() { } } @Api(tags = \u0026#34;Book\u0026#34;) @RestController @RequestMapping(path = \u0026#34;api/book\u0026#34;) public class BookApi { // Details omitted for brevity @RolesAllowed(Role.BOOK_ADMIN) @PostMapping public BookView create() { } @RolesAllowed(Role.BOOK_ADMIN) @PutMapping(\u0026#34;{id}\u0026#34;) public void edit() { } @RolesAllowed(Role.BOOK_ADMIN) @DeleteMapping(\u0026#34;{id}\u0026#34;) public void delete() { } @GetMapping(\u0026#34;{id}\u0026#34;) public void get() { } @GetMapping(\u0026#34;{id}/author\u0026#34;) public void getAuthors() { } @PostMapping(\u0026#34;search\u0026#34;) public void search() { } } 请注意，安全注释可以在类级别和方法级别上提供。\n演示的示例很简单，并不代表真实场景，但 Spring Security 提供了一组丰富的注释，如果您选择使用它们，您可以处理复杂的授权模式。\n角色名称默认前缀 在这个单独的小节中，我想强调一个让很多新用户感到困惑的更微妙的细节。\nSpring Security 框架区分两个术语：\nAuthority 代表个人权限。 Role 代表一组权限。 两者都可以用一个名为 GrantedAuthority 的接口来表示，然后使用 Spring Security 注释中的 Spring 表达式语言进行检查，如下所示：\nAuthority: @PreAuthorize(“hasAuthority(‘EDIT_BOOK’)”) Role: @PreAuthorize(“hasRole(‘BOOK_ADMIN’)”) 为了使这两个术语之间的区别更加明确，Spring Security 框架默认在角色名称中添加 ROLE_ 前缀。因此，它不会检查名为 BOOK_ADMIN 的角色，而是检查 ROLE_BOOK_ADMIN 。\n就我个人而言，我发现这种行为令人困惑，并且更喜欢在我的应用程序中禁用它。可以在 Spring Security 配置中禁用它，如下所示：\n@EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { // Details omitted for brevity @Bean GrantedAuthorityDefaults grantedAuthorityDefaults() { return new GrantedAuthorityDefaults(\u0026#34;\u0026#34;); // Remove the ROLE_ prefix } } 测试我们的 Spring Security JWT 解决方案 要在使用 Spring Security 框架时通过单元测试或集成测试来测试端点，我们需要添加 spring-security-test 依赖项以及 spring-boot-starter-test 。我们的 pom.xml 构建文件将如下所示：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 这种依赖关系使我们能够访问一些注释，这些注释可用于向我们的测试函数添加安全上下文。\nThese annotations are: 这些注释是：\n@WithMockUser 可以添加到测试方法中以模拟使用模拟用户运行。 @WithUserDetails 可以添加到测试方法中，以模拟使用从 UserDetailsService 返回的 UserDetails 运行。 @WithAnonymousUser 可以添加到测试方法中以模拟匿名用户的运行。当用户想要以特定用户身份运行大部分测试并覆盖一些匿名方法时，这非常有用。 @WithSecurityContext 决定使用什么 SecurityContext ，上面描述的所有三个注释都基于它。如果我们有特定的用例，我们可以创建自己的注释，使用 @WithSecurityContext 来创建我们想要的任何 SecurityContext 。它的讨论超出了我们的 Spring Security 教程的范围，请参阅 Spring Security 文档以获取更多详细信息。 对特定用户运行测试的最简单方法是使用 @WithMockUser 注释。我们可以用它创建一个模拟用户并运行测试，如下所示：\n@Test @WithMockUser(username=\u0026#34;customUsername@example.io\u0026#34;, roles={\u0026#34;USER_ADMIN\u0026#34;}) public void test() { // Details omitted for brevity } 不过，这种方法有一些缺点。首先，模拟用户不存在，如果运行集成测试，稍后从数据库查询用户信息，测试将失败。其次，mock user 是 org.springframework.security.core.userdetails.User 类的实例，它是 Spring 框架对 UserDetails 接口的内部实现，如果我们有自己的实现，这可能会导致后面的冲突，在测试执行期间。\n如果前面的缺点阻碍了我们的应用程序，那么 @WithUserDetails 注释就是正确的选择。当我们有自定义 UserDetails 和 UserDetailsService 实现时使用它。它假设用户存在，因此我们必须在数据库中创建实际行或在运行测试之前提供 UserDetailsService 模拟实例。\n我们可以这样使用这个注解：\n@Test @WithUserDetails(\u0026#34;customUsername@example.io\u0026#34;) public void test() { // Details omitted for brevity } 这是我们示例项目集成测试中的首选注释，因为我们有上述接口的自定义实现。\n使用 @WithAnonymousUser 允许以匿名用户身份运行。当您希望使用特定用户运行大多数测试但以匿名用户身份运行一些测试时，这尤其方便。例如，以下将使用模拟用户运行 test1 和 test2 测试用例，并使用匿名用户运行 test3：\n@SpringBootTest @AutoConfigureMockMvc @WithMockUser public class WithUserClassLevelAuthenticationTests { @Test public void test1() { // Details omitted for brevity } @Test public void test2() { // Details omitted for brevity } @Test @WithAnonymousUser public void test3() throws Exception { // Details omitted for brevity } } 征服 Spring Security JWT 学习曲线 最后，我想提一下，Spring Security 框架可能不会赢得任何选美比赛，而且它的学习曲线肯定很陡峭。我遇到过很多情况，由于其初始配置的复杂性，它被一些自行开发的解决方案所取代。但是，一旦开发人员了解其内部结构并设法设置初始配置，它的使用就会变得相对简单。\n在本 Spring Security 教程中，我尝试演示配置的所有微妙细节，希望您会发现这些示例很有用。有关完整的代码示例，请参阅我的示例 Spring Security 项目的 Git 存储库。\n原文链接：https://www.toptal.com/spring/spring-security-tutorial\n","permalink":"https://blog.chensoul.cc/posts/2023/09/19/spring-security-tutorial/","summary":"免责声明：Spring Security 5+ 已发布 OAuth JWT 支持。建议使用最新版本的 OAuth 来支持 JWT，而不是使用自定义安全性或过滤器。\nSpring 被认为是 Java 生态系统中值得信赖的框架，并且被广泛使用。将 Spring 称为框架不再有效，因为它更多的是涵盖各种框架的总括术语。其中一个框架是 Spring Security，它是一个功能强大且可定制的身份验证和授权框架。它被认为是保护基于 Spring 的应用程序的事实标准，因此，如果您希望实现 Spring JWT 令牌解决方案，那么将其基于 Spring Security 是有意义的。\n尽管它很受欢迎，但我必须承认，当涉及到单页应用程序时，Spring 的配置并不简单和直接。我怀疑原因是它更多地是作为一个面向应用程序的 MVC 框架开始的，其中网页渲染发生在服务器端，并且通信是基于会话的。\n如果后端基于 Java 和 Spring，那么使用 Spring Security 和 JWT 进行身份验证/授权并将其配置为无状态通信是有意义的。虽然有很多文章解释了这是如何完成的，但对我来说，第一次设置它仍然令人沮丧，我必须阅读并总结来自多个来源的信息。这就是我决定编写这个 Spring Security 教程的原因，我将在其中尝试总结并涵盖您在配置过程中可能遇到的所有必需的微妙细节和缺陷。\n术语定义 在深入探讨技术细节之前，我想明确定义 Spring Security 上下文中使用的术语，以确保我们都使用相同的语言。 这些是我们需要解决的术语：\nAuthentication 验证是指根据提供的凭据验证用户身份的过程。一个常见的示例是在登录网站时输入用户名和密码。您可以将其视为对“您是谁？”这个问题的答案。 Authorization 授权是指假设用户已成功通过身份验证，则确定用户是否具有执行特定操作或读取特定数据的适当权限的过程。您可以将其视为“用户可以执行/阅读此操作吗？”问题的答案。 Principle 原则是指当前经过身份验证的用户。 Granted authority 授予权限是指经过认证的用户的权限。 Role 角色是指经过身份验证的用户的一组权限。 创建基本的 Spring 应用程序 在开始配置 Spring Security 框架之前，让我们创建一个基本的 Spring Web 应用程序。为此，我们可以使用 Spring Initializr 并生成一个模板项目。对于一个简单的 Web 应用程序，只需要 Spring Web 框架依赖就足够了：\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 创建项目后，我们可以向其中添加一个简单的 REST 控制器，如下所示：\n@RestController @RequestMapping(\u0026#34;hello\u0026#34;) public class HelloRestController { @GetMapping(\u0026#34;user\u0026#34;) public String helloUser() { return \u0026#34;Hello User\u0026#34;; } @GetMapping(\u0026#34;admin\u0026#34;) public String helloAdmin() { return \u0026#34;Hello Admin\u0026#34;; } } 之后，如果我们构建并运行该项目，我们可以在 Web 浏览器中访问以下 URL：","title":"[译]Spring Security 与 JWT for REST API"},{"content":"本文主要介绍 Builder 构造器模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 构造器模式（Builder Pattern）是一种创建型设计模式，用于将复杂对象的构建过程与其表示分离，从而可以使用相同的构建过程创建不同的表示。\n在构造器模式中，通常有两个主要角色：产品（Product）和建造者（Builder）。产品是最终构建的对象，而建造者负责构建产品。\n以下是构造器模式的类图示例：\n+-------------------+ +----------------------+ | Director | | Builder | +-------------------+ +----------------------+ | construct() | | buildPartA() | | | | buildPartB() | +-------------------+ | getResult() | +----------+-----------+ | v +----------+-----------+ | Product | +----------------------+ | partA | | partB | +----------------------+ 在上述类图中，Director（指导者）负责定义构建产品的顺序和方式，而Builder（建造者）负责实际构建产品的具体步骤。Product（产品）是最终构建的对象。\n以下是一个简单的示例，演示如何使用构造器模式创建一个角色生成器的例子：\n// 产品类 public class Character { private String profession; private String name; private String hairColor; private String weapon; // 构造器私有化，只能通过建造者创建对象 private Character() {} // Getters public String getProfession() { return profession; } public String getName() { return name; } public String getHairColor() { return hairColor; } public String getWeapon() { return weapon; } // 建造者类 public static class CharacterBuilder { private Character character; public CharacterBuilder() { character = new Character(); } public CharacterBuilder withProfession(String profession) { character.profession = profession; return this; } public CharacterBuilder withName(String name) { character.name = name; return this; } public CharacterBuilder withHairColor(String hairColor) { character.hairColor = hairColor; return this; } public CharacterBuilder withWeapon(String weapon) { character.weapon = weapon; return this; } public Character build() { return character; } } } // 使用示例 public class BuilderExample { public static void main(String[] args) { Character character = new Character.CharacterBuilder() .withProfession(\u0026#34;Warrior\u0026#34;) .withName(\u0026#34;Conan\u0026#34;) .withHairColor(\u0026#34;Black\u0026#34;) .withWeapon(\u0026#34;Sword\u0026#34;) .build(); System.out.println(character.getProfession()); // 输出：Warrior System.out.println(character.getName()); // 输出：Conan System.out.println(character.getHairColor()); // 输出：Black System.out.println(character.getWeapon()); // 输出：Sword } } 在上述示例中，Character（产品）是要构建的复杂对象，CharacterBuilder（建造者）负责构建这个对象的具体步骤。通过链式调用建造者的方法，可以设置产品的各个属性。最后，调用build()方法返回最终构建的对象。\n优缺点 构造器模式的优点： 简化对象的创建过程，提供一种清晰和可读的创建对象的方式。 允许通过构造器参数来定制对象的属性和行为。 支持链式调用，使得对象的创建和配置更加灵活和可配置。 提供了一种标准化的对象创建方式，符合面向对象设计的原则。 构造器模式的缺点： 当有很多属性需要设置时，构造器参数列表可能变得很长，不易维护。 对于属性可选的情况，需要创建多个构造器或使用可选参数的方式，增加了代码复杂性。 与其他模式区别 构造器模式和其他创建型模式的区别：构造器模式是创建型设计模式之一，专注于通过构造器来创建对象。与其他创建型模式（如工厂模式、抽象工厂模式、建造者模式）相比，构造器模式更加注重对象的初始化过程，并通过构造器参数来设置对象的属性和状态。 构造器模式与 JavaBean 模式的比较：构造器模式和 JavaBean 模式是两种不同的对象创建方式。 构造器模式通过在构造器中传递参数来创建对象，强调对象的不变性和一次性初始化。 JavaBean 模式使用默认构造器和 setter 方法来设置对象的属性，强调可变性和逐步初始化。 构造器模式的变体：\n静态内部类构造器模式：通过静态内部类的方式来构建对象，实现了懒加载和线程安全。传统的建造者模式相比，静态 Builder 模式将 Builder 类定义为静态内部类，以简化对象创建过程，同时保持可读性和可配置性。\npublic class Product { private String name; private String description; private int price; private Product(Builder builder) { this.name = builder.name; this.description = builder.description; this.price = builder.price; } public String getName() { return name; } public String getDescription() { return description; } public int getPrice() { return price; } public static class Builder { private String name; private String description; private int price; public Builder() { } public Builder name(String name) { this.name = name; return this; } public Builder description(String description) { this.description = description; return this; } public Builder price(int price) { this.price = price; return this; } public Product build() { return new Product(this); } } } 在上述代码中，Product 类是要构建的产品类，其中包含了一些属性。Product 类的构造函数被定义为私有，只能通过内部的 Builder 类来构建对象。\nBuilder 类是一个静态内部类，它拥有与 Product 类相同的属性，并提供了链式调用的方法来配置这些属性。最后，通过 build() 方法来创建 Product 对象，并将 Builder 对象作为参数传递给 Product 类的私有构造函数来进行对象的构建。\n使用静态 Builder 模式，可以以链式调用的方式来构建对象，使代码更加简洁和可读。同时，由于 Builder 类是静态内部类，可以直接通过类名进行访问，无需先创建外部类的实例。这种模式也提供了一种可配置的对象创建方式，允许根据需要选择性地设置对象的属性值。\n构造器参数过多时，使用构造器模式的变种可以改善代码可读性，如使用构建器模式（Builder Pattern）或流式接口模式（Fluent Interface Pattern）\n适用场景 构造器模式适用于以下场景：\n当需要创建复杂对象时，对象的构建过程需要多个步骤，并且这些步骤可以灵活组合，产生不同的对象表示。 当一个对象的构建过程独立于组成对象的部件及其组装方式，并且希望通过改变构建过程来构建不同的表示。 当构建过程必须允许构建的对象具有不同的表示形式，而不需要暴露其内部结构。 当创建过程中存在共享的部件，并且希望避免重复创建相同的部件。 下面是一些常见的适用场景示例：\n创建复杂的配置对象：例如，一个配置对象有多个可选项和参数，使用构造器模式可以通过设置不同的选项和参数来构建不同的配置对象。 创建具有不同选项的菜单项：例如，一个菜单项可以有不同的名称、图标、快捷键等选项，使用构造器模式可以根据需要组合这些选项来构建菜单项。 创建具有多个步骤的表单：例如，一个表单需要用户填写多个字段，使用构造器模式可以定义不同的步骤来构建表单，并在每个步骤中设置相应的字段。 创建复杂的对象图：例如，创建一个包含多个对象和关联关系的对象图，使用构造器模式可以通过逐步构建对象并建立它们之间的关联关系来创建整个对象图。 在许多开源框架和库中，构造器模式经常被使用。下面是一些常见的开源框架中使用构造器模式的例子：\nApache HttpClient：Apache HttpClient 是一个流行的开源框架，用于进行 HTTP 通信。它使用了构造器模式来构建HttpClient和HttpRequest对象。例如，通过使用HttpClientBuilder类的构造器模式，可以创建自定义的HttpClient实例。 CloseableHttpClient httpClient = HttpClientBuilder.create() .setConnectionTimeout(5000) .setRetryHandler(new DefaultHttpRequestRetryHandler(3, true)) .build(); Gson：Gson 是 Google 提供的用于在 Java 对象和 JSON 数据之间进行转换的库。在 Gson 中，可以使用构造器模式来构建Gson对象，并设置不同的配置选项。 Gson gson = new GsonBuilder() .setDateFormat(\u0026#34;yyyy-MM-dd\u0026#34;) .disableHtmlEscaping() .create(); Retrofit：Retrofit 是一个用于进行 RESTful API 通信的库。它使用构造器模式来构建Retrofit实例，并设置不同的配置选项，例如设置基本 URL、添加拦截器等。 Retrofit retrofit = new Retrofit.Builder() .baseUrl(\u0026#34;https://api.example.com\u0026#34;) .addConverterFactory(GsonConverterFactory.create()) .build(); JUnit：JUnit 是一个用于编写单元测试的 Java 框架。在 JUnit 中，可以使用构造器模式来构建不同类型的测试对象，例如使用@RunWith注解配置不同的测试运行器。 @RunWith(Parameterized.class) public class MyParameterizedTest { // constructor with parameters public MyParameterizedTest(String input, int expected) { // ... } } Spring Framework：Spring Framework 是一个广泛应用于 Java 企业应用开发的开源框架。在 Spring 中，可以使用构造器模式来构建不同的对象，例如使用RestTemplateBuilder构建RestTemplate对象。 RestTemplate restTemplate = new RestTemplateBuilder() .setConnectTimeout(5000) .setReadTimeout(5000) .build(); Hibernate ORM：Hibernate 是一个流行的 Java 对象关系映射（ORM）框架，用于将 Java 对象映射到数据库表。在 Hibernate 中，可以使用构造器模式来构建SessionFactory和Session对象。 Configuration configuration = new Configuration() .configure(\u0026#34;hibernate.cfg.xml\u0026#34;) .addAnnotatedClass(User.class); SessionFactory sessionFactory = configuration.buildSessionFactory(); 以下是一些 Java 中使用构造器模式的例子：\nStringBuilder 类：Java 中的 StringBuilder 类使用构造器模式来构建可变的字符串对象。它允许通过构造器链式调用来追加、插入和修改字符串内容。 StringBuilder sb = new StringBuilder(\u0026#34;Hello\u0026#34;); sb.append(\u0026#34; World\u0026#34;) .insert(5, \u0026#34;,\u0026#34;) .replace(6, 11, \u0026#34;Java\u0026#34;) .deleteCharAt(11); String result = sb.toString(); // \u0026#34;Hello, Java\u0026#34; StringBuffer 总结 构造器模式是一种创建型设计模式，旨在通过使用构造器来创建对象。它提供了一种清晰、可读和可配置的对象创建方式，允许通过构造器参数来设置对象的属性和状态。下面是对构造器模式的总结：\n目的：构造器模式旨在提供一种标准化的对象创建方式，将对象的构建和初始化过程封装在构造器中，以便于使用者创建对象。 主要组件： 构造器（Constructor）：构造器负责创建对象并设置其属性和状态。它可以接收一组参数来初始化对象。 对象（Object）：构造器模式创建的目标对象，具有一组属性和状态。 优点： 简化对象的创建过程，提供一种清晰和可读的创建对象的方式。 允许通过构造器参数来定制对象的属性和行为。 支持链式调用，使得对象的创建和配置更加灵活和可配置。 提供了一种标准化的对象创建方式，符合面向对象设计的原则。 缺点： 当有很多属性需要设置时，构造器参数列表可能变得很长，不易维护。 对于属性可选的情况，需要创建多个构造器或使用可选参数的方式，增加了代码复杂性。 与其他模式的关系： 构造器模式与其他创建型模式（如工厂模式、抽象工厂模式、建造者模式）相比，更加注重对象的初始化过程。 静态内部类构造器模式是构造器模式的一种变体，通过静态内部类实现了懒加载和线程安全。 构造器模式可以与其他设计模式结合使用，如单例模式、适配器模式等，以满足更复杂的需求。 构造器模式提供了一种简单而强大的对象创建方式，使得创建对象变得直观、可配置和可读。它是面向对象设计中常用的模式之一，可以帮助程序员编写可维护、可扩展的代码。\n","permalink":"https://blog.chensoul.cc/posts/2023/09/05/java-design-patterns-builder/","summary":"本文主要介绍 Builder 构造器模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 构造器模式（Builder Pattern）是一种创建型设计模式，用于将复杂对象的构建过程与其表示分离，从而可以使用相同的构建过程创建不同的表示。\n在构造器模式中，通常有两个主要角色：产品（Product）和建造者（Builder）。产品是最终构建的对象，而建造者负责构建产品。\n以下是构造器模式的类图示例：\n+-------------------+ +----------------------+ | Director | | Builder | +-------------------+ +----------------------+ | construct() | | buildPartA() | | | | buildPartB() | +-------------------+ | getResult() | +----------+-----------+ | v +----------+-----------+ | Product | +----------------------+ | partA | | partB | +----------------------+ 在上述类图中，Director（指导者）负责定义构建产品的顺序和方式，而Builder（建造者）负责实际构建产品的具体步骤。Product（产品）是最终构建的对象。\n以下是一个简单的示例，演示如何使用构造器模式创建一个角色生成器的例子：\n// 产品类 public class Character { private String profession; private String name; private String hairColor; private String weapon; // 构造器私有化，只能通过建造者创建对象 private Character() {} // Getters public String getProfession() { return profession; } public String getName() { return name; } public String getHairColor() { return hairColor; } public String getWeapon() { return weapon; } // 建造者类 public static class CharacterBuilder { private Character character; public CharacterBuilder() { character = new Character(); } public CharacterBuilder withProfession(String profession) { character.","title":"Java设计模式：Builder"},{"content":"本文主要介绍 Business Delegate 业务委托模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 业务委托模式（Business Delegate Pattern）在表示层和业务层之间引入了一个抽象层，旨在实现这两个层之间的松散耦合，并封装了有关如何定位、连接和交互业务对象的逻辑。\n在该模式中，业务委托（Business Delegate）充当一个中间人角色，负责将表示层的调用委托给业务对象。它隐藏了具体业务对象的实现细节，包括底层服务的查找和可访问性，以提供简化的接口供表示层使用。\n业务委托模式用于解耦表示层和业务层。它基本上用于减少表示层代码中业务层代码的通信或远程查找功能。在业务层，我们有以下实体。\nClient - 表示层代码可以是 JSP、Servlet 或 UI java 代码。 Business Delegate -业务委托 - 客户端实体提供对业务服务方法的访问的单个入口点类。 LookUp Service - 查找服务对象负责获取相关业务实现并提供对业务委托对象的业务对象访问。 Business Service - 业务服务接口。具体类实现该业务服务以提供实际的业务实现逻辑。 以下是一个示例的程序代码，演示了业务委托模式的实现：\npublic interface VideoStreamingService { void doProcessing(); } @Slf4j public class NetflixService implements VideoStreamingService { @Override public void doProcessing() { LOGGER.info(\u0026#34;NetflixService is now processing\u0026#34;); } } @Slf4j public class YouTubeService implements VideoStreamingService { @Override public void doProcessing() { LOGGER.info(\u0026#34;YouTubeService is now processing\u0026#34;); } } @Setter public class BusinessLookup { private NetflixService netflixService; private YouTubeService youTubeService; public VideoStreamingService getBusinessService(String movie) { if (movie.toLowerCase(Locale.ROOT).contains(\u0026#34;die hard\u0026#34;)) { return netflixService; } else { return youTubeService; } } } @Setter public class BusinessDelegate { private BusinessLookup lookupService; public void playbackMovie(String movie) { VideoStreamingService videoStreamingService = lookupService.getBusinessService(movie); videoStreamingService.doProcessing(); } } public class MobileClient { private final BusinessDelegate businessDelegate; public MobileClient(BusinessDelegate businessDelegate) { this.businessDelegate = businessDelegate; } public void playbackMovie(String movie) { businessDelegate.playbackMovie(movie); } } public static void main(String[] args) { // 准备对象 var businessDelegate = new BusinessDelegate(); var businessLookup = new BusinessLookup(); businessLookup.setNetflixService(new NetflixService()); businessLookup.setYouTubeService(new YouTubeService()); businessDelegate.setLookupService(businessLookup); // 创建客户端并使用业务委托 var client = new MobileClient(businessDelegate); client.playbackMovie(\u0026#34;Die Hard 2\u0026#34;); client.playbackMovie(\u0026#34;Maradona: The Greatest Ever\u0026#34;); } 上述示例中，VideoStreamingService是一个抽象接口，由具体的实现类NetflixService和YouTubeService实现。BusinessLookup负责根据电影名称选择合适的视频流服务。BusinessDelegate则使用BusinessLookup来将电影播放请求路由到适当的视频流服务。MobileClient作为移动客户端使用业务委托来调用业务层。\n类图：\n适用场景 业务委托模式适用于以下场景：\n松散耦合：当需要在表示层和业务层之间实现松散耦合时，可以使用业务委托模式。该模式通过引入一个抽象层，将表示层与具体的业务对象解耦，使它们可以独立演化和修改。 多个业务服务的调用编排：当需要对多个业务服务进行编排和协调时，业务委托模式可以提供一个统一的接口供表示层调用。委托对象负责决定如何分配请求给不同的业务服务，并处理可能的错误和异常情况。 封装查找服务和服务调用：业务委托模式可以封装底层服务的查找和调用过程。通过将这些实现细节隐藏在委托对象中，表示层可以更专注于业务逻辑的处理，而不需要关注底层服务的具体实现和访问方式。 虽然业务委托模式没有在所有开源框架中以明确的形式出现，但它的核心思想可以在许多框架和应用程序中找到。\n在开源框架中，你可能会看到以下方式来使用业务委托模式：\n服务代理：许多开源框架使用代理模式来封装底层服务，并为客户端提供一个统一的接口。这个代理对象可以被视为业务委托对象，它负责处理底层服务的调用和错误处理，同时隐藏了底层服务的具体实现细节。客户端只需要与代理对象进行交互，而不需要直接与底层服务进行通信。 依赖注入（DI）：开源框架通常支持依赖注入，它可以用于将业务委托对象注入到其他组件中。通过依赖注入，你可以将具体的业务委托对象与客户端代码解耦，使其更易于测试、扩展和维护。框架通常提供了相应的注入机制，如构造函数注入、属性注入或使用注解进行注入。 中间件和消息代理：某些开源框架专注于中间件或消息代理，用于处理不同服务之间的通信。这些框架可能提供一种机制，允许你定义业务委托对象，并通过中间件或消息代理将请求路由到相应的服务。这种方式可以帮助实现业务逻辑的解耦和灵活性。 需要明确的是，业务委托模式并不是所有开源框架中的显式设计模式。然而，许多框架和库借鉴了业务委托模式的思想，以提供更好的模块化、可测试性和可维护性。在使用开源框架时，你可以查看框架的文档和示例，以了解是否有类似于业务委托模式的概念或最佳实践可供参考。\n","permalink":"https://blog.chensoul.cc/posts/2023/09/05/java-design-patterns-business-delegate/","summary":"本文主要介绍 Business Delegate 业务委托模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 业务委托模式（Business Delegate Pattern）在表示层和业务层之间引入了一个抽象层，旨在实现这两个层之间的松散耦合，并封装了有关如何定位、连接和交互业务对象的逻辑。\n在该模式中，业务委托（Business Delegate）充当一个中间人角色，负责将表示层的调用委托给业务对象。它隐藏了具体业务对象的实现细节，包括底层服务的查找和可访问性，以提供简化的接口供表示层使用。\n业务委托模式用于解耦表示层和业务层。它基本上用于减少表示层代码中业务层代码的通信或远程查找功能。在业务层，我们有以下实体。\nClient - 表示层代码可以是 JSP、Servlet 或 UI java 代码。 Business Delegate -业务委托 - 客户端实体提供对业务服务方法的访问的单个入口点类。 LookUp Service - 查找服务对象负责获取相关业务实现并提供对业务委托对象的业务对象访问。 Business Service - 业务服务接口。具体类实现该业务服务以提供实际的业务实现逻辑。 以下是一个示例的程序代码，演示了业务委托模式的实现：\npublic interface VideoStreamingService { void doProcessing(); } @Slf4j public class NetflixService implements VideoStreamingService { @Override public void doProcessing() { LOGGER.info(\u0026#34;NetflixService is now processing\u0026#34;); } } @Slf4j public class YouTubeService implements VideoStreamingService { @Override public void doProcessing() { LOGGER.info(\u0026#34;YouTubeService is now processing\u0026#34;); } } @Setter public class BusinessLookup { private NetflixService netflixService; private YouTubeService youTubeService; public VideoStreamingService getBusinessService(String movie) { if (movie.toLowerCase(Locale.ROOT).contains(\u0026#34;die hard\u0026#34;)) { return netflixService; } else { return youTubeService; } } } @Setter public class BusinessDelegate { private BusinessLookup lookupService; public void playbackMovie(String movie) { VideoStreamingService videoStreamingService = lookupService.","title":"Java设计模式：Business Delegate"},{"content":"本文主要介绍 Bridge 桥接模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 桥接模式（Bridge Pattern）是一种结构型设计模式，用于将抽象与其实现分离，使它们可以独立地变化。桥接模式通过创建两个独立的层次结构，一个是抽象部分，一个是实现部分，来实现这种分离。\n在桥接模式中，抽象部分包含抽象类或接口，定义了高层逻辑和功能。实现部分包含具体实现类，负责实现抽象部分定义的接口或方法。通过桥接模式，可以在两个层次结构中独立地扩展和变化类，而不会相互影响。同时，抽象部分和实现部分之间的耦合度降低，使系统更加灵活和可维护。\n举例 考虑一下你拥有一种具有不同附魔的武器，并且应该允许将具有不同附魔的不同武器混合使用。 你会怎么做？ 为每个附魔创建每种武器的多个副本，还是只是创建单独的附魔并根据需要为武器设置它？ 桥接模式使您可以进行第二次操作。\n翻译一下上面的武器示例。下面我们有武器的类层级：\npublic interface Weapon { void wield(); void swing(); void unwield(); Enchantment getEnchantment(); } public class Sword implements Weapon { private final Enchantment enchantment; public Sword(Enchantment enchantment) { this.enchantment = enchantment; } @Override public void wield() { LOGGER.info(\u0026#34;The sword is wielded.\u0026#34;); enchantment.onActivate(); } @Override public void swing() { LOGGER.info(\u0026#34;The sword is swinged.\u0026#34;); enchantment.apply(); } @Override public void unwield() { LOGGER.info(\u0026#34;The sword is unwielded.\u0026#34;); enchantment.onDeactivate(); } @Override public Enchantment getEnchantment() { return enchantment; } } public class Hammer implements Weapon { private final Enchantment enchantment; public Hammer(Enchantment enchantment) { this.enchantment = enchantment; } @Override public void wield() { LOGGER.info(\u0026#34;The hammer is wielded.\u0026#34;); enchantment.onActivate(); } @Override public void swing() { LOGGER.info(\u0026#34;The hammer is swinged.\u0026#34;); enchantment.apply(); } @Override public void unwield() { LOGGER.info(\u0026#34;The hammer is unwielded.\u0026#34;); enchantment.onDeactivate(); } @Override public Enchantment getEnchantment() { return enchantment; } } 这里是单独的附魔类结构：\npublic interface Enchantment { void onActivate(); void apply(); void onDeactivate(); } public class FlyingEnchantment implements Enchantment { @Override public void onActivate() { LOGGER.info(\u0026#34;The item begins to glow faintly.\u0026#34;); } @Override public void apply() { LOGGER.info(\u0026#34;The item flies and strikes the enemies finally returning to owner\u0026#39;s hand.\u0026#34;); } @Override public void onDeactivate() { LOGGER.info(\u0026#34;The item\u0026#39;s glow fades.\u0026#34;); } } public class SoulEatingEnchantment implements Enchantment { @Override public void onActivate() { LOGGER.info(\u0026#34;The item spreads bloodlust.\u0026#34;); } @Override public void apply() { LOGGER.info(\u0026#34;The item eats the soul of enemies.\u0026#34;); } @Override public void onDeactivate() { LOGGER.info(\u0026#34;Bloodlust slowly disappears.\u0026#34;); } } 这里是两种层次结构的实践：\nvar enchantedSword = new Sword(new SoulEatingEnchantment()); enchantedSword.wield(); enchantedSword.swing(); enchantedSword.unwield(); // The sword is wielded. // The item spreads bloodlust. // The sword is swinged. // The item eats the soul of enemies. // The sword is unwielded. // Bloodlust slowly disappears. var hammer = new Hammer(new FlyingEnchantment()); hammer.wield(); hammer.swing(); hammer.unwield(); // The hammer is wielded. // The item begins to glow faintly. // The hammer is swinged. // The item flies and strikes the enemies finally returning to owner\u0026#39;s hand. // The hammer is unwielded. // The item\u0026#39;s glow fades. 类图 适用场景 桥接模式适用于以下情况：\n当你希望在抽象部分和实现部分之间存在独立的扩展和变化时，可以使用桥接模式。这样可以避免在两个层次结构之间的紧耦合关系，使它们可以相互独立地进行修改和扩展。 当你想要避免在编译时将抽象部分与实现部分绑定在一起时，桥接模式是一个很好的选择。通过桥接模式，可以在运行时动态地将抽象部分和实现部分进行组合，而不需要修改客户端的代码。 当你有多个独立变化的维度时，可以使用桥接模式。例如，在给定的示例中，武器和附魔是两个独立变化的维度，通过桥接模式可以灵活地组合它们，而不需要为每种武器和每种附魔创建大量的子类。 总的来说，桥接模式适用于需要在抽象与实现之间存在独立变化和组合的情况，以及需要动态地进行选择和共享实现的情况。它能够提高系统的灵活性、可扩展性和可维护性。\n举例 以下是一个实际的例子，以帮助说明桥接模式的应用。\n假设你正在开发一个绘图应用程序，其中包含不同类型的形状（如圆形、矩形）和不同的颜色（如红色、蓝色）。你希望能够在任意形状上应用不同的颜色，而不是为每种形状和颜色的组合创建大量的子类。\n在这种情况下，可以使用桥接模式来实现形状和颜色之间的组合。首先，定义一个抽象的形状类 Shape，其中包含一个颜色对象的引用。然后，定义一个抽象的颜色类 Color，其中包含一个绘制方法。通过桥接模式，将形状和颜色进行分离，使它们可以独立地进行扩展和变化。\n下面是示例代码：\n// 形状抽象类 abstract class Shape { protected Color color; public Shape(Color color) { this.color = color; } public abstract void draw(); } // 颜色抽象类 interface Color { void applyColor(); } // 具体形状类：圆形 class Circle extends Shape { public Circle(Color color) { super(color); } @Override public void draw() { System.out.print(\u0026#34;绘制圆形，\u0026#34;); color.applyColor(); } } // 具体形状类：矩形 class Rectangle extends Shape { public Rectangle(Color color) { super(color); } @Override public void draw() { System.out.print(\u0026#34;绘制矩形，\u0026#34;); color.applyColor(); } } // 具体颜色类：红色 class RedColor implements Color { @Override public void applyColor() { System.out.println(\u0026#34;使用红色\u0026#34;); } } // 具体颜色类：蓝色 class BlueColor implements Color { @Override public void applyColor() { System.out.println(\u0026#34;使用蓝色\u0026#34;); } } 现在，你可以创建不同的形状对象，并将不同的颜色对象与之组合，而无需创建大量的子类。例如：\nShape redCircle = new Circle(new RedColor()); Shape blueRectangle = new Rectangle(new BlueColor()); redCircle.draw(); // 输出：绘制圆形，使用红色 blueRectangle.draw(); // 输出：绘制矩形，使用蓝色 通过桥接模式，你可以轻松地扩展形状和颜色的种类，而不需要修改现有的代码。你可以添加新的形状或颜色类，并将它们组合在一起，以满足不同的需求，同时保持了形状和颜色之间的独立性。\n开源框架中的应用 在开源框架中，有一些使用桥接模式的例子。以下是其中一些常见的开源框架和其使用桥接模式的示例：\nJDBC（Java 数据库连接）框架：JDBC 框架是 Java 中用于与数据库进行交互的标准 API。在 JDBC 中，使用了桥接模式来连接不同的数据库驱动程序和应用程序。桥接模式将 JDBC API 与特定的数据库驱动程序实现分离，使得应用程序可以独立于不同的数据库实现进行开发。 AWT（Abstract Window Toolkit）：AWT 是 Java 中用于创建图形用户界面（GUI）的原始工具包。在 AWT 中，使用了桥接模式来分离抽象的 GUI 组件（例如按钮、文本框）和具体的平台实现。这样可以使得 AWT 可以在不同的操作系统上运行，并且可以根据不同的平台提供不同的外观和行为。 Spring 框架：Spring 是一个开源的 Java 企业应用程序开发框架。在 Spring 中，使用了桥接模式来实现不同层之间的解耦。例如，Spring 的数据访问模块（Spring Data）使用了桥接模式来连接不同的数据访问技术，如 JPA、Hibernate、MyBatis 等。这样，开发人员可以选择适合其需求的数据访问技术，而不需要修改其他部分的代码。 Apache Log4j：Log4j 框架使用了桥接模式将日志记录器（Logger）与具体的日志输出（Appender）分离。通过Logger接口和Appender接口的组合使用，可以在运行时动态地将日志记录器与不同的日志输出实现进行桥接。例如，可以将Logger桥接到FileAppender、ConsoleAppender或DatabaseAppender等不同的具体实现上。 Apache Commons IO：Commons IO 是 Apache Commons 项目的一部分，提供了一组用于处理 I/O 操作的实用工具。在 Commons IO 中，使用了桥接模式来分离抽象的 I/O 操作（如文件读写、流处理）和具体的实现。这使得开发人员可以在不同的环境中使用相同的 API 进行 I/O 操作。 Hibernate ORM：Hibernate 使用了桥接模式将不同数据库厂商的驱动程序与核心功能分离。它通过DriverManager接口和具体的数据库驱动程序实现的桥接，能够在运行时动态地选择和切换数据库驱动程序。这样，开发人员可以使用相同的 Hibernate API 与不同的数据库进行交互，而不需要修改核心代码。 Retrofit：Retrofit 库使用了桥接模式来将网络请求的抽象表示与具体的 HTTP 客户端实现分离。它通过Call接口和HttpClient接口的组合使用，可以将不同的 HTTP 客户端库（如 OkHttp、Apache HttpClient）桥接到统一的网络请求抽象上。这使得开发人员可以根据需要选择不同的 HTTP 客户端实现，而不需要修改使用 Retrofit 的代码。 Apache HttpClient：HttpClient 是 Apache 软件基金会提供的一个用于发送 HTTP 请求的 Java 库。它使用了桥接模式来将抽象的 HTTP 请求和具体的 HTTP 协议实现（如 HTTP/1.1 或 HTTP/2）分离。这使得开发人员可以根据需要选择不同的 HTTP 协议版本，而不需要修改代码。 Apache Commons Logging：Commons Logging 是 Apache Commons 项目中的一个通用日志记录接口。它使用了桥接模式来将应用程序代码与底层的具体日志实现（如 Log4j、java.util.logging 等）分离。这使得开发人员可以在不同的环境中切换和配置不同的日志实现。 以下是一个简单的示例代码，演示了桥接模式在 JDBC 框架中的应用：\n首先，定义桥接接口 DatabaseDriver，它包含了数据库操作的方法声明：\npublic interface DatabaseDriver { void connect(String url, String username, String password); void executeQuery(String query); void disconnect(); } 然后，实现具体的数据库驱动程序，例如 MySQLDriver 和 OracleDriver，它们实现了 DatabaseDriver 接口：\npublic class MySQLDriver implements DatabaseDriver { // MySQL数据库特定的实现代码 @Override public void connect(String url, String username, String password) { // 连接MySQL数据库的代码 } @Override public void executeQuery(String query) { // 执行MySQL查询的代码 } @Override public void disconnect() { // 断开MySQL数据库连接的代码 } } public class OracleDriver implements DatabaseDriver { // Oracle数据库特定的实现代码 @Override public void connect(String url, String username, String password) { // 连接Oracle数据库的代码 } @Override public void executeQuery(String query) { // 执行Oracle查询的代码 } @Override public void disconnect() { // 断开Oracle数据库连接的代码 } } 接下来，定义使用桥接模式的应用程序代码，其中包含了一个 Database 类作为抽象化角色，它使用桥接接口 DatabaseDriver 进行数据库操作：\npublic class Database { private DatabaseDriver driver; public Database(DatabaseDriver driver) { this.driver = driver; } public void connectToDatabase(String url, String username, String password) { driver.connect(url, username, password); } public void executeQuery(String query) { driver.executeQuery(query); } public void disconnectFromDatabase() { driver.disconnect(); } } 最后，可以在应用程序中使用这些类进行数据库操作：\npublic class Main { public static void main(String[] args) { // 创建MySQLDriver实例 DatabaseDriver mysqlDriver = new MySQLDriver(); // 创建Database实例，并使用MySQLDriver进行操作 Database mysqlDatabase = new Database(mysqlDriver); // 连接到MySQL数据库 mysqlDatabase.connectToDatabase(\u0026#34;jdbc:mysql://localhost:3306/mydb\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;); // 执行MySQL查询 mysqlDatabase.executeQuery(\u0026#34;SELECT * FROM mytable\u0026#34;); // 断开MySQL数据库连接 mysqlDatabase.disconnectFromDatabase(); // 创建OracleDriver实例 DatabaseDriver oracleDriver = new OracleDriver(); // 创建Database实例，并使用OracleDriver进行操作 Database oracleDatabase = new Database(oracleDriver); // 连接到Oracle数据库 oracleDatabase.connectToDatabase(\u0026#34;jdbc:oracle:thin:@localhost:1521:xe\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;); // 执行Oracle查询 oracleDatabase.executeQuery(\u0026#34;SELECT * FROM mytable\u0026#34;); // 断开Oracle数据库连接 oracleDatabase.disconnectFromDatabase(); } } 这个例子展示了如何使用桥接模式将 JDBC API 与特定的数据库驱动程序实现分离。通过创建不同的数据库驱动程序实例，并将其传递给 Database 类，应用程序可以独立于不同的数据库实现进行开发和操作。\n参考文章 https://www.digitalocean.com/community/tutorials/bridge-design-pattern-java ","permalink":"https://blog.chensoul.cc/posts/2023/08/28/java-design-patterns-bridge/","summary":"本文主要介绍 Bridge 桥接模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 桥接模式（Bridge Pattern）是一种结构型设计模式，用于将抽象与其实现分离，使它们可以独立地变化。桥接模式通过创建两个独立的层次结构，一个是抽象部分，一个是实现部分，来实现这种分离。\n在桥接模式中，抽象部分包含抽象类或接口，定义了高层逻辑和功能。实现部分包含具体实现类，负责实现抽象部分定义的接口或方法。通过桥接模式，可以在两个层次结构中独立地扩展和变化类，而不会相互影响。同时，抽象部分和实现部分之间的耦合度降低，使系统更加灵活和可维护。\n举例 考虑一下你拥有一种具有不同附魔的武器，并且应该允许将具有不同附魔的不同武器混合使用。 你会怎么做？ 为每个附魔创建每种武器的多个副本，还是只是创建单独的附魔并根据需要为武器设置它？ 桥接模式使您可以进行第二次操作。\n翻译一下上面的武器示例。下面我们有武器的类层级：\npublic interface Weapon { void wield(); void swing(); void unwield(); Enchantment getEnchantment(); } public class Sword implements Weapon { private final Enchantment enchantment; public Sword(Enchantment enchantment) { this.enchantment = enchantment; } @Override public void wield() { LOGGER.info(\u0026#34;The sword is wielded.\u0026#34;); enchantment.onActivate(); } @Override public void swing() { LOGGER.info(\u0026#34;The sword is swinged.\u0026#34;); enchantment.apply(); } @Override public void unwield() { LOGGER.info(\u0026#34;The sword is unwielded.\u0026#34;); enchantment.onDeactivate(); } @Override public Enchantment getEnchantment() { return enchantment; } } public class Hammer implements Weapon { private final Enchantment enchantment; public Hammer(Enchantment enchantment) { this.","title":"Java设计模式：Bridge"},{"content":"本文主要介绍 Balking 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 止步模式（Balking）是一种在对象处于特定状态时才执行操作的设计模式。它用于防止对象在不完整或不合适的状态下执行某些代码，从而确保代码的正确性和一致性。\n该模式的核心思想是，在执行操作之前，检查对象的状态，并只在特定的状态下才执行操作。如果对象不处于预期状态，操作将被忽略或推迟执行，从而避免了不必要的操作或不一致的状态转换。\n以下是止步模式的要点和示例：\n对象状态检查：在执行操作之前，对象会检查自身的状态。这可以通过使用条件语句或状态标志来实现。 特定状态执行：只有当对象处于特定状态时，操作才会被执行。如果对象不满足执行条件，操作将被忽略或推迟执行。 线程安全考虑：由于止步模式通常涉及多线程环境，需要确保对共享资源的访问是线程安全的。可以使用同步机制（如 synchronized 关键字）来保护共享资源。 解释 真实世界例子\n洗衣机中有一个开始按钮，用于启动衣物洗涤。当洗衣机处于非活动状态时，按钮将按预期工作，但是如果已经在洗涤，则按钮将不起任何作用。\n通俗地说\n使用止步模式，仅当对象处于特定状态时才执行特定代码。\n维基百科说\n禁止模式是一种软件设计模式，仅当对象处于特定状态时才对对象执行操作。例如，一个对象读取 zip 压缩文件并在压缩文件没打开的时候调用 get 方法，对象将在请求的时候”止步“。\n程序示例\n在此示例中， WashingMachine是一个具有两个状态的对象，可以处于两种状态：ENABLED 和WASHING。 如果机器已启用，则使用线程安全方法将状态更改为 WASHING。 另一方面，如果已经进行了清洗并且任何其他线程执行 wash（），则它将不执行该操作，而是不执行任何操作而返回。\n这里是 WashingMachine 类相关的部分。\n@Slf4j public class WashingMachine { private final DelayProvider delayProvider; private WashingMachineState washingMachineState; public WashingMachine(DelayProvider delayProvider) { this.delayProvider = delayProvider; this.washingMachineState = WashingMachineState.ENABLED; } public WashingMachineState getWashingMachineState() { return washingMachineState; } public void wash() { synchronized (this) { var machineState = getWashingMachineState(); LOGGER.info(\u0026#34;{}: Actual machine state: {}\u0026#34;, Thread.currentThread().getName(), machineState); if (this.washingMachineState == WashingMachineState.WASHING) { LOGGER.error(\u0026#34;Cannot wash if the machine has been already washing!\u0026#34;); return; } this.washingMachineState = WashingMachineState.WASHING; } LOGGER.info(\u0026#34;{}: Doing the washing\u0026#34;, Thread.currentThread().getName()); this.delayProvider.executeAfterDelay(50, TimeUnit.MILLISECONDS, this::endOfWashing); } public synchronized void endOfWashing() { washingMachineState = WashingMachineState.ENABLED; LOGGER.info(\u0026#34;{}: Washing completed.\u0026#34;, Thread.currentThread().getId()); } } 这里是一个 WashingMachine 所使用的 DelayProvider 简单接口。\npublic interface DelayProvider { void executeAfterDelay(long interval, TimeUnit timeUnit, Runnable task); } 现在，我们使用WashingMachine介绍该应用程序。\npublic static void main(String... args) { final var washingMachine = new WashingMachine(); var executorService = Executors.newFixedThreadPool(3); for (int i = 0; i \u0026lt; 3; i++) { executorService.execute(washingMachine::wash); } executorService.shutdown(); try { executorService.awaitTermination(10, TimeUnit.SECONDS); } catch (InterruptedException ie) { LOGGER.error(\u0026#34;ERROR: Waiting on executor service shutdown!\u0026#34;); Thread.currentThread().interrupt(); } } 下面是程序的输出。\n14:02:52.268 [pool-1-thread-2] INFO com.iluwatar.balking.WashingMachine - pool-1-thread-2: Actual machine state: ENABLED 14:02:52.272 [pool-1-thread-2] INFO com.iluwatar.balking.WashingMachine - pool-1-thread-2: Doing the washing 14:02:52.272 [pool-1-thread-3] INFO com.iluwatar.balking.WashingMachine - pool-1-thread-3: Actual machine state: WASHING 14:02:52.273 [pool-1-thread-3] ERROR com.iluwatar.balking.WashingMachine - Cannot wash if the machine has been already washing! 14:02:52.273 [pool-1-thread-1] INFO com.iluwatar.balking.WashingMachine - pool-1-thread-1: Actual machine state: WASHING 14:02:52.273 [pool-1-thread-1] ERROR com.iluwatar.balking.WashingMachine - Cannot wash if the machine has been already washing! 14:02:52.324 [pool-1-thread-2] INFO com.iluwatar.balking.WashingMachine - 14: Washing completed. 在示例中，洗衣机（WashingMachine）是一个具有两个状态的对象：ENABLED（已启用）和 WASHING（正在洗涤）。通过使用同步方法和状态检查，洗衣机可以确保在正确的状态下执行特定的代码。如果洗衣机已经在洗涤过程中，再次调用洗涤方法时将不执行任何操作。\n使用止步模式可以确保洗衣机在适当的状态下执行洗涤操作，避免了重复洗涤或并发冲突。\n类图 适用场景 止步模式适用于以下场景：\n对象状态依赖：当对象的操作依赖于其当前状态时，可以使用止步模式来确保操作只在特定状态下执行。这可以避免在对象状态不符合要求时执行无效或有害的操作。 状态转换控制：当对象需要在特定状态之间进行转换时，可以使用止步模式来控制状态转换的发生。它可以防止不正确的状态转换和不一致的对象状态。 网络连接管理：在一个网络应用程序中，当需要与远程服务器建立连接时，可以使用止步模式来确保只在未建立连接或已断开连接的状态下执行连接操作。这样可以避免重复连接、并发连接或在无效连接上执行操作。 系统启动和关闭控制：在系统的启动和关闭过程中，可能需要限制某些操作只在特定阶段执行。使用止步模式，可以检查系统的状态，并只允许在特定阶段执行相应的操作，以确保系统的正确启动和安全关闭。 并发环境下的状态同步：在多线程环境中，止步模式可以用于同步对象的状态，以确保在并发访问时只有一个线程可以执行特定操作。它可以避免并发冲突和数据损坏。 并发任务调度：考虑一个任务调度器，允许添加和执行任务。如果在任务执行期间尝试添加新任务，可能会导致并发冲突或执行不一致的结果。通过使用止步模式，在任务执行开始时检查任务调度器的状态，并只允许在特定状态下添加新任务，可以避免并发冲突和不一致的任务执行。 资源访问控制：当多个对象需要访问共享资源时，止步模式可以用于控制对资源的访问。它可以防止多个对象同时访问或修改资源，从而确保资源的一致性和完整性。 文件读写操作：假设有一个文件处理类，其中某个方法负责读取文件的内容并返回。如果文件正在被写入或修改，那么读取操作可能会导致不一致的结果。使用止步模式，可以在读取操作开始时检查文件的状态，如果文件正在被写入，则推迟读取操作或直接忽略。 缓存更新控制：在缓存系统中，当某个缓存项过期时需要更新，但同时可能有多个请求同时到达。使用止步模式，可以在更新操作开始时检查缓存项的状态，并只允许一个线程执行更新操作，其他线程等待或忽略更新请求，从而确保缓存的一致性和避免并发冲突。 错误处理和异常避免：止步模式可以用于检测和处理潜在的错误情况，避免在不适当的状态下引发异常或导致错误的操作。 总的来说，止步模式适用于需要在特定状态下执行操作并确保状态一致性、避免并发冲突、控制资源访问以及处理错误的场景。它提供了一种简洁而有效的方式来管理对象的状态和操作。\n举例 文件读写操作 当涉及到文件读写操作时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制文件读取操作：\nimport java.io.File; import java.io.IOException; public class FileProcessor { private File file; private boolean isWriting; public FileProcessor(String filePath) { this.file = new File(filePath); this.isWriting = false; } public synchronized void processFile() { if (isWriting) { System.out.println(\u0026#34;File is being written. Cannot process at the moment.\u0026#34;); return; } isWriting = true; try { // Perform file processing operations System.out.println(\u0026#34;Processing file: \u0026#34; + file.getName()); // ... // File processing code goes here // ... System.out.println(\u0026#34;File processing completed.\u0026#34;); } catch (IOException e) { // Handle exception e.printStackTrace(); } finally { isWriting = false; } } } 在上述示例中，FileProcessor类代表了一个文件处理器，其中的processFile方法用于处理文件。在方法中，我们使用synchronized关键字来保证方法的同步执行，以防止并发访问。\n在方法的开头，我们检查isWriting标志，如果文件正在被写入，则输出一条消息并直接返回。否则，我们将isWriting标志设置为true，表示文件正在被写入。\n然后，我们可以在// File processing code goes here的注释处编写特定的文件处理逻辑，例如读取文件内容、修改文件等。\n最后，在finally块中，我们将isWriting标志设置为false，表示文件写入操作已完成。\n通过使用止步模式，我们确保了在文件正在被写入时不执行处理文件的操作，从而避免了不一致的结果和并发冲突。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节和异常处理。此外，具体的文件处理逻辑需要根据实际需求进行编写。\n并发任务调度 当涉及到并发任务调度时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制任务调度器的操作：\nimport java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class TaskScheduler { private ExecutorService executorService; private boolean isRunning; public TaskScheduler() { this.executorService = Executors.newFixedThreadPool(1); this.isRunning = false; } public synchronized void addTask(Runnable task) { if (isRunning) { System.out.println(\u0026#34;Task scheduler is already running. Cannot add new task at the moment.\u0026#34;); return; } executorService.execute(task); } public synchronized void start() { if (isRunning) { System.out.println(\u0026#34;Task scheduler is already running.\u0026#34;); return; } isRunning = true; System.out.println(\u0026#34;Task scheduler started.\u0026#34;); } public synchronized void stop() { if (!isRunning) { System.out.println(\u0026#34;Task scheduler is not running.\u0026#34;); return; } executorService.shutdown(); isRunning = false; System.out.println(\u0026#34;Task scheduler stopped.\u0026#34;); } } 在上述示例中，TaskScheduler类代表了一个任务调度器，其中的addTask方法用于添加任务，start方法用于启动任务调度器，stop方法用于停止任务调度器。\n在addTask方法中，我们首先检查isRunning标志，如果任务调度器正在运行，则输出一条消息并直接返回。否则，我们将任务提交到线程池中进行执行。\n在start方法中，我们检查isRunning标志，如果任务调度器已经在运行，则输出一条消息并直接返回。否则，我们将isRunning标志设置为true，表示任务调度器已经启动。\n在stop方法中，我们检查isRunning标志，如果任务调度器没有在运行，则输出一条消息并直接返回。否则，我们调用线程池的shutdown方法来停止任务的执行，然后将isRunning标志设置为false，表示任务调度器已经停止。\n通过使用止步模式，我们确保了在任务调度器正在运行时不添加新任务，以及在任务调度器未运行时不停止任务调度器，从而避免了并发冲突和不一致的任务调度。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、并发安全性和异常处理。此外，具体的任务逻辑需要根据实际需求进行编写。\n网络连接管理 当涉及到网络连接管理时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制网络连接的操作：\nimport java.util.concurrent.locks.ReentrantLock; public class NetworkConnectionManager { private ReentrantLock lock; private boolean isConnected; public NetworkConnectionManager() { this.lock = new ReentrantLock(); this.isConnected = false; } public void connect() { lock.lock(); try { if (isConnected) { System.out.println(\u0026#34;Already connected to the network.\u0026#34;); return; } // Perform network connection operation System.out.println(\u0026#34;Connecting to the network...\u0026#34;); // ... // Network connection code goes here // ... isConnected = true; System.out.println(\u0026#34;Successfully connected to the network.\u0026#34;); } finally { lock.unlock(); } } public void disconnect() { lock.lock(); try { if (!isConnected) { System.out.println(\u0026#34;Not currently connected to the network.\u0026#34;); return; } // Perform disconnection operation System.out.println(\u0026#34;Disconnecting from the network...\u0026#34;); // ... // Network disconnection code goes here // ... isConnected = false; System.out.println(\u0026#34;Successfully disconnected from the network.\u0026#34;); } finally { lock.unlock(); } } } 在上述示例中，NetworkConnectionManager类代表了一个网络连接管理器，其中的connect方法用于连接到网络，disconnect方法用于断开网络连接。\n在connect方法中，我们首先获取锁，然后检查isConnected标志，如果已经连接到网络，则输出一条消息并直接返回。否则，我们执行网络连接操作，然后将isConnected标志设置为true，表示成功连接到网络。\n在disconnect方法中，我们同样获取锁，然后检查isConnected标志，如果未连接到网络，则输出一条消息并直接返回。否则，我们执行网络断开操作，然后将isConnected标志设置为false，表示成功断开网络连接。\n通过使用止步模式和可重入锁，我们确保了在网络连接期间不执行重复的连接操作或在未连接时执行断开操作，从而避免了并发冲突和不一致的网络状态。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、并发安全性和异常处理。此外，具体的网络连接和断开逻辑需要根据实际需求进行编写。\n缓存更新控制 当涉及到缓存更新控制时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制缓存的更新操作：\nimport java.util.concurrent.locks.ReentrantLock; public class CacheManager { private ReentrantLock lock; private boolean isUpdating; public CacheManager() { this.lock = new ReentrantLock(); this.isUpdating = false; } public void updateCache() { lock.lock(); try { if (isUpdating) { System.out.println(\u0026#34;Cache is already being updated. Cannot perform update at the moment.\u0026#34;); return; } isUpdating = true; // Perform cache update operation System.out.println(\u0026#34;Updating cache...\u0026#34;); // ... // Cache update code goes here // ... System.out.println(\u0026#34;Cache update completed.\u0026#34;); } finally { isUpdating = false; lock.unlock(); } } } 在上述示例中，CacheManager类代表了一个缓存管理器，其中的updateCache方法用于更新缓存。\n在updateCache方法中，我们首先获取锁，然后检查isUpdating标志，如果缓存正在被更新，则输出一条消息并直接返回。否则，我们将isUpdating标志设置为true，表示缓存正在被更新。\n然后，我们可以在// Cache update code goes here的注释处编写特定的缓存更新逻辑，例如从数据库中获取最新数据、更新缓存项等。\n最后，在finally块中，我们将isUpdating标志设置为false，表示缓存更新操作已完成，并释放锁。\n通过使用止步模式和可重入锁，我们确保了在缓存正在被更新时不执行重复的更新操作，从而避免了并发冲突和不一致的缓存状态。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、并发安全性和异常处理。此外，具体的缓存更新逻辑需要根据实际需求进行编写。\n资源分配和释放 当涉及到资源分配和释放时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制资源的获取和释放操作：\nimport java.util.concurrent.Semaphore; public class ResourceManager { private Semaphore semaphore; public ResourceManager(int resourceCount) { this.semaphore = new Semaphore(resourceCount); } public void acquireResource() { try { semaphore.acquire(); System.out.println(\u0026#34;Resource acquired.\u0026#34;); // Perform resource allocation and usage here // ... // Simulating resource usage Thread.sleep(2000); System.out.println(\u0026#34;Resource released.\u0026#34;); semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } } 在上述示例中，ResourceManager类代表了一个资源管理器，其中的acquireResource方法用于获取和释放资源。\n在acquireResource方法中，我们首先调用semaphore.acquire()来获取一个可用资源。如果没有可用资源，当前线程会阻塞，直到有资源可用。\n一旦成功获取资源，我们可以在获取资源后的代码块中执行资源的分配和使用逻辑。这里只是一个简单的示例，你可以根据实际需求编写你自己的资源分配和使用逻辑。\n在模拟资源使用的部分，我们使用Thread.sleep(2000)来模拟资源的实际使用，这里暂停 2 秒钟。然后，我们释放资源，调用semaphore.release()来通知信号量，表示资源已经释放。\n通过使用止步模式和信号量（Semaphore），我们可以控制资源的获取和释放操作，确保资源在被使用时不会被多个线程同时访问，从而避免了资源冲突和不一致的结果。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、并发安全性和异常处理。此外，具体的资源分配和释放逻辑需要根据实际需求进行编写。\n数据库事务管理 当涉及到数据库事务管理时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式来控制数据库事务的操作：\nimport java.sql.Connection; import java.sql.DriverManager; import java.sql.SQLException; public class DatabaseManager { private Connection connection; private boolean inTransaction; public DatabaseManager() { this.connection = null; this.inTransaction = false; } public void startTransaction() throws SQLException { if (inTransaction) { System.out.println(\u0026#34;Transaction is already in progress.\u0026#34;); return; } connection = DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/mydb\u0026#34;, \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;); connection.setAutoCommit(false); inTransaction = true; System.out.println(\u0026#34;Transaction started.\u0026#34;); } public void commitTransaction() throws SQLException { if (!inTransaction) { System.out.println(\u0026#34;No transaction in progress.\u0026#34;); return; } connection.commit(); connection.setAutoCommit(true); connection.close(); connection = null; inTransaction = false; System.out.println(\u0026#34;Transaction committed and connection closed.\u0026#34;); } public void rollbackTransaction() throws SQLException { if (!inTransaction) { System.out.println(\u0026#34;No transaction in progress.\u0026#34;); return; } connection.rollback(); connection.setAutoCommit(true); connection.close(); connection = null; inTransaction = false; System.out.println(\u0026#34;Transaction rolled back and connection closed.\u0026#34;); } } 在上述示例中，DatabaseManager类代表了一个数据库管理器，其中的startTransaction方法用于开始事务，commitTransaction方法用于提交事务，rollbackTransaction方法用于回滚事务。\n在startTransaction方法中，我们首先检查inTransaction标志，如果已经存在一个事务正在进行，则输出一条消息并直接返回。否则，我们通过DriverManager获取数据库连接，并将自动提交设置为false，表示手动管理事务。然后，我们将inTransaction标志设置为true，表示事务已开始。\n在commitTransaction方法中，我们检查inTransaction标志，如果没有进行中的事务，则输出一条消息并直接返回。否则，我们调用connection.commit()提交事务，然后将自动提交设置为true，关闭数据库连接，并将相关变量重置为初始状态。\n在rollbackTransaction方法中，我们同样检查inTransaction标志，如果没有进行中的事务，则输出一条消息并直接返回。否则，我们调用connection.rollback()回滚事务，然后将自动提交设置为true，关闭数据库连接，并将相关变量重置为初始状态。\n通过使用止步模式和数据库事务，我们可以确保在同一时间只有一个事务在进行，避免了并发冲突和不一致的数据库状态。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、异常处理和连接池管理。此外，具体的数据库操作和事务逻辑需要根据实际需求进行编写。\n线程间的协调和同步 当涉及到线程间的协调和同步时，下面是一个简单的 Java 示例代码，演示了如何使用止步模式和条件变量来实现生产者-消费者模式：\nimport java.util.LinkedList; import java.util.Queue; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.ReentrantLock; public class ProducerConsumer { private Queue\u0026lt;Integer\u0026gt; buffer; private int maxSize; private ReentrantLock lock; private Condition notFull; private Condition notEmpty; public ProducerConsumer(int maxSize) { this.buffer = new LinkedList\u0026lt;\u0026gt;(); this.maxSize = maxSize; this.lock = new ReentrantLock(); this.notFull = lock.newCondition(); this.notEmpty = lock.newCondition(); } public void produce() throws InterruptedException { lock.lock(); try { while (buffer.size() == maxSize) { System.out.println(\u0026#34;Buffer is full. Producer is waiting.\u0026#34;); notFull.await(); } int item = generateItem(); buffer.offer(item); System.out.println(\u0026#34;Produced item: \u0026#34; + item); notEmpty.signalAll(); } finally { lock.unlock(); } } public void consume() throws InterruptedException { lock.lock(); try { while (buffer.isEmpty()) { System.out.println(\u0026#34;Buffer is empty. Consumer is waiting.\u0026#34;); notEmpty.await(); } int item = buffer.poll(); System.out.println(\u0026#34;Consumed item: \u0026#34; + item); notFull.signalAll(); } finally { lock.unlock(); } } private int generateItem() { // Generate a random item return (int) (Math.random() * 100); } } 在上述示例中，ProducerConsumer类代表了一个生产者消费者模型的实现，其中的produce方法用于生产项目，consume方法用于消费项目。\n在构造函数中，我们初始化了一个队列buffer作为缓冲区，以及一个maxSize变量表示缓冲区的最大容量。我们还创建了一个可重入锁lock，以及两个条件变量notFull和notEmpty，用于协调生产者和消费者之间的操作。\n在produce方法中，我们首先获取锁，并使用while循环来检查缓冲区是否已满。如果已满，表示无法继续生产，生产者线程会等待在notFull条件变量上。一旦有空闲空间，生产者会生成一个项目，并将其添加到缓冲区中。然后，我们唤醒所有等待在notEmpty条件变量上的消费者线程。\n在consume方法中，我们同样获取锁，并使用while循环来检查缓冲区是否为空。如果为空，表示无法继续消费，消费者线程会等待在notEmpty条件变量上。一旦有项目可供消费，消费者会从缓冲区中取出一个项目。然后，我们唤醒所有等待在notFull条件变量上的生产者线程。\n通过使用止步模式、可重入锁和条件变量，我们实现了生产者消费者模式的线程协调和同步，确保了生产者在缓冲区已满时等待，消费者在缓冲区为空时等待，从而避免了并发冲突和不一致的结果。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节、异常处理和线程安全性。此外，具体的生产者和消费者逻辑需要根据实际需求进行编写。\n错误处理和异常避免 当涉及到错误处理和异常避免时，下面是一个简单的 Java 示例代码，演示了如何使用异常处理和防御性编程来处理潜在的错误情况：\nimport java.io.File; import java.io.FileNotFoundException; import java.io.FileReader; import java.io.IOException; public class ErrorHandling { public static void main(String[] args) { try { readFile(\u0026#34;myfile.txt\u0026#34;); } catch (FileNotFoundException e) { System.out.println(\u0026#34;File not found: \u0026#34; + e.getMessage()); } catch (IOException e) { System.out.println(\u0026#34;Error reading file: \u0026#34; + e.getMessage()); } } public static void readFile(String filename) throws IOException { File file = new File(filename); if (!file.exists()) { throw new FileNotFoundException(\u0026#34;File not found: \u0026#34; + filename); } FileReader reader = null; try { reader = new FileReader(file); // 读取文件内容 } finally { if (reader != null) { try { reader.close(); } catch (IOException e) { System.out.println(\u0026#34;Error closing file: \u0026#34; + e.getMessage()); } } } } } 在上述示例中，我们尝试读取名为myfile.txt的文件。首先，我们调用readFile方法，并在方法签名中声明可能抛出的异常类型IOException。\n在readFile方法中，我们首先创建一个File对象，表示要读取的文件。然后，我们检查文件是否存在，如果不存在，抛出FileNotFoundException异常。\n接下来，我们创建一个FileReader对象来读取文件内容。在finally块中，我们使用防御性编程的方式关闭文件读取器。首先，我们检查读取器是否为null，如果不为null，则调用close方法关闭读取器。在关闭过程中，如果发生异常，我们捕获并处理它，并输出相应的错误消息。\n在main方法中，我们使用try-catch块来捕获可能抛出的异常。如果文件不存在，我们捕获并处理FileNotFoundException，如果在读取文件时发生错误，我们捕获并处理IOException。在异常处理块中，我们输出相应的错误消息。\n通过使用异常处理和防御性编程，我们可以捕获和处理潜在的错误情况，从而避免程序因错误而崩溃，并提供有用的错误信息。\n请注意，上述代码是一个简化的示例，实际应用中可能需要考虑更多的细节和特定的错误处理方式。此外，具体的错误处理和异常避免策略需要根据实际需求进行编写。\n相关模式 保护性暂挂模式 双重检查锁模式 鸣谢 Patterns in Java: A Catalog of Reusable Design Patterns Illustrated with UML, 2nd Edition, Volume 1 原文链接：https://java-design-patterns.com/zh/patterns/balking/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/java-design-patterns-balking/","summary":"本文主要介绍 Balking 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 止步模式（Balking）是一种在对象处于特定状态时才执行操作的设计模式。它用于防止对象在不完整或不合适的状态下执行某些代码，从而确保代码的正确性和一致性。\n该模式的核心思想是，在执行操作之前，检查对象的状态，并只在特定的状态下才执行操作。如果对象不处于预期状态，操作将被忽略或推迟执行，从而避免了不必要的操作或不一致的状态转换。\n以下是止步模式的要点和示例：\n对象状态检查：在执行操作之前，对象会检查自身的状态。这可以通过使用条件语句或状态标志来实现。 特定状态执行：只有当对象处于特定状态时，操作才会被执行。如果对象不满足执行条件，操作将被忽略或推迟执行。 线程安全考虑：由于止步模式通常涉及多线程环境，需要确保对共享资源的访问是线程安全的。可以使用同步机制（如 synchronized 关键字）来保护共享资源。 解释 真实世界例子\n洗衣机中有一个开始按钮，用于启动衣物洗涤。当洗衣机处于非活动状态时，按钮将按预期工作，但是如果已经在洗涤，则按钮将不起任何作用。\n通俗地说\n使用止步模式，仅当对象处于特定状态时才执行特定代码。\n维基百科说\n禁止模式是一种软件设计模式，仅当对象处于特定状态时才对对象执行操作。例如，一个对象读取 zip 压缩文件并在压缩文件没打开的时候调用 get 方法，对象将在请求的时候”止步“。\n程序示例\n在此示例中， WashingMachine是一个具有两个状态的对象，可以处于两种状态：ENABLED 和WASHING。 如果机器已启用，则使用线程安全方法将状态更改为 WASHING。 另一方面，如果已经进行了清洗并且任何其他线程执行 wash（），则它将不执行该操作，而是不执行任何操作而返回。\n这里是 WashingMachine 类相关的部分。\n@Slf4j public class WashingMachine { private final DelayProvider delayProvider; private WashingMachineState washingMachineState; public WashingMachine(DelayProvider delayProvider) { this.delayProvider = delayProvider; this.washingMachineState = WashingMachineState.ENABLED; } public WashingMachineState getWashingMachineState() { return washingMachineState; } public void wash() { synchronized (this) { var machineState = getWashingMachineState(); LOGGER.info(\u0026#34;{}: Actual machine state: {}\u0026#34;, Thread.currentThread().getName(), machineState); if (this.washingMachineState == WashingMachineState.WASHING) { LOGGER.error(\u0026#34;Cannot wash if the machine has been already washing!\u0026#34;); return; } this.","title":"Java设计模式：Balking"},{"content":"1. 概述 在本教程中，我们将讨论如何为 Spring REST API 实现全局错误处理程序。\n我们将使用每个异常的语义为客户端构建有意义的错误消息，其明确的目标是为客户端提供所有信息以轻松诊断问题。\n2. 自定义错误消息 让我们首先实现一个用于通过线路发送错误的简单结构 — ApiError：\npublic class ApiError { private HttpStatus status; private String message; private List\u0026lt;String\u0026gt; errors; public ApiError(HttpStatus status, String message, List\u0026lt;String\u0026gt; errors) { super(); this.status = status; this.message = message; this.errors = errors; } public ApiError(HttpStatus status, String message, String error) { super(); this.status = status; this.message = message; errors = Arrays.asList(error); } } 这里的信息应该很简单：\nstatus – HTTP 状态代码 message – 与异常相关的错误消息 error – 构建的错误消息列表 当然，对于 Spring 中的实际异常处理逻辑，我们将使用 @ControllerAdvice 注解：\n@ControllerAdvice public class CustomRestExceptionHandler extends ResponseEntityExceptionHandler { ... } 3. 处理错误请求异常 3.1.处理异常 现在让我们看看如何处理最常见的客户端错误 - 基本上是客户端向 API 发送无效请求的情况：\nBindException – 发生致命绑定错误时抛出此异常。 MethodArgumentNotValidException – 当使用 @Valid 注解的参数验证失败时抛出此异常： @Override protected ResponseEntity\u0026lt;Object\u0026gt; handleMethodArgumentNotValid( MethodArgumentNotValidException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;String\u0026gt;(); for (FieldError error : ex.getBindingResult().getFieldErrors()) { errors.add(error.getField() + \u0026#34;: \u0026#34; + error.getDefaultMessage()); } for (ObjectError error : ex.getBindingResult().getGlobalErrors()) { errors.add(error.getObjectName() + \u0026#34;: \u0026#34; + error.getDefaultMessage()); } ApiError apiError = new ApiError(HttpStatus.BAD_REQUEST, ex.getLocalizedMessage(), errors); return handleExceptionInternal( ex, apiError, headers, apiError.getStatus(), request); } 请注意，我们正在重写 ResponseEntityExceptionHandler 的基本方法并提供我们自己的自定义实现。情况并非总是如此。有时，我们需要处理基类中没有默认实现的自定义异常，稍后我们将在这里看到。\n下一个：\nMissingServletRequestPartException – 当未找到多部分请求的一部分时引发此异常。 MissingServletRequestParameterException – 当请求缺少参数时抛出此异常： @Override protected ResponseEntity\u0026lt;Object\u0026gt; handleMissingServletRequestParameter( MissingServletRequestParameterException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { String error = ex.getParameterName() + \u0026#34; parameter is missing\u0026#34;; ApiError apiError = new ApiError(HttpStatus.BAD_REQUEST, ex.getLocalizedMessage(), error); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } ConstraintViolationException – 此异常报告约束违规的结果： @ExceptionHandler({ ConstraintViolationException.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleConstraintViolation( ConstraintViolationException ex, WebRequest request) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;String\u0026gt;(); for (ConstraintViolation\u0026lt;?\u0026gt; violation : ex.getConstraintViolations()) { errors.add(violation.getRootBeanClass().getName() + \u0026#34; \u0026#34; + violation.getPropertyPath() + \u0026#34;: \u0026#34; + violation.getMessage()); } ApiError apiError = new ApiError(HttpStatus.BAD_REQUEST, ex.getLocalizedMessage(), errors); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } TypeMismatchException – 当尝试设置错误类型的 bean 属性时抛出此异常。 MethodArgumentTypeMismatchException – 当方法参数不是预期类型时抛出此异常： @ExceptionHandler({ MethodArgumentTypeMismatchException.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleMethodArgumentTypeMismatch( MethodArgumentTypeMismatchException ex, WebRequest request) { String error = ex.getName() + \u0026#34; should be of type \u0026#34; + ex.getRequiredType().getName(); ApiError apiError = new ApiError(HttpStatus.BAD_REQUEST, ex.getLocalizedMessage(), error); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } 3.2.从客户端使用 API 现在让我们看一下遇到 MethodArgumentTypeMismatchException 的测试。\n我们将发送一个 id 为 String 而不是 long 的请求：\n@Test public void whenMethodArgumentMismatch_thenBadRequest() { Response response = givenAuth().get(URL_PREFIX + \u0026#34;/api/foos/ccc\u0026#34;); ApiError error = response.as(ApiError.class); assertEquals(HttpStatus.BAD_REQUEST, error.getStatus()); assertEquals(1, error.getErrors().size()); assertTrue(error.getErrors().get(0).contains(\u0026#34;should be of type\u0026#34;)); } 最后，考虑到同样的请求：\nRequest method:\tGET Request path:\thttp://localhost:8080/spring-security-rest/api/foos/ccc 此类 JSON 错误响应如下所示：\n{ \u0026#34;status\u0026#34;: \u0026#34;BAD_REQUEST\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Failed to convert value of type [java.lang.String] to required type [java.lang.Long]; nested exception is java.lang.NumberFormatException: For input string: \\\u0026#34;ccc\\\u0026#34;\u0026#34;, \u0026#34;errors\u0026#34;: [ \u0026#34;id should be of type java.lang.Long\u0026#34; ] } 4. 处理 NoHandlerFoundException 接下来，我们可以自定义 servlet 来抛出此异常，而不是发送 404 响应：\n\u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;api\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt; org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;throwExceptionIfNoHandlerFound\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/servlet\u0026gt; 然后，一旦发生这种情况，我们可以像处理任何其他异常一样简单地处理它：\n@Override protected ResponseEntity\u0026lt;Object\u0026gt; handleNoHandlerFoundException( NoHandlerFoundException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { String error = \u0026#34;No handler found for \u0026#34; + ex.getHttpMethod() + \u0026#34; \u0026#34; + ex.getRequestURL(); ApiError apiError = new ApiError(HttpStatus.NOT_FOUND, ex.getLocalizedMessage(), error); return new ResponseEntity\u0026lt;Object\u0026gt;(apiError, new HttpHeaders(), apiError.getStatus()); } 这是一个简单的测试：\n@Test public void whenNoHandlerForHttpRequest_thenNotFound() { Response response = givenAuth().delete(URL_PREFIX + \u0026#34;/api/xx\u0026#34;); ApiError error = response.as(ApiError.class); assertEquals(HttpStatus.NOT_FOUND, error.getStatus()); assertEquals(1, error.getErrors().size()); assertTrue(error.getErrors().get(0).contains(\u0026#34;No handler found\u0026#34;)); }让我们看一下完整的请求： Request method:\tDELETE Request path:\thttp://localhost:8080/spring-security-rest/api/xx 以及错误 JSON 响应：\n{ \u0026#34;status\u0026#34;:\u0026#34;NOT_FOUND\u0026#34;, \u0026#34;message\u0026#34;:\u0026#34;No handler found for DELETE /spring-security-rest/api/xx\u0026#34;, \u0026#34;errors\u0026#34;:[ \u0026#34;No handler found for DELETE /spring-security-rest/api/xx\u0026#34; ] } 接下来，我们将看看另一个有趣的异常。\n5. 处理 HttpRequestMethodNotSupportedException 当我们使用不受支持的 HTTP 方法发送请求时，会发生 HttpRequestMethodNotSupportedException：\n@Override protected ResponseEntity\u0026lt;Object\u0026gt; handleHttpRequestMethodNotSupported( HttpRequestMethodNotSupportedException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { StringBuilder builder = new StringBuilder(); builder.append(ex.getMethod()); builder.append( \u0026#34; method is not supported for this request. Supported methods are \u0026#34;); ex.getSupportedHttpMethods().forEach(t -\u0026gt; builder.append(t + \u0026#34; \u0026#34;)); ApiError apiError = new ApiError(HttpStatus.METHOD_NOT_ALLOWED, ex.getLocalizedMessage(), builder.toString()); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } 这是一个重现此异常的简单测试：\n@Test public void whenHttpRequestMethodNotSupported_thenMethodNotAllowed() { Response response = givenAuth().delete(URL_PREFIX + \u0026#34;/api/foos/1\u0026#34;); ApiError error = response.as(ApiError.class); assertEquals(HttpStatus.METHOD_NOT_ALLOWED, error.getStatus()); assertEquals(1, error.getErrors().size()); assertTrue(error.getErrors().get(0).contains(\u0026#34;Supported methods are\u0026#34;)); } 这是完整的请求：\nRequest method:\tDELETE Request path:\thttp://localhost:8080/spring-security-rest/api/foos/1 以及错误 JSON 响应：\n{ \u0026#34;status\u0026#34;:\u0026#34;METHOD_NOT_ALLOWED\u0026#34;, \u0026#34;message\u0026#34;:\u0026#34;Request method \u0026#39;DELETE\u0026#39; not supported\u0026#34;, \u0026#34;errors\u0026#34;:[ \u0026#34;DELETE method is not supported for this request. Supported methods are GET \u0026#34; ] } 6. 处理 HttpMediaTypeNotSupportedException 现在让我们处理 HttpMediaTypeNotSupportedException，当客户端发送不支持的媒体类型的请求时会发生该异常：\n@Override protected ResponseEntity\u0026lt;Object\u0026gt; handleHttpMediaTypeNotSupported( HttpMediaTypeNotSupportedException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { StringBuilder builder = new StringBuilder(); builder.append(ex.getContentType()); builder.append(\u0026#34; media type is not supported. Supported media types are \u0026#34;); ex.getSupportedMediaTypes().forEach(t -\u0026gt; builder.append(t + \u0026#34;, \u0026#34;)); ApiError apiError = new ApiError(HttpStatus.UNSUPPORTED_MEDIA_TYPE, ex.getLocalizedMessage(), builder.substring(0, builder.length() - 2)); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } 这是针对此问题的简单测试：\n@Test public void whenSendInvalidHttpMediaType_thenUnsupportedMediaType() { Response response = givenAuth().body(\u0026#34;\u0026#34;).post(URL_PREFIX + \u0026#34;/api/foos\u0026#34;); ApiError error = response.as(ApiError.class); assertEquals(HttpStatus.UNSUPPORTED_MEDIA_TYPE, error.getStatus()); assertEquals(1, error.getErrors().size()); assertTrue(error.getErrors().get(0).contains(\u0026#34;media type is not supported\u0026#34;)); } 最后，这是一个示例请求：\nRequest method:\tPOST Request path:\thttp://localhost:8080/spring-security- Headers:\tContent-Type=text/plain; charset=ISO-8859-1 以及错误 JSON 响应：\n{ \u0026#34;status\u0026#34;:\u0026#34;UNSUPPORTED_MEDIA_TYPE\u0026#34;, \u0026#34;message\u0026#34;:\u0026#34;Content type \u0026#39;text/plain;charset=ISO-8859-1\u0026#39; not supported\u0026#34;, \u0026#34;errors\u0026#34;:[\u0026#34;text/plain;charset=ISO-8859-1 media type is not supported. Supported media types are text/xml application/x-www-form-urlencoded application/*+xml application/json;charset=UTF-8 application/*+json;charset=UTF-8 */\u0026#34; ] } 7. 默认处理程序 最后，我们将实现一个后备处理程序 - 一种包罗万象的逻辑类型，用于处理没有特定处理程序的所有其他异常：\n@ExceptionHandler({ Exception.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleAll(Exception ex, WebRequest request) { ApiError apiError = new ApiError( HttpStatus.INTERNAL_SERVER_ERROR, ex.getLocalizedMessage(), \u0026#34;error occurred\u0026#34;); return new ResponseEntity\u0026lt;Object\u0026gt;( apiError, new HttpHeaders(), apiError.getStatus()); } 8.结论 为 Spring REST API 构建适当、成熟的错误处理程序非常困难，而且绝对是一个迭代过程。希望本教程将是一个良好的起点，也是帮助 API 客户端快速轻松地诊断错误并克服错误的良好锚点。\n本教程的完整实现可以在 GitHub 项目中找到。这是一个基于 Eclipse 的项目，因此应该很容易导入并按原样运行。\n原文链接：https://www.baeldung.com/global-error-handler-in-a-spring-rest-api\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/global-error-handler-in-a-spring-rest-api/","summary":"1. 概述 在本教程中，我们将讨论如何为 Spring REST API 实现全局错误处理程序。\n我们将使用每个异常的语义为客户端构建有意义的错误消息，其明确的目标是为客户端提供所有信息以轻松诊断问题。\n2. 自定义错误消息 让我们首先实现一个用于通过线路发送错误的简单结构 — ApiError：\npublic class ApiError { private HttpStatus status; private String message; private List\u0026lt;String\u0026gt; errors; public ApiError(HttpStatus status, String message, List\u0026lt;String\u0026gt; errors) { super(); this.status = status; this.message = message; this.errors = errors; } public ApiError(HttpStatus status, String message, String error) { super(); this.status = status; this.message = message; errors = Arrays.asList(error); } } 这里的信息应该很简单：\nstatus – HTTP 状态代码 message – 与异常相关的错误消息 error – 构建的错误消息列表 当然，对于 Spring 中的实际异常处理逻辑，我们将使用 @ControllerAdvice 注解：\n@ControllerAdvice public class CustomRestExceptionHandler extends ResponseEntityExceptionHandler { ... } 3. 处理错误请求异常 3.1.处理异常 现在让我们看看如何处理最常见的客户端错误 - 基本上是客户端向 API 发送无效请求的情况：\nBindException – 发生致命绑定错误时抛出此异常。 MethodArgumentNotValidException – 当使用 @Valid 注解的参数验证失败时抛出此异常： @Override protected ResponseEntity\u0026lt;Object\u0026gt; handleMethodArgumentNotValid( MethodArgumentNotValidException ex, HttpHeaders headers, HttpStatus status, WebRequest request) { List\u0026lt;String\u0026gt; errors = new ArrayList\u0026lt;String\u0026gt;(); for (FieldError error : ex.","title":"[译]REST API 的自定义错误消息处理"},{"content":"1. 概述 本教程将说明如何使用 Spring 为 REST API 实现异常处理。我们还将获得一些历史概述，并了解不同版本引入了哪些新选项。\n在 Spring 3.2 之前，Spring MVC 应用程序中处理异常的两种主要方法是 HandlerExceptionResolver 或 @ExceptionHandler 注解。两者都有一些明显的缺点。\n从 3.2 开始，我们使用了 @ControllerAdvice 注释来解决前两个解决方案的局限性，并促进整个应用程序的统一异常处理。\n现在 Spring 5 引入了 ResponseStatusException 类，一种在 REST API 中进行基本错误处理的快速方法。\n所有这些都有一个共同点：它们很好地处理了关注点分离。应用程序可以正常抛出异常来指示某种失败，然后将单独处理。\n最后，我们将了解 Spring Boot 带来的功能以及如何配置它以满足我们的需求。\n2.方案一：控制器级@ExceptionHandler 第一个解决方案在 @Controller 级别工作。我们将定义一个处理异常的方法并使用@ExceptionHandler 进行注释：\npublic class FooController{ //... @ExceptionHandler({ CustomException1.class, CustomException2.class }) public void handleException() { // } } 这种方法有一个主要缺点：· 注解的方法仅对特定的控制器有效，而不是对整个应用程序全局有效。当然，将其添加到每个控制器使其不太适合通用异常处理机制。\n我们可以通过让所有控制器扩展基本控制器类来解决此限制。\n然而，对于无论出于何种原因这是不可能的应用程序来说，此解决方案可能是一个问题。例如，控制器可能已经从另一个基类扩展，该基类可能位于另一个 jar 中或不可直接修改，或者本身可能不可直接修改。\n接下来，我们将研究另一种解决异常处理问题的方法 - 一种全局的方法，不包括对现有工件（例如控制器）的任何更改。\n3.解决方案 2：HandlerExceptionResolver 第二种解决方案是定义一个 HandlerExceptionResolver。这将解决应用程序抛出的任何异常。它还允许我们在 REST API 中实现统一的异常处理机制。\n在选择自定义解析器之前，让我们先回顾一下现有的实现。\n3.1.异常处理器异常解析器 该解析器是在 Spring 3.1 中引入的，并且在 DispatcherServlet 中默认启用。这实际上是前面介绍的 @ExceptionHandler 机制如何工作的核心组件。\n3.2.默认处理程序异常解析器 这个解析器是在 Spring 3.0 中引入的，并且在 DispatcherServlet 中默认启用。\n它用于将标准 Spring 异常解析为其相应的 HTTP 状态代码，即客户端错误 4xx 和服务器错误 5xx 状态代码。以下是它处理的 Spring 异常的完整列表以及它们如何映射到状态代码。\n虽然它确实正确设置了响应的状态代码，但一个限制是它不会对响应正文设置任何内容。对于 REST API（状态代码实际上不足以向客户端提供足够的信息），响应还必须有一个正文，以允许应用程序提供有关失败的附加信息。\n这可以通过 · 配置视图分辨率并渲染错误内容来解决，但该解决方案显然不是最优的。这就是为什么 Spring 3.2 引入了一个更好的选项，我们将在后面的部分中讨论。\n3.3.响应状态异常解析器 这个解析器也在 Spring 3.0 中引入，并且在 · 中默认启用。\n它的主要职责是使用自定义异常上可用的 @ResponseStatus 注释并将这些异常映射到 HTTP 状态代码。\n这样的自定义异常可能如下所示：\n@ResponseStatus(value = HttpStatus.NOT_FOUND) public class MyResourceNotFoundException extends RuntimeException { public MyResourceNotFoundException() { super(); } public MyResourceNotFoundException(String message, Throwable cause) { super(message, cause); } public MyResourceNotFoundException(String message) { super(message); } public MyResourceNotFoundException(Throwable cause) { super(cause); } } 与 DefaultHandlerExceptionResolver 相同，此解析器在处理响应正文的方式上受到限制 - 它确实将状态代码映射到响应上，但正文仍然为空。\n3.4.自定义 HandlerExceptionResolver DefaultHandlerExceptionResolver 和 ResponseStatusExceptionResolver 的组合大大有助于为 Spring RESTful 服务提供良好的错误处理机制。如前所述，缺点是无法控制响应的正文。\n理想情况下，我们希望能够输出 JSON 或 XML，具体取决于客户端要求的格式（通过 Accept 标头）。\n仅此一点就证明创建一个新的自定义异常解析器是合理的：\n@Component public class RestResponseStatusExceptionResolver extends AbstractHandlerExceptionResolver { @Override protected ModelAndView doResolveException( HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) { try { if (ex instanceof IllegalArgumentException) { return handleIllegalArgument( (IllegalArgumentException) ex, response, handler); } ... } catch (Exception handlerException) { logger.warn(\u0026#34;Handling of [\u0026#34; + ex.getClass().getName() + \u0026#34;] resulted in Exception\u0026#34;, handlerException); } return null; } private ModelAndView handleIllegalArgument(IllegalArgumentException ex, HttpServletResponse response) throws IOException { response.sendError(HttpServletResponse.SC_CONFLICT); String accept = request.getHeader(HttpHeaders.ACCEPT); ... return new ModelAndView(); } } 这里需要注意的一个细节是我们可以访问请求本身，因此我们可以考虑客户端发送的 Accept 标头的值。\n例如，如果客户端请求 application/json，那么在出现错误情况时，我们希望确保返回用 application/json 编码的响应正文。\n另一个重要的实现细节是我们返回一个 ModelAndView——这是响应的主体，它将允许我们对其进行必要的设置。\n这种方法是一种一致且易于配置的机制，用于 Spring REST 服务的错 ​​ 误处理。\n然而，它确实有局限性：它与低级 HtttpServletResponse 交互，并且适合使用 ModelAndView 的旧 MVC 模型，因此仍有改进的空间。\n4.解决方案 3：@ControllerAdvice Spring 3.2 通过 @ControllerAdvice 注释支持全局 @ExceptionHandler。\n这实现了一种脱离旧 MVC 模型的机制，并利用 ResponseEntity 以及 @ExceptionHandler 的类型安全性和灵活性：\n@ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler(value = { IllegalArgumentException.class, IllegalStateException.class }) protected ResponseEntity\u0026lt;Object\u0026gt; handleConflict( RuntimeException ex, WebRequest request) { String bodyOfResponse = \u0026#34;This should be application specific\u0026#34;; return handleExceptionInternal(ex, bodyOfResponse, new HttpHeaders(), HttpStatus.CONFLICT, request); } } @ControllerAdvice 注释允许我们将之前的多个分散的 @ExceptionHandler 合并到一个全局错误处理组件中。\n实际的机制非常简单但也非常灵活：\n它使我们能够完全控制响应正文以及状态代码。 它提供了多个异常到同一方法的映射，以便一起处理。 它充分利用了较新的 RESTful ResposeEntity 响应。 这里要记住的一件事是将使用 @ExceptionHandler 声明的异常与用作方法参数的异常相匹配。\n如果它们不匹配，编译器不会抱怨——没有理由应该抱怨——Spring 也不会抱怨。\n然而，当异常在运行时实际抛出时，异常解决机制将失败，并显示：\njava.lang.IllegalStateException: No suitable resolver for argument [0] [type=...] HandlerMethod details: ... 5.解决方案 4：ResponseStatusException（Spring 5 及以上版本） Spring 5 引入了 ResponseStatusException 类。\n我们可以创建它的一个实例，提供 HttpStatus 和可选的原因：\n@GetMapping(value = \u0026#34;/{id}\u0026#34;) public Foo findById(@PathVariable(\u0026#34;id\u0026#34;) Long id, HttpServletResponse response) { try { Foo resourceById = RestPreconditions.checkFound(service.findOne(id)); eventPublisher.publishEvent(new SingleResourceRetrievedEvent(this, response)); return resourceById; } catch (MyResourceNotFoundException exc) { throw new ResponseStatusException( HttpStatus.NOT_FOUND, \u0026#34;Foo Not Found\u0026#34;, exc); } } 使用 ResponseStatusException 有什么好处？\n非常适合原型设计：我们可以非常快速地实施基本解决方案。 一种类型，多个状态代码：一种异常类型可以导致多种不同的响应。与 @ExceptionHandler 相比，这减少了紧密耦合。 我们不必创建那么多自定义异常类。 由于可以通过编程方式创建异常，因此我们可以更好地控制异常处理。 那么权衡又如何呢？\n没有统一的异常处理方式：与提供全局方法的 @ControllerAdvice 相比，强制执行一些应用程序范围的约定更加困难。 代码重复：我们可能会发现自己在多个控制器中复制代码。 我们还应该注意到，可以在一个应用程序中组合不同的方法。\n例如，我们可以全局实现 @ControllerAdvice，也可以在本地实现 ResponseStatusExceptions。\n但是，我们需要小心：如果可以通过多种方式处理相同的异常，我们可能会注意到一些令人惊讶的行为。一种可能的约定是始终以一种方式处理一种特定类型的异常。\n有关更多详细信息和更多示例，请参阅有关 ResponseStatusException 的教程。\n6.处理 Spring Security 中拒绝访问的情况 当经过身份验证的用户尝试访问他没有足够权限访问的资源时，就会发生访问被拒绝的情况。\n6.1. REST 和方法级安全性 最后，让我们看看如何处理方法级安全注解 @PreAuthorize、@PostAuthorize 和 @Secure 抛出的 Access Denied 异常。\n当然，我们也将使用前面讨论的全局异常处理机制来处理 AccessDeniedException：\n@ControllerAdvice public class RestResponseEntityExceptionHandler extends ResponseEntityExceptionHandler { @ExceptionHandler({ AccessDeniedException.class }) public ResponseEntity\u0026lt;Object\u0026gt; handleAccessDeniedException( Exception ex, WebRequest request) { return new ResponseEntity\u0026lt;Object\u0026gt;( \u0026#34;Access denied message here\u0026#34;, new HttpHeaders(), HttpStatus.FORBIDDEN); } ... } 7. Spring Boot 支持 Spring Boot 提供了 ErrorController 实现来以合理的方式处理错误。\n简而言之，它为浏览器提供后备错误页面（也称为 Whitelabel 错误页面），并为 RESTful、非 HTML 请求提供 JSON 响应：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2019-01-17T16:12:45.977+0000\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Error processing the request!\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/my-endpoint-with-exceptions\u0026#34; } 与往常一样，Spring Boot 允许使用属性配置这些功能：\nserver.error.whitelabel.enabled: 可用于禁用 Whitelabel 错误页面并依赖 servlet 容器提供 HTML 错误消息 server.error.include-stacktrace: 具有始终值；在 HTML 和 JSON 默认响应中包含堆栈跟踪 server.error.include-message: 从 2.3 版本开始，Spring Boot 隐藏了响应中的 message 字段，以避免泄露敏感信息；我们可以使用带有 always 值的这个属性来启用它 除了这些属性之外，我们还可以为 /error 提供我们自己的视图解析器映射，覆盖白标签页面。\n我们还可以通过在上下文中包含 ErrorAttributes bean 来自定义要在响应中显示的属性。我们可以扩展 Spring Boot 提供的 DefaultErrorAttributes 类来使事情变得更简单：\n@Component public class MyCustomErrorAttributes extends DefaultErrorAttributes { @Override public Map\u0026lt;String, Object\u0026gt; getErrorAttributes( WebRequest webRequest, ErrorAttributeOptions options) { Map\u0026lt;String, Object\u0026gt; errorAttributes = super.getErrorAttributes(webRequest, options); errorAttributes.put(\u0026#34;locale\u0026#34;, webRequest.getLocale() .toString()); errorAttributes.remove(\u0026#34;error\u0026#34;); //... return errorAttributes; } } 如果我们想进一步定义（或覆盖）应用程序如何处理特定内容类型的错误，我们可以注册一个 ErrorController bean。\n同样，我们可以利用 Spring Boot 提供的默认 BasicErrorController 来帮助我们。\n例如，假设我们想要自定义应用程序如何处理 XML 端点中触发的错误。我们所要做的就是使用 @RequestMapping 定义一个公共方法，并声明它生成 application/xml 媒体类型：\n@Component public class MyErrorController extends BasicErrorController { public MyErrorController( ErrorAttributes errorAttributes, ServerProperties serverProperties) { super(errorAttributes, serverProperties.getError()); } @RequestMapping(produces = MediaType.APPLICATION_XML_VALUE) public ResponseEntity\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; xmlError(HttpServletRequest request) { // ... } } 注意：这里我们仍然依赖于我们项目中可能定义的 server.error.* 引导属性，这些属性绑定到 ServerProperties bean。\n8. 结论 本文讨论了在 Spring 中实现 REST API 异常处理机制的几种方法，从旧的机制开始，继续提供 Spring 3.2 支持，一直到 4.x 和 5.x。\n与往常一样，本文中提供的代码可以在 GitHub 上获取。\nSpring Security 相关的代码可以查看 spring-security-rest 模块。\n原文链接：https://www.baeldung.com/exception-handling-for-rest-with-spring\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/exception-handling-for-rest-with-spring/","summary":"1. 概述 本教程将说明如何使用 Spring 为 REST API 实现异常处理。我们还将获得一些历史概述，并了解不同版本引入了哪些新选项。\n在 Spring 3.2 之前，Spring MVC 应用程序中处理异常的两种主要方法是 HandlerExceptionResolver 或 @ExceptionHandler 注解。两者都有一些明显的缺点。\n从 3.2 开始，我们使用了 @ControllerAdvice 注释来解决前两个解决方案的局限性，并促进整个应用程序的统一异常处理。\n现在 Spring 5 引入了 ResponseStatusException 类，一种在 REST API 中进行基本错误处理的快速方法。\n所有这些都有一个共同点：它们很好地处理了关注点分离。应用程序可以正常抛出异常来指示某种失败，然后将单独处理。\n最后，我们将了解 Spring Boot 带来的功能以及如何配置它以满足我们的需求。\n2.方案一：控制器级@ExceptionHandler 第一个解决方案在 @Controller 级别工作。我们将定义一个处理异常的方法并使用@ExceptionHandler 进行注释：\npublic class FooController{ //... @ExceptionHandler({ CustomException1.class, CustomException2.class }) public void handleException() { // } } 这种方法有一个主要缺点：· 注解的方法仅对特定的控制器有效，而不是对整个应用程序全局有效。当然，将其添加到每个控制器使其不太适合通用异常处理机制。\n我们可以通过让所有控制器扩展基本控制器类来解决此限制。\n然而，对于无论出于何种原因这是不可能的应用程序来说，此解决方案可能是一个问题。例如，控制器可能已经从另一个基类扩展，该基类可能位于另一个 jar 中或不可直接修改，或者本身可能不可直接修改。\n接下来，我们将研究另一种解决异常处理问题的方法 - 一种全局的方法，不包括对现有工件（例如控制器）的任何更改。\n3.解决方案 2：HandlerExceptionResolver 第二种解决方案是定义一个 HandlerExceptionResolver。这将解决应用程序抛出的任何异常。它还允许我们在 REST API 中实现统一的异常处理机制。\n在选择自定义解析器之前，让我们先回顾一下现有的实现。\n3.1.异常处理器异常解析器 该解析器是在 Spring 3.1 中引入的，并且在 DispatcherServlet 中默认启用。这实际上是前面介绍的 @ExceptionHandler 机制如何工作的核心组件。\n3.2.默认处理程序异常解析器 这个解析器是在 Spring 3.0 中引入的，并且在 DispatcherServlet 中默认启用。\n它用于将标准 Spring 异常解析为其相应的 HTTP 状态代码，即客户端错误 4xx 和服务器错误 5xx 状态代码。以下是它处理的 Spring 异常的完整列表以及它们如何映射到状态代码。","title":"[译]使用Spring进行REST的错误处理"},{"content":"1. 简介 在本教程中，我们将重点关注使用 @Async 传播 Spring Security 主体 默认情况下，Spring Security 身份验证绑定到 ThreadLocal - 因此，当执行流在带有 @Async 的新线程中运行时，它不会是经过身份验证的上下文。\n这并不理想——让我们解决它。\n2.Maven 依赖 为了在 Spring Security 中使用异步集成，我们需要在 pom.xml 的依赖项中包含以下部分：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Spring Security 依赖项。\n3.使用@Async 进行 Spring Security 传播 我们先写一个简单的例子：\n@RequestMapping(method = RequestMethod.GET, value = \u0026#34;/async\u0026#34;) @ResponseBody public Object standardProcessing() throws Exception { log.info(\u0026#34;Outside the @Async logic - before the async call: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); asyncService.asyncCall(); log.info(\u0026#34;Inside the @Async logic - after the async call: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); return SecurityContextHolder.getContext().getAuthentication().getPrincipal(); } 我们想要检查 Spring SecurityContext 是否传播到新线程。首先，我们在异步调用之前记录上下文，接下来我们运行异步方法，最后再次记录上下文。 asyncCall() 方法具有以下实现：\n@Async @Override public void asyncCall() { log.info(\u0026#34;Inside the @Async logic: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); } 正如我们所看到的，只有一行代码将输出异步方法的新线程内的上下文。\n4. 默认配置 默认情况下，@Async 方法内的安全上下文将具有空值。\n特别是，如果我们运行异步逻辑，我们将能够在主程序中记录 Authentication 对象，但是当我们将其记录在 @Async 中时，它将为 null。这是日志输出的示例：\nweb - 2016-12-30 22:41:58,916 [http-nio-8081-exec-3] INFO o.baeldung.web.service.AsyncService - Outside the @Async logic - before the async call: org.springframework.security.core.userdetails.User@76507e51: Username: temporary; ... web - 2016-12-30 22:41:58,921 [http-nio-8081-exec-3] INFO o.baeldung.web.service.AsyncService - Inside the @Async logic - after the async call: org.springframework.security.core.userdetails.User@76507e51: Username: temporary; ... web - 2016-12-30 22:41:58,926 [SimpleAsyncTaskExecutor-1] ERROR o.s.a.i.SimpleAsyncUncaughtExceptionHandler - Unexpected error occurred invoking async method \u0026#39;public void com.baeldung.web.service.AsyncServiceImpl.asyncCall()\u0026#39;. java.lang.NullPointerException: null 因此，正如您所看到的，在执行程序线程内，我们的调用失败并出现 NPE，正如预期的那样——因为主体在那里不可用。\n5. 异步安全上下文配置 如果我们想要访问异步线程内部的主体，就像我们可以在外部访问它一样，我们需要创建 DelegatingSecurityContextAsyncTaskExecutor bean：\n@Bean public DelegatingSecurityContextAsyncTaskExecutor taskExecutor(ThreadPoolTaskExecutor delegate) { return new DelegatingSecurityContextAsyncTaskExecutor(delegate); } 通过这样做，Spring 将在每个 @Async 调用中使用当前的 SecurityContext。\n现在，让我们再次运行该应用程序并查看日志信息以确保情况确实如此：\nweb - 2016-12-30 22:45:18,013 [http-nio-8081-exec-3] INFO o.baeldung.web.service.AsyncService - Outside the @Async logic - before the async call: org.springframework.security.core.userdetails.User@76507e51: Username: temporary; ... web - 2016-12-30 22:45:18,018 [http-nio-8081-exec-3] INFO o.baeldung.web.service.AsyncService - Inside the @Async logic - after the async call: org.springframework.security.core.userdetails.User@76507e51: Username: temporary; ... web - 2016-12-30 22:45:18,019 [SimpleAsyncTaskExecutor-1] INFO o.baeldung.web.service.AsyncService - Inside the @Async logic: org.springframework.security.core.userdetails.User@76507e51: Username: temporary; ... 正如我们所期望的，我们在异步执行器线程中看到了相同的原理。\n6. 使用案例 有一些有趣的用例，我们可能希望确保 SecurityContext 像这样传播：\n我们想要发出多个可以并行运行并且可能需要大量时间来执行的外部请求 我们需要在本地进行一些重要的处理，并且我们的外部请求可以与该处理并行执行 其他代表即发即忘场景，例如发送电子邮件 7.结论 在本快速教程中，我们介绍了 Spring 对使用传播的 SecurityContext 发送异步请求的支持。从编程模型的角度来看，新功能看似简单。\n请注意，如果先前以同步方式将多个方法调用链接在一起，则转换为异步方法可能需要同步结果。\n此 示例 也可作为 Github 上的 Maven 项目提供。\n原文链接：https://www.baeldung.com/spring-security-async-principal-propagation\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/spring-security-async-principal-propagation/","summary":"1. 简介 在本教程中，我们将重点关注使用 @Async 传播 Spring Security 主体 默认情况下，Spring Security 身份验证绑定到 ThreadLocal - 因此，当执行流在带有 @Async 的新线程中运行时，它不会是经过身份验证的上下文。\n这并不理想——让我们解决它。\n2.Maven 依赖 为了在 Spring Security 中使用异步集成，我们需要在 pom.xml 的依赖项中包含以下部分：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.7.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以在此处找到最新版本的 Spring Security 依赖项。\n3.使用@Async 进行 Spring Security 传播 我们先写一个简单的例子：\n@RequestMapping(method = RequestMethod.GET, value = \u0026#34;/async\u0026#34;) @ResponseBody public Object standardProcessing() throws Exception { log.info(\u0026#34;Outside the @Async logic - before the async call: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); asyncService.asyncCall(); log.info(\u0026#34;Inside the @Async logic - after the async call: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); return SecurityContextHolder.getContext().getAuthentication().getPrincipal(); } 我们想要检查 Spring SecurityContext 是否传播到新线程。首先，我们在异步调用之前记录上下文，接下来我们运行异步方法，最后再次记录上下文。 asyncCall() 方法具有以下实现：\n@Async @Override public void asyncCall() { log.info(\u0026#34;Inside the @Async logic: \u0026#34; + SecurityContextHolder.getContext().getAuthentication().getPrincipal()); } 正如我们所看到的，只有一行代码将输出异步方法的新线程内的上下文。","title":"[译]使用@Async进行Spring Security上下文传播"},{"content":"1. 概述 在本教程中，我们将讨论如何在 Spring 中使用事件。\n事件是框架中最容易被忽视的功能之一，但也是最有用的功能之一。与 Spring 中的许多其他功能一样，事件发布是 ApplicationContext 提供的功能之一。\n有一些简单的准则需要遵循：\n如果我们使用 Spring Framework 4.2 之前的版本，事件类应该扩展 ApplicationEvent。从 4.2 版本开始，事件类不再需要扩展 ApplicationEvent 类。 发布者应该注入一个 ApplicationEventPublisher 对象。 监听器应该实现 ApplicationListener 接口。 2. 自定义事件 Spring 允许我们创建和发布默认情况下同步的自定义事件。这有一些优点，例如侦听器能够参与发布者的事务上下文。\n2.1.一个简单的应用程序事件 让我们创建一个简单的事件类——只是一个存储事件数据的占位符。\n在本例中，事件类保存一条字符串消息：\npublic class CustomSpringEvent extends ApplicationEvent { private String message; public CustomSpringEvent(Object source, String message) { super(source); this.message = message; } public String getMessage() { return message; } } 2.2.发布者 现在让我们创建该事件的发布者。发布者构造事件对象并将其发布给正在侦听的任何人。\n要发布事件，发布者只需注入 ApplicationEventPublisher 并使用 publishEvent() API：\n@Component public class CustomSpringEventPublisher { @Autowired private ApplicationEventPublisher applicationEventPublisher; public void publishCustomEvent(final String message) { System.out.println(\u0026#34;Publishing custom event. \u0026#34;); CustomSpringEvent customSpringEvent = new CustomSpringEvent(this, message); applicationEventPublisher.publishEvent(customSpringEvent); } } 或者，发布者类可以实现 ApplicationEventPublisherAware 接口，这也将在应用程序启动时注入事件发布者。通常，使用 @Autowire 注入发布者会更简单。\n从 Spring Framework 4.2 开始，ApplicationEventPublisher 接口为publishEvent(Object event) 方法提供了新的重载，该方法接受任何对象作为事件。因此，Spring 事件不再需要扩展ApplicationEvent 类。\n2.3.监听者 最后，让我们创建监听器。\n监听器的唯一要求是是一个 bean 并实现 ApplicationListener 接口：\n@Component public class CustomSpringEventListener implements ApplicationListener\u0026lt;CustomSpringEvent\u0026gt; { @Override public void onApplicationEvent(CustomSpringEvent event) { System.out.println(\u0026#34;Received spring custom event - \u0026#34; + event.getMessage()); } } 请注意我们的自定义侦听器如何使用自定义事件的通用类型进行参数化，这使得 onApplicationEvent() 方法类型安全。这也避免了必须检查对象是否是特定事件类的实例并转换它。\n而且，正如已经讨论过的（默认情况下 Spring 事件是同步的）， doStuffAndPublishAnEvent() 方法会阻塞，直到所有侦听器完成对事件的处理。\n3. 创建异步事件 在某些情况下，同步发布事件并不是我们真正想要的——我们可能需要异步处理事件。\n我们可以通过创建带有执行器的 ApplicationEventMulticaster bean 在配置中打开它。\n出于我们的目的，SimpleAsyncTaskExecutor 效果很好：\n@Configuration public class AsynchronousSpringEventsConfig { @Bean(name = \u0026#34;applicationEventMulticaster\u0026#34;) public ApplicationEventMulticaster simpleApplicationEventMulticaster() { SimpleApplicationEventMulticaster eventMulticaster = new SimpleApplicationEventMulticaster(); eventMulticaster.setTaskExecutor(new SimpleAsyncTaskExecutor()); return eventMulticaster; } } 事件、发布者和侦听器实现与以前相同，但现在侦听器将在单独的线程中异步处理事件。\n4.现有框架事件 Spring 本身发布了各种开箱即用的事件。例如，ApplicationContext 将触发各种框架事件：ContextRefreshedEvent、ContextStartedEvent、RequestHandledEvent 等。\n这些事件为应用程序开发人员提供了一个选项，可以挂钩应用程序和上下文的生命周期，并在需要时添加自己的自定义逻辑。\n下面是侦听器侦听上下文刷新的简单示例：\npublic class ContextRefreshedListener implements ApplicationListener\u0026lt;ContextRefreshedEvent\u0026gt; { @Override public void onApplicationEvent(ContextRefreshedEvent cse) { System.out.println(\u0026#34;Handling context re-freshed event. \u0026#34;); } } 5. 注解驱动的事件监听器 从 Spring 4.2 开始，事件侦听器不需要是实现 ApplicationListener 接口的 bean — 它可以通过 @EventListener 注释在托管 bean 的任何公共方法上注册：\n@Component public class AnnotationDrivenEventListener { @EventListener public void handleContextStart(ContextStartedEvent cse) { System.out.println(\u0026#34;Handling context started event.\u0026#34;); } } 和以前一样，方法签名声明它消耗的事件类型。\n默认情况下，监听器是同步调用的。但是，我们可以通过添加 @Async 注解轻松使其异步。我们只需要记住在应用程序中启用异步支持即可。\n6. 泛型支持 还可以使用事件类型中的泛型信息来调度事件。\n6.1.通用应用程序事件 让我们创建一个通用事件类型。\n在我们的示例中，事件类包含任何内容和成功状态指示器：\npublic class GenericSpringEvent\u0026lt;T\u0026gt; { private T what; protected boolean success; public GenericSpringEvent(T what, boolean success) { this.what = what; this.success = success; } // ... standard getters } 请注意 GenericSpringEvent 和 CustomSpringEvent 之间的区别。我们现在可以灵活地发布任何任意事件，并且不再需要从 ApplicationEvent 进行扩展。\n6.2.监听者 现在让我们创建该事件的侦听器。\n我们可以像以前一样通过实现 ApplicationListener 接口来定义监听器：\n@Component public class GenericSpringEventListener implements ApplicationListener\u0026lt;GenericSpringEvent\u0026lt;String\u0026gt;\u0026gt; { @Override public void onApplicationEvent(@NonNull GenericSpringEvent\u0026lt;String\u0026gt; event) { System.out.println(\u0026#34;Received spring generic event - \u0026#34; + event.getWhat()); } } 但不幸的是这个定义要求我们从 ApplicationEvent 类继承 GenericSpringEvent。因此，在本教程中，我们将使用前面讨论的注释驱动事件侦听器。\n还可以通过在 @EventListener 注释上定义布尔 SpEL 表达式来使事件侦听器成为有条件的。\n在这种情况下，只有成功的 String GenericSpringEvent 才会调用事件处理程序：\n@Component public class AnnotationDrivenEventListener { @EventListener(condition = \u0026#34;#event.success\u0026#34;) public void handleSuccessful(GenericSpringEvent\u0026lt;String\u0026gt; event) { System.out.println(\u0026#34;Handling generic event (conditional).\u0026#34;); } } Spring 表达式语言 (SpEL) 是一种功能强大的表达式语言，在另一个教程中详细介绍了它。\n6.3.发布者 事件发布者与上面描述的类似。但由于类型擦除，我们需要发布一个事件来解析我们要过滤的泛型参数，例如，class GenericStringSpringEvent extends GenericSpringEvent。\n此外，还有另一种发布事件的方式。如果我们从使用 @EventListener 注释的方法返回一个非空值作为结果，Spring Framework 会将该结果作为新事件发送给我们。此外，我们可以通过将多个新事件作为事件处理的结果返回到集合中来发布它们。\n7. 交易绑定事件 本节介绍如何使用 @TransactionalEventListener 注释。要了解有关事务管理的更多信息，请查看 Transactions With Spring and JPA。\n从 Spring 4.2 开始，框架提供了一个新的 @TransactionalEventListener 注解，它是@EventListener 的扩展，允许将事件的监听器绑定到事务的某个阶段。\n可以对以下交易阶段进行绑定：\nAFTER_COMMIT（默认）用于在事务成功完成时触发该事件。 AFTER_ROLLBACK – 如果事务已回滚 AFTER_COMPLETION – 如果事务已完成（AFTER_COMMIT 和 AFTER_ROLLBACK 的别名） BEFORE_COMMIT – 用于在事务提交之前触发该事件。 这是事务事件侦听器的一个简单示例：\n@TransactionalEventListener(phase = TransactionPhase.BEFORE_COMMIT) public void handleCustom(CustomSpringEvent event) { System.out.println(\u0026#34;Handling event inside a transaction BEFORE COMMIT.\u0026#34;); } 仅当事件生成器正在运行且即将提交的事务中时，才会调用此侦听器。\n如果没有事务正在运行，则根本不会发送事件，除非我们通过将 FallbackExecution 属性设置为 true 来覆盖它。\n8. 结论 在这篇简短的文章中，我们回顾了在 Spring 中处理事件的基础知识，包括创建一个简单的自定义事件、发布它，然后在侦听器中处理它。\n我们还简要了解了如何在配置中启用事件的异步处理。\n然后我们了解了 Spring 4.2 中引入的改进，例如注释驱动的侦听器、更好的泛型支持以及绑定到事务阶段的事件。\n与往常一样，本文中提供的代码可以在 GitHub 上获取。这是一个基于 Maven 的项目，因此应该很容易导入并按原样运行。\n原文链接：https://www.baeldung.com/spring-events\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/spring-events/","summary":"1. 概述 在本教程中，我们将讨论如何在 Spring 中使用事件。\n事件是框架中最容易被忽视的功能之一，但也是最有用的功能之一。与 Spring 中的许多其他功能一样，事件发布是 ApplicationContext 提供的功能之一。\n有一些简单的准则需要遵循：\n如果我们使用 Spring Framework 4.2 之前的版本，事件类应该扩展 ApplicationEvent。从 4.2 版本开始，事件类不再需要扩展 ApplicationEvent 类。 发布者应该注入一个 ApplicationEventPublisher 对象。 监听器应该实现 ApplicationListener 接口。 2. 自定义事件 Spring 允许我们创建和发布默认情况下同步的自定义事件。这有一些优点，例如侦听器能够参与发布者的事务上下文。\n2.1.一个简单的应用程序事件 让我们创建一个简单的事件类——只是一个存储事件数据的占位符。\n在本例中，事件类保存一条字符串消息：\npublic class CustomSpringEvent extends ApplicationEvent { private String message; public CustomSpringEvent(Object source, String message) { super(source); this.message = message; } public String getMessage() { return message; } } 2.2.发布者 现在让我们创建该事件的发布者。发布者构造事件对象并将其发布给正在侦听的任何人。\n要发布事件，发布者只需注入 ApplicationEventPublisher 并使用 publishEvent() API：\n@Component public class CustomSpringEventPublisher { @Autowired private ApplicationEventPublisher applicationEventPublisher; public void publishCustomEvent(final String message) { System.out.println(\u0026#34;Publishing custom event. \u0026#34;); CustomSpringEvent customSpringEvent = new CustomSpringEvent(this, message); applicationEventPublisher.publishEvent(customSpringEvent); } } 或者，发布者类可以实现 ApplicationEventPublisherAware 接口，这也将在应用程序启动时注入事件发布者。通常，使用 @Autowire 注入发布者会更简单。","title":"[译]Spring Events"},{"content":"1. 概述 在本教程中，我们将探讨 Spring 中的异步执行支持和 @Async 注解。\n简单地说，用 @Async 注解 bean 的方法将使其在单独的线程中执行。换句话说，调用者不会等待被调用方法的完成。\nSpring 的一个有趣的方面是，框架中的事件支持还 支持异步处理（如果需要）。\n2.启用异步支持 让我们首先通过 Java 注解启用异步处理。\n我们将通过将 @EnableAsync 添加到配置类来完成此操作：\n@Configuration @EnableAsync public class SpringAsyncConfig { ... } 启用注解就足够了。但也有一些简单的配置选项：\nannotation 默认情况下，@EnableAsync 检测 Spring 的 @Async 注解和 EJB 3.1 javax.ejb.Asynchronous。我们也可以使用此选项来检测其他用户定义的注解类型。 mode 指示应使用的建议类型 - 基于 JDK 代理或 AspectJ 编织。 proxyTargetClass 指示应使用的代理类型 — CGLIB 或 JDK。仅当模式设置为 AdviceMode.PROXY 时，此属性才有效。 order 设置应用 AsyncAnnotationBeanPostProcessor 的顺序。默认情况下，它最后运行，以便它可以考虑所有现有代理。 我们还可以使用任务命名空间通过 XML 配置启用异步处理：\n\u0026lt;task:executor id=\u0026#34;myexecutor\u0026#34; pool-size=\u0026#34;5\u0026#34; /\u0026gt; \u0026lt;task:annotation-driven executor=\u0026#34;myexecutor\u0026#34;/\u0026gt; 3.@Async 注解 首先，让我们回顾一下规则。 @Async 有两个限制：\n它必须仅应用于公共方法。 自调用（从同一个类中调用异步方法）将不起作用。 原因很简单：该方法需要公开，以便可以被代理。并且自调用不起作用，因为它绕过代理并直接调用底层方法。\n3.1.返回类型为 void 的方法 这是配置具有 void 返回类型的方法以异步运行的简单方法：\n@Async public void asyncMethodWithVoidReturnType() { System.out.println(\u0026#34;Execute method asynchronously. \u0026#34; + Thread.currentThread().getName()); } 3.2.具有返回类型的方法 我们还可以通过将实际返回包装在 Future 中来将 @Async 应用于具有返回类型的方法：\n@Async public Future\u0026lt;String\u0026gt; asyncMethodWithReturnType() { System.out.println(\u0026#34;Execute method asynchronously - \u0026#34; + Thread.currentThread().getName()); try { Thread.sleep(5000); return new AsyncResult\u0026lt;String\u0026gt;(\u0026#34;hello world !!!!\u0026#34;); } catch (InterruptedException e) { // } return null; } Spring 还提供了一个实现Future的AsyncResult类。我们可以用它来跟踪异步方法执行的结果。\n现在让我们调用上述方法并使用 Future 对象检索异步过程的结果。\npublic void testAsyncAnnotationForMethodsWithReturnType() throws InterruptedException, ExecutionException { System.out.println(\u0026#34;Invoking an asynchronous method. \u0026#34; + Thread.currentThread().getName()); Future\u0026lt;String\u0026gt; future = asyncAnnotationExample.asyncMethodWithReturnType(); while (true) { if (future.isDone()) { System.out.println(\u0026#34;Result from asynchronous process - \u0026#34; + future.get()); break; } System.out.println(\u0026#34;Continue doing something else. \u0026#34;); Thread.sleep(1000); } } 4. Executor 默认情况下，Spring 使用 SimpleAsyncTaskExecutor 来实际异步运行这些方法。但我们可以在两个级别覆盖默认值：应用程序级别或单个方法级别。\n4.1.在方法级别重写 Executor 我们需要在配置类中声明所需的执行器：\n@Configuration @EnableAsync public class SpringAsyncConfig { @Bean(name = \u0026#34;threadPoolTaskExecutor\u0026#34;) public Executor threadPoolTaskExecutor() { return new ThreadPoolTaskExecutor(); } } 然后我们应该在 @Async 中提供执行程序名称作为属性：\n@Async(\u0026#34;threadPoolTaskExecutor\u0026#34;) public void asyncMethodWithConfiguredExecutor() { System.out.println(\u0026#34;Execute method with configured executor - \u0026#34; + Thread.currentThread().getName()); } 4.2.在应用程序级别覆盖 Executor 配置类应实现 AsyncConfigurer 接口。因此，它必须实现 getAsyncExecutor() 方法。在这里，我们将返回整个应用程序的执行器。现在，它成为运行用 @Async 注解的方法的默认执行器：\n@Configuration @EnableAsync public class SpringAsyncConfig implements AsyncConfigurer { @Override public Executor getAsyncExecutor() { ThreadPoolTaskExecutor threadPoolTaskExecutor = new ThreadPoolTaskExecutor(); threadPoolTaskExecutor.initialize(); return threadPoolTaskExecutor; } } 5. 异常处理 当方法返回类型是 Future 时，异常处理很容易。 Future.get() 方法将抛出异常。\n但如果返回类型为 void，异常将不会传播到调用线程。因此，我们需要添加额外的配置来处理异常。\n我们将通过实现 AsyncUncaughtExceptionHandler 接口来创建自定义异步异常处理程序。当存在任何未捕获的异步异常时，将调用 handleUncaughtException() 方法：\npublic class CustomAsyncExceptionHandler implements AsyncUncaughtExceptionHandler { @Override public void handleUncaughtException( Throwable throwable, Method method, Object... obj) { System.out.println(\u0026#34;Exception message - \u0026#34; + throwable.getMessage()); System.out.println(\u0026#34;Method name - \u0026#34; + method.getName()); for (Object param : obj) { System.out.println(\u0026#34;Parameter value - \u0026#34; + param); } } } 在上一节中，我们了解了配置类实现的 AsyncConfigurer 接口。作为其中的一部分，我们还需要重写 getAsyncUncaughtExceptionHandler() 方法以返回我们的自定义异步异常处理程序：\n@Override public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() { return new CustomAsyncExceptionHandler(); } 6. 结论 在本文中，我们研究了使用 Spring 运行异步代码。\n我们从非常基本的配置和注解开始，以使其正常工作。但我们也研究了更高级的配置，例如提供我们自己的执行器或异常处理策略。\n与往常一样，本文中提供的完整代码可以在 GitHub 上找到。\n原文链接：https://www.baeldung.com/spring-async\n","permalink":"https://blog.chensoul.cc/posts/2023/08/25/spring-async/","summary":"1. 概述 在本教程中，我们将探讨 Spring 中的异步执行支持和 @Async 注解。\n简单地说，用 @Async 注解 bean 的方法将使其在单独的线程中执行。换句话说，调用者不会等待被调用方法的完成。\nSpring 的一个有趣的方面是，框架中的事件支持还 支持异步处理（如果需要）。\n2.启用异步支持 让我们首先通过 Java 注解启用异步处理。\n我们将通过将 @EnableAsync 添加到配置类来完成此操作：\n@Configuration @EnableAsync public class SpringAsyncConfig { ... } 启用注解就足够了。但也有一些简单的配置选项：\nannotation 默认情况下，@EnableAsync 检测 Spring 的 @Async 注解和 EJB 3.1 javax.ejb.Asynchronous。我们也可以使用此选项来检测其他用户定义的注解类型。 mode 指示应使用的建议类型 - 基于 JDK 代理或 AspectJ 编织。 proxyTargetClass 指示应使用的代理类型 — CGLIB 或 JDK。仅当模式设置为 AdviceMode.PROXY 时，此属性才有效。 order 设置应用 AsyncAnnotationBeanPostProcessor 的顺序。默认情况下，它最后运行，以便它可以考虑所有现有代理。 我们还可以使用任务命名空间通过 XML 配置启用异步处理：\n\u0026lt;task:executor id=\u0026#34;myexecutor\u0026#34; pool-size=\u0026#34;5\u0026#34; /\u0026gt; \u0026lt;task:annotation-driven executor=\u0026#34;myexecutor\u0026#34;/\u0026gt; 3.@Async 注解 首先，让我们回顾一下规则。 @Async 有两个限制：\n它必须仅应用于公共方法。 自调用（从同一个类中调用异步方法）将不起作用。 原因很简单：该方法需要公开，以便可以被代理。并且自调用不起作用，因为它绕过代理并直接调用底层方法。\n3.1.返回类型为 void 的方法 这是配置具有 void 返回类型的方法以异步运行的简单方法：\n@Async public void asyncMethodWithVoidReturnType() { System.out.println(\u0026#34;Execute method asynchronously. \u0026#34; + Thread.currentThread().getName()); } 3.2.具有返回类型的方法 我们还可以通过将实际返回包装在 Future 中来将 @Async 应用于具有返回类型的方法：","title":"[译]如何在Spring中执行@Async"},{"content":"用户故事（User Stories）是敏捷软件开发中的一种需求表达方式，用于描述用户的需求、期望和价值。尽管用户故事主要应用于软件开发团队，但其原则和方法也可以应用到个人管理中，以帮助个人更好地管理自己的任务和目标。\n在个人管理中，可以将用户故事的思维方式应用如下：\n角色定义：将自己作为一个角色，例如“个人”或“自己的名字”。明确自己的身份和角色，以便更好地理解自己的需求和期望。 需求描述：将自己的需求和期望转化为用户故事的形式。例如：“作为一个个人，我希望每天早晨锻炼，以保持健康和增加活力。” 价值定义：确定每个用户故事的价值和意义。例如，锻炼身体可以增强健康、提高精力和改善心情，从而提升整体生活质量。 优先级排序：对用户故事进行优先级排序，以确定哪些是最重要的和紧急的。这有助于集中精力和资源，实现最有价值的目标。 制定计划：根据用户故事的优先级，制定个人管理计划。将每个用户故事转化为具体的任务、行动和时间安排，以实现期望的结果。 迭代和反馈：将个人管理过程视为一个迭代循环，不断评估和调整。根据实际执行情况和反馈，对计划进行调整和改进。 以下是一个制定个人管理计划的示例：\n用户故事：作为一个个人，我希望提高工作效率和时间管理，以更好地完成任务和增加工作成果。\n计划：\n用户故事：作为一个个人，我希望设定明确的目标和优先级，以便更好地管理我的任务。 任务 1：制定长期目标和短期目标，并将其记录在个人笔记本或任务管理工具中。 任务 2：为每个目标设定优先级，以确定最重要的任务和活动。 用户故事：作为一个个人，我希望改善时间管理，以充分利用我的时间。 任务 1：分析我的日常时间分配，并识别时间浪费的区域。 任务 2：制定时间表或日程安排，将任务和活动合理分配到特定时间段。 任务 3：学习和采用时间管理技巧，如番茄工作法（Pomodoro Technique）或时间块（Time Blocking）。 用户故事：作为一个个人，我希望提高专注力和减少干扰，以更好地完成任务。 任务 1：创建一个有利于专注的工作环境，如清理工作区域、关闭手机通知或使用专注应用程序。 任务 2：学习并使用注意力管理技巧，如集中注意力训练（Focused Attention Training）或冥想。 用户故事：作为一个个人，我希望保持健康和提高精力，以更好地应对工作和任务。 任务 1：制定健康的生活习惯，如定期锻炼、健康饮食和充足的睡眠。 任务 2：安排休息和放松的时间，以避免过度劳累和疲劳。 用户故事：作为一个个人，我希望定期评估和调整我的个人管理计划，以适应变化和改进效果。 任务 1：每周或每月回顾我的个人管理计划，并记录我取得的成果和遇到的挑战。 任务 2：根据反馈和经验，调整计划中的任务和策略，以改进效果和适应新的需求。 这只是一个示例个人管理计划，你可以根据自己的需求和目标进行定制和调整。记得将计划中的任务具体化、可衡量，并逐步实施，以确保计划的可行性和有效性。\n逐步实施个人管理计划是确保计划可行性和有效性的重要步骤。以下是一些方法来逐步实施你的个人管理计划：\n制定优先级：根据计划中的任务和目标，确定它们的优先级顺序。将重要且紧急的任务放在首位，逐步处理其他任务。 制定计划：为每个任务制定具体的计划和行动步骤。将任务分解为更小的可管理的子任务，并为每个子任务设定截止日期或时间范围。 设定目标：为每个任务设定明确的目标和可衡量的指标。这样可以更好地跟踪和评估你的进展。 时间管理：合理安排时间以实施计划。使用时间管理技巧，如时间块，将任务和活动分配到特定的时间段，并设定时间限制以保持专注和高效。 建立习惯：将计划中的任务和行动转化为习惯。重复执行任务并坚持一段时间，以形成良好的习惯。 监控和评估：定期监控和评估你的进展。检查完成的任务，评估是否达到预期的目标和指标。根据反馈和经验，进行调整和改进。 适应变化：灵活应对变化和调整。如果遇到新的需求或情况，根据实际情况重新安排任务和优先级。 持续改进：根据实施的经验和反馈，不断改进个人管理计划。尝试新的方法和策略，寻找提高效率和成果的机会。 逐步实施个人管理计划需要耐心和坚持，一步一个脚印地完成每个任务，并逐渐扩大和提高目标的范围。记得给自己一定的弹性和容错空间，以适应意外情况和挑战。最重要的是保持积极的态度和动力，不断努力实现个人目标和提升自我管理能力。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/21/user-stories-in-self-manager/","summary":"用户故事（User Stories）是敏捷软件开发中的一种需求表达方式，用于描述用户的需求、期望和价值。尽管用户故事主要应用于软件开发团队，但其原则和方法也可以应用到个人管理中，以帮助个人更好地管理自己的任务和目标。\n在个人管理中，可以将用户故事的思维方式应用如下：\n角色定义：将自己作为一个角色，例如“个人”或“自己的名字”。明确自己的身份和角色，以便更好地理解自己的需求和期望。 需求描述：将自己的需求和期望转化为用户故事的形式。例如：“作为一个个人，我希望每天早晨锻炼，以保持健康和增加活力。” 价值定义：确定每个用户故事的价值和意义。例如，锻炼身体可以增强健康、提高精力和改善心情，从而提升整体生活质量。 优先级排序：对用户故事进行优先级排序，以确定哪些是最重要的和紧急的。这有助于集中精力和资源，实现最有价值的目标。 制定计划：根据用户故事的优先级，制定个人管理计划。将每个用户故事转化为具体的任务、行动和时间安排，以实现期望的结果。 迭代和反馈：将个人管理过程视为一个迭代循环，不断评估和调整。根据实际执行情况和反馈，对计划进行调整和改进。 以下是一个制定个人管理计划的示例：\n用户故事：作为一个个人，我希望提高工作效率和时间管理，以更好地完成任务和增加工作成果。\n计划：\n用户故事：作为一个个人，我希望设定明确的目标和优先级，以便更好地管理我的任务。 任务 1：制定长期目标和短期目标，并将其记录在个人笔记本或任务管理工具中。 任务 2：为每个目标设定优先级，以确定最重要的任务和活动。 用户故事：作为一个个人，我希望改善时间管理，以充分利用我的时间。 任务 1：分析我的日常时间分配，并识别时间浪费的区域。 任务 2：制定时间表或日程安排，将任务和活动合理分配到特定时间段。 任务 3：学习和采用时间管理技巧，如番茄工作法（Pomodoro Technique）或时间块（Time Blocking）。 用户故事：作为一个个人，我希望提高专注力和减少干扰，以更好地完成任务。 任务 1：创建一个有利于专注的工作环境，如清理工作区域、关闭手机通知或使用专注应用程序。 任务 2：学习并使用注意力管理技巧，如集中注意力训练（Focused Attention Training）或冥想。 用户故事：作为一个个人，我希望保持健康和提高精力，以更好地应对工作和任务。 任务 1：制定健康的生活习惯，如定期锻炼、健康饮食和充足的睡眠。 任务 2：安排休息和放松的时间，以避免过度劳累和疲劳。 用户故事：作为一个个人，我希望定期评估和调整我的个人管理计划，以适应变化和改进效果。 任务 1：每周或每月回顾我的个人管理计划，并记录我取得的成果和遇到的挑战。 任务 2：根据反馈和经验，调整计划中的任务和策略，以改进效果和适应新的需求。 这只是一个示例个人管理计划，你可以根据自己的需求和目标进行定制和调整。记得将计划中的任务具体化、可衡量，并逐步实施，以确保计划的可行性和有效性。\n逐步实施个人管理计划是确保计划可行性和有效性的重要步骤。以下是一些方法来逐步实施你的个人管理计划：\n制定优先级：根据计划中的任务和目标，确定它们的优先级顺序。将重要且紧急的任务放在首位，逐步处理其他任务。 制定计划：为每个任务制定具体的计划和行动步骤。将任务分解为更小的可管理的子任务，并为每个子任务设定截止日期或时间范围。 设定目标：为每个任务设定明确的目标和可衡量的指标。这样可以更好地跟踪和评估你的进展。 时间管理：合理安排时间以实施计划。使用时间管理技巧，如时间块，将任务和活动分配到特定的时间段，并设定时间限制以保持专注和高效。 建立习惯：将计划中的任务和行动转化为习惯。重复执行任务并坚持一段时间，以形成良好的习惯。 监控和评估：定期监控和评估你的进展。检查完成的任务，评估是否达到预期的目标和指标。根据反馈和经验，进行调整和改进。 适应变化：灵活应对变化和调整。如果遇到新的需求或情况，根据实际情况重新安排任务和优先级。 持续改进：根据实施的经验和反馈，不断改进个人管理计划。尝试新的方法和策略，寻找提高效率和成果的机会。 逐步实施个人管理计划需要耐心和坚持，一步一个脚印地完成每个任务，并逐渐扩大和提高目标的范围。记得给自己一定的弹性和容错空间，以适应意外情况和挑战。最重要的是保持积极的态度和动力，不断努力实现个人目标和提升自我管理能力。","title":"用户故事如何应用到个人管理"},{"content":"如何成为一名合格的架构师 成为一名合格的架构师需要不断学习和积累经验。以下是一些步骤和建议，可以帮助你成为一名合格的架构师：\n学习基础知识：建立坚实的计算机科学和软件工程基础，包括数据结构、算法、操作系统、数据库等。深入学习编程语言和开发技术，了解不同技术栈的优缺点。\n实践项目开发：通过参与实际的软件开发项目，积累项目管理和开发经验。亲身经历软件开发的各个阶段，从需求分析到设计、开发、测试和部署，深入了解软件开发的流程和挑战。\n学习系统设计和架构：深入学习系统设计和架构的相关知识，包括架构模式、设计原则。阅读相关的书籍、文章和技术博客，参与架构设计讨论和社区活动。\n以下是关于架构模式、设计原则和一些常见架构的简要介绍：\n架构模式： 分层架构（Layered Architecture）：将系统划分为多个层次，每个层次有不同的职责和功能，实现松耦合和可维护性。 客户端-服务器模式（Client-Server）：将系统分为客户端和服务器，客户端发送请求并接收响应，服务器处理请求并提供服务。 发布-订阅模式（Publish-Subscribe）：基于事件的模式，发布者发布事件，订阅者订阅感兴趣的事件，实现解耦和扩展性。 微服务架构（Microservices Architecture）：将系统拆分为一组小型、自治的服务，每个服务专注于一个特定的业务功能，通过轻量通信协议进行交互。 事件驱动架构（Event-Driven Architecture）：系统的组成部分通过事件进行通信和协调，事件的发生触发相应的处理和反应。 设计原则： 单一职责原则（Single Responsibility Principle）：一个模块或类应该有且只有一个单一的责任。 开闭原则（Open-Closed Principle）：软件实体应该对扩展开放，对修改封闭。 里氏替换原则（Liskov Substitution Principle）：子类应该能够替换掉父类，并且不会破坏程序的正确性。 接口隔离原则（Interface Segregation Principle）：不应该强迫客户端依赖于它们不需要的接口。 依赖倒置原则（Dependency Inversion Principle）：应该依赖于抽象而不是具体实现。 实践架构设计：在实际项目中担任架构师的角色，负责系统的整体设计和架构决策。通过实践中的挑战和经验，不断提升自己的架构设计能力。\n学习领域知识：根据自己的兴趣和发展方向，深入学习特定领域的知识。例如，如果你在金融领域工作，了解金融系统的特点和要求，掌握相关的技术和解决方案。\n不断学习和跟进技术趋势：保持对新技术和趋势的敏感性，持续学习和跟进行业的最新发展。参加技术研讨会、培训课程和行业会议，阅读技术书籍和博客，与同行进行交流和讨论。\n培养沟通和领导能力：作为架构师，与团队成员、业务部门和其他利益相关者进行有效的沟通和合作非常重要。培养良好的沟通和领导能力，能够清晰地表达设计思想和技术方案，并协调各方利益。\n寻求 mentor 或参与指导项目：寻找经验丰富的架构师作为 mentor，从他们那里获得指导和建议。参与指导性项目，与其他架构师合作，共同解决复杂问题，学习他们的设计思路和方法。\n持续改进和反思：持续改进自己的技术能力和专业素养。定期回顾和反思自己的设计决策和经验，寻找改进的空间，并从失败和挑战中吸取教训。\n最重要的是，成为一名合格的架构师是一个渐进的过程，需要不断学习、实践和积累经验。通过不断提升自己的技术水平、设计能力和沟通能力，你将逐步成为一名优秀的架构师。\n架构师必备的技能和知识 作为架构师，以下是一些必备的技能和知识：\n系统设计和架构：具备全面的系统设计和架构能力，能够设计可靠、可扩展、高性能和安全的系统架构。了解常用的架构模式和设计原则，如分层架构、微服务架构、事件驱动架构等。 编程和开发经验：具备扎实的编程能力和开发经验，熟悉多种编程语言和技术栈。能够理解和评估不同技术选型的优缺点，并在需要时能够进行原型开发和演示。 分布式系统：了解分布式系统的概念、原理和常见挑战，熟悉分布式计算、分布式存储和分布式通信等相关技术。能够设计和优化分布式系统的架构，解决分布式系统中的一致性、容错和性能问题。 性能优化和调优：具备性能优化和调优的经验，能够分析和解决系统性能瓶颈。熟悉性能测试工具和性能监控工具，能够设计和实施性能测试计划，并提出相应的优化建议。 安全设计和防御：具备系统安全设计和防御的能力，了解常见的安全威胁和攻击方式，能够设计和实施安全策略和措施，确保系统的安全性和数据的保密性。 数据库和存储系统：熟悉各种数据库和存储系统的原理和使用，包括关系型数据库、NoSQL 数据库、缓存系统等。能够进行数据库设计和优化，保证数据的一致性和可靠性。 云计算和容器技术：了解云计算和容器技术的概念和基本原理，包括虚拟化、容器化、自动化部署等。能够设计和部署基于云计算和容器技术的系统架构，如使用 Docker、Kubernetes 等。 消息队列和事件驱动：熟悉消息队列和事件驱动架构，了解消息中间件的选择和使用。能够设计和实现基于消息队列和事件驱动的系统，实现松耦合和可扩展性。 高可用和容错设计：能够设计和实现高可用和容错的系统架构，包括故障恢复、负载均衡、容灾和备份策略等。了解分布式一致性和容错算法，如 Paxos、Raft 等。 沟通和领导能力：作为架构师，需要具备良好的沟通和领导能力。能够与团队成员、业务部门和其他利益相关者进行有效的沟通和合作，推动项目的顺利进行。 这些技能和知识将帮助架构师在设计和构建复杂系统时做出明智的决策，并确保系统的可靠性、可扩展性和性能。此外，架构师还应不断学习和保持对新技术和趋势的敏感性，以保持在技术领域的竞争力。\n架构师学习路线图 作为架构师，以下是一个可能的学习路线图，可以帮助你系统地学习和发展架构师的技能：\n基础知识： 学习软件开发基础知识，包括编程语言、数据结构和算法等。 理解软件开发流程和常用开发方法，如敏捷开发和 DevOps。 学习面向对象设计和设计模式。 架构设计基础： 学习软件架构的基本概念、原则和模式。 研究和理解常见的架构模式，如分层架构、客户端-服务器模式和发布-订阅模式等。 掌握设计原则，如单一职责原则、开闭原则和依赖倒置原则等。 深入学习架构模式和技术： 学习微服务架构的原理、设计和实施。 研究事件驱动架构和消息队列的使用。 探索大数据架构和分布式系统设计。 了解容器化和容器编排技术，如 Docker 和 Kubernetes。 实践和项目经验： 参与实际项目，从中学习架构设计和实施的经验。 尝试设计和开发自己的小型项目，实践架构设计和解决实际问题。 参与开源项目或贡献，与其他架构师交流和分享经验。 持续学习和发展： 关注行业趋势和新兴技术，如人工智能、物联网和区块链等。 参加架构师培训和认证课程，如 TOGAF、AWS Certified Solutions Architect 等。 参与架构师社区和论坛，与其他专业人士交流和学习。 请注意，这只是一个示例学习路线图，你可以根据自己的兴趣、目标和实际情况进行调整和扩展。重要的是保持持续学习和不断实践，通过实际项目和经验来提升自己的架构师技能。\n架构师学习资源 以下是一些关于系统设计和架构的经典书籍：\n《软件架构实践》（Software Architecture in Practice） - Len Bass、Paul Clements、Rick Kazman 《大规模分布式存储系统》（Designing Data-Intensive Applications） - Martin Kleppmann 《企业集成模式》（Enterprise Integration Patterns） - Gregor Hohpe、Bobby Woolf 《架构之美》（Beautiful Architecture） - Diomidis Spinellis、Georgios Gousios 《架构设计原则》（The Art of Software Architecture: Design Methods and Techniques） - Stephen T. Albin、Wei-Tek Tsai 《领域驱动设计》（Domain-Driven Design: Tackling Complexity in the Heart of Software） - Eric Evans 《系统架构设计师的指南》（A Practical Guide to SysML: The Systems Modeling Language） - Sanford Friedenthal、Alan Moore、Rick Steiner 《微服务设计》（Building Microservices） - Sam Newman 《设计数据密集型应用》（Designing Data-Intensive Applications） - Martin Kleppmann 《模式语言》（Pattern-Oriented Software Architecture: A System of Patterns） - Frank Buschmann、Regine Meunier、Hans Rohnert、Peter Sommerlad、Michael Stal 这些书籍涵盖了系统设计和架构的不同方面，从基本原理到实践指南都有所涉及。通过阅读这些书籍，你可以深入了解系统设计和架构的概念、原则和最佳实践，并从实际案例中学习。记住，实践是提升架构能力的关键，所以在阅读的同时，尽量将所学应用到实际项目中。\n以下是一些关于系统设计和架构的在线资源，包括博客、网站和在线课程：\n架构师博客和文章： Martin Fowler\u0026rsquo;s Blog: https://martinfowler.com/ ThoughtWorks Insights: https://www.thoughtworks.com/insights InfoQ Architecture \u0026amp; Design: https://www.infoq.com/architecture-design/ High Scalability: http://highscalability.com/ 架构师社区和论坛： Reddit /r/SoftwareArchitecture: https://www.reddit.com/r/SoftwareArchitecture/ Stack Exchange - Software Engineering: https://softwareengineering.stackexchange.com/ 在线课程和学习平台： Coursera: 有许多与软件架构和系统设计相关的课程，如《Software Architecture for the Internet of Things》、《Software Design and Architecture Specialization》等。 Udemy: 提供广泛的系统设计和架构课程，如《Software Architecture: Complete Guide》、《Microservices Architecture and Design》等。 edX: 有一些与软件架构和系统设计相关的课程，如《Software Construction and Architecture》等。 架构模式和设计模式： Martin Fowler\u0026rsquo;s Patterns of Enterprise Application Architecture: https://martinfowler.com/eaaCatalog/ Design Patterns by the Gang of Four: https://sourcemaking.com/design_patterns 这些资源提供了广泛的架构设计和系统设计的内容和讨论，你可以通过阅读文章、参与社区讨论和完成在线课程来加深对系统设计和架构的理解。同时，也可以根据自己的兴趣和需求，进一步探索其他相关资源。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/21/architecture/","summary":"如何成为一名合格的架构师 成为一名合格的架构师需要不断学习和积累经验。以下是一些步骤和建议，可以帮助你成为一名合格的架构师：\n学习基础知识：建立坚实的计算机科学和软件工程基础，包括数据结构、算法、操作系统、数据库等。深入学习编程语言和开发技术，了解不同技术栈的优缺点。\n实践项目开发：通过参与实际的软件开发项目，积累项目管理和开发经验。亲身经历软件开发的各个阶段，从需求分析到设计、开发、测试和部署，深入了解软件开发的流程和挑战。\n学习系统设计和架构：深入学习系统设计和架构的相关知识，包括架构模式、设计原则。阅读相关的书籍、文章和技术博客，参与架构设计讨论和社区活动。\n以下是关于架构模式、设计原则和一些常见架构的简要介绍：\n架构模式： 分层架构（Layered Architecture）：将系统划分为多个层次，每个层次有不同的职责和功能，实现松耦合和可维护性。 客户端-服务器模式（Client-Server）：将系统分为客户端和服务器，客户端发送请求并接收响应，服务器处理请求并提供服务。 发布-订阅模式（Publish-Subscribe）：基于事件的模式，发布者发布事件，订阅者订阅感兴趣的事件，实现解耦和扩展性。 微服务架构（Microservices Architecture）：将系统拆分为一组小型、自治的服务，每个服务专注于一个特定的业务功能，通过轻量通信协议进行交互。 事件驱动架构（Event-Driven Architecture）：系统的组成部分通过事件进行通信和协调，事件的发生触发相应的处理和反应。 设计原则： 单一职责原则（Single Responsibility Principle）：一个模块或类应该有且只有一个单一的责任。 开闭原则（Open-Closed Principle）：软件实体应该对扩展开放，对修改封闭。 里氏替换原则（Liskov Substitution Principle）：子类应该能够替换掉父类，并且不会破坏程序的正确性。 接口隔离原则（Interface Segregation Principle）：不应该强迫客户端依赖于它们不需要的接口。 依赖倒置原则（Dependency Inversion Principle）：应该依赖于抽象而不是具体实现。 实践架构设计：在实际项目中担任架构师的角色，负责系统的整体设计和架构决策。通过实践中的挑战和经验，不断提升自己的架构设计能力。\n学习领域知识：根据自己的兴趣和发展方向，深入学习特定领域的知识。例如，如果你在金融领域工作，了解金融系统的特点和要求，掌握相关的技术和解决方案。\n不断学习和跟进技术趋势：保持对新技术和趋势的敏感性，持续学习和跟进行业的最新发展。参加技术研讨会、培训课程和行业会议，阅读技术书籍和博客，与同行进行交流和讨论。\n培养沟通和领导能力：作为架构师，与团队成员、业务部门和其他利益相关者进行有效的沟通和合作非常重要。培养良好的沟通和领导能力，能够清晰地表达设计思想和技术方案，并协调各方利益。\n寻求 mentor 或参与指导项目：寻找经验丰富的架构师作为 mentor，从他们那里获得指导和建议。参与指导性项目，与其他架构师合作，共同解决复杂问题，学习他们的设计思路和方法。\n持续改进和反思：持续改进自己的技术能力和专业素养。定期回顾和反思自己的设计决策和经验，寻找改进的空间，并从失败和挑战中吸取教训。\n最重要的是，成为一名合格的架构师是一个渐进的过程，需要不断学习、实践和积累经验。通过不断提升自己的技术水平、设计能力和沟通能力，你将逐步成为一名优秀的架构师。\n架构师必备的技能和知识 作为架构师，以下是一些必备的技能和知识：\n系统设计和架构：具备全面的系统设计和架构能力，能够设计可靠、可扩展、高性能和安全的系统架构。了解常用的架构模式和设计原则，如分层架构、微服务架构、事件驱动架构等。 编程和开发经验：具备扎实的编程能力和开发经验，熟悉多种编程语言和技术栈。能够理解和评估不同技术选型的优缺点，并在需要时能够进行原型开发和演示。 分布式系统：了解分布式系统的概念、原理和常见挑战，熟悉分布式计算、分布式存储和分布式通信等相关技术。能够设计和优化分布式系统的架构，解决分布式系统中的一致性、容错和性能问题。 性能优化和调优：具备性能优化和调优的经验，能够分析和解决系统性能瓶颈。熟悉性能测试工具和性能监控工具，能够设计和实施性能测试计划，并提出相应的优化建议。 安全设计和防御：具备系统安全设计和防御的能力，了解常见的安全威胁和攻击方式，能够设计和实施安全策略和措施，确保系统的安全性和数据的保密性。 数据库和存储系统：熟悉各种数据库和存储系统的原理和使用，包括关系型数据库、NoSQL 数据库、缓存系统等。能够进行数据库设计和优化，保证数据的一致性和可靠性。 云计算和容器技术：了解云计算和容器技术的概念和基本原理，包括虚拟化、容器化、自动化部署等。能够设计和部署基于云计算和容器技术的系统架构，如使用 Docker、Kubernetes 等。 消息队列和事件驱动：熟悉消息队列和事件驱动架构，了解消息中间件的选择和使用。能够设计和实现基于消息队列和事件驱动的系统，实现松耦合和可扩展性。 高可用和容错设计：能够设计和实现高可用和容错的系统架构，包括故障恢复、负载均衡、容灾和备份策略等。了解分布式一致性和容错算法，如 Paxos、Raft 等。 沟通和领导能力：作为架构师，需要具备良好的沟通和领导能力。能够与团队成员、业务部门和其他利益相关者进行有效的沟通和合作，推动项目的顺利进行。 这些技能和知识将帮助架构师在设计和构建复杂系统时做出明智的决策，并确保系统的可靠性、可扩展性和性能。此外，架构师还应不断学习和保持对新技术和趋势的敏感性，以保持在技术领域的竞争力。\n架构师学习路线图 作为架构师，以下是一个可能的学习路线图，可以帮助你系统地学习和发展架构师的技能：\n基础知识： 学习软件开发基础知识，包括编程语言、数据结构和算法等。 理解软件开发流程和常用开发方法，如敏捷开发和 DevOps。 学习面向对象设计和设计模式。 架构设计基础： 学习软件架构的基本概念、原则和模式。 研究和理解常见的架构模式，如分层架构、客户端-服务器模式和发布-订阅模式等。 掌握设计原则，如单一职责原则、开闭原则和依赖倒置原则等。 深入学习架构模式和技术： 学习微服务架构的原理、设计和实施。 研究事件驱动架构和消息队列的使用。 探索大数据架构和分布式系统设计。 了解容器化和容器编排技术，如 Docker 和 Kubernetes。 实践和项目经验： 参与实际项目，从中学习架构设计和实施的经验。 尝试设计和开发自己的小型项目，实践架构设计和解决实际问题。 参与开源项目或贡献，与其他架构师交流和分享经验。 持续学习和发展： 关注行业趋势和新兴技术，如人工智能、物联网和区块链等。 参加架构师培训和认证课程，如 TOGAF、AWS Certified Solutions Architect 等。 参与架构师社区和论坛，与其他专业人士交流和学习。 请注意，这只是一个示例学习路线图，你可以根据自己的兴趣、目标和实际情况进行调整和扩展。重要的是保持持续学习和不断实践，通过实际项目和经验来提升自己的架构师技能。\n架构师学习资源 以下是一些关于系统设计和架构的经典书籍：\n《软件架构实践》（Software Architecture in Practice） - Len Bass、Paul Clements、Rick Kazman 《大规模分布式存储系统》（Designing Data-Intensive Applications） - Martin Kleppmann 《企业集成模式》（Enterprise Integration Patterns） - Gregor Hohpe、Bobby Woolf 《架构之美》（Beautiful Architecture） - Diomidis Spinellis、Georgios Gousios 《架构设计原则》（The Art of Software Architecture: Design Methods and Techniques） - Stephen T.","title":"如何成为一名合格的架构师"},{"content":"软件开发流程和常用开发方法，如敏捷开发和 DevOps，对于架构师来说非常重要。下面我将简要介绍这些概念：\n软件开发流程：\n软件开发流程是指在开发软件时，按照一定的步骤和阶段进行工作的过程。常见的软件开发流程包括瀑布模型、迭代模型和增量模型等。这些流程以不同的方式组织和管理开发过程，包括需求分析、设计、编码、测试和部署等阶段。\n敏捷开发：\n敏捷开发是一种迭代和增量的软件开发方法，强调团队协作、快速响应变化和持续交付。敏捷开发强调通过迭代周期（如 Scrum 中的 Sprint）来开发软件，每个迭代都会产生可部署的软件功能。常见的敏捷方法包括 Scrum、XP（极限编程）和 Kanban 等。\nDevOps：\nDevOps 是一种软件开发和运维的方法论，旨在通过自动化和协作来加速软件交付和提高质量。DevOps 强调开发团队和运维团队之间的协作和共享责任，借助自动化工具和流程来实现持续集成、持续交付和持续部署。\n开发流程 软件开发流程通常包括以下阶段：\n需求收集：收集和记录软件的功能和非功能性需求。 分析与规划：分析需求并规划开发过程，包括资源分配、时间表和交付物。 设计：基于需求创建软件架构、模块和组件的详细设计。 实现：编写代码并集成设计的组件，进行软件开发。 测试：进行各种测试活动，如单元测试、集成测试和系统测试，确保软件按预期功能。 部署：发布软件并在生产环境中向最终用户提供使用。 维护与支持：在部署后提供持续的维护、错误修复和支持。 在整个过程中，遵循版本控制、文档化和协作等最佳实践是非常重要的，以确保软件开发生命周期的顺利和高效进行。\n常见的软件开发流程包括瀑布模型、迭代模型和增量模型等：\n瀑布模型（Waterfall Model）： 瀑布模型是一种线性顺序的软件开发流程，按照固定的阶段依次执行，每个阶段的输出作为下一个阶段的输入。典型的阶段包括需求分析、系统设计、编码、测试和维护等。瀑布模型适用于需求稳定且较小规模的项目，但缺乏灵活性和适应变化的能力。\n下面是瀑布模型的典型阶段：\n需求分析阶段：在这个阶段，与用户和利益相关者一起收集和明确软件系统的需求。定义系统的功能和性能要求，并编写详细的需求规格说明书。 系统设计阶段：在需求分析完成后，进行系统设计。这包括定义系统的整体架构、模块划分、数据结构和算法设计等。设计结果通常以文档形式呈现。 编码阶段：在系统设计完成后，开发团队开始实际的编码工作。根据设计文档，开发人员编写代码并实现系统的各个功能模块。 测试阶段：在编码完成后，进行系统测试。测试人员根据需求和设计规范执行功能测试、集成测试和系统测试，以验证系统的正确性和稳定性。 集成和部署阶段：在测试通过后，将各个模块进行集成，并进行系统级的测试和部署准备。确保整个系统能够协同工作，并准备好部署到目标环境中。 运维和维护阶段：一旦系统部署并投入使用，进入运维和维护阶段。在这个阶段，团队负责监控系统的运行状况，处理问题和错误，并进行必要的修复和更新。 瀑布模型的特点是每个阶段的工作是线性、顺序的，下一个阶段的开始依赖于前一个阶段的完成。这种模型适合需求稳定、项目规模较小、技术风险较低的项目。然而，瀑布模型缺乏灵活性和对变化的适应能力，难以应对需求变更和项目延期等问题。\n因此，在面对需求变化频繁、项目复杂度高、风险较大的情况下，敏捷开发方法如 Scrum 和 Kanban 等更为适用，它们强调迭代、增量和持续交付，能更好地满足客户需求并快速响应变化。\n迭代模型（Iterative Model）： 迭代模型强调通过多个迭代周期来逐步构建和完善软件。每个迭代周期包括需求分析、设计、编码、测试和部署等阶段，每个迭代都会产生可部署的软件版本。迭代模型适用于需求不完全明确或可能变化的项目，能够更好地适应变化和快速反馈。\n以下是迭代模型的一般流程：\n阶段规划：确定每个迭代周期的目标、范围和计划。这包括确定要开发的功能、分配资源、制定时间表等。 需求分析：在每个迭代的开始阶段，与用户和利益相关者一起收集和分析需求，并明确每个迭代的功能和优先级。 设计和开发：根据需求分析的结果，进行系统设计和开发工作。在每个迭代中，系统的某个部分会被设计、开发和测试。 测试和验证：在每个迭代周期结束时，进行系统的内部测试和验证。确保开发的功能符合需求，并满足预期的质量标准。 评审和反馈：在每个迭代周期结束后，与用户和利益相关者进行评审和反馈。他们提供对当前功能的评价和建议，以指导下一个迭代的开发工作。 迭代调整：根据用户的反馈和评审结果，对下一个迭代的计划进行调整和优化。可能需要重新定义需求、调整功能优先级、增加新的需求等。 重复迭代：通过不断重复上述步骤，每个迭代周期都会逐步增加系统的功能、完善系统的性能，并在每个迭代中交付一个可用的软件增量。 迭代模型的优势在于能够快速响应变化和不断提供增值。它允许在开发过程中灵活调整需求，并通过每个迭代的反馈和评审来改进产品。然而，迭代模型也需要适当的计划和管理，以确保每个迭代都能按时交付，并控制开发过程中的风险。\n敏捷方法如 Scrum 和 Kanban 是迭代模型的典型实践，它们更加强调团队的协作、自组织和持续交付，适用于需求变化频繁和项目复杂度较高的环境\n增量模型（Incremental Model）： 增量模型将软件按模块或功能进行划分，每个模块或功能被称为一个增量，通过逐步添加增量来逐渐构建完整的软件系统。每个增量都经历需求分析、设计、开发和测试等阶段。增量模型适用于大规模项目和需要分阶段交付的情况，可以提供更早的价值交付和更好的风险管理。\n以下是增量模型的一般流程：\n阶段划分：将整个软件系统划分为多个增量，每个增量都代表一个可用的软件部分。划分的方式可以基于功能、模块、业务流程等来定义。 需求分析：在每个增量开始时，与用户和利益相关者一起收集和明确关于该增量的需求和功能。确定每个增量的优先级和范围。 设计和开发：根据需求分析的结果，进行系统设计和开发工作。每个增量的设计和开发都是独立进行的，可以采用适合的开发方法和技术。 测试和验证：在每个增量完成开发后，进行系统的测试和验证。确保该增量的功能符合需求，并满足预期的质量标准。 增量交付：经过测试和验证后，将该增量交付给用户或利益相关者。用户可以开始使用该增量，并提供反馈和建议以进一步改进和优化。 增量整合：在完成一个增量的交付后，将该增量与之前交付的增量进行整合。确保不同增量之间的功能和模块可以协同工作，并形成一个完整的软件系统。 通过不断重复上述步骤，每个增量都逐步增加系统的功能和完善系统的性能。增量模型允许在开发过程中快速交付可用的软件部分，并根据用户的反馈和需求变化进行调整。它可以提高软件开发的可见性和用户满意度，降低项目风险。\n与迭代模型相比，增量模型更加强调不同增量之间的独立性和可用性。每个增量都是一个可用的软件部分，用户可以在开发过程中逐步使用和评估系统功能。然而，增量模型可能需要更好的规划和管理，以确保增量之间的集成和整合顺利进行，并避免系统架构上的问题。\n敏捷开发 敏捷开发（Agile Development）是一种以迭代、增量和协作为核心的软件开发方法。它强调团队合作、快速响应变化和持续交付，以提高客户满意度和项目成功率。以下是敏捷开发的核心原则和常用实践：\n核心原则：\n个体和互动胜过流程和工具（Individuals and interactions over processes and tools）：强调团队成员之间的沟通、合作和相互支持，重视人与人之间的交流。 可工作的软件胜过详尽的文档（Working software over comprehensive documentation）：注重以可工作的软件作为验证和沟通的手段，而不是过多依赖繁杂的文档。 客户合作胜过合同谈判（Customer collaboration over contract negotiation）：鼓励与客户密切合作，及时获取反馈并根据需求变化进行调整。 响应变化胜过遵循计划（Responding to change over following a plan）：灵活应对需求变化，通过迭代和增量的方式快速适应变化的环境。 常用实践：\nScrum：Scrum 是一种常用的敏捷开发框架，通过迭代周期（称为 Sprint）来组织工作，每个 Sprint 都会产生可部署的软件功能。Scrum 强调自组织团队、产品待办清单、Sprint 计划会议、每日站会和回顾等实践。\nScrum 提供了一组明确定义的角色、仪式和工件，以促进团队合作和高效交付。\n以下是 Scrum 框架中的核心元素：\nScrum 团队： 产品负责人（Product Owner）：负责明确并优先排序产品待办清单（Product Backlog），确保团队开发出有价值的产品。 开发团队（Development Team）：负责实际的软件开发工作，自组织、跨功能且具备自我管理的团队。 Scrum 主管（Scrum Master）：负责促进 Scrum 框架的实施，协助团队移除障碍并保持团队高效运作。 仪式（Ceremonies）： 产品待办清单会议（Product Backlog Refinement）：产品负责人与开发团队一起审查、细化和优化产品待办清单。 计划会议（Sprint Planning）：团队确定下一个 Sprint 要完成的工作，并制定达成目标的计划。 每日站会（Daily Scrum）：团队成员每天举行短暂会议，分享进展、讨论问题和协调工作。 评审会议（Sprint Review）：在 Sprint 结束时，团队展示并回顾已完成的工作，获得利益相关者的反馈。 回顾会议（Sprint Retrospective）：团队回顾 Sprint 过程，识别问题并制定改进措施。 工件（Artifacts）： 产品待办清单（Product Backlog）：按优先级排序的需求列表，包含所有待开发的功能和任务。 冲刺待办清单（Sprint Backlog）：选定的产品待办清单中的任务，团队在 Sprint 期间承诺完成的工作。 冲刺目标（Sprint Goal）：每个 Sprint 的总体目标，指导团队的工作并提供价值交付的方向。 增量（Increment）：每个 Sprint 结束时可部署的软件产品的可工作版本。 用户故事（User Stories）：用户故事是用简短、可理解的方式描述系统的功能需求，以用户角度来阐述需求，以便更好地理解和满足用户期望。\n用户故事（User Stories）是敏捷开发中用于描述软件系统功能需求的简洁、可理解的方式。它们从用户的角度描述了系统应该具备的功能或特性，以便开发团队理解和满足用户的需求。\n一个用户故事通常由以下几个元素组成：\n用户角色（User Role）：描述使用系统的用户角色或身份，例如\u0026quot;顾客\u0026quot;、\u0026ldquo;管理员\u0026rdquo;、\u0026ldquo;游客\u0026quot;等。 活动（Activity）：说明用户在系统中要执行的操作或任务，强调用户的目标和行为，例如\u0026quot;查看订单历史\u0026rdquo;、\u0026ldquo;发布评论\u0026quot;等。 业务价值（Business Value）：描述用户从完成该功能中获得的价值或好处，例如\u0026quot;提高用户满意度\u0026rdquo;、\u0026ldquo;加快订单处理时间\u0026quot;等。 用户故事通常以简短、简洁的语句形式编写，例如：\n作为一个顾客，我希望能够浏览商品目录，以便查找感兴趣的产品。 作为一个管理员，我希望能够添加新用户，以便管理系统的用户账户。 以下是用户故事如何落地的一般步骤：\n故事拆分：首先，将大型用户故事拆分为更小、可执行的部分。这通常通过将用户故事分解为更小的任务、功能或子故事来完成。确保每个拆分后的部分都具有独立的价值，并能够在较短时间内完成。 任务定义：针对每个拆分后的用户故事，明确定义需要进行的具体任务。任务应该是清晰、具体和可测量的。任务可以包括设计、编码、测试、文档编写等。 任务估算：对每个任务进行估算，以确定完成任务所需的时间和资源。可以使用团队共识、专家评估、历史数据等方法进行估算。确保任务的估算是合理和可实现的。 任务分配：将任务分配给团队成员，并确保每个人都清楚自己负责的任务和截止日期。根据每个成员的技能和专长进行任务分配，以最大程度地提高效率和质量。 任务执行：团队成员根据任务的分配和优先级进行任务的执行。在此过程中，开发人员进行编码、设计师进行设计、测试人员进行测试等。团队成员应保持良好的协作和沟通，确保任务按时完成。 验收测试：完成任务后，进行验收测试以确保任务达到预期的要求和质量标准。验收测试应基于用户故事的定义和验收标准，以验证任务的功能和可用性。 用户验收：将任务交付给用户或利益相关者进行最终的用户验收。用户根据用户故事的定义，检查任务是否满足他们的需求和期望。他们提供反馈和建议，以便进一步改进和优化。 通过以上步骤，用户故事可以被有效地落地并转化为实际的功能和任务。这种迭代的方式使团队能够快速响应需求变化，逐步交付增值，提高产品的质量和用户满意度。同时，保持良好的沟通和协作，以及及时的用户反馈，对于成功落地用户故事也非常重要。\n迭代开发和持续集成：采用迭代的方式进行开发，每个迭代周期产生可部署的软件版本。同时，借助持续集成工具和实践，实现频繁地集成和自动化测试，以确保软件质量。\n迭代开发（Iterative Development）和持续集成（Continuous Integration）是敏捷开发中常用的实践方法，旨在提高软件开发的效率、质量和灵活性。\n迭代开发是一种通过多次迭代循环来开发软件的方法。每个迭代周期（通常称为 Sprint）都包含了完整的软件开发流程，包括需求分析、设计、编码、测试和部署。在每个迭代的结束，团队会产生一个可部署的软件版本，也就是一个可工作的增量。迭代开发强调快速交付和持续改进，团队通过不断迭代，逐步完善软件并满足用户需求。\n迭代开发的主要优势包括：\n快速交付价值：每个迭代都产生可工作的软件版本，可以快速交付给用户，获得及早反馈。 高度灵活性：迭代开发可以更好地应对需求变化和新的发现，团队可以在每个迭代中调整计划和优先级。 减少风险：通过迭代和增量交付，风险可以更早地被发现和解决，减少了项目失败的风险。 持续集成是一种软件开发实践，旨在频繁地将开发人员的代码集成到共享代码库中，并通过自动化的构建和测试流程，确保整体系统的稳定性和质量。持续集成要求开发人员频繁地提交代码变更，并将其集成到主干代码库中。集成过程会触发自动化的构建、编译、测试和部署流程，以确保代码的一致性和可靠性。\n持续集成的主要优势包括：\n快速发现问题：通过频繁地集成和自动化测试，可以更早地发现代码问题和错误，减少问题的积累和修复成本。 提高团队协作：持续集成要求开发人员频繁地提交代码变更，促进团队之间的沟通和合作，减少代码冲突和集成问题。 自动化构建和部署：持续集成通过自动化的构建和部署流程，简化了开发人员的工作，提高了交付速度和质量。 迭代开发和持续集成相互配合，可以加强团队的协作、交付能力和软件质量。迭代开发提供了一个明确的工作周期，每个迭代结束时都进行集成和测试，而持续集成则通过频繁的代码集成和自动化测试，确保每次集成都是稳定和可靠的。这两种实践方法的结合可以帮助团队更好地应对需求变化、提高交付速度和质量，以及增强项目的可控性和透明度。\n燃尽图（Burn-down Chart）：燃尽图是一种可视化工具，用于跟踪项目进度和剩余工作量。它展示了团队完成工作的速度，帮助团队预测项目完成时间和调整计划。\n燃尽图（Burn-down Chart）是敏捷开发中的一种可视化工具，用于跟踪项目的进度和工作量。它以图表的形式显示团队在一个迭代周期（通常是 Sprint）中剩余工作的估计量，以及时间的推移而消耗的工作量。\n燃尽图通常以横轴表示时间，纵轴表示工作量（通常以任务数量、故事点或小时数表示）。图表的起点是该迭代周期的工作量总数，随着时间的推移，团队会记录每天的工作量变化，以显示剩余工作的减少情况。理想情况下，燃尽图的线条应该趋近于斜率为负的直线，表示团队按计划逐渐完成剩余工作。\n通过观察燃尽图，团队和利益相关者可以了解项目的进度和工作量的变化情况。以下是一些燃尽图的常见特征：\n理想燃尽线（Ideal Burn-down Line）：这是一条理想的直线，表示如果团队按计划完成每天固定数量的工作，将在迭代结束时完成所有工作。它用于与实际燃尽线进行比较，评估团队的进度。 实际燃尽线（Actual Burn-down Line）：这是实际的工作量消耗曲线，根据每天记录的工作量更新。它显示了团队实际完成工作的速度和剩余工作的变化。 提前或滞后：燃尽图可以显示团队的工作量消耗是否与理想情况相符。如果实际燃尽线在理想燃尽线之上，表示团队进度滞后；如果实际燃尽线在理想燃尽线之下，表示团队进度提前。 Sprint 目标和工作量调整：通过观察燃尽图，团队可以根据实际进度调整工作量和优先级，以确保在迭代结束时能够完成目标。 燃尽图是一种强大的工具，可以帮助团队和利益相关者了解项目的进展情况，并及时采取措施来解决问题或调整计划。它提供了一个可视化的方式来跟踪工作量消耗，促进团队的透明度和自我组织能力，以便更好地管理项目和交付有价值的成果。\n客户反馈和迭代改进：鼓励与客户保持紧密沟通，及时获取反馈并进行迭代改进。通过持续反馈和改进，不断提高软件的质量和满足客户的需求。\n以下是客户反馈和迭代改进的一般流程：\n收集客户反馈：与客户和利益相关者进行沟通，收集他们对产品的意见、建议和需求。可以通过面对面的会议、用户调查、用户测试、用户分析等方式获取反馈。 分析和优先级排序：对收集到的反馈进行分析和评估，理解客户需求的重要性和紧迫性。根据反馈的价值和优先级，将其归类并确定下一步的行动计划。 制定迭代计划：基于客户反馈和优先级，制定下一个迭代周期的计划。确定要在下一个迭代中改进、新增或调整的功能和任务。 迭代开发和测试：根据制定的计划，开展迭代开发和测试工作。在每个迭代周期结束时，产生一个可部署的软件增量，以便客户进行评估和反馈。 客户评估和反馈：将迭代结束后的增量交付给客户进行评估。客户可以通过使用产品、进行测试、提供意见和建议等方式提供反馈。 迭代改进：根据客户的评估和反馈，团队进行迭代改进。根据反馈，修复问题、调整功能、优化用户体验等。这些改进会纳入下一个迭代的计划中。 反复迭代：重复以上步骤，不断收集客户反馈，进行改进，并持续交付增量。每个迭代都可以带来更好的产品版本和更满意的用户体验。 通过客户反馈和迭代改进的循环，团队能够更好地理解客户需求，及时调整产品方向和功能，提供更具价值的产品。这种持续的迭代和改进过程使团队能够适应变化、快速响应客户需求，并不断提高产品质量和用户满意度。\n敏捷开发方法可以提高团队的灵活性、反应速度和交付价值的能力。它适用于需求变化频繁、创新性强或团队协作重要的项目。然而，敏捷开发并非适用于所有项目，因此在选择和实施敏捷开发时，需要根据具体情况进行评估和适应。\nDevOps DevOps 是一种软件开发和运维（Operations）的方法论和实践，旨在通过加强开发团队和运维团队之间的协作和整合，实现快速、可靠的软件交付和持续改进。\nDevOps 强调以下关键原则和实践：\n文化变革：DevOps 鼓励开发团队和运维团队之间的协作、沟通和共享责任的文化变革。通过打破组织内的壁垒，促进团队间的合作和理解。 自动化：自动化是 DevOps 的核心要素。通过使用自动化工具和流程，提高软件交付的速度和质量。包括自动化构建、测试、部署、监控等环节。 持续集成和持续交付：持续集成（Continuous Integration）和持续交付（Continuous Delivery）是 DevOps 的关键实践。持续集成要求开发团队频繁地将代码集成到共享代码库中，并进行自动化的构建和测试。持续交付则要求在每次集成通过后，能够自动、可靠地部署软件到生产环境中。 监控和反馈：DevOps 强调对软件系统的持续监控和反馈。通过实时监测系统的性能、稳定性和用户反馈，及时发现和解决问题，持续改进软件质量和用户体验。 基础设施即代码：DevOps 倡导使用代码和自动化工具来管理和配置基础设施，实现弹性、可伸缩的部署和管理。通过基础设施即代码的实践，能够快速搭建、修改和复制整个环境。 DevOps 的目标是缩短软件交付的周期、提高交付的频率、增强软件的质量和可靠性，并加强团队之间的协作和沟通。通过 DevOps 的实践，开发团队和运维团队能够更好地响应变化、降低风险、提高效率，并为用户提供更好的软件产品和服务。\nDevOps 并非单一的工具或方法，而是一种整体的文化和实践，可以根据组织的需求和情况进行定制和实施。在实践中，常见的 DevOps 工具包括版本控制系统（如 Git）、自动化构建工具（如 Jenkins）、配置管理工具（如 Ansible）、容器化平台（如 Docker、Kubernetes）等。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/21/the-software-development-process/","summary":"软件开发流程和常用开发方法，如敏捷开发和 DevOps，对于架构师来说非常重要。下面我将简要介绍这些概念：\n软件开发流程：\n软件开发流程是指在开发软件时，按照一定的步骤和阶段进行工作的过程。常见的软件开发流程包括瀑布模型、迭代模型和增量模型等。这些流程以不同的方式组织和管理开发过程，包括需求分析、设计、编码、测试和部署等阶段。\n敏捷开发：\n敏捷开发是一种迭代和增量的软件开发方法，强调团队协作、快速响应变化和持续交付。敏捷开发强调通过迭代周期（如 Scrum 中的 Sprint）来开发软件，每个迭代都会产生可部署的软件功能。常见的敏捷方法包括 Scrum、XP（极限编程）和 Kanban 等。\nDevOps：\nDevOps 是一种软件开发和运维的方法论，旨在通过自动化和协作来加速软件交付和提高质量。DevOps 强调开发团队和运维团队之间的协作和共享责任，借助自动化工具和流程来实现持续集成、持续交付和持续部署。\n开发流程 软件开发流程通常包括以下阶段：\n需求收集：收集和记录软件的功能和非功能性需求。 分析与规划：分析需求并规划开发过程，包括资源分配、时间表和交付物。 设计：基于需求创建软件架构、模块和组件的详细设计。 实现：编写代码并集成设计的组件，进行软件开发。 测试：进行各种测试活动，如单元测试、集成测试和系统测试，确保软件按预期功能。 部署：发布软件并在生产环境中向最终用户提供使用。 维护与支持：在部署后提供持续的维护、错误修复和支持。 在整个过程中，遵循版本控制、文档化和协作等最佳实践是非常重要的，以确保软件开发生命周期的顺利和高效进行。\n常见的软件开发流程包括瀑布模型、迭代模型和增量模型等：\n瀑布模型（Waterfall Model）： 瀑布模型是一种线性顺序的软件开发流程，按照固定的阶段依次执行，每个阶段的输出作为下一个阶段的输入。典型的阶段包括需求分析、系统设计、编码、测试和维护等。瀑布模型适用于需求稳定且较小规模的项目，但缺乏灵活性和适应变化的能力。\n下面是瀑布模型的典型阶段：\n需求分析阶段：在这个阶段，与用户和利益相关者一起收集和明确软件系统的需求。定义系统的功能和性能要求，并编写详细的需求规格说明书。 系统设计阶段：在需求分析完成后，进行系统设计。这包括定义系统的整体架构、模块划分、数据结构和算法设计等。设计结果通常以文档形式呈现。 编码阶段：在系统设计完成后，开发团队开始实际的编码工作。根据设计文档，开发人员编写代码并实现系统的各个功能模块。 测试阶段：在编码完成后，进行系统测试。测试人员根据需求和设计规范执行功能测试、集成测试和系统测试，以验证系统的正确性和稳定性。 集成和部署阶段：在测试通过后，将各个模块进行集成，并进行系统级的测试和部署准备。确保整个系统能够协同工作，并准备好部署到目标环境中。 运维和维护阶段：一旦系统部署并投入使用，进入运维和维护阶段。在这个阶段，团队负责监控系统的运行状况，处理问题和错误，并进行必要的修复和更新。 瀑布模型的特点是每个阶段的工作是线性、顺序的，下一个阶段的开始依赖于前一个阶段的完成。这种模型适合需求稳定、项目规模较小、技术风险较低的项目。然而，瀑布模型缺乏灵活性和对变化的适应能力，难以应对需求变更和项目延期等问题。\n因此，在面对需求变化频繁、项目复杂度高、风险较大的情况下，敏捷开发方法如 Scrum 和 Kanban 等更为适用，它们强调迭代、增量和持续交付，能更好地满足客户需求并快速响应变化。\n迭代模型（Iterative Model）： 迭代模型强调通过多个迭代周期来逐步构建和完善软件。每个迭代周期包括需求分析、设计、编码、测试和部署等阶段，每个迭代都会产生可部署的软件版本。迭代模型适用于需求不完全明确或可能变化的项目，能够更好地适应变化和快速反馈。\n以下是迭代模型的一般流程：\n阶段规划：确定每个迭代周期的目标、范围和计划。这包括确定要开发的功能、分配资源、制定时间表等。 需求分析：在每个迭代的开始阶段，与用户和利益相关者一起收集和分析需求，并明确每个迭代的功能和优先级。 设计和开发：根据需求分析的结果，进行系统设计和开发工作。在每个迭代中，系统的某个部分会被设计、开发和测试。 测试和验证：在每个迭代周期结束时，进行系统的内部测试和验证。确保开发的功能符合需求，并满足预期的质量标准。 评审和反馈：在每个迭代周期结束后，与用户和利益相关者进行评审和反馈。他们提供对当前功能的评价和建议，以指导下一个迭代的开发工作。 迭代调整：根据用户的反馈和评审结果，对下一个迭代的计划进行调整和优化。可能需要重新定义需求、调整功能优先级、增加新的需求等。 重复迭代：通过不断重复上述步骤，每个迭代周期都会逐步增加系统的功能、完善系统的性能，并在每个迭代中交付一个可用的软件增量。 迭代模型的优势在于能够快速响应变化和不断提供增值。它允许在开发过程中灵活调整需求，并通过每个迭代的反馈和评审来改进产品。然而，迭代模型也需要适当的计划和管理，以确保每个迭代都能按时交付，并控制开发过程中的风险。\n敏捷方法如 Scrum 和 Kanban 是迭代模型的典型实践，它们更加强调团队的协作、自组织和持续交付，适用于需求变化频繁和项目复杂度较高的环境\n增量模型（Incremental Model）： 增量模型将软件按模块或功能进行划分，每个模块或功能被称为一个增量，通过逐步添加增量来逐渐构建完整的软件系统。每个增量都经历需求分析、设计、开发和测试等阶段。增量模型适用于大规模项目和需要分阶段交付的情况，可以提供更早的价值交付和更好的风险管理。\n以下是增量模型的一般流程：\n阶段划分：将整个软件系统划分为多个增量，每个增量都代表一个可用的软件部分。划分的方式可以基于功能、模块、业务流程等来定义。 需求分析：在每个增量开始时，与用户和利益相关者一起收集和明确关于该增量的需求和功能。确定每个增量的优先级和范围。 设计和开发：根据需求分析的结果，进行系统设计和开发工作。每个增量的设计和开发都是独立进行的，可以采用适合的开发方法和技术。 测试和验证：在每个增量完成开发后，进行系统的测试和验证。确保该增量的功能符合需求，并满足预期的质量标准。 增量交付：经过测试和验证后，将该增量交付给用户或利益相关者。用户可以开始使用该增量，并提供反馈和建议以进一步改进和优化。 增量整合：在完成一个增量的交付后，将该增量与之前交付的增量进行整合。确保不同增量之间的功能和模块可以协同工作，并形成一个完整的软件系统。 通过不断重复上述步骤，每个增量都逐步增加系统的功能和完善系统的性能。增量模型允许在开发过程中快速交付可用的软件部分，并根据用户的反馈和需求变化进行调整。它可以提高软件开发的可见性和用户满意度，降低项目风险。\n与迭代模型相比，增量模型更加强调不同增量之间的独立性和可用性。每个增量都是一个可用的软件部分，用户可以在开发过程中逐步使用和评估系统功能。然而，增量模型可能需要更好的规划和管理，以确保增量之间的集成和整合顺利进行，并避免系统架构上的问题。\n敏捷开发 敏捷开发（Agile Development）是一种以迭代、增量和协作为核心的软件开发方法。它强调团队合作、快速响应变化和持续交付，以提高客户满意度和项目成功率。以下是敏捷开发的核心原则和常用实践：\n核心原则：\n个体和互动胜过流程和工具（Individuals and interactions over processes and tools）：强调团队成员之间的沟通、合作和相互支持，重视人与人之间的交流。 可工作的软件胜过详尽的文档（Working software over comprehensive documentation）：注重以可工作的软件作为验证和沟通的手段，而不是过多依赖繁杂的文档。 客户合作胜过合同谈判（Customer collaboration over contract negotiation）：鼓励与客户密切合作，及时获取反馈并根据需求变化进行调整。 响应变化胜过遵循计划（Responding to change over following a plan）：灵活应对需求变化，通过迭代和增量的方式快速适应变化的环境。 常用实践：","title":"软件开发流程和常用开发方法"},{"content":" 没有人可以否认这样一个事实：安全性是生产就绪应用程序的一项重要功能。尽管我们可以使用内存身份验证、JDBC 身份验证或通过 UserDetailsS​​ervice 来保护一个 Web 应用程序的安全。但是，当一个应用程序在内部使用其他应用程序的服务时，使用 Web 服务概念实现安全性就变得很重要。在这种情况下，我们使用具有特定有效期的令牌来保护我们的应用程序。此外，我们将学习“如何在 Spring Boot 项目中实现 JWT 身份验证？”以整体了解 JWT（JSON Web Token）身份验证背后的概念。\n由于 JWT 代表“JSON Web Token”，很明显，该令牌仅以 JSON 形式保存数据。\n此外，与上述身份验证技术不同，JWT 属于无状态身份验证。简而言之，它没有数据。通常，这种类型的身份验证用于 Web 服务、服务器的水平扩展，甚至在某种程度上用于 OAuth 技术。为了说明该网络服务，让我们可视化从亚马逊预订订单的过程。在这里，用户与 Amazon 应用程序交互，而 Amazon 应用程序在内部通过 Web 服务调用与支付网关应用程序交互。\n现在让我们开始讨论我们的主题“如何在 Spring Boot 项目中实现 JWT 身份验证？”以及相关点。\n您对整篇文章有何期望？ 读完本文后，您将能够回答：\n什么是安全上下文中的无状态和有状态身份验证？ 无状态认证和有状态认证有什么区别？ 那么什么是 Token，什么是 JWT(JSON Web Token)？\n使用 JWT 认证有什么好处？\nJWT 内部如何运作？\n我们在什么情况下使用 JWT 身份验证？\n此外，JWT 身份验证和状态身份验证之间有什么区别？\n此外，如何生成 JWT 编码令牌以及如何将其解码回来？\n如何在 Spring Boot 项目中逐步实现 JWT 认证？\n在 Spring Boot 3.0 中，如何在不使用 WebSecurityConfigurerAdapter 的情况下编写安全配置类？\n最后，如何测试启用 JWT 安全的应用程序？\n什么是无状态和有状态身份验证？ 通常有两种类型的认证技术。两者都发生在客户端服务器概念中，服务器仅在身份验证后才向客户端提供服务。这里的客户端可以是浏览器，也可以是另一个服务器。\n状态认证 在这种类型的身份验证中，客户端和服务器之间涉及会话管理。当客户端向服务器请求服务时，它首先登录到服务器。然后服务器创建一个会话并以键值对的形式存储该信息。这个会话是服务器端的一种内存。我们也称其为 HttpSession，因为 Http 协议管理它。\n此外，为了响应客户端请求，服务器以 Cookie 的形式向客户端提供带有响应的会话 id。该 cookie 存储在客户端浏览器中。当同一个客户端第二次发出请求时，请求头中也会带有 cookie。因此，服务器会检查请求标头，如果在 cookie 中发现相同的 SID（会话 ID），则假定该请求来自同一客户端。通过这种方式，会话管理就发生了。\n当客户端从服务器注销时，会话会相应地被销毁。结果，服务器相应地从内存中删除会话信息（键值）。同样重要的是，对于每个新客户端，服务器都会创建一个新会话（内存）。\n无状态身份验证 当客户端向服务器发送服务请求时，它首先登录到服务器。因此，服务器生成一个令牌（编码格式的数据）并将响应发送到客户端。在发出第二个请求时，客户端将相同的令牌与请求一起发送到服务器。现在，服务器从请求中读取令牌并验证令牌。事实上，从第一个请求开始，服务器就检查客户端的有效登录（凭据）。\n如果它是有效的登录，那么服务器只会创建一个令牌。\n此外，在第二个请求时，它会验证令牌。如果令牌有效，则发送请求的响应，否则要求客户端再次登录。但每个 Token 都会有一个有效时间段，比如 30 分钟、1 小时等。根据业务需求，Token 的有效期可以配置。\n对于 Token 来说，没有注销的概念。相反，客户端可以发出请求并获取响应，直到令牌过期。\n什么是令牌、JWT 身份验证是什么以及使用它的好处是什么？ 简单来说，Token 就是一种编码格式的数据。它可以使用密钥（一种密码）生成。 JWT 是“JSON Web Token”的缩写，它是生成令牌的标准机制。它定义了一种紧凑且独立的方式，以 JSON 对象的形式在各 ​​ 方（多个服务器）之间安全地传输信息。 JWT 由三部分组成：标头、有效负载和签名。每个部分都用逗号分隔。它是一个开源 API。\nJWT 概念不仅存在于 Java 中，也存在于其他语言中。\nader : 包含 JWT 特定信息 Payload : 有效负载，包含声明（客户 ID、客户名称、发行人名称、受众名称、发行日期、到期日期等\u0026hellip;） Signature: 签名，标头和有效负载的 Base64 编码形式。另外，用密钥签名 以下是格式示例：\naaaaaaaaaaa.bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb.cccccccccccccccccccccccccccccccccc 编码后的 JWT 例子 :\neyJhbGciOiJIUzUxMiJ9 .eyJqdGkiOiIzNDMyIiwic3ViIjoiZHMyNTI1IiwiaXNzIjoiQUJDX0x0ZCIsImF1ZCI6IlhZWl9MdGQiLCJpYXQiOjE2MDc0NDI1NzQsImV4cCI6MTYwNzQ0NjE3NH0 .3fIcXIvL9Uz0WtZgaXC95Wj8Hn7ONWKkaaspRwCT6v5Q8QSxZx7hiDQY3klYUMkfe5t2ioasYzEulM_OGc_GEw JWT 身份验证如何工作？ 当客户端向服务器请求服务时，它首先登录到服务器。因此，服务器生成一个令牌（编码格式的数据）并将其与响应一起发送给客户端。在发出第二个请求时，客户端将令牌与请求一起发送到服务器。现在服务器从请求中读取令牌并验证令牌。在验证客户端随请求发送的令牌时，服务器再次需要该密钥来对其进行解码。\n此外，为了验证令牌服务器始终需要密钥。即使在成功登录后，服务器也仅在第一次使用密钥生成令牌。总之，服务器在生成令牌时甚至在验证令牌时也需要密钥。\n与状态身份验证不同，这里服务器仅在服务器端维护令牌。如上所述，在状态认证中，浏览器（客户端）以 cookie 的形式存储会话 ID。\n假设我们通过 JWT 应用程序预订订单。整体至少需要三名参与者才能完成预订。用户、亚马逊应用程序和支付网关应用程序。这里支付网关应用程序验证亚马逊应用程序而不是客户端。发生这种情况是由于令牌身份验证技术。此外，一旦付款完成，亚马逊应用程序将不再使用支付网关的服务。因此，在这种情况下令牌身份验证是更好的选择。有关智威汤逊的更多内部详细信息，请访问智威汤逊网站。\n如何生成 JWT 编码令牌并再次解码（阅读声明）？ 这里的声明是通过提供两个输入来读取或解析 JWT 详细信息的过程：令牌和密钥\n为了实现“如何生成和读取声明”的 POC（概念验证），我们应该考虑为 JWT 找到一个 JAVA API。毫无疑问，我们已经有了 jjwt.jar 来使它成为可能。现在让我们创建一个 POC 来逐步实现我们的功能。\n步骤#1：在 Eclipse 或 STS 中创建一个简单的 Maven 项目。 打开 Eclipse 并选择 File\u0026gt;New\u0026gt;Other，然后搜索“Maven Project”。然后单击“下一步”，选择“创建一个简单项目”复选框。现在点击“下一步”。输入“Group Id”和“Artifact id”作为您的项目详细信息。最后点击“完成”。\n步骤#2：在 pom.xml 中包含 jjwt 依赖项。 包含“jjwt”依赖项，如下所示。此外，如果您使用 JDK8 或更高版本，您还需要包含“jaxb”依赖项。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 步骤#3：创建类并实现功能 因此，我们将创建两个类：JWTUtil.java 和 JWT_Test.java\n在 JWTUtil.java 中，我们将具有可以作为实用程序类工作的实现逻辑。此外，我们将相应地从 JWT_Test.java 测试我们的 POC。\nJWTUtil.java\nackage com.dev.spring.security.jwt; import java.util.Base64; import java.util.Date; import java.util.concurrent.TimeUnit; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; public class JWTUtil { // code to generate Token public static String generateToken(String subject, String secret_key) { return Jwts.builder() .setId(\u0026#34;tk9931\u0026#34;) .setSubject(subject) .setIssuer(\u0026#34;ABC_Ltd\u0026#34;) .setAudience(\u0026#34;XYZ_Ltd\u0026#34;) .setIssuedAt(new Date(System.currentTimeMillis())) .setExpiration(new Date(System.currentTimeMillis() + TimeUnit.HOURS.toMillis(1))) .signWith(SignatureAlgorithm.HS512, Base64.getEncoder().encode(secret_key.getBytes())) .compact(); } //code to get Claims public static Claims getClaims(String token, String secret_key) { return Jwts.parser() .setSigningKey(Base64.getEncoder().encode(secret_key.getBytes())) .parseClaimsJws(token) .getBody(); } } JWT_Test.java\npackage com.dev.spring.security.jwt; import java.util.Base64; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; public class JWT_Test { private static String secret_key = \u0026#34;J@!gt*K\u0026#34;; public static void main(String[] args) { // code to test generated Token String token= JWTUtil.generateToken(\u0026#34;Token1\u0026#34;, secret_key); System.out.println(\u0026#34;------------------------TOKEN----------------------------------------------------\u0026#34;); System.out.println(token); System.out.println(); System.out.println(\u0026#34;------------------------CLAIMS----------------------------------------------------\u0026#34;); //code to test parsed token : Claims Claims claims= Jwts.parser() .setSigningKey(Base64.getEncoder().encode(secret_key.getBytes())) .parseClaimsJws(token) .getBody(); System.out.println(\u0026#34;Token ID: \u0026#34;+claims.getId()); System.out.println(\u0026#34;Token Subject: \u0026#34;+claims.getSubject()); System.out.println(\u0026#34;Token Issuer: \u0026#34;+claims.getIssuer()); System.out.println(\u0026#34;Token Issue Date: \u0026#34;+claims.getIssuedAt()); System.out.println(\u0026#34;Token Expiration Date: \u0026#34;+claims.getExpiration()); System.out.println(\u0026#34;Token Audience: \u0026#34;+claims.getAudience()); } } 输出 以下是我们的 POC 的输出。\n------------------------TOKEN---------------------------------------------------- eyJhbGciOiJIUzUxMiJ9.eyJqdGkiOiJ0azk5MzEiLCJzdWIiOiJUb2tlbjEiLCJpc3MiOiJBQkNfTHRkIiwiYXVkIjoiWFlaX0x0ZCIsImlhdCI6MTYwNzUwNjY0OCwiZXhwIjoxNjA3NTEwMjQ4fQ.lFA0_Jvnt0o69CnotXbTIyYANpWjjeTGxvv6avVihlCqKnuw1bXADp_y3s-NMdohcD2Sq0Cft16wLo7rwvTHpQ ------------------------CLAIMS---------------------------------------------------- Token ID: tk9931 Token Subject: Token1 Token Issuer: ABC_Ltd Token Issue Date: Wed Dec 09 15:07:28 IST 2020 Token Expiration Date: Wed Dec 09 16:07:28 IST 2020 Token Audience: XYZ_Ltd 如何在 Spring Boot 项目中实现 JWT 认证？ 为了说明 JWT 身份验证的实现，我们肯定需要一个 Web 服务调用。为此，我们将使用 REST Web 服务将一些用户注册到数据库中。为了实现这一点，我们将使用 POSTMAN 软件，因为在这种情况下我们不会有注册表。然后我们将 JWT 安全功能应用到我们的代码中。最后，我们将通过测试验证我们纳入的安全功能。让我们开始相应地实施它。\n您需要什么软件/技术？ STS (Spring Tool Suite) : Version-\u0026gt; 4.7.1.RELEASE Dependent Starters : Spring Security, Spring Web, Lombok, Spring Data JPA, MySQL Driver, Spring Boot DevTools MySQL Database : Version -\u0026gt;8.0.19 MySQL Community Server JDK8 or later versions (Extremely tested on JDK8, JDK11 and JDK14) 步骤#1：在 STS(Spring Tool Suite) 中创建 Spring Boot Starter 项目 创建入门项目时，选择“Spring Security”、“Spring Web”、“Spring Data JPA”、“MySQL Driver”、“Lombok”和“Spring Boot DevTools”作为入门项目依赖项。另外，如上所述，在 pom.xml 中添加“jaxb”依赖项。即使您不知道如何创建 Spring Boot Starter 项目，也请访问内部链接。另外，如果您想了解有关 Lombok 的更多信息，请访问 Lombok 上的内部链接。\n步骤#2A：创建实体类 User.java （适用于低于 Spring Boot 3.0 的版本） User.java\npackage com.dev.spring.security.jwt.entity; import java.util.Set; import javax.persistence.CollectionTable; import javax.persistence.Column; import javax.persistence.ElementCollection; import javax.persistence.Entity; import javax.persistence.FetchType; import javax.persistence.GeneratedValue; import javax.persistence.Id; import javax.persistence.JoinColumn; import javax.persistence.Table; import lombok.Data; @Data @Entity @Table(name=\u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue @Column(name=\u0026#34;user_id\u0026#34;) private Integer id; @Column(name=\u0026#34;user_name\u0026#34;) private String username; @Column(name=\u0026#34;user_passwd\u0026#34;) private String password; @Column(name=\u0026#34;user_email\u0026#34;) private String email; @ElementCollection(fetch= FetchType.EAGER) @CollectionTable( name=\u0026#34;roles\u0026#34;, joinColumns = @JoinColumn(name=\u0026#34;user_id\u0026#34;) ) @Column(name=\u0026#34;user_role\u0026#34;) private Set\u0026lt;String\u0026gt; roles; } 步骤#2B：创建实体类 User.java（适用于 Spring Boot 3.0 及更高版本） 在 import 语句中，使用“jakarta”代替“javax”。例如：使用“jakarta.persistence.Entity;”代替“javax.persistence.Entity;”。\nUser.java\npackage com.dev.spring.security.jwt.entity; import java.util.Set; import jakarta.persistence.CollectionTable; import jakarta.persistence.Column; import jakarta.persistence.ElementCollection; import jakarta.persistence.Entity; import jakarta.persistence.FetchType; import jakarta.persistence.GeneratedValue; import jakarta.persistence.Id; import jakarta.persistence.JoinColumn; import jakarta.persistence.Table; import lombok.Data; @Data @Entity @Table(name=\u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue @Column(name=\u0026#34;user_id\u0026#34;) private Integer id; @Column(name=\u0026#34;user_name\u0026#34;) private String username; @Column(name=\u0026#34;user_passwd\u0026#34;) private String password; @Column(name=\u0026#34;user_email\u0026#34;) private String email; @ElementCollection(fetch= FetchType.EAGER) @CollectionTable( name=\u0026#34;roles\u0026#34;, joinColumns = @JoinColumn(name=\u0026#34;user_id\u0026#34;) ) @Column(name=\u0026#34;user_role\u0026#34;) private Set\u0026lt;String\u0026gt; roles; } 步骤#3：更新 application.properties #application.properties #-------------------- Server Properties --------------- server.port=8080 #--------------------- DB Connection Properties ------------------ #AutoLoading of driver class since JDBC 4 #spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/testJWTSecurity spring.datasource.username=root spring.datasource.password=devs #--------------------JPA Properties----------------- spring.jpa.show-sql=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernet.dialect.MySQL8Dialect #------------------Security Specific Properties------- app.secret.key=J@!gt*K 步骤#4：创建接口 UserRepository.java UserRepository.java\npackage com.dev.spring.security.jwt.repo; import java.util.Optional; import org.springframework.data.jpa.repository.JpaRepository; import com.dev.spring.security.jwt.entity.User; public interface UserRepository extends JpaRepository\u0026lt;User, Integer\u0026gt; { Optional\u0026lt;User\u0026gt; findByUsername(String username); } 步骤#5：创建 AppConfig.java AppConfig.java\npackage com.dev.spring.security.jwt.config; import org.springframework.context.annotation.Bean; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Component; @Component public class AppConfig { @Bean public BCryptPasswordEncoder encodePassword() { return new BCryptPasswordEncoder(); } } 步骤#6：创建用户服务接口及其实现类 IUserService.java\npackage com.dev.spring.security.jwt.service; import java.util.Optional; import com.dev.spring.security.jwt.entity.User; public interface IUserService { Integer saveUser(User user); Optional\u0026lt;User\u0026gt; findByUsername(String username); } UserServiceImpl.java\npackage com.dev.spring.security.jwt.service; import java.util.HashSet; import java.util.Optional; import java.util.Set; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Service; import com.dev.spring.security.jwt.entity.User; import com.dev.spring.security.jwt.repo.UserRepository; @Service public class UserServiceImpl implements IUserService, UserDetailsService { @Autowired private UserRepository userRepo; @Autowired private BCryptPasswordEncoder bCryptEncoder; @Override public Integer saveUser(User user) { //Encode password before saving to DB user.setPassword(bCryptEncoder.encode(user.getPassword())); return userRepo.save(user).getId(); } //find user by username @Override public Optional\u0026lt;User\u0026gt; findByUsername(String username) { return userRepo.findByUsername(username); } @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findByUsername(username); org.springframework.security.core.userdetails.User springUser=null; if(opt.isEmpty()) { throw new UsernameNotFoundException(\u0026#34;User with username: \u0026#34; +username +\u0026#34; not found\u0026#34;); }else { User user =opt.get();\t//retrieving user from DB Set\u0026lt;String\u0026gt; roles = user.getRoles(); Set\u0026lt;GrantedAuthority\u0026gt; ga = new HashSet\u0026lt;\u0026gt;(); for(String role:roles) { ga.add(new SimpleGrantedAuthority(role)); } springUser = new org.springframework.security.core.userdetails.User( username, user.getPassword(), ga ); } return springUser; } } 步骤#7：创建 JWTUtil.java JWTUtil.java\npackage com.dev.spring.security.jwt.util; import java.util.Base64; import java.util.Date; import java.util.Random; import java.util.concurrent.TimeUnit; import org.springframework.beans.factory.annotation.Value; import org.springframework.stereotype.Component; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; @Component public class JWTUtil { @Value(\u0026#34;${app.secret.key}\u0026#34;) private String secret_key; // code to generate Token public String generateToken(String subject) { String tokenId= String.valueOf(new Random().nextInt(10000)); return Jwts.builder() .setId(tokenId) .setSubject(subject) .setIssuer(\u0026#34;ABC_Ltd\u0026#34;) .setAudience(\u0026#34;XYZ_Ltd\u0026#34;) .setIssuedAt(new Date(System.currentTimeMillis())) .setExpiration(new Date(System.currentTimeMillis() + TimeUnit.HOURS.toMillis(1))) .signWith(SignatureAlgorithm.HS512, Base64.getEncoder().encode(secret_key.getBytes())) .compact(); } // code to get Claims public Claims getClaims(String token) { return Jwts.parser() .setSigningKey(Base64.getEncoder().encode(secret_key.getBytes())) .parseClaimsJws(token) .getBody(); } // code to check if token is valid public boolean isValidToken(String token) { return getClaims(token).getExpiration().after(new Date(System.currentTimeMillis())); } // code to check if token is valid as per username public boolean isValidToken(String token,String username) { String tokenUserName=getSubject(token); return (username.equals(tokenUserName) \u0026amp;\u0026amp; !isTokenExpired(token)); } // code to check if token is expired public boolean isTokenExpired(String token) { return getExpirationDate(token).before(new Date(System.currentTimeMillis())); } //code to get expiration date public Date getExpirationDate(String token) { return getClaims(token).getExpiration(); } //code to get expiration date public String getSubject(String token) { return getClaims(token).getSubject(); } } 步骤#7：创建 UserRequest 和 UserResponse 模型 UserRequest.java\npackage com.dev.spring.security.jwt.entity; import lombok.Data; @Data public class UserRequest { private String username; private String password; } UserResponse.java\npackage com.dev.spring.security.jwt.entity; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor public class UserResponse { private String token; private String message; } 步骤#8：创建 UserRestController.java UserRestController.java\npackage com.dev.spring.security.jwt.controller; import java.security.Principal; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RequestMapping; import com.dev.spring.security.jwt.entity.User; import com.dev.spring.security.jwt.entity.UserRequest; import com.dev.spring.security.jwt.entity.UserResponse; import com.dev.spring.security.jwt.service.IUserService; import com.dev.spring.security.jwt.util.JWTUtil; @Controller @RequestMapping(\u0026#34;/user\u0026#34;) public class UserRestController { @Autowired private IUserService userService; @Autowired private JWTUtil util; @Autowired private AuthenticationManager authenticationManager; @PostMapping(\u0026#34;/saveUser\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; saveUser(@RequestBody User user) { Integer id = userService.saveUser(user); String message= \u0026#34;User with id \u0026#39;\u0026#34;+id+\u0026#34;\u0026#39; saved succssfully!\u0026#34;; //return new ResponseEntity\u0026lt;String\u0026gt;(message, HttpStatus.OK); return ResponseEntity.ok(message); } @PostMapping(\u0026#34;/loginUser\u0026#34;) public ResponseEntity\u0026lt;UserResponse\u0026gt; login(@RequestBody UserRequest request){ //Validate username/password with DB(required in case of Stateless Authentication) authenticationManager.authenticate(new UsernamePasswordAuthenticationToken( request.getUsername(), request.getPassword())); String token =util.generateToken(request.getUsername()); return ResponseEntity.ok(new UserResponse(token,\u0026#34;Token generated successfully!\u0026#34;)); } @PostMapping(\u0026#34;/getData\u0026#34;) public ResponseEntity\u0026lt;String\u0026gt; testAfterLogin(Principal p){ return ResponseEntity.ok(\u0026#34;You are accessing data after a valid Login. You are :\u0026#34; +p.getName()); } } 步骤＃9：创建 SecurityFilter.java SecurityFilter.java\npackage com.dev.spring.security.jwt.filter; import java.io.IOException; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.web.authentication.WebAuthenticationDetailsSource; import org.springframework.stereotype.Component; import org.springframework.web.filter.OncePerRequestFilter; import com.dev.spring.security.jwt.util.JWTUtil; @Component public class SecurityFilter extends OncePerRequestFilter { @Autowired private JWTUtil util; @Autowired private UserDetailsService userDetailsService; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { // Reading Token from Authorization Header String token= request.getHeader(\u0026#34;Authorization\u0026#34;); if(token !=null) { String username= util.getSubject(token); //if username is not null \u0026amp; Context Authentication must be null if(username !=null \u0026amp;\u0026amp; SecurityContextHolder.getContext().getAuthentication()==null) { UserDetails user= userDetailsService.loadUserByUsername(username); boolean isValid=util.isValidToken(token, user.getUsername()); if(isValid) { UsernamePasswordAuthenticationToken authToken= new UsernamePasswordAuthenticationToken(username, user.getPassword(), user.getAuthorities()); authToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); SecurityContextHolder.getContext().setAuthentication(authToken); } } } filterChain.doFilter(request, response); } } 步骤#10：创建 UnAuthorizedUserAuthenticationEntryPoint.java UnAuthorizedUserAuthenticationEntryPoint.java\npackage com.dev.spring.security.jwt.config; import java.io.IOException; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.springframework.security.core.AuthenticationException; import org.springframework.security.web.AuthenticationEntryPoint; import org.springframework.stereotype.Component; @Component public class UnAuthorizedUserAuthenticationEntryPoint implements AuthenticationEntryPoint { @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED,\u0026#34;UnAuthorized User\u0026#34;); } } 步骤#11A：创建 SecurityConfig.java（适用于低于 Spring Security 5.7 的版本） SecurityConfig.java\npackage com.dev.spring.security.jwt.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import com.dev.spring.security.jwt.filter.SecurityFilter; @EnableWebSecurity @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UserDetailsService userDetailsService; @Autowired private BCryptPasswordEncoder bCryptEncoder; @Autowired private UnAuthorizedUserAuthenticationEntryPoint authenticationEntryPoint; @Autowired private SecurityFilter secFilter; //Required in case of Stateless Authentication @Override @Bean protected AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService) .passwordEncoder(bCryptEncoder); } @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() //Disabling CSRF as not using form based login .authorizeRequests() .antMatchers(\u0026#34;/user/saveUser\u0026#34;,\u0026#34;/user/loginUser\u0026#34;).permitAll() .anyRequest().authenticated() .and() .exceptionHandling() .authenticationEntryPoint(authenticationEntryPoint) .and() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) //To Verify user from second request onwards............ .and() .addFilterBefore(secFilter, UsernamePasswordAuthenticationFilter.class) ; } } 步骤#11B：创建 SecurityConfig.java（适用于高于 Spring Security 5.7 且低于 Spring Security 6.0 的版本） 由于根据 Spring 官网发布的公告，WebSecurityConfigurerAdapter 已从 Spring Security 5.7.0-M2 中弃用，因此，2022 年 2 月 21 日，我们将不使用 WebSecurityConfigurerAdapter 来编写 SecurityConfig 类，如下所示：\nSecurityConfig.java\npackage com.dev.spring.security.jwt.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import com.dev.spring.security.jwt.filter.SecurityFilter; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService userDetailsService; @Autowired private BCryptPasswordEncoder bCryptEncoder; @Autowired private UnAuthorizedUserAuthenticationEntryPoint authenticationEntryPoint; @Autowired private SecurityFilter secFilter; //Required in case of Stateless Authentication @Override @Bean protected AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService) .passwordEncoder(bCryptEncoder); } @Override protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http // .csrf().disable() //Disabling CSRF as not using form based login .authorizeRequests() .antMatchers(\u0026#34;/user/saveUser\u0026#34;,\u0026#34;/user/loginUser\u0026#34;).permitAll() .anyRequest().authenticated() .and() .exceptionHandling() .authenticationEntryPoint(authenticationEntryPoint) .and() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) //To Verify user from second request onwards............ .and() .addFilterBefore(secFilter, UsernamePasswordAuthenticationFilter.class) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(userDetailsService); authenticationProvider.setPasswordEncoder(bCryptEncoder); return authenticationProvider; } } 步骤＃11C：创建 SecurityConfig.java（对于 Spring Security 6.0 及更高版本：Spring Boot 3.0） 从 Spring Security 6.0（2022 年 11 月发布）开始，WebSecurityConfigurerAdapter 已从 Spring Security API 中完全删除。它还影响了 2022 年 11 月新发布的 Spring Boot 3.0。因此，如果您使用 Spring Framework 6.0+ 或 Spring Boot 3.0+，无论哪种情况，SecurityConfig.java 的实现应如下所示。此外，您还可以检查 Spring Framework 6.0 中与 Spring Security 相关的更改。\nSecurityConfig.java\npackage com.dev.spring.security.jwt.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import com.dev.spring.security.jwt.filter.SecurityFilter; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService userDetailsService; @Autowired private BCryptPasswordEncoder bCryptEncoder; @Autowired private UnAuthorizedUserAuthenticationEntryPoint authenticationEntryPoint; @Autowired private SecurityFilter secFilter; //Required in case of Stateless Authentication @Override @Bean protected AuthenticationManager authenticationManager() throws Exception { return super.authenticationManager(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService) .passwordEncoder(bCryptEncoder); } @Override protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http // .csrf().disable() //Disabling CSRF as not using form based login .authorizeHttpRequests() .requestMatchers(\u0026#34;/user/saveUser\u0026#34;,\u0026#34;/user/loginUser\u0026#34;).permitAll() .anyRequest().authenticated() .and() .exceptionHandling() .authenticationEntryPoint(authenticationEntryPoint) .and() .sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.STATELESS) //To Verify user from second request onwards............ .and() .addFilterBefore(secFilter, UsernamePasswordAuthenticationFilter.class) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(userDetailsService); authenticationProvider.setPasswordEncoder(bCryptEncoder); return authenticationProvider; } } Finally, your project structure should look like below screenshot. 最后，您的项目结构应如下图所示。\n如何测试启用 JWT 安全的应用程序？ 虽然“测试”这个词对开发人员来说看起来很容易，但它同样重要，因为它提供了我们整体实施的结果。因此，请按照以下步骤操作：\n1) 使用 Postman 通过 REST 调用注册用户 在 Postman 中输入 URL http://localhost:8080/user/saveUser，选择 POST 方法，然后分别选择 Body\u0026gt;Raw\u0026gt;JSON。现在粘贴下面的 JSON 数据，然后单击“发送”按钮。\n{ “username”: “ds2525”, “password”: “donotforgetme”, “email”: “ds2525@gmail.com”, “roles”: [“Admin”,”Manager”] } 您应该得到以下回复：\nUser with id ‘1’ saved succssfully! 2）以用户身份登录生成令牌 在 Postman 中输入 URL http://localhost:8080/user/loginUser，选择 POST 方法，然后分别选择 Body\u0026gt;Raw\u0026gt;JSON。现在粘贴下面的 JSON 数据，然后单击“发送”按钮。\n{ “username”: “ds2525”, “用户名”：“ds2525”， “password”: “donotforgetme”, “密码”：“不要忘记我”， } 您应该得到以下回复：\n{ \u0026#34;token\u0026#34;:\u0026#34;eyJhbGciOiJIUzUxMiJ9.eyJqdGkiOiI0MzI5Iiwic3ViIjoiZHMyNDI0IiwiaXNzIjoiQUJDX0x0ZCIsImF1ZCI6IlhZWl9MdGQiLCJpYXQiOjE2MDc0MzA5OTIsImV4cCI6MTYwNzQzNDU5Mn0.hIET_EjL6dqgdUMX-dH9a7msPHSO5-GlLFfSotXWWvvxO69hVOLjkiUGYKBZDyux0QRA_bb75Mpp34EOXLHYiw\u0026#34;,\u0026#34;message\u0026#34;: \u0026#34;Token generated successfully!\u0026#34;; } 如果输入了错误的用户名/密码，则输出将如下所示：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-12-08T12:38:25.778+00:00\u0026#34;, \u0026#34;status\u0026#34;: 401, \u0026#34;error\u0026#34;: \u0026#34;Unauthorized\u0026#34;, \u0026#34;trace\u0026#34;: \u0026#34;org.springframework.security.authentication.BadCredentialsException: Bad credentials\\r\\n\\tat org..................................... \u0026#34;message\u0026#34;: \u0026#34;UnAuthorized User\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/user/loginUser\u0026#34; } 3）在 token 有效期内访问数据/资源 在 Postman URL 栏中输入 URL http://localhost:8080/user/getData，选择 POST 方法，然后选择 Headers。在标题下选择密钥作为“授权”。现在将令牌粘贴为授权值，如下面的屏幕截图所示。然后单击“发送”按钮。\n作为成功的响应，您应该得到以下输出：\nYou are accessing data after a valid Login. You are :ds2525 概括 在完成“如何在 Spring Boot 项目中实现 JWT 身份验证？”的所有理论和示例部分之后，最后，我们能够在 Spring Boot 项目中实现 JWT 身份验证安全性。当然，在这篇文章中我们已经彻底了解了 JWT 认证特性。同样，我们希望您进一步扩展此示例并在您的项目中相应地实现它。另外，如果将来有任何变化，我们将相应地更新文章。\n另外，欢迎在评论区提出你的意见。\n原文链接：https://javatechonline.com/how-to-implement-jwt-authentication-in-spring-boot-project/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/18/how-to-implement-jwt-authentication-in-spring-boot-project/","summary":"没有人可以否认这样一个事实：安全性是生产就绪应用程序的一项重要功能。尽管我们可以使用内存身份验证、JDBC 身份验证或通过 UserDetailsS​​ervice 来保护一个 Web 应用程序的安全。但是，当一个应用程序在内部使用其他应用程序的服务时，使用 Web 服务概念实现安全性就变得很重要。在这种情况下，我们使用具有特定有效期的令牌来保护我们的应用程序。此外，我们将学习“如何在 Spring Boot 项目中实现 JWT 身份验证？”以整体了解 JWT（JSON Web Token）身份验证背后的概念。\n由于 JWT 代表“JSON Web Token”，很明显，该令牌仅以 JSON 形式保存数据。\n此外，与上述身份验证技术不同，JWT 属于无状态身份验证。简而言之，它没有数据。通常，这种类型的身份验证用于 Web 服务、服务器的水平扩展，甚至在某种程度上用于 OAuth 技术。为了说明该网络服务，让我们可视化从亚马逊预订订单的过程。在这里，用户与 Amazon 应用程序交互，而 Amazon 应用程序在内部通过 Web 服务调用与支付网关应用程序交互。\n现在让我们开始讨论我们的主题“如何在 Spring Boot 项目中实现 JWT 身份验证？”以及相关点。\n您对整篇文章有何期望？ 读完本文后，您将能够回答：\n什么是安全上下文中的无状态和有状态身份验证？ 无状态认证和有状态认证有什么区别？ 那么什么是 Token，什么是 JWT(JSON Web Token)？\n使用 JWT 认证有什么好处？\nJWT 内部如何运作？\n我们在什么情况下使用 JWT 身份验证？\n此外，JWT 身份验证和状态身份验证之间有什么区别？\n此外，如何生成 JWT 编码令牌以及如何将其解码回来？\n如何在 Spring Boot 项目中逐步实现 JWT 认证？\n在 Spring Boot 3.0 中，如何在不使用 WebSecurityConfigurerAdapter 的情况下编写安全配置类？\n最后，如何测试启用 JWT 安全的应用程序？\n什么是无状态和有状态身份验证？ 通常有两种类型的认证技术。两者都发生在客户端服务器概念中，服务器仅在身份验证后才向客户端提供服务。这里的客户端可以是浏览器，也可以是另一个服务器。\n状态认证 在这种类型的身份验证中，客户端和服务器之间涉及会话管理。当客户端向服务器请求服务时，它首先登录到服务器。然后服务器创建一个会话并以键值对的形式存储该信息。这个会话是服务器端的一种内存。我们也称其为 HttpSession，因为 Http 协议管理它。\n此外，为了响应客户端请求，服务器以 Cookie 的形式向客户端提供带有响应的会话 id。该 cookie 存储在客户端浏览器中。当同一个客户端第二次发出请求时，请求头中也会带有 cookie。因此，服务器会检查请求标头，如果在 cookie 中发现相同的 SID（会话 ID），则假定该请求来自同一客户端。通过这种方式，会话管理就发生了。\n当客户端从服务器注销时，会话会相应地被销毁。结果，服务器相应地从内存中删除会话信息（键值）。同样重要的是，对于每个新客户端，服务器都会创建一个新会话（内存）。\n无状态身份验证 当客户端向服务器发送服务请求时，它首先登录到服务器。因此，服务器生成一个令牌（编码格式的数据）并将响应发送到客户端。在发出第二个请求时，客户端将相同的令牌与请求一起发送到服务器。现在，服务器从请求中读取令牌并验证令牌。事实上，从第一个请求开始，服务器就检查客户端的有效登录（凭据）。","title":"[译]Spring Boot项目如何实现JWT认证？"},{"content":" 在 Spring Security 模块的上下文中，WebSecurityConfigurerAdapter 是一个抽象类，根据 Spring 官方网站 2022 年 2 月 21 日发布的公告，该类已从 Spring Security 5.7.0-M2 中弃用。它通常用于扩展 configure() 方法由自定义配置子类实现。因此，它鼓励用户转向基于组件的安全配置。为了支持对这种新配置设计的更改，我们将讨论常见用例列表和未来建议的替代方案。因此，我们将讨论没有 WebSecurityConfigurerAdapter 的 Spring Security 用例的实现。\n了解这一变化很重要，因为迟早我们将使用最新版本的 Spring Security 来开发安全功能。让我们讨论“没有 WebSecurityConfigurerAdapter 的 Spring Security”主题及其相关概念。\n什么是 WebSecurityConfigurerAdapter？ WebSecurityConfigurerAdapter 是 Spring Security 模块提供的一个抽象类。一般来说，我们使用它来重写它的 configure()方法来定义我们的安全配置类。通常，我们在应用程序中实现 Spring Security 时使用两个具有不同参数的 configure() 方法。一种用于声明与身份验证相关的配置，另一种用于声明与授权相关的配置。该代码类似于下面的代码片段。\n@Configuration @EnableWebSecurity public class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // configure Authentication ...... } @Override protected void configure(HttpSecurity http) throws Exception { // configure Authorization ...... } } 为什么我们需要学习这个改变？ 如果您使用 Spring Boot 2.7.0 和 maven，它将自动下载 Spring Security 5.7.0 或更高版本。在这种情况下，您会发现 WebSecurityConfigurerAdapter 已被弃用。如果您仍然想使用此类而不弃用，您可以在 pom.xml 中将 Spring Boot 版本更改为较低版本（例如 2.6.6 ），如下所示。它将自动下载低于 5.7.0 的 Spring Security 版本，并且弃用警告将消失。\n但是，如果您不使用 Spring Boot，而是使用简单的 Spring Security 模块，您甚至可以降低 Spring Security 的版本。\n\u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.6\u0026lt;/version\u0026gt; \u0026lt;/parent\u0026gt; 这样，我们就可以在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security。\n我们需要在哪里实施这一改变？ 以下是一些可能实施此更改的情况。\n如果您使用的是 Spring Boot 2.7.0 或更高版本\n如果您正在使用 Spring Security 5.7.0 或更高版本\n如果你的项目得到如上所述升级或迁移到更高版本\n如果您想使用最新版本的 Spring Boot 自定义 Spring Security 配置\n如果您想删除 WebSecurityConfigurerAdapter Deprecated 的烦人警告\n如果你想在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security。\n如何删除已弃用的警告？ 下面就让我们一步一步来学习吧：\n如果您使用 STS 作为 IDE 来开发项目，则需要降低 Spring Boot 的版本。如果您使用的是 Spring Boot 2.7.0 或更高版本，请将其设为 2.6.x（例如 2.6.6）。您可以通过更新 pom.xml 来做到这一点。完成后，它将自动下载 Spring Security 模块的兼容版本。\n检查您的配置类是否扩展了 WebSecurityConfigurerAdapter 类。已弃用的警告应该消失。现在您可以在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security。\n如何在没有 WebSecurityConfigurerAdapter 的情况下使用 Spring Security？ 如上所述，通常我们会在自定义配置类中继承 WebSecurityConfigurerAdapter 的 configure() 方法。因此，我们需要找到这些方法的替代方案，因为自 Spring Security 5.7.0-M2 发布以来，WebSecurityConfigurerAdapter 已被弃用。\n让我们讨论一些例子\n示例#1：使用 WebSecurityConfigurerAdapter 此示例演示了 HttpSecurity 配置。通常，我们编写它来声明授权工件。\n@Configuration @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.cors().and().csrf().disable() .and().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and().authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .anyRequest().authenticated() ; } } 示例#1：没有 WebSecurityConfigurerAdapter 下面的代码演示了在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security 的可能解决方案。\n@Configuration @EnableWebSecurity public class WebSecurityConfig { @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.cors().and().csrf().disable() .and().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS) .and().authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .anyRequest().authenticated(); return http.build(); } } 在这里，我们需要执行以下步骤：\n步骤#1：删除@override，因为我们不会从任何类中扩展和覆盖它。 步骤＃2：在此方法上应用@Bean 注解 步骤#3：现在将方法返回类型声明为 SecurityFilterChain，而不是 void 步骤#4：根据需要更新方法名称。比如说 filterChain。 步骤#5：方法结束时，主体返回 http.build()。这里 http 是 HttpSecurity 类型的变量。 示例#2：使用 WebSecurityConfigurerAdapter 在下面的示例中，我们使用了这两种方法。\nimport org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // {noop} =\u0026gt; No operation for password encoder (no password encoding needed) auth.inMemoryAuthentication() .withUser(\u0026#34;devs\u0026#34;) .password (\u0026#34;{noop} devs\u0026#34;) //no password encoding needed .authorities(\u0026#34;ADMIN\u0026#34;); auth.inMemoryAuthentication().withUser(\u0026#34;ns\u0026#34;).password(\u0026#34;{noop}ns\u0026#34;).authorities(\u0026#34;EMPLOYEE\u0026#34;); auth.inMemoryAuthentication().withUser(\u0026#34;vs\u0026#34;).password(\u0026#34;{noop}vs\u0026#34;).authorities(\u0026#34;MANAGER\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { //declares which Page(URL) will have What access type http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;EMPLOYEE\u0026#34;,\u0026#34;MANAGER\u0026#34;) // Any other URLs which are not configured in above antMatchers // generally declared aunthenticated() in real time .anyRequest().authenticated() // Login Form Details .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true) // Logout Form Details .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) // Exception Details .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; } } 示例#2：没有 WebSecurityConfigurerAdapter 下面的代码演示了在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security 的可能解决方案。\nimport java.util.ArrayList; import java.util.List; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfigNew { @Bean protected InMemoryUserDetailsManager configAuthentication() { List\u0026lt;UserDetails\u0026gt; users = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;GrantedAuthority\u0026gt; adminAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;ADMIN\u0026#34;)); UserDetails admin= new User(\u0026#34;devs\u0026#34;, \u0026#34;{noop}devs\u0026#34;, adminAuthority); users.add(admin); List\u0026lt;GrantedAuthority\u0026gt; employeeAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;EMPLOYEE\u0026#34;)); UserDetails employee= new User(\u0026#34;ns\u0026#34;, \u0026#34;{noop}ns\u0026#34;, employeeAuthority); users.add(employee); List\u0026lt;GrantedAuthority\u0026gt; managerAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;MANAGER\u0026#34;)); UserDetails manager= new User(\u0026#34;vs\u0026#34;, \u0026#34;{noop}vs\u0026#34;, managerAuthority); users.add(manager); return new InMemoryUserDetailsManager(users); } @Bean protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { //declares which Page(URL) will have What access type http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;EMPLOYEE\u0026#34;,\u0026#34;MANAGER\u0026#34;) // Any other URLs which are not configured in above antMatchers // generally declared aunthenticated() in real time .anyRequest().authenticated() // Login Form Details .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true) // Logout Form Details .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) // Exception Details .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; return http.build(); } } 上面的代码片段是使用 Spring Security 的内存中身份验证的示例。\n示例#3：使用 WebSecurityConfigurerAdapter @Configuration @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Autowire UserDetailsService userDetailsService; @Override public void configure(AuthenticationManagerBuilder authenticationManagerBuilder) throws Exception { authenticationManagerBuilder.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder()); } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } } 示例#3：没有 WebSecurityConfigurerAdapter 下面的代码演示了在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security 的可能解决方案。\n@Configuration @EnableWebSecurity public class WebSecurityConfig { @Bean AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception { return authenticationConfiguration.getAuthenticationManager(); } } 在这里，在旧版本中我们注入 AuthenticationManagerBuilder，设置 userDetailsS​​ervice、passwordEncoder 并构建它。但是 AuthenticationManager 已经在这一步中创建了。它是按照我们想要的方式创建的（使用 userDetailsS​​ervice 和 passwordEncoder）。\n示例#4：使用 WebSecurityConfigurerAdapter 在实现网络安全配置时，WebSecurityCustomizer 是一个回调接口，可用于自定义 WebSecurity。\n@Configuration @EnableWebSecurity public class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override public void configure(WebSecurity web) { web.ignoring().antMatchers(\u0026#34;/ignore1\u0026#34;, \u0026#34;/ignore2\u0026#34;); } } 示例#4：没有 WebSecurityConfigurerAdapter 从 Spring Security 5.7.0-M2 开始，推荐的方法是注册 WebSecurityCustomizer bean。下面的代码演示了在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security 的可能解决方案：\n@Configuration @EnableWebSecurity public class SecurityConfiguration { @Bean public WebSecurityCustomizer webSecurityCustomizer() { return (web) -\u0026gt; web.ignoring().antMatchers(\u0026#34;/ignore1\u0026#34;, \u0026#34;/ignore2\u0026#34;); } } 示例#5：使用 WebSecurityConfigurerAdapter 下面的代码演示了 Spring Security 上下文中 JDBC 身份验证的变化。\nong\u0026gt;@Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private DataSource dataSource; @Autowired private BCryptPasswordEncoder passwordEncoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.jdbcAuthentication() .dataSource(dataSource) //creates database connection .usersByUsernameQuery(\u0026#34;select user_name,user_pwd,user_enabled from user where user_name=?\u0026#34;) .authoritiesByUsernameQuery(\u0026#34;select user_name,user_role from user where user_name=?\u0026#34;) .passwordEncoder(passwordEncoder); } } 示例#5：没有 WebSecurityConfigurerAdapter 展望未来，如果我们想在没有 WebSecurityConfigurerAdapter 的情况下实现 Spring Security，新代码将如下所示。\n@Configuration @EnableWebSecurity public class SecurityConfig { @Autowired private DataSource dataSource; @Bean public UserDetailsManager authenticateUsers() { UserDetails user = User.withUsername(\u0026#34;username\u0026#34;) .password(PasswordEncoderFactories.createDelegatingPasswordEncoder().encode(\u0026#34;password\u0026#34;)).build(); JdbcUserDetailsManager users = new JdbcUserDetailsManager(dataSource); users.setAuthoritiesByUsernameQuery(\u0026#34;select user_name,user_pwd,user_enabled from user where user_name=?\u0026#34;); users.setUsersByUsernameQuery(\u0026#34;select user_name,user_role from user where user_name=?\u0026#34;); users.createUser(user); return users; } } 新的实现将如上所示。这可能不是确切的解决方案。\nSpring Security 6.0.0 或更高版本中有哪些弃用更新？ 如果您使用 Spring Security 6.0.0 或更高版本（以及 Spring Boot 3.0 或更高版本），您还会看到其他 API 弃用。例如，以下是需要进行的一些更改：\nauthorizeRequests() -\u0026gt;authorizeHttpRequests()\nantMatchers() -\u0026gt; requestMatchers()\nregexMatchers() -\u0026gt; RegexRequestMatchers()\nFAQ 在哪里可以找到“没有 WebSecurityConfigurerAdapter 的 Spring Security 的完整示例？” 以下是查找“没有 WebSecurityConfigurerAdapter 的 Spring Security”完整示例的链接：\nHow To Implement Security In Spring Boot Project?\nHow to implement Role Based Spring Security Without WebSecurityConfigurerAdapter in Spring Boot using UserDetailsService?\nHow to implement JWT Authentication in Spring Boot Project?\n结论 在完成了“没有 WebSecurityConfigurerAdapter 的 Spring Security”的所有理论和示例部分之后，最后，我们应该准备好在实时项目中处理警告“WebSecurityConfigurerAdapter Deprecated”。此外，我们希望您扩展“没有 WebSecurityConfigurerAdapter 的 Spring Security”一文中提供的知识，并在您的项目中相应地实现该概念。如需进一步学习 Spring Security，您可以访问 Spring Security 使用 Spring Boot 系列教程。另外，如果后续有任何更新，我们也会对文章进行相应的更新。此外，请随时在下面的评论部分提供您的意见。\n原文链接：https://javatechonline.com/spring-security-without-websecurityconfigureradapter/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/18/spring-security-without-websecurityconfigureradapter/","summary":"在 Spring Security 模块的上下文中，WebSecurityConfigurerAdapter 是一个抽象类，根据 Spring 官方网站 2022 年 2 月 21 日发布的公告，该类已从 Spring Security 5.7.0-M2 中弃用。它通常用于扩展 configure() 方法由自定义配置子类实现。因此，它鼓励用户转向基于组件的安全配置。为了支持对这种新配置设计的更改，我们将讨论常见用例列表和未来建议的替代方案。因此，我们将讨论没有 WebSecurityConfigurerAdapter 的 Spring Security 用例的实现。\n了解这一变化很重要，因为迟早我们将使用最新版本的 Spring Security 来开发安全功能。让我们讨论“没有 WebSecurityConfigurerAdapter 的 Spring Security”主题及其相关概念。\n什么是 WebSecurityConfigurerAdapter？ WebSecurityConfigurerAdapter 是 Spring Security 模块提供的一个抽象类。一般来说，我们使用它来重写它的 configure()方法来定义我们的安全配置类。通常，我们在应用程序中实现 Spring Security 时使用两个具有不同参数的 configure() 方法。一种用于声明与身份验证相关的配置，另一种用于声明与授权相关的配置。该代码类似于下面的代码片段。\n@Configuration @EnableWebSecurity public class SecurityConfiguration extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // configure Authentication ...... } @Override protected void configure(HttpSecurity http) throws Exception { // configure Authorization ...... } } 为什么我们需要学习这个改变？ 如果您使用 Spring Boot 2.7.0 和 maven，它将自动下载 Spring Security 5.7.0 或更高版本。在这种情况下，您会发现 WebSecurityConfigurerAdapter 已被弃用。如果您仍然想使用此类而不弃用，您可以在 pom.xml 中将 Spring Boot 版本更改为较低版本（例如 2.6.6 ），如下所示。它将自动下载低于 5.","title":"[译]没有WebSecurityConfigurerAdapter的Spring Security.md"},{"content":" 继续上一篇关于实现 Spring Security 的两种不同方法的文章，在本文中，我们将学习第三种方法“如何使用 UserDetailsS​​ervice 在 Spring Boot 中实现 Security？”。经过上一篇文章后，我希望我们都非常熟悉安全性的基础知识，甚至是 Spring Boot 应用程序中的安全性基础知识。这次我们将创建一个用户注册表并将用户及其角色保存到数据库中。\n然后，根据用户角色，我们将借助预定义的 UserDetailsS​​ervice 检查身份验证和授权功能。\n如果您正在寻找“如何在 Spring Boot 3 及以上版本中使用 UserDetailsS​​ervice 在 Spring Boot 中实现安全性？”，请访问有关使用 Spring Boot 3 的 Spring Security UserDetailsS​​ervice 的单独文章。\n为了说明这一点，我们将把一些角色发挥作用，并在整个过程中围绕它们进行发挥，以使其变得清晰。此外，我们将有一些页面并限制它们仅可由某些特定角色访问。同样重要的是，我们必须创建一个小型 MVC Web 应用程序，以使注册过程向用户开放。用户在注册时将输入自己的角色。然后我们可以在其之上实现安全功能。\n让我们开始相应的主题“如何使用 UserDetailsS​​ervice 在 Spring Boot 中实现安全性？”。\n总体而言，您对这篇文章有何期望？ Spring Security 上下文中的 UserDetailsS​​ervice 概念是什么？\n实施 UserDetailsService 有什么好处？\n如何使用 UserDetailsService 在 Spring Boot 中实现安全性？\nUserDetailsService 在 Spring Security 应用程序中如何内部工作并带有流程图？\n另外，如何使用注解：@EnableWebSecurity、@Configuration、@Bean、@GetMapping、@Autowired、@Data、@Entity、@Table、@Id、@GenerateValue、@Column、@ElementCollection、@CollectionTable、@JoinColumn ， @服务\n如何使用 Spring MVC 和 Thymeleaf 开发用户注册应用程序？\n如何测试启用安全的应用程序？\n如何在没有 WebSecurityConfigurerAdapter 的情况下使用 UserDetailsService 在 Spring Boot 中实现安全性？\nUserDetailsService 是做什么的？使用它有什么好处？ UserDetailsS​​ervice 是 Spring 中 org.springframework.security.core.userdetails 包下的预定义接口。我们的实现类实现了这个接口并重写了它的 loadUserByUsername(String username) 方法。此方法返回 UserDetails，它又是一个接口。预定义的 User 类（org.springframework.security.core.userdetails.User）是 UserDetails 接口的实现。总之，在 loadUserByUsername(String username) 方法中，我们传递用户名，它返回我们预定义的 User 对象（org.springframework.security.core.userdetails.User）。\n事实上，我们只向 UserDetailsS​​ervice 提供用户名和一些小的配置，并且我们将所有基于角色的安全功能作为框架的一部分实现。因此，我们在实施安全性方面节省了大量精力。\n如何在我们的应用程序中实现 UserDetailsService 安全性？ 首先，您必须有一个 Spring Boot Web 应用程序，其中您将有一个表单，即一种用户注册表单。作为 Spring MVC 结构的一部分，您将拥有一个 UserService 实现类。假设它是 UserServiceImpl.java。要记住的第二件事是，您必须将 User 对象转换为预定义的 Spring User 对象。此外，请按照以下步骤在您的应用程序中实现 UserDetailsService。\n1）你的用户服务类‘UserServiceImpl.java’应该实现接口 UserDetailsService.java（由 Spring 提供）\n2）同样重要的是，重写 UserServiceImpl 类中 UserDetailsService 接口的 loadUserByUsername(String username) 方法。\n3）作为实施的一部分，(A) 借助 UserRepository 中的用户名/电子邮件获取您的用户对象。 (B) 将你的 User 对象相应地转换为 Spring 预定义的 User 对象(org.springframework.security.core.userdetails.User)。 (C) 返回 Spring 定义的 User 对象，它是 UserDetails（方法的返回类型）的实现。\n下面的代码代表了 UserDetailsService 的实现。但是，您将在下面的部分中看到完整的代码。\nUserServiceImpl.java\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import java.util.HashSet; import java.util.List; import java.util.Optional; import java.util.Set; import java.util.stream.Collectors; @Service public class UserServiceImpl implements IUserService, UserDetailsService { @Autowired private UserRepository userRepo; @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); org.springframework.security.core.userdetails.User springUser = null; if (opt.isEmpty()) { throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; + email + \u0026#34; not found\u0026#34;); } else { User user = opt.get(); List\u0026lt;String\u0026gt; roles = user.getRoles(); Set\u0026lt;GrantedAuthority\u0026gt; ga = new HashSet\u0026lt;\u0026gt;(); for (String role : roles) { ga.add(new SimpleGrantedAuthority(role)); } springUser = new org.springframework.security.core.userdetails.User( email, user.getPassword(), ga); } return springUser; } //Other Approach: Using Lambda \u0026amp; Stream API of Java 8 //\t@Override //\tpublic UserDetails loadUserByUsername(String email) //\tthrows UsernameNotFoundException { // //\tOptional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); // //\tif (opt.isEmpty()) //\tthrow new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; + email + \u0026#34; not found !\u0026#34;); //\telse { //\tUser user = opt.get(); //\treturn new org.springframework.security.core.userdetails.User( //\tuser.getEmail(), //\tuser.getPassword(), //\tuser.getRoles() //\t.stream() //\t.map(role -\u0026gt; new SimpleGrantedAuthority(role)) //\t.collect(Collectors.toSet()) //\t); //\t} //\t} } UserDetailsService 在 Spring Security 应用程序内部如何工作？ ` 一旦用户输入用户名和密码并单击“登录”按钮，就会调用 WebSecurityConfigurerAdapter，该适配器在内部调用 UserServiceImpl.java（实现类，由程序员提供）。此外，UserServiceImpl.java 中实现的 loadUserByUserName()方法将我们的 User 对象转换为 Spring 提供的 User 对象。此外，我们的 SecurityConfig.java 扩展了 WebSecurityConfigurerAdapter 并通过两种方法提供了身份验证和授权逻辑的实现；分别配置（AuthenticationManagerBuilder）和配置（HttpSecurity），如下面的代码所示。\nSecurityConfig.java\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; @EnableWebSecurity @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(uds).passwordEncoder(encoder); } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;, \u0026#34;/register\u0026#34;, \u0026#34;/saveUser\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .antMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee,Manager,Admin\u0026#34;) .anyRequest().authenticated().and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true).and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)).and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;); } } 注意：从 Spring Security 5.7.0-M2 开始，WebSecurityConfigurerAdapter 已被弃用。因此，如果您使用 Spring Security 5.7.0-M2 或更高版本，请更新您的实现，如下面的代码片段所示。此外，为了了解实现自定义配置类的新方法，请访问有关不使用 WebSecurityConfigurerAdapter 的 Spring Security 的单独文章。\nSecurityConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;,\u0026#34;/register\u0026#34;,\u0026#34;/saveUser\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .antMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee,Manager,Admin\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(uds); authenticationProvider.setPasswordEncoder(encoder); return authenticationProvider; } } 实现 UserDetailsService 的示例 为了说明 UserDetailsS​​ervice 的实现，我们假设一个小公司的内部门户。在公司中，我们的员工扮演着各种角色，例如管理员、人力资源、经理，当然还有员工。此外，门户还具有基于角色的页面访问权限。甚至某些页面可供所有角色访问，而其他页面则仅限于某些特定角色。\n同样重要的是，公司将有一个用户注册页面，即使没有登录，所有用户也必须可以访问该页面。现在让我们创建一个标准用户注册流程，如下所示。\n步骤#1：在 STS(Spring Tool Suite)中创建一个 Spring Boot Starter 项目 创建入门项目时，选择“Spring Security”、“Thymeleaf”、“Spring Web”、“Spring Data JPA”、“MySQL Driver”、“Lombok”和“Spring Boot DevTools”作为入门项目依赖项。即使您不知道如何创建 Spring Boot 入门项目，也请访问“如何在 Spring boot 中创建入门项目？”的内部链接。另外，如果您想了解有关 Lombok 的更多信息，请访问 Lombok 上的内部链接。\n步骤#2：更新数据库配置 更新 application.properties 以连接到 MySQL 数据库。请注意，我们还可以省略 driver-class-name，因为 Spring Boot 会自动从数据库 URL 中找到它，如下所示。不过，建议保留。\n#application.properties --------------------------------------------------------------------- #-------------------- server properties --------------- server.port=8080 #--------------------- DB Connection ------------------ #AutoLoading of driver class since JDBC 4 #spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/testBootSecurity spring.datasource.username=root spring.datasource.password=devs #--------------------JPA-ORM Properties----------------- spring.jpa.show-sql=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernet.dialect.MySQL8Dialect 步骤#3：创建用户实体和存储库类 现在创建 User.java 和 UserRepositoty.java 如下。同样重要的是，User.java 有一个 List 类型的变量“roles”。它将在数据库中创建一个单独的表，其中相应地包含两列 user_id 和 user_role 。此外，@ElementCollection(fetch= FetchType.EAGER)表示在获取 User 对象的同时，也同时获取角色。另一方面，UserRepository 扩展了“JpaRepository”以利用内置数据库操作。\nUser.java\npackage com.dev.springboot.security.UserDetailsService.model; import java.util.List; import javax.persistence.CollectionTable; import javax.persistence.Column; import javax.persistence.ElementCollection; import javax.persistence.Entity; import javax.persistence.FetchType; import javax.persistence.GeneratedValue; import javax.persistence.Id; import javax.persistence.JoinColumn; import javax.persistence.Table; import lombok.Data; @Data @Entity @Table(name=\u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue @Column(name=\u0026#34;user_id\u0026#34;) private Integer id; @Column(name=\u0026#34;user_name\u0026#34;) private String name; @Column(name=\u0026#34;user_passwd\u0026#34;) private String password; @Column(name=\u0026#34;user_email\u0026#34;) private String email; @ElementCollection(fetch= FetchType.EAGER) @CollectionTable( name=\u0026#34;roles\u0026#34;, joinColumns = @JoinColumn(name=\u0026#34;user_id\u0026#34;) ) @Column(name=\u0026#34;user_role\u0026#34;) private List\u0026lt;String\u0026gt; roles; } UserRepository.java\npackage com.dev.springboot.security.UserDetailsService.repo; import java.util.Optional; import org.springframework.data.jpa.repository.JpaRepository; import com.dev.springboot.security.UserDetailsService.model.User; public interface UserRepository extends JpaRepository\u0026lt;User, Integer\u0026gt; { Optional\u0026lt;User\u0026gt; findUserByEmail(String email); } 步骤#4：创建 AppConfig 类来实例化 BCryptPasswordEncoder 由于 BCryptPasswordEncoder 是一个预定义的类，因此我们需要在 AppConfig.java 中提供它的实例化代码作为配置类。此外，需要 BCryptPasswordEncoder 在其他类中对我们的密码值进行编码。\nAppConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; @Configuration public class AppConfig { @Bean public BCryptPasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } } 步骤#5：创建服务接口和服务实现类 相应地创建服务接口和服务 Impl 类作为 IUserService.java 和 UserServiceImpl.java，如下所示。事实上，UserServiceImpl.java 中 loadUserByUsername(String email) 方法的实现是整个 UserDetailsS​​ervice 中最重要的部分。\nIUserService.java\npackage com.dev.springboot.security.UserDetailsService.service; import com.dev.springboot.security.UserDetailsService.model.User; public interface IUserService { public Integer saveUser(User user); } UserServiceImpl.java\npackage com.dev.springboot.security.UserDetailsService.service.impl; import java.util.HashSet; import java.util.List; import java.util.Optional; import java.util.Set; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Service; import com.dev.springboot.security.UserDetailsService.model.User; import com.dev.springboot.security.UserDetailsService.repo.UserRepository; import com.dev.springboot.security.UserDetailsService.service.IUserService; @Service public class UserServiceImpl implements IUserService, UserDetailsService{ @Autowired private UserRepository userRepo; @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public Integer saveUser(User user) { String passwd= user.getPassword(); String encodedPasswod = passwordEncoder.encode(passwd); user.setPassword(encodedPasswod); user = userRepo.save(user); return user.getId(); } @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); org.springframework.security.core.userdetails.User springUser=null; if(opt.isEmpty()) { throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found\u0026#34;); }else { User user =opt.get(); List\u0026lt;String\u0026gt; roles = user.getRoles(); Set\u0026lt;GrantedAuthority\u0026gt; ga = new HashSet\u0026lt;\u0026gt;(); for(String role:roles) { ga.add(new SimpleGrantedAuthority(role)); } springUser = new org.springframework.security.core.userdetails.User( email, user.getPassword(), ga ); } return springUser; } //Other Approach: Using Lambda \u0026amp; Stream API of Java 8 /*@Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); if(opt.isEmpty()) throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found !\u0026#34;); else { User user = opt.get(); return new org.springframework.security.core.userdetails.User( user.getEmail(), user.getPassword(), user.getRoles() .stream() .map(role-\u0026gt; new SimpleGrantedAuthority(role)) .collect(Collectors.toSet()) ); }*/ } 步骤#6：创建一个 UserController 类 随后，为用户编写一个控制器类“UserController.java”，它将控制用户注册页面。\nUserController.java\npackage com.dev.springboot.security.UserDetailsService.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.PostMapping; import com.dev.springboot.security.UserDetailsService.model.User; import com.dev.springboot.security.UserDetailsService.service.IUserService; @Controller public class UserController { @Autowired private IUserService userService; // Go to Registration Page @GetMapping(\u0026#34;/register\u0026#34;) public String register() { return \u0026#34;registerUser\u0026#34;; } // Read Form data to save into DB @PostMapping(\u0026#34;/saveUser\u0026#34;) public String saveUser( @ModelAttribute User user, Model model ) { Integer id = userService.saveUser(user); String message = \u0026#34;User \u0026#39;\u0026#34;+id+\u0026#34;\u0026#39; saved successfully !\u0026#34;; model.addAttribute(\u0026#34;msg\u0026#34;, message); return \u0026#34;registerUser\u0026#34;; } } 步骤#7：编写一个控制器类来浏览页面 除了 UserController，再编写一个控制器类并将其命名为“HomeController.java”。该类将负责浏览不同的页面。\nHomeController.java\npackage com.dev.springboot.security.UserDetailsService.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class HomeController { @GetMapping(\u0026#34;/home\u0026#34;) public String getHomePage() { return \u0026#34;homePage\u0026#34;; } @GetMapping(\u0026#34;/welcome\u0026#34;) public String getWelcomePage() { return \u0026#34;welcomePage\u0026#34;; } @GetMapping(\u0026#34;/admin\u0026#34;) public String getAdminPage() { return \u0026#34;adminPage\u0026#34;; } @GetMapping(\u0026#34;/emp\u0026#34;) public String getEmployeePage() { return \u0026#34;empPage\u0026#34;; } @GetMapping(\u0026#34;/mgr\u0026#34;) public String getManagerPage() { return \u0026#34;mgrPage\u0026#34;; } @GetMapping(\u0026#34;/hr\u0026#34;) public String getHrPage() { return \u0026#34;hrPage\u0026#34;; } @GetMapping(\u0026#34;/common\u0026#34;) public String getCommonPage() { return \u0026#34;commonPage\u0026#34;; } @GetMapping(\u0026#34;/accessDenied\u0026#34;) public String getAccessDeniedPage() { return \u0026#34;accessDeniedPage\u0026#34;; } } 步骤#8：编写 UI 页面(Thymeleaf) 以下是 UI 页面的 .html 文件。将这些页面相应地放入“src/main/resources/templates”文件夹中。\nregisterUser.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;User Registration\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;User Registration\u0026lt;/h3\u0026gt; \u0026lt;form action=\u0026#34;saveUser\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;pre\u0026gt; Name : \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34;/\u0026gt; Email: \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34;/\u0026gt; Password: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;/\u0026gt; Role(s): \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Admin\u0026#34;/\u0026gt;Admin \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Manager\u0026#34;/\u0026gt;Manager \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;HR\u0026#34;/\u0026gt;HR \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Employee\u0026#34;/\u0026gt;Employee \u0026lt;input type=\u0026#34;hidden\u0026#34; th:name=\u0026#34;${_csrf.parameterName}\u0026#34; th:value=\u0026#34;${_csrf.token}\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Register\u0026#34;/\u0026gt; \u0026lt;/pre\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;div th:text=\u0026#34;${msg}\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; homePage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;welcome to the Home Page\u0026lt;/h3\u0026gt; This page is accessible to ALL. \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; welcomePage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Welcome Page after successful Login\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; adminPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Admin Page\u0026lt;/h3\u0026gt; Welcome to Admin page.!!! \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; empPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Employee Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; mgrPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Manager Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; hrPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;HR Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; commonPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;You are not allowed to access this page. Please go to Welcome Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/welcome}\u0026#34;\u0026gt;Welcome\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; accessDeniedPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;You are not allowed to access this page. Please go to Welcome Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/welcome}\u0026#34;\u0026gt;Welcome\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 步骤＃9：编写 SecurityConfig 类 最后，编写另一个重要的类 SecurityConfig.java ，它将扩展预定义的类 WebSecurityConfigurerAdapter.java 并相应地实现两个 configure() 方法，如下所示。\nSecurityConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @EnableWebSecurity @Configuration public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(uds).passwordEncoder(encoder); } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;,\u0026#34;/register\u0026#34;,\u0026#34;/saveUser\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .antMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee,Manager,Admin\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;); } } 步骤＃9A：编写 SecurityConfig 类而不使用 WebSecurityConfigurerAdapter 如前所述，从 Spring Security 5.7.0-M2 开始，WebSecurityConfigurerAdapter 已被弃用。因此，如果您使用 Spring Security 5.7.0-M2 或更高版本，请更新您的实现，如下面的代码片段所示。\nSecurityConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;,\u0026#34;/register\u0026#34;,\u0026#34;/saveUser\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .antMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee,Manager,Admin\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(uds); authenticationProvider.setPasswordEncoder(encoder); return authenticationProvider; } } 最后我们完成了编码部分。\n如何测试启用安全的应用程序？ 虽然“测试”这个词对于开发人员来说看起来很容易，但它同样重要，因为它提供了我们整体实现的结果。在测试应用程序时，您应该将 SecurityConfig 类的 configure(HttpSecurity http) 方法保留在您面前，然后按照以下步骤操作：\n启动应用程序：右键单击项目，然后选择“Run As”\u0026raquo;“Spring Boot App”。\n输入注册页面网址 http://localhost:8080/register，然后检查是否每个人都可以访问，甚至不需要登录应用程序。\n输入必填字段值并相应地单击“注册”按钮完成注册过程。\n现在输入您在注册时选择的角色特定的任何 URL。假设您输入 URL http://localhost:8080/admin，那么它应该将您重定向到内置的登录页面。\n输入凭据（电子邮件 ID 代替用户名）并登录到应用程序。它会将您重定向到默认的成功 URL，即欢迎页面。\n现在输入网址 http://localhost:8080/admin\n对其他角色也重复上述步骤。\n此外，如上所述，将代码放在您面前并随后测试每个场景。\n概括 在完成“如何使用 UserDetailsS​​ervice 在 Spring Boot 中实现安全性？”的所有理论和示例部分之后，最后，我们能够在 Spring Boot 项目中实现 Web 安全性。当然，在本文中我们介绍了实现安全功能的第三种方法。同样，我们将在接下来的文章中讨论更多安全方法，例如 REST 安全性。未来若有任何变化，我们将进行相应更新。\n如果您想了解有关 Spring Security 的更多信息，请访问 spring.io 文档。另外，欢迎在评论区提出你的意见。\n原文链接：https://javatechonline.com/how-to-implement-security-in-spring-boot-using-userdetailsservice/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/18/how-to-implement-security-in-spring-boot2-using-userdetailsservice/","summary":"继续上一篇关于实现 Spring Security 的两种不同方法的文章，在本文中，我们将学习第三种方法“如何使用 UserDetailsS​​ervice 在 Spring Boot 中实现 Security？”。经过上一篇文章后，我希望我们都非常熟悉安全性的基础知识，甚至是 Spring Boot 应用程序中的安全性基础知识。这次我们将创建一个用户注册表并将用户及其角色保存到数据库中。\n然后，根据用户角色，我们将借助预定义的 UserDetailsS​​ervice 检查身份验证和授权功能。\n如果您正在寻找“如何在 Spring Boot 3 及以上版本中使用 UserDetailsS​​ervice 在 Spring Boot 中实现安全性？”，请访问有关使用 Spring Boot 3 的 Spring Security UserDetailsS​​ervice 的单独文章。\n为了说明这一点，我们将把一些角色发挥作用，并在整个过程中围绕它们进行发挥，以使其变得清晰。此外，我们将有一些页面并限制它们仅可由某些特定角色访问。同样重要的是，我们必须创建一个小型 MVC Web 应用程序，以使注册过程向用户开放。用户在注册时将输入自己的角色。然后我们可以在其之上实现安全功能。\n让我们开始相应的主题“如何使用 UserDetailsS​​ervice 在 Spring Boot 中实现安全性？”。\n总体而言，您对这篇文章有何期望？ Spring Security 上下文中的 UserDetailsS​​ervice 概念是什么？\n实施 UserDetailsService 有什么好处？\n如何使用 UserDetailsService 在 Spring Boot 中实现安全性？\nUserDetailsService 在 Spring Security 应用程序中如何内部工作并带有流程图？\n另外，如何使用注解：@EnableWebSecurity、@Configuration、@Bean、@GetMapping、@Autowired、@Data、@Entity、@Table、@Id、@GenerateValue、@Column、@ElementCollection、@CollectionTable、@JoinColumn ， @服务\n如何使用 Spring MVC 和 Thymeleaf 开发用户注册应用程序？\n如何测试启用安全的应用程序？\n如何在没有 WebSecurityConfigurerAdapter 的情况下使用 UserDetailsService 在 Spring Boot 中实现安全性？\nUserDetailsService 是做什么的？使用它有什么好处？ UserDetailsS​​ervice 是 Spring 中 org.springframework.security.core.userdetails 包下的预定义接口。我们的实现类实现了这个接口并重写了它的 loadUserByUsername(String username) 方法。此方法返回 UserDetails，它又是一个接口。预定义的 User 类（org.springframework.security.core.userdetails.User）是 UserDetails 接口的实现。总之，在 loadUserByUsername(String username) 方法中，我们传递用户名，它返回我们预定义的 User 对象（org.","title":"[译]如何在Spring Boot2中使用UserDetailsService实现安全性？"},{"content":" 作为有关 Spring Security 的系列文章的继续，在本文中我们将学习“如何在 Spring Boot 3 中使用 UserDetailsService 实现 Spring Boot 中的安全性？”。经过前面的文章，我希望我们都非常熟悉安全性的基础知识，甚至 Spring Boot 应用程序中的安全性基础知识。 Spring Boot 3 发布后，我们将在这里实现“使用 Spring Boot 3 的 Spring Security UserDetailsService”。\n在本文中，我们将创建一个用户注册表单并将用户及其角色保存在数据库中。然后，根据用户角色，我们将借助预定义的 UserDetailsS​​ervice 检查身份验证和授权功能。\n您对整篇文章有何期望？ Spring Security 上下文中的 UserDetailsS​​ervice 概念是什么？\n实施 UserDetailsService 有什么好处？\n如何使用 Spring Boot 3 实现 Spring Security UserDetailsService？\n如何在基于 Spring 的应用程序中实现基于角色的安全性？\n此外，如何以及在哪里使用注释：@EnableWebSecurity，@Configuration，@Bean，@GetMapping，@Autowired，@Data，@Entity，@Table，@Id，@GenerateValue，@Column，@ElementCollection，@CollectionTable， @JoinColumn，@Service\n如何使用 Spring MVC 和 Thymeleaf 开发用户注册应用程序？\n如何测试启用安全的应用程序？\n如何在没有 WebSecurityConfigurerAdapter 的情况下使用 UserDetailsService 在 Spring Boot 中实现安全性？\n示例中使用的软件/技术 有时某些版本与其他版本冲突。因此，列出经过测试可以相互协作的组合。下面是经过测试的软件组合，用于使用 Spring Boot 3 开发 Spring Security UserDetailsS​​ervice。它也使实现完美无缺。\nSpring Boot 3.0.0\nJDK 17 or later\nMaven 3.8.1 3）Maven 3.8.1\nIDE – STS 4.7.1. RELEASE\nIDE – STS 4.7.1。发布\nJars Used 下面是这些示例中 maven 使用 pom.xml 自动下载的主要 jar 的列表。如果您在执行中遇到任何问题，它们可能有助于交叉验证。\nspring-boot-3.0.0.jar\nspring-boot-starter-3.0.0.jar\nspring-boot-starter-security-3.0.0.jar\nspring-core-6.0.2.jar\nspring-security-core-6.0.0.jar\nthymeleaf-spring6-3.1.0.RELEASE.jar\nUserDetailsService 是做什么的？使用它有什么好处？ UserDetailsS​​ervice 是 Spring 框架在 org.springframework.security.core.userdetails 包下提供的预定义接口。为了使用 UserDetailsS​​ervice，我们的实现类实现了这个接口并重写了它的 loadUserByUsername(String username) 方法。该方法的返回类型是 UserDetails，它又是一个接口。预定义的 User 类（org.springframework.security.core.userdetails.User）是 UserDetails 接口的实现。此外，我们在 loadUserByUsername(String username) 方法中传递用户名，它返回我们预定义的 User 对象（org.springframework.security.core.userdetails.User）。\n事实上，我们只向 UserDetailsS​​ervice 提供用户名和一些小配置。因此，我们将所有基于角色的内置安全功能作为框架的一部分实现。因此，当我们使用 UserDetailsS​​ervice 接口时，我们在实现安全性方面节省了很多精力。\n如何将 UserDetailsService 安全性合并到我们的应用程序中？ 首先，您必须有一个 Spring Boot Web 应用程序，其中您将有一个表单，即一种用户注册表单。作为 Spring MVC 结构的一部分，您将拥有一个 UserService 实现类。假设它是 UserServiceImpl.java。要记住的第二件事是，您必须将 User 对象转换为预定义的 Spring User 对象。此外，请按照以下步骤在您的应用程序中实现 UserDetailsS​​ervice。\n1) 你的用户服务类‘UserServiceImpl.java’应该实现接口 UserDetailsS​​ervice.java（由 Spring 提供）\n2) 同样重要的是，重写 UserServiceImpl 类中 UserDetailsS​​ervice 接口的 loadUserByUsername(String username) 方法。\n3) 作为实施的一部分，\n(A) 借助 UserRepository 中的用户名/电子邮件获取您的用户对象。 (B) 将你的 User 对象相应地转换为 Spring 预定义的 User 对象(org.springframework.security.core.userdetails.User)。 (C) 返回 Spring 定义的 User 对象，它是 UserDetails（方法的返回类型）的实现。\n下面的代码代表了 UserDetailsS​​ervice 的实现。但是，您将在下面的部分中看到完整的代码。\nUserServiceImpl.java\nimport java.util.Optional; import java.util.stream.Collectors; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Service; import com.dev.springboot.security.UserDetailsService.model.User; import com.dev.springboot.security.UserDetailsService.repo.UserRepository; import com.dev.springboot.security.UserDetailsService.service.IUserService; @Service public class UserServiceImpl implements IUserService, UserDetailsService{ @Autowired private UserRepository userRepo; @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public Integer saveUser(User user) { String passwd= user.getPassword(); String encodedPasswod = passwordEncoder.encode(passwd); user.setPassword(encodedPasswod); user = userRepo.save(user); return user.getId(); } @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); if(opt.isEmpty()) throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found !\u0026#34;); else { User user = opt.get(); return new org.springframework.security.core.userdetails.User( user.getEmail(), user.getPassword(), user.getRoles() .stream() .map(role-\u0026gt; new SimpleGrantedAuthority(role)) .collect(Collectors.toSet()) ); } } //Other Approach: Without Using Lambda \u0026amp; Stream API Of Java 8 /** @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); org.springframework.security.core.userdetails.User springUser=null; if(opt.isEmpty()) { throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found\u0026#34;); } User user =opt.get(); List\u0026lt;String\u0026gt; roles = user.getRoles(); Set\u0026lt;GrantedAuthority\u0026gt; ga = new HashSet\u0026lt;\u0026gt;(); for(String role:roles) { ga.add(new SimpleGrantedAuthority(role)); } springUser = new org.springframework.security.core.userdetails.User( email, user.getPassword(), ga ); return springUser; } */ } 我们如何在基于 Spring 的应用程序中实现基于角色的安全性？ 通常，在基于 Spring 的应用程序中，我们通过创建一个 java 类并在其上应用 @EnableWebSecurity 和 @Configuration 来实现基于角色的访问。 @EnableWebSecurity 在应用程序中启用 Spring Security 功能，而 @Configuration 表示该类是一个配置类。例如，下面的代码演示了基于角色的安全性的实现。\nSecurityConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;,\u0026#34;/register\u0026#34;,\u0026#34;/saveUser\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .antMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee,Manager,Admin\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(uds); authenticationProvider.setPasswordEncoder(encoder); return authenticationProvider; } } 使用 Spring Boot 3 的 Spring Security UserDetailsService 示例 为了简化使用 Spring Boot 3 的 Spring Security UserDetailsS​​ervice 的实现，让我们考虑一个用例。\nUse case Details 用例详细信息 让我们假设一个小型组织的内部门户。在组织中，我们的员工扮演着各种角色，例如管理员、人力资源、经理，当然还有员工。此外，门户还具有基于角色的页面访问权限。此外，某些页面应该可供所有角色访问，例如注册和公共信息页面，而其他页面则应仅限于各自的角色。\n不用说，该组织将有一个用户注册页面，即使没有登录，所有用户也必须可以访问该页面。现在让我们创建一个标准用户注册流程，如下所示。\n步骤#1：在 STS(Spring Tool Suite)中创建一个 Spring Boot Starter 项目 创建入门项目时，选择“Spring Security”、“Thymeleaf”、“Spring Web”、“Spring Data JPA”、“MySQL Driver”、“Lombok”和“Spring Boot DevTools”作为入门项目依赖项。即使您不知道如何创建 Spring Boot 入门项目，也请访问“如何在 Spring boot 中创建入门项目？”的内部链接。另外，如果您想了解有关 Lombok 的更多信息，请访问 Lombok 上的内部链接。\n步骤#2：更新 application.properties 文件中的数据库属性 更新 application.properties 以连接到 MySQL 数据库。请注意，我们还可以省略 driver-class-name，因为 Spring Boot 会自动从数据库 URL 中找到它，如下所示。不过，建议保留。\n#application.properties #-------------------- server properties --------------- server.port=8080 #--------------------- DB Connection ------------------ #AutoLoading of driver class since JDBC 4 #spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/testBootSecurity spring.datasource.username=root spring.datasource.password=devs #--------------------JPA-ORM Properties----------------- spring.jpa.show-sql=true spring.jpa.hibernate.ddl-auto=update #spring.jpa.database-platform=org.hibernet.dialect.MySQL8Dialect 步骤#3：创建用户实体和存储库类 现在创建 User.java 和 UserRepositoty.java 如下。请注意，从 Spring Boot 3.0.0 和 Spring Security 6.0 开始，所有以“javax”开头的导入语句都将替换为“jakarta”，如下面的代码所示。例如：“javax.persistence.Entity;”应替换为“jakarta.persistence.Entity;”。\n同样重要的是，User.java 有一个 List 类型的变量“roles”。它将在数据库中创建一个单独的表，其中包含两列 user_id 和 user_role。此外，@ElementCollection(fetch= FetchType.EAGER)表示在获取 User 对象的同时，也同时获取角色。另一方面，UserRepository 扩展了“JpaRepository”以利用内置数据库操作。\nUser.java\npackage com.dev.springboot.security.UserDetailsService.model; import java.util.List; import jakarta.persistence.CollectionTable; import jakarta.persistence.Column; import jakarta.persistence.ElementCollection; import jakarta.persistence.Entity; import jakarta.persistence.FetchType; import jakarta.persistence.GeneratedValue; import jakarta.persistence.Id; import jakarta.persistence.JoinColumn; import jakarta.persistence.Table; import lombok.Data; @Data @Entity @Table(name=\u0026#34;users\u0026#34;) public class User { @Id @GeneratedValue @Column(name=\u0026#34;user_id\u0026#34;) private Integer id; @Column(name=\u0026#34;user_name\u0026#34;) private String name; @Column(name=\u0026#34;user_passwd\u0026#34;) private String password; @Column(name=\u0026#34;user_email\u0026#34;) private String email; @ElementCollection(fetch= FetchType.EAGER) @CollectionTable( name=\u0026#34;roles\u0026#34;, joinColumns = @JoinColumn(name=\u0026#34;user_id\u0026#34;) ) @Column(name=\u0026#34;user_role\u0026#34;) private List\u0026lt;String\u0026gt; roles; } UserRepository.java\npackage com.dev.springboot.security.UserDetailsService.repo; import java.util.Optional; import org.springframework.data.jpa.repository.JpaRepository; import com.dev.springboot.security.UserDetailsService.model.User; public interface UserRepository extends JpaRepository\u0026lt;User, Integer\u0026gt; { Optional\u0026lt;User\u0026gt; findUserByEmail(String email); } 步骤#4：创建 AppConfig 类来实例化 BCryptPasswordEncoder 由于 BCryptPasswordEncoder 是一个预定义的类，因此我们需要在 AppConfig.java 中提供它的实例化代码作为配置类。此外，需要 BCryptPasswordEncoder 在其他类中对我们的密码值进行编码。\nAppConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; @Configuration public class AppConfig { @Bean public BCryptPasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } } 步骤#5：创建服务接口和服务实现类 相应地创建服务接口和服务 Impl 类作为 IUserService.java 和 UserServiceImpl.java，如下所示。事实上，UserServiceImpl.java 中 loadUserByUsername(String email) 方法的实现是整个 UserDetailsS​​ervice 中最重要的部分。\nIUserService.java\npackage com.dev.springboot.security.UserDetailsService.service; import com.dev.springboot.security.UserDetailsService.model.User; public interface IUserService { public Integer saveUser(User user); } UserServiceImpl.java\npackage com.dev.springboot.security.UserDetailsService.service.impl; import java.util.Optional; import java.util.stream.Collectors; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.stereotype.Service; import com.dev.springboot.security.UserDetailsService.model.User; import com.dev.springboot.security.UserDetailsService.repo.UserRepository; import com.dev.springboot.security.UserDetailsService.service.IUserService; @Service public class UserServiceImpl implements IUserService, UserDetailsService{ @Autowired private UserRepository userRepo; @Autowired private BCryptPasswordEncoder passwordEncoder; @Override public Integer saveUser(User user) { String passwd= user.getPassword(); String encodedPasswod = passwordEncoder.encode(passwd); user.setPassword(encodedPasswod); user = userRepo.save(user); return user.getId(); } @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); if(opt.isEmpty()) throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found !\u0026#34;); else { User user = opt.get(); return new org.springframework.security.core.userdetails.User( user.getEmail(), user.getPassword(), user.getRoles() .stream() .map(role-\u0026gt; new SimpleGrantedAuthority(role)) .collect(Collectors.toSet()) ); } } //Other Approach: Without Using Lambda \u0026amp; Stream API Of Java 8 /** @Override public UserDetails loadUserByUsername(String email) throws UsernameNotFoundException { Optional\u0026lt;User\u0026gt; opt = userRepo.findUserByEmail(email); org.springframework.security.core.userdetails.User springUser=null; if(opt.isEmpty()) { throw new UsernameNotFoundException(\u0026#34;User with email: \u0026#34; +email +\u0026#34; not found\u0026#34;); } User user =opt.get(); List\u0026lt;String\u0026gt; roles = user.getRoles(); Set\u0026lt;GrantedAuthority\u0026gt; ga = new HashSet\u0026lt;\u0026gt;(); for(String role:roles) { ga.add(new SimpleGrantedAuthority(role)); } springUser = new org.springframework.security.core.userdetails.User( email, user.getPassword(), ga ); return springUser; } */ } 步骤#6：创建一个 UserController 类 随后，为用户编写一个控制器类“UserController.java”，它将控制用户注册页面。\nUserController.java\npackage com.dev.springboot.security.UserDetailsService.controller; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.ui.Model; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.ModelAttribute; import org.springframework.web.bind.annotation.PostMapping; import com.dev.springboot.security.UserDetailsService.model.User; import com.dev.springboot.security.UserDetailsService.service.IUserService; @Controller public class UserController { @Autowired private IUserService userService; // Go to Registration Page @GetMapping(\u0026#34;/register\u0026#34;) public String register() { return \u0026#34;registerUser\u0026#34;; } // Read Form data to save into DB @PostMapping(\u0026#34;/saveUser\u0026#34;) public String saveUser( @ModelAttribute User user, Model model ) { Integer id = userService.saveUser(user); String message = \u0026#34;User \u0026#39;\u0026#34;+id+\u0026#34;\u0026#39; saved successfully !\u0026#34;; model.addAttribute(\u0026#34;msg\u0026#34;, message); return \u0026#34;registerUser\u0026#34;; } } 步骤#7：编写一个控制器类来浏览页面 除了 UserController，再编写一个控制器类并将其命名为“HomeController.java”。该类将负责浏览不同的页面。\nHomeController.java\npackage com.dev.springboot.security.UserDetailsService.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class HomeController { @GetMapping(\u0026#34;/home\u0026#34;) public String getHomePage() { return \u0026#34;homePage\u0026#34;; } @GetMapping(\u0026#34;/welcome\u0026#34;) public String getWelcomePage() { return \u0026#34;welcomePage\u0026#34;; } @GetMapping(\u0026#34;/admin\u0026#34;) public String getAdminPage() { return \u0026#34;adminPage\u0026#34;; } @GetMapping(\u0026#34;/emp\u0026#34;) public String getEmployeePage() { return \u0026#34;empPage\u0026#34;; } @GetMapping(\u0026#34;/mgr\u0026#34;) public String getManagerPage() { return \u0026#34;mgrPage\u0026#34;; } @GetMapping(\u0026#34;/hr\u0026#34;) public String getHrPage() { return \u0026#34;hrPage\u0026#34;; } @GetMapping(\u0026#34;/common\u0026#34;) public String getCommonPage() { return \u0026#34;commonPage\u0026#34;; } @GetMapping(\u0026#34;/accessDenied\u0026#34;) public String getAccessDeniedPage() { return \u0026#34;accessDeniedPage\u0026#34;; } } 步骤#8：编写 UI 页面(Thymeleaf) 以下是 UI 页面的 .html 文件。将这些页面相应地放入“src/main/resources/templates”文件夹中。\nregisterUser.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;User Registration\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;User Registration\u0026lt;/h3\u0026gt; \u0026lt;form action=\u0026#34;saveUser\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;pre\u0026gt; Name : \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34;/\u0026gt; Email: \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;email\u0026#34;/\u0026gt; Password: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34;/\u0026gt; Role(s): \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Admin\u0026#34;/\u0026gt;Admin \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Manager\u0026#34;/\u0026gt;Manager \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;HR\u0026#34;/\u0026gt;HR \u0026lt;input type=\u0026#34;checkbox\u0026#34; name=\u0026#34;roles\u0026#34; value=\u0026#34;Employee\u0026#34;/\u0026gt;Employee \u0026lt;input type=\u0026#34;hidden\u0026#34; th:name=\u0026#34;${_csrf.parameterName}\u0026#34; th:value=\u0026#34;${_csrf.token}\u0026#34;/\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Register\u0026#34;/\u0026gt; \u0026lt;/pre\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;div th:text=\u0026#34;${msg}\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; homePage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;welcome to the Home Page\u0026lt;/h3\u0026gt; This page is accessible to ALL. \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; welcomePage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Welcome Page after successful Login\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; adminPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Admin Page\u0026lt;/h3\u0026gt; Welcome to Admin page.!!! \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; empPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Employee Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; mgrPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Manager Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; hrPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;HR Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; commonPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;You are not allowed to access this page. Please go to Welcome Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/welcome}\u0026#34;\u0026gt;Welcome\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; accessDeniedPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;You are not allowed to access this page. Please go to Welcome Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/welcome}\u0026#34;\u0026gt;Welcome\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 步骤＃9：编写 SecurityConfig 类而不使用 WebSecurityConfigurerAdapter 最后，编写另一个重要的类 SecurityConfig.java。在 Spring Security 5.7.0-M2 之前，此类应该扩展预定义的类 WebSecurityConfigurerAdapter.java 并相应地实现两个 configure() 方法。但从 Spring Security 5.7.0-M2 开始，WebSecurityConfigurerAdapter 已被弃用。此外，从 Spring Boot 3.0.0 和 Spring Security 6.0 开始，WebSecurityConfigurerAdapter 已从 Spring Security API 中完全删除。\n因此，所需的实现自 Spring 3.0.0 起就适用，如下面的代码片段所示。\nSecurityConfig.java\npackage com.dev.springboot.security.UserDetailsService.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.dao.DaoAuthenticationProvider; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @EnableWebSecurity @Configuration public class SecurityConfig { @Autowired private UserDetailsService uds; @Autowired private BCryptPasswordEncoder encoder; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests() .requestMatchers(\u0026#34;/home\u0026#34;,\u0026#34;/register\u0026#34;,\u0026#34;/saveUser\u0026#34;).permitAll() .requestMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .requestMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;Admin\u0026#34;) .requestMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;Manager\u0026#34;) .requestMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;Employee\u0026#34;) .requestMatchers(\u0026#34;/hr\u0026#34;).hasAuthority(\u0026#34;HR\u0026#34;) .requestMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;Employeee\u0026#34;, \u0026#34;Manager\u0026#34;, \u0026#34;Admin\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) .and() .authenticationProvider(authenticationProvider()); return http.build(); } @Bean public AuthenticationProvider authenticationProvider() { DaoAuthenticationProvider authenticationProvider = new DaoAuthenticationProvider(); authenticationProvider.setUserDetailsService(uds); authenticationProvider.setPasswordEncoder(encoder); return authenticationProvider; } } 从上面的 SecurityConfig 实现中可以明显看出，旧版本中的一些方法也被删除了。例如：\nauthorizeRequests() -\u0026gt; authorizeHttpRequests()\nantMatchers() -\u0026gt; requestMatchers()\nregexMatchers() -\u0026gt; RegexRequestMatchers()\n最后，我们完成了编码部分。\n如何测试启用安全性的应用程序？ 虽然“测试”这个词对于开发人员来说看起来很容易，但它同样重要，因为它提供了我们整体实现的结果。在测试应用程序时，您应该将 SecurityConfig 类的 configure(HttpSecurity http) 方法保留在您面前，然后按照以下步骤操作：\n启动应用程序：右键单击项目，然后选择“Run As”\u0026raquo;“Spring Boot App”。\n输入注册页面 URL http://localhost:8080/register，然后检查是否每个人都可以访问，甚至不需要登录应用程序。\n输入必填字段值并相应地单击“注册”按钮完成注册过程。\n现在输入您在注册时选择的角色特定的任何 URL。假设您输入 URL http://localhost:8080/admin，那么它应该将您重定向到内置的登录页面。\n输入凭据并登录到应用程序。它会将您重定向到默认的成功 URL，即欢迎页面。\n现在再次输入 URL http://localhost:8080/admin，这次您将能够访问管理页面。\n对其他角色也重复上述步骤。\n此外，如上所述，将 SecurityConfig.java 代码保留在您面前，并随后测试每个场景。\n如何使用 Spring Boot 3 将以前的实现迁移到 Spring Security UserDetailsService？ 以下是一些分步指南，您可以按照这些指南从旧版本实现迁移到使用 Spring Boot 3 的 Spring Security UserDetailsS​​ervice。\n根据推荐 Spring 官方文档，如果使用较低版本实现，请先将实现升级到 Spring Boot 2.7.0。我们可以通过更新 pom.xml 中的 Spring Boot 版本来做到这一点，如下所示。 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; 更新后，保存 pom.xml 并让 Maven 下载新的依赖项。\n对于此示例，您将发现 WebSecurityConfigurerAdapter 已被弃用。提供新的实现，而不使用 WebSecurityConfigurerAdapter。您可以使用本文中的 SecurityConfig.java 实现。如果还有其他错误，也请修复它们。\n下一步，按照 Spring Boot 官方文档的建议在项目中配置 JDK 17 环境。\n在 pom.xml 中将 Spring Boot 版本更新为“3.0.0”，保存文件并让 maven 下载新的依赖项。\n修复编译错误，如下图：\n(A) I 在 SecurityConfig.java 中：\n将 authorizeRequests() 替换为 authorizeHttpRequests()\n将 antMatchers() 替换为 requestMatchers()\n将 regexMatchers() 替换为 RegexRequestMatchers()\n(B) 在实体类中：\n将所有出现的“javax”替换为“jakarta”。例如：“javax.persistence.Entity;”应替换为“jakarta.persistence.Entity;”。\n故障排除 将 Spring Boot 版本升级到 3.0.0 时，您可能会遇到以下错误：\n[ERROR] Some problems were encountered while processing the POMs: [ERROR] \u0026#39;dependencies.dependency.version\u0026#39; for org.thymeleaf.extras:thymeleaf-extras-springsecurity5:jar is missing. 为了解决此错误，请更新 Thymeleaf 的版本，如下所示。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.thymeleaf.extras\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;thymeleaf-extras-springsecurity5\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 更新完成后，maven 会自动下载合适的依赖项。\n概括 在完成“使用 Spring Boot 3 的 Spring Security UserDetailsS​​ervice”的所有理论和示例部分之后，最后，我们应该能够在 Spring Boot 项目中实现基于角色的 Web 安全性。当然，在本文中我们介绍了实现安全功能的第三种方法。同样，我们将在接下来的文章中讨论更多安全方法。未来若有任何变化，我们将进行相应更新。\n如果您想了解 Spring Boot 3.0 中的新增功能，请访问我们关于“Spring Boot 3 中的新功能”的单独文章。另外，欢迎在评论区提出你的意见。\n原文链接：https://javatechonline.com/spring-security-userdetailsservice-using-spring-boot-3/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/18/how-to-implement-security-in-spring-boot3-using-userdetailsservice/","summary":"作为有关 Spring Security 的系列文章的继续，在本文中我们将学习“如何在 Spring Boot 3 中使用 UserDetailsService 实现 Spring Boot 中的安全性？”。经过前面的文章，我希望我们都非常熟悉安全性的基础知识，甚至 Spring Boot 应用程序中的安全性基础知识。 Spring Boot 3 发布后，我们将在这里实现“使用 Spring Boot 3 的 Spring Security UserDetailsService”。\n在本文中，我们将创建一个用户注册表单并将用户及其角色保存在数据库中。然后，根据用户角色，我们将借助预定义的 UserDetailsS​​ervice 检查身份验证和授权功能。\n您对整篇文章有何期望？ Spring Security 上下文中的 UserDetailsS​​ervice 概念是什么？\n实施 UserDetailsService 有什么好处？\n如何使用 Spring Boot 3 实现 Spring Security UserDetailsService？\n如何在基于 Spring 的应用程序中实现基于角色的安全性？\n此外，如何以及在哪里使用注释：@EnableWebSecurity，@Configuration，@Bean，@GetMapping，@Autowired，@Data，@Entity，@Table，@Id，@GenerateValue，@Column，@ElementCollection，@CollectionTable， @JoinColumn，@Service\n如何使用 Spring MVC 和 Thymeleaf 开发用户注册应用程序？\n如何测试启用安全的应用程序？\n如何在没有 WebSecurityConfigurerAdapter 的情况下使用 UserDetailsService 在 Spring Boot 中实现安全性？\n示例中使用的软件/技术 有时某些版本与其他版本冲突。因此，列出经过测试可以相互协作的组合。下面是经过测试的软件组合，用于使用 Spring Boot 3 开发 Spring Security UserDetailsS​​ervice。它也使实现完美无缺。\nSpring Boot 3.0.0\nJDK 17 or later\nMaven 3.8.1 3）Maven 3.8.1\nIDE – STS 4.7.1. RELEASE\nIDE – STS 4.7.1。发布\nJars Used 下面是这些示例中 maven 使用 pom.","title":"[译]如何在Spring Boot3中使用UserDetailsService实现安全性？"},{"content":" 如今，几乎每个客户都要求在实时应用程序中实现强大的安全功能。安全功能对于保持机密性、完整性和可用性的需求是非常有效的。现实世界中有很多类型的安全性，但我们作为开发人员将重点关注应用程序/软件安全性。\n此外，在应用程序安全方面，我们的工作基本上是确保两件事。首先，只有有效的用户才能访问该应用程序。其次，如果用户有效，他/她只能访问该应用程序中允许的数据/信息。我认为，没有什么可以解释它们，因为您必须已经了解这两个术语，即身份验证和授权。\n您可能已经猜到我们将在当前主题“如何在 Spring Boot 项目中实现安全性？”中讨论什么内容。\n在本文中，我们将从基本原理开始学习。接下来，我们将逐步结束它，直到我们有信心在 Spring Boot 应用程序中实现安全功能。因此，让我们开始逐步讨论“如何在 Spring Boot 项目中实现安全性？”。 Spring Boot 教程页面上有一系列有关 Spring Boot Security 的教程。\n我们在本文中介绍了两个版本的“如何在 Spring Boot 项目中实现安全性？”的示例：使用 WebSecurityConfigurerAdapter 和不使用 WebSecurityConfigurerAdapter。此外，还涵盖了使用 Spring Boot 3.0 及更高版本的“如何在 Spring Boot 项目中实现安全性？”的示例。\n您将从本文中学到什么？ 为什么我们需要在 Spring Boot 应用程序中实现安全性？\nSecurity 在 Spring Boot 应用程序内部如何工作？\njavax.servlet.Filter 在 Spring Boot 应用程序中实现安全性方面的作用是什么？\nSpring Boot 项目中使用了多少种授权类型？\nSpring Boot 项目中有多少种实现安全性的方法？\n在 Spring Boot 项目中实现 WebSecurity 的步骤是什么？\n另外，如何在 Spring Boot 项目中使用@EnableWebSecurity、@Configuration、@Bean？\n如何实现内存中身份验证安全示例\n如何实现 JDBC 认证安全示例\n如何在 Spring Boot 项目中使用 Thymeleaf ？\n如何测试启用安全的功能？\n相反，如何禁用应用程序的安全功能？\n最后但并非最不重要的一点是，您将学习“如何在 Spring Boot 项目中实现安全性？”使用 WebSecurityConfigurerAdapter 和不使用 WebSecurityConfigurerAdapter。\n为什么我们需要应用程序中的安全性？ 现在，随着恶意攻击将重点从操作系统和网络转移到应用程序/软件和移动设备/设备，一天的数据面临最大的风险。此外，从业务/客户的角度来看，应用程序安全在维护信任、建立品牌形象和降低风险方面发挥着重要作用。事实上，没有其中任何一项，都无法想象一家成功的企业。\n总之，无论您是为了内部使用、销售目的还是购买目的而创建应用程序，安全性都是每个应用程序最重要的功能。\n根据最新的 2020 年 Verizon 数据泄露调查报告，所有数据泄露中有 43% 是针对 Web 应用程序的攻击。这一数字比 2019 年增加了一倍。此外，86% 的违规行为都是出于经济动机。\nSpring Boot 应用程序内部安全性如何工作？ 从根本上来说，Spring Security 的工作原理是 JAAS（Java 身份验证和授权服务）。简而言之，它适用于 Filter (javax.servlet.Filter) 概念。我们都知道，如果我们想在 servlet 请求之前应用一些预处理逻辑，可以使用过滤器。同样的概念也被应用于在 Spring boot 项目中实现安全功能。\nDelegatingFilterProxy 是 Spring Security 模块提供的 org.springframework.web.filter 包下的预定义类，在这里充当过滤器。\n如下图所示，当用户向应用程序发送请求时，请求会先经过安全过滤器，然后再发送给 DispatcherServlet。如果用户验证此过滤器的安全性，则只有请求才会发送到 DispatcherServlet 来满足用户的目的。\nSpring Boot 应用程序使用了多少种授权类型？ 有四种最常用的授权实现类型。他们是 ：\n1) permitAll 允许全部 PermitAll 表示无需任何授权即可访问当前页面。\n示例 URL：/login、/home、/contactUs、/aboutUs ..等。\n2) authenticated 已认证 它表示需要登录（用户名/密码）并且不需要授权（基于角色的访问）。\n示例 URL：/updateUserDetails、/inbox、/settings 等。\n3) hasAuthority hasAuthority 表示用户应该具有身份验证和基于角色的授权访问权限。\n示例 URL+role：/approveRequest + MANAGER、/blockUser + ADMIN、/addUser + ADMIN …等。\n4) hasAnyAuthority 有任何权限 它表示用户应该具有身份验证和基于多个角色的授权访问。就像经理和人力资源这两个角色都可以访问特定页面。 示例 URLs+role: /approveRequest + (MANAGER \u0026amp; HR)\n在 Spring Boot Web 应用程序中实现安全性有哪些不同的方法？ 简而言之，在 Spring Boot Web 应用程序中实现安全性有三种最常见的方法。他们是\nIn-Memory Security 内存安全 在这种类型的实现中，我们将数据存储在 RAM（内存中）中，并在有请求时验证数据。我们在测试或开发环境中使用这种方法。在生产应用中不建议使用此方法。\n使用数据库(JDBC) 在这种类型的实现中，我们将数据存储在数据库中，并在请求到来时验证数据/登录。但它是基于程序员提供的 SQL 查询来工作的。\nUsing UserDetailsService 使用用户详细信息服务 我们将数据存储在数据库中，并在请求到来时验证数据。但 UserDetailsS​​ervice 是基于 ORM（Spring Data JPA）工作的。简而言之，UserDetailsS​​ervice 是 Spring Security 模块提供的一个接口。在登录表单中输入用户名后，当我们单击登录按钮时，将调用该服务。随后，它根据提供的用户名找到用户。它包含一个方法 loadUserByUsername(String username) 返回 UserDetails 对象。此外，UserDetails 对象为我们提供了用户名。\n在 Spring Boot 应用程序中实现 Web 安全的步骤是什么？ 以下是步骤：\n编写一个类“SecurityConfig.java”，它扩展了预定义的抽象类 WebSecurityConfigurerAdapter.java\n在“SecurityConfig.java”之上相应地应用注释@Configuration 和@EnableWebSecurity。不用说，注释@EnableWebSecurity 是为了在 Web 应用程序中启用安全功能。\n覆盖下面两种方法同时实现身份验证和授权逻辑。\nconfigure(AuthenticationManagerBuilder auth) configure(HttpSecurity http) 此外，通过使用@Autowired（如 DataSource、BCryptPasswordEncoder 等）注入其他对象依赖项（如果有），并在需要的地方使用它们。\n同样重要的是，根据需要编写控制器类和视图页面。\n最后，如果您不实施内存中身份验证，请更新 application.properties 文件中的数据库属性。\n注意：从 Spring Security 5.7.0-M2 开始，WebSecurityConfigurerAdapter 已被弃用。为了了解实现自定义配置类的新方法，请访问有关不使用 WebSecurityConfigurerAdapter 的 Spring Security 的单独文章。\n如何实现内存中身份验证安全性的示例 例如，让我们考虑一个小型组织的应用程序，其中我们有三个角色：员工、经理和管理员。此外，我们将对某些特定页面进行基于角色的限制访问。一方面，某些页面可供多个角色访问，另一方面，某些页面没有限制（所有角色均可访问）。此外，我们将使用 thymeleaf 来创建页面。此外，我们将有一个控制器类来满足用户的请求。\nSoftware/Technologies Used 使用的软件/技术 STS (Spring Tool Suite) : Version-\u0026gt; 4.7.1.RELEASE JDK14 (JDK8 or later versions are sufficient) 步骤#1：在 STS(Spring Tool Suite)中创建一个 Spring Boot Starter 项目 创建入门项目时，选择“Spring Security”、“Thymeleaf”、“Spring Web”和“Spring Boot DevTools”作为入门项目依赖项。要了解“如何创建 Spring Boot Starter 项目？”，请访问内部链接。\n步骤#2：编写控制器类 请检查以下代码作为控制器类。\nHomeController.java\npackage com.dev.springboot.security.controller; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class HomeController { @GetMapping(\u0026#34;/home\u0026#34;) public String getHomePage() { return \u0026#34;homePage\u0026#34;; } @GetMapping(\u0026#34;/welcome\u0026#34;) public String getWelcomePage() { return \u0026#34;welcomePage\u0026#34;; } @GetMapping(\u0026#34;/admin\u0026#34;) public String getAdminPage() { return \u0026#34;adminPage\u0026#34;; } @GetMapping(\u0026#34;/emp\u0026#34;) public String getEmployeePage() { return \u0026#34;empPage\u0026#34;; } @GetMapping(\u0026#34;/mgr\u0026#34;) public String getManagerPage() { return \u0026#34;mgrPage\u0026#34;; } @GetMapping(\u0026#34;/common\u0026#34;) public String getCommonPage() { return \u0026#34;commonPage\u0026#34;; } @GetMapping(\u0026#34;/accessDenied\u0026#34;) public String getAccessDeniedPage() { return \u0026#34;accessDeniedPage\u0026#34;; } } 步骤#3：编写 UI 页面 (Thymeleaf) 以下文件是 UI 页面。因此，仅将它们放在“src/main/resources/templates”文件夹中。\nhomepage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;welcome to Home Page\u0026lt;/h3\u0026gt; This page is accessible to ALL. \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; welcomePage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Welcome Page after successful Login\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; adminPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Admin Page\u0026lt;/h3\u0026gt; Only Admins are allowed to access this page.!!! \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; empPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Employee Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; mgrPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;Manager Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; commonPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;COMMON Page\u0026lt;/h3\u0026gt; Both Manager \u0026amp; Employee are allowed to access this page. ! \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; accessDeniedPage.html\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns:th=\u0026#34;http://www.thymeleaf.org\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h3\u0026gt;You are not allowed to access this page. Please go to Welcome Page\u0026lt;/h3\u0026gt; \u0026lt;a th:href=\u0026#34;@{/welcome}\u0026#34;\u0026gt;Welcome\u0026lt;/a\u0026gt; \u0026lt;a th:href=\u0026#34;@{/logout}\u0026#34;\u0026gt;LOGOUT\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 步骤#4：编写 SecurityConfig 类 此类对于实现包含所有安全相关逻辑的安全功能而言是最重要的。如下面的代码示例所示，如果我们不想对密码进行编码，我们可以在密码值之前使用“{noop}”。\n步骤#4A：Spring Security 5.7.0 以下版本的代码 SecurityConfig.java\npackage com.dev.springboot.security; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { // {noop} =\u0026gt; No operation for password encoder\t(no password encoding needed) auth.inMemoryAuthentication().withUser(\u0026#34;devs\u0026#34;).password(\u0026#34;{noop}devs\u0026#34;).authorities(\u0026#34;ADMIN\u0026#34;); auth.inMemoryAuthentication().withUser(\u0026#34;ns\u0026#34;).password(\u0026#34;{noop}ns\u0026#34;).authorities(\u0026#34;EMPLOYEE\u0026#34;); auth.inMemoryAuthentication().withUser(\u0026#34;vs\u0026#34;).password(\u0026#34;{noop}vs\u0026#34;).authorities(\u0026#34;MANAGER\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { //declares which Page(URL) will have What access type http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;EMPLOYEE\u0026#34;,\u0026#34;MANAGER\u0026#34;) // Any other URLs which are not configured in above antMatchers // generally declared aunthenticated() in real time .anyRequest().authenticated() //Login Form Details .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true) //Logout Form Details .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) //Exception Details .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; } } 步骤#4B：Spring Security 5.7 以上版本和 Spring Security 6.0 以下版本的代码 由于根据 Spring 官网发布的公告，WebSecurityConfigurerAdapter 已从 Spring Security 5.7.0-M2 中弃用，因此，2022 年 2 月 21 日，我们将不使用 WebSecurityConfigurerAdapter 来编写 SecurityConfig 类，如下所示：\nSecurityConfig.java\npackage com.dev.springboot.security; import java.util.ArrayList; import java.util.List; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig { @Bean protected InMemoryUserDetailsManager configAuthentication() { List\u0026lt;UserDetails\u0026gt; users = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;GrantedAuthority\u0026gt; adminAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;ADMIN\u0026#34;)); UserDetails admin= new User(\u0026#34;devs\u0026#34;, \u0026#34;{noop}devs\u0026#34;, adminAuthority); users.add(admin); List\u0026lt;GrantedAuthority\u0026gt; employeeAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;EMPLOYEE\u0026#34;)); UserDetails employee= new User(\u0026#34;ns\u0026#34;, \u0026#34;{noop}ns\u0026#34;, employeeAuthority); users.add(employee); List\u0026lt;GrantedAuthority\u0026gt; managerAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;MANAGER\u0026#34;)); UserDetails manager= new User(\u0026#34;vs\u0026#34;, \u0026#34;{noop}vs\u0026#34;, managerAuthority); users.add(manager); return new InMemoryUserDetailsManager(users); } @Bean protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { //declares which Page(URL) will have What access type http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .antMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;EMPLOYEE\u0026#34;,\u0026#34;MANAGER\u0026#34;) // Any other URLs which are not configured in above antMatchers // generally declared aunthenticated() in real time .anyRequest().authenticated() //Login Form Details .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true) //Logout Form Details .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) //Exception Details .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; return http.build(); } } 步骤#4C：Spring Security 6.0.0 及更高版本的代码（Spring Boot 3.0+） 从 Spring Security 6.0（2022 年 11 月发布）开始，WebSecurityConfigurerAdapter 已从 Spring Security API 中完全删除。它还影响了 2022 年 11 月新发布的 Spring Boot 3.0。因此，如果您使用 Spring Framework 6.0+ 或 Spring Boot 3.0+，无论哪种情况，SecurityConfig.java 的实现应如下所示。此外，您还可以检查Spring Framework 6.0 中与 Spring Security 相关的更改。\nSecurityConfig.java\npackage com.dev.springboot.security; import java.util.ArrayList; import java.util.List; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.authority.SimpleGrantedAuthority; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig { @Bean protected InMemoryUserDetailsManager configAuthentication() { List\u0026lt;UserDetails\u0026gt; users = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;GrantedAuthority\u0026gt; adminAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;ADMIN\u0026#34;)); UserDetails admin= new User(\u0026#34;devs\u0026#34;, \u0026#34;{noop}devs\u0026#34;, adminAuthority); users.add(admin); List\u0026lt;GrantedAuthority\u0026gt; employeeAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;EMPLOYEE\u0026#34;)); UserDetails employee= new User(\u0026#34;ns\u0026#34;, \u0026#34;{noop}ns\u0026#34;, employeeAuthority); users.add(employee); List\u0026lt;GrantedAuthority\u0026gt; managerAuthority = new ArrayList\u0026lt;\u0026gt;(); adminAuthority.add(new SimpleGrantedAuthority(\u0026#34;MANAGER\u0026#34;)); UserDetails manager= new User(\u0026#34;vs\u0026#34;, \u0026#34;{noop}vs\u0026#34;, managerAuthority); users.add(manager); return new InMemoryUserDetailsManager(users); } @Bean protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { //declares which Page(URL) will have What access type http.authorizeHttpRequests() .requestMatchers(\u0026#34;/home\u0026#34;).permitAll() .requestMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .requestMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .requestMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .requestMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .requestMatchers(\u0026#34;/common\u0026#34;).hasAnyAuthority(\u0026#34;EMPLOYEE\u0026#34;,\u0026#34;MANAGER\u0026#34;) // Any other URLs which are not configured in above antMatchers // generally declared aunthenticated() in real time .anyRequest().authenticated() //Login Form Details .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;, true) //Logout Form Details .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) //Exception Details .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; return http.build(); } } 注意：在上面的代码中，观察 Spring Security 6.0 中的 API 变化：antMatchers()被 requestMatchers()替换，authorizeRequests()被 authorizeHttpRequests()替换。\n您的项目结构将如下图所示。\n如何实现 JDBC 身份验证安全性示例 在这种身份验证方法中，我们根据数据库中的现有值验证凭据和角色。此外，在此示例中，我们还将研究密码加密逻辑。首先，我们将在数据库中插入一些虚拟数据，然后相应地测试安全功能。归根结底，如果我们比较前面示例的功能，我们将把用户凭据和角色保存到数据库而不是 RAM 中。\n此外，在此示例中，我们将提供用于实现密码加密逻辑的附加代码。因此，上一个示例中的所有文件在此示例中也将有效。\n此外，我们将有一个配置类来创建 BCryptPasswordEncoder 对象来对密码进行编码，并在 application.properties 中创建数据库属性条目以连接数据库。不用说，SecurityConfig 类的实现这次会有所不同。\n使用的软件/技术 STS (Spring Tool Suite) : Version-\u0026gt; 4.7.1.RELEASE MySQL Database : Version -\u0026gt;8.0.19 MySQL Community Server JDK14 (JDK8 or later versions are sufficient) 步骤#1：在数据库中插入一些虚拟记录 请注意，此步骤仅用于测试目的。如果您最近已经使用用户凭据和角色映射创建了数据库，请忽略此步骤。在步骤#1A 中，我们将创建一些密码编码值，然后在步骤#1B 中将它们插入到数据库中。\n步骤#1A：使用 BCryptPasswordEncoder 创建编码密码值 我们将使用 BCryptPasswordEncoder 生成一些编码密码值，如下所示\nBCryptPasswordEncoderTest.java\npackage com.dev.springboot.security.util; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; public class BCryptPasswordEncoderTest { public static void main(String[] args) { BCryptPasswordEncoder bpe = new BCryptPasswordEncoder(); String encodedPWD = bpe.encode(\u0026#34;devs@A!5003\u0026#34;); System.out.println(encodedPWD); } } 输出\n$2a$10$qnOB2PH1CqRvw8f5epvHzOlrounRkVGi.Y5ho6ENdmj/C1DmPdAsy 步骤#1B：创建数据库并插入虚拟记录 执行 MySQL DB 命令如下：\nTo create the database as \u0026#39;testbootsecurity\u0026#39; ♦ create database testbootsecurity; To take \u0026#39;testbootsecurity\u0026#39; in use: ♦ use testbootsecurity; To create the user table: ♦ create table user (user_id int, user_name varchar(30), user_pwd varchar(100), user_role varchar(20), user_enabled int); To check the description of user table: ♦ desc user; INSERT INTO user values(501,\u0026#39;devs\u0026#39;,\u0026#39;$2a$10$qnOB2PH1CqRvw8f5epvHzOlrounRkVGi.Y5ho6ENdmj/C1DmPdAsy\u0026#39;,\u0026#39;ADMIN\u0026#39;,1); INSERT INTO user values(502,\u0026#39;ns\u0026#39;,\u0026#39;$2a$10$mmUMC5ZwoVnEQYV7/R6m.uWWtj7EiIo3lKasBObkOCc12huVUWpMC\u0026#39;,\u0026#39;EMPLOYEE\u0026#39;,1); INSERT INTO user values(503,\u0026#39;vs\u0026#39;,\u0026#39;$2a$10$kqEC/fhQ7SNDhnncOQ9pb.yXXxJ/c7a1SQx2QPNZ.47fUmvF3Wb.i\u0026#39;,\u0026#39;MANAGER\u0026#39;,1); ♦ select * from user; (To check if values are inserted into DB) 此外，在实现 SecurityConfig.java 类的 configure(AuthenticationManagerBuilder auth) 方法时，我们将需要以下两个查询。\nQuery#1 : Retrieve username,password,enabled using username ; ♦ select user_name,user_pwd,user_enabled from user where user_name=?; Query#2 : Retrieve username,role using username; ♦ select user_name,user_role from user where user_name=?; 步骤#2：在 STS(Spring Tool Suite)中创建一个 Spring Boot Starter 项目 创建入门项目时，选择“Spring Security”、“Thymeleaf”、“Spring Web”、“JDBC API”、“MySQL Driver”和“Spring Boot DevTools”作为入门项目依赖项。\n步骤#3：从上一个示例复制控制器类和 UI 页面 复制 HomeController.java 以及前面示例中的所有 thymeleaf 页面。\n步骤#4：创建 AppConfig.java 以创建 BCryptPasswordEncoder 对象 如下创建 AppConfig.java。在实现 SecurityConfig.java 类时，我们将需要 BCryptPasswordEncoder 对象。\nAppConfig.java\npackage com.dev.springboot.security.jdbc.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; @Configuration public class AppConfig { @Bean public BCryptPasswordEncoder encode() { return new BCryptPasswordEncoder(); } } 步骤#5：更新 application.properties 文件中的数据库属性 更新 application.properties 以连接到 MySQL DB，如下所示。请注意，我们可以省略 driver-class-name，因为 Spring Boot 会自动从数据库 URL 中找到它。\n#application.properties ------------------------------------------------------------------- spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver spring.datasource.url=jdbc:mysql://localhost:3306/testBootSecurity spring.datasource.username=root spring.datasource.password=devs 步骤#6：更新 SecurityConfig.java 从前面的示例中复制 SecurityConfig.java 并更新 configure( AuthenticationManagerBuilder auth) 方法，如下所示。\n步骤#6A：Spring Security 5.7.0 以下版本的代码 SecurityConfig.java\npackage com.dev.springboot.security.jdbc.config; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private DataSource dataSource; @Autowired private BCryptPasswordEncoder passwordEncoder; @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.jdbcAuthentication() .dataSource(dataSource) //creates database connection .usersByUsernameQuery(\u0026#34;select user_name,user_pwd,user_enabled from user where user_name=?\u0026#34;) .authoritiesByUsernameQuery(\u0026#34;select user_name,user_role from user where user_name=?\u0026#34;) .passwordEncoder(passwordEncoder); } @Override public void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; } } 步骤#6B：Spring Security 5.7.0 以上版本和 Spring Security 6.0.0 以下版本的代码 由于根据 Spring 官网发布的公告，WebSecurityConfigurerAdapter 已从 Spring Security 5.7.0-M2 中弃用，因此，2022 年 2 月 21 日，我们将不使用 WebSecurityConfigurerAdapter 来编写 SecurityConfig 类，如下所示：\nSecurityConfig.java\npackage com.dev.springboot.security.jdbc.config; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.factory.PasswordEncoderFactories; import org.springframework.security.provisioning.JdbcUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig { @Autowired private DataSource dataSource; @Autowired private BCryptPasswordEncoder passwordEncoder; @Bean public UserDetailsManager authenticateUsers() { UserDetails user = User.withUsername(\u0026#34;devs\u0026#34;). password(PasswordEncoderFactories.createDelegatingPasswordEncoder().encode(\u0026#34;password\u0026#34;)).build(); JdbcUserDetailsManager users = new JdbcUserDetailsManager(dataSource); users.setAuthoritiesByUsernameQuery(\u0026#34;select user_name,user_pwd,user_enabled from user where user_name=?\u0026#34;); users.setUsersByUsernameQuery(\u0026#34;select user_name,user_role from user where user_name=?\u0026#34;); users.createUser(user); return users; } @Bean protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(\u0026#34;/home\u0026#34;).permitAll() .antMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .antMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .antMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; return http.build(); } } 步骤#6C：Spring Security 6.0.0 及更高版本的代码（Spring Boot 3.0+） 从 Spring Security 6.0（2022 年 11 月发布）开始，WebSecurityConfigurerAdapter 已从 Spring Security API 中完全删除。它还影响了 2022 年 11 月新发布的 Spring Boot 3.0。因此，如果您使用 Spring Framework 6.0+ 或 Spring Boot 3.0+，无论哪种情况，SecurityConfig.java 的实现应如下所示。此外，您还可以检查 Spring Framework 6.0 中与 Spring Security 相关的更改。\nSecurityConfig.java\npackage com.dev.springboot.security.jdbc.config; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.factory.PasswordEncoderFactories; import org.springframework.security.provisioning.JdbcUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; import org.springframework.security.web.SecurityFilterChain; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; @Configuration @EnableWebSecurity public class SecurityConfig { @Autowired private DataSource dataSource; @Autowired private BCryptPasswordEncoder passwordEncoder; @Bean public UserDetailsManager authenticateUsers() { UserDetails user = User.withUsername(\u0026#34;devs\u0026#34;). password(PasswordEncoderFactories.createDelegatingPasswordEncoder().encode(\u0026#34;password\u0026#34;)).build(); JdbcUserDetailsManager users = new JdbcUserDetailsManager(dataSource); users.setAuthoritiesByUsernameQuery(\u0026#34;select user_name,user_pwd,user_enabled from user where user_name=?\u0026#34;); users.setUsersByUsernameQuery(\u0026#34;select user_name,user_role from user where user_name=?\u0026#34;); users.createUser(user); return users; } @Bean protected SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests() .requestMatchers(\u0026#34;/home\u0026#34;).permitAll() .requestMatchers(\u0026#34;/welcome\u0026#34;).authenticated() .requestMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ADMIN\u0026#34;) .requestMatchers(\u0026#34;/emp\u0026#34;).hasAuthority(\u0026#34;EMPLOYEE\u0026#34;) .requestMatchers(\u0026#34;/mgr\u0026#34;).hasAuthority(\u0026#34;MANAGER\u0026#34;) .anyRequest().authenticated() .and() .formLogin() .defaultSuccessUrl(\u0026#34;/welcome\u0026#34;,true) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout\u0026#34;)) .and() .exceptionHandling() .accessDeniedPage(\u0026#34;/accessDenied\u0026#34;) ; return http.build(); } } 注意：在上面的代码中，观察 Spring Security 6.0 中的 API 变化：antMatchers()被 requestMatchers()替换，authorizeRequests()被 authorizeHttpRequests()替换。\n如何测试启用安全的应用程序？ 同时完成大量理论和编码步骤之后，是时候测试“如何在 Spring Boot 项目中实现安全性？”了。请按照以下步骤操作。\n启动应用程序，然后右键单击该项目，然后选择“Run As”\u0026raquo;“Spring Boot App”。\n输入首页网址 http://localhost:8080/home，检查是否存在每个人都可以访问，甚至无需登录应用程序。\n输入管理页面 URL http://localhost:8080/admin，然后它应该被重定向到内置登录页面（由 Spring Security 提供）\n使用提供的管理员凭据登录，您将被重定向到欢迎页面。\n输入 URL http://localhost:8080/admin，然后您就可以看到管理页面了。\n当您使用管理员凭据登录时，您还可以通过点击其他页面 URL 来查看所有页面。\n随后对其他角色也重复上述步骤并检查用户是否可以根据授予的角色访问该页面。\nSpring Boot 项目如何实现安全性？ ：Spring Boot 3.0 及以上 Spring Boot 3.0 在 Spring Security 模块中进行了重大 API 级别更改。因此，如果您使用 Spring Boot 3.0 或更高版本，则需要遵循以下指南以及使用 JDK 17。\n在 SecurityConfig.java 中： 使用 authorizeHttpRequests()代替 authorizeRequests()\n使用 requestMatchers() 代替 antMatchers()\n使用 RegexRequestMatchers() 代替 regexMatchers()\n在实体类中： 在 import 语句中，使用“jakarta”代替“javax”。例如：使用“jakarta.persistence.Entity;”代替“javax.persistence.Entity;”。 FAQ 如何禁用应用程序的安全功能？ 同样重要的是，有时我们需要禁用安全功能，特别是在开发和测试环境中，以避免再次输入凭据。为此，我们可以相应地在 pom.xml 文件中注释以下两个依赖项。\n\u0026lt;!-- \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; --\u0026gt; 概括 随后，通过“如何在 Spring Boot 项目中实现安全性？”的所有理论和示例部分，最后，我们能够在 Spring Boot 项目中实现 Web 安全性。当然，在本文中我们介绍了两种实现安全功能的方法。此外，我们可以在另一篇文章中了解 UserDetailsS​​ervice（实现安全性的第三种方式）。此外，有关 Spring Boot Security 的完整教程请访问此处。后续如有更新，我们也会及时更新。也请随时在下面的评论部分提供您的意见。\n原文链接：https://javatechonline.com/how-to-implement-security-in-spring-boot-project/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/18/how-to-implement-security-in-spring-boot-project/","summary":"如今，几乎每个客户都要求在实时应用程序中实现强大的安全功能。安全功能对于保持机密性、完整性和可用性的需求是非常有效的。现实世界中有很多类型的安全性，但我们作为开发人员将重点关注应用程序/软件安全性。\n此外，在应用程序安全方面，我们的工作基本上是确保两件事。首先，只有有效的用户才能访问该应用程序。其次，如果用户有效，他/她只能访问该应用程序中允许的数据/信息。我认为，没有什么可以解释它们，因为您必须已经了解这两个术语，即身份验证和授权。\n您可能已经猜到我们将在当前主题“如何在 Spring Boot 项目中实现安全性？”中讨论什么内容。\n在本文中，我们将从基本原理开始学习。接下来，我们将逐步结束它，直到我们有信心在 Spring Boot 应用程序中实现安全功能。因此，让我们开始逐步讨论“如何在 Spring Boot 项目中实现安全性？”。 Spring Boot 教程页面上有一系列有关 Spring Boot Security 的教程。\n我们在本文中介绍了两个版本的“如何在 Spring Boot 项目中实现安全性？”的示例：使用 WebSecurityConfigurerAdapter 和不使用 WebSecurityConfigurerAdapter。此外，还涵盖了使用 Spring Boot 3.0 及更高版本的“如何在 Spring Boot 项目中实现安全性？”的示例。\n您将从本文中学到什么？ 为什么我们需要在 Spring Boot 应用程序中实现安全性？\nSecurity 在 Spring Boot 应用程序内部如何工作？\njavax.servlet.Filter 在 Spring Boot 应用程序中实现安全性方面的作用是什么？\nSpring Boot 项目中使用了多少种授权类型？\nSpring Boot 项目中有多少种实现安全性的方法？\n在 Spring Boot 项目中实现 WebSecurity 的步骤是什么？\n另外，如何在 Spring Boot 项目中使用@EnableWebSecurity、@Configuration、@Bean？\n如何实现内存中身份验证安全示例\n如何实现 JDBC 认证安全示例\n如何在 Spring Boot 项目中使用 Thymeleaf ？\n如何测试启用安全的功能？\n相反，如何禁用应用程序的安全功能？\n最后但并非最不重要的一点是，您将学习“如何在 Spring Boot 项目中实现安全性？”使用 WebSecurityConfigurerAdapter 和不使用 WebSecurityConfigurerAdapter。\n为什么我们需要应用程序中的安全性？ 现在，随着恶意攻击将重点从操作系统和网络转移到应用程序/软件和移动设备/设备，一天的数据面临最大的风险。此外，从业务/客户的角度来看，应用程序安全在维护信任、建立品牌形象和降低风险方面发挥着重要作用。事实上，没有其中任何一项，都无法想象一家成功的企业。\n总之，无论您是为了内部使用、销售目的还是购买目的而创建应用程序，安全性都是每个应用程序最重要的功能。\n根据最新的 2020 年 Verizon 数据泄露调查报告，所有数据泄露中有 43% 是针对 Web 应用程序的攻击。这一数字比 2019 年增加了一倍。此外，86% 的违规行为都是出于经济动机。","title":"[译]Spring Boot项目如何实现Security？"},{"content":"Spring Security 是一个有助于保护企业应用程序安全的框架。通过与 Spring MVC、Spring Webflux 或 Spring Boot 集成，我们可以创建一个强大且高度可定制的身份验证和访问控制框架。在本文中，我们将解释核心概念并仔细研究 Spring Security 提供的默认配置及其工作原理。我们将进一步尝试自定义它们并分析它们对示例 Spring Boot 应用程序的影响。\n示例代码 本文附有 GitHub 上的工作代码示例。\n创建示例应用程序 让我们从头开始构建一个 Spring Boot 应用程序，看看 spring 如何配置和提供安全性。让我们从 spring starter 创建一个应用程序并添加所需的最少依赖项。\n生成项目后，我们将其导入到 IDE 中并将其配置为在端口 8083 上运行。\nmvnw clean verify spring-boot:run (for Windows) ./mvnw clean verify spring-boot:run (for Linux) 在应用程序启动时，我们应该看到一个登录页面。\n控制台日志打印作为默认安全配置的一部分随机生成的默认密码：\n使用默认用户名 user 和默认密码（来自日志），我们应该能够登录该应用程序。我们可以在 application.yml 中覆盖这些默认值：\nspring: security: user: name: admin password: passw@rd 现在，我们应该能够使用用户 admin 和密码 passw@rd 登录。\n依赖版本 在这里，我们使用了 Spring Boot 2.7.5 版本。基于此版本，Spring Boot 内部将 Spring Security 版本解析为 5.7.4。但是，如果需要，我们可以在 pom.xml 中覆盖这些版本，如下所示：\n\u0026lt;properties\u0026gt; \u0026lt;spring-security.version\u0026gt;5.2.5.RELEASE\u0026lt;/spring-security.version\u0026gt; \u0026lt;/properties\u0026gt; 了解安全组件 要了解默认配置的工作原理，我们首先需要了解以下内容：\nServlet Filters 过滤器 Authentication 认证 Authorization 授权 Servlet Filters 让我们仔细看看应用程序启动时的控制台日志。我们看到 DefaultSecurityFilterChain 在请求到达 DispatcherServlet 之前触发一系列过滤器。 DispatcherServlet 是 Web 框架中的关键组件，用于处理传入的 Web 请求并将它们分派到适当的处理程序进行处理。\no.s.s.web.DefaultSecurityFilterChain : Will secure any request with [org.springframework.security.web.session.DisableEncodeUrlFilter@2fd954f, org.springframework.security.web.context.request.async. WebAsyncManagerIntegrationFilter@5731d3a, org.springframework.security.web.context.SecurityContextPersistenceFilter@5626d18c, org.springframework.security.web.header.HeaderWriterFilter@52b3bf03, org.springframework.security.web.csrf.CsrfFilter@30c4e352, org.springframework.security.web.authentication.logout.LogoutFilter@37ad042b, org.springframework.security.web.authentication. UsernamePasswordAuthenticationFilter@1e60b459, org.springframework.security.web.authentication.ui. DefaultLoginPageGeneratingFilter@29b40b3, org.springframework.security.web.authentication.ui. DefaultLogoutPageGeneratingFilter@6a0f2853, org.springframework.security.web.authentication.www. BasicAuthenticationFilter@254449bb, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@3dc95b8b, org.springframework.security.web.servletapi. SecurityContextHolderAwareRequestFilter@2d55e826, org.springframework.security.web.authentication. AnonymousAuthenticationFilter@1eff3cfb, org.springframework.security.web.session.SessionManagementFilter@462abec3, org.springframework.security.web.access.ExceptionTranslationFilter@6f8aba08, org.springframework.security.web.access.intercept. FilterSecurityInterceptor@7ce85af2] 要了解 FilterChain 的工作原理，让我们看一下 Spring Security 文档中的流程图\n现在，让我们看看参与过滤器链的核心组件：\nDelegatingFilterProxy Spring 提供的一个 servlet 过滤器，充当 Servlet 容器和 Spring Application Context 之间的桥梁。 DelegatingFilterProxy 类负责将任何实现 javax.servlet.Filter 的类连接到过滤器链中。 FilterChainProxy Spring 安全性在内部创建一个名为 springSecurityFilterChain 的 FilterChainProxy bean，包装在 DelegatingFilterProxy 中。 FilterChainProxy 是一个过滤器，它根据安全配置链接多个过滤器。因此， DelegatingFilterProxy 将请求委托给 FilterChainProxy ，后者确定要调用的过滤器。 SecurityFilterChain: SecurityFilterChain 中的安全过滤器是用 FilterChainProxy 注册的 bean。一个应用程序可以有多个 SecurityFilterChain 。 FilterChainProxy 使用 HttpServletRequest 上的 RequestMatcher 接口来确定需要调用哪个 SecurityFilterChain 。 Spring Security Chain 补充说明 Spring Boot 应用程序中的默认后备过滤器链有一个请求匹配器 /** ，这意味着它将应用于所有请求。 默认过滤器链具有预定义的 @Order SecurityProperties.BASIC_AUTH_ORDER。 我们可以通过设置 security.basic.enabled=false 来排除这个完整的过滤器链。 我们可以定义多个过滤器链的顺序。例如，要在默认过滤器链之前调用自定义过滤器链，我们需要设置较低的 @Order 。示例 @Order(SecurityProperties.BASIC_AUTH_ORDER - 10) 。 我们可以使用 FilterRegistrationBean 或扩展 OncePerRequestFilter 在现有过滤器链中插入自定义过滤器（随时调用或针对特定 URL 模式调用）。 对于定义的自定义过滤器，如果未指定@Order，则它是安全链中的最后一个。 （具有默认顺序 LOWEST_PRECEDENCE 。） 我们还可以使用方法 addFilterAfter() 、 addFilterAt() 和 addFilterBefore() 来更好地控制我们定义的自定义过滤器的顺序。 我们将在后面的部分中定义自定义过滤器和过滤器链。\n现在我们知道 Spring Security 为我们提供了一个默认的过滤器链，它调用一组预定义且有序的过滤器，让我们尝试简要了解链中几个重要过滤器的角色。\norg.springframework.security.web.csrf.CsrfFilter : 此过滤器默认将 CSRF 保护应用于所有 REST 端点。要详细了解 Spring Boot 和 Spring Security 中的 CSRF 功能，请参考这篇文章。 org.springframework.security.web.authentication.logout.LogoutFilter : 当用户注销应用程序时调用此过滤器。调用默认注册的 LogoutHandler 实例，负责使会话无效并清除 SecurityContext 。接下来， LogoutSuccessHandler 的默认实现将用户重定向到新页面 ( /login?logout )。 org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter : 使用启动时提供的默认凭据验证 URL ( /login ) 的用户名和密码。 org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter : 在 /login 处生成默认登录页面 html org.springframework.security.web.authentication.ui.DefaultLogoutPageGeneratingFilter : 在 /login?logout 处生成默认注销页面 html org.springframework.security.web.authentication.www.BasicAuthenticationFilter : 此过滤器负责处理任何具有授权、基本身份验证方案、Base64 编码的用户名密码的 HTTP 请求标头的请求。身份验证成功后， Authentication 对象将被放置在 SecurityContextHolder 中。 org.springframework.security.web.authentication.AnonymousAuthenticationFilter : 如果在 SecurityContext 中找不到 Authentication 对象，它会创建一个具有主体 anonymousUser 和角色。 org.springframework.security.web.access.ExceptionTranslationFilter :处理过滤器链中抛出的 AccessDeniedException 和 AuthenticationException 。对于 AuthenticationException ，需要 AuthenticationEntryPoint 实例来处理响应。对于 AccessDeniedException ，此过滤器将委托给 AccessDeniedHandler ，其默认实现为 AccessDeniedHandlerImpl 。 org.springframework.security.web.access.intercept.FilterSecurityInterceptor : 此过滤器负责在请求到达控制器之前对通过过滤器链的每个请求进行授权。 Authentication 身份验证是验证用户凭据并确保其有效性的过程。让我们了解一下 spring 框架如何验证创建的默认凭据：\n步骤 1：当启用 FormLogin 时，即向 URL /login 发出请求时， UsernamePasswordAuthenticationFilter 被调用作为安全过滤器链的一部分。该类是基类 AbstractAuthenticationProcessingFilter 的具体实现。当尝试进行身份验证时，过滤器会将请求转发到 AuthenticationManager 。\n步骤 2： UsernamePasswordAuthenticationToken 是 Authentication 接口的实现。此类指定身份验证机制必须通过用户名-密码进行。\n步骤 3：获得身份验证详细信息后， AuthenticationManager 尝试在 AuthenticationProvider 的适当实现和经过完全身份验证的 Authentication 对象的帮助下对请求进行身份验证被返回。默认实现是 DaoAuthenticationProvider ，它从 UserDetailsService 检索用户详细信息。如果身份验证失败，则抛出 AuthenticationException 。\n步骤 4： UserDetailsService 的 loadUserByUsername(username) 方法返回包含用户数据的 UserDetails 对象。如果没有找到具有给定用户名的用户，则抛出 UsernameNotFoundException 。\n步骤 5：身份验证成功后， SecurityContext 将更新为当前经过身份验证的用户。\n为了理解上面概述的步骤，让我们看一下 Spring Security 文档中定义的身份验证架构。\nProviderManager 是 AuthenticationManager 最常见的实现。如图所示， ProviderManager 将请求委托给已配置的 AuthenticationProvider 列表，每个列表都会被查询以查看是否可以执行身份验证。如果认证失败，返回 ProviderNotFoundException ，这是 AuthenticationException 的特殊类型，说明 ProviderManager 不支持 Authentication\nAuthenticationEntryPoint 是一个充当身份验证入口点的接口，用于确定客户端在请求资源时是否包含有效的凭据。如果没有，则使用该接口的适当实现来向客户端请求凭证。\n现在，让我们了解 Authentication 对象如何绑定整个身份验证过程。 Authentication 接口有以下用途：\n向 AuthenticationManager 提供用户凭据。 代表 SecurityContext 中当前经过身份验证的用户。 Authentication 的每个实例都必须包含 principal - 这是标识用户的 UserDetails 实例。 credentials - 凭证 authorities - GrantedAuthority GrantedAuthority 的实例在授权过程中发挥着重要作用。 关于 Spring 身份验证的附加说明 在某些情况下，我们可能需要在单独授权的情况下使用 Spring Security，因为在访问我们的应用程序之前它已经由外部系统进行了可靠的身份验证。请参阅预认证文档了解如何配置和处理此类场景。 Spring 允许通过多种方式来定制身份验证机制，我们将在后面的部分中介绍其中的几种。 Authorization 授权 授权是确保访问资源的用户或系统具有有效权限的过程。\n在 Spring security 过滤器链中， FilterSecurityInterceptor 触发授权检查。从过滤器的执行顺序可以看出，认证先于授权运行。该过滤器在用户成功通过身份验证后检查有效权限。如果授权失败，则会抛出 AccessDeniedException 。\n授予权限 如上一节所示，每个用户实例都包含一个 GrantedAuthority 对象列表。 GrantedAuthority 是一个具有单一方法的接口：\npublic interface GrantedAuthority extends Serializable { String getAuthority(); } Spring security 默认情况下调用具体的 GrantedAuthority 实现 SimpleGrantedAuthority 。 SimpleGrantedAuthority 允许我们将角色指定为字符串，自动将它们映射到 GrantedAuthority 实例中。 AuthenticationManager 负责将 GrantedAuthority 对象列表插入到 Authentication 对象中。然后 AccessDecisionManager 使用 getAuthority() 来决定授权是否成功。\n授予的权限与角色 Spring Security 分别使用 hasAuthority() 和 hasRole() 方法通过授予的权限和角色提供授权支持。这些方法用于基于表达式的安全性，并且是接口 SecurityExpressionOperations 的一部分。对于大多数情况，这两种方法可以互换使用，最显着的区别是 hasRole() 不需要指定 ROLE 前缀，而 hasAuthority() 需要显式指定完整的字符串。例如， hasAuthority(\u0026quot;ROLE_ADMIN\u0026quot;) 和 hasRole(\u0026quot;ADMIN\u0026quot;) 执行相同的任务。\nSpring 授权的补充说明 Spring 允许我们使用 @PreAuthorize 和 @PostAuthorize 注释来配置方法级安全性。正如名称所示，它们允许我们在方法执行之前和之后对用户进行授权。授权检查的条件可以在 Spring 表达式语言 (SpEL) 中指定。我们将在后面的部分中查看一些示例。 我们可以通过公开 GrantedAuthorityDefaults bean 将授权规则配置为使用不同的前缀（ ROLE_ 除外）。 常见漏洞保护 默认的 spring security 配置带有默认启用的针对各种攻击的保护功能。我们不会在本文中介绍这些细节。您可以参考 Spring 文档以获取详细指南。但是，要了解 CORS 和 CSRF 上的深入 Spring Security 配置，请参阅以下文章：\nCORS in Spring Security CSRF in Spring Security 实现安全配置 现在我们已经熟悉了 Spring Security 工作原理的细节，接下来让我们了解应用程序中的配置设置，以处理我们在前面几节中简要提到的各种场景。\n默认配置 org.springframework.boot.autoconfigure.security.servlet 包中的 SpringBootWebSecurityConfiguration 类为 Spring Boot 应用程序提供了一组默认的 Spring 安全配置。该类的反编译版本如下所示：\nclass SpringBootWebSecurityConfiguration { @ConditionalOnDefaultWebSecurity static class SecurityFilterChainConfiguration { SecurityFilterChainConfiguration() { } @Bean @Order(2147483642) SecurityFilterChain defaultSecurityFilterChain(HttpSecurity http) throws Exception { ((AuthorizedUrl) http.authorizeRequests().anyRequest()).authenticated(); http.formLogin(); http.httpBasic(); return (SecurityFilterChain) http.build(); } } } Spring 使用上述配置来创建默认的 SecurityFilterChainBean ：\nauthorizeRequests() 基于 RequestMatcher 实现限制访问。这里 authorizeRequests().anyRequest() 将允许所有请求。为了更好地控制限制访问，我们可以通过 antMatchers() 指定 URL 模式。 authenticated() 要求所有调用的端点在进入过滤器链之前都经过身份验证。 formLogin() 调用默认的 FormLoginConfigurer 类，该类加载登录页面以通过用户名密码进行身份验证，并相应地重定向到相应的失败或成功处理程序。有关表单登录工作原理的图示，请参阅 Spring 文档中的详细说明。 httpBasic() 调用设置默认值的 HttpBasicConfigurer 以帮助进行基本身份验证。详细理解可以参考 Spring 文档。 Spring Security 与 SecurityFilterChain 从 Spring Security 5.7.0-M2 开始， WebSecurityConfigurerAdapter 已被弃用并替换为 SecurityFilterChain ，从而进入基于组件的安全配置。 要了解差异，请参阅这篇 Spring 博客文章。 本文中的所有示例都将使用使用 SecurityFilterChain 的较新配置。 常见用例 现在我们了解了 Spring Security 默认值的工作原理，让我们看一些场景并相应地自定义配置。\n1. 自定义默认配置 @Configuration @EnableWebSecurity public class SecurityConfiguration { public static final String[] ENDPOINTS_WHITELIST = { \u0026#34;/css/**\u0026#34;, \u0026#34;/\u0026#34;, \u0026#34;/login\u0026#34;, \u0026#34;/home\u0026#34; }; public static final String LOGIN_URL = \u0026#34;/login\u0026#34;; public static final String LOGOUT_URL = \u0026#34;/logout\u0026#34;; public static final String LOGIN_FAIL_URL = LOGIN_URL + \u0026#34;?error\u0026#34;; public static final String DEFAULT_SUCCESS_URL = \u0026#34;/home\u0026#34;; public static final String USERNAME = \u0026#34;username\u0026#34;; public static final String PASSWORD = \u0026#34;password\u0026#34;; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests(request -\u0026gt; request.antMatchers(ENDPOINTS_WHITELIST).permitAll() .anyRequest().authenticated()) .csrf().disable() .formLogin(form -\u0026gt; form .loginPage(LOGIN_URL) .loginProcessingUrl(LOGIN_URL) .failureUrl(LOGIN_FAIL_URL) .usernameParameter(USERNAME) .passwordParameter(PASSWORD) .defaultSuccessUrl(DEFAULT_SUCCESS_URL)); return http.build(); } } 我们可以自定义登录的各个方面，而不是使用 spring security 登录默认设置：\nloginPage - 自定义默认登录页面。在这里，我们创建了一个自定义 login.html 及其相应的 LoginController 类。 loginProcessingUrl - 验证用户名和密码的 URL。 failureUrl - 登录失败时定向到的 URL。 defaultSuccessUrl - 成功登录后定向到的 URL。在这里，我们创建了一个自定义 homePage.html 及其相应的 HomeController 类。 antMatchers() - 过滤掉将成为登录过程一部分的 URL。 同样，我们也可以自定义注销过程。\n@Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests(request -\u0026gt; request.antMatchers(ENDPOINTS_WHITELIST).permitAll() .anyRequest().authenticated()) .csrf().disable() .formLogin(form -\u0026gt; form .loginPage(LOGIN_URL) .loginProcessingUrl(LOGIN_URL) .failureUrl(LOGIN_FAIL_URL) .usernameParameter(USERNAME) .passwordParameter(PASSWORD) .defaultSuccessUrl(DEFAULT_SUCCESS_URL)) .logout(logout -\u0026gt; logout .logoutUrl(\u0026#34;/logout\u0026#34;) .invalidateHttpSession(true) .deleteCookies(\u0026#34;JSESSIONID\u0026#34;) .logoutSuccessUrl(LOGIN_URL + \u0026#34;?logout\u0026#34;)); return http.build(); } 在这里，当用户注销时，http 会话将失效，但会话 cookie 不会被清除。使用 deleteCookies(\u0026quot;JSESSIONID\u0026quot;) 有助于避免基于会话的冲突。\n此外，我们可以通过 Spring Security 管理和配置会话。\n@Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests(request -\u0026gt; request.antMatchers(ENDPOINTS_WHITELIST).permitAll() .anyRequest().authenticated()) .csrf().disable() .formLogin(form -\u0026gt; form .loginPage(LOGIN_URL) .loginProcessingUrl(LOGIN_URL) .failureUrl(LOGIN_FAIL_URL) .usernameParameter(USERNAME) .passwordParameter(PASSWORD) .defaultSuccessUrl(DEFAULT_SUCCESS_URL)) .logout(logout -\u0026gt; logout .logoutUrl(\u0026#34;/logout\u0026#34;) .invalidateHttpSession(true) .deleteCookies(\u0026#34;JSESSIONID\u0026#34;) .logoutSuccessUrl(LOGIN_URL + \u0026#34;?logout\u0026#34;)) .sessionManagement(session -\u0026gt; session .sessionCreationPolicy(SessionCreationPolicy.ALWAYS) .invalidSessionUrl(\u0026#34;/invalidSession.htm\u0026#34;) .maximumSessions(1) .maxSessionsPreventsLogin(true)); return http.build(); } 它为我们提供了以下会话属性 sessionCreationPolicy 值：\nSessionCreationPolicy.STATELESS - 不会创建或使用任何会话。 SessionCreationPolicy.ALWAYS - 如果会话不存在，则始终会创建该会话。 SessionCreationPolicy.NEVER - 永远不会创建会话。但如果会话存在，就会使用它。 SessionCreationPolicy.IF_REQUIRED - 如果需要，将创建会话。 （默认配置） Other options include: 其他选项包括：\ninvalidSessionUrl - 检测到无效会话时重定向到的 URL。 maximumSessions - 限制单个用户可以同时拥有的活动会话数。 maxSessionsPreventsLogin - 默认值为 false ，表示在现有用户的会话过期时允许经过身份验证的用户访问。 true 表示到达 SessionManagementConfigurer.maximumSessions(int) 时不会对用户进行身份验证。在这种情况下，当检测到多次登录时，它将重定向到 /invalidSession 。 2. 配置多个过滤器链 Spring Security 允许我们拥有多个共存的安全配置，使我们能够更好地控制应用程序。为了演示这一点，让我们为图书馆应用程序创建 REST 端点，该应用程序使用 H2 数据库根据体裁存储书籍。我们的 BookController 类将有一个端点定义如下：\n@GetMapping(\u0026#34;/library/books\u0026#34;) public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getBooks(@RequestParam String genre) { return ResponseEntity.ok().body(bookService.getBook(genre)); } 为了保护此端点，让我们在 SecurityConfiguration 类中使用基本身份验证并配置详细信息：\n@Configuration @EnableWebSecurity @EnableConfigurationProperties(BasicAuthProperties.class) public class SecurityConfiguration { private final BasicAuthProperties props; public SecurityConfiguration(BasicAuthProperties props) { this.props = props; } @Bean @Order(1) public SecurityFilterChain bookFilterChain(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement(session -\u0026gt; session .sessionCreationPolicy(SessionCreationPolicy.STATELESS)) .antMatcher(\u0026#34;/library/**\u0026#34;) .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/library/**\u0026#34;).hasRole(\u0026#34;USER\u0026#34;) .anyRequest().authenticated() .and() .httpBasic() .and() .exceptionHandling(exception -\u0026gt; exception .authenticationEntryPoint(userAuthenticationErrorHandler()) .accessDeniedHandler(new UserForbiddenErrorHandler())); return http.build(); } @Bean public UserDetailsService userDetailsService() { return new InMemoryUserDetailsManager(props.getUserDetails()); } @Bean public AuthenticationEntryPoint userAuthenticationErrorHandler() { UserAuthenticationErrorHandler userAuthenticationErrorHandler = new UserAuthenticationErrorHandler(); userAuthenticationErrorHandler.setRealmName(\u0026#34;Basic Authentication\u0026#34;); return userAuthenticationErrorHandler; } public static final String[] ENDPOINTS_WHITELIST = { \u0026#34;/css/**\u0026#34;, \u0026#34;/login\u0026#34;, \u0026#34;/home\u0026#34; }; public static final String LOGIN_URL = \u0026#34;/login\u0026#34;; public static final String LOGIN_FAIL_URL = LOGIN_URL + \u0026#34;?error\u0026#34;; public static final String DEFAULT_SUCCESS_URL = \u0026#34;/home\u0026#34;; public static final String USERNAME = \u0026#34;username\u0026#34;; public static final String PASSWORD = \u0026#34;password\u0026#34;; @Bean @Order(2) public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests(request -\u0026gt; request.antMatchers(ENDPOINTS_WHITELIST).permitAll() .anyRequest().authenticated()) .csrf().disable() .antMatcher(\u0026#34;/login\u0026#34;) .formLogin(form -\u0026gt; form .loginPage(LOGIN_URL) .loginProcessingUrl(LOGIN_URL) .failureUrl(LOGIN_FAIL_URL) .usernameParameter(USERNAME) .passwordParameter(PASSWORD) .defaultSuccessUrl(DEFAULT_SUCCESS_URL)) .logout(logout -\u0026gt; logout .logoutUrl(\u0026#34;/logout\u0026#34;) .invalidateHttpSession(true) .deleteCookies(\u0026#34;JSESSIONID\u0026#34;) .logoutSuccessUrl(LOGIN_URL + \u0026#34;?logout\u0026#34;)) .sessionManagement(session -\u0026gt; session .sessionCreationPolicy(SessionCreationPolicy.ALWAYS) .invalidSessionUrl(\u0026#34;/invalidSession\u0026#34;) .maximumSessions(1) .maxSessionsPreventsLogin(true)); return http.build(); } } 让我们仔细看看代码：\n我们有两个 SecurityFilterChain 方法 bookFilterChain() 和 filterChain() 方法以及 @Order(1) 和 @Order(2) 。它们都将按上述顺序执行。 由于两个过滤器链都满足不同的端点，因此 application.yml 中存在不同的凭据 auth: users: loginadmin: role: admin password: loginpass bookadmin: role: user password: bookpass 为了让 Spring Security 使用这些凭据，我们将 UserDetailsService 自定义为：\n@Bean public UserDetailsService userDetailsService() { return new InMemoryUserDetailsManager(props.getUserDetails()); } 为了满足 AuthenticationException 和 AccessDeniedException ，我们定制了 exceptionHandling() 并配置了自定义类 UserAuthenticationErrorHandler 和 UserForbiddenErrorHandler 。 使用此配置，REST 端点的邮递员响应如下所示：\n成功的回应:\n未经授权的回应：\n禁止的回应：\n3. 默认情况下保护的其他端点 一旦为请求匹配器配置了 Spring Security，默认情况下添加的其他端点就会受到保护。例如，让我们向 BookController 类添加一个端点\n@GetMapping(\u0026#34;/library/books/all\u0026#34;) public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getAllBooks() { return ResponseEntity.ok().body(bookService.getAllBooks()); } 为了成功调用此端点，我们需要提供基本的身份验证凭据。\n没有通过凭据时的错误响应：\n成功的回应：\n4. 不安全的特定端点 我们可以指定需要从安全配置中排除的端点列表。为此，我们首先向 BookController 类添加另一个端点，并添加以下配置：\n@GetMapping(\u0026#34;/library/info\u0026#34;) public ResponseEntity\u0026lt;LibraryInfo\u0026gt; getInfo() { return ResponseEntity.ok().body(bookService.getLibraryInfo()); } @Bean public WebSecurityCustomizer webSecurityCustomizer() { return (web) -\u0026gt; web.ignoring().antMatchers(\u0026#34;/library/info\u0026#34;); } 现在，我们应该能够在不传递凭据的情况下从邮递员到达端点：\n5. 添加自定义过滤器 Spring 通过执行链中的一系列过滤器来提供安全性。如果我们需要在请求到达控制器之前对其添加额外的检查，Spring Security 为我们提供了以下方法，帮助我们在链中所需的位置添加自定义过滤器。\naddFilterBefore(Filter filter, Class beforeFilter)：此方法允许我们在链中指定过滤器之前添加自定义过滤器。 addFilterAfter(Filter filter, Class afterFilter)：此方法允许我们在链中指定过滤器之后添加自定义过滤器。 addFilterAt(Filter filter, Class atFilter)：此方法允许我们以相同的优先级在链中的指定过滤器处添加自定义过滤器。添加自定义过滤器后，这两个过滤器都将在过滤器链中被调用（无特定顺序）。 让我们看一下示例配置：\n@Configuration @EnableWebSecurity @EnableConfigurationProperties(BasicAuthProperties.class) public class SecurityConfiguration { private final BasicAuthProperties props; public SecurityConfiguration(BasicAuthProperties props) { this.props = props; } @Bean @Order(1) public SecurityFilterChain bookFilterChain(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement(session -\u0026gt; session .sessionCreationPolicy(SessionCreationPolicy.STATELESS)) .antMatcher(\u0026#34;/library/**\u0026#34;) .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/library/**\u0026#34;).hasRole(\u0026#34;USER\u0026#34;) .anyRequest().authenticated() .and() .httpBasic() .and() .exceptionHandling(exception -\u0026gt; exception .authenticationEntryPoint(userAuthenticationErrorHandler()) .accessDeniedHandler(new UserForbiddenErrorHandler())); http.addFilterBefore(customHeaderValidatorFilter(), BasicAuthenticationFilter.class); return http.build(); } @Bean public CustomHeaderValidatorFilter customHeaderValidatorFilter() { return new CustomHeaderValidatorFilter(); } } 为了编写自定义过滤器，我们创建一个类 CustomHeaderValidatorFilter ，它扩展了为此目的而创建的特殊过滤器 OncePerRequestFilter 。这确保我们的过滤器对于每个请求仅被调用一次。\npublic class CustomHeaderValidatorFilter extends OncePerRequestFilter { private static final Logger log = LoggerFactory.getLogger (CustomHeaderValidatorFilter.class); @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { log.info(\u0026#34;Custom filter called...\u0026#34;); if (StringUtils.isEmpty(request.getHeader(\u0026#34;X-Application-Name\u0026#34;))) { response.setStatus(HttpServletResponse.SC_FORBIDDEN); response.setContentType(\u0026#34;application/json\u0026#34;); response.getOutputStream().println(new ObjectMapper(). writeValueAsString(CommonException.headerError())); } else { filterChain.doFilter(request, response); } } } 在这里，我们重写了 doFilterInternal() 并添加了我们的逻辑。在这种情况下，仅当请求中传递了所需的标头 X-Application-Name 时，请求才会在过滤器链中继续进行。此外，我们还可以验证该过滤器是否已从日志连接到我们的 SecurityConfiguration 类。\nWill secure Ant [pattern=\u0026#39;/library/**\u0026#39;] with [org.springframework.security.web.session.DisableEncodeUrlFilter@669469c9, org.springframework.security.web.context.request.async. WebAsyncManagerIntegrationFilter@7f39ad3f, org.springframework.security.web.context.SecurityContextPersistenceFilter@1b901f7b, org.springframework.security.web.header.HeaderWriterFilter@64f49b3, org.springframework.security.web.authentication.logout.LogoutFilter@628aea61, com.reflectoring.security.CustomHeaderValidatorFilter@3d40a3b4, org.springframework.security.web.authentication.www. BasicAuthenticationFilter@8d23cd8, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@1a1e38ab, org.springframework.security.web.servletapi. SecurityContextHolderAwareRequestFilter@5bfdabf3, org.springframework.security.web.authentication. AnonymousAuthenticationFilter@7524125c, org.springframework.security.web.session.SessionManagementFilter@3dc14f80, org.springframework.security.web.access.ExceptionTranslationFilter@58c16efd, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@5ab06829] 这里为所有端点 /library/** 调用过滤器。为了进一步限制它以满足特定的端点，我们可以将 Filter 类修改为：\n@Override protected boolean shouldNotFilter(HttpServletRequest request) throws ServletException { String path = request.getRequestURI(); return path.startsWith(\u0026#34;/library/books/all\u0026#34;); } 通过此更改，对于端点 /library/books/all ，将不会执行 doFilterInternal() 方法。相同的概念适用于使用 addFilterAt() 和 addFilterAfter() 方法添加的过滤器。\n6. 基于角色的授权 在 Spring Security 的上下文中，授权是在用户通过身份验证后发生的。在前面的部分中，我们查看了处理 AccessDeniedException 的示例。当用户授权失败时抛出该异常。在我们的示例中，我们在 application.yml 中为用户 bookadmin 和 loginadmin 定义了角色：\nauth: users: loginadmin: role: admin password: loginpass bookadmin: role: user password: bookpass 为了确保授权，我们将 Spring Security 配置为：\npublic class SecurityConfiguration { @Bean @Order(1) public SecurityFilterChain filterChain(HttpSecurity http) throws Exception { http.authorizeRequests(request -\u0026gt; request.antMatchers(ENDPOINTS_WHITELIST).hasRole(\u0026#34;ADMIN\u0026#34;) .anyRequest().authenticated()); /* Code continued.. */ return http.build(); } } 以及\npublic class SecurityConfiguration { @Bean @Order(2) public SecurityFilterChain bookFilterChain(HttpSecurity http) throws Exception { http .csrf().disable() .sessionManagement(session -\u0026gt; session .sessionCreationPolicy(SessionCreationPolicy.STATELESS)) .antMatcher(\u0026#34;/library/**\u0026#34;) .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/library/**\u0026#34;).hasRole(\u0026#34;USER\u0026#34;) .anyRequest().authenticated(); /* Code continued.. */ return http.build(); } } 让我们看一下可用于授权端点的方法。\nhasRole(String role) : 如果当前主体具有指定角色，则返回 true 。例如。 hasRole(\u0026quot;ADMIN\u0026quot;) hasAnyRole(String... roles) :可以指定多个角色。如果任何角色匹配，则返回 true 。例如。 hasAnyRole(\u0026quot;ADMIN\u0026quot;, \u0026quot;USER\u0026quot;) 注意：在上述两种情况下， ROLE_ 前缀默认添加到提供的角色字符串中。 hasAuthority(String authority) :如果当前主体具有指定的权限，则返回 true 。例如。 hasAuthority(ROLE_ADMIN) hasAnyAuthority(String... authorities) : 可以指定多个权限。如果任何权限匹配，则返回 true 。例如。 hasAnyAuthority(\u0026quot;ROLE_ADMIN\u0026quot;, \u0026quot;ROLE_USER\u0026quot;) Spring Security 访问控制的附加说明 上面讨论的所有方法都使用 spEL 来支持更复杂的访问控制。这允许我们使用特定的类来实现 Web 和方法安全性来访问当前主体等值。要了解如何利用 spEL，请参阅此 Spring 文档 另外，如果我们不需要设置授权，我们可以使用方法 permitAll() 和 denyAll() 分别允许或拒绝所有角色和权限。 让我们看一下一个示例配置，该配置在同一方法中为不同端点使用不同的角色。\npublic class SecurityConfiguration { @Bean public SecurityFilterChain bookFilterChain(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/library/info\u0026#34;).permitAll() .antMatchers(HttpMethod.GET, \u0026#34;/library/books\u0026#34;).hasRole(\u0026#34;USER\u0026#34;) .antMatchers(HttpMethod.GET, \u0026#34;/library/books/all\u0026#34;).hasRole(\u0026#34;ADMIN\u0026#34;); return http.build(); } } 7.@PreAuthorize 和@PostAuthorize Spring Security 允许我们通过 @PreAuthorize 和 @PostAuthorize 注解将安全机制扩展到方法。这些注释使用 spEL 根据传递的参数进行评估和授权。\n@PreAuthorize: 在执行方法之前授权条件。 @PostAuthorize: 授权方法执行后的条件。为了使这些注释起作用，我们需要将 @EnableGlobalMethodSecurity(prePostEnabled = true) 添加到我们的配置类中，如下所示： @Configuration @EnableWebSecurity @EnableGlobalMethodSecurity(prePostEnabled = true) @EnableConfigurationProperties(BasicAuthProperties.class) public class SecurityConfiguration { /* ... */ } 接下来我们看看如何使用这些注解。这里我们在 Controller 类中使用了 @PreAuthorize 。\n@Controller public class BookController { private static final Logger log = LoggerFactory.getLogger(BookController.class); private final BookService bookService; public BookController(BookService bookService) { this.bookService = bookService; } @GetMapping(\u0026#34;/library/books\u0026#34;) @PreAuthorize(\u0026#34;#user == authentication.principal.username\u0026#34;) public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getBooks(@RequestParam String genre, @RequestParam String user) { return ResponseEntity.ok().body(bookService.getBook(genre)); } @GetMapping(\u0026#34;/library/books/all\u0026#34;) @PreAuthorize(\u0026#34;hasRole(\u0026#39;ROLE_USER\u0026#39;)\u0026#34;) public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getAllBooks() { return ResponseEntity.ok().body(bookService.getAllBooks()); } } 在这里，我们演示了使用 @PreAuthorize 注释的两种方法。\n登录的用户名作为请求参数传递，并使用当前主体进行验证。对于成功的匹配，邮递员会返回有效的响应。 如果出现错误，我们会得到：\n@PreAuthorize(\u0026quot;hasRole('ROLE_USER')\u0026quot;) : 仅当当前主体具有 USER 角色时，我们才会收到成功响应。 接下来，让我们在 Repository 类中使 ​​ 用 @PostAuthorize 。\n@Repository public interface BookRepository extends JpaRepository\u0026lt;Book, Long\u0026gt; { List\u0026lt;Book\u0026gt; findByGenre(String genre); @PostAuthorize(\u0026#34;returnObject.size() \u0026gt; 0\u0026#34;) List\u0026lt;Book\u0026gt; findAll(); } 这里， returnObject 表示 List\u0026lt;Book\u0026gt; 。因此，当 size() 返回 0 时，我们将得到一个错误响应。\n自定义授权 要自定义表达式的处理方式，我们需要将 MethodSecurityExpressionHandler 公开为 bean。 Spring 方法安全性是使用 Spring AOP 构建的。有关更多示例，请参阅方法安全文档。 8. 基于数据库的认证和授权 在之前的所有示例中，我们都使用 InMemoryUserDetailsManager 配置用户、密码、角色。 Spring Security 允许我们自定义身份验证和授权过程。我们还可以在数据库中配置这些详细信息，并让 Spring Security 相应地访问它们。\n有关工作示例，请参阅本文。它还解释了为了提高安全性而应采用的不同方式处理密码。\n让我们概述一下使此配置正常工作所需的步骤。\nStep.1 : 通过重写 loadUserByUsername() 自定义 UserDetailsService 以从数据库加载用户凭据。\nStep.2 : 根据使用的编码机制创建 PasswordEncoder bean。\nStep.3 : 由于 AuthenticationProvider 负责验证凭据，因此自定义并覆盖 authenticate() 以使用数据库凭据进行验证。\n有关密码编码器的附加信息 在 Spring Security 5.0 之前，默认的 PasswordEncoder 是 NoOpPasswordEncoder ，它需要纯文本密码。 从 Spring Security 5.0 开始，我们使用 DelegatingPasswordEncoder 确保使用当前密码存储建议对密码进行编码。 有关 DelegatingPasswordEncoder 的更多信息，请参阅此文档 使用 Spring Security 进行测试 现在我们已经了解了各种安全配置的工作原理，让我们看看它们的单元测试。 Spring security 为我们提供了以下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 此外，我们还添加了 Hamcrest 依赖项。 Hamcrest 是一个框架，允许我们在断言中使用 Matcher 对象来进行更具表现力的响应匹配。请参阅 Hamcrest 文档以深入了解其功能。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.hamcrest\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;hamcrest-library\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 首先，让我们设置 ApplicationContext 来测试 BookController 类。这里我们使用 @Sql 定义了一个示例测试数据\n@SpringBootTest @AutoConfigureMockMvc @SqlGroup({ @Sql(value = \u0026#34;classpath:init/first.sql\u0026#34;, executionPhase = BEFORE_TEST_METHOD), @Sql(value = \u0026#34;classpath:init/second.sql\u0026#34;, executionPhase = BEFORE_TEST_METHOD) }) public class BookControllerTest { } 现在，让我们看看可用于测试基本身份验证安全端点的各种选项。\n@WithMockUser 顾名思义，我们将此注释与默认用户名 user 、密码 password 和角色 ROLE_USER 一起使用。由于我们正在模拟用户，因此用户不需要实际存在。只要我们的端点是安全的， @WithMockUser 就会成功。\npublic class BookControllerTest { @Autowired private MockMvc mockMvc; @Test @DisplayName(\u0026#34;TestCase1 Check if spring security applies to the endpoint\u0026#34;) @WithMockUser(username = \u0026#34;bookadmin\u0026#34;, roles = {\u0026#34;USER\u0026#34;}) void successIfSecurityApplies() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fiction\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;)) .andDo(print()) .andExpect(status().isOk()) .andExpect(authenticated().withUsername(\u0026#34;bookadmin\u0026#34;)) .andExpect(authenticated().withRoles(\u0026#34;USER\u0026#34;)) .andExpect(jsonPath(\u0026#34;$\u0026#34;, hasSize(3))) ; } @Test @DisplayName(\u0026#34;TestCase2 Fails when wrong roles are provided\u0026#34;) @WithMockUser(username = \u0026#34;bookadmin\u0026#34;, roles = {\u0026#34;ADMIN\u0026#34;}) void failsForWrongAuthorization() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fiction\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;)) .andDo(print()) .andExpect(status().isForbidden()) ; } @Test @DisplayName(\u0026#34;TestCase3 Fails when we run the test with no security\u0026#34;) void failsIfSecurityApplies() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fiction\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;)) .andDo(print()) .andExpect(status().isUnauthorized()) ; } } @WithMockUser(username = \u0026quot;bookadmin\u0026quot;, roles = {\u0026quot;USER\u0026quot;}) :这里我们使用用户名 bookadmin 和角色 USER 运行测试。此测试仅用于验证端点是否安全。此外，我们还使用方法 authenticated() 来验证身份验证详细信息，并使用 hamcrest 匹配器 hasSize() 来验证响应对象。 @WithMockUser(username = \u0026quot;bookadmin\u0026quot;, roles = {\u0026quot;ADMIN\u0026quot;}) : 在这里，我们收到 Forbidden 响应，因为角色不匹配。尽管用户被嘲笑，但角色需要匹配才能获得成功响应。 当没有指定用户细节时，端点没有得到保护，因此我们收到了未授权的响应。 @WithUserDetails 我们还可以使用在 SecurityConfiguration 类中创建的 UserDetailsService bean，而不是模拟用户。\npublic class BookControllerTest { @Autowired private MockMvc mockMvc; @Test @DisplayName(\u0026#34;TestCase4 Run the test with configured UserDetailsService\u0026#34;) @WithUserDetails(value = \u0026#34;bookadmin\u0026#34;, userDetailsServiceBeanName = \u0026#34;userDetailsService\u0026#34;) void testBookWithConfiguredUserDetails() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fantasy\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;)) .andDo(print()) .andExpect(status().isOk()) .andExpect(jsonPath(\u0026#34;$\u0026#34;, hasSize(1))) ; } @Test @DisplayName(\u0026#34;TestCase5 Fails when execution of CustomHeaderValidatorFilter \u0026#34; + \u0026#34;does not meet the criteria\u0026#34;) @WithUserDetails(value = \u0026#34;bookadmin\u0026#34;, userDetailsServiceBeanName = \u0026#34;userDetailsService\u0026#34;) void failsIfMandatoryHeaderIsMissing() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fantasy\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;)) .andDo(print()) .andExpect(status().isForbidden()) ; } @Test @DisplayName(\u0026#34;TestCase6 Fails when preauthorization \u0026#34; + \u0026#34;of current principal fails\u0026#34;) @WithUserDetails(value = \u0026#34;bookadmin\u0026#34;, userDetailsServiceBeanName = \u0026#34;userDetailsService\u0026#34;) void failsIfPreAuthorizeConditionFails() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fantasy\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookuser\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;)) .andDo(print()) .andExpect(status().isForbidden()) ; } @Test @DisplayName(\u0026#34;TestCase7 Fails when wrong basic auth credentials are applied\u0026#34;) void testBookWithWrongCredentialsUserDetails() throws Exception { mockMvc.perform(get(\u0026#34;/library/books\u0026#34;) .param(\u0026#34;genre\u0026#34;, \u0026#34;Fantasy\u0026#34;) .param(\u0026#34;user\u0026#34;, \u0026#34;bookadmin\u0026#34;) .header(\u0026#34;X-Application-Name\u0026#34;, \u0026#34;Library\u0026#34;) .with(httpBasic(\u0026#34;bookadmin\u0026#34;, \u0026#34;password\u0026#34;))) .andDo(print()) .andExpect(status().isUnauthorized()); } } 通过此配置，端点将使用 userDetailsService bean 进行身份验证。我们可以使用 httpBasic() 来确保拒绝错误的凭据。此外，上述测试验证了预授权和自定义过滤器检查。\n结论 在本文中，我们研究了适用于 Spring Security 的基本概念。此外，我们还解释了 spring 提供的默认配置以及如何覆盖它们。此外，我们还研究了一些常见的用例，并通过单元测试对其进行了验证。正如我们所看到的，Spring 提供了很大的灵活性，允许我们为复杂的应用程序定制安全性。我们可以扩展 GitHub 上应用程序中应用的示例配置以满足我们的需求。\n原文链接：https://reflectoring.io/spring-security/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security/","summary":"Spring Security 是一个有助于保护企业应用程序安全的框架。通过与 Spring MVC、Spring Webflux 或 Spring Boot 集成，我们可以创建一个强大且高度可定制的身份验证和访问控制框架。在本文中，我们将解释核心概念并仔细研究 Spring Security 提供的默认配置及其工作原理。我们将进一步尝试自定义它们并分析它们对示例 Spring Boot 应用程序的影响。\n示例代码 本文附有 GitHub 上的工作代码示例。\n创建示例应用程序 让我们从头开始构建一个 Spring Boot 应用程序，看看 spring 如何配置和提供安全性。让我们从 spring starter 创建一个应用程序并添加所需的最少依赖项。\n生成项目后，我们将其导入到 IDE 中并将其配置为在端口 8083 上运行。\nmvnw clean verify spring-boot:run (for Windows) ./mvnw clean verify spring-boot:run (for Linux) 在应用程序启动时，我们应该看到一个登录页面。\n控制台日志打印作为默认安全配置的一部分随机生成的默认密码：\n使用默认用户名 user 和默认密码（来自日志），我们应该能够登录该应用程序。我们可以在 application.yml 中覆盖这些默认值：\nspring: security: user: name: admin password: passw@rd 现在，我们应该能够使用用户 admin 和密码 passw@rd 登录。\n依赖版本 在这里，我们使用了 Spring Boot 2.7.5 版本。基于此版本，Spring Boot 内部将 Spring Security 版本解析为 5.7.4。但是，如果需要，我们可以在 pom.xml 中覆盖这些版本，如下所示：\n\u0026lt;properties\u0026gt; \u0026lt;spring-security.version\u0026gt;5.2.5.RELEASE\u0026lt;/spring-security.version\u0026gt; \u0026lt;/properties\u0026gt; 了解安全组件 要了解默认配置的工作原理，我们首先需要了解以下内容：\nServlet Filters 过滤器 Authentication 认证 Authorization 授权 Servlet Filters 让我们仔细看看应用程序启动时的控制台日志。我们看到 DefaultSecurityFilterChain 在请求到达 DispatcherServlet 之前触发一系列过滤器。 DispatcherServlet 是 Web 框架中的关键组件，用于处理传入的 Web 请求并将它们分派到适当的处理程序进行处理。","title":"[译]Spring Security 和 Spring Boot 入门"},{"content":"容器已成为打包具有所有软件和操作系统依赖项的应用程序，然后将其传送到不同环境的首选方式。\n本文着眼于容器化 Spring Boot 应用程序的不同方法：\n使用 Docker 文件构建 Docker 镜像， 使用 Cloud-Native Buildpack 从源代码构建 OCI 映像， 通过使用分层工具将 JAR 的各个部分拆分为不同的层，在运行时优化映像。 示例代码 本文附有 GitHub 上的工作代码示例。\n容器术语 我们将从整篇文章中使用的容器术语开始：\nContainer image: 具有特定格式的文件。我们通过运行构建工具将应用程序转换为容器映像。 Container: 容器镜像的运行时实例。 Container engine: t 负责运行 Container 的守护进程。 Container host: 容器引擎运行的主机。 Container registry: 用于发布和分发容器映像的共享位置。 OCI Standard: 开放容器倡议 (OCI) 是在 Linux 基金会下形成的一个轻量级、开放的治理结构。 OCI 镜像规范定义了容器镜像格式和运行时的行业标准，以确保所有容器引擎都可以运行任何构建工具生成的容器镜像。 为了容器化应用程序，我们将应用程序封装在容器映像中，并将该映像发布到共享注册表。容器运行时从注册表中提取该映像，解压该映像，然后在其中运行应用程序。\nSpring Boot 2.3 版本提供了用于构建 OCI 映像的插件。\nDocker 恰好是最常用的容器实现，并且我们在示例中使用 Docker，因此本文中所有后续对容器的引用都将指 Docker。\n以传统方式构建容器镜像 通过向 Docker 文件添加一些指令，可以非常轻松地创建 Spring Boot 应用程序的 Docker 镜像。\n我们首先构建一个可执行 JAR，并作为 Docker 文件指令的一部分，在应用必要的自定义后将可执行 JAR 复制到基本 JRE 映像上。\n让我们从 Spring Initializr 创建带有 web 、 lombok 和 actuator 依赖项的 Spring Boot 应用程序。我们还添加了一个休息控制器来使用 GET 方法公开 API。\n创建 Docker 文件 接下来，我们通过添加 Dockerfile 来容器化该应用程序：\nFROM adoptopenjdk:11-jre-hotspot ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} application.jar EXPOSE 8080 ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/application.jar\u0026#34;] 我们的 Docker 文件包含来自 adoptopenjdk 的基本映像，我们在该映像上复制 JAR 文件，然后公开将侦听请求的端口 8080 。\n构建应用程序 我们首先使用 Maven 或 Gradle 构建应用程序。我们在这里使用 Maven：\nmvn clean package 这将创建应用程序的可执行 JAR。我们需要将这个可执行 JAR 转换为 Docker 映像，以便在 Docker 引擎中运行。\n构建容器镜像 接下来，我们通过从包含之前创建的 Docker 文件的根项目目录运行 docker build 命令，将此可执行 JAR 放入 Docker 映像中：\ndocker build -t usersignup:v1 . 我们可以看到使用以下命令列出的图像：\ndocker images 上述命令的输出包括我们的映像 usersignup 以及 Docker 文件中指定的基础映像 adoptopenjdk 。\nREPOSITORY TAG SIZE usersignup v1 249MB adoptopenjdk 11-jre-hotspot 229MB 查看容器镜像内的层 让我们看看图像内的图层堆栈。我们将使用 dive tool 来查看这些图层：\ndive usersignup:v1 以下是运行 Dive 命令的部分输出：\n正如我们所看到的，应用层构成了图像大小的重要组成部分。作为优化的一部分，我们的目标是在以下部分中减小该层的大小。\n使用 Buildpack 构建容器镜像 Buildpacks 是各种平台即服务 (PAAS) 产品使用的通用术语，用于从源代码构建容器映像。它由 Heroku 于 2011 年发起，此后已被 Cloud Foundry、Google App Engine、Gitlab、Knative 等采用。\n云原生 Buildpack 的优势 使用 Buildpack 构建映像的一个主要优点是，可以在集中位置（构建器）管理对映像配置的更改，并将其传播到使用该构建器的所有应用程序。\nBuildpack 与平台紧密耦合。云原生 Buildpack 通过支持 OCI 映像格式实现跨平台标准化，确保映像可以由 Docker 引擎运行。\n使用 Spring Boot 插件 Spring Boot 插件使用 Buildpack 从源代码创建 OCI 映像。映像是使用 bootBuildImage 任务 (Gradle) 或 spring-boot:build-image 目标 (Maven) 和本地 Docker 安装构建的。\n我们可以通过在 image tag 中指定名称来自定义推送到 Docker 注册表所需的镜像名称：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;image\u0026gt; \u0026lt;name\u0026gt;docker.io/pratikdas/${project.artifactId}:v1\u0026lt;/name\u0026gt; \u0026lt;/image\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 让我们使用 Maven 运行 build-image 目标来构建应用程序并创建容器映像。我们现在没有使用任何 Docker 文件。\nmvn spring-boot:build-image 运行此命令将产生类似于以下内容的输出：\n[INFO] --- spring-boot-maven-plugin:2.3.3.RELEASE:build-image (default-cli) @ usersignup --- [INFO] Building image \u0026#39;docker.io/pratikdas/usersignup:v1\u0026#39; [INFO] [INFO] \u0026gt; Pulling builder image \u0026#39;gcr.io/paketo-buildpacks/builder:base-platform-api-0.3\u0026#39; 0% . . .. [creator] Adding label \u0026#39;org.springframework.boot.version\u0026#39; .. [creator] *** Images (c311fe74ec73): .. [creator] docker.io/pratikdas/usersignup:v1 [INFO] [INFO] Successfully built image \u0026#39;docker.io/pratikdas/usersignup:v1\u0026#39; 从输出中，我们可以看到 paketo Cloud-Native buildpack 被用来构建可运行的 OCI 映像。正如我们之前所做的那样，我们可以通过运行以下命令来查看列为 Docker 映像的映像：\ndocker images 输出：\nREPOSITORY SIZE paketobuildpacks/run 84.3MB gcr.io/paketo-buildpacks/builder 652MB pratikdas/usersignup 257MB 使用 Jib 构建容器镜像 Jib 是 Google 的一个镜像构建器插件，提供了一种从源代码构建容器镜像的替代方法。\n我们在 pom.xml 中配置 jib-maven-plugin ：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.google.cloud.tools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jib-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.2\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; 接下来，我们使用 Maven 命令触发 Jib 插件来构建应用程序并创建容器映像。和以前一样，我们在这里没有使用任何 Docker 文件：\nmvn compile jib:build -Dimage=\u0026lt;docker registry name\u0026gt;/usersignup:v1 运行上述 Maven 命令后，我们得到以下输出：\n[INFO] Containerizing application to pratikdas/usersignup:v1... . . [INFO] Container entrypoint set to [java, -cp, /app/resources:/app/classes:/app/libs/*, io.pratik.users.UsersignupApplication] [INFO] [INFO] Built and pushed image as pratikdas/usersignup:v1 [INFO] Executing tasks: [INFO] [==============================] 100.0% complete 输出显示容器映像已构建并推送到注册表。\n构建优化镜像的动机和技术 我们优化的主要动机有两个：\n性能：在容器编排系统中，容器镜像从镜像仓库拉取到运行容器引擎的主机上。这个过程称为调度。从注册表中提取大型映像会导致容器编排系统中的调度时间较长以及 CI 管道中的构建时间较长。 安全性：大尺寸图像也有更大的漏洞表面积。 Docker 镜像由一堆层组成，每个层代表 Dockerfile 中的一条指令。每一层都是底层变化的增量。当我们从注册中心拉取 Docker 镜像时，它是被分层拉取并缓存在主机中的。\nSpring Boot 使用“fat JAR”作为其默认打包格式。当我们检查 fat JAR 时，我们可以看到该应用程序只占整个 JAR 的很小一部分。这是变化最频繁的部分。其余部分由 Spring 框架依赖项组成。\n优化公式的核心是将应用程序与 Spring 框架依赖项隔离到一个单独的层中。\n构成 fat JAR 大部分的依赖项层仅下载一次并缓存在主机系统中。\n在应用程序更新和容器调度期间，仅拉取应用程序的薄层，如下图所示：\n让我们在接下来的部分中了解如何为 Spring Boot 应用程序构建这些优化的映像。\n使用 Buildpack 为 Spring Boot 应用程序构建优化的容器映像 Spring Boot 2.3 通过将 fat JAR 的各个部分提取到单独的层中来支持分层。分层功能默认关闭，需要使用 Spring Boot Maven 插件显式启用：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;layers\u0026gt; \u0026lt;enabled\u0026gt;true\u0026lt;/enabled\u0026gt; \u0026lt;/layers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 我们将使用此配置首先使用 Buildpack 生成容器映像，然后在以下部分中使用 Docker 生成容器映像。\n让我们运行 Maven build-image 目标来创建容器映像：images/stock/-1200x628-branded.jpg\nmvn spring-boot:build-image 如果我们运行 Dive 来查看生成图像中的各层，我们可以看到应用程序层（以红色圈出）在千字节范围内比我们使用 fat JAR 格式获得的要小得多：\n使用 Docker 为 Spring Boot 应用程序构建优化的容器映像 我们还可以使用 Docker 文件创建分层的 JAR Docker 镜像，而不是使用 Maven 或 Gradle 插件。\n当我们使用 Docker 时，我们需要执行两个额外的步骤来提取层并将其复制到最终映像中。\n使用 Maven 构建并启用分层功能后，生成的 JAR 内容将如下所示：\nMETA-INF/ . BOOT-INF/lib/ . BOOT-INF/lib/spring-boot-jarmode-layertools-2.3.3.RELEASE.jar BOOT-INF/classpath.idx BOOT-INF/layers.idx 输出显示一个名为 spring-boot-jarmode-layertools 的附加 JAR 和一个 layersfle.idx 文件。分层功能由这个附加 JAR 提供，如下一节所述。\n取不同层中的依赖关系 要查看并从分层 JAR 中提取层，我们使用系统属性 -Djarmode=layertools 来启动 spring-boot-jarmode-layertools JAR 而不是应用程序：\njava -Djarmode=layertools -jar target/usersignup-0.0.1-SNAPSHOT.jar 运行此命令会生成包含可用命令选项的输出：\nUsage: java -Djarmode=layertools -jar usersignup-0.0.1-SNAPSHOT.jar Available commands: list List layers from the jar that can be extracted extract Extracts layers from the jar for image creation help Help about any command 输出显示命令 list 、 extract 和 help ，其中 help 是默认命令。让我们使用 list 选项运行命令：\njava -Djarmode=layertools -jar target/usersignup-0.0.1-SNAPSHOT.jar list dependencies spring-boot-loader snapshot-dependencies application 我们可以看到可以作为层添加的依赖项列表。\n默认层是：\n图层名称 内容 dependencies 版本不包含 SNAPSHOT 的任何依赖项 spring-boot-loader JAR 加载器类 snapshot-dependencies 版本包含 SNAPSHOT 的任何依赖项 application 应用程序类和资源 这些层按照应添加到 Docker 映像的顺序在 layers.idx 文件中定义。这些层在第一次拉取后会缓存在主机中，因为它们不会更改。仅将更新的应用程序层下载到主机，由于大小减小，速度更快。\n使用在单独层中提取的依赖项构建图像 我们将使用称为多阶段构建的方法分两个阶段构建最终图像。在第一阶段，我们将提取依赖项，在第二阶段，我们将提取的依赖项复制到最终映像。\n让我们修改 Docker 文件以进行多阶段构建：\n# the first stage of our build will extract the layers FROM adoptopenjdk:14-jre-hotspot as builder WORKDIR application ARG JAR_FILE=target/*.jar COPY ${JAR_FILE} application.jar RUN java -Djarmode=layertools -jar application.jar extract # the second stage of our build will copy the extracted layers FROM adoptopenjdk:14-jre-hotspot WORKDIR application COPY --from=builder application/dependencies/ ./ COPY --from=builder application/spring-boot-loader/ ./ COPY --from=builder application/snapshot-dependencies/ ./ COPY --from=builder application/application/ ./ ENTRYPOINT [\u0026#34;java\u0026#34;, \u0026#34;org.springframework.boot.loader.JarLauncher\u0026#34;] 我们将此配置保存在单独的文件中 - Dockerfile2 。\n我们使用以下命令构建 Docker 镜像：\ndocker build -f Dockerfile2 -t usersignup:v1 . 运行此命令后，我们得到以下输出：\nSending build context to Docker daemon 20.41MB Step 1/12 : FROM adoptopenjdk:14-jre-hotspot as builder 14-jre-hotspot: Pulling from library/adoptopenjdk . . Successfully built a9ebf6970841 Successfully tagged userssignup:v1 我们可以看到 Docker 镜像是使用镜像 ID 创建的，然后被标记的。\n最后，我们像以前一样运行 Dive 命令来检查生成的 Docker 镜像内的层。我们可以指定图像 ID 或标签作为 Dive 命令的输入：\ndive userssignup:v1 正如我们在输出中看到的，包含应用程序的层现在只有 11 kB，依赖项缓存在单独的层中。\n提取不同层中的内部依赖关系 我们可以通过在单独的层中提取任何自定义依赖项来进一步减小应用程序层的大小，而不是通过在名为 layers.idx 的 yml 类似文件中声明它们来将它们与应用程序一起打包：\n- \u0026#34;dependencies\u0026#34;: - \u0026#34;BOOT-INF/lib/\u0026#34; - \u0026#34;spring-boot-loader\u0026#34;: - \u0026#34;org/\u0026#34; - \u0026#34;snapshot-dependencies\u0026#34;: - \u0026#34;custom-dependencies\u0026#34;: - \u0026#34;io/myorg/\u0026#34; - \u0026#34;application\u0026#34;: - \u0026#34;BOOT-INF/classes/\u0026#34; - \u0026#34;BOOT-INF/classpath.idx\u0026#34; - \u0026#34;BOOT-INF/layers.idx\u0026#34; - \u0026#34;META-INF/\u0026#34; 在此文件中 - layers.idx 我们添加了一个名为 io.myorg 的自定义依赖项，其中包含从共享存储库中提取的组织依赖项。\n结论 在本文中，我们研究了使用云原生 Buildpack 直接从源代码创建容器映像。这是使用 Docker 构建容器映像的传统方式的替代方案，首先构建 fat 可执行 JAR，然后通过在 Dockerfile 中指定指令将其打包到容器映像中。\n我们还考虑通过启用分层功能来优化我们的容器，该功能提取缓存在主机中的单独层中的依赖项，并在容器运行时引擎的调度期间下载应用程序的薄层。\n文章中使用的所有源码可以参考Github上的。\n命令参考 以下是我们在本文中使用的命令摘要，以供快速参考。\n清洁我们的环境：\ndocker system prune -a 使用 Docker 文件构建容器镜像：\ndocker build -f \u0026lt;Docker file name\u0026gt; -t \u0026lt;tag\u0026gt; . 从源代码构建容器镜像（没有 Dockerfile）：\nmvn spring-boot:build-image 查看依赖关系层。在构建应用程序 JAR 之前，确保在 spring-boot-maven-plugin 中启用分层功能：\njava -Djarmode=layertools -jar application.jar list 提取依赖层。在构建应用程序 JAR 之前，确保在 spring-boot-maven-plugin 中启用分层功能：\njava -Djarmode=layertools -jar application.jar extract 查看容器镜像列表\ndocker images 查看容器镜像内的层（确保已安装 dive tool 工具）：\ndive \u0026lt;image ID or image tag\u0026gt; 原文链接：https://reflectoring.io/spring-boot-docker/\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-boot-docker/","summary":"容器已成为打包具有所有软件和操作系统依赖项的应用程序，然后将其传送到不同环境的首选方式。\n本文着眼于容器化 Spring Boot 应用程序的不同方法：\n使用 Docker 文件构建 Docker 镜像， 使用 Cloud-Native Buildpack 从源代码构建 OCI 映像， 通过使用分层工具将 JAR 的各个部分拆分为不同的层，在运行时优化映像。 示例代码 本文附有 GitHub 上的工作代码示例。\n容器术语 我们将从整篇文章中使用的容器术语开始：\nContainer image: 具有特定格式的文件。我们通过运行构建工具将应用程序转换为容器映像。 Container: 容器镜像的运行时实例。 Container engine: t 负责运行 Container 的守护进程。 Container host: 容器引擎运行的主机。 Container registry: 用于发布和分发容器映像的共享位置。 OCI Standard: 开放容器倡议 (OCI) 是在 Linux 基金会下形成的一个轻量级、开放的治理结构。 OCI 镜像规范定义了容器镜像格式和运行时的行业标准，以确保所有容器引擎都可以运行任何构建工具生成的容器镜像。 为了容器化应用程序，我们将应用程序封装在容器映像中，并将该映像发布到共享注册表。容器运行时从注册表中提取该映像，解压该映像，然后在其中运行应用程序。\nSpring Boot 2.3 版本提供了用于构建 OCI 映像的插件。\nDocker 恰好是最常用的容器实现，并且我们在示例中使用 Docker，因此本文中所有后续对容器的引用都将指 Docker。\n以传统方式构建容器镜像 通过向 Docker 文件添加一些指令，可以非常轻松地创建 Spring Boot 应用程序的 Docker 镜像。\n我们首先构建一个可执行 JAR，并作为 Docker 文件指令的一部分，在应用必要的自定义后将可执行 JAR 复制到基本 JRE 映像上。\n让我们从 Spring Initializr 创建带有 web 、 lombok 和 actuator 依赖项的 Spring Boot 应用程序。我们还添加了一个休息控制器来使用 GET 方法公开 API。\n创建 Docker 文件 接下来，我们通过添加 Dockerfile 来容器化该应用程序：","title":"[译]为 Spring Boot 应用程序创建优化的 Docker 映像"},{"content":"您可以使用本指南来了解 Spring Security 是什么以及其核心功能（如身份验证、授权或常见漏洞保护）如何工作。此外，还有全面的常见问题解答。\n（编者注：大约 6500 字，您可能不想尝试在移动设备上阅读本文。将其添加为书签，稍后再回来。）\n介绍 迟早每个人都需要为其项目添加安全性，在 Spring 生态系统中，您可以借助 Spring Security 库来实现这一点。\n因此，您继续将 Spring Security 添加到您的 Spring Boot（或普通 Spring）项目中，然后突然……​\n\u0026hellip;您有自动生成的登录页面。 \u0026hellip;您无法再执行 POST 请求。 \u0026hellip;​ 您的整个应用程序处于锁定状态，并提示您输入用户名和密码。 在经历了随后的精神崩溃之后，您可能会对这一切是如何运作的感兴趣。\n什么是 Spring Security 以及它是如何工作的？ 简短的回答： 从本质上讲，Spring Security 实际上只是一堆 servlet 过滤器，可帮助您向 Web 应用程序添加身份验证和授权。 它还与 Spring Web MVC（或 Spring Boot）等框架以及 OAuth2 或 SAML 等标准很好地集成。它会自动生成登录/注销页面并防止 CSRF 等常见漏洞。 现在，这并没有什么帮助，不是吗？ 幸运的是，还有一个很长的答案：本文的其余部分。\n网络应用程序安全：101 在成为 Spring Security 大师之前，您需要了解三个重要概念：\nAuthentication 验证 Authorization 授权 Servlet Filters 过滤器 建议：不要跳过本节，因为它是 Spring Security 所做的一切的基础。另外，我会让它尽可能有趣。\n1. 认证 首先，如果您正在运行典型的（Web）应用程序，您需要用户进行身份验证。这意味着您的应用程序需要验证用户是否是他所声称的人，通常通过用户名和密码检查来完成。\n用户：“我是美国总统。我的 *username* 是：potus！” 您的网络应用程序：“当然可以，那么您的 *password* 是什么，总统先生？” 用户：“我的密码是：th3don4ld”。 您的网络应用程序：“正确。欢迎，先生！”\n2、授权 在更简单的应用程序中，身份验证可能就足够了：用户经过身份验证后，她就可以访问应用程序的每个部分。\n但大多数应用程序都有权限（或角色）的概念。想象一下：可以访问您的网上商店面向公众的前端的客户，以及可以访问单独管理区域的管理员。\n两种类型的用户都需要登录，但身份验证这一事实并不能说明他们可以在系统中执行哪些操作。因此，您还需要检查经过身份验证的用户的权限，即您需要授权该用户。\n用户：“让我玩那个核足球\u0026hellip;\u0026hellip;”。 您的网络应用程序：“等一下，我需要先检查您的 *permissions* ……是的，总统先生，您拥有正确的许可级别。尽情享受吧。” 用户：“那个红色按钮又是什么……​？”\n3.Servlet 过滤器 最后但并非最不重要的一点是，让我们看一下 Servlet 过滤器。它们与身份验证和授权有什么关系？ （如果您对 Java Servlet 或 Filter 完全陌生，我建议您阅读旧的但仍然非常有效的 Head First Servlets 书。）\n为什么使用 Servlet 过滤器？ 回想一下我的另一篇文章，我们发现基本上任何 Spring Web 应用程序都只是一个 servlet：Spring 的旧式 DispatcherServlet，它将传入的 HTTP 请求（例如来自浏览器）重定向到 @Controllers 或 @RestControllers。 问题是：DispatcherServlet 中没有硬编码安全性，而且您也很可能不想在 @Controllers 中摸索原始 HTTP Basic Auth 标头。最佳情况下，身份验证和授权应该在请求到达 @Controller 之前完成。 幸运的是，在 Java Web 世界中有一种方法可以做到这一点：您可以将过滤器放在 servlet 前面，这意味着您可以考虑编写一个 SecurityFilter 并在 Tomcat（servlet 容器/应用程序服务器）中配置它来过滤每个传入的内容 HTTP 请求在到达您的 servlet 之前。\n一个原生的安全过滤器 SecurityFilter 大约有 4 个任务，简单且过于简化的实现可能如下所示：\nimport javax.servlet.*; import javax.servlet.http.HttpFilter; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; public class SecurityServletFilter extends HttpFilter { @Override protected void doFilter(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws IOException, ServletException { UsernamePasswordToken token = extractUsernameAndPasswordFrom(request); // (1) if (notAuthenticated(token)) { // (2) // either no or wrong username/password // unfortunately the HTTP status code is called \u0026#34;unauthorized\u0026#34;, instead of \u0026#34;unauthenticated\u0026#34; response.setStatus(HttpServletResponse.SC_UNAUTHORIZED); // HTTP 401. return; } if (notAuthorized(token, request)) { // (3) // you are logged in, but don\u0026#39;t have the proper rights response.setStatus(HttpServletResponse.SC_FORBIDDEN); // HTTP 403 return; } // allow the HttpRequest to go to Spring\u0026#39;s DispatcherServlet // and @RestControllers/@Controllers. chain.doFilter(request, response); // (4) } private UsernamePasswordToken extractUsernameAndPasswordFrom(HttpServletRequest request) { // Either try and read in a Basic Auth HTTP Header, which comes in the form of user:password // Or try and find form login request parameters or POST bodies, i.e. \u0026#34;username=me\u0026#34; \u0026amp; \u0026#34;password=\u0026#34;myPass\u0026#34; return checkVariousLoginOptions(request); } private boolean notAuthenticated(UsernamePasswordToken token) { // compare the token with what you have in your database...or in-memory...or in LDAP... return false; } private boolean notAuthorized(UsernamePasswordToken token, HttpServletRequest request) { // check if currently authenticated user has the permission/role to access this request\u0026#39;s /URI // e.g. /admin needs a ROLE_ADMIN , /callcenter needs ROLE_CALLCENTER, etc. return false; } } 首先，过滤器需要从请求中提取用户名/密码。它可以通过基本身份验证 HTTP 标头、表单字段或 cookie 等实现。 然后，过滤器需要根据某些内容（例如数据库）验证用户名/密码组合。 成功验证后，过滤器需要检查用户是否有权访问所请求的 URI。 如果请求通过了所有这些检查，那么过滤器可以让请求传递到您的 DispatcherServlet，即您的 @Controller。 过滤器链 现实检查：虽然上述代码可以编译，但它迟早会导致一个怪物过滤器，其中包含大量用于各种身份验证和授权机制的代码。\n然而，在现实世界中，您可以将这个过滤器拆分为多个过滤器，然后将它们链接在一起。\n例如，传入的 HTTP 请求将\u0026hellip;​\n首先，通过 LoginMethodFilter\u0026hellip;​ 然后，通过 AuthenticationFilter\u0026hellip;​ 然后，通过授权过滤器\u0026hellip;​ 最后，点击您的 servlet。 这个概念称为 FilterChain，上面过滤器中的最后一个方法调用实际上委托给了该链：\nchain.doFilter(request, response); 使用这样的过滤器（链），您基本上可以处理应用程序中存在的每个身份验证或授权问题，而无需更改实际的应用程序实现（想想：您的@RestControllers / @Controllers）。\n有了这些知识，让我们看看 Spring Security 如何利用这种过滤魔法。\nFilterChain 和安全配置 DSL 我们将从 Spring Security 的 FilterChain 开始，以与上一章相反的方向开始介绍 Spring Security。\nSpring 的 DefaultSecurityFilterChain 假设您正确设置了 Spring Security，然后启动您的 Web 应用程序。您将看到以下日志消息：\n2020-02-25 10:24:27.875 INFO 11116 --- [ main] o.s.s.web.DefaultSecurityFilterChain : Creating filter chain: any request, [org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter@46320c9a, org.springframework.security.web.context.SecurityContextPersistenceFilter@4d98e41b, org.springframework.security.web.header.HeaderWriterFilter@52bd9a27, org.springframework.security.web.csrf.CsrfFilter@51c65a43, org.springframework.security.web.authentication.logout.LogoutFilter@124d26ba, org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter@61e86192, org.springframework.security.web.authentication.ui.DefaultLoginPageGeneratingFilter@10980560, org.springframework.security.web.authentication.ui.DefaultLogoutPageGeneratingFilter@32256e68, org.springframework.security.web.authentication.www.BasicAuthenticationFilter@52d0f583, org.springframework.security.web.savedrequest.RequestCacheAwareFilter@5696c927, org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter@5f025000, org.springframework.security.web.authentication.AnonymousAuthenticationFilter@5e7abaf7, org.springframework.security.web.session.SessionManagementFilter@681c0ae6, org.springframework.security.web.access.ExceptionTranslationFilter@15639d09, org.springframework.security.web.access.intercept.FilterSecurityInterceptor@4f7be6c8]| 如果将这一行展开到列表中，看起来 Spring Security 不仅仅安装一个过滤器，而是安装由 15 个（！）不同过滤器组成的整个过滤器链。\n因此，当 HTTPRequest 传入时，它将通过所有这 15 个过滤器，然后您的请求最终到达 @RestControllers。顺序也很重要，从列表的顶部开始一直到底部。\n分析 Spring 的 FilterChain 详细查看该链中的每个过滤器就太过分了，但这里是对其中一些过滤器的解释。请随意查看 Spring Security 的源代码以了解其他过滤器。\nBasicAuthenticationFilter: 尝试在请求中查找基本身份验证 HTTP 标头，如果找到，则尝试使用标头的用户名和密码对用户进行身份验证。 UsernamePasswordAuthenticationFilter: T 尝试查找用户名/密码请求参数/POST 正文，如果找到，则尝试使用这些值对用户进行身份验证。 DefaultLoginPageGeneratingFilter: 如果您没有明确禁用该功能，则为您生成登录页面。这个过滤器就是您在启用 Spring Security 时获得默认登录页面的原因。 DefaultLogoutPageGeneratingFilter: 如果您没有明确禁用该功能，则为您生成一个注销页面。 FilterSecurityInterceptor: 是否经过您的授权。 因此，通过这两个过滤器，Spring Security 为您提供了一个登录/注销页面，以及使用基本身份验证或表单登录进行登录的能力，以及一些额外的好东西，例如 CsrfFilter，我们将有一个稍后再看。\n中场休息：这些过滤器大部分是 Spring Security。不多也不少。他们做所有的工作。剩下的就是配置它们的工作方式，即要保护哪些 URL、要忽略哪些 URL 以及使用哪些数据库表进行身份验证。\n因此，接下来我们需要看看如何配置 Spring Security。\n如何配置 Spring Security：WebSecurityConfigurerAdapter 使用最新的 Spring Security 和/或 Spring Boot 版本，配置 Spring Security 的方法是使用一个类：\n使用@EnableWebSecurity 进行注释。 扩展 WebSecurityConfigurer，它基本上为您提供配置 DSL/方法。使用这些方法，您可以指定应用程序中要保护的 URI 或要启用/禁用的漏洞利用保护。 典型的 WebSecurityConfigurerAdapter 如下所示：\n@Configuration @EnableWebSecurity // (1) public class WebSecurityConfig extends WebSecurityConfigurerAdapter { // (1) @Override protected void configure(HttpSecurity http) throws Exception { // (2) http .authorizeRequests() .antMatchers(\u0026#34;/\u0026#34;, \u0026#34;/home\u0026#34;).permitAll() // (3) .anyRequest().authenticated() // (4) .and() .formLogin() // (5) .loginPage(\u0026#34;/login\u0026#34;) // (5) .permitAll() .and() .logout() // (6) .permitAll() .and() .httpBasic(); // (7) } } 带有 @EnableWebSecurity 注释的普通 Spring @Configuration，从 WebSecurityConfigurerAdapter 扩展。 通过重写适配器的 configure(HttpSecurity)方法，您将获得一个漂亮的小 DSL，您可以用它来配置您的 FilterChain。 所有发送至 */* 和 */home* 的请求均被允许（允许） - 用户无需进行身份验证。您正在使用 antMatcher，这意味着您还可以在字符串中使用通配符（*、**、?）。 任何其他请求都需要首先对用户进行身份验证，即用户需要登录。 您允许使用自定义登录页面（ */login* ，即不是 Spring Security 自动生成的）进行表单登录（表单中的用户名/密码）。任何人都应该能够访问登录页面，而不必先登录（permitAll；否则我们就会遇到第 22 条军规！）。 注销页面也是如此 最重要的是，您还允许基本身份验证，即发送 HTTP 基本身份验证标头进行身份验证。 如何使用 Spring Security 的配置 DSL 习惯该 DSL 需要一些时间，但您可以在常见问题解答部分找到更多示例：AntMatchers：常见示例。\n现在重要的是，您可以在这个 *configure* 方法中指定：\n要保护哪些 URL (authenticated()) 以及允许哪些 URL (permitAll())。 允许哪些身份验证方法（formLogin()、httpBasic()）以及它们的配置方式。 简而言之：您的应用程序的完整安全配置。 注意：您不需要立即覆盖适配器的配置方法，因为它带有一个非常合理的实现 - 默认情况下。它看起来是这样的：\npublic abstract class WebSecurityConfigurerAdapter implements WebSecurityConfigurer\u0026lt;WebSecurity\u0026gt; { protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .anyRequest().authenticated() // (1) .and() .formLogin().and() // (2) .httpBasic(); // (3) } } 要访问应用程序上的任何 URI ( *anyRequest()* )，您需要进行身份验证 (authenticated())。 启用默认设置的表单登录 ( *formLogin()* )。 HTTP 基本身份验证 ( *httpBasic()* ) 也是如此。 此默认配置就是您的应用程序在添加 Spring Security 后立即处于锁定状态的原因。很简单，不是吗？\n总结：WebSecurityConfigurerAdapter 的 DSL 配置 我们了解到 Spring Security 由几个使用 WebSecurityConfigurerAdapter @Configuration 类配置的过滤器组成。\n但缺少一个关键的部分。我们以 Spring 的 BasicAuthFilter 为例。它可以从 HTTP Basic Auth 标头中提取用户名/密码，但它根据什么来验证这些凭据呢？\n这自然引出了我们的问题：身份验证如何与 Spring Security 一起工作。\n使用 Spring Security 进行身份验证 当涉及到身份验证和 Spring Security 时，您大致会遇到三种情况：\n默认值：您可以访问用户的（散列）密码，因为您将他的详细信息（用户名、密码）保存在例如一个数据库表。 不太常见：您无法访问用户的（散列）密码。如果您的用户和密码存储在其他地方（例如提供 REST 身份验证服务的第三方身份管理产品），就会出现这种情况。想想：Atlassian Crowd。 也很受欢迎：您想使用 OAuth2 或“使用 Google/Twitter/等登录”。 (OpenID)，可能与 JWT 结合使用。那么以下内容都不适用，您应该直接进入 OAuth2 章节。 注意：根据您的场景，您需要指定不同的 @Bean 才能使 Spring Security 正常工作，否则您最终会得到非常混乱的异常（例如，如果您忘记指定 PasswordEncoder，则会出现 NullPointerException）。记住这一点。\n让我们看一下最重要的两个场景。\n1. UserDetailsService：获取用户密码 假设您有一个存储用户的数据库表。它有几列，但最重要的是它有一个用户名和密码列，您可以在其中存储用户的散列（！）密码。\ncreate table users (id int auto_increment primary key, username varchar(255), password varchar(255)); 在这种情况下，Spring Security 需要您定义两个 bean 来启动并运行身份验证。\n用户详细信息服务。 密码编码器。 指定 UserDetailsS​​ervice 就这么简单：\n@Bean public UserDetailsService userDetailsService() { return new MyDatabaseUserDetailsService(); // (1) } MyDatabaseUserDetailsS​​ervice 实现了 UserDetailsS​​ervice，这是一个非常简单的接口，它由一个返回 UserDetails 对象的方法组成： public class MyDatabaseUserDetailsService implements UserDetailsService { UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { // (1) // 1. Load the user from the users table by username. If not found, throw UsernameNotFoundException. // 2. Convert/wrap the user to a UserDetails object and return it. return someUserDetails; } } public interface UserDetails extends Serializable { // (2) String getUsername(); String getPassword(); // \u0026lt;3\u0026gt; more methods: // isAccountNonExpired,isAccountNonLocked, // isCredentialsNonExpired,isEnabled } UserDetailsS​​ervice 通过用户的用户名加载 UserDetails。请注意，该方法仅采用一个参数：用户名（而不是密码）。 UserDetails 接口具有获取（散列！）密码的方法和获取用户名的方法。 UserDetails 有更多方法，例如帐户处于活动状态还是被阻止、凭据是否已过期或用户拥有什么权限 - 但我们不会在这里介绍它们。 因此，您可以像我们上面那样自己实现这些接口，也可以使用 Spring Security 提供的现有接口。\n现成的实施 简单说明一下：您始终可以自己实现 UserDetailsS​​ervice 和 UserDetails 接口。\n但是，您还会发现 Spring Security 提供的现成实现，您可以使用/配置/扩展/覆盖。\nJdbcUserDetailsManager, 这是一个基于 JDBC（数据库）的 UserDetailsS​​ervice。您可以配置它以匹配您的用户表/列结构。 InMemoryUserDetailsManager, 它将所有用户详细信息保留在内存中，非常适合测试。 org.springframework.security.core.userdetail.User, 这是您可以使用的合理的默认 UserDetails 实现。这意味着实体/数据库表和此用户类之间可能存在映射/复制。或者，您可以简单地让您的实体实现 UserDetails 接口。 完整的用户详细信息工作流程：HTTP 基本身份验证 现在回想一下您的 HTTP 基本身份验证，这意味着您正在使用 Spring Security 和基本身份验证来保护您的应用程序。当您指定 UserDetailsS​​ervice 并尝试登录时会发生以下情况：\n从过滤器中的 HTTP Basic Auth 标头中提取用户名/密码组合。您无需为此做任何事情，它会在幕后发生。 调用 MyDatabaseUserDetailsS​​ervice 从数据库加载相应的用户，包装为 UserDetails 对象，该对象公开用户的哈希密码。 从 HTTP Basic Auth 标头中获取提取的密码，自动对其进行哈希处理，并将其与 UserDetails 对象中的哈希密码进行比较。如果两者匹配，则用户身份验证成功。 这里的所有都是它的。但是等一下，Spring Security 如何对来自客户端的密码进行哈希处理（步骤 3）？用什么算法？\n密码编码器 Spring Security 无法神奇地猜测您首选的密码哈希算法。这就是为什么你需要指定另一个@Bean，一个 PasswordEncoder。例如，如果您想对所有密码使用 BCrypt 密码哈希函数（Spring Security 的默认值），则可以在 SecurityConfig 中指定此 @Bean。\n@Bean public BCryptPasswordEncoder bCryptPasswordEncoder() { return new BCryptPasswordEncoder(); } 如果您有多种密码哈希算法，因为您有一些旧用户的密码是使用 MD5 存储的（不要这样做），而较新的用户则使用 Bcrypt 甚至是 SHA-256 等第三种算法，该怎么办？然后您将使用以下编码器：\n@Bean public PasswordEncoder passwordEncoder() { return PasswordEncoderFactories.createDelegatingPasswordEncoder(); } 这个委托编码器如何工作？它将查看 UserDetail 的哈希密码（来自例如您的数据库表），该密码现在必须以 *{prefix}* 开头。那个前缀，就是你的哈希方法！您的数据库表将如下所示：\nusername 用户名 password 密码 john@doe.com {bcrypt}$2y$12$6t86Rpr3llMANhCUt26oUen2WhvXr/A89Xo9zJion8W7gWgZ/zA0C {bcrypt}$2y$12$6t86Rpr3llMANhCUt26oUen2WhvXr/A89Xo9zJion8W7gWgZ/zA0C my@user.com {sha256}5ffa39f5757a0dad5dfada519d02c6b71b61ab1df51b4ed1f3beed6abe0ff5f6 {sha256}5ffa39f5757a0dad5dfada519d02c6b71b61ab1df51b4ed1f3beed6abe0ff5f6 Spring Security 将：\n读入这些密码并去掉前缀（ {bcrypt} 或 {sha256} ）。 根据前缀值，使用正确的密码编码器（即 BCryptEncoder 或 SHA256Encoder） 使用该密码编码器对传入的原始密码进行哈希处理，并将其与存储的密码进行比较。 这就是密码编码器的全部内容。\n摘要：获取用户密码 本节的要点是：如果您使用 Spring Security 并有权访问用户的密码，那么：\n指定 UserDetailsS​​ervice。要么是自定义实现，要么使用并配置 Spring Security 提供的实现。 指定密码编码器。 简而言之，这就是 Spring Security 身份验证。 2. AuthenticationProvider：无权访问用户的密码 现在，假设您正在使用 Atlassian Crowd 进行集中身份管理。这意味着您所有应用程序的所有用户和密码都存储在 Atlassian Crowd 中，而不再存储在数据库表中。\n这有两个含义：\n您的应用程序中不再有用户密码，因为您不能要求 Crowd 只提供这些密码。 但是，您确实有一个 REST API，您可以使用您的用户名和密码登录。 （对 */rest/usermanagement/1/authentication* REST 端点的 POST 请求）。 如果是这种情况，您不能再使用 UserDetailsS​​ervice，而是需要实现并提供 AuthenticationProvider @Bean。\n@Bean public AuthenticationProvider authenticationProvider() { return new AtlassianCrowdAuthenticationProvider(); } AuthenticationProvider 主要包含一种方法，简单的实现可能如下所示：\npublic class AtlassianCrowdAuthenticationProvider implements AuthenticationProvider { Authentication authenticate(Authentication authentication) // (1) throws AuthenticationException { String username = authentication.getPrincipal().toString(); // (1) String password = authentication.getCredentials().toString(); // (1) User user = callAtlassianCrowdRestService(username, password); // (2) if (user == null) { // (3) throw new AuthenticationException(\u0026#34;could not login\u0026#34;); } return new UserNamePasswordAuthenticationToken(user.getUsername(), user.getPassword(), user.getAuthorities()); // (4) } // other method ignored } 与只能访问用户名的 UserDetails load() 方法相比，您现在可以访问完整的身份验证尝试，通常包含用户名和密码。 您可以执行任何您想要验证用户身份的操作，例如调用 REST 服务。 如果身份验证失败，则需要抛出异常。 如果认证成功，需要返回一个完全初始化的 UsernamePasswordAuthenticationToken。它是 Authentication 接口的实现，需要将 authentiated 字段设置为 true（上面使用的构造函数会自动设置）。我们将在下一章介绍权威。 完整的 AuthenticationProvider 工作流程：HTTP 基本身份验证 现在回想一下您的 HTTP 基本身份验证，这意味着您正在使用 Spring Security 和基本身份验证来保护您的应用程序。当您指定 AuthenticationProvider 并尝试登录时会发生以下情况：\n从过滤器中的 HTTP Basic Auth 标头中提取用户名/密码组合。您无需为此做任何事情，它会在幕后发生。 使用该用户名和密码调用您的 AuthenticationProvider（例如 AtlassianCrowdAuthenticationProvider），以便您自己进行身份验证（例如 REST 调用）。 没有密码散列或类似的事情发生，因为您本质上是委托第三方进行实际的用户名/密码检查。简而言之，这就是 AuthenticationProvider 身份验证！\n摘要：身份验证提供者 本节的要点是：如果您使用 Spring Security 并且无权访问用户的密码，则实现并提供 AuthenticationProvider @Bean。\nSpring Security 授权 到目前为止，我们只讨论了身份验证，例如用户名和密码检查。\n现在让我们看一下 Spring Security 中的权限，或者更确切地说是角色和权限。\n什么是授权？ 以典型的电子商务网上商店为例。它可能由以下几部分组成：\n网上商店本身。我们假设它的 URL 是 *www.youramazinshop.com* 。 也许是呼叫中心代理的区域，他们可以登录并查看客户最近购买了什么或他们的包裹在哪里。它的 URL 可以是 *www.youramazinshop.com/callcenter* 。 一个单独的管理区域，管理员可以在其中登录和管理呼叫中心代理或网上商店的其他技术方面（如主题、性能等）。它的 URL 可以是 *www.youramazinshop.com/admin* 。 这具有以下含义，因为仅仅对用户进行身份验证已经不够了：\n客户显然不应该能够访问呼叫中心或管理区域。他只被允许在网站上购物。 呼叫中心代理不应该能够访问管理区域。 而管理员可以访问网上商店、呼叫中心区域和管理区域。 简而言之，您希望根据不同的用户的权限或角色来允许不同的访问权限。\n什么是权限？什么是角色？ 简单的：\n权限（最简单的形式）只是一个字符串，它可以是任何类似的内容：user、ADMIN、ROLE_ADMIN 或 53cr37_r0l3。 角色是具有 *ROLE_* 前缀的权限。因此，名为 *ADMIN* 的角色与名为 *ROLE_ADMIN* 的权限相同。 角色和权限之间的区别纯粹是概念性的，这常常让 Spring Security 的新手感到困惑。\n为什么角色和权限之间有区别？ 老实说，我已经阅读了 Spring Security 文档以及关于这个问题的几个相关 StackOverflow 线程，但我无法给你一个明确的、好的答案。\n什么是授予权限？什么是 SimpleGrantedAuthorities？ 当然，Spring Security 不会让你只使用字符串就可以逃脱惩罚。有一个 Java 类代表您的权限 String，一个流行的类是 SimpleGrantedAuthority。\npublic final class SimpleGrantedAuthority implements GrantedAuthority { private final String role; @Override public String getAuthority() { return role; } } （注意：还有其他权限类，可以让您在字符串旁边存储其他对象（例如主体），我不会在这里介绍它们。现在，我们将仅使用 SimpleGrantedAuthority。）\n1. UserDetailsService：在哪里存储和获取权限？ 假设您将用户存储在自己的应用程序中（想想：UserDetailsS​​ervice），您将有一个 Users 表。\n现在，您只需向其中添加一个名为“authorities”的列即可。对于本文，我在这里选择了一个简单的字符串列，尽管它可以包含多个以逗号分隔的值。或者，我也可以有一个完全独立的表 AUTHORITIES，但对于本文的范围来说，这样做就可以了。\n注意：请参阅什么是权限？什么是角色？：您将权限（即字符串）保存到数据库中。碰巧这些权限以 ROLE_ 前缀开头，因此，就 Spring Security 而言，这些权限也是角色。\nusername 用户名 password 密码 authorities 当局 john@doe.com {bcrypt}… {bcrypt}\u0026hellip; ROLEADMIN ROLE管理员 my@callcenter.com {sha256}… {sha256}… ROLE_CALLCENTER ROLE_CALLCENTER 剩下要做的唯一一件事就是调整您的 UserDetailsS​​ervice 以在该权限列中读取。\npublic class MyDatabaseUserDetailsService implements UserDetailsService { UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { User user = userDao.findByUsername(username); List\u0026lt;SimpleGrantedAuthority\u0026gt; grantedAuthorities = user.getAuthorities().map(authority -\u0026gt; new SimpleGrantedAuthority(authority)).collect(Collectors.toList()); // (1) return new org.springframework.security.core.userdetails.User(user.getUsername(), user.getPassword(), grantedAuthorities); // (2) } } 您只需将数据库列中的任何内容映射到 SimpleGrantedAuthorities 列表即可。完毕。 同样，我们在这里使用 Spring Security 的 UserDetails 基本实现。您还可以在此处使用自己的类实现 UserDetails，甚至可能不需要映射。 2. AuthenticationManager：在哪里存储和获取权限？ 当用户来自第三方应用程序（例如 Atlassian Cloud）时，您需要找出他们使用什么概念来支持当局。 Atlassian Crowd 有“角色”的概念，但不赞成使用“组”。\n因此，根据您使用的实际产品，您需要将其映射到 AuthenticationProvider 中的 Spring Security 权限。\npublic class AtlassianCrowdAuthenticationProvider implements AuthenticationProvider { Authentication authenticate(Authentication authentication) throws AuthenticationException { String username = authentication.getPrincipal().toString(); String password = authentication.getCredentials().toString(); atlassian.crowd.User user = callAtlassianCrowdRestService(username, password); // (1) if (user == null) { throw new AuthenticationException(\u0026#34;could not login\u0026#34;); } return new UserNamePasswordAuthenticationToken(user.getUsername(), user.getPassword(), mapToAuthorities(user.getGroups())); // (2) } // other method ignored } 注意：这不是实际的 Atlassian Crowd 代码，但达到了其目的。您针对 REST 服务进行身份验证并获取 JSON User 对象，然后该对象将转换为 atlassian.crowd.User 对象。 该用户可以是一个或多个组的成员，此处假定这些组只是字符串。然后，您可以简单地将这些组映射到 Spring 的“SimpleGrantedAuthority”。 重新审视 WebSecurityConfigurerAdapter 到目前为止，我们讨论了很多有关在 Spring Security 中存储和检索经过身份验证的用户的权限的内容。但是如何使用 Spring Security 的 DSL 保护具有不同权限的 URL？简单的：\n@Configuration @EnableWebSecurity public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\u0026#34;/admin\u0026#34;).hasAuthority(\u0026#34;ROLE_ADMIN\u0026#34;) // (1) .antMatchers(\u0026#34;/callcenter\u0026#34;).hasAnyAuthority(\u0026#34;ROLE_ADMIN\u0026#34;, \u0026#34;ROLE_CALLCENTER\u0026#34;) // (2) .anyRequest().authenticated() // (3) .and() .formLogin() .and() .httpBasic(); } } 要访问 */admin* 区域，您（即用户）需要经过身份验证并拥有权限（一个简单的字符串）ROLE_ADMIN。 要访问 */callcenter* 区域，您需要经过身份验证并拥有权限 ROLE_ADMIN 或 ROLE_CALLCENTER。 对于任何其他请求，您不需要特定角色，但仍需要进行身份验证。 请注意，上面的代码 (1,2) 等效于以下内容：\nhttp .authorizeRequests() .antMatchers(\u0026#34;/admin\u0026#34;).hasRole(\u0026#34;ADMIN\u0026#34;) // (1) .antMatchers(\u0026#34;/callcenter\u0026#34;).hasAnyRole(\u0026#34;ADMIN\u0026#34;, \u0026#34;CALLCENTER\u0026#34;) // (2) 现在，您不再调用“hasAuthority”，而是调用“hasRole”。注意：Spring Security 将在经过身份验证的用户上查找名为 *ROLE_ADMIN* 的权限。 现在，您不再调用“hasAnyAuthority”，而是调用“hasAnyRole”。注意：Spring Security 将在经过身份验证的用户上查找名为 *ROLE_ADMIN* 或 *ROLE_CALLCENTER* 的权限。 hasAccess 和 SpEL 最后但并非最不重要的一点是，配置授权的最强大方法是使用访问方法。它允许您指定几乎任何有效的 SpEL 表达式。\nhttp .authorizeRequests() .antMatchers(\u0026#34;/admin\u0026#34;).access(\u0026#34;hasRole(\u0026#39;admin\u0026#39;) and hasIpAddress(\u0026#39;192.168.1.0/24\u0026#39;) and @myCustomBean.checkAccess(authentication,request)\u0026#34;) // (1) 您正在检查用户是否具有 ROLE_ADMIN、特定的 IP 地址以及自定义 bean 检查。 要全面了解 Spring 基于表达式的访问控制的功能，请查看官方文档。\n常见漏洞保护 Spring Security 可以帮助您防范多种常见攻击。它从计时攻击开始（即 Spring Security 始终会在登录时对提供的密码进行哈希处理，即使用户不存在），最终提供针对缓存控制攻击、内容嗅探、点击劫持、跨站点脚本等的保护。\n在本指南的范围内不可能详细介绍每种攻击。因此，我们只会关注一种最让大多数 Spring Security 新手望而却步的保护措施：跨站点请求伪造。\n跨站请求伪造：CSRF 如果您对 CSRF 完全陌生，您可能需要观看此 YouTube 视频来快速了解它。然而，快速的结论是，默认情况下 Spring Security 使用有效的 CSRF 令牌保护任何传入的 POST（或 PUT/DELETE/PATCH）请求。\n这意味着什么？\nCSRF 和服务器端渲染的 HTML 想象一下银行转账表单或任何表单（如登录表单），这些表单是由 @Controller 借助 Thymeleaf 或 Freemarker 等模板技术呈现的。\n\u0026lt;form action=\u0026#34;/transfer\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;!-- 1 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;amount\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;routingNumber\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;account\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Transfer\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; 启用 Spring Security 后，您将无法再提交该表单。因为 Spring Security 的 CSRFFilter 正在任何 POST (PUT/DELETE) 请求上寻找额外的隐藏参数：所谓的 CSRF 令牌。\n默认情况下，它会为每个 HTTP 会话生成这样的令牌并将其存储在那里。您需要确保将其注入到您的任何 HTML 表单中。\nCSRF 令牌和 Thymeleaf 由于 Thymeleaf 与 Spring Security 具有良好的集成（当与 Spring Boot 一起使用时），您只需将以下代码片段添加到任何表单中，您就可以将令牌从会话中自动注入到您的表单中。更好的是，如果您在表单中使用“th:action”，Thymeleaf 会自动为您注入该隐藏字段，而无需手动执行。\n\u0026lt;form action=\u0026#34;/transfer\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;!-- 1 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;amount\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;routingNumber\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;account\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Transfer\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;${_csrf.parameterName}\u0026#34; value=\u0026#34;${_csrf.token}\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;!-- OR --\u0026gt; \u0026lt;form th:action=\u0026#34;/transfer\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;!-- 2 --\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;amount\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;routingNumber\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;account\u0026#34; /\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Transfer\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; 在这里，我们手动添加 CSRF 参数。 在这里，我们使用 Thymeleaf 的表单支持。 注意：有关 Thymeleaf 的 CSRF 支持的更多信息，请参阅官方文档。\nCSRF 和其他模板库 我无法涵盖本节中的所有模板库，但作为最后的手段，您始终可以将 CSRFToken 注入到任何 @Controller 方法中，然后将其简单地添加到模型中以在视图中呈现它或直接作为 HttpServletRequest 请求属性访问它。\n@Controller public class MyController { @GetMaping(\u0026#34;/login\u0026#34;) public String login(Model model, CsrfToken token) { // the token will be injected automatically return \u0026#34;/templates/login\u0026#34;; } } CSRF 和 React 或 Angular 对于 Javascript 应用程序来说，情况有些不同，例如 React 或 Angular 单页应用程序。您需要执行以下操作：\n配置 Spring Security 以使用 CookieCsrfTokenRepository，它将把 CSRFToken 放入 cookie“XSRF-TOKEN”（并将其发送到浏览器）。 让您的 Javascript 应用程序采用该 cookie 值，并将其作为“X-XSRF-TOKEN”标头与每个 POST(/PUT/PATCH/DELETE) 请求一起发送。 有关完整的复制粘贴 React 示例，请查看这篇精彩的博客文章：https://developer.okta.com/blog/2018/07/19/simple-crud-react-and-spring-boot。\n禁用 CSRF 如果您仅提供无状态 REST API，其中 CSRF 保护没有任何意义，您将完全禁用 CSRF 保护。您将这样做：\n@EnableWebSecurity @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable(); } } OAuth2 Spring Security 的 OAuth2 集成是一个复杂的主题，另外 7,000 字就足够了，这不属于本文的范围。\nSpring 集成 Spring Security \u0026amp; Spring Framework 在本文的大部分内容中，您仅在应用程序的 Web 层上指定了安全配置。您使用 antMatcher 或 regexMatchers 以及 WebSecurityConfigurerAdapter 的 DSL 来保护某些 URL。这是一种完美且标准的安全方法。\n除了保护您的网络层之外，还有“纵深防御”的想法。这意味着除了保护 URL 之外，您可能还想保护业务逻辑本身。想想：你的@Controllers、@Components、@Services 甚至@Repositories。简而言之，就是您的 Spring beans。\n方法安全性 该方法称为 *method security* 并通过注释工作，您基本上可以将这些注释放在 Spring bean 的任何公共方法上。您还需要通过在 ApplicationContextConfiguration 上放置 @EnableGlobalMethodSecurity 注释来显式启用方法安全性。\n@Configuration @EnableGlobalMethodSecurity( prePostEnabled = true, // (1) securedEnabled = true, // (2) jsr250Enabled = true) // (3) public class YourSecurityConfig extends WebSecurityConfigurerAdapter{ } prePostEnabled 属性启用对 Spring 的 *@PreAuthorize* 和 *@PostAuthorize* 注释的支持。支持意味着，除非您将标志设置为 true，否则 Spring 将忽略此注释。 secureEnabled 属性启用对 *@Secured* 注释的支持。支持意味着，除非您将标志设置为 true，否则 Spring 将忽略此注释。 jsr250Enabled 属性启用对 *@RolesAllowed* 注释的支持。支持意味着，除非您将标志设置为 true，否则 Spring 将忽略此注释。 @PreAuthorize、@Secured 和 @RolesAllowed 之间有什么区别？ @Secured 和 @RolesAllowed 基本上是相同的，尽管 @Secured 是 Spring 特定的注释，带有 spring-security-core 依赖项，而 @RolesAllowed 是一个标准化注释，存在于 javax.annotation-api 依赖项中。两个注释都采用权限/角色字符串作为值。\n@PreAuthorize/@PostAuthorize 也是（较新的）Spring 特定注释，并且比上述注释更强大，因为它们不仅可以包含权限/角色，还可以包含任何有效的 SpEL 表达式。\n最后，如果您尝试使用权限/角色不足访问受保护的方法，所有这些注释都会引发 *AccessDeniedException* 。\n那么，让我们最终看看这些注释的实际效果。\n@Service public class SomeService { @Secured(\u0026#34;ROLE_CALLCENTER\u0026#34;) // (1) // == @RolesAllowed(\u0026#34;ADMIN\u0026#34;) public BankAccountInfo get(...) { } @PreAuthorize(\u0026#34;isAnonymous()\u0026#34;) // (2) // @PreAuthorize(\u0026#34;#contact.name == principal.name\u0026#34;) // @PreAuthorize(\u0026#34;ROLE_ADMIN\u0026#34;) public void trackVisit(Long id); } } 如前所述，@Secured 将权限/角色作为参数。 @RolesAllowed，同样。注意：请记住 *@RolesAllowed(\u0026quot;ADMIN\u0026quot;)* 将检查授予的权限 *ROLE_ADMIN* 。 如前所述，@PreAuthorize 接受权限，但也接受任何有效的 SpEL 表达式。有关常见内置安全表达式（如上面的 *isAnonymous()* ）的列表，而不是编写您自己的 SpEL 表达式，请查看官方文档。 我应该使用哪个注释？ 这主要是同质性问题，而不是将自己过多地束缚于 Spring 特定的 API（这是一个经常提出的论点）。\n如果使用 @Secured，请坚持下去，不要在 28% 的其他 bean 中使用 @RolesAllowed 注释来努力标准化，但永远不会完全实现。\n首先，您始终可以使用 @Secured 并在需要时立即切换到 @PreAuthorize。\nSpring Security 和 Spring Web MVC 至于与 Spring WebMVC 的集成，Spring Security 允许您执行以下操作：\n除了 antMatchers 和 regexMatchers 之外，您还可以使用 mvcMatchers。不同之处在于，虽然 antMatchers 和 regexMatchers 基本上使用通配符匹配 URI 字符串，但 mvcMatchers 的行为与 @RequestMappings 完全相同。 将当前经过身份验证的主体注入到 @Controller/@RestController 方法中。 将当前会话 CSRFToken 注入到 @Controller/@RestController 方法中。 正确处理异步请求处理的安全性。 @Controller public class MyController { @RequestMapping(\u0026#34;/messages/inbox\u0026#34;) public ModelAndView findMessagesForUser(@AuthenticationPrincipal CustomUser customUser, CsrfToken token) { // (1) (2) // .. find messages for this user and return them ... } } 如果用户经过身份验证，@AuthenticationPrincipal 将注入主体；如果没有用户经过身份验证，则 @AuthenticationPrincipal 将注入 null。该主体是来自 UserDetailsS​​ervice/AuthenticationManager 的对象！ 或者您可以将当前会话 CSRFToken 注入每个方法中。 如果您不使用 @AuthenticationPrincipal 注释，则必须通过 SecurityContextHolder 自行获取主体。这是一种在遗留 Spring Security 应用程序中常见的技术。\n@Controller public class MyController { @RequestMapping(\u0026#34;/messages/inbox\u0026#34;) public ModelAndView findMessagesForUser(CsrfToken token) { SecurityContext context = SecurityContextHolder.getContext(); Authentication authentication = context.getAuthentication(); if (authentication != null \u0026amp;\u0026amp; authentication.getPrincipal() instanceof UserDetails) { CustomUser customUser = (CustomUser) authentication.getPrincipal(); // .. find messages for this user and return them ... } // todo } } Spring Security \u0026amp; Spring Boot 每当您将 spring-boot-starter-security 依赖项添加到 Spring Boot 项目时，Spring Boot 实际上只会为您预先配置 Spring Security。\n除此之外，所有安全配置都是通过简单的 Spring Security 概念（例如：WebSecurityConfigurerAdapter、身份验证和授权规则）完成的，这些概念本身与 Spring Boot 无关。\n因此，您在本指南中阅读的所有内容都一一适用于将 Spring Security 与 Spring Boot 结合使用。如果您不了解简单的安全性，就不要指望正确理解这两种技术如何协同工作。\nSpring Security \u0026amp; Thymeleaf Spring Security 与 Thymeleaf 集成良好。它提供了一种特殊的 Spring Security Thymeleaf 方言，允许您将安全表达式直接放入 Thymeleaf HTML 模板中。\n\u0026lt;div sec:authorize=\u0026#34;isAuthenticated()\u0026#34;\u0026gt; This content is only shown to authenticated users. \u0026lt;/div\u0026gt; \u0026lt;div sec:authorize=\u0026#34;hasRole(\u0026#39;ROLE_ADMIN\u0026#39;)\u0026#34;\u0026gt; This content is only shown to administrators. \u0026lt;/div\u0026gt; \u0026lt;div sec:authorize=\u0026#34;hasRole(\u0026#39;ROLE_USER\u0026#39;)\u0026#34;\u0026gt; This content is only shown to users. \u0026lt;/div\u0026gt; 有关这两种技术如何协同工作的完整且更详细的概述，请查看官方文档。\nFAQ Spring Security 的最新版本是什么？ 截至 2022 年 5 月，即为 5.7.1.RELEASE。\n请注意，如果您使用 Spring Boot 定义的 Spring Security 依赖项，您可能使用的是稍旧的 Spring Security 版本，例如 5.2.1。\n较旧的 Spring Security 版本是否与最新版本兼容？ Spring Security 最近经历了一些重大变化。因此，您需要找到目标版本的迁移指南并完成它们：\nSpring Security 3.x 到 4.x → https://docs.spring.io/spring-security/site/migrate/current/3-to-4/html5/migrate-3-to-4-jc.html Spring Security 4.x 到 5.x(\u0026lt; 5.3) → https://docs.spring.io/spring-security/site/docs/5.0.15.RELEASE/reference/htmlsingle/#new （不是迁移指南，但有什么新鲜事） Spring Security 5.x 到 5.3 → https://docs.spring.io/spring-security/site/docs/5.3.1.RELEASE/reference/html5/#new （不是迁移指南，而是新功能） Spring Security 最新版本 → https://docs.spring.io/spring-security/reference/whats-new.html（不是迁移指南，而是新功能） 我需要添加哪些依赖项才能使 Spring Security 正常工作？ Plain Spring Project 如果您使用的是普通 Spring 项目（不是 Spring Boot），则需要将以下两个 Maven/Gradle 依赖项添加到您的项目中：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.7.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-config\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.7.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 您还需要在 web.xml 或 Java 配置中配置 SecurityFilterChain。请参阅此处如何操作。\nSpring Boot Project 如果您正在使用 Spring Boot 项目，则需要将以下 Maven/Gradle 依赖项添加到您的项目中：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 其他所有内容都会自动为您配置，您可以立即开始编写 WebSecurityConfigurerAdapter。\n如何以编程方式访问 Spring Security 中当前经过身份验证的用户？ 正如本文中提到的，Spring Security 将当前经过身份验证的用户（或者更确切地说是 SecurityContext）存储在 SecurityContextHolder 内的线程局部变量中。您可以像这样访问它：\nSecurityContext context = SecurityContextHolder.getContext(); Authentication authentication = context.getAuthentication(); String username = authentication.getName(); Object principal = authentication.getPrincipal(); Collection\u0026lt;? extends GrantedAuthority\u0026gt; authorities = authentication.getAuthorities(); 请注意，如果您未登录，Spring Security 默认情况下会在 SecurityContextHolder 上设置 *AnonymousAuthenticationToken* 作为身份验证。这会导致一些混乱，因为人们自然会期望那里有一个 null 值。\nAntMatchers：常见示例 一个无意义的示例显示了最有用的 antMatchers （和 regexMatcher/mvcMatcher）可能性：\n@Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\u0026#34;/api/user/**\u0026#34;, \u0026#34;/api/ticket/**\u0026#34;, \u0026#34;/index\u0026#34;).hasAuthority(\u0026#34;ROLE_USER\u0026#34;) .antMatchers(HttpMethod.POST, \u0026#34;/forms/**\u0026#34;).hasAnyRole(\u0026#34;ADMIN\u0026#34;, \u0026#34;CALLCENTER\u0026#34;) .antMatchers(\u0026#34;/user/**\u0026#34;).access(\u0026#34;@webSecurity.check(authentication,request)\u0026#34;); } 如何在 Spring Security 中使用自定义登录页面？ @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .anyRequest().authenticated() .and() .formLogin() .loginPage(\u0026#34;/login\u0026#34;) // (1) .permitAll(); } 您的自定义登录页面的 URL。一旦指定此选项，自动生成的登录页面就会消失。 如何使用 Spring Security 进行编程登录？ UserDetails principal = userDetailsService.loadUserByUsername(username); Authentication authentication = new UsernamePasswordAuthenticationToken(principal, principal.getPassword(), principal.getAuthorities()); SecurityContext context = SecurityContextHolder.createEmptyContext(); context.setAuthentication(authentication); 如何仅针对某些路径禁用 CSRF？ @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().ignoringAntMatchers(\u0026#34;/api/**\u0026#34;); } Fin 如果您已经读到这里，您现在应该对 Spring Security 生态系统的复杂性有了很好的了解，即使没有 OAuth2。总结一下：\n如果您对 Spring Security 的 FilterChain 如何工作以及它的默认漏洞保护有什么基本了解（想想：CSRF），这会很有帮助。 确保了解身份验证和授权之间的区别。还有您需要为特定身份验证工作流程指定哪些 @Beans。 确保您了解 Spring Security 的 WebSecurityConfigurerAdapter 的 DSL 以及基于注释的方法安全性。 最后但并非最不重要的一点是，它有助于仔细检查 Spring Security 与其他框架和库（如 Spring MVC 或 Thymeleaf）的集成。 今天就够了，因为这真是一段旅程，不是吗？谢谢阅读！\n致谢 向 Patricio \u0026ldquo;Pato\u0026rdquo; Moschcovich 致以深深的谢意，他不仅对本文进行了校对，还提供了宝贵的反馈！\n原文链接：https://www.marcobehler.com/guides/spring-security\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security-authentication-and-authorization/","summary":"您可以使用本指南来了解 Spring Security 是什么以及其核心功能（如身份验证、授权或常见漏洞保护）如何工作。此外，还有全面的常见问题解答。\n（编者注：大约 6500 字，您可能不想尝试在移动设备上阅读本文。将其添加为书签，稍后再回来。）\n介绍 迟早每个人都需要为其项目添加安全性，在 Spring 生态系统中，您可以借助 Spring Security 库来实现这一点。\n因此，您继续将 Spring Security 添加到您的 Spring Boot（或普通 Spring）项目中，然后突然……​\n\u0026hellip;您有自动生成的登录页面。 \u0026hellip;您无法再执行 POST 请求。 \u0026hellip;​ 您的整个应用程序处于锁定状态，并提示您输入用户名和密码。 在经历了随后的精神崩溃之后，您可能会对这一切是如何运作的感兴趣。\n什么是 Spring Security 以及它是如何工作的？ 简短的回答： 从本质上讲，Spring Security 实际上只是一堆 servlet 过滤器，可帮助您向 Web 应用程序添加身份验证和授权。 它还与 Spring Web MVC（或 Spring Boot）等框架以及 OAuth2 或 SAML 等标准很好地集成。它会自动生成登录/注销页面并防止 CSRF 等常见漏洞。 现在，这并没有什么帮助，不是吗？ 幸运的是，还有一个很长的答案：本文的其余部分。\n网络应用程序安全：101 在成为 Spring Security 大师之前，您需要了解三个重要概念：\nAuthentication 验证 Authorization 授权 Servlet Filters 过滤器 建议：不要跳过本节，因为它是 Spring Security 所做的一切的基础。另外，我会让它尽可能有趣。\n1. 认证 首先，如果您正在运行典型的（Web）应用程序，您需要用户进行身份验证。这意味着您的应用程序需要验证用户是否是他所声称的人，通常通过用户名和密码检查来完成。\n用户：“我是美国总统。我的 *username* 是：potus！” 您的网络应用程序：“当然可以，那么您的 *password* 是什么，总统先生？” 用户：“我的密码是：th3don4ld”。 您的网络应用程序：“正确。欢迎，先生！”\n2、授权 在更简单的应用程序中，身份验证可能就足够了：用户经过身份验证后，她就可以访问应用程序的每个部分。\n但大多数应用程序都有权限（或角色）的概念。想象一下：可以访问您的网上商店面向公众的前端的客户，以及可以访问单独管理区域的管理员。\n两种类型的用户都需要登录，但身份验证这一事实并不能说明他们可以在系统中执行哪些操作。因此，您还需要检查经过身份验证的用户的权限，即您需要授权该用户。\n用户：“让我玩那个核足球\u0026hellip;\u0026hellip;”。 您的网络应用程序：“等一下，我需要先检查您的 *permissions* ……是的，总统先生，您拥有正确的许可级别。尽情享受吧。” 用户：“那个红色按钮又是什么……​？”\n3.Servlet 过滤器 最后但并非最不重要的一点是，让我们看一下 Servlet 过滤器。它们与身份验证和授权有什么关系？ （如果您对 Java Servlet 或 Filter 完全陌生，我建议您阅读旧的但仍然非常有效的 Head First Servlets 书。）","title":"[译]Spring Security：深入了解身份验证和授权"},{"content":"您可以使用本指南来简单实用地了解 Spring 使用 @Transactional 注释进行事务管理的工作原理。\n唯一的先决条件？您需要对 ACID 有一个粗略的了解，即什么是数据库事务以及为什么使用它们。此外，这里不讨论分布式事务或反应式事务，但就 Spring 而言，一般原则仍然适用。\n介绍 在本指南中，您将了解 Spring 核心事务抽象框架的主要支柱（这是一个令人困惑的术语，不是吗？） - 用大量代码示例进行描述：\n@Transactional （声明式事务管理）与编程式事务管理。 物理事务与逻辑事务。 Spring @Transactional 与 JPA/Hibernate 集成。 Spring @Transactional 与 Spring Boot 或 Spring MVC 集成。 回滚、代理、常见陷阱等等。 与 Spring 官方文档相反，本指南不会直接深入探讨 Spring-first 主题，从而让您感到困惑。\n相反，您将以非常规的方式学习 Spring 事务管理：从头开始，一步一步。这意味着，从普通的老式 JDBC 事务管理开始。\nWhy? 为什么？\n因为 Spring 所做的一切都是基于这些 JDBC 基础知识。如果您掌握了这些基础知识，稍后您将可以使用 Spring 的 @Transactional 注释节省大量时间。\n普通 JDBC 事务管理的工作原理 如果您在不完全了解 JDBC 事务的情况下考虑跳过本节：请不要这样做。\n如何启动、提交或回滚 JDBC 事务 第一个重要的收获是：无论您使用 Spring 的 @Transactional 注释、普通 Hibernate、jOOQ 还是任何其他数据库库，都没有关系。\n最后，它们都执行相同的操作来打开和关闭（我们称之为“管理”）数据库事务。普通的 JDBC 事务管理代码如下所示：\nimport java.sql.Connection; Connection connection = dataSource.getConnection(); // (1) try (connection) { connection.setAutoCommit(false); // (2) // execute some SQL statements... connection.commit(); // (3) } catch (SQLException e) { connection.rollback(); // (4) } 您需要连接到数据库才能启动事务。 DriverManager.getConnection（url，user，password）也可以工作，尽管在大多数企业应用程序中，您将配置一个数据源并从中获取连接。 这是在 Java 中“启动”数据库事务的唯一方法，尽管这个名字听起来有点不对劲。 setAutoCommit(true) 确保每个 SQL 语句自动包装在自己的事务中，而 setAutoCommit(false) 则相反：您是事务的主人，您需要开始调用 *commit* 标志在连接打开的整个时间内都有效，这意味着您只需调用该方法一次，而不是重复。 让我们提交我们的交易\u0026hellip;​ 或者，如果出现异常，则回滚我们的更改。 是的，这 4 行（过于简单化的）是当你使用 @Transactional 注释时 Spring 所做的一切。在下一章中，您将了解其工作原理。但在我们开始之前，您还需要学习一些知识。\n（聪明人的一个快速说明：像 HikariCP 这样的连接池库可能会根据配置自动为您切换自动提交模式。但这是一个高级主题。）\n如何使用 JDBC 隔离级别和保存点 如果您已经使用过 Spring 的 @Transactional 注释，您可能遇到过类似的情况：\n@Transactional(propagation=TransactionDefinition.NESTED, isolation=TransactionDefinition.ISOLATION_READ_UNCOMMITTED) 稍后我们将更详细地介绍嵌套 Spring 事务和隔离级别，但再次了解这些参数都可以归结为以下基本 JDBC 代码会有所帮助：\nimport java.sql.Connection; // isolation=TransactionDefinition.ISOLATION_READ_UNCOMMITTED connection.setTransactionIsolation(Connection.TRANSACTION_READ_UNCOMMITTED); // (1) // propagation=TransactionDefinition.NESTED Savepoint savePoint = connection.setSavepoint(); // (2) ... connection.rollback(savePoint); 这就是 Spring 在数据库连接上设置隔离级别的方式。不完全是火箭科学，是吗？ Spring 中的嵌套事务只是 JDBC/数据库保存点。例如，如果您不知道什么是保存点，请查看本教程。请注意，保存点支持取决于您的 JDBC 驱动程序/数据库。 Spring 或 Spring Boot 的事务管理如何工作 现在您已经对 JDBC 事务有了很好的了解，让我们看看简单的、核心的 Spring 是如何管理事务的。这里的所有内容都一一适用于 Spring Boot 和 Spring MVC，稍后会详细介绍。\nSpring 的事务管理或其（名称相当令人困惑的）事务抽象框架实际上是什么？\n请记住，事务管理简单地说就是：Spring 如何启动、提交或回滚 JDBC 事务？这听起来是不是很熟悉？\n问题是：使用普通 JDBC，您只有一种方法 (setAutocommit(false)) 来管理事务，而 Spring 为您提供了许多不同的、更方便的方法来实现相同的目的。\n如何使用 Spring 的程序化事务管理？ 在 Spring 中定义事务的第一种但很少使用的方法是通过编程方式：通过 TransactionTemplate 或直接通过 PlatformTransactionManager。从代码角度来看，它看起来像这样：\n@Service public class UserService { @Autowired private TransactionTemplate template; public Long registerUser(User user) { Long id = template.execute(status -\u0026gt; { // execute some SQL that e.g. // inserts the user into the db and returns the autogenerated id return id; }); } } 与普通 JDBC 示例相比：\n您不必自己搞乱打开或关闭数据库连接（try-finally）。相反，您使用事务回调。 您也不必捕获 SQLException，因为 Spring 会为您将这些异常转换为运行时异常。 并且您可以更好地融入 Spring 生态系统。 TransactionTemplate 将在内部使用 TransactionManager，它将使用数据源。所有这些都是您必须在 Spring 上下文配置中指定的 bean，但以后不必再担心。 虽然这算是一个小小的改进，但程序化事务管理并不是 Spring 事务框架的主要功能。相反，这都是关于声明式事务管理的。让我们看看那是什么。\n如何使用 Spring 的 XML 声明式事务管理？ 过去，当 XML 配置成为 Spring 项目的标准时，您可以直接在 XML 中配置事务。除了一些遗留的企业项目之外，您将不再在野外找到这种方法，因为它已被更简单的 @Transactional 注释所取代。\n我们不会在本指南中详细介绍 XML 配置，但您可以使用此示例作为深入研究的起点 - 如果需要的话（直接取自 Spring 官方文档）：\n\u0026lt;!-- the transactional advice (what \u0026#39;happens\u0026#39;; see the \u0026lt;aop:advisor/\u0026gt; bean below) --\u0026gt; \u0026lt;tx:advice id=\u0026#34;txAdvice\u0026#34; transaction-manager=\u0026#34;txManager\u0026#34;\u0026gt; \u0026lt;!-- the transactional semantics... --\u0026gt; \u0026lt;tx:attributes\u0026gt; \u0026lt;!-- all methods starting with \u0026#39;get\u0026#39; are read-only --\u0026gt; \u0026lt;tx:method name=\u0026#34;get*\u0026#34; read-only=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;!-- other methods use the default transaction settings (see below) --\u0026gt; \u0026lt;tx:method name=\u0026#34;*\u0026#34;/\u0026gt; \u0026lt;/tx:attributes\u0026gt; \u0026lt;/tx:advice\u0026gt; 您使用上面的 XML 块指定 AOP 建议（面向方面 ​​ 的编程），然后可以将其应用到 UserService bean，如下所示：\n\u0026lt;aop:config\u0026gt; \u0026lt;aop:pointcut id=\u0026#34;userServiceOperation\u0026#34; expression=\u0026#34;execution(* x.y.service.UserService.*(..))\u0026#34;/\u0026gt; \u0026lt;aop:advisor advice-ref=\u0026#34;txAdvice\u0026#34; pointcut-ref=\u0026#34;userServiceOperation\u0026#34;/\u0026gt; \u0026lt;/aop:config\u0026gt; \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;x.y.service.UserService\u0026#34;/\u0026gt; 您的 UserService bean 将如下所示：\npublic class UserService { public Long registerUser(User user) { // execute some SQL that e.g. // inserts the user into the db and retrieves the autogenerated id return id; } } 从 Java 代码的角度来看，这种声明式事务方法看起来比编程方法简单得多。但它会导致大量复杂、冗长的 XML，以及切入点和顾问程序配置。\n因此，这就引出了一个问题：是否有比 XML 更好的声明式事务管理方法？是的，有：@Transactional 注释。\n如何使用 Spring 的@Transactional 注解（声明式事务管理） 现在让我们看看现代 Spring 事务管理通常是什么样子的：\npublic class UserService { @Transactional public Long registerUser(User user) { // execute some SQL that e.g. // inserts the user into the db and retrieves the autogenerated id // userDao.save(user); return id; } } 这怎么可能？不再需要 XML 配置，也不需要其他代码。相反，您现在需要做两件事：\n确保您的 Spring 配置带有 @EnableTransactionManagement 注释（在 Spring Boot 中，这将自动为您完成）。 确保您在 Spring 配置中指定了事务管理器（无论如何您都需要这样做）。 然后 Spring 足够智能，可以透明地为您处理事务：您用 @Transactional 注释注释的任何 bean 的公共方法都将在数据库事务内执行（注意：存在一些陷阱）。 因此，要使 @Transactional 注释正常工作，您需要做的就是：\n@Configuration @EnableTransactionManagement public class MySpringConfig { @Bean public PlatformTransactionManager txManager() { return yourTxManager; // more on that later } } 现在，当我说 Spring 透明地为您处理事务时。那个的真实意义是什么？\n借助 JDBC 事务示例中的知识，上面的 @Transactional UserService 代码可以直接转换（简化）为：\npublic class UserService { public Long registerUser(User user) { Connection connection = dataSource.getConnection(); // (1) try (connection) { connection.setAutoCommit(false); // (1) // execute some SQL that e.g. // inserts the user into the db and retrieves the autogenerated id // userDao.save(user); \u0026lt;(2) connection.commit(); // (1) } catch (SQLException e) { connection.rollback(); // (1) } } } 这只是 JDBC 连接的标准打开和关闭。这就是 Spring 的事务注释自动为您做的事情，而无需您显式地编写它。 这是您自己的代码，通过 DAO 或类似的东西保存用户。 这个例子可能看起来有点神奇，但是让我们看看 Spring 如何为您插入这个连接代码。\nCGlib 和 JDK 代理 - @Transactional 的幕后黑手 Spring 无法真正重写您的 Java 类，就像我上面所做的那样，以插入连接代码（除非您使用字节码编织等高级技术，但我们现在忽略它）。\n你的 registerUser() 方法实际上只是调用 userDao.save(user) ，没有办法动态改变它。\n但 Spring 有一个优势。它的核心是一个 IoC 容器。它为您实例化一个 UserService 并确保将该 UserService 自动装配到任何其他需要 UserService 的 bean 中。\n现在，每当您在 bean 上使用 @Transactional 时，Spring 都会使用一个小技巧。它不仅实例化 UserService，而且还实例化该 UserService 的事务代理。\n它在 Cglib 库的帮助下通过一种称为代理通过子类化的方法来实现这一点。还有其他构建代理的方法（例如动态 JDK 代理），但我们暂时就这样吧。\n让我们看看这张图中代理的作用：\n从该图中可以看出，代理有一项工作。\n打开和关闭数据库连接/事务。 然后委托给真正的 UserService，即您编写的那个。 而其他 bean，例如 UserRestController，永远不会知道它们正在与代理通信，而不是与真实的事物通信。 快速考试\n看一下下面的源代码，告诉我 Spring 自动构造什么类型的 UserService，假设它带有 @Transactional 标记或具有 @Transactional 方法。\n@Configuration @EnableTransactionManagement public static class MyAppConfig { @Bean public UserService userService() { // (1) return new UserService(); } } 正确的。 Spring 在这里为您的 UserService 类构造一个动态 CGLib 代理，它可以为您打开和关闭数据库事务。您或任何其他 bean 甚至不会注意到它不是您的 UserService，而是包装您的 UserService 的代理。 为什么需要事务管理器（如 PlatformTransactionManager）？ 现在只缺少一条关键信息，尽管我们已经提到过几次了。\n您的 UserService 会动态被代理，并且代理会为您管理事务。但处理所有事务状态（打开、提交、关闭）的不是代理本身，而是代理委托给事务管理器。\nSpring 为您提供了 PlatformTransactionManager / TransactionManager 接口，默认情况下，它附带了一些方便的实现。其中之一是数据源事务管理器。\n它所做的正是您迄今为止所做的管理事务的操作，但首先，让我们看看所需的 Spring 配置：\n@Bean public DataSource dataSource() { return new MysqlDataSource(); // (1) } @Bean public PlatformTransactionManager txManager() { return new DataSourceTransactionManager(dataSource()); // (2) } 您可以在此处创建特定于数据库或特定于连接池的数据源。本示例使用 MySQL。 在这里，您创建事务管理器，它需要一个数据源才能管理事务。 简单如。然后，所有事务管理器都有像“doBegin”（用于启动事务）或“doCommit”这样的方法，它们看起来像这样——直接取自 Spring 的源代码并进行了一些简化：\npublic class DataSourceTransactionManager implements PlatformTransactionManager { @Override protected void doBegin(Object transaction, TransactionDefinition definition) { Connection newCon = obtainDataSource().getConnection(); // ... con.setAutoCommit(false); // yes, that\u0026#39;s it! } @Override protected void doCommit(DefaultTransactionStatus status) { // ... Connection connection = status.getTransaction().getConnectionHolder().getConnection(); try { con.commit(); } catch (SQLException ex) { throw new TransactionSystemException(\u0026#34;Could not commit JDBC transaction\u0026#34;, ex); } } } 因此，数据源事务管理器在管理事务时使用与您在 JDBC 部分中看到的完全相同的代码。\n考虑到这一点，让我们从上面扩展我们的图片：\n总结一下：\n如果 Spring 检测到 bean 上的 @Transactional 注释，它会创建该 bean 的动态代理。 代理可以访问事务管理器，并要求它打开和关闭事务/连接。 事务管理器本身将简单地执行您在普通 Java 部分中所做的操作：管理良好的旧 JDBC 连接。 物理事务和逻辑事务有什么区别？ 想象一下以下两个事务类。\n@Service public class UserService { @Autowired private InvoiceService invoiceService; @Transactional public void invoice() { invoiceService.createPdf(); // send invoice as email, etc. } } @Service public class InvoiceService { @Transactional public void createPdf() { // ... } } UserService 有一个事务性 Invoice() 方法。它调用 InvoiceService 上的另一个事务方法 createPdf()。\n现在就数据库事务而言，这实际上应该只是一个数据库事务。 （记住：getConnection().setAutocommit(false).commit()。）Spring 调用此物理事务，尽管一开始这听起来有点令人困惑。\n然而，从 Spring 的角度来看，发生了两个逻辑事务：第一个在 UserService 中，另一个在 InvoiceService 中。 Spring 必须足够聪明，知道这两个 @Transactional 方法应该使用相同的底层物理数据库事务。\n如果对 InvoiceService 进行以下更改，情况会有什么不同？\n@Service public class InvoiceService { @Transactional(propagation = Propagation.REQUIRES_NEW) public void createPdf() { // ... } } 将传播模式更改为 require_new 是告诉 Spring createPDF() 需要在自己的事务中执行，独立于任何其他已存在的事务。回想一下本指南的纯 Java 部分，您是否看到了将事务“拆分”为两半的方法？我也不。\n这基本上意味着您的代码将打开两个到数据库的（物理）连接/事务。 （再次：getConnection() x2.setAutocommit(false) x2.commit() x2）Spring 现在必须足够智能，两个逻辑事务部分 (invoice()/createPdf()) 现在也映射到两个不同的物理数据库交易。\n所以，总结一下：\n物理事务：是您实际的 JDBC 事务。 逻辑事务：是（可能嵌套的）@Transactional 注解的（Spring）方法。 这使我们能够更详细地介绍传播模式。\n@Transactional 传播级别的用途是什么？ 查看 Spring 源代码时，您会发现可以插入 @Transactional 方法的各种传播级别或模式。\n@Transactional(propagation = Propagation.REQUIRED) // or @Transactional(propagation = Propagation.REQUIRES_NEW) // etc 完整列表：\nREQUIRED 必需的 SUPPORTS 支持 MANDATORY 强制的 REQUIRES_NEW REQUIRES_NEW NOT_SUPPORTED 不支持 NEVER 绝不 NESTED 嵌套 练习：\n在普通 Java 部分中，我向您展示了 JDBC 在事务方面可以执行的所有操作。花点时间思考一下每个 Spring 传播模式最终对您的数据源（或者更确切地说，您的 JDBC 连接）到底做了什么。\n那就看看下面的回答吧。\n答案：\nRequired (default)：我的方法需要一个事务，要么为我打开一个事务，要么使用现有的事务 → getConnection()。设置自动提交（假）。犯罪（）。 Supports：我并不关心事务是否打开，我可以以任何一种方式工作 → 与 JDBC 无关 Mandatory：我自己不会打开一个事务，但是如果没有人打开一个事务我会哭 → 与 JDBC 无关 Require_new：我想要完全自己的事务 → getConnection()。设置自动提交（假）。犯罪（）。 Not_Supported：我真的不喜欢事务，我什至会尝试挂起当前正在运行的事务 → 与 JDBC 无关 **Never：**如果其他人启动事务我会哭 → 与 JDBC 无关 Nested： 听起来很复杂，但我们只是在谈论保存点！ → 连接.setSavepoint() 正如您所看到的，大多数传播模式实际上与数据库或 JDBC 无关，而更多地与您如何使用 Spring 构建程序以及 Spring 期望事务出现的方式/时间/地点有关。\n看这个例子：\npublic class UserService { @Transactional(propagation = Propagation.MANDATORY) public void myMethod() { // execute some sql } } 在这种情况下，每当您调用 UserService 类的 myMethod() 时，Spring 都会期望打开一个事务。它本身不会打开一个方法，相反，如果您在没有预先存在的事务的情况下调用该方法，Spring 将抛出异常。请记住这一点，作为“逻辑事务处理”的附加点。\n@Transactional 隔离级别有什么用？ 此时这几乎是一个棘手的问题，但是当您像这样配置 @Transactional 注释时会发生什么？\n@Transactional(isolation = Isolation.REPEATABLE_READ) 是的，它确实会导致这样的结果：\nconnection.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ); 然而，数据库隔离级别是一个复杂的主题，您应该花一些时间来完全掌握它们。一个好的开始是 Postgres 官方文档及其有关隔离级别的部分。\n另请注意，在事务期间切换隔离级别时，您必须确保咨询 JDBC 驱动程序/数据库以了解支持哪些场景，哪些不支持。\n最常见的@Transactional 陷阱 Spring 初学者通常会遇到一个陷阱。看一下下面的代码：\n@Service public class UserService { @Transactional public void invoice() { createPdf(); // send invoice as email, etc. } @Transactional(propagation = Propagation.REQUIRES_NEW) public void createPdf() { // ... } } 您有一个带有事务发票方法的 UserService 类。它调用 createPDF()，这也是事务性的。\n一旦有人调用 invoice()，您期望打开多少实际交易？\n不，答案不是两个，而是一个。为什么？\n让我们回到本指南的代理部分。 Spring 为您创建事务性 UserService 代理，但是一旦您进入 UserService 类并调用其他内部方法，就不再涉及代理。这意味着，您没有新的交易。\n我们用一张图来看看：\n您可以使用一些技巧（例如自注入）来绕过此限制。但主要的要点是：始终牢记代理事务边界。\n如何在 Spring Boot 或 Spring MVC 中使用 @Transactional 到目前为止，我们只讨论了简单的、核心的 Spring。但是 Spring Boot 呢？还是 Spring Web MVC？他们处理交易的方式有什么不同吗？\n最简洁的答案是不。\n对于任一框架（或者更确切地说：Spring 生态系统中的所有框架），您将始终使用 *@Transactional* 注释，并结合事务管理器和 @EnableTransactionManagement 注释。没有其他办法。\n然而，与 Spring Boot 的唯一区别是，它使用 JDBC 自动配置自动设置 *@EnableTransactionManagement* 注释并为您创建 *PlatformTransactionManager* 。在此处了解有关自动配置的更多信息。\nSpring 如何处理回滚（以及默认回滚策略） 有关 Spring 回滚的部分将在本指南的下一版本中处理。\nSpring 和 JPA/Hibernate 事务管理如何工作 目标：同步 Spring 的 @Transactional 和 Hibernate / JPA 在某些时候，您会希望 Spring 应用程序与另一个数据库库集成，例如 Hibernate（一种流行的 JPA 实现）或 Jooq 等。\n让我们以普通 Hibernate 为例（注意：直接使用 Hibernate，或者通过 JPA 使用 Hibernate 并不重要）。\n将之前的 UserService 重写为 Hibernate 如下所示：\npublic class UserService { @Autowired private SessionFactory sessionFactory; // (1) public void registerUser(User user) { Session session = sessionFactory.openSession(); // (2) // lets open up a transaction. remember setAutocommit(false)! session.beginTransaction(); // save == insert our objects session.save(user); // and commit it session.getTransaction().commit(); // close the session == our jdbc connection session.close(); } } 这是一个普通的、旧的 Hibernate SessionFactory，是所有 Hibernate 查询的入口点。 使用 Hibernate API 手动管理会话（即：数据库连接）和事务。 然而，上面的代码有一个很大的问题：\nHibernate 不会知道 Spring 的 @Transactional 注释。 Spring 的 @Transactional 对 Hibernate 的事务一无所知。 但我们实际上希望 Spring 和 Hibernate 能够无缝集成，这意味着它们了解彼此的事务。\n用纯代码表示：\n@Service public class UserService { @Autowired private SessionFactory sessionFactory; // (1) @Transactional public void registerUser(User user) { sessionFactory.getCurrentSession().save(user); // (2) } } 与之前相同的 SessionFactory 但不再需要手动状态管理。相反， getCurrentSession() 和 @Transactional 是同步的。 到那里怎么走？\n使用 HibernateTransactionManager 对于这个集成问题有一个非常简单的解决方法：\n您将使用 HibernateTransactionManager（如果使用普通 Hibernate）或 JpaTransactionManager（如果通过 JPA 使用 Hibernate），而不是在 Spring 配置中使用 DataSourcePlatformTransactionManager。\n专门的 HibernateTransactionManager 将确保：\n通过 Hibernate（即 SessionFactory）管理事务。 足够聪明，允许 Spring 在非 Hibernate 中使用相同的事务，即 @Transactional Spring 代码。 与往常一样，图片可能更容易理解（但请注意，代理和实际服务之间的流程仅在概念上正确且过于简单）。\n简而言之，就是如何集成 Spring 和 Hibernate。\n对于其他集成或更深入的理解，快速查看 Spring 提供的所有可能的 PlatformTransactionManager 实现会有所帮助。\nFin 到目前为止，您应该对事务管理如何与 Spring 框架配合使用以及它如何应用于其他 Spring 库（如 Spring Boot 或 Spring WebMVC）有一个很好的概述。最大的收获应该是，最终使用哪个框架并不重要，这都与 JDBC 基础知识有关。\n如果它们正确（记住：getConnection().setAutocommit(false).commit().），您将更容易理解稍后在复杂的企业应用程序中发生的情况。\n谢谢阅读。\n致谢 感谢 Andreas Eisele 对本指南早期版本的反馈。感谢 Ben Horsfield 提供了急需的 Javascript 片段来增强本指南。\n原文链接：https://www.marcobehler.com/guides/spring-transaction-management-transactional-in-depth\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-transaction-management-transactional-in-depth/","summary":"您可以使用本指南来简单实用地了解 Spring 使用 @Transactional 注释进行事务管理的工作原理。\n唯一的先决条件？您需要对 ACID 有一个粗略的了解，即什么是数据库事务以及为什么使用它们。此外，这里不讨论分布式事务或反应式事务，但就 Spring 而言，一般原则仍然适用。\n介绍 在本指南中，您将了解 Spring 核心事务抽象框架的主要支柱（这是一个令人困惑的术语，不是吗？） - 用大量代码示例进行描述：\n@Transactional （声明式事务管理）与编程式事务管理。 物理事务与逻辑事务。 Spring @Transactional 与 JPA/Hibernate 集成。 Spring @Transactional 与 Spring Boot 或 Spring MVC 集成。 回滚、代理、常见陷阱等等。 与 Spring 官方文档相反，本指南不会直接深入探讨 Spring-first 主题，从而让您感到困惑。\n相反，您将以非常规的方式学习 Spring 事务管理：从头开始，一步一步。这意味着，从普通的老式 JDBC 事务管理开始。\nWhy? 为什么？\n因为 Spring 所做的一切都是基于这些 JDBC 基础知识。如果您掌握了这些基础知识，稍后您将可以使用 Spring 的 @Transactional 注释节省大量时间。\n普通 JDBC 事务管理的工作原理 如果您在不完全了解 JDBC 事务的情况下考虑跳过本节：请不要这样做。\n如何启动、提交或回滚 JDBC 事务 第一个重要的收获是：无论您使用 Spring 的 @Transactional 注释、普通 Hibernate、jOOQ 还是任何其他数据库库，都没有关系。\n最后，它们都执行相同的操作来打开和关闭（我们称之为“管理”）数据库事务。普通的 JDBC 事务管理代码如下所示：\nimport java.sql.Connection; Connection connection = dataSource.getConnection(); // (1) try (connection) { connection.setAutoCommit(false); // (2) // execute some SQL statements... connection.commit(); // (3) } catch (SQLException e) { connection.","title":"[译]深入了解Spring事务管理：@Transactional"},{"content":"简介和概述 JSON Web Token 或 JWT（更常见的名称）是一种开放的互联网标准 (RFC 7519)，用于以紧凑的方式在各方之间安全地传输可信信息。令牌包含编码为 JSON 对象的声明，并使用私有密钥或公钥/私钥对进行数字签名。它们是独立且可验证的，因为它们经过数字签名。 JWT 可以进行签名和/或加密。\n签名的令牌验证令牌中包含的声明的完整性，而加密的令牌则向其他方隐藏声明。\nJWT 也可用于信息交换，尽管它们更常用于授权，因为它们比使用内存中随机令牌的会话管理具有很多优势。其中最重要的是允许将身份验证逻辑委托给第三方服务器，例如 AuthO 等。\nJWT 令牌分为 3 部分，即标头、有效负载和签名，格式为\n[Header].[Payload].[Signature] Header − JWT 令牌的标头包含应用于 JWT 的加密操作列表。这可以是签名技术、有关内容类型的元数据信息等。标头以 JSON 对象的形式呈现，该对象被编码为 base64URL。有效 JWT 标头的示例是 { \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } 这里，“alg”为我们提供了有关所用算法类型的信息，“typ”为我们提供了信息的类型。\nPayload − JWT 的有效负载部分包含使用令牌传输的实际数据。这部分也称为 JWT 令牌的“声明”部分。索赔可以分为三种类型：注册索赔、公开索赔和私人索赔。 注册的声明是推荐的但不是强制的声明，例如 iss(发行者)、sub(主题)、aud(受众) 等。 公共声明是那些使用 JWT 的人定义的声明。 私人声明或自定义声明是为了在相关方之间共享信息而创建的用户定义的声明。 有效负载对象的示例可以是。\n{ \u0026#34;sub\u0026#34;: \u0026#34;12345\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Johnny Hill\u0026#34;, \u0026#34;admin\u0026#34;: false } 有效负载对象与标头对象一样，也采用 base64Url 编码，并且该字符串构成 JWT 的第二部分。\nSignature− JWT 的签名部分用于验证消息在此过程中没有更改。如果令牌是用私钥签名的，它还会验证发送者的身份。它是使用编码的标头、编码的有效负载、秘密和标头中指定的算法创建的。签名的一个例子是。 HMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret); 如果我们输入标头、有效负载和签名，我们会得到一个令牌，如下所示。\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6I kpvaG4gRG9lIiwiYWRtaW4iOmZhbHNlfQ.gWDlJdpCTIHVYKkJSfAVNUn0ZkAjMxskDDm-5Fhe WJ7xXgW8k5CllcGk4C9qPrfa1GdqfBrbX_1x1E39JY8BYLobAfAg1fs_Ky8Z7U1oCl6HL63yJq_ wVNBHp49hWzg3-ERxkqiuTv0tIuDOasIdZ5FtBdtIP5LM9Oc1tsuMXQXCGR8GqGf1Hl2qv8MCyn NZJuVdJKO_L3WGBJouaTpK1u2SEleVFGI2HFvrX_jS2ySzDxoO9KjbydK0LNv_zOI7kWv-gAmA j-v0mHdJrLbxD7LcZJEGRScCSyITzo6Z59_jG_97oNLFgBKJbh12nvvPibHpUYWmZuHkoGvuy5RLUA 现在，可以使用承载模式在授权标头中使用此令牌。\nAuthorization − Bearer 授权 - 持有者\n使用 JWT 令牌进行授权是其最常见的应用。令牌通常在服务器中生成并发送到客户端，并存储在会话存储或本地存储中。要访问受保护的资源，客户端将在标头中发送 JWT，如上所述。我们将在下面的部分中看到 Spring Security 中的 JWT 实现。\n使用 JWT 开始使用 Spring Security 我们要开发的应用程序将使用 JWT 处理基本的用户身份验证和授权。让我们开始访问 start.spring.io，我们将在其中创建一个具有以下依赖项的 Maven 应用程序。\nSpring Web Spring Security 我们生成项目，下载后将其解压到我们选择的文件夹中。然后我们可以使用我们选择的任何 IDE。我将使用 Spring Tools Suite 4，因为它针对 Spring 应用程序进行了最优化。\n除了上述依赖项之外，我们还将包含来自 Maven 中央存储库的 io.jsonwebtoken 的 jwt 依赖项，因为它不包含在 spring 初始化程序中。这种依赖关系负责涉及 JWT 的所有操作，包括构建令牌、解析令牌以获取声明等。\n\u0026lt;dependency\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 我们的 pom.xml 文件现在应该与此类似。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;version\u0026gt; \u0026lt;relativePath /\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.spring.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jwtbasic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;jwtbasic\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.jsonwebtoken\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jjwt\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.9.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.xml.bind\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jaxb-api\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;scope\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 现在我们的项目已经设置完毕，我们将创建控制器类 Hello Controller，它公开一个 Get 端点。\npackage com.spring.security.jwtbasic.controllers; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class HelloController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello() { return \u0026#34;hello\u0026#34;; } } 现在我们将创建一个名为 config 的包，在其中添加扩展 Spring Security 的 WebSecurityConfigurerAdapter 类的配置类。这将为我们提供项目配置和应用程序安全性所需的所有功能和定义。现在，我们通过实现生成相同实例的方法来提供 BcryptPasswordEncoder 实例。我们用 @Bean 注释该方法以添加到 Spring 上下文中。\npackage com.spring.security.jwtbasic.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import com.spring.security.jwtbasic.jwtutils.JwtAuthenticationEntryPoint; import com.spring.security.jwtbasic.jwtutils.JwtFilter; @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } } The JWT includes a secret which we will define in our application.properties file as given below. JWT 包含一个秘密，我们将在 application.properties 文件中定义该秘密，如下所示。\nsecret=somerandomsecret 现在让我们创建一个名为 jwtutils 的包。该包将包含与 JWT 操作相关的所有类和接口，其中包括。\n生成令牌 验证令牌 检查签名 验证声明和权限 在此包中，我们创建第一个类，称为令牌管理器。此类将负责使用 io.jsonwebtoken.Jwts 创建和验证令牌。\npackage com.spring.security.jwtbasic.jwtutils; import java.io.Serializable; import java.util.Base64; import java.util.Date; import java.util.HashMap; import java.util.Map; import org.springframework.beans.factory.annotation.Value; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.stereotype.Component; import io.jsonwebtoken.Claims; import io.jsonwebtoken.Jwts; import io.jsonwebtoken.SignatureAlgorithm; @Component public class TokenManager implements Serializable { /** * */ private static final long serialVersionUID = 7008375124389347049L; public static final long TOKEN_VALIDITY = 10 * 60 * 60; @Value(\u0026#34;${secret}\u0026#34;) private String jwtSecret; public String generateJwtToken(UserDetails userDetails) { Map\u0026lt;String, Object\u0026gt; claims = new HashMap\u0026lt;\u0026gt;(); return Jwts.builder().setClaims(claims).setSubject(userDetails.getUsername()) .setIssuedAt(new Date(System.currentTimeMillis())) .setExpiration(new Date(System.currentTimeMillis() + TOKEN_VALIDITY * 1000)) .signWith(SignatureAlgorithm.HS512, jwtSecret).compact(); } public Boolean validateJwtToken(String token, UserDetails userDetails) { String username = getUsernameFromToken(token); Claims claims = Jwts.parser().setSigningKey(jwtSecret).parseClaimsJws(token).getBody(); Boolean isTokenExpired = claims.getExpiration().before(new Date()); return (username.equals(userDetails.getUsername()) \u0026amp;\u0026amp; !isTokenExpired); } public String getUsernameFromToken(String token) { final Claims claims = Jwts.parser().setSigningKey(jwtSecret).parseClaimsJws(token).getBody(); return claims.getSubject(); } } 在这里，由于所有令牌都应该有一个到期日期，因此我们从令牌有效性常量开始。在这里，我们希望我们的令牌在生成后 10 分钟内有效。当我们生成令牌时，我们将使用这个值。然后，我们使用 @Value 注释将歌唱键的值从 application.properties 文件中提取到 jwtSecret 字段中。\n我们这里有两种方法 -\ngenerateJwtToken() − 此方法用于在用户成功进行身份验证时生成令牌。要在此处创建令牌，我们使用用户名、令牌发行日期和令牌到期日期。正如我们之前讨论的，这将形成令牌或声明的有效负载部分。为了生成令牌，我们使用 Jwts 的 builder() 方法。此方法返回一个新的 JwtBuilder 实例，可用于创建紧凑的 JWT 序列化字符串。 为了设置声明，我们使用 setClaims() 方法，然后设置每个声明。对于这个令牌，我们有 setSubject(username)、发行日期和到期日期。我们还可以像上面讨论的那样提出自定义声明。这可以是我们想要的任何值，其中可能包括用户角色、用户权限等。\n然后我们设置令牌的签名部分。这是使用 signWith() 方法完成的，我们设置我们喜欢使用的哈希算法和密钥。然后，我们使用 compact()方法构建 JWT，并根据 JWT 紧凑序列化规则将其序列化为紧凑的、URL 安全的字符串。\nvalidateJwtToken() − 现在已经处理了令牌的生成，我们应该关注令牌作为请求的一部分时的验证过程。验证令牌意味着验证请求是否经过身份验证，并且令牌是生成并发送给用户的令牌。在这里，我们需要解析令牌以获取用户名、角色、权限、有效期等声明。 为了验证令牌，我们需要首先解析它。这是使用 Jwts 的 parser() 方法完成的。然后，我们需要设置用于生成令牌的签名密钥，然后在令牌上使用 parseClaimsJws() 方法根据构建器的当前配置状态解析紧凑的序列化 JWS 字符串，并返回生成的 Claims JWS 实例。然后使用 getBody() 方法返回生成令牌时使用的声明实例。\n从获得的声明实例中，我们提取主题和到期日期以验证令牌的有效性。用户名应该是用户的用户名，并且令牌不应过期。如果满足这两个条件，我们将返回 true，这表示令牌有效。\n我们要创建的下一个类是 JwtUserDetailsS​​ervice。这个类将扩展 Spring security 的 UserDetailsS​​ervice，我们将实现 loadUserByUsername() 方法，如下所示 -\npackage com.spring.security.jwtbasic.jwtutils; import java.util.ArrayList; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.stereotype.Service; @Service public class JwtUserDetailsService implements UserDetailsService { @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { if (\u0026#34;randomuser123\u0026#34;.equals(username)) { return new User(\u0026#34;randomuser123\u0026#34;, \u0026#34;$2a$10$slYQmyNdGzTn7ZLBXBChFOC9f6kFjAqPhccnP6DxlWXx2lPk1C3G6\u0026#34;, new ArrayList\u0026lt;\u0026gt;()); } else { throw new UsernameNotFoundException(\u0026#34;User not found with username: \u0026#34; + username); } } } 在这里，由于这是一个基本应用程序，其唯一目的是演示 JWT 身份验证，因此我们使用了一组用户详细信息，而不是使用数据库。为了方便起见，我们将用户名指定为“randomuser123”，并将密码（即“密码”）编码为“$2a$10$slYQmyNdGzTn7ZLBXBChFOC9f6kFjAqPhccnP6DxlWXx2lPk1C3G6”。\n接下来，我们为请求和响应模型创建类。这些模型决定了我们的请求和响应格式如何进行身份验证。下面给出的第一个快照是请求模型。正如我们所看到的，我们将在请求中接受两个属性——用户名和密码。\npackage com.spring.security.jwtbasic.jwtutils.models; import java.io.Serializable; public class JwtRequestModel implements Serializable { /** * */ private static final long serialVersionUID = 2636936156391265891L; private String username; private String password; public JwtRequestModel() { } public JwtRequestModel(String username, String password) { super(); this.username = username; this.password = password; } public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } } 以下是身份验证成功后的响应模型的代码。正如我们所看到的，在身份验证成功后，我们将把令牌发送回用户。\npackage com.spring.security.jwtbasic.jwtutils.models; import java.io.Serializable; public class JwtResponseModel implements Serializable { /** * */ private static final long serialVersionUID = 1L; private final String token; public JwtResponseModel(String token) { this.token = token; } public String getToken() { return token; } } 现在为了进行身份验证，让我们创建一个控制器，如下所示。\npackage com.spring.security.jwtbasic.jwtutils; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.ResponseEntity; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.DisabledException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestBody; import org.springframework.web.bind.annotation.RestController; import com.spring.security.jwtbasic.jwtutils.models.JwtRequestModel; import com.spring.security.jwtbasic.jwtutils.models.JwtResponseModel; @RestController @CrossOrigin public class JwtController { @Autowired private JwtUserDetailsService userDetailsService; @Autowired private AuthenticationManager authenticationManager; @Autowired private TokenManager tokenManager; @PostMapping(\u0026#34;/login\u0026#34;) public ResponseEntity\u0026lt;\u0026gt; createToken(@RequestBody JwtRequestModel request) throws Exception { try { authenticationManager.authenticate( new UsernamePasswordAuthenticationToken(request.getUsername(), request.getPassword()) ); } catch (DisabledException e) { throw new Exception(\u0026#34;USER_DISABLED\u0026#34;, e); } catch (BadCredentialsException e) { throw new Exception(\u0026#34;INVALID_CREDENTIALS\u0026#34;, e); } final UserDetails userDetails = userDetailsService.loadUserByUsername(request.getUsername()); final String jwtToken = tokenManager.generateJwtToken(userDetails); return ResponseEntity.ok(new JwtResponseModel(jwtToken)); } } 如果我们查看代码，我们可以看到，我们自动装配了三个依赖项，即 JwtUserDetailsS​​ervice、AuthenticationManager 和 TokenManager。虽然我们已经看到了上面 JwtUserDetailsS​​ervice 和 TokenManager 类的实现，但身份验证管理器 bean 是我们将在 WebSecurityConfig 类中创建的一个。\nAuthenticationManager 类将负责我们的身份验证。我们将使用 UsernamePasswordAuthenticationToken 模型来验证请求。如果身份验证成功，我们将为用户生成一个 JWT，该 JWT 可以在后续请求的 Authorization 标头中发送以获取任何资源。\n正如我们所看到的，我们正在使用 JwtUserDetailsS​​ervice 类的 loadUserByUsername() 方法和 TokenManager 类中的 generateJwtToken()。\n如上所述，生成的 JWT 作为成功身份验证的响应发送给用户。\n现在是我们创建过滤器的时候了。过滤器类将用于跟踪我们的请求并检测它们是否在标头中包含有效令牌。如果令牌有效，我们将继续请求，否则我们将发送 401 错误（未经授权）。\npackage com.spring.security.jwtbasic.jwtutils; import java.io.IOException; import javax.servlet.FilterChain; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.web.authentication.WebAuthenticationDetailsSource; import org.springframework.stereotype.Component; import org.springframework.web.filter.OncePerRequestFilter; import io.jsonwebtoken.ExpiredJwtException; @Component public class JwtFilter extends OncePerRequestFilter { @Autowired private JwtUserDetailsService userDetailsService; @Autowired private TokenManager tokenManager; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException { String tokenHeader = request.getHeader(\u0026#34;Authorization\u0026#34;); String username = null; String token = null; if (tokenHeader != null \u0026amp;\u0026amp; tokenHeader.startsWith(\u0026#34;Bearer \u0026#34;)) { token = tokenHeader.substring(7); try { username = tokenManager.getUsernameFromToken(token); } catch (IllegalArgumentException e) { System.out.println(\u0026#34;Unable to get JWT Token\u0026#34;); } catch (ExpiredJwtException e) { System.out.println(\u0026#34;JWT Token has expired\u0026#34;); } } else { System.out.println(\u0026#34;Bearer String not found in token\u0026#34;); } if (null != username \u0026amp;\u0026amp;SecurityContextHolder.getContext().getAuthentication() == null) { UserDetails userDetails = userDetailsService.loadUserByUsername(username); if (tokenManager.validateJwtToken(token, userDetails)) { UsernamePasswordAuthenticationToken authenticationToken = new UsernamePasswordAuthenticationToken( userDetails, null, userDetails.getAuthorities()); authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request)); SecurityContextHolder.getContext().setAuthentication(authenticationToken); } } filterChain.doFilter(request, response); } } 正如我们在上面看到的，我们也在这里自动装配了 JwtUserDetailsS​​ervice 和 TokenManager 类。我们扩展了 SpringSecurity 的 OncePerRequestFilter，确保过滤器针对每个请求运行。我们已经为 OncePerRequestFilter 类的重写方法 doFilterInternal() 提供了实现。\n这里的方法从标头中提取令牌并借助 TokenManager 类的 validateJwtToken() 方法对其进行验证。在验证过程中，它会检查用户名和到期日期。如果两个值都有效，我们会将身份验证保存在 Spring Security 上下文中，并让代码继续执行过滤器链中的下一个过滤器。如果任何验证失败或令牌存在问题，或者未找到令牌，我们会抛出适当的异常并发回适当的响应，同时阻止请求继续进行。\n为我们的请求创建过滤器后，我们现在创建 JwtAutheticationEntryPoint 类。该类扩展了 Spring 的 AuthenticationEntryPoint 类，并拒绝每个未经身份验证的请求，并向客户端发送错误代码 401。我们重写了 AuthenticationEntryPoint 类的 begin() 方法来做到这一点。\npackage com.spring.security.jwtbasic.jwtutils; import java.io.IOException; import java.io.Serializable; import javax.servlet.ServletException; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import org.springframework.security.core.AuthenticationException; import org.springframework.security.web.AuthenticationEntryPoint; import org.springframework.stereotype.Component; @Component public class JwtAuthenticationEntryPoint implements AuthenticationEntryPoint, Serializable { @Override public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException authException) throws IOException, ServletException { response.sendError(HttpServletResponse.SC_UNAUTHORIZED, \u0026#34;Unauthorized\u0026#34;); } } 现在，让我们回到 WebSecurityConfig 类并完成其余的配置。如果我们还记得的话，我们将需要我们的 Jwt 控制器类的 AuthenticationManager bean，并将我们刚刚创建的过滤器添加到我们的配置中。我们还将配置哪些请求需要进行身份验证，哪些请求不需要进行身份验证。我们还将 AuthenticationEntryPoint 添加到请求中以发回 401 错误响应。因为，我们在使用 jwt 时也不需要维护会话变量，我们可以使会话成为无状态的。\npackage com.spring.security.jwtbasic.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.config.http.SessionCreationPolicy; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import com.spring.security.jwtbasic.jwtutils.JwtAuthenticationEntryPoint; import com.spring.security.jwtbasic.jwtutils.JwtFilter; @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Autowired private JwtAuthenticationEntryPoint authenticationEntryPoint; @Autowired private UserDetailsService userDetailsService; @Autowired private JwtFilter filter; @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder()); } @Bean @Override public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests().antMatchers(\u0026#34;/login\u0026#34;).permitAll() .anyRequest().authenticated() .and() .exceptionHandling().authenticationEntryPoint(authenticationEntryPoint) .and() .sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS); http.addFilterBefore(filter, UsernamePasswordAuthenticationFilter.class); } } 正如我们所看到的，我们已经完成了所有这些，现在我们的应用程序已准备就绪。让我们启动应用程序并使用邮递员来发出我们的请求。\n在这里，我们发出了第一个获取令牌的请求，正如我们所看到的，在提供正确的用户名/密码组合后，我们将取回令牌。\n现在，在标头中使用该标记，让我们调用 /hello 端点。\n正如我们所看到的，由于请求已通过身份验证，我们得到了所需的响应。现在，如果我们篡改令牌或不发送 Authorization 标头，我们将收到应用程序中配置的 401 错误。这确保了使用 JWT 保护我们的请求。\n原文链接：https://www.tutorialspoint.com/spring_security/spring_security_with_jwt.htm\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security-with-jwt/","summary":"简介和概述 JSON Web Token 或 JWT（更常见的名称）是一种开放的互联网标准 (RFC 7519)，用于以紧凑的方式在各方之间安全地传输可信信息。令牌包含编码为 JSON 对象的声明，并使用私有密钥或公钥/私钥对进行数字签名。它们是独立且可验证的，因为它们经过数字签名。 JWT 可以进行签名和/或加密。\n签名的令牌验证令牌中包含的声明的完整性，而加密的令牌则向其他方隐藏声明。\nJWT 也可用于信息交换，尽管它们更常用于授权，因为它们比使用内存中随机令牌的会话管理具有很多优势。其中最重要的是允许将身份验证逻辑委托给第三方服务器，例如 AuthO 等。\nJWT 令牌分为 3 部分，即标头、有效负载和签名，格式为\n[Header].[Payload].[Signature] Header − JWT 令牌的标头包含应用于 JWT 的加密操作列表。这可以是签名技术、有关内容类型的元数据信息等。标头以 JSON 对象的形式呈现，该对象被编码为 base64URL。有效 JWT 标头的示例是 { \u0026#34;alg\u0026#34;: \u0026#34;HS256\u0026#34;, \u0026#34;typ\u0026#34;: \u0026#34;JWT\u0026#34; } 这里，“alg”为我们提供了有关所用算法类型的信息，“typ”为我们提供了信息的类型。\nPayload − JWT 的有效负载部分包含使用令牌传输的实际数据。这部分也称为 JWT 令牌的“声明”部分。索赔可以分为三种类型：注册索赔、公开索赔和私人索赔。 注册的声明是推荐的但不是强制的声明，例如 iss(发行者)、sub(主题)、aud(受众) 等。 公共声明是那些使用 JWT 的人定义的声明。 私人声明或自定义声明是为了在相关方之间共享信息而创建的用户定义的声明。 有效负载对象的示例可以是。\n{ \u0026#34;sub\u0026#34;: \u0026#34;12345\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Johnny Hill\u0026#34;, \u0026#34;admin\u0026#34;: false } 有效负载对象与标头对象一样，也采用 base64Url 编码，并且该字符串构成 JWT 的第二部分。\nSignature− JWT 的签名部分用于验证消息在此过程中没有更改。如果令牌是用私钥签名的，它还会验证发送者的身份。它是使用编码的标头、编码的有效负载、秘密和标头中指定的算法创建的。签名的一个例子是。 HMACSHA256(base64UrlEncode(header) + \u0026#34;.\u0026#34; + base64UrlEncode(payload), secret); 如果我们输入标头、有效负载和签名，我们会得到一个令牌，如下所示。\neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6I kpvaG4gRG9lIiwiYWRtaW4iOmZhbHNlfQ.gWDlJdpCTIHVYKkJSfAVNUn0ZkAjMxskDDm-5Fhe WJ7xXgW8k5CllcGk4C9qPrfa1GdqfBrbX_1x1E39JY8BYLobAfAg1fs_Ky8Z7U1oCl6HL63yJq_ wVNBHp49hWzg3-ERxkqiuTv0tIuDOasIdZ5FtBdtIP5LM9Oc1tsuMXQXCGR8GqGf1Hl2qv8MCyn NZJuVdJKO_L3WGBJouaTpK1u2SEleVFGI2HFvrX_jS2ySzDxoO9KjbydK0LNv_zOI7kWv-gAmA j-v0mHdJrLbxD7LcZJEGRScCSyITzo6Z59_jG_97oNLFgBKJbh12nvvPibHpUYWmZuHkoGvuy5RLUA 现在，可以使用承载模式在授权标头中使用此令牌。\nAuthorization − Bearer 授权 - 持有者\n使用 JWT 令牌进行授权是其最常见的应用。令牌通常在服务器中生成并发送到客户端，并存储在会话存储或本地存储中。要访问受保护的资源，客户端将在标头中发送 JWT，如上所述。我们将在下面的部分中看到 Spring Security 中的 JWT 实现。","title":"[译]Spring Security - JWT"},{"content":"OAuth 2.0 基础知识 OAuth 2.0 由 IETF OAuth 工作组开发并于 2012 年 10 月发布。它作为一种开放授权协议，使第三方应用程序能够代表资源所有者对 HTTP 服务进行有限访问。它可以在不泄露用户身份或长期凭证的情况下做到这一点。第三方应用程序本身也可以代表其使用它。\nOAuth 的工作原理包括将用户身份验证委托给托管用户帐户的服务，并授权第三方应用程序访问用户的帐户。\n让我们考虑一个例子。假设我们要登录网站“clientsite.com”。我们可以通过 Facebook、Github、Google 或 Microsoft 登录。我们选择上面给出的选项中的任何选项，然后我们将被重定向到相应的网站进行登录。如果登录成功，系统会询问我们是否要授予 clientsite.com 访问其请求的特定数据的权限。\n我们选择所需的选项，然后使用授权代码或错误代码重定向到 clientsite.com，登录是否成功取决于我们在第三方资源中的操作。这就是 OAuth 2 的基本工作原理。\nOAuth 系统涉及五个关键角色。让我们把它们列出来 -\nUser / Resource Owner − 用户/资源所有者- 最终用户，负责身份验证并同意与客户端共享资源。 User-Agent − 用户代理- 用户使用的浏览器。 Client − 客户端 - 请求访问令牌的应用程序。 Authorization Server − 授权服务器- 用于验证用户/客户端的服务器。它颁发访问令牌并在其整个生命周期内对其进行跟踪。 Resource Server − 资源服务器- 提供对所请求资源的访问的 API。它验证访问令牌并提供授权。 入门 我们将使用 Spring Security 和 OAuth 2.0 开发一个 Spring Boot 应用程序来说明上述内容。我们现在将开发一个带有内存数据库的基本应用程序来存储用户凭据。该应用程序将使我们轻松了解 OAuth 2.0 与 Spring Security 的工作原理。\n让我们使用 Spring 初始化程序在 Java 8 中创建一个 Maven 项目。让我们从 start.spring.io 开始。我们生成一个具有以下依赖项的应用程序 -\nSpring Web Spring Security Cloud OAuth2 Spring Boot Devtools 通过上面的配置，我们点击 Generate 按钮生成一个项目。该项目将以 zip 文件形式下载。我们将 zip 解压到一个文件夹中。然后我们可以在我们选择的 IDE 中打开该项目。我在这里使用 Spring Tools Suite，因为它针对 Spring 应用程序进行了优化。我们也可以根据需要使用 Eclipse 或 IntelliJ Idea。\n因此，我们在 STS 中打开项目，让依赖项被下载。然后我们可以在包资源管理器窗口中看到项目结构。它应该类似于下面的屏幕截图。\n如果我们打开 pom.xml 文件，我们可以查看与项目相关的依赖项和其他详细信息。它应该看起来像这样。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.tutorial\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring.security.oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;spring.security.oauth2\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;spring-cloud.version\u0026gt;Hoxton.SR6\u0026lt;/spring-cloud.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-oauth2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-dependencies\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring-cloud.version}\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;\u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 现在，在我们应用程序的基础包（即 com.tutorial.spring.security.oauth2）中，添加一个名为 config 的新包，我们将在其中添加配置类。\n让我们创建第一个配置类 UserConfig，它扩展了 Spring Security 的 WebSecurityConfigurerAdapter 类来管理客户端应用程序的用户。我们给这个类加上@Configuration 注解，告诉 Spring 它是一个配置类。\npackage com.tutorial.spring.security.oauth2.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; @Configuration public class UserConfig extends WebSecurityConfigurerAdapter { @Bean public UserDetailsService userDetailsService() { UserDetailsManager userDetailsManager = new InMemoryUserDetailsManager(); UserDetails user = User.withUsername(\u0026#34;john\u0026#34;) .password(\u0026#34;12345\u0026#34;) .authorities(\u0026#34;read\u0026#34;) .build(); userDetailsManager.createUser(user); return userDetailsManager; } @Bean public PasswordEncoder passwordEncoder() { return NoOpPasswordEncoder.getInstance(); } @Override @Bean public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } } 然后，我们添加 UserDetailsS​​ervice 的 bean 来检索用户详细信息以进行身份 ​​ 验证和授权。为了将其放入 Spring 上下文中，我们用 @Bean 对其进行注释。为了使本教程简单易懂，我们使用 InMemoryUserDetailsManager 实例。对于实际应用程序，我们可以使用其他实现，例如 JdbcUserDetailsManager 来连接到数据库等。为了能够在此示例中轻松创建用户，我们使用 UserDetailsManager 接口，该接口扩展了 UserDetailsS​​ervice 并具有 createUser()、updateUser() 等方法。然后，我们使用构建器类创建一个用户。我们现在给他一个用户名、密码和“读取”权限。然后，使用 createUser() 方法添加新创建的用户并返回 UserDetailsManager 实例，从而将其放入 Spring 上下文中。\n为了能够使用我们定义的 UserDetailsS​​ervice，有必要在 Spring 上下文中提供一个 PasswordEncoder bean。再次强调，为了简单起见，我们现在使用 NoOpPasswordEncoder。 NoOpPasswordEncoder 不应该用于实际生产应用程序，因为它不安全。 NoOpPasswordEncoder 不会对密码进行编码，仅适用于开发或测试场景或概念证明。\n我们应该始终使用 Spring Security 提供的其他高度安全的选项，其中最流行的是 BCryptPasswordEncoder，我们将在后面的系列教程中使用它。为了将其放入 Spring 上下文中，我们使用 @Bean 注释该方法。\n然后，我们重写 WebSecurityConfigurerAdapter 的 AuthenticationManager bean 方法，该方法返回 authenticationManagerBean 以将身份验证管理器放入 Spring 上下文中。\n现在，为了添加客户端配置，我们添加一个名为 AuthorizationServerConfig 的新配置类，它扩展了 Spring Security 的 AuthorizationServerConfigurerAdapter 类。 AuthorizationServerConfigurerAdapter 类用于使用 spring security oauth2 模块配置授权服务器。我们也用@Configuration 注释这个类。要将授权服务器功能添加到此类中，我们需要添加 @EnableAuthorizationServer 注释，以便应用程序可以充当授权服务器。\npackage com.tutorial.spring.security.oauth2.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer; import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter; import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer; import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer; @Configuration @EnableAuthorizationServer public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory() .withClient(\u0026#34;oauthclient1\u0026#34;) .secret(\u0026#34;oauthsecret1\u0026#34;) .scopes(\u0026#34;read\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;) } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.authenticationManager(authenticationManager); } } 为了检查 oauth 令牌，Spring Security oauth 公开两个端点 - /oauth/check_token 和 /oauth/token_key。默认情况下，这些端点在 denyAll() 后面受到保护。 tokenKeyAccess() 和 checkTokenAccess() 方法打开这些端点以供使用。\n我们将在 UserConfig 类中配置的 AuthenticationManager bean 自动装配为此处的依赖项，稍后我们将使用它。\n然后，我们重写 AuthorizationServerConfigurerAdapter 的两个 configure() 方法，以提供客户端详细信息服务的内存中实现。第一种方法使用 ClientDetailsS​​erviceConfigurer 作为参数，顾名思义，允许我们为授权服务器配置客户端。这些客户端代表能够使用该授权服务器功能的应用程序。由于这是学习 OAuth2 实现的基本应用程序，因此我们现在将保持简单并使用具有以下属性的内存中实现 -\nclientId − 客户端的 ID。必需的。 secret − 客户端密码，受信任的客户端所需 scope − 范围 - 客户端的限制范围，换句话说，客户端权限。如果留空或未定义，则客户端不受任何范围的限制。 authorizedGrantTypes − 客户端被授权使用的授权类型。 grant type 表示客户端从授权服务器获取 token 的方式。我们将使用“密码”授予类型，因为它是最简单的。稍后，我们将针对另一个用例使用另一种授权类型。 在“密码”授权授予类型中，用户需要向我们的客户端应用程序提供他/她的用户名、密码和范围，然后客户端应用程序使用这些凭据以及我们想要从中获取令牌的授权服务器的凭据。\n我们重写的另一个 configure()方法使用 AuthorizationServerEndpointsConfigurer 作为参数，用于将 AuthenticationManager 附加到授权服务器配置。\n通过这些基本配置，我们的授权服务器就可以使用了。让我们继续启动并使用它。我们将使用 Postman (h ttps://www.postman.com/downloads/) 来提出我们的请求。\n使用 STS 时，我们可以启动应用程序并开始在控制台中查看日志。当应用程序启动时，我们可以在控制台中找到应用程序公开的 oauth2 端点。在这些端点中，我们现在将使用以下令牌 -\n/oauth/token – 用于获取令牌。\n如果我们检查这里的邮递员快照，我们可以注意到一些事情。让我们在下面列出它们。\nURL - 我们的 Spring Boot 应用程序在本地计算机的端口 8080 上运行，因此请求指向 http://localhost:8080。接下来的部分是 /oauth/token，我们知道它是 OAuth 公开的用于生成令牌的端点。 查询参数 - 由于这是“密码”授权授予类型，因此用户需要向我们的客户端应用程序提供他/她的用户名、密码和范围，然后客户端应用程序使用这些凭据及其凭据发送给我们想要令牌的授权服务器从。 客户端授权- Oauth 系统要求客户端获得授权才能提供令牌。因此，在授权标头下，我们提供客户端身份验证信息，即我们在应用程序中配置的用户名和密码。 让我们仔细看看查询参数和授权标头 -\n查询参数\n客户凭证\n如果一切正确，我们将能够在响应中看到生成的令牌以及 200 ok 状态。\n响应\n我们可以通过输入错误的凭据或不输入凭据来测试我们的服务器，我们将收到一个错误，表明请求未经授权或凭据错误。\n这是我们的基本 oauth 授权服务器，它使用密码授予类型来生成并提供密码。\n接下来，让我们实现一个更安全、更常见的 oauth2 身份验证应用，即使用授权码授予类型。为此，我们将更新当前的应用程序。\n授权授予类型与密码授予类型不同，因为用户不必与客户端应用程序共享其凭据。他仅与授权服务器共享它们，作为回报，授权代码被发送到客户端，用于对客户端进行身份验证。它比密码授予类型更安全，因为用户凭据不与客户端应用程序共享，因此用户的信息保持安全。\n除非得到用户的批准，客户端应用程序无法访问任何重要的用户信息。\n通过几个简单的步骤，我们可以在应用程序中设置一个具有授权授予类型的基本 oauth 服务器。让我们看看如何。\npackage com.tutorial.spring.security.oauth2.config; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer; import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter; import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer; import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer; @Configuration @EnableAuthorizationServer public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory() .withClient(\u0026#34;oauthclient1\u0026#34;) .secret(\u0026#34;oauthsecret1\u0026#34;) .scopes(\u0026#34;read\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;) .and() .withClient(\u0026#34;oauthclient2\u0026#34;) .secret(\u0026#34;oauthsecret2\u0026#34;) .scopes(\u0026#34;read\u0026#34;) .authorizedGrantTypes(\u0026#34;authorization_code\u0026#34;) .redirectUris(\u0026#34;http://locahost:9090\u0026#34;); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.authenticationManager(authenticationManager); } } 让我们为此操作添加第二个客户端 oauthclient2，并使用新的密钥和读取范围。在这里，我们已将此客户端的授权类型更改为授权代码。我们还添加了重定向 URI，以便授权服务器可以回调客户端。因此，基本上重定向 URI 就是客户端的 URI。\n现在，我们必须在用户和授权服务器之间建立连接。我们必须为授权服务器设置一个接口，用户可以在其中提供凭据。我们使用 Spring Security 的 formLogin() 实现来实现该功能，同时保持简单。我们还确保所有请求都经过身份验证。\npackage com.tutorial.spring.security.oauth2.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.authentication.AuthenticationManager; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; @SuppressWarnings(\u0026#34;deprecation\u0026#34;) @Configuration public class UserConfig extends WebSecurityConfigurerAdapter { @Bean public UserDetailsService userDetailsService() { UserDetailsManager userDetailsManager = new InMemoryUserDetailsManager(); UserDetails user = User.withUsername(\u0026#34;john\u0026#34;) .password(\u0026#34;12345\u0026#34;) .authorities(\u0026#34;read\u0026#34;) .build(); userDetailsManager.createUser(user); return userDetailsManager; } @Bean public PasswordEncoder passwordEncoder() { return NoOpPasswordEncoder.getInstance(); } @Override @Bean public AuthenticationManager authenticationManagerBean() throws Exception { return super.authenticationManagerBean(); } @Override protected void configure(HttpSecurity http) throws Exception { http.formLogin(); http.authorizeRequests().anyRequest().authenticated(); } } 这就完成了我们对授权授予类型的设置。现在测试我们的设置并启动我们的应用程序。我们在 http://localhost:8080/oauth/authorize?response_type=code\u0026amp;client_id=oauthclient2\u0026amp;scope=read 启动浏览器。我们将重定向到 Spring Security 的默认表单登录页面。\n这里，响应类型代码意味着授权服务器将返回一个访问代码，客户端将使用该访问代码进行登录。当我们使用用户凭据时，我们将被询问是否要授予客户端请求的权限，在类似的屏幕如下所示。\n如果我们批准并单击“授权”，我们将看到我们被重定向到给定的重定向 URL 以及访问代码。在我们的例子中，我们被重定向到 http://locahost:9090/?code=7Hibnw，正如我们在应用程序中指定的那样。我们现在可以使用该代码作为 Postman 中的客户端来登录授权服务器。\n正如我们在这里所看到的，我们在 URL 中使用了从授权服务器收到的代码，并且 grant_type 作为授权代码，范围作为读取。我们充当客户端并提供应用程序中配置的客户端凭据。当我们发出这个请求时，我们会得到我们可以进一步使用的 access_token。\n我们已经了解了如何使用 OAuth 2.0 配置 Spring Security。该应用程序非常简单且易于理解，可以帮助我们相当轻松地理解该过程。我们使用了两种授权授予类型，并了解了如何使用它们来获取客户端应用程序的访问令牌。\n原文链接：https://www.tutorialspoint.com/spring_security/spring_security_with_oauth2.htm\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security-with-oauth2/","summary":"OAuth 2.0 基础知识 OAuth 2.0 由 IETF OAuth 工作组开发并于 2012 年 10 月发布。它作为一种开放授权协议，使第三方应用程序能够代表资源所有者对 HTTP 服务进行有限访问。它可以在不泄露用户身份或长期凭证的情况下做到这一点。第三方应用程序本身也可以代表其使用它。\nOAuth 的工作原理包括将用户身份验证委托给托管用户帐户的服务，并授权第三方应用程序访问用户的帐户。\n让我们考虑一个例子。假设我们要登录网站“clientsite.com”。我们可以通过 Facebook、Github、Google 或 Microsoft 登录。我们选择上面给出的选项中的任何选项，然后我们将被重定向到相应的网站进行登录。如果登录成功，系统会询问我们是否要授予 clientsite.com 访问其请求的特定数据的权限。\n我们选择所需的选项，然后使用授权代码或错误代码重定向到 clientsite.com，登录是否成功取决于我们在第三方资源中的操作。这就是 OAuth 2 的基本工作原理。\nOAuth 系统涉及五个关键角色。让我们把它们列出来 -\nUser / Resource Owner − 用户/资源所有者- 最终用户，负责身份验证并同意与客户端共享资源。 User-Agent − 用户代理- 用户使用的浏览器。 Client − 客户端 - 请求访问令牌的应用程序。 Authorization Server − 授权服务器- 用于验证用户/客户端的服务器。它颁发访问令牌并在其整个生命周期内对其进行跟踪。 Resource Server − 资源服务器- 提供对所请求资源的访问的 API。它验证访问令牌并提供授权。 入门 我们将使用 Spring Security 和 OAuth 2.0 开发一个 Spring Boot 应用程序来说明上述内容。我们现在将开发一个带有内存数据库的基本应用程序来存储用户凭据。该应用程序将使我们轻松了解 OAuth 2.0 与 Spring Security 的工作原理。\n让我们使用 Spring 初始化程序在 Java 8 中创建一个 Maven 项目。让我们从 start.spring.io 开始。我们生成一个具有以下依赖项的应用程序 -\nSpring Web Spring Security Cloud OAuth2 Spring Boot Devtools 通过上面的配置，我们点击 Generate 按钮生成一个项目。该项目将以 zip 文件形式下载。我们将 zip 解压到一个文件夹中。然后我们可以在我们选择的 IDE 中打开该项目。我在这里使用 Spring Tools Suite，因为它针对 Spring 应用程序进行了优化。我们也可以根据需要使用 Eclipse 或 IntelliJ Idea。","title":"[译]Spring Security - OAuth2"},{"content":"内容 简介和概述 入门（实用指南） 简介和概述 Spring Security 附带了大量内置功能和工具，为我们提供方便。在这个例子中，我们将讨论其中三个有趣且有用的功能 -\n表单登录 记住账号 登出 表单登录 基于表单的登录是 Spring Security 提供支持的一种用户名/密码身份验证形式。这是通过 Html 表单提供的。\n每当用户请求受保护的资源时，Spring Security 都会检查请求的身份验证。如果请求未经过身份验证/授权，用户将被重定向到登录页面。登录页面必须由应用程序以某种方式呈现。 Spring Security 默认提供该登录表单。\n此外，如果需要，任何其他配置都必须明确提供，如下所示 -\nprotected void configure(HttpSecurity http) throws Exception { http // ... .formLogin( form -\u0026gt; form.loginPage(\u0026#34;/login\u0026#34;) .permitAll() ); } 此代码要求模板文件夹中存在一个 login.html 文件，该文件将在点击 /login 时返回。该 HTML 文件应包含一个登录表单。此外，该请求应该是对 /login 的 post 请求。参数名称应分别为用户名和密码的“username”和“password”。除此之外，表单中还需要包含 CSRF 令牌。\n一旦我们完成了代码练习，上面的代码片段就会更加清晰。\n记住账号 这种类型的身份验证需要将记住我的 cookie 发送到浏览器。该 cookie 存储用户信息/身份验证主体，并存储在浏览器中。因此，网站可以在下次会话启动时记住用户的身份。 Spring Security 已为此操作准备了必要的实现。\n一种使用散列来保护基于 cookie 的令牌的安全性，而另一种使用数据库或其他持久存储机制来存储生成的令牌。\n登出 默认 URL /logout 通过以下方式注销用户：\n使 HTTP 会话失效 清除配置的所有 RememberMe 身份验证 清除 SecurityContextHolder 重定向到/login?logout WebSecurityConfigurerAdapter 自动将注销功能应用于 Spring Boot 应用程序。\nGetting Started (Practical Guide) 像往常一样，我们首先访问 start.spring.io。这里我们选择一个 maven 项目。我们将项目命名为“formlogin”并选择所需的 Java 版本。我在此示例中选择 Java 8。我们还继续添加以下依赖项 -\nSpring Web Spring Security Thymeleaf Spring Boot DevTools Thymeleaf 是 Java 的模板引擎。它允许我们快速开发静态或动态网页以在浏览器中呈现。它具有极强的可扩展性，允许我们详细定义和自定义模板的处理。除此之外，我们还可以通过点击此链接了解有关 Thymeleaf 的更多信息。\n让我们继续生成项目并下载它。然后，我们将其解压到我们选择的文件夹中，并使用任何 IDE 将其打开。我将使用 Spring Tools Suite 4。它可以从 https://spring.io/tools 网站免费下载，并且针对 Spring 应用程序进行了优化。\n让我们看一下 pom.xml 文件。它应该看起来与此类似 -\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath /\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt; com.spring.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;formlogin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;formlogin\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 让我们在默认包下的文件夹 /src/main/java 中创建一个包。我们将其命名为 config，因为我们会将所有配置类放置在这里。因此，名称应该类似于 - com.tutorial.spring.security.formlogin.config。\n配置类 package com.tutorial.spring.security.formlogin.config; import java.util.List; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; import org.springframework.security.provisioning.UserDetailsManager; import org.springframework.security.web.authentication.UsernamePasswordAuthenticationFilter; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; import com.spring.security.formlogin.AuthFilter; @Configuration public class WebSecurityConfig extends WebSecurityConfigurerAdapter { @Bean protected UserDetailsService userDetailsService() { UserDetailsManager userDetailsManager = new InMemoryUserDetailsManager(); UserDetails user = User.withUsername(\u0026#34;abby\u0026#34;) .password(passwordEncoder().encode(\u0026#34;12345\u0026#34;)) .authorities(\u0026#34;read\u0026#34;) .build(); userDetailsManager.createUser(user); return userDetailsManager; } @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); }; @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable() .authorizeRequests().anyRequest() .authenticated() .and() .formLogin() .and() .rememberMe() .and() .logout() .logoutUrl(\u0026#34;/logout\u0026#34;) .logoutSuccessUrl(\u0026#34;/login\u0026#34;) .deleteCookies(\u0026#34;remember-me\u0026#34;); } } 代码分解 在我们的配置包中，我们创建了 WebSecurityConfig 类。该类扩展了 Spring Security 的 WebSecurityConfigurerAdapter。我们将使用此类进行安全配置，因此让我们用 @Configuration 注释来注释它。因此，Spring Security 知道将此类视为配置类。正如我们所看到的，Spring 使应用程序的配置变得非常容易。\n让我们看一下我们的配置类。\n首先，我们将使用 userDetailsS​​ervice() 方法创建 UserDetailsS​​ervice 类的 bean。我们将使用此 bean 来管理此应用程序的用户。在这里，为了简单起见，我们将使用 InMemoryUserDetailsManager 实例来创建用户。该用户以及我们给定的用户名和密码将包含一个简单的“读取”权限。 现在，让我们看看我们的密码编码器。在本例中，我们将使用 BCryptPasswordEncoder 实例。因此，在创建用户时，我们使用 passwordEncoder 对我们的明文密码进行编码，如下所示 .password(passwordEncoder().encode(\u0026#34;12345\u0026#34;)) 完成上述步骤后，我们继续进行下一个配置。这里，我们重写 WebSecurityConfigurerAdapter 类的 configure 方法。该方法将 HttpSecurity 作为参数。我们将对其进行配置以使用我们的表单登录和注销以及记住我功能。 HTTP 安全配置 我们可以观察到所有这些功能在 Spring Security 中都可用。让我们详细研究以下部分 -\nhttp.csrf().disable() .authorizeRequests().anyRequest().authenticated() .and() .formLogin() .and() .rememberMe() .and() .logout() .logoutUrl(\u0026#34;/logout\u0026#34;) .logoutSuccessUrl(\u0026#34;/login\u0026#34;) .deleteCookies(\u0026#34;remember-me\u0026#34;); 这里有几点需要注意 -\n我们已经禁用了 csrf 或跨站点请求伪造保护，因为这是一个仅用于演示目的的简单应用程序，所以我们现在可以安全地禁用它。\n然后我们添加需要对所有请求进行身份验证的配置。正如我们稍后将看到的，为了简单起见，我们将为此应用程序的索引页使用一个“/”端点。\n之后，我们将使用上面提到的 Spring Security 的 formLogin() 功能。这会生成一个简单的登录页面。\n然后，我们使用 Spring Security 的 RememberMe() 功能。这将执行两件事。\n首先，它会在我们使用 formLogin() 生成的默认登录表单中添加一个“记住我”复选框。 其次，勾选复选框会生成记住我的 cookie。 cookie 存储用户的身份，浏览器存储它。 Spring Security 在将来的会话中检测 cookie 以自动登录。因此，用户无需再次登录即可再次访问该应用程序。 最后，我们有 logout() 功能。为此，Spring security 也提供了默认功能。它在这里执行两个重要的功能 -\n使 Http 会话无效，并取消绑定到会话的对象。 它会清除“记住我”cookie。 从 Spring 的安全上下文中删除身份验证。 我们还提供了一个 logoutSuccessUrl()，以便应用程序在注销后返回到登录页面。这样就完成了我们的应用程序配置。\n受保护的内容（可选） 我们现在将创建一个虚拟索引页面，供用户登录时查看。它还将包含一个注销按钮。\n在我们的/src/main/resources/templates 中，我们添加一个 index.html 文件。然后向其中添加一些 Html 内容。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Hello, world!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, world!\u0026lt;/h1\u0026gt; \u0026lt;a href=\u0026#34;logout\u0026#34;\u0026gt;logout\u0026lt;/a\u0026gt; \u0026lt;!-- Optional JavaScript --\u0026gt; \u0026lt;!-- jQuery first, then Popper.js, then Bootstrap JS --\u0026gt; \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.5.1.slim.min.js\u0026#34; integrity=\u0026#34;sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js\u0026#34; integrity=\u0026#34;sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 此内容来自 Bootstrap 4 入门模板。\n我们还添加\n\u0026lt;a href=\u0026#34;logout\u0026#34;\u0026gt;logout\u0026lt;/a\u0026gt; 到我们的文件，以便用户可以使用此链接注销应用程序。\n资源控制器 我们已经创建了受保护的资源，现在添加控制器来服务该资源。\npackage com.tutorial.spring.security.formlogin.controllers; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; @Controller public class AuthController { @GetMapping(\u0026#34;/\u0026#34;) public String home() { return \u0026#34;index\u0026#34;; } } 正如我们所看到的，这是一个非常简单的控制器。它只有一个 get 端点，在启动我们的应用程序时为我们的 index.html 文件提供服务。\n运行应用程序 让我们将应用程序作为 Spring Boot 应用程序运行。当应用程序启动时，我们可以在浏览器上访问 http://localhost:8080。它应该要求我们提供用户名和密码。此外，我们还可以看到“记住我”复选框。\n登录页面 现在，如果我们提供在 WebSecurity 配置文件中配置的用户信息，我们将能够登录。此外，如果我们勾选“记住我”复选框，我们将能够在我们的 WebSecurity 配置文件中看到“记住我”cookie 浏览器的开发者工具部分。\n正如我们所看到的，cookie 是与我们的登录请求一起发送的。\n此外，网页中还包含一个用于注销的链接。单击该链接后，我们将退出我们的应用程序并返回到我们的登录页面。\n原文链接：https://www.tutorialspoint.com/spring_security/spring_security_form_login_remember_me_and_logout.htm\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security-form-login-remember-me-and-logout/","summary":"内容 简介和概述 入门（实用指南） 简介和概述 Spring Security 附带了大量内置功能和工具，为我们提供方便。在这个例子中，我们将讨论其中三个有趣且有用的功能 -\n表单登录 记住账号 登出 表单登录 基于表单的登录是 Spring Security 提供支持的一种用户名/密码身份验证形式。这是通过 Html 表单提供的。\n每当用户请求受保护的资源时，Spring Security 都会检查请求的身份验证。如果请求未经过身份验证/授权，用户将被重定向到登录页面。登录页面必须由应用程序以某种方式呈现。 Spring Security 默认提供该登录表单。\n此外，如果需要，任何其他配置都必须明确提供，如下所示 -\nprotected void configure(HttpSecurity http) throws Exception { http // ... .formLogin( form -\u0026gt; form.loginPage(\u0026#34;/login\u0026#34;) .permitAll() ); } 此代码要求模板文件夹中存在一个 login.html 文件，该文件将在点击 /login 时返回。该 HTML 文件应包含一个登录表单。此外，该请求应该是对 /login 的 post 请求。参数名称应分别为用户名和密码的“username”和“password”。除此之外，表单中还需要包含 CSRF 令牌。\n一旦我们完成了代码练习，上面的代码片段就会更加清晰。\n记住账号 这种类型的身份验证需要将记住我的 cookie 发送到浏览器。该 cookie 存储用户信息/身份验证主体，并存储在浏览器中。因此，网站可以在下次会话启动时记住用户的身份。 Spring Security 已为此操作准备了必要的实现。\n一种使用散列来保护基于 cookie 的令牌的安全性，而另一种使用数据库或其他持久存储机制来存储生成的令牌。\n登出 默认 URL /logout 通过以下方式注销用户：\n使 HTTP 会话失效 清除配置的所有 RememberMe 身份验证 清除 SecurityContextHolder 重定向到/login?logout WebSecurityConfigurerAdapter 自动将注销功能应用于 Spring Boot 应用程序。\nGetting Started (Practical Guide) 像往常一样，我们首先访问 start.spring.io。这里我们选择一个 maven 项目。我们将项目命名为“formlogin”并选择所需的 Java 版本。我在此示例中选择 Java 8。我们还继续添加以下依赖项 -","title":"[译]Spring Security - 表单登录、记住我和注销"},{"content":"内容 简介和概述 Spring Security 的基本组件 AuthenticationFilter 认证过滤器 AuthenticationManager 认证管理器 AuthenticationProvider 认证提供者 UserDetailsService 用户详情服务 PasswordEncoder 密码编码器 Spring 安全上下文 表单登录 使用数据库登录 登录尝试限制 入门（实用指南） 简介和概述 除了提供各种内置的身份验证和授权选项之外，Spring Security 还允许我们根据需要自定义身份验证过程。从自定义登录页面到我们自己的自定义身份验证提供程序和身份验证过滤器，我们几乎可以自定义身份验证过程的各个方面。\n我们可以定义自己的身份验证过程，范围可以从使用用户名和密码的基本身份验证到复杂的身份验证，例如使用令牌和 OTP 的双因素身份验证。此外，我们可以使用各种数据库 - 关系数据库和非关系数据库，使用各种密码编码器，将恶意用户锁定在其帐户之外，等等。\n今天，我们将讨论三种此类自定义，即自定义表单登录、数据库提供的身份验证以及限制登录尝试。尽管这些都是非常基本的用例，但它们仍然可以让我们更仔细地了解 Spring Security 的身份验证和授权过程。我们还将建立一个注册页面，用户可以通过该页面在我们的应用程序中进行注册。\n首先我们看一下 Spring Security 的架构。它从 servlet 过滤器开始。这些过滤器拦截请求，对其执行操作，然后将请求传递到过滤器链中的下一个过滤器或请求处理程序，或者在不满足某些条件时阻止它们。正是在这个过程中，Spring Security 可以对请求进行身份验证并对请求执行各种身份验证检查。\n它还可以通过不允许未经身份验证或恶意请求访问我们受保护的资源来阻止它们通过。因此我们的应用程序和资源受到保护。\nSpring Security 架构的组件 正如我们在上图中看到的那样，Spring Security 的基本组件如下所示。我们将在讨论过程中简要讨论它们。我们还将讨论它们在身份验证和授权过程中的角色。\nAuthenticationFilter 认证过滤器 这是拦截请求并尝试对其进行身份验证的过滤器。在 Spring Security 中，它将请求转换为身份验证对象并将身份验证委托给 AuthenticationManager。\nAuthenticationManager 认证管理器 它是身份验证的主要策略接口。它使用单独的方法 authenticate()来验证请求。 authenticate() 方法执行身份验证，并在身份验证成功时返回 Authentication 对象，或者在身份验证失败时抛出 AuthenticationException。如果该方法无法决定，它将返回 null。这个过程中的认证过程委托给了我们接下来要讨论的 AuthenticationProvider。\nAuthenticationProvider 认证提供者 AuthenticationManager 由 ProviderManager 实现，后者将流程委托给一个或多个 AuthenticationProvider 实例。任何实现 AuthenticationProvider 接口的类都必须实现两个方法——authenticate() 和 supports()。首先，我们来谈谈 supports()方法。它用于检查我们的 AuthenticationProvider 实现类是否支持特定的身份验证类型。如果支持则返回 true，否则返回 false。\n接下来是 authenticate() 方法。这是身份验证发生的地方。如果支持该认证类型，则启动认证过程。这里这个类可以使用 UserDetailsS​​ervice 实现的 loadUserByUsername() 方法。如果未找到用户，则会抛出 UsernameNotFoundException。\n另一方面，如果找到用户，则使用该用户的身份验证详细信息来验证该用户。例如，在基本认证场景中，可以将用户提供的密码与数据库中的密码进行核对。如果发现它们彼此匹配，则说明成功。然后我们可以从此方法返回一个 Authentication 对象，该对象将存储在安全上下文中，我们将在稍后讨论。\nUserDetailsService 用户详情服务 它是 Spring Security 的核心接口之一。任何请求的身份验证主要取决于 UserDetailsS​​ervice 接口的实现。它最常用于数据库支持的身份验证中以检索用户数据。通过单独的 loadUserByUsername() 方法的实现来检索数据，我们可以在其中提供逻辑来获取用户的用户详细信息。如果未找到用户，该方法将抛出 UsernameNotFoundException。\n密码编码器 在 Spring Security 4 之前，PasswordEncoder 的使用是可选的。用户可以使用内存中身份验证来存储纯文本密码。但 Spring Security 5 强制使用 PasswordEncoder 来存储密码。这使用其多种实现之一对用户的密码进行编码。最常见的实现是 BCryptPasswordEncoder。此外，我们还可以使用 NoOpPasswordEncoder 的实例来进行开发。它将允许密码以纯文本形式存储。\n但它不应该用于生产或现实世界的应用程序。\nSpring 安全上下文 这是在成功验证后存储当前已验证用户的详细信息的位置。然后，身份验证对象在会话的整个应用程序中可用。因此，如果我们需要用户名或任何其他用户详细信息，我们需要首先获取 SecurityContext。这是通过 SecurityContextHolder（一个帮助程序类）完成的，它提供对安全上下文的访问。\n我们可以使用 setAuthentication() 和 getAuthentication() 方法分别存储和检索用户详细信息。\n继续，现在让我们讨论我们将在应用程序中使用的三个自定义实现。\n表单登录 当我们将 Spring Security 添加到现有 Spring 应用程序时，它会添加一个登录表单并设置一个虚拟用户。这是自动配置模式下的 Spring Security。在此模式下，它还设置默认过滤器、身份验证管理器、身份验证提供程序等。此设置是内存中身份验证设置。我们可以覆盖此自动配置来设置我们自己的用户和身份验证过程。我们还可以设置自定义登录方法，例如自定义登录表单。\nSpring Security 只需要了解登录表单的详细信息，例如登录表单的 URI、登录处理 URL 等。然后它将为应用程序呈现我们的登录表单并执行身份验证过程其他提供的配置或 Spring 自己的实现。\n此自定义表单设置只需遵守某些规则即可与 Spring Security 集成。我们需要有一个用户名参数和一个密码参数，参数名称应该是“用户名”和“密码”，因为这些是默认名称。如果我们在自定义中对这些字段使用我们自己的参数名称，我们必须使用 usernameParameter() 和 passwordParameter() 方法通知 Spring Security 这些更改。\n同样，对于我们对登录表单或表单登录方法所做的每一次更改，我们都必须使用适当的方法通知 Spring Security 这些更改，以便它可以将它们与身份验证过程集成。\n使用数据库登录 正如我们所讨论的，Spring Security 默认情况下自动提供内存中身份验证实现。我们可以通过验证其详细信息存储在数据库中的用户来覆盖这一点。在这种情况下，在对用户进行身份验证时，我们可以根据数据库中的凭据验证用户提供的凭据以进行身份 ​​ 验证。我们还可以让新用户在我们的应用程序中注册并将他们的凭据存储在同一数据库中。\n此外，我们还可以提供更改或更新其密码、角色或其他数据的方法。因此，这为我们提供了可以使用更长时间的持久用户数据。\n登录尝试限制 为了限制应用程序中的登录尝试，我们可以使用 Spring Security 的 isAccountNonLocked 属性。 Spring Security 的 UserDetails 为我们提供了该属性。我们可以设置一种身份验证方法，如果任何用户或其他人提供不正确的凭据超过一定次数，我们可以锁定他们的帐户。即使用户提供了正确的凭据，Spring Security 也会禁用锁定用户的身份验证。这是 Spring Security 提供的内置功能。\n我们可以将错误登录尝试的次数存储在数据库中。然后，针对每次错误的身份验证尝试，我们可以更新并检查数据库表。当此类尝试的次数超过给定数量时，我们可以将用户锁定在其帐户之外。因此，在帐户解锁之前，用户将无法再次登录。\n入门（实用指南） 现在让我们开始我们的应用程序。下面列出了此应用程序所需的工具 -\nA Java IDE − 最好是 STS 4，但 Eclipse、IntelliJ Idea 或任何其他 IDE 都可以。 MySql Server Community Edition - 我们需要在我们的系统中下载并安装 MySql Community Server。我们可以点击这里进入官方网站。 MySql Workbench − 它是一个 GUI 工具，我们可以用来与 MySql 数据库交互。 数据库设置 我们先设置数据库。我们将为此应用程序使用 MySql 数据库实例。 MySql Server 社区版可供免费下载和使用。我们将使用 MySql Workbench 与 MySql 服务器连接，并创建一个名为“spring”的数据库以与我们的应用程序一起使用。\n然后我们将创建两个表 - 用户和尝试 - 来保存我们的用户和登录尝试。如前所述，注册我们的应用程序的用户的详细信息将存储在 users 表中。任何用户的登录尝试次数将根据其用户名存储在 attempts 表中。这样我们就可以跟踪尝试并采取必要的行动。\n让我们看一下设置用户表和尝试表的 SQL。\nCREATE TABLE users ( username VARCHAR(45) NOT NULL , password VARCHAR(45) NOT NULL , account_non_locked TINYINT NOT NULL DEFAULT 1 , PRIMARY KEY (username) ); CREATE TABLE attempts ( id int(45) NOT NULL AUTO_INCREMENT, username varchar(45) NOT NULL, attempts varchar(45) NOT NULL, PRIMARY KEY (id) ); 我们现在可以向我们的应用程序添加一个虚拟用户。\nINSERT INTO users(username,password,account_non_locked) VALUES (\u0026#39;user\u0026#39;,\u0026#39;12345\u0026#39;, true); 项目设置 像往常一样，我们将使用 Spring 初始化程序来设置我们的项目。我们将使用 Spring Boot 版本 2.3.2 创建一个 Maven 项目。让我们将项目命名为 formlogin（我们可以选择任何我们想要的名称）和组 id 为 com.tutorial.spring.security。此外，我们将在该项目中使用 Java 版本 8。\n依赖关系 现在，谈到依赖项，我们将在此演示中使应用程序尽可能简单。我们将继续关注今天要探索的功能。因此，我们将选择最少数量的依赖项，这将有助于我们设置应用程序并快速启动和运行。让我们看一下依赖关系 -\nSpring Web − 它捆绑了与 Web 开发相关的所有依赖项，包括 Spring MVC、REST 和嵌入式 Tomcat 服务器。 Spring Security − 用于实现 Spring Security 提供的安全功能。 Thymeleaf − 用于 HTML5/XHTML/XML 的服务器端 Java 模板引擎。 Spring Data JPA − 除了使用 JPA 规范定义的所有功能之外，Spring Data JPA 还添加了自己的功能，例如存储库模式的无代码实现以及从方法名称创建数据库查询。 Mysql Driver − 用于 MySQL 数据库驱动程序。 有了这五个依赖项，我们现在就可以设置我们的项目了。让我们点击生成按钮。这会将我们的项目下载为 zip 文件。我们可以将其解压到我们选择的文件夹中。然后我们在 IDE 中打开该项目。为此，我们将使用 Spring Tool Suite 4。例子。\n让我们将项目加载到 STS 中。我们的 IDE 需要一些时间来下载依赖项并验证它们。让我们看一下 pom.xml 文件。\npom.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;ISO-8859-1\u0026#34;?\u0026gt; \u0026lt;project xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;groupId\u0026gt;com.tutorial.spring.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;formlogin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;formlogin\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-thymeleaf\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-devtools\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;scope\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.junit.vintage\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit-vintage-engine\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-test\u0026lt;artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; We can see that our project details along with our dependencies are enlisted here. 我们可以看到我们的项目详细信息以及我们的依赖项都列在这里。\n数据源 我们将在 application.properties 文件中配置数据源。由于我们将使用本地 MySQL 数据库作为数据源，因此我们在此处提供本地数据库实例的 URL、用户名和密码。我们将我们的数据库命名为“spring”。\nspring.datasource.url=jdbc:mysql://localhost:3306/spring spring.datasource.username=root spring.datasource.password=root 实体 现在让我们创建我们的实体。我们从 User 实体开始，它包含三个字段 - 用户名、密码和 accountNonLocked。该 User 类还实现了 Spring Security 的 UserDetails 接口。此类提供核心用户信息。它用于存储用户数据，稍后可以将其封装到 Authentication 对象中。不建议直接实现接口。\n但对于我们的例子，由于这是一个简单的应用程序来演示数据库登录，因此我们直接在这里实现了这个接口以保持简单。我们可以通过在 User 实体周围使用包装类来实现此接口。\nUser.java\npackage com.tutorial.spring.security.formlogin.model; import java.util.Collection; import java.util.List; import javax.persistence.Column; import javax.persistence.Entity; import javax.persistence.Id; import javax.persistence.Table; import org.springframework.security.core.GrantedAuthority; import org.springframework.security.core.userdetails.UserDetails; @Entity @Table(name = \u0026#34;users\u0026#34;) public class User implements UserDetails { /** * */ private static final long serialVersionUID = 1L; @Id private String username; private String password; @Column(name = \u0026#34;account_non_locked\u0026#34;) private boolean accountNonLocked; public User() { } public User(String username, String password, boolean accountNonLocked) { this.username = username; this.password = password; this.accountNonLocked = accountNonLocked; } @Override public Collection\u0026lt; extends GrantedAuthority\u0026gt; getAuthorities() { return List.of(() -\u0026gt; \u0026#34;read\u0026#34;); } @Override public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } @Override public String getUsername() { return username; } public void setUsername(String username) { this.username = username; } @Override public boolean isAccountNonExpired() { return true; } @Override public boolean isAccountNonLocked() { return accountNonLocked; } @Override public boolean isCredentialsNonExpired() { return true; } @Override public boolean isEnabled() { return true; } public void setAccountNonLocked(Boolean accountNonLocked) { this.accountNonLocked = accountNonLocked; } public boolean getAccountNonLocked() { return accountNonLocked; } } 这里要注意 accountNonLocked 字段。 Spring Security 中的每个用户的帐户默认都是解锁的。为了覆盖该属性并在用户超过允许的尝试次数后将用户锁定在其帐户之外，我们将使用该属性。如果用户超过允许的无效尝试次数，我们将使用此属性将他锁定在帐户之外。 Also, during every authentication attempt, we shall be checking this property with the isAccountNonLocked() method along with the credentials to authenticate the user. Any user with a locked account will not be allowed to authenticate into the application. 此外，在每次身份验证尝试期间，我们将使用 isAccountNonLocked() 方法检查此属性以及凭据以对用户进行身份验证。任何帐户被锁定的用户都将不允许通过身份验证进入应用程序。\n对于 UserDetails 接口的其他方法，我们现在可以简单地提供一个返回 true 的实现，因为我们不会为此应用程序探索这些属性。\n对于该用户的权限列表，我们现在为他分配一个虚拟角色。我们也不会将此属性用于此应用程序。\nAttempts.java\n继续，让我们创建尝试实体来保存无效尝试计数。在数据库中创建时，我们将在此处包含三个字段 - 用户名、一个名为 attempts 的整数（用于记录尝试次数）和一个标识符。\npackage com.tutorial.spring.security.formlogin.model; import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; import javax.persistence.Id; @Entity public class Attempts { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private int id; private String username; private int attempts; /** * @return the id */ public int getId() { return id; } /** * @param id the id to set */ public void setId(int id) { this.id = id; } /** * @return the username */ public String getUsername() { return username; } /** * @param username the username to set */ public void setUsername(String username) { this.username = username; } /** * @return the attempts */ public int getAttempts() { return attempts; } /** * @param attempts the attempts to set */ public void setAttempts(int attempts) { this.attempts = attempts; } } 存储库 我们已经创建了实体，让我们创建存储库来存储和检索数据。我们将有两个存储库，每个实体类一个。对于这两个存储库接口，我们将扩展 JpaRepository，它为我们提供了内置实现，用于保存和检索 application.properties 文件中配置的数据库中的数据。除了提供的方法或查询之外，我们还可以在此处添加我们的方法或查询。\nUserRepository.java\npackage com.tutorial.spring.security.formlogin.repository; import java.util.Optional; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.stereotype.Repository; import com.tutorial.spring.security.formlogin.model.User; @Repository public interface UserRepository extends JpaRepository\u0026lt;User, String\u0026gt; { Optional\u0026lt;User\u0026gt; findUserByUsername(String username); } 正如所讨论的，我们在此处添加了通过用户名检索用户的方法。这将返回我们的用户详细信息，包括用户名、密码和帐户锁定状态。\nAttemptsRepository.java\npackage com.tutorial.spring.security.formlogin.repository; import java.util.Optional; import org.springframework.data.jpa.repository.JpaRepository; import org.springframework.stereotype.Repository; import com.tutorial.spring.security.formlogin.model.Attempts; @Repository public interface AttemptsRepository extends JpaRepository\u0026lt;Attempts, Integer\u0026gt; { Optional\u0026lt;Attempts\u0026gt; findAttemptsByUsername(String username); } 类似地，对于 Attempts，在 AttemptsRepository 中，我们添加了一个自定义方法 findAttemptsByUsername(String username) 来获取有关使用用户名的用户尝试的数据。这将返回一个 Attempts 对象，其中包含用户名和用户尝试身份验证失败的次数。\n配置 由于我们将使用自定义登录表单，因此我们必须覆盖 Spring Security 的默认配置。为此，我们创建配置类，该类扩展了 Spring Security 的 WebSecurityConfigurerAdapter 类。\npackage com.tutorial.spring.security.formlogin.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; @Configuration public class ApplicationConfig extends WebSecurityConfigurerAdapter { @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Override protected void configure(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeRequests().antMatchers(\u0026#34;/register**\u0026#34;) .permitAll() .anyRequest().authenticated() .and() .formLogin() .loginPage(\u0026#34;/login\u0026#34;) .permitAll() .and() .logout() .invalidateHttpSession(true) .clearAuthentication(true) .permitAll(); } } 在这里我们做了两件事 -\n首先，我们指定了将要使用的 PasswordEncoder 接口的实现。我们使用 BCryptPasswordEncoder 的实例来对本示例的密码进行编码。 PasswordEncoder 接口有很多实现，我们可以使用其中任何一个。我们在这里选择 BCryptPasswordEncoder 作为最常用的实现。它使用非常强大的 BCrypt 哈希算法对密码进行编码。\n它通过加入盐来防止彩虹表攻击来实现这一点。除此之外，bcrypt 是一个自适应函数：随着时间的推移，迭代次数可以增加以使其变慢，因此即使计算能力不断增加，它仍然可以抵抗暴力搜索攻击。\n其次，我们重写了 configure()方法来提供登录方法的实现。\n每当我们使用自定义表单代替 Spring Security 提供的表单进行身份验证时，我们都必须使用 formLogin() 方法通知 Spring Security。 然后我们还指定登录 URL – /login。稍后我们会将 URL 映射到控制器中的自定义登录页面。 我们还指定以 /register、/login 开头的端点和注销页面不需要受到保护。我们使用 PermitAll() 方法来做到这一点。这允许每个人访问这些端点。除了这些端点之外，所有端点都需要进行身份验证()。也就是说，用户必须登录才能访问所有其他端点。 注销时，我们指定会话失效，并清除存储在应用程序 SecurityContext 中的身份验证。 安全设置 现在，我们将设置身份验证过程。我们将使用数据库设置身份验证并锁定用户帐户。\n让我们首先创建 UserDetailsS​​ervice 的实现。正如我们之前讨论的，我们需要提供使用数据库进行身份验证的自定义实现。这是因为，正如我们所知，Spring Security 默认情况下仅提供内存中的身份验证实现。因此，我们需要使用基于数据库的流程来覆盖该实现。为此，我们需要重写 UserDetailsS​​ervice 的 loadUserByUsername() 方法。\n用户详情服务 package com.tutorial.spring.security.formlogin.security; import java.util.Optional; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.security.provisioning.UserDetailsManager; import org.springframework.stereotype.Service; import com.tutorial.spring.security.formlogin.model.User; import com.tutorial.spring.security.formlogin.repository.UserRepository; @Service public class SecurityUserDetailsService implements UserDetailsService { @Autowired private UserRepository userRepository; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { User user = userRepository.findUserByUsername(username) .orElseThrow(() -\u0026lt; new UsernameNotFoundException(\u0026#34;User not present\u0026#34;)); return user; } public void createUser(UserDetails user) { userRepository.save((User) user); } } 正如我们在这里看到的，我们在这里实现了 loadUserByUsername() 方法。在这里，我们使用 UserRepository 接口从数据库中获取用户。如果未找到用户，则会抛出 UsernameNotFoundException。\n我们还有一个 createUser() 方法。我们将使用此方法将已使用 UserRepository 在我们的应用程序中注册的用户添加到我们的数据库中。\n认证提供者 我们现在将实现我们的自定义身份验证提供程序。它将实现 AuthenticationProvider 接口。我们这里有两个必须重写和实现的方法。\npackage com.tutorial.spring.security.formlogin.security; import java.util.Optional; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.authentication.AuthenticationProvider; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.LockedException; import org.springframework.security.authentication.UsernamePasswordAuthenticationToken; import org.springframework.security.core.Authentication; import org.springframework.security.core.AuthenticationException; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.stereotype.Component; import com.tutorial.spring.security.formlogin.model.Attempts; import com.tutorial.spring.security.formlogin.model.User; import com.tutorial.spring.security.formlogin.repository.AttemptsRepository; import com.tutorial.spring.security.formlogin.repository.UserRepository; @Component public class AuthProvider implements AuthenticationProvider { private static final int ATTEMPTS_LIMIT = 3; @Autowired private SecurityUserDetailsService userDetailsService; @Autowired private PasswordEncoder passwordEncoder; @Autowired private AttemptsRepository attemptsRepository; @Autowired private UserRepository userRepository; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { String username = authentication.getName(); import com.tutorial.spring.security.formlogin.repository.UserRepository; @Component public class AuthProvider implements AuthenticationProvider { private static final int ATTEMPTS_LIMIT = 3; @Autowired private SecurityUserDetailsService userDetailsService; @Autowired private PasswordEncoder passwordEncoder; @Autowired private AttemptsRepository attemptsRepository; @Autowired private UserRepository userRepository; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { String username = authentication.getName(); Optional\u0026lt;Attempts\u0026gt; userAttempts = attemptsRepository.findAttemptsByUsername(username); if (userAttempts.isPresent()) { Attempts attempts = userAttempts.get(); attempts.setAttempts(0); attemptsRepository.save(attempts); } } private void processFailedAttempts(String username, User user) { Optional\u0026lt;Attempts\u0026gt; userAttempts = attemptsRepository.findAttemptsByUsername(username); if (userAttempts.isEmpty()) { Attempts attempts = new Attempts(); attempts.setUsername(username); attempts.setAttempts(1); attemptsRepository.save(attempts); } else { Attempts attempts = userAttempts.get(); attempts.setAttempts(attempts.getAttempts() + 1); attemptsRepository.save(attempts); if (attempts.getAttempts() + 1 \u0026gt; ATTEMPTS_LIMIT) { user.setAccountNonLocked(false); userRepository.save(user); throw new LockedException(\u0026#34;Too many invalid attempts. Account is locked!!\u0026#34;); } } } @Override public boolean supports(Class\u0026lt;?\u0026gt; authentication) { return true; } } authenticate() - 此方法返回一个经过完全身份验证的对象，包括成功身份验证时的凭据。然后将该对象存储在 SecurityContext 中。为了执行身份验证，我们将使用应用程序的 SecurityUserDetailsS​​ervice 类的 loaduserByUsername() 方法。在这里我们执行多项操作 -\n首先，我们从身份验证请求对象中提取用户凭据，该对象作为参数传递给我们的函数。该身份验证对象由 AuthenticationFilter 类准备，并通过 AuthenticationManager 向下传递到 AuthenticationProvider。\n我们还使用 loadUserByUsername() 方法从数据库中获取用户详细信息。\n现在，首先，我们检查用户帐户是否由于之前失败的身份验证尝试而被锁定。如果我们发现账户被锁定，我们会抛出 LockedException，用户将无法进行身份验证，除非账户再次解锁。\n如果帐户未锁定，我们会将提供的密码与数据库中针对该用户存储的密码进行匹配。这是使用 PasswordEncoder 接口的 matches() 方法完成的。\n如果密码匹配，并且帐户尚未被锁定，我们将返回一个经过完全身份验证的对象。这里我们使用了一个实例 UsernamePasswordAuthenticationToken 类（因为它是用户名密码身份验证）来实现身份验证。同时，我们还将尝试计数器重置为 0。\n另一方面，如果密码不匹配，我们会检查一些条件 -\n如果这是用户第一次尝试，那么他的名字可能不会出现在数据库中。我们使用 AttemptsRepository 中的 findAttemptsByUsername() 方法来检查这一点。 如果未找到，我们会在数据库中为该用户创建一个条目，并将尝试次数设置为 1。 如果找到用户，那么我们将尝试次数增加 1。 然后，我们使用之前定义的常量值检查允许的最大失败尝试次数。 如果该次数超过允许的尝试次数，则用户将被锁定应用程序并引发 LockedException。 supports() - 我们还有 supports 方法来检查我们的 AuthenticationProvider 实现类是否支持我们的身份验证类型。如果匹配、不匹配或无法决定，则分别返回 true、false 或 null。目前我们已将其硬编码为 true。\n控制器 现在让我们创建控制器包。它将包含我们的 HelloController 类。使用这个控制器类，我们将把视图映射到端点，并在命中相应的端点时提供这些视图。我们还将自动装配该组件中的 PasswordEncoder 和 UserDetailsS​​ervice 类。这些注入的依赖项将用于创建我们的用户。现在让我们创建端点。\npackage com.tutorial.spring.security.formlogin.controller; import java.util.Map; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpSession; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.http.MediaType; import org.springframework.security.authentication.BadCredentialsException; import org.springframework.security.authentication.LockedException; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RequestParam; import com.tutorial.spring.security.formlogin.model.User; import com.tutorial.spring.security.formlogin.security.SecurityUserDetailsService; @Controller public class HelloController { @Autowired private SecurityUserDetailsService userDetailsManager; @Autowired private PasswordEncoder passwordEncoder; @GetMapping(\u0026#34;/\u0026#34;) public String index() { return \u0026#34;index\u0026#34;; } @GetMapping(\u0026#34;/login\u0026#34;) public String login(HttpServletRequest request, HttpSession session) { session.setAttribute( \u0026#34;error\u0026#34;, getErrorMessage(request, \u0026#34;SPRING_SECURITY_LAST_EXCEPTION\u0026#34;) ); return \u0026#34;login\u0026#34;; } @GetMapping(\u0026#34;/register\u0026#34;) public String register() { return \u0026#34;register\u0026#34;; } @PostMapping( value = \u0026#34;/register\u0026#34;, consumes = MediaType.APPLICATION_FORM_URLENCODED_VALUE, produces = { MediaType.APPLICATION_ATOM_XML_VALUE, MediaType.APPLICATION_JSON_VALUE } ) public void addUser(@RequestParam Map\u0026lt;String, String\u0026gt; body) { User user = new User(); user.setUsername(body.get(\u0026#34;username\u0026#34;)); user.setPassword(passwordEncoder.encode(body.get(\u0026#34;password\u0026#34;))); user.setAccountNonLocked(true); userDetailsManager.createUser(user); } private String getErrorMessage(HttpServletRequest request, String key) { Exception exception = (Exception) request.getSession().getAttribute(key); String error = \u0026#34;\u0026#34;; if (exception instanceof BadCredentialsException) { error = \u0026#34;Invalid username and password!\u0026#34;; } else if (exception instanceof LockedException) { error = exception.getMessage(); } else { error = \u0026#34;Invalid username and password!\u0026#34;; } return error; } } index (\u0026quot;/\u0026quot;) – 该端点将为我们的应用程序的索引页面提供服务。正如我们之前配置的那样，我们将保护此页面并仅允许经过身份验证的用户能够访问此页面。 login (\u0026quot;/login\u0026quot;) – 如前所述，这将用于服务我们的自定义登录页面。任何未经身份验证的用户都将被重定向到此端点进行身份验证。 register(\u0026quot;/register\u0026quot;) (GET) – 我们的应用程序将有两个“注册”端点。其中之一是提供注册页面。另一项任务是处理注册过程。因此，前者将使用 Http GET，后者将使用 POST 端点。 register(\u0026quot;/register\u0026quot;) (POST) – 我们将使用此端点来处理用户注册过程。我们将从参数中获取用户名和密码。然后我们将使用@Autowired 到该组件中的 passwordEncoder 对密码进行编码。此时我们还将用户帐户设置为解锁。然后，我们将使用 createUser() 方法将此用户数据保存在用户表中。 除了上面的方法之外，我们还有 getErrorMessage() 方法。它用于确定最后抛出的异常以在我们的登录模板中添加消息。这样，我们就可以意识到身份验证错误并显示正确的消息。\n资源 我们已经创建了端点，唯一剩下的就是创建视图。\n首先，我们将创建索引页面。只有成功验证后，用户才能访问此页面。该页面可以访问 Servlet 请求对象，使用该对象我们可以显示登录用户的用户名。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34; xmlns:th=\u0026#34;https://www.thymeleaf.org\u0026#34; xmlns:sec=\u0026#34;https://www.thymeleaf.org/thymeleaf-extras-springsecurity3\u0026#34; \u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello World!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1 th:inline=\u0026#34;text\u0026#34;\u0026gt;Hello [[${#httpServletRequest.remoteUser}]]!\u0026lt;/h1\u0026gt; \u0026lt;form th:action=\u0026#34;@{/logout}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Sign Out\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;html\u0026gt;\u0026lt;/html\u0026gt; \u0026lt;/html\u0026gt; 接下来，我们创建登录视图。这将显示我们的自定义登录表单，其中包含用户名和密码字段。在注销或身份验证失败的情况下也会呈现此视图，并将针对每种情况显示适当的消息。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html xmlns=\u0026#34;http://www.w3.org/1999/xhtml\u0026#34; xmlns:th=\u0026#34;https://www.thymeleaf.org\u0026#34; xmlns:sec=\u0026#34;https://www.thymeleaf.org/thymeleaf-extras-springsecurity3\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Spring Security Example\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div th:if=\u0026#34;${param.error}\u0026#34;\u0026gt; \u0026lt;p th:text=\u0026#34;${session.error}\u0026#34; th:unless=\u0026#34;${session == null}\u0026#34;\u0026gt;[...]\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div th:if=\u0026#34;${param.logout}\u0026#34;\u0026gt;You have been logged out.\u0026lt;/div\u0026gt; \u0026lt;form th:action=\u0026#34;@{/login}\u0026#34; method=\u0026#34;post\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label\u0026gt; User Name : \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label\u0026gt; Password: \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Sign In\u0026#34; /\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 接下来，我们创建所需的视图，即寄存器视图。该视图将允许用户在应用程序中注册自己。该用户数据将存储在数据库中，然后用于身份验证。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;ISO-8859-1\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Insert title here\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/register\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Register\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Please fill in this form to create an account.\u0026lt;/p\u0026gt; \u0026lt;hr /\u0026gt; \u0026lt;label for=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;b\u0026gt;Username\u0026lt;/b\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Enter Username\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;username\u0026#34; required /\u0026gt; \u0026lt;label for=\u0026#34;password\u0026#34;\u0026gt;\u0026lt;b\u0026gt;Password\u0026lt;/b\u0026gt;\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; placeholder=\u0026#34;Enter Password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;password\u0026#34; required /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; class=\u0026#34;registerbtn\u0026#34;\u0026gt;Register\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 最终项目结构 我们最终的项目结构应该与此类似。\n运行应用程序\n然后我们可以将应用程序作为 SpringBootApp 运行。当我们在浏览器上访问 localhost:8080 时，它会将我们重定向回登录页面。\n身份验证成功后，它将带我们进入带有问候语的索引视图。\n因为，在帐户被锁定之前，我们只允许三次失败的尝试，因此在第三次失败的身份验证中，用户将被锁定，并且该消息会显示在屏幕上。\n在点击 /register 端点时，我们还可以注册一个新用户。\n结论 从今天的文章中，我们学习了如何使用基于注释的配置使用数据库来使用自定义表单进行登录。我们还学习了如何防止多次登录尝试失败。在这样做的过程中，我们已经看到了如何实现我们自己的 AuthenticationProvider 和 UserDetailsS​​ervice 来使用我们的自定义身份验证流程对用户进行身份验证。\n原文链接：https://www.tutorialspoint.com/spring_security/spring_security_form_login_with_database.htm\n","permalink":"https://blog.chensoul.cc/posts/2023/08/16/spring-security-form-login-with-database/","summary":"内容 简介和概述 Spring Security 的基本组件 AuthenticationFilter 认证过滤器 AuthenticationManager 认证管理器 AuthenticationProvider 认证提供者 UserDetailsService 用户详情服务 PasswordEncoder 密码编码器 Spring 安全上下文 表单登录 使用数据库登录 登录尝试限制 入门（实用指南） 简介和概述 除了提供各种内置的身份验证和授权选项之外，Spring Security 还允许我们根据需要自定义身份验证过程。从自定义登录页面到我们自己的自定义身份验证提供程序和身份验证过滤器，我们几乎可以自定义身份验证过程的各个方面。\n我们可以定义自己的身份验证过程，范围可以从使用用户名和密码的基本身份验证到复杂的身份验证，例如使用令牌和 OTP 的双因素身份验证。此外，我们可以使用各种数据库 - 关系数据库和非关系数据库，使用各种密码编码器，将恶意用户锁定在其帐户之外，等等。\n今天，我们将讨论三种此类自定义，即自定义表单登录、数据库提供的身份验证以及限制登录尝试。尽管这些都是非常基本的用例，但它们仍然可以让我们更仔细地了解 Spring Security 的身份验证和授权过程。我们还将建立一个注册页面，用户可以通过该页面在我们的应用程序中进行注册。\n首先我们看一下 Spring Security 的架构。它从 servlet 过滤器开始。这些过滤器拦截请求，对其执行操作，然后将请求传递到过滤器链中的下一个过滤器或请求处理程序，或者在不满足某些条件时阻止它们。正是在这个过程中，Spring Security 可以对请求进行身份验证并对请求执行各种身份验证检查。\n它还可以通过不允许未经身份验证或恶意请求访问我们受保护的资源来阻止它们通过。因此我们的应用程序和资源受到保护。\nSpring Security 架构的组件 正如我们在上图中看到的那样，Spring Security 的基本组件如下所示。我们将在讨论过程中简要讨论它们。我们还将讨论它们在身份验证和授权过程中的角色。\nAuthenticationFilter 认证过滤器 这是拦截请求并尝试对其进行身份验证的过滤器。在 Spring Security 中，它将请求转换为身份验证对象并将身份验证委托给 AuthenticationManager。\nAuthenticationManager 认证管理器 它是身份验证的主要策略接口。它使用单独的方法 authenticate()来验证请求。 authenticate() 方法执行身份验证，并在身份验证成功时返回 Authentication 对象，或者在身份验证失败时抛出 AuthenticationException。如果该方法无法决定，它将返回 null。这个过程中的认证过程委托给了我们接下来要讨论的 AuthenticationProvider。\nAuthenticationProvider 认证提供者 AuthenticationManager 由 ProviderManager 实现，后者将流程委托给一个或多个 AuthenticationProvider 实例。任何实现 AuthenticationProvider 接口的类都必须实现两个方法——authenticate() 和 supports()。首先，我们来谈谈 supports()方法。它用于检查我们的 AuthenticationProvider 实现类是否支持特定的身份验证类型。如果支持则返回 true，否则返回 false。\n接下来是 authenticate() 方法。这是身份验证发生的地方。如果支持该认证类型，则启动认证过程。这里这个类可以使用 UserDetailsS​​ervice 实现的 loadUserByUsername() 方法。如果未找到用户，则会抛出 UsernameNotFoundException。\n另一方面，如果找到用户，则使用该用户的身份验证详细信息来验证该用户。例如，在基本认证场景中，可以将用户提供的密码与数据库中的密码进行核对。如果发现它们彼此匹配，则说明成功。然后我们可以从此方法返回一个 Authentication 对象，该对象将存储在安全上下文中，我们将在稍后讨论。\nUserDetailsService 用户详情服务 它是 Spring Security 的核心接口之一。任何请求的身份验证主要取决于 UserDetailsS​​ervice 接口的实现。它最常用于数据库支持的身份验证中以检索用户数据。通过单独的 loadUserByUsername() 方法的实现来检索数据，我们可以在其中提供逻辑来获取用户的用户详细信息。如果未找到用户，该方法将抛出 UsernameNotFoundException。","title":"[译]Spring Security - 使用数据库表单登录"},{"content":"在 MySQL 中，设计树形结构的区域表有多种方式。以下是一些常见的方案：\n父子关系（Parent-Child Relationship）模型：在这种模型中，每个行记录包含一个指向其父级的引用。可以使用一个额外的列来存储父级 ID，或者使用自连接表来表示关系。这种模型简单直观，易于理解和管理。 路径（Path）模型：在这种模型中，每个行记录都包含一个代表其完整路径的字段。路径可以是以某种分隔符（如斜杠）分隔的字符串，例如：/地区/国家/城市。通过解析和处理路径字段，可以轻松地查询父级、子级和兄弟节点。 嵌套集模型（Nested Set Model）：这是一种基于左右值的模型，通过预先计算每个节点的左右值，可以高效地查询树形结构。每个节点都有一个左值和一个右值，用于表示其在树中的位置。这种模型适用于大型树结构，但需要特殊的操作来维护左右值。 物化路径（Materialized Path）模型：这是路径模型的一种改进版本，它使用额外的列来存储节点的层级关系。除了路径字段外，还可以添加一个表示节点级别的字段。这样可以更高效地进行查询，并且可以轻松地获取节点的父级、子级和兄弟节点。 父子关系（Parent-Child Relationship）模型 父子关系（Parent-Child Relationship）模型是一种在 MySQL 中设计树形结构的方式。在该模型中，每个区域记录包含一个指向其父级区域的引用。通过这种父子关系，可以建立区域之间的层级结构。\n以区域为例，我们可以创建一个名为\u0026quot;area\u0026quot;的表来存储区域信息。该表可以包含以下列：\nid：区域的唯一标识符（主键） name：区域的名称 parent_id：指向父级区域的引用 通过使用父子关系模型，我们可以创建以下区域的层级结构：\nid | name | parent_id --------------------------- 1 | 世界 | NULL 2 | 亚洲 | 1 3 | 欧洲 | 1 4 | 北美洲 | 1 5 | 中国 | 2 6 | 日本 | 2 7 | 德国 | 3 8 | 法国 | 3 9 | 美国 | 4 10 | 加拿大 | 4 11 | 北京市 | 5 12 | 上海市 | 5 13 | 东京都 | 6 14 | 横滨市 | 6 在上述示例中，\u0026ldquo;area\u0026quot;表的每一行代表一个区域，通过\u0026quot;parent_id\u0026quot;列建立父子关系。根区域（世界）的\u0026quot;parent_id\u0026quot;为 NULL，表示没有父级区域。其他区域通过指定父级区域的\u0026quot;id\u0026quot;来建立层级关系。\n查询父区域 使用这种模型，我们可以轻松地查询区域的父级、子级和兄弟节点。例如，要查找中国的父级区域，可以通过以下查询实现：\nSELECT * FROM area WHERE id = ( SELECT parent_id FROM area WHERE name = \u0026#39;中国\u0026#39; ); 要查询中国的所有父级区域，可以使用递归查询（Recursive Query）来实现。在 MySQL 中，递归查询可以使用WITH RECURSIVE关键字进行构建。以下是一条查询中国的所有父级区域的 SQL 语句：\nWITH RECURSIVE area_hierarchy AS ( SELECT id, name, parent_id FROM area WHERE name = \u0026#39;中国\u0026#39; UNION ALL SELECT r.id, r.name, r.parent_id FROM area r INNER JOIN area_hierarchy rh ON r.id = rh.parent_id ) SELECT * FROM area_hierarchy; 上述查询语句使用了 WITH RECURSIVE 子句来创建名为\u0026quot;area_hierarchy\u0026quot;的递归查询。初始查询选择名称为\u0026quot;中国\u0026quot;的区域记录作为起始点。然后，使用 UNION ALL 将初始查询结果与后续的递归查询结果连接起来，通过连接条件将父级区域与子级区域关联起来，直到没有更多的父级区域可供连接。\n最终的 SELECT 语句从\u0026quot;area_hierarchy\u0026quot;中选择所有的父级区域记录，并返回结果集。\n请注意，上述查询假设区域的名称（name）列是唯一的，因此使用名称进行查询是准确的。如果存在多个具有相同名称的区域记录，可能需要根据其他条件进行进一步的筛选。\n查询子区域 同样地，我们可以查询中国的子级区域，例如：\nSELECT * FROM area WHERE parent_id = ( SELECT id FROM area WHERE name = \u0026#39;中国\u0026#39; ); 要查询中国的所有子级区域，可以使用递归查询（Recursive Query）来实现。在 MySQL 中，递归查询可以使用 WITH RECURSIVE 关键字进行构建。以下是一条查询中国的所有子级区域的 SQL 语句：\nWITH RECURSIVE area_hierarchy AS ( SELECT id, name, parent_id FROM area WHERE name = \u0026#39;中国\u0026#39; UNION ALL SELECT r.id, r.name, r.parent_id FROM area r INNER JOIN area_hierarchy rh ON r.parent_id = rh.id ) SELECT * FROM area_hierarchy; 上述查询语句使用了 WITH RECURSIVE 子句来创建名为\u0026quot;area_hierarchy\u0026quot;的递归查询。初始查询选择名称为\u0026quot;中国\u0026quot;的区域记录作为起始点。然后，使用 UNION ALL 将初始查询结果与后续的递归查询结果连接起来，通过连接条件将子级区域与父级区域关联起来，直到没有更多的子级区域可供连接。\n最终的 SELECT 语句从\u0026quot;area_hierarchy\u0026quot;中选择所有的子级区域记录，并返回结果集。\n请注意，上述查询假设区域的名称（name）列是唯一的，因此使用名称进行查询是准确的。如果存在多个具有相同名称的区域记录，可能需要根据其他条件进行进一步的筛选。\n查询层级 要查询区域的层级，可以使用递归查询（Recursive Query）来实现。以下是一条查询区域的层级的 SQL 语句：\nWITH RECURSIVE area_hierarchy AS ( SELECT id, name, parent_id, 0 AS level FROM area WHERE parent_id IS NULL UNION ALL SELECT r.id, r.name, r.parent_id, rh.level + 1 FROM area r INNER JOIN area_hierarchy rh ON r.parent_id = rh.id ) SELECT id, name, level FROM area_hierarchy; 上述查询语句使用了 WITH RECURSIVE 子句来创建名为\u0026quot;area_hierarchy\u0026quot;的递归查询。初始查询选择没有父级区域（根区域）的记录作为起始点，并将层级（level）设置为 0。然后，使用 UNION ALL 将初始查询结果与后续的递归查询结果连接起来，通过连接条件将子级区域与父级区域关联起来，并递增层级（level）。\n最终的 SELECT 语句从\u0026quot;area_hierarchy\u0026quot;中选择区域的唯一标识符（id）、名称（name）和层级（level）字段，并返回结果集。\n查询结果将包含每个区域的唯一标识符、名称和其在层级结构中的层级信息。\n请注意，上述查询假设区域的父子关系是正确的，且没有循环依赖。如果存在错误的父子关系或循环依赖，可能会导致查询结果不准确或产生无限递归。\n路径（Path）模型 路径（Path）模型是一种在数据库中表示层级结构的方法，它使用包含完整路径信息的字段来表示每个节点的位置。每个节点的路径由其祖先节点的标识符构成，以特定的分隔符分隔开来。路径模型可以用于表示树形结构、组织结构等。\n以下是一个使用路径模型表示地理区域的示例。假设我们有一个名为\u0026quot;area\u0026quot;的表，其中包含以下列：\nid：区域的唯一标识符（主键） name：区域的名称 path：区域的路径 我们可以使用路径模型来表示以下地理区域的层级结构。\n第一种，path 包括父节点 ID 和当前节点 ID，使用/作为分隔符。\nid | name | path --------------------------- 1 | 世界 | /1/ 2 | 亚洲 | /1/2/ 3 | 欧洲 | /1/3/ 4 | 北美洲 | /1/4/ 5 | 中国 | /1/2/5/ 6 | 日本 | /1/2/6/ 7 | 德国 | /1/3/7/ 8 | 法国 | /1/3/8/ 9 | 美国 | /1/4/9/ 10 | 加拿大 | /1/4/10/ 11 | 北京市 | /1/2/5/11/ 12 | 上海市 | /1/2/5/12/ 13 | 东京都 | /1/2/6/13/ 14 | 横滨市 | /1/2/6/14/ 在上述示例中，每个区域的路径列（path）都以斜杠（/）开始和结束。例如，中国的路径为\u0026rdquo;/1/2/5/\u0026quot;，表示从根区域（id 为 1）到中国的路径。\n第一种，path 包括只父节点 ID，不包括当前节点 ID，使用/作为分隔符。\nid | name | path ---+----------+--------- 1 | 世界 | / 2 | 亚洲 | /1/ 3 | 欧洲 | /1/ 4 | 北美洲 | /1/ 5 | 中国 | /1/2/ 6 | 日本 | /1/2/ 7 | 德国 | /1/3/ 8 | 法国 | /1/3/ 9 | 美国 | /1/4/ 10 | 纽约 | /1/4/9/ 11 | 加利福尼亚 | /1/4/9/ 实际使用过程中，个人倾向于使用第二种。第一种，需要保存区域之后，将 id 拼接到 path 做一次更新操作；而第二种只用做一次插入操作即可。\n第二种建表语句：\nCREATE TABLE area ( id INT PRIMARY KEY, name VARCHAR(255), path VARCHAR(255) ); 插入示例数据的语句：\nINSERT INTO area (id, name, path) VALUES (1, \u0026#39;世界\u0026#39;, \u0026#39;/\u0026#39;), (2, \u0026#39;亚洲\u0026#39;, \u0026#39;/1/\u0026#39;), (3, \u0026#39;欧洲\u0026#39;, \u0026#39;/1/\u0026#39;), (4, \u0026#39;北美洲\u0026#39;, \u0026#39;/1/\u0026#39;), (5, \u0026#39;中国\u0026#39;, \u0026#39;/1/2/\u0026#39;), (6, \u0026#39;日本\u0026#39;, \u0026#39;/1/2/\u0026#39;), (7, \u0026#39;德国\u0026#39;, \u0026#39;/1/3/\u0026#39;), (8, \u0026#39;法国\u0026#39;, \u0026#39;/1/3/\u0026#39;), (9, \u0026#39;美国\u0026#39;, \u0026#39;/1/4/\u0026#39;), (10, \u0026#39;纽约\u0026#39;, \u0026#39;/1/4/9/\u0026#39;), (11, \u0026#39;加利福尼亚\u0026#39;, \u0026#39;/1/4/9/\u0026#39;); 查询父节点 查询指定节点的直接父节点，您可以使用以下 SQL 查询语句：\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE \u0026#39;your_specific_path\u0026#39; = CONCAT(path, id, \u0026#39;/\u0026#39;) 查询指定节点的所有父节点\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE \u0026#39;your_specific_path\u0026#39; = CONCAT(path, id, \u0026#39;%\u0026#39;) ORDER BY LENGTH(path); 请将 your_specific_path 替换为您要查找直接父节点的节点的实际路径值。\n查询子节点 要查询指定节点的直接子节点，您可以使用以下 SQL 查询语句：\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE path = CONCAT(\u0026#39;your_specific_path\u0026#39;,\u0026#39;your_specific_id\u0026#39;,\u0026#39;/\u0026#39;) 查询指定节点的所有子节点：\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE path like CONCAT(\u0026#39;your_specific_path\u0026#39;,\u0026#39;your_specific_id\u0026#39;,\u0026#39;%\u0026#39;) 查询兄弟节点 查询指定节点的兄弟节点：\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE path = \u0026#39;your_specific_path\u0026#39; and id \u0026lt;\u0026gt; \u0026#39;your_specific_id\u0026#39; 查询叶子节点 查询所有的叶子节点：\nSELECT *, SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) AS parent_id, (LENGTH(path) - LENGTH(REPLACE(path, \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;))) AS level FROM area WHERE id NOT IN ( SELECT DISTINCT SUBSTRING_INDEX(SUBSTRING_INDEX(path, \u0026#39;/\u0026#39;, -2), \u0026#39;/\u0026#39;, 1) FROM area WHERE path LIKE \u0026#39;/%\u0026#39; ); 判断是否为叶子节点 判断指定节点是否为叶子节点：\nSELECT count(1)=0 FROM area WHERE path LIKE CONCAT(\u0026#39;your_specific_path\u0026#39;,\u0026#39;your_specific_id\u0026#39;,\u0026#39;%\u0026#39;) 嵌套集模型（Nested Set Model） 嵌套集模型（Nested Set Model）是一种用于表示树形结构数据的数据库设计模式。它使用左右值（Left and Right Values）来表示每个节点在树中的位置关系。嵌套集模型的特点是可以高效地执行树形结构的查询，如获取节点的所有子节点、父节点、兄弟节点等。\n在嵌套集模型中，每个节点都有两个值：左值（Left Value）和右值（Right Value）。左值表示节点在树中的进入顺序，右值表示节点在树中的离开顺序。通过这种方式，树中的每个节点都可以用一个范围（左值和右值之间的范围）来表示。\n下面是一个示例，展示了使用嵌套集模型表示的树形结构：\nid | name | left_value | right_value ----------------------------------------- 1 | 世界 | 1 | 14 2 | 亚洲 | 2 | 9 3 | 欧洲 | 3 | 8 4 | 北美洲 | 10 | 13 5 | 中国 | 4 | 7 6 | 日本 | 5 | 6 7 | 德国 | 11 | 12 在上述示例中，我们使用嵌套集模型表示了一棵树形结构，其中包含了世界、亚洲、欧洲、北美洲、中国、日本和德国等区域。\n世界是根节点，其左值为 1，右值为 14。 亚洲是世界的子节点，其左值为 2，右值为 9。 欧洲是世界的子节点，其左值为 3，右值为 8。 北美洲是世界的子节点，其左值为 10，右值为 13。 中国是亚洲的子节点，其左值为 4，右值为 7。 日本是亚洲的子节点，其左值为 5，右值为 6。 德国是欧洲的子节点，其左值为 11，右值为 12。 通过使用左右值，我们可以轻松地执行一些常见的树形结构查询：\n获取中国的所有子区域：\nSELECT * FROM area WHERE left_value \u0026gt; 4 AND right_value \u0026lt; 7; 获取亚洲的父区域：\nSELECT * FROM area WHERE left_value \u0026lt; 2 AND right_value \u0026gt; 9 LIMIT 1; 获取日本的所有兄弟区域：\nSELECT * FROM area WHERE left_value \u0026gt; 4 AND right_value \u0026lt; 7 AND id != 6; 物化路径（Materialized Path）模型 材料化路径（Materialized Path）模型：这是路径模型的一种改进版本，它使用额外的列来存储节点的层级关系。除了路径字段外，还可以添加一个表示节点级别的字段。这样可以更高效地进行查询，并且可以轻松地获取节点的父级、子级和兄弟节点。\n以下是一个示例，展示了使用带有层级字段的路径模型表示区域的数据：\nid | name | path | depth ------------------------------------- 1 | 世界 | /1/ | 0 2 | 亚洲 | /1/2/ | 1 3 | 欧洲 | /1/3/ | 1 4 | 北美洲 | /1/4/ | 1 5 | 中国 | /1/2/5/ | 2 6 | 日本 | /1/2/6/ | 2 7 | 德国 | /1/3/7/ | 2 在上述示例中，除了路径字段（path）外，增加了一个表示节点层级（depth）的列。节点的层级信息表示了节点在树中的深度，根节点的层级通常为 0。\n通过添加层级字段，可以更高效地进行查询，并且轻松地获取节点的父级、子级和兄弟节点。例如：\n获取节点的父级节点：\nSELECT * FROM area WHERE depth = \u0026lt;node_depth\u0026gt; - 1; 获取节点的父级节点\nSELECT * FROM area WHERE depth \u0026lt; \u0026lt;node_depth\u0026gt; 在上述查询中，假设 \u0026lt;node_depth\u0026gt; 是要查询节点的层级。通过将节点的层级与数据库中的 depth 字段进行比较，我们可以筛选出所有层级小于指定节点层级的记录，即节点的所有父级节点。\n这种方法相对简单且直观，无需对路径进行字符串匹配和比较。然而，使用 depth 字段的前提是节点的层级信息是正确且一致的，并且在插入、更新和删除节点时，正确地维护 depth 字段的值。\n请注意，使用 depth 字段来获取节点的所有父级节点可能会受到性能方面的限制，尤其是在具有大量记录和深层次树结构的情况下。如果性能成为问题，您可能需要考虑使用其他数据模型或结合索引和缓存等技术来提高查询性能。\n获取节点的子级节点：\nSELECT * FROM area WHERE depth = \u0026lt;node_depth\u0026gt; + 1; 获取节点的所有子级节点：\nSELECT * FROM area WHERE depth \u0026gt; \u0026lt;node_depth\u0026gt; 在上述查询中，假设 \u0026lt;node_depth\u0026gt; 是要查询节点的层级。通过将节点的层级与数据库中的 depth 字段进行比较，我们可以筛选出所有层级大于指定节点层级的记录，即节点的所有子级节点。\n获取节点的兄弟节点：\nSELECT * FROM area WHERE depth = \u0026lt;node_depth\u0026gt; AND id != \u0026lt;node_id\u0026gt;; 通过使用带有层级字段的路径模型，查询和操作树形结构数据可以更加高效和直观。这种模型可以结合路径信息和层级信息，提供更灵活和便捷的查询能力。\n总结 在 MySQL 中设计树形结构的区域表时，有多种常用的方法可供选择：\n父节点引用（Parent-Reference）：在区域表中添加一个指向父节点的外键列。简单直观，每个节点都包含其父节点的引用。但查询需要使用递归或自连接。 路径（Path）：在区域表中添加一个表示节点路径的字符串字段。路径可以是层级关系的完整表示，方便查询父节点、子节点和整个子树。 左右值（Nested Set）：使用左右值模型表示树形结构，为每个节点添加左右边界字段。查询节点的父节点、子节点和整个子树时不需要递归，但更新操作可能影响性能。 嵌套集合路径（Nested Set Path）：结合路径和左右值的方法，在区域表中添加路径和左右值字段。方便查询节点的父节点、子节点和整个子树，同时避免了左右值模型的更新性能问题。 每种方法都有其优点和限制，选择适合您应用需求、查询频率、数据量和性能要求的方法至关重要。\n在设计树形结构表时，需要考虑到查询的复杂性、数据一致性、更新操作的性能和数据量的大小。根据具体情况进行权衡和选择合适的设计方案。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/15/tree-structure-in-database/","summary":"在 MySQL 中，设计树形结构的区域表有多种方式。以下是一些常见的方案：\n父子关系（Parent-Child Relationship）模型：在这种模型中，每个行记录包含一个指向其父级的引用。可以使用一个额外的列来存储父级 ID，或者使用自连接表来表示关系。这种模型简单直观，易于理解和管理。 路径（Path）模型：在这种模型中，每个行记录都包含一个代表其完整路径的字段。路径可以是以某种分隔符（如斜杠）分隔的字符串，例如：/地区/国家/城市。通过解析和处理路径字段，可以轻松地查询父级、子级和兄弟节点。 嵌套集模型（Nested Set Model）：这是一种基于左右值的模型，通过预先计算每个节点的左右值，可以高效地查询树形结构。每个节点都有一个左值和一个右值，用于表示其在树中的位置。这种模型适用于大型树结构，但需要特殊的操作来维护左右值。 物化路径（Materialized Path）模型：这是路径模型的一种改进版本，它使用额外的列来存储节点的层级关系。除了路径字段外，还可以添加一个表示节点级别的字段。这样可以更高效地进行查询，并且可以轻松地获取节点的父级、子级和兄弟节点。 父子关系（Parent-Child Relationship）模型 父子关系（Parent-Child Relationship）模型是一种在 MySQL 中设计树形结构的方式。在该模型中，每个区域记录包含一个指向其父级区域的引用。通过这种父子关系，可以建立区域之间的层级结构。\n以区域为例，我们可以创建一个名为\u0026quot;area\u0026quot;的表来存储区域信息。该表可以包含以下列：\nid：区域的唯一标识符（主键） name：区域的名称 parent_id：指向父级区域的引用 通过使用父子关系模型，我们可以创建以下区域的层级结构：\nid | name | parent_id --------------------------- 1 | 世界 | NULL 2 | 亚洲 | 1 3 | 欧洲 | 1 4 | 北美洲 | 1 5 | 中国 | 2 6 | 日本 | 2 7 | 德国 | 3 8 | 法国 | 3 9 | 美国 | 4 10 | 加拿大 | 4 11 | 北京市 | 5 12 | 上海市 | 5 13 | 东京都 | 6 14 | 横滨市 | 6 在上述示例中，\u0026ldquo;area\u0026quot;表的每一行代表一个区域，通过\u0026quot;parent_id\u0026quot;列建立父子关系。根区域（世界）的\u0026quot;parent_id\u0026quot;为 NULL，表示没有父级区域。其他区域通过指定父级区域的\u0026quot;id\u0026quot;来建立层级关系。","title":"数据库如何设计树形结构"},{"content":"Spring Security 的发展过程 Spring Security 是一个功能强大且广泛使用的安全框架，为企业级应用程序提供了全面的安全性。Spring Security 最初是 Acegi Security 项目的一部分，于 2004 年发布，现在已经成为 Spring 生态系统的核心组件。 Spring Security 的发展过程可以分为三个阶段：\n第一阶段：Spring Security 起源于一个名为 Acegi Security 的开源项目，初期重点实现了 Spring 应用的身份认证和授权服务功能。2003 年，Acegi Security 作为一个孵化项目被捐献给 Spring 社区。2004 年，正式作为 Spring 框架的核心组件之一 Absorbed 进 Spring。并更名为 Spring Security。Spring Security 1.0 版本 Spring Security 1.0 版本发布于 2004 年。它提供了最基本的安全功能，包括身份验证和授权。身份验证是验证用户是否是他们所声称的人的过程。授权是确定用户是否有权访问特定资源的过程。 Spring Security 1.0 版本使用了以下技术来实现身份验证和授权：\n表单身份验证：表单身份验证是通过用户提交表单来验证用户身份的过程。 基于角色的访问控制 (RBAC)：RBAC 是一种授权模型，它将用户分配到角色，然后这些角色被授予对特定资源的访问权限。 第二阶段：Spring Security 2.0 版本 Spring Security 2.0 版本发布于 2006 年。它提供了更多的安全功能，包括加密和会话管理。加密是将数据转换成无法被他人理解的形式的过程。会话管理是跟踪用户会话的状态的过程。 Spring Security 2.0 版本使用了以下技术来实现加密和会话管理：\n安全套接字层 (SSL)：SSL 是一种加密协议，它可以保护数据在传输过程中不被窃听。 会话管理：Spring Security 提供了自己的会话管理实现，它可以跟踪用户会话的状态。 第三阶段：Spring Security 3.0 版本 Spring Security 3.0 版本发布于 2008 年。它是一个重大的版本更新，它提供了许多新的安全功能，包括 OAuth、SAML 和 OpenID。 OAuth 是一种授权框架，它允许第三方应用程序访问用户的资源。SAML 是一种单点登录 (SSO) 协议，它允许用户在一个地方登录，然后访问多个网站。OpenID 是一种开放的身份验证协议，它允许用户使用他们选择的身份提供商来验证他们的身份。 Spring Security 3.0 版本使用了以下技术来实现 OAuth、SAML 和 OpenID：\nOAuth：Spring Security 提供了自己的 OAuth 实现，它可以让你轻松地在你的应用程序中使用 OAuth。\nSAML：Spring Security 提供了自己的 SAML 实现，它可以让你轻松地在你的应用程序中使用 SAML。\nOpenID：Spring Security 提供了自己的 OpenID 实现，它可以让你轻松地在你的应用程序中使用 OpenID。\n以下是 Spring Security 的详细的发展过程和版本变化：\nAcegi Security：Acegi Security 是 Spring Security 的前身，最初由 Ben Alex 创建并于 2004 年发布。Acegi Security 提供了一组基于 Spring 的安全性功能，用于保护 Web 应用程序、Web 服务和基于 Spring 的应用程序。\nSpring Security 2：Spring Security 2 是 Acegi Security 的继任者，于 2006 年发布。Spring Security 2 提供了一些新的功能和改进，例如对 OpenID、LDAP 和 CAS 的支持，以及更好的集成和配置选项。\nSpring Security 3：Spring Security 3 于 2009 年发布，是 Spring Security 的一个重大更新。Spring Security 3 提供了更多的安全功能和改进，例如对 RESTful Web 服务的支持、基于注解的安全性、更好的 CSRF 防护、更好的密码存储和认证管理等。\nSpring Security 4：Spring Security 4 于 2015 年发布，带来了一些新的功能和改进，例如对 OAuth2、JWT 和 Spring Boot 的支持、更好的 SSO 和多因素认证等。\nSpring Security 5：Spring Security 5 于 2017 年发布，是一个重大的更新，带来了一些新的功能和改进，例如对 WebFlux 和 Reactive Spring 的支持、更好的 OAuth2 和 OpenID Connect 的支持、更好的密码编码和认证管理等。\nSpring Security 5.1：Spring Security 5.1 发布于 2018 年，主要提供了对 Spring Boot 2.1 的支持和一些新的功能，如 Kotlin DSL、OAuth2 支持的私有证书、JWT 生成器等。\nSpring Security 5.2：Spring Security 5.2 发布于 2019 年，带来了许多改进和新特性，包括对 Spring Cloud Gateway 和 Spring MVC 的 WebFlux 支持、OAuth2 和 OpenID Connect 的改进、更好的密码管理和认证、更好的跨域资源共享（CORS）支持等。\nSpring Security 5.3：Spring Security 5.3 发布于 2020 年，主要提供了更好的 WebFlux 和 RSocket 支持、更好的 OAuth2 支持、更好的测试和性能、更好的 Kotlin 支持、更好的 JUnit 5 支持等。\nSpring Security 5.4：Spring Security 5.4 发布于 2021 年，带来了一些新的功能和改进，例如对 Spring Boot 2.4 的支持、更好的 JWT 和 OAuth2 支持、更好的密码编码、更好的 WebFlux 和 RSocket 支持、更好的测试和性能等。\nSpring Security 5.5：是当前最新的版本，于 2022 年发布。Spring Security 5.5 带来了一些新的功能和改进，包括对 Spring Framework 6 和 Java 17 的支持、更好的密码编码和认证管理、更好的 OAuth2 和 OpenID Connect 支持、更好的 WebFlux 和 RSocket 支持、更好的测试和性能等。\nSpring Security 5.7：由于根据 Spring 官网发布的公告，WebSecurityConfigurerAdapter 已从 Spring Security 5.7.0-M2 中弃用。\nSpring Security 6.0：2022 年 11 月发布，WebSecurityConfigurerAdapter 已从 Spring Security API 中完全删除。它还影响了 2022 年 11 月新发布的 Spring Boot 3.0。\n除了不断改进和增强现有功能之外，Spring Security 还增加了对新的安全威胁的防御和支持，例如 CSRF、XSS、CSP 等。此外，Spring Security 还提供了许多有用的扩展和插件，例如 Spring Security OAuth、Spring Security SAML、Spring Security Kerberos 等，以满足不同的安全需求。\nSpring Security OAuth2 发展 Spring Security OAuth2 是一个用于构建安全的 OAuth2-based 网络应用的框架，它是 Spring Security 的一部分。下面是 Spring Security OAuth2 的发展过程：\n1. Spring Security OAuth2 V1.x – V2.0 最初的几个版本是为了构建一个安全的 OAuth2-based 网络应用。核心的功能包括：\n支持 OAuth2 协议的四种授权方式：授权码（authorization code）、隐式授权（implicit）、密码授权（resource owner password credentials）和客户端凭据（client credentials） 提供了一个简单易用的 API 用于构建 OAuth2 服务器和客户端 支持 JWT（JSON Web Tokens） 提供了详细的文档和示例代码 2. Spring Security OAuth2 V2.1 在 2.1 版本中，Spring Security OAuth2 进行了一系列的改进和扩展，包括：\n支持 OpenID Connect 1.0 支持 Token Introspection Endpoint 更好的支持 JWT，包括 JWS（JSON Web Signatures）和 JWE（JSON Web Encryption） 3. Spring Security 5.0 OAuth2 Login and OAuth2 Client 在 Spring Security 5.0 中，Spring Security OAuth2 的部分功能被合并到了 Spring Security 5.0 中，提供了 OAuth2 登录和客户端支持。\n4. Spring Security 5.1 OAuth2 Resource Server 在 Spring Security 5.1 中，Spring Security OAuth2 的资源服务器功能被合并到了 Spring Security 中。\n5. Spring Security 5.2 OAuth2 Authorization Server 在 Spring Security 5.2 中，Spring Security OAuth2 的授权服务器功能被合并到了 Spring Security 中。这是 Spring Security OAuth2 的最后一个独立版本。\n6. Spring Authorization Server 在 2020 年 4 月，Spring 宣布了一个新的项目——Spring Authorization Server，该项目旨在提供一个用于实现 OAuth 2.1 授权服务器的基础。\n7. Spring Security 5.3 and beyond 在 Spring Security 5.3 和之后的版本中，Spring Security OAuth2 的所有功能都被合并到了 Spring Security 中，而 Spring Security OAuth2 作为一个独立的项目已经停止开发。与之相对应的 Spring Security OAuth Boot 2 Autoconfig 也停止了开发。\n总结一下，目前，Spring Security OAuth2 的最新版本为 2.5.2.RELEASE，并且所有类都标注为 @Deprecated，官方也提供了一个迁移文档 OAuth 2.0 Migration Guide。\nSpring Boot 和 Spring OAuth2 版本关系 Spring Boot 和 Spring OAuth2 是可以配合使用的，主要注意版本匹配即可。\nSpring Boot 使用了特定版本的 Spring OAuth2 作为依赖。所以使用对应的 Spring Boot 版本，就会自动获取匹配的 Spring OAuth2 版本。\n举几个版本的例子：\nSpring Boot 1.5.x 使用 Spring OAuth2 2.0.x Spring Boot 2.0.x 使用 Spring OAuth2 2.0.x Spring Boot 2.1.x 使用 Spring OAuth2 2.1.x Spring Boot 2.2.x 使用 Spring OAuth2 2.2.x Spring Boot 2.3.x 使用 Spring OAuth2 2.3.x 所以使用 Spring Boot 时，不需要额外指定 Spring OAuth2 的版本，只需要选择匹配的 Spring Boot 版本即可。\n在配置和使用 Spring OAuth2 时，只需要参考 Spring OAuth2 的文档即可，不需要特别关注其版本。Spring Boot 会负责管理版本匹配。\n此外，从 Spring Boot 1.5 开始，Spring Security 已经集成了 OAuth2 的实现，可以直接使用 Spring Security 来实现 OAuth2，无需引入 Spring OAuth 项目。\n总之，Spring Boot 大大简化了 Spring OAuth2 的使用，只需要关注 Spring Boot 版本即可自动获取正确的 Spring OAuth2 版本。\nSpring Cloud 和 Spring OAuth2 版本关系 Spring Cloud 和 Spring OAuth2 版本之间没有固定的对应关系，但通常来说建议符合以下情况：\nSpring Cloud 版本越新，内置的 Spring OAuth 支持也会更稳定和完善。 Spring Cloud Hoxton/Greenwich 等主流版本，内置的 Spring OAuth 支持正常使用 Spring Security OAuth2 版本 2.x。 Spring Cloud Edgware 及更早版本，内置的 Spring OAuth 支持建议使用 Spring Security OAuth2 版本 1.x。 即使 Spring Cloud 版本和 Spring Security OAuth 版本不完全匹配，也无大碍，但功能和兼容性会受一定影响。 所以一般来说：\nSpring Cloud Finch/ Greenwich 等最新版本，建议使用 Spring Security OAuth2 版本 2.3.x 及以上。 Spring Cloud Edgware 到 Hoxton，建议使用 Spring Security OAuth2 版本 1.5.x 到 2.3.x 都可以。 Spring Cloud 版本比较早，如 Dalston 以下，建议使用 Spring Security OAuth2 版本 1.0.x 到 1.5.x。 但不是说版本一定要完全匹配，主要看自己需要用到的 Spring OAuth 功能是否得到支持。选择版本时优先考虑 Spring Cloud 版本的内置支持程度。此外，也可以根据项目其他依赖选择一个相对稳定的 Spring Security OAuth 版本。\nSpring Cloud Security Spring Cloud Security 提供了一种集成化的方式来实现微服务应用的安全功能。主要有以下几点：\n身份认证(Authentication) Spring Cloud Security 支持常见的认证方式，比如基于 OAuth2.0 的认证协议。可以实现集中式的认证管理，登入后获取访问令牌并在各个微服务之间传递。\n授权(Authorization) 支持基于 RBAC 和 ABAC 等授权模型。可以实现集中式的授权管理，给不同用户或组分配不同的访问权限。\n安全终端(Security Endpoints) 提供了安全终端的实现，比如/oauth/token 令牌访问端点、/userinfo 用户信息端点等。\n加密通信(Encryption) 支持在微服务之间进行安全的 HTTP 通信，通过 TLS/SSL 加密数据传输和服务间调用。\n日志审计(Logging \u0026amp; Auditing) 支持收集和记录安全相关的审计日志，比如授权错误日志、登入/登出日志等，方便管理和监控。\n安全配置(Security Configuration) 提供了弹性和易用的安全配置能力，如动态配置安全相关 Bean 等。\n集成支持(Integration Support) 天然支持 Spring Cloud 和 Springboot 项目，无缝集成从认证到授权的全套安全功能。\n所以总体来说，Spring Cloud Security 提供了一种标准化和集成的方式来实现微服务环境下的安全需求。开发人员可以更便捷地利用其丰富的功能。\n示例 Spring Security 如何实现 JSON Web Token 的功能？ Spring Security 可以通过如下方式实现 JSON Web Token(JWT)的功能：\n导入 spring-security-jwt 依赖。 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.security\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-security-jwt\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; spring-boot-starter-security 版本信息如下：\nspring-boot-starter-parent 版本号：2.7.5 依赖的 spring-boot-starter-security 版本号：2.7.5 spring-boot-starter-security 是 Spring Boot 安全功能的启动器依赖，它会自动引入核心安全依赖：\nspring-security-core：Spring Security 的核心模块，提供认证、授权、安全相关的主要接口和组件。\nspring-security-config：提供了 Spring Security 的基础配置能力，包含过滤器链、密码编码器等。\nspring-security-web：提供了 web 安全相关的支持，如过滤器、登录表单、注解等。\nspring-security-crypto：包含密码哈希功能的实现类，用于对密码进行安全的加密存储。\nspring-security-data：包含了支持 JDBC 和 LDAP 等后端数据源的安全组件。\nspring-security-oauth2-client：提供了对 OAuth2 客户端功能的支持。主要提供以下 OAuth2 客户端相关功能：\n客户端注册和资源服务器配置：支持为客户端应用配置 clientId、secret 等信息。 客户端凭证获取：支持 BasicAuth 和密码模式获取 client credentials。 访问令牌请求：实现客户端向授权服务器请求访问令牌的功能，支持 password、refresh_token 等 grant 类型。 令牌存储：提供 TokenStore 接口的实现，支持在会话或数据库中存储/获取访问令牌。 资源服务器访问：通过访问令牌来访问受保护的资源，支持从请求头或参数中提取令牌。 刷新令牌：实现使用 refresh_token 来刷新过期的访问令牌功能。 用户授权：提供类似@PreAuthorize 注解来处理用户授权逻辑。 客户端详情：封装 ClientDetails 实现类，包含客户端注册信息。 默认令牌服务：DefaultTokenServices 实现类管理令牌生命周期。 请求工厂：提供 RestTemplate 和 Apache HTTP Components 等请求客户端。 spring-security-oauth2-client 模块同时也提供部分支持其他授权类型：\n授权码模式(authorization_code)：主流模式，客户端通过 auth code 获取 access token。 密码模式(password)：客户端直接提供用户名密码获取 token，适合 trusted 客户端。 隐藏式授权模式(implicit)：客户端直接获取 access token，不支持 refresh。 客户端模式(client_credentials)：客户端以自身名义请求资源服务，适合机密客户端。 资主授权模式(owner)：类似密码模式但用户需确认通过用户界面。 运行时审批模式(approval_prompt)：用户每次访问都需确认授权。 除了上述常见授权类型外，spring-security-oauth2-client 还提供了对以下模式的选择性支持：\n断路器模式(urn:ietf:params:oauth:grant-type:device_code) 分阶段授权模式(urn:ietf:params:oauth:grant-type:stage) 令牌交换模式(urn:ietf:params:oauth:grant-type:token-exchange) spring-security-oauth2-core：OAuth2 协议支持的核心部件。\n因此 spring-boot-starter-security 的版本始终保持与 spring-boot-starters 版本一致。\n当前较为主流和稳定的 spring-boot 版本有：\nSpring Boot 2.7.x 最新版 Spring Boot 2.6.x Spring Boot 2.5.x 对应的 spring-boot-starter-security 版本如下：\nSpring Boot 2.7.x - spring-boot-starter-security 2.7.x Spring Boot 2.6.x - spring-boot-starter-security 2.6.x Spring Boot 2.5.x - spring-boot-starter-security 2.5.x 所以在选择 spring boot 版本时，直接依赖 spring-boot-starter-security 而不用单独指定版本，就可以保证安全功能的版本一致性。\n目前大多数场景下可以使用 Spring Boot 2.6.x 或者 2.7.x 作为选择，它们内置的 spring-boot-starter-security 版本都很成熟。\n配置 JwtToken enhancer 来生成 JWT 令牌。 @Bean public JwtAccessTokenConverter jwtTokenEnhancer() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\u0026#34;123456\u0026#34;); return converter; } 定义 JwtTokenStore 来保存 JWT 令牌。 @Bean public TokenStore tokenStore() { return new JwtTokenStore(jwtTokenEnhancer()); } 在 AuthorizationServerConfigurerAdapter 配置类中设置 tokenStore。 @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) { endpoints.tokenStore(tokenStore()); } 客户端使用 JWT 令牌进行认证访问资源服务器。\n资源服务器使用 JwtTokenStore 和 JwtAccessTokenConverter 校验 JWT 令牌的合法性。\n解析 JWTpayload 获取用户信息，实现鉴权决策。\nString username = ((Jwt)authentication.getPrincipal()).getSubject(); 完整代码，配置类：\n@Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean public JwtAccessTokenConverter accessTokenConverter() { JwtAccessTokenConverter converter = new JwtAccessTokenConverter(); converter.setSigningKey(\u0026#34;as123456dfsdf\u0026#34;); return converter; } @Bean public TokenStore tokenStore() { return new JwtTokenStore(accessTokenConverter()); } @Override protected void configure(HttpSecurity http) throws Exception { http.csrf().disable(); http .authorizeRequests() .antMatchers(\u0026#34;/oauth/**\u0026#34;).permitAll(); } @Bean @Primary public DefaultTokenServices tokenServices() { DefaultTokenServices defaultTokenServices = new DefaultTokenServices(); defaultTokenServices.setTokenStore(tokenStore()); defaultTokenServices.setSupportRefreshToken(true); return defaultTokenServices; } } 授权服务器配置，使用客户端模式配置：\n@Configuration public class AuthorizationServerConfig extends AuthorizationServerConfigurerAdapter { @Autowired private TokenStore tokenStore; @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory() .withClient(\u0026#34;clientapp\u0026#34;) .secret(\u0026#34;$2a$10$6aQQyhlhol4M1KAncczPdu4zX7/TgvjpOU.sWzt7j5Xl6W/z5V4cC\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;， \u0026#34;refresh_token\u0026#34;) .scopes(\u0026#34;read\u0026#34;， \u0026#34;write\u0026#34;) .accessTokenValiditySeconds(3600); } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.tokenStore(tokenStore) .authenticationManager(authenticationManager()); } } 主要配置：\n使用 ClientDetailsServiceConfigurer 配置客户端信息，如 clientId、secret 等 配置 tokenStore 配置 authenticationManager 来获取用户信息 这样就实现了基于客户端模式下的授权服务配置，客户端可以使用 clientId/secret 获取访问令牌而无需用户登录。\n客户端访问示例：\ncurl -X POST http://localhost:8080/oauth/token -d \u0026#34;grant_type=password\u0026amp;username=user\u0026amp;password=password\u0026amp;client_id=clientapp\u0026amp;client_secret=secret\u0026#34; 让客户端在后台获取访问令牌，资源服务再使用令牌验证授权。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/15/spring-security-oauth2-history/","summary":"Spring Security 的发展过程 Spring Security 是一个功能强大且广泛使用的安全框架，为企业级应用程序提供了全面的安全性。Spring Security 最初是 Acegi Security 项目的一部分，于 2004 年发布，现在已经成为 Spring 生态系统的核心组件。 Spring Security 的发展过程可以分为三个阶段：\n第一阶段：Spring Security 起源于一个名为 Acegi Security 的开源项目，初期重点实现了 Spring 应用的身份认证和授权服务功能。2003 年，Acegi Security 作为一个孵化项目被捐献给 Spring 社区。2004 年，正式作为 Spring 框架的核心组件之一 Absorbed 进 Spring。并更名为 Spring Security。Spring Security 1.0 版本 Spring Security 1.0 版本发布于 2004 年。它提供了最基本的安全功能，包括身份验证和授权。身份验证是验证用户是否是他们所声称的人的过程。授权是确定用户是否有权访问特定资源的过程。 Spring Security 1.0 版本使用了以下技术来实现身份验证和授权：\n表单身份验证：表单身份验证是通过用户提交表单来验证用户身份的过程。 基于角色的访问控制 (RBAC)：RBAC 是一种授权模型，它将用户分配到角色，然后这些角色被授予对特定资源的访问权限。 第二阶段：Spring Security 2.0 版本 Spring Security 2.0 版本发布于 2006 年。它提供了更多的安全功能，包括加密和会话管理。加密是将数据转换成无法被他人理解的形式的过程。会话管理是跟踪用户会话的状态的过程。 Spring Security 2.0 版本使用了以下技术来实现加密和会话管理：\n安全套接字层 (SSL)：SSL 是一种加密协议，它可以保护数据在传输过程中不被窃听。 会话管理：Spring Security 提供了自己的会话管理实现，它可以跟踪用户会话的状态。 第三阶段：Spring Security 3.0 版本 Spring Security 3.0 版本发布于 2008 年。它是一个重大的版本更新，它提供了许多新的安全功能，包括 OAuth、SAML 和 OpenID。 OAuth 是一种授权框架，它允许第三方应用程序访问用户的资源。SAML 是一种单点登录 (SSO) 协议，它允许用户在一个地方登录，然后访问多个网站。OpenID 是一种开放的身份验证协议，它允许用户使用他们选择的身份提供商来验证他们的身份。 Spring Security 3.0 版本使用了以下技术来实现 OAuth、SAML 和 OpenID：","title":"Spring Security和OAuth2发展过程"},{"content":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：减少可变性。\n原文 不可变类是实例不能被修改的类。每个实例中包含的所有信息在对象的生命周期内都是固定的，因此永远不会观察到任何更改。Java 库包含许多不可变的类，包括 String、基本类型的包装类、BigInteger 和 BigDecimal。这么做有很好的理由：不可变类比可变类更容易设计、实现和使用。它们不太容易出错，而且更安全。\n要使类不可变，请遵循以下 5 条规则：\n1、不要提供修改对象状态的方法（这类方法也被称为修改器）\n2、确保类不能被继承。 这可以防止粗心或恶意的通过子类实例对象状态可改变的方式，损害父类的不可变行为。防止子类化通常用 final 修饰父类，但是还有一种替代方法，我们将在后面讨论。\n3、所有字段用 final 修饰。 这清楚地表达了意图，并由系统强制执行。同样，如果在没有同步的情况下，引用新创建的实例并从一个线程传递到另一个线程，那么就有必要确保正确的行为，就像内存模型中描述的那样。\n4、所有字段设为私有。 这将阻止客户端访问字段引用的可变对象并直接修改这些对象。虽然在技术上允许不可变类拥有包含基本类型或对不可变对象的引用的公共 final 字段，但不建议这样做，因为在以后的版本中无法更改内部表示。\n5、确保对任何可变组件的独占访问。 如果你的类有任何引用可变对象的字段，请确保该类的客户端无法获得对这些对象的引用。永远不要向提供对象引用的客户端初始化这样的字段，也不要从访问器返回字段。在构造函数、访问器和 readObject 方法中创建防御性副本。\n前面条目中的许多示例类都是不可变的。其中一个类是 PhoneNumber，它的每个属性都有访问器，但没有对应的修改器。下面是一个稍微复杂的例子：\n// Immutable complex number class public final class Complex { private final double re; private final double im; public Complex(double re, double im) { this.re = re; this.im = im; } public double realPart() { return re; } public double imaginaryPart() { return im; } public Complex plus(Complex c) { return new Complex(re + c.re, im + c.im); } public Complex minus(Complex c) { return new Complex(re - c.re, im - c.im); } public Complex times(Complex c) { return new Complex(re * c.re - im * c.im, re * c.im + im * c.re); } public Complex dividedBy(Complex c) { double tmp = c.re * c.re + c.im * c.im; return new Complex((re * c.re + im * c.im) / tmp, (im * c.re - re * c.im) / tmp); } @Override public boolean equals(Object o) { if (o == this) return true; if (!(o instanceof Complex)) return false; Complex c = (Complex) o; // See page 47 to find out why we use compare instead of == return Double.compare(c.re, re) == 0 \u0026amp;\u0026amp; Double.compare(c.im, im) == 0; } @Override public int hashCode() { return 31 * Double.hashCode(re) + Double.hashCode(im); } @Override public String toString() { return \u0026#34;(\u0026#34; + re + \u0026#34; + \u0026#34; + im + \u0026#34;i)\u0026#34;; } } 这个类表示一个复数（包含实部和虚部的数）。除了标准的 Object 方法之外，它还为实部和虚部提供访问器，并提供四种基本的算术运算：加法、减法、乘法和除法。值得注意的是，算术操作创建和返回一个新的 Complex 实例，而不是修改这个实例。这种模式称为函数式方法，因为方法返回的结果是将函数应用到其操作数，而不是修改它。将其与过程式或命令式方法进行对比，在这种方法中，方法将一个计算过程应用于它们的操作数，从而导致其状态发生变化。注意，方法名是介词（如 plus)，而不是动词（如 add)。这强调了这样一个事实，即方法不会改变对象的值。BigInteger 和 BigDecimal 类不遵守这种命名约定，这导致了许多使用错误。\n如果不熟悉函数式方法，那么它可能看起来不自然，但它实现了不变性，这么做有很多优势。 不可变对象很简单。 不可变对象可以保持它被创建时的状态。如果能够确保所有构造函数都建立了类不变量，那么就可以保证这些不变量将一直保持，而无需你或使用类的程序员做进一步的工作。另一方面，可变对象可以具有任意复杂的状态空间。如果文档没有提供由修改器方法执行的状态转换的精确描述，那么就很难或不可能可靠地使用可变类。\n不可变对象本质上是线程安全的；它们不需要同步。 它们不会因为多线程并发访问而损坏。这无疑是实现线程安全的最简单方法。由于任何线程都无法观察到另一个线程对不可变对象的任何影响，因此 可以自由共享不可变对象。 同时，不可变类应该鼓励客户端尽可能复用现有的实例。一种简单的方法是为常用值提供公共静态 final 常量。例如，Complex 类可能提供以下常量：\npublic static final Complex ZERO = new Complex(0, 0); public static final Complex ONE = new Complex(1, 0); public static final Complex I = new Complex(0, 1); 这种方法可以更进一步。不可变类可以提供静态工厂，这些工厂缓存经常请求的实例，以避免在现有实例可用时创建新实例。所有包装类和 BigInteger 都是这样做的。使用这种静态工厂会导致客户端共享实例而不是创建新实例，从而减少内存占用和垃圾收集成本。在设计新类时，选择静态工厂而不是公共构造函数，这将使你能够灵活地在以后添加缓存，而无需修改客户端。\n不可变对象可以自由共享这一事实的结果之一是，你永远不需要对它们进行防御性的复制。事实上，你根本不需要做任何拷贝，因为拷贝将永远等同于原件。因此，你不需要也不应该在不可变类上提供克隆方法或复制构造函数。这在 Java 平台的早期并没有得到很好的理解，因此 String 类确实有一个复制构造函数，但是，即使有，也应该少用。\n你不仅可以共享不可变对象，而且可以共享它们的内部实现。 例如，BigInteger 类在内部使用符号大小来表示。符号由 int 表示，大小由 int 数组表示。negate 方法产生一个新的 BigInteger，大小相同，符号相反。即使数组是可变的，也不需要复制；新创建的 BigInteger 指向与原始数组相同的内部数组。\n不可变对象可以很好的作为其他对象的构建模块， 无论是可变的还是不可变的。如果知道复杂对象的组件对象不会在其内部发生更改，那么维护复杂对象的不变性就会容易得多。这个原则的一个具体的例子是，不可变对象很合适作为 Map 的键和 Set 的元素：你不必担心它们的值在 Map 或 Set 中发生变化，从而破坏 Map 或 Set 的不变性。\n不可变对象自带提供故障原子性。他们的状态从未改变，所以不可能出现暂时的不一致。\n不可变类的主要缺点是每个不同的值都需要一个单独的对象。 创建这些对象的成本可能很高，尤其是对象很大的时候。例如，假设你有一个百万位的 BigInteger，你想改变它的低阶位：\nBigInteger moby = ...; moby = moby.flipBit(0); flipBit 方法创建了一个新的 BigInteger 实例，也有百万位长，只在一个比特上与原始的不同。该操作需要与 BigInteger 的大小成比例的时间和空间。与 java.util.BitSet 形成对比。与 BigInteger 一样，BitSet 表示任意长的位序列，但与 BigInteger 不同，BitSet 是可变的。BitSet 类提供了一种方法，可以让你在固定的时间内改变百万位实例的单个位的状态：\nBitSet moby = ...; moby.flip(0); 如果执行多步操作，在每一步生成一个新对象，最终丢弃除最终结果之外的所有对象，那么性能问题就会被放大。有两种方法可以解决这个问题。第一种方法是猜测通常需要哪些多步操作，并将它们作为基本数据类型提供。如果将多步操作作为基本数据类型提供，则不可变类不必在每个步骤中创建单独的对象。在内部，不可变类可以任意聪明。例如，BigInteger 有一个包私有的可变「伴随类」，它使用这个类来加速多步操作，比如模块化求幂。由于前面列出的所有原因，使用可变伴随类要比使用 BigInteger 难得多。幸运的是，你不必使用它：BigInteger 的实现者为你做了艰苦的工作。\n如果你能够准确地预测客户端希望在不可变类上执行哪些复杂操作，那么包私有可变伴随类方法就可以很好地工作。如果不是，那么你最好的选择就是提供一个公共可变伴随类。这种方法在 Java 库中的主要示例是 String 类，它的可变伴随类是 StringBuilder（及其过时的前身 StringBuffer)。\n既然你已经知道了如何创建不可变类，并且了解了不可变性的优缺点，那么让我们来讨论一些设计方案。回想一下，为了保证不变性，类不允许自己被子类化。可以用 final 修饰以达到目的，但是还有另外一个更灵活的选择，你可以将其所有构造函数变为私有或包私有，并使用公共静态工厂方法来代替公共的构造函数。Complex 类采用这种方式修改后如下所示：\n// Immutable class with static factories instead of constructors public class Complex { private final double re; private final double im; private Complex(double re, double im) { this.re = re; this.im = im; } public static Complex valueOf(double re, double im) { return new Complex(re, im); } ... // Remainder unchanged } 这种方式通常是最好的选择。它是最灵活的，因为它允许使用多个包私有实现类。对于驻留在包之外的客户端而言，不可变类实际上是 final 类，因为不可能继承自另一个包的类，因为它缺少公共或受保护的构造函数。除了允许多实现类的灵活性之外，这种方法还通过改进静态工厂的对象缓存功能，使得后续版本中调优该类的性能成为可能。\n当编写 BigInteger 和 BigDecimal 时，不可变类必须是有效的 final 这一点没有被广泛理解，因此它们的所有方法都可能被重写。遗憾的是，在保留向后兼容性的情况下，这个问题无法得到纠正。如果你编写的类的安全性依赖于来自不受信任客户端的 BigInteger 或 BigDecimal 参数的不可变性，那么你必须检查该参数是否是「真正的」BigInteger 或 BigDecimal，而不是不受信任的子类实例。如果是后者，你必须防御性的复制它，假设它可能是可变的:\npublic static BigInteger safeInstance(BigInteger val) { return val.getClass() == BigInteger.class ? val : new BigInteger(val.toByteArray()); } 这个条目开头的不可变类的规则列表指出，没有方法可以修改对象，它的所有字段必须是 final 的。实际上，这些规则过于严格，可以适当放松来提高性能。实际上，任何方法都不能在对象的状态中产生外部可见的更改。然而，一些不可变类有一个或多个非 final 字段，它们在第一次需要这些字段时，就会在其中缓存昂贵计算的结果。如果再次请求相同的值，则返回缓存的值，从而节省了重新计算的成本。这个技巧之所以有效，是因为对象是不可变的，这就保证了重复计算会产生相同的结果。\n例如，PhoneNumber 的 hashCode 方法在第一次调用时计算哈希代码，并缓存它，以备再次调用。这个技术是一个延迟初始化的例子，String 也使用这个技术。\n关于可序列化性，应该提出一个警告。如果你选择让不可变类实现 Serializable，并且该类包含一个或多个引用可变对象的字段，那么你必须提供一个显式的 readObject 或 readResolve 方法，或者使用 ObjectOutputStream.writeUnshared 或 ObjectInputStream.readUnshared 方法，即使默认的序列化形式是可以接受的。否则攻击者可能创建类的可变实例。\n总而言之，不要急于为每个 getter 都编写 setter。类应该是不可变的，除非有很好的理由让它们可变。 不可变类提供了许多优点，它们唯一的缺点是在某些情况下可能出现性能问题。你应该始终使小的值对象（如 PhoneNumber 和 Complex）成为不可变的。（Java 库中有几个类，比如 java.util.Date 和 java.awt.Point，应该是不可改变的，但事实并非如此。）也应该认真考虑将较大的值对象（如 String 和 BigInteger）设置为不可变的。只有确认了实现令人满意的性能是必要的，才应该为不可变类提供一个公共可变伴随类。\n对于某些类来说，不变性是不切实际的。如果一个类不能成为不可变的，那么就尽可能地限制它的可变性。 减少对象可能存在的状态数可以更容易地 reason about the object 并减少出错的可能性。因此，除非有令人信服的理由，否则每个字段都应该用 final 修饰。将本条目的建议与 Item-15 的建议结合起来，你自然会倾向于 声明每个字段为私有 final，除非有很好的理由不这样做。\n构造函数应该创建完全初始化的对象，并建立所有的不变量。 除非有充分的理由，否则不要提供与构造函数或静态工厂分离的公共初始化方法。类似地，不要提供「重新初始化」的方法，该方法允许复用对象，就好像它是用不同的初始状态构造的一样。这些方法通常只提供很少的性能收益，而代价是增加了复杂性。\nCountDownLatch 类体现了这些原则。它是可变的，但是它的状态空间故意保持很小。创建一个实例，使用它一次，它就完成了使命：一旦倒计时锁存器的计数达到零，你可能不会复用它。\n关于本条目中 Complex 类的最后一点需要补充的说明。这个例子只是为了说明不变性。它不是一个工业级强度的复数实现。它使用了复杂乘法和除法的标准公式，这些公式没有被正确地四舍五入，并且为复杂的 NaNs 和 infinities 提供了糟糕的语义。\n扩展 常见的方法来减少可变性 减少可变性是一种重要的编程原则，它旨在减少代码中可变状态的数量，以提高代码的可维护性、可测试性和并发安全性。以下是一些常见的方法来减少可变性：\n使用不可变类：不可变类是指其实例在创建后不能被修改的类。不可变类的字段都是 final 的，并且类中没有提供修改字段的方法（setter）。通过使用不可变类，可以确保对象的状态不会被意外地修改，从而减少潜在的错误和并发问题。 封装可变状态：如果某个类必须具有可变状态，建议将可变状态封装在类内部，并通过访问器方法（getter 和 setter）来控制对状态的访问和修改。这样可以限制对状态的直接访问，提供更好的封装和控制机制。 避免共享可变对象：在多线程环境下，共享可变对象可能导致并发问题。为了减少可变性，可以避免共享可变对象，或者确保在共享时进行适当的同步。如果可能，使用不可变对象或线程安全的对象来代替可变对象。 使用不可变集合：Java 提供了许多不可变集合类，如 Collections.unmodifiableList 和 Collections.unmodifiableMap 等。通过使用这些不可变集合类，可以确保集合内容不会被修改，从而减少可变性。 使用函数式编程风格：函数式编程鼓励使用不可变数据和无副作用的函数。通过使用纯函数（没有副作用，并且对相同的输入始终产生相同的输出），可以减少可变性，并提高代码的可读性和可维护性。 下面是一些常见的不可变数据结构的例子：\n不可变列表（Immutable List）：不可变列表是指一旦创建就不能修改的列表。在 Java 中，可以使用java.util.Collections.unmodifiableList()方法来创建不可变列表。\nList\u0026lt;String\u0026gt; immutableList = Collections.unmodifiableList(Arrays.asList(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;)); 上述代码创建了一个不可变列表，无法对其进行添加、删除或修改操作。\n不可变映射（Immutable Map）：不可变映射是指一旦创建就不能修改的映射关系。在 Java 中，可以使用java.util.Collections.unmodifiableMap()方法来创建不可变映射。\nMap\u0026lt;String, Integer\u0026gt; immutableMap = Collections.unmodifiableMap(Map.of(\u0026#34;apple\u0026#34;, 1, \u0026#34;banana\u0026#34;, 2, \u0026#34;cherry\u0026#34;, 3)); 上述代码创建了一个不可变映射，无法对其进行添加、删除或修改操作。\n不可变集合（Immutable Set）：不可变集合是指一旦创建就不能修改的集合。在 Java 中，可以使用java.util.Collections.unmodifiableSet()方法来创建不可变集合。\nSet\u0026lt;String\u0026gt; immutableSet = Collections.unmodifiableSet(Set.of(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;)); ​ 上述代码创建了一个不可变集合，无法对其进行添加、删除或修改操作。\n不可变数据结构的特点是它们在创建后不能被修改，这意味着它们具有固定的状态。如果需要修改数据结构，必须创建一个新的不可变实例。这种不可变性使得数据结构更安全、线程安全，并且可以有效地用于并发环境。\n需要注意的是，虽然不可变数据结构本身是不可变的，但其中的元素对象可能是可变的。如果需要确保元素对象也是不可变的，则需要采取相应的措施来保证元素对象的不可变性。\n下面是一些使用函数式编程风格减少可变性的示例：\n使用不可变数据结构：函数式编程鼓励使用不可变的数据结构，如不可变列表、不可变映射等。这些数据结构在创建后不能被修改，而是通过创建新的不可变实例来表示修改后的状态。例如，Java 8 引入的java.util.stream.Stream中的操作返回的是不可变流，它们无法修改原始流，而是生成一个新的流。\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(1, 2, 3, 4, 5); List\u0026lt;Integer\u0026gt; doubledNumbers = numbers.stream() .map(n -\u0026gt; n * 2) .collect(Collectors.toList()); System.out.println(doubledNumbers); // 输出: [2, 4, 6, 8, 10] 在上面的示例中，通过使用map操作创建了一个新的流来表示每个元素翻倍后的状态，而原始的numbers列表保持不变。\n避免副作用：函数式编程鼓励使用无副作用的函数，即函数的执行不会对外部状态产生影响。这意味着函数不应该修改传入的参数或任何外部状态。相反，函数应该返回计算结果，并且对于相同的输入应该始终返回相同的输出。\n// 有副作用的示例 int counter = 0; void incrementCounter() { counter++; } // 无副作用的示例 int increment(int value) { return value + 1; } ​ 在上面的示例中，incrementCounter函数对外部状态进行了修改（副作用），而increment函数则返回了新的计算结果，而不改变传入的参数或任何外部状态。\n通过使用不可变数据结构和避免副作用，函数式编程风格可以减少可变性，提高代码的可读性、可测试性和并发安全性。同时，这种风格还可以使代码更易于推理和调试，并减少潜在的错误和 bug。\n如何确保不可变数据结构中的元素对象也是不可变的？ 确保不可变数据结构中的元素对象也是不可变的，可以遵循以下几个步骤：\n使用不可变对象：尽可能使用不可变对象作为元素对象。不可变对象是指其状态在创建后不能被修改的对象。如果使用现有的不可变类（如String和Integer），则无需额外的步骤，因为它们本身就是不可变的。\n使用深度不可变性：如果元素对象是可变的，并且需要确保它们不会被修改，可以采用深度不可变性的方法。这意味着在创建不可变数据结构时，对于每个可变元素对象，都要进行克隆或创建新的不可变实例，而不是直接引用可变对象。\n// 以不可变对象作为元素 List\u0026lt;String\u0026gt; immutableList = List.of(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;); // 使用深度不可变性 List\u0026lt;Person\u0026gt; immutablePersonList = List.of( new Person(\u0026#34;John\u0026#34;, 25), new Person(\u0026#34;Alice\u0026#34;, 30), new Person(\u0026#34;Bob\u0026#34;, 35) ); // Person类需要是不可变的 class Person { private final String name; private final int age; public Person(String name, int age) { this.name = name; this.age = age; } // 只提供getter方法，没有setter方法 public String getName() { return name; } public int getAge() { return age; } } ``` 在上述示例中，`Person`类是不可变的，它没有提供修改属性的方法（setter）。通过创建新的`Person`实例，并将其作为不可变列表的元素，确保了元素对象的不可变性。 防御性复制：如果不可变数据结构中的元素对象是可变的，并且不希望它们被外部修改，可以在访问器方法中返回元素对象的防御性复制。这样可以确保返回的是一个新的副本，而不是直接返回原始对象的引用。\nclass ImmutableDataStructure { private final List\u0026lt;Person\u0026gt; persons; public ImmutableDataStructure(List\u0026lt;Person\u0026gt; persons) { this.persons = new ArrayList\u0026lt;\u0026gt;(persons); // 防御性复制 } public List\u0026lt;Person\u0026gt; getPersons() { return new ArrayList\u0026lt;\u0026gt;(persons); // 防御性复制 } } ​ 在上述示例中，ImmutableDataStructure类包含一个persons列表，通过在构造函数和访问器方法中进行防御性复制，返回了一个新的列表副本，从而保护了元素对象的不可变性。\n通过遵循这些步骤，可以确保不可变数据结构中的元素对象也是不可变的。这有助于保持数据的一致性、线程安全性，并提供更好的封装性和可维护性。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/14/minimize-mutability/","summary":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：减少可变性。\n原文 不可变类是实例不能被修改的类。每个实例中包含的所有信息在对象的生命周期内都是固定的，因此永远不会观察到任何更改。Java 库包含许多不可变的类，包括 String、基本类型的包装类、BigInteger 和 BigDecimal。这么做有很好的理由：不可变类比可变类更容易设计、实现和使用。它们不太容易出错，而且更安全。\n要使类不可变，请遵循以下 5 条规则：\n1、不要提供修改对象状态的方法（这类方法也被称为修改器）\n2、确保类不能被继承。 这可以防止粗心或恶意的通过子类实例对象状态可改变的方式，损害父类的不可变行为。防止子类化通常用 final 修饰父类，但是还有一种替代方法，我们将在后面讨论。\n3、所有字段用 final 修饰。 这清楚地表达了意图，并由系统强制执行。同样，如果在没有同步的情况下，引用新创建的实例并从一个线程传递到另一个线程，那么就有必要确保正确的行为，就像内存模型中描述的那样。\n4、所有字段设为私有。 这将阻止客户端访问字段引用的可变对象并直接修改这些对象。虽然在技术上允许不可变类拥有包含基本类型或对不可变对象的引用的公共 final 字段，但不建议这样做，因为在以后的版本中无法更改内部表示。\n5、确保对任何可变组件的独占访问。 如果你的类有任何引用可变对象的字段，请确保该类的客户端无法获得对这些对象的引用。永远不要向提供对象引用的客户端初始化这样的字段，也不要从访问器返回字段。在构造函数、访问器和 readObject 方法中创建防御性副本。\n前面条目中的许多示例类都是不可变的。其中一个类是 PhoneNumber，它的每个属性都有访问器，但没有对应的修改器。下面是一个稍微复杂的例子：\n// Immutable complex number class public final class Complex { private final double re; private final double im; public Complex(double re, double im) { this.re = re; this.im = im; } public double realPart() { return re; } public double imaginaryPart() { return im; } public Complex plus(Complex c) { return new Complex(re + c.re, im + c.im); } public Complex minus(Complex c) { return new Complex(re - c.","title":"《Effective Java 3》笔记17：减少可变性"},{"content":"本文主要介绍 Async Method Invocation 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 Async Method Invocation（异步方法调用）是一种编程模式，用于处理异步操作和并发执行。它允许在执行某个操作时不阻塞主线程，而是将操作委托给另一个线程或处理程序，并在操作完成后获取结果或执行回调。\n异步方法调用的主要目的是提高应用程序的性能和响应能力。通过将耗时的操作（如网络请求、文件读写、数据库查询等）置于后台线程或异步任务中，可以使主线程能够继续执行其他任务，而不会被阻塞。\n异步方法调用可以在不同的编程语言和框架中以不同的方式实现，包括以下几种常见的形式：\n回调函数（Callback）：通过定义回调函数，将异步操作的结果传递给调用方。当异步操作完成时，回调函数会被调用并处理结果。 Future/Promise（Future/Deferred）：通过 Future 或 Promise 对象表示异步操作的结果，调用方可以在需要时获取结果或添加回调函数来处理结果。 异步/await：异步/await 是一种语法糖，用于简化异步代码的编写和理解。它允许以同步的方式编写异步操作，使代码更具可读性。 观察者模式（Observer）：通过定义观察者对象，异步操作的结果可以被观察者订阅。当结果可用时，观察者会被通知并执行相应的操作。 使用异步方法调用可以提高应用程序的并发性能和用户体验。它可以在后台执行耗时的操作，使主线程保持响应，并允许应用程序同时处理多个并发请求。然而，对于并发操作的正确处理和管理资源的安全性仍然需要仔细考虑和实施。\n举例 AsyncResult（用于异步评估值的中间容器），AsyncCallback（可以在任务完成时被执行）和AsyncExecutor（用于管理异步任务的执行）。\npublic interface AsyncResult\u0026lt;T\u0026gt; { boolean isCompleted(); T getValue() throws ExecutionException; void await() throws InterruptedException; } public interface AsyncCallback\u0026lt;T\u0026gt; { void onComplete(T value, Optional\u0026lt;Exception\u0026gt; ex); } public interface AsyncExecutor { \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task); \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task, AsyncCallback\u0026lt;T\u0026gt; callback); \u0026lt;T\u0026gt; T endProcess(AsyncResult\u0026lt;T\u0026gt; asyncResult) throws ExecutionException, InterruptedException; } ThreadAsyncExecutor是AsyncExecutor的实现。 接下来将突出显示其一些关键部分。\npublic class ThreadAsyncExecutor implements AsyncExecutor { @Override public \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task) { return startProcess(task, null); } @Override public \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task, AsyncCallback\u0026lt;T\u0026gt; callback) { var result = new CompletableResult\u0026lt;\u0026gt;(callback); new Thread( () -\u0026gt; { try { result.setValue(task.call()); } catch (Exception ex) { result.setException(ex); } }, \u0026#34;executor-\u0026#34; + idx.incrementAndGet()) .start(); return result; } @Override public \u0026lt;T\u0026gt; T endProcess(AsyncResult\u0026lt;T\u0026gt; asyncResult) throws ExecutionException, InterruptedException { if (!asyncResult.isCompleted()) { asyncResult.await(); } return asyncResult.getValue(); } } 然后，看看一切是如何协同工作的。\npublic static void main(String[] args) throws Exception { // 构造一个将执行异步任务的新执行程序 var executor = new ThreadAsyncExecutor(); // 以不同的处理时间开始一些异步任务，最后两个使用回调处理程序 final var asyncResult1 = executor.startProcess(lazyval(10, 500)); final var asyncResult2 = executor.startProcess(lazyval(\u0026#34;test\u0026#34;, 300)); final var asyncResult3 = executor.startProcess(lazyval(50L, 700)); final var asyncResult4 = executor.startProcess(lazyval(20, 400), callback(\u0026#34;Deploying lunar rover\u0026#34;)); final var asyncResult5 = executor.startProcess(lazyval(\u0026#34;callback\u0026#34;, 600), callback(\u0026#34;Deploying lunar rover\u0026#34;)); // 在当前线程中模拟异步任务正在它们自己的线程中执行 Thread.sleep(350); // 哦，兄弟，我们在这很辛苦 log(\u0026#34;Mission command is sipping coffee\u0026#34;); // 等待任务完成 final var result1 = executor.endProcess(asyncResult1); final var result2 = executor.endProcess(asyncResult2); final var result3 = executor.endProcess(asyncResult3); asyncResult4.await(); asyncResult5.await(); // log the results of the tasks, callbacks log immediately when complete // 记录任务结果的日志， 回调的日志会在回调完成时立刻记录 log(\u0026#34;Space rocket \u0026lt;\u0026#34; + result1 + \u0026#34;\u0026gt; launch complete\u0026#34;); log(\u0026#34;Space rocket \u0026lt;\u0026#34; + result2 + \u0026#34;\u0026gt; launch complete\u0026#34;); log(\u0026#34;Space rocket \u0026lt;\u0026#34; + result3 + \u0026#34;\u0026gt; launch complete\u0026#34;); } 这是程序控制台的输出。\n21:47:08.227 [executor-2] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;test\u0026gt; launched successfully 21:47:08.269 [main] INFO com.iluwatar.async.method.invocation.App - Mission command is sipping coffee 21:47:08.318 [executor-4] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;20\u0026gt; launched successfully 21:47:08.335 [executor-4] INFO com.iluwatar.async.method.invocation.App - Deploying lunar rover \u0026lt;20\u0026gt; 21:47:08.414 [executor-1] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;10\u0026gt; launched successfully 21:47:08.519 [executor-5] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;callback\u0026gt; launched successfully 21:47:08.519 [executor-5] INFO com.iluwatar.async.method.invocation.App - Deploying lunar rover \u0026lt;callback\u0026gt; 21:47:08.616 [executor-3] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;50\u0026gt; launched successfully 21:47:08.617 [main] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;10\u0026gt; launch complete 21:47:08.617 [main] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;test\u0026gt; launch complete 21:47:08.618 [main] INFO com.iluwatar.async.method.invocation.App - Space rocket \u0026lt;50\u0026gt; launch complete 类图 注意事项 线程安全性和管理异步任务 在使用异步方法调用模式时，确保线程安全性和管理异步任务是非常重要的。以下是一些常用的方法和技术：\n线程安全性： 使用线程安全的数据结构：在异步方法调用中，多个线程可能同时访问和修改共享的数据。为了确保线程安全，可以使用线程安全的数据结构，如ConcurrentHashMap、ConcurrentLinkedQueue等，来管理共享数据。 使用同步机制：使用同步机制，如synchronized关键字或Lock接口，来保护共享资源的访问，以避免并发访问导致的数据竞争和不一致性。 避免共享状态：尽可能避免在异步任务之间共享状态，而是通过参数传递和返回值来进行数据交换。这可以减少对共享资源的并发访问，从而简化线程安全性的管理。 异步任务管理： 使用线程池：使用线程池可以有效地管理和调度异步任务的执行。线程池可以控制并发线程的数量，重用线程，避免线程创建和销毁的开销，并提供任务队列来缓冲待执行的任务。 使用 Future 和 Promise：Future 和 Promise 是用于管理异步任务的常用概念。Future 表示一个异步任务的结果，可以通过它来获取任务的返回值或等待任务完成。Promise 是 Future 的扩展，它允许设置异步任务的结果。通过使用 Future 和 Promise，可以更方便地管理异步任务的状态和结果。 使用回调函数：回调函数是异步方法调用中常用的一种方式，用于在任务完成时执行相应的操作。通过定义回调函数，可以将任务的处理逻辑与任务执行的异步性解耦，从而更灵活地处理异步任务的结果。 同时，请注意以下几点：\n在设计和实现异步方法调用时，需要仔细考虑线程安全性和并发访问的问题，并进行适当的测试和验证。 根据具体的应用场景和需求，选择适合的线程安全机制和异步任务管理策略。 在多线程环境下使用异步方法调用时，要注意可能出现的线程安全性问题，如数据竞争、死锁和活锁等，并采取相应的预防和解决措施。 综上所述，线程安全性和异步任务管理是确保异步方法调用模式正确运行的关键因素，需要仔细设计和实施相应的策略和机制。\n异常处理 在异步任务管理中，处理任务执行过程中可能出现的异常是很重要的。以下是一些常用的方法和技术：\n异常处理机制： 使用 try-catch 块：在异步任务的执行代码块内，使用 try-catch 块捕获可能抛出的异常，并在 catch 块中进行相应的异常处理。可以根据具体需求选择恰当的异常处理策略，如记录日志、发送通知、回滚操作等。 使用异常回调函数：定义一个异常回调函数，用于在任务执行过程中捕获异常并进行相应的处理。回调函数可以接收异常对象作为参数，并在任务执行完成时被调用。这样可以将异常处理逻辑与任务执行逻辑解耦，提高代码的可维护性和灵活性。 异常传递和封装： 使用 Future 和 Promise：在异步任务中，可以使用 Future 和 Promise 来传递任务的执行结果和异常。当任务执行过程中发生异常时，可以将异常信息设置到 Promise 对象中，并通过 Future 获取异常信息进行处理。 封装异常信息：在异常发生时，可以将异常信息封装到自定义的异常类中，并通过抛出该异常来表示任务执行过程中的异常情况。调用方可以通过捕获并处理相应的异常来处理任务的执行结果和异常情况。 错误处理策略： 重试机制：当任务执行过程中发生异常时，可以根据一定的策略进行重试。可以设置最大重试次数和重试间隔时间，以便在一定程度上解决临时性的异常情况。 回退策略：当任务执行过程中发生异常时，可以使用回退策略来处理。回退策略可以选择执行备选方案或使用默认值，以确保任务的正常执行。 请注意以下几点：\n在异步任务管理中，及时捕获和处理异常是非常重要的，以防止异常的传播和影响其他任务或系统的正常运行。 根据具体的应用场景和需求，选择适合的异常处理机制和错误处理策略。 在处理异常时，需要根据异常类型和情况进行适当的处理，以确保任务的正确执行和系统的稳定性。 总结而言，在异步任务管理中，合理处理任务执行过程中的异常是保证系统稳定性和可靠性的关键因素之一。通过适当的异常处理机制、异常传递和封装，以及错误处理策略，可以有效地处理任务执行中可能出现的异常情况。\n适用性 异步方法调用模式适用于以下情况:\n当您有多个可以并行运行的独立任务时：该模式允许您以并行的方式处理多个任务，而无需等待单个任务完成。这对于并行处理独立任务的情况非常有用，以提高整体的执行效率。 当您需要提高一组顺序任务的性能时：如果存在一组任务按照特定顺序执行，但其中某些任务可能是耗时的，您可以使用异步方法调用模式来并行处理这些任务。这样，在等待某个任务完成时，其他任务可以继续执行，从而提高整体性能。 当您的处理能力或长时间运行的任务数量有限，并且调用方不应等待任务执行完毕时：如果您的系统资源有限，无法同时处理大量的长时间运行任务，而且调用方不希望被阻塞等待任务完成，那么异步方法调用模式可以很好地满足这种需求。它允许调用方立即返回，并在任务完成后通过回调或等待来获取任务结果。 异步方法调用模式可以提高应用程序的性能、资源利用率和响应能力。通过并行处理任务和减少等待时间，可以更好地利用系统资源，提高整体效率。然而，使用该模式可能会增加代码复杂性，需要考虑线程安全性和异步任务的管理等问题。\n请注意，适用性取决于具体的应用场景和需求。在决定是否使用异步方法调用模式时，需要综合考虑系统的要求、资源限制以及代码复杂性等因素。\n","permalink":"https://blog.chensoul.cc/posts/2023/08/14/java-design-patterns-async-method-invocation/","summary":"本文主要介绍 Async Method Invocation 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 Async Method Invocation（异步方法调用）是一种编程模式，用于处理异步操作和并发执行。它允许在执行某个操作时不阻塞主线程，而是将操作委托给另一个线程或处理程序，并在操作完成后获取结果或执行回调。\n异步方法调用的主要目的是提高应用程序的性能和响应能力。通过将耗时的操作（如网络请求、文件读写、数据库查询等）置于后台线程或异步任务中，可以使主线程能够继续执行其他任务，而不会被阻塞。\n异步方法调用可以在不同的编程语言和框架中以不同的方式实现，包括以下几种常见的形式：\n回调函数（Callback）：通过定义回调函数，将异步操作的结果传递给调用方。当异步操作完成时，回调函数会被调用并处理结果。 Future/Promise（Future/Deferred）：通过 Future 或 Promise 对象表示异步操作的结果，调用方可以在需要时获取结果或添加回调函数来处理结果。 异步/await：异步/await 是一种语法糖，用于简化异步代码的编写和理解。它允许以同步的方式编写异步操作，使代码更具可读性。 观察者模式（Observer）：通过定义观察者对象，异步操作的结果可以被观察者订阅。当结果可用时，观察者会被通知并执行相应的操作。 使用异步方法调用可以提高应用程序的并发性能和用户体验。它可以在后台执行耗时的操作，使主线程保持响应，并允许应用程序同时处理多个并发请求。然而，对于并发操作的正确处理和管理资源的安全性仍然需要仔细考虑和实施。\n举例 AsyncResult（用于异步评估值的中间容器），AsyncCallback（可以在任务完成时被执行）和AsyncExecutor（用于管理异步任务的执行）。\npublic interface AsyncResult\u0026lt;T\u0026gt; { boolean isCompleted(); T getValue() throws ExecutionException; void await() throws InterruptedException; } public interface AsyncCallback\u0026lt;T\u0026gt; { void onComplete(T value, Optional\u0026lt;Exception\u0026gt; ex); } public interface AsyncExecutor { \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task); \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task, AsyncCallback\u0026lt;T\u0026gt; callback); \u0026lt;T\u0026gt; T endProcess(AsyncResult\u0026lt;T\u0026gt; asyncResult) throws ExecutionException, InterruptedException; } ThreadAsyncExecutor是AsyncExecutor的实现。 接下来将突出显示其一些关键部分。\npublic class ThreadAsyncExecutor implements AsyncExecutor { @Override public \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task) { return startProcess(task, null); } @Override public \u0026lt;T\u0026gt; AsyncResult\u0026lt;T\u0026gt; startProcess(Callable\u0026lt;T\u0026gt; task, AsyncCallback\u0026lt;T\u0026gt; callback) { var result = new CompletableResult\u0026lt;\u0026gt;(callback); new Thread( () -\u0026gt; { try { result.","title":"Java设计模式：Async Method Invocation"},{"content":"本文主要介绍 API Gateway 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n目的 API 网关设计模式旨在将所有对微服务的调用聚合到一起。客户端通过调用 API 网关来实现对多个微服务的访问，而不是直接调用每个微服务。这种模式的目的是解决以下问题：\n减少客户端的网络请求：如果客户端直接调用每个微服务，会导致额外的网络请求，增加加载时间。通过使用 API 网关，客户端只需要进行一次调用，而不是多次调用。 解耦客户端和微服务：如果客户端直接与每个微服务进行通信，客户端与微服务之间的耦合度很高。当微服务的实现发生变化或位置发生变化时，需要更新所有客户端。使用 API 网关可以将客户端与具体的微服务解耦，客户端只需要与 API 网关通信。 提供集中化的功能和服务：API 网关可以实现一些通用的功能和服务，例如限流、认证、授权、安全性等。这样可以避免每个微服务都实现这些功能，减少重复代码。 解释 在实际应用中，API 网关通常包括一个转换引擎，用于实时地编排和修改请求和响应。它还可以提供收集分析数据和提供缓存等功能。另外，API 网关还可以支持身份验证、授权、安全性、审计和法规遵从性等功能。\n假设你正在开发一个电子商务平台，其中包含多个微服务，如用户服务、产品服务、图片服务、订单服务和支付服务等。每个微服务都有自己的 API 和数据库。\n在这种情况下，你可以引入一个 API 网关来处理对这些微服务的访问。API 网关作为一个入口点，接收来自客户端的请求，并将请求转发到适当的微服务。\n例如，当一个客户端需要获取某个产品的详细信息时，他们可以发送一个 HTTP 请求到 API 网关的特定端点。API 网关会验证请求并将其转发到产品服务。产品服务将查询数据库获取产品信息，并将响应返回给 API 网关。然后，API 网关将产品信息返回给客户端。\nAPI 网关可以实现以下功能：\n认证和授权：API 网关可以验证客户端的身份和权限，确保只有经过授权的用户能够访问特定的微服务。 请求转发和路由：API 网关根据请求的路径和参数将请求转发到适当的微服务。它可以执行负载均衡和路由策略，确保请求被正确地分发到相应的微服务实例。 响应聚合：如果一个请求需要从多个微服务获取数据，API 网关可以将这些请求发送给相应的微服务，并将它们的响应聚合到一个响应中返回给客户端。 缓存和性能优化：API 网关可以缓存常用的请求和响应，以提高性能并减轻后端微服务的负载。 安全性和监控：API 网关可以实施安全策略，例如防止恶意请求和 DDoS 攻击。它还可以监控请求和响应，收集应用程序的指标和日志数据。 程序示例\n此实现展示了电子商务站点的 API 网关模式。 ApiGateway分别使用 ImageClientImpl和 PriceClientImpl来调用 Image 和 Price 微服务。 在桌面设备上查看该网站的客户可以看到价格信息和产品图片，因此 ApiGateway会调用这两种微服务并在DesktopProduct模型中汇总数据。 但是，移动用户只能看到价格信息。 他们看不到产品图片。 对于移动用户，ApiGateway仅检索价格信息，并将其用于填充MobileProduct模型。\n这个是图像微服务的实现。\npublic interface ImageClient { String getImagePath(); } public class ImageClientImpl implements ImageClient { @Override public String getImagePath() { var httpClient = HttpClient.newHttpClient(); var httpGet = HttpRequest.newBuilder() .GET() .uri(URI.create(\u0026#34;http://localhost:50005/image-path\u0026#34;)) .build(); try { var httpResponse = httpClient.send(httpGet, BodyHandlers.ofString()); return httpResponse.body(); } catch (IOException | InterruptedException e) { e.printStackTrace(); } return null; } } 这里是价格服务的实现。\npublic interface PriceClient { String getPrice(); } public class PriceClientImpl implements PriceClient { @Override public String getPrice() { var httpClient = HttpClient.newHttpClient(); var httpGet = HttpRequest.newBuilder() .GET() .uri(URI.create(\u0026#34;http://localhost:50006/price\u0026#34;)) .build(); try { var httpResponse = httpClient.send(httpGet, BodyHandlers.ofString()); return httpResponse.body(); } catch (IOException | InterruptedException e) { e.printStackTrace(); } return null; } } 在这里，我们可以看到 API 网关如何将请求映射到微服务。\npublic class ApiGateway { @Resource private ImageClient imageClient; @Resource private PriceClient priceClient; @RequestMapping(path = \u0026#34;/desktop\u0026#34;, method = RequestMethod.GET) public DesktopProduct getProductDesktop() { var desktopProduct = new DesktopProduct(); desktopProduct.setImagePath(imageClient.getImagePath()); desktopProduct.setPrice(priceClient.getPrice()); return desktopProduct; } @RequestMapping(path = \u0026#34;/mobile\u0026#34;, method = RequestMethod.GET) public MobileProduct getProductMobile() { var mobileProduct = new MobileProduct(); mobileProduct.setPrice(priceClient.getPrice()); return mobileProduct; } } 类图 适用性 API 网关模式适用于以下情况：\n微服务架构：当你的应用程序采用微服务架构时，每个微服务负责特定的业务功能。API 网关可以作为微服务架构的入口点，聚合和管理所有微服务的访问。 多渠道访问：如果你的应用程序需要支持多个客户端渠道（如 Web、移动应用、第三方集成等），API 网关可以提供统一的接入点，处理不同渠道的请求，并将其转发到相应的微服务。 安全性和认证：当你需要对客户端进行身份验证和授权，并确保只有合法用户能够访问你的微服务时，API 网关可以实施安全性策略，集中管理认证和授权。 请求聚合和转换：如果客户端需要从多个微服务获取数据，并希望将这些数据聚合为单个响应，API 网关可以处理这种请求聚合，并在需要时转换请求和响应的格式。 性能优化和缓存：API 网关可以实现请求的缓存机制，减少对后端微服务的重复请求，提高性能和响应时间。 监控和日志记录：通过集中管理请求和响应的流量，API 网关可以收集应用程序的指标和日志数据，用于监控和故障排除。 总的来说，API 网关模式适用于需要对微服务架构进行统一管理、安全性控制、请求聚合、性能优化和监控的场景。它提供了一个中心化的入口点，简化了客户端与微服务之间的通信，并提供了额外的功能和服务。\n参考 \u0026ldquo;API Gateway\u0026rdquo; - Martin Fowler: https://martinfowler.com/articles/microservices.html#APIGateway\n\u0026ldquo;API Gateway\u0026rdquo; - AWS Well-Architected Framework: https://wa.aws.amazon.com/wat.pillar.apigateway.en.html\n\u0026ldquo;Introduction to API Gateways\u0026rdquo; - NGINX: https://www.nginx.com/api-gateway/\nmicroservices.io - API Gateway\nNGINX - Building Microservices: Using an API Gateway\nMicroservices Patterns: With examples in Java\nBuilding Microservices: Designing Fine-Grained Systems\n","permalink":"https://blog.chensoul.cc/posts/2023/08/13/java-design-patterns-api-gateway/","summary":"本文主要介绍 API Gateway 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n目的 API 网关设计模式旨在将所有对微服务的调用聚合到一起。客户端通过调用 API 网关来实现对多个微服务的访问，而不是直接调用每个微服务。这种模式的目的是解决以下问题：\n减少客户端的网络请求：如果客户端直接调用每个微服务，会导致额外的网络请求，增加加载时间。通过使用 API 网关，客户端只需要进行一次调用，而不是多次调用。 解耦客户端和微服务：如果客户端直接与每个微服务进行通信，客户端与微服务之间的耦合度很高。当微服务的实现发生变化或位置发生变化时，需要更新所有客户端。使用 API 网关可以将客户端与具体的微服务解耦，客户端只需要与 API 网关通信。 提供集中化的功能和服务：API 网关可以实现一些通用的功能和服务，例如限流、认证、授权、安全性等。这样可以避免每个微服务都实现这些功能，减少重复代码。 解释 在实际应用中，API 网关通常包括一个转换引擎，用于实时地编排和修改请求和响应。它还可以提供收集分析数据和提供缓存等功能。另外，API 网关还可以支持身份验证、授权、安全性、审计和法规遵从性等功能。\n假设你正在开发一个电子商务平台，其中包含多个微服务，如用户服务、产品服务、图片服务、订单服务和支付服务等。每个微服务都有自己的 API 和数据库。\n在这种情况下，你可以引入一个 API 网关来处理对这些微服务的访问。API 网关作为一个入口点，接收来自客户端的请求，并将请求转发到适当的微服务。\n例如，当一个客户端需要获取某个产品的详细信息时，他们可以发送一个 HTTP 请求到 API 网关的特定端点。API 网关会验证请求并将其转发到产品服务。产品服务将查询数据库获取产品信息，并将响应返回给 API 网关。然后，API 网关将产品信息返回给客户端。\nAPI 网关可以实现以下功能：\n认证和授权：API 网关可以验证客户端的身份和权限，确保只有经过授权的用户能够访问特定的微服务。 请求转发和路由：API 网关根据请求的路径和参数将请求转发到适当的微服务。它可以执行负载均衡和路由策略，确保请求被正确地分发到相应的微服务实例。 响应聚合：如果一个请求需要从多个微服务获取数据，API 网关可以将这些请求发送给相应的微服务，并将它们的响应聚合到一个响应中返回给客户端。 缓存和性能优化：API 网关可以缓存常用的请求和响应，以提高性能并减轻后端微服务的负载。 安全性和监控：API 网关可以实施安全策略，例如防止恶意请求和 DDoS 攻击。它还可以监控请求和响应，收集应用程序的指标和日志数据。 程序示例\n此实现展示了电子商务站点的 API 网关模式。 ApiGateway分别使用 ImageClientImpl和 PriceClientImpl来调用 Image 和 Price 微服务。 在桌面设备上查看该网站的客户可以看到价格信息和产品图片，因此 ApiGateway会调用这两种微服务并在DesktopProduct模型中汇总数据。 但是，移动用户只能看到价格信息。 他们看不到产品图片。 对于移动用户，ApiGateway仅检索价格信息，并将其用于填充MobileProduct模型。\n这个是图像微服务的实现。\npublic interface ImageClient { String getImagePath(); } public class ImageClientImpl implements ImageClient { @Override public String getImagePath() { var httpClient = HttpClient.newHttpClient(); var httpGet = HttpRequest.newBuilder() .","title":"Java设计模式：API Gateway "},{"content":"本文主要介绍 Arrange/Act/Assert 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 Arrange/Act/Assert（安排/执行/断言）又称 Given/When/Then，是一种测试设计模式，用于组织和编写单元测试的结构。它提供了一种清晰的测试布局，使得测试代码易于理解和维护。\n该模式的三个阶段如下：\nArrange（安排）：在这个阶段，你准备测试环境和设置测试数据。这包括创建对象、设置输入参数、模拟依赖项等。你的目标是为将要进行的测试创建一个合适的环境。 Act（执行）：在这个阶段，你执行要测试的操作或调用要测试的方法。这是你对被测试代码进行实际调用的地方。 Assert（断言）：在这个阶段，你验证测试的结果是否符合预期。你会检查实际的输出、状态变化或异常情况，并使用断言语句来断言测试的期望结果。 这种测试结构的优势在于它提供了清晰的分离和组织测试代码的方式，并使得测试的目的和预期结果更容易理解。它也有助于减少测试代码中的重复和冗余。\n以下是一个使用 Arrange/Act/Assert 模式编写的示例测试方法的伪代码：\npublic void testCalculateTotalPrice() { // Arrange ShoppingCart cart = new ShoppingCart(); cart.addItem(new Item(\u0026#34;Item 1\u0026#34;, 10.0)); cart.addItem(new Item(\u0026#34;Item 2\u0026#34;, 15.0)); // Act double totalPrice = cart.calculateTotalPrice(); // Assert assertEquals(25.0, totalPrice, 0.01); } 在上述示例中，首先在 Arrange 阶段创建了一个购物车对象，并添加了两个商品。然后，在 Act 阶段调用了calculateTotalPrice()方法来计算总价格。最后，在 Assert 阶段使用断言语句来验证计算的结果是否等于预期的总价格。\n适用性 Arrange/Act/Assert（安排/执行/断言）设计模式适用于编写单元测试，特别是针对函数、方法或类的单元测试。它在以下情况下特别有用：\n单元测试：Arrange/Act/Assert 模式适用于对单个函数或方法进行测试。它帮助你组织测试代码，使其结构清晰，并确保每个测试只关注一个特定的功能或行为。 易于理解和维护：这种模式提供了一种一致的测试结构，使得测试代码易于理解和维护。通过明确的安排、执行和断言阶段，你可以更清楚地了解测试的目的和预期结果。 测试代码可读性：Arrange/Act/Assert 模式可以使测试代码更具可读性。通过按照统一的结构组织测试代码，使得测试逻辑更加清晰可见，易于他人理解和参与。 提高可维护性：使用这种模式可以减少测试代码中的重复和冗余，使得测试代码更易于维护。在 Arrange 阶段设置测试环境和准备数据，可以减少在每个测试中重复的代码。 测试结果验证：Arrange/Act/Assert 模式明确了测试结果的验证过程。在 Assert 阶段使用断言语句来验证实际结果与预期结果的一致性，帮助你确保被测试代码的正确性。 需要注意的是，Arrange/Act/Assert 模式主要适用于单元测试，而对于集成测试或端到端测试等更大范围的测试，可能需要使用其他测试设计模式或框架来进行组织和管理测试代码。\n除了 Arrange/Act/Assert 模式，以下是一些适用于集成测试或端到端测试的设计模式或框架：\nPage Object 模式：Page Object 模式是一种用于管理用户界面元素和操作的设计模式。它将页面的元素和操作封装到可重用的对象中，使得测试代码更具可读性和可维护性。Page Object 模式特别适用于 Web 应用程序的端到端测试。 数据构建器模式：数据构建器模式用于生成测试数据，以便在集成测试或端到端测试中使用。它提供了一种灵活的方式来创建测试数据，包括复杂的数据结构和关联关系。 数据准备和清理模式：在集成测试或端到端测试中，通常需要准备测试数据和环境，并在测试完成后进行清理。数据准备和清理模式提供了一种结构化的方法来管理这些操作，确保测试的一致性和可重复性。 Mock 对象模式：Mock 对象模式用于模拟或替代外部依赖项，以便进行集成测试或端到端测试。通过使用 Mock 对象，你可以隔离被测试代码与外部系统的交互，使得测试更加可控和独立。 BDD（行为驱动开发）框架：BDD 框架（如 Cucumber、SpecFlow 等）提供了一种以自然语言编写测试用例和规范的方式。它将测试用例描述为可读性强的场景和步骤，帮助开发人员、测试人员和业务利益相关者之间的沟通和理解。 参考 Arrange, Act, Assert: What is AAA Testing? Bill Wake: 3A – Arrange, Act, Assert Martin Fowler: GivenWhenThen xUnit Test Patterns: Refactoring Test Code Unit Testing Principles, Practices, and Patterns Test Driven Development: By Example ","permalink":"https://blog.chensoul.cc/posts/2023/08/13/java-design-patterns-arrange-act-assert/","summary":"本文主要介绍 Arrange/Act/Assert 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\n介绍 Arrange/Act/Assert（安排/执行/断言）又称 Given/When/Then，是一种测试设计模式，用于组织和编写单元测试的结构。它提供了一种清晰的测试布局，使得测试代码易于理解和维护。\n该模式的三个阶段如下：\nArrange（安排）：在这个阶段，你准备测试环境和设置测试数据。这包括创建对象、设置输入参数、模拟依赖项等。你的目标是为将要进行的测试创建一个合适的环境。 Act（执行）：在这个阶段，你执行要测试的操作或调用要测试的方法。这是你对被测试代码进行实际调用的地方。 Assert（断言）：在这个阶段，你验证测试的结果是否符合预期。你会检查实际的输出、状态变化或异常情况，并使用断言语句来断言测试的期望结果。 这种测试结构的优势在于它提供了清晰的分离和组织测试代码的方式，并使得测试的目的和预期结果更容易理解。它也有助于减少测试代码中的重复和冗余。\n以下是一个使用 Arrange/Act/Assert 模式编写的示例测试方法的伪代码：\npublic void testCalculateTotalPrice() { // Arrange ShoppingCart cart = new ShoppingCart(); cart.addItem(new Item(\u0026#34;Item 1\u0026#34;, 10.0)); cart.addItem(new Item(\u0026#34;Item 2\u0026#34;, 15.0)); // Act double totalPrice = cart.calculateTotalPrice(); // Assert assertEquals(25.0, totalPrice, 0.01); } 在上述示例中，首先在 Arrange 阶段创建了一个购物车对象，并添加了两个商品。然后，在 Act 阶段调用了calculateTotalPrice()方法来计算总价格。最后，在 Assert 阶段使用断言语句来验证计算的结果是否等于预期的总价格。\n适用性 Arrange/Act/Assert（安排/执行/断言）设计模式适用于编写单元测试，特别是针对函数、方法或类的单元测试。它在以下情况下特别有用：\n单元测试：Arrange/Act/Assert 模式适用于对单个函数或方法进行测试。它帮助你组织测试代码，使其结构清晰，并确保每个测试只关注一个特定的功能或行为。 易于理解和维护：这种模式提供了一种一致的测试结构，使得测试代码易于理解和维护。通过明确的安排、执行和断言阶段，你可以更清楚地了解测试的目的和预期结果。 测试代码可读性：Arrange/Act/Assert 模式可以使测试代码更具可读性。通过按照统一的结构组织测试代码，使得测试逻辑更加清晰可见，易于他人理解和参与。 提高可维护性：使用这种模式可以减少测试代码中的重复和冗余，使得测试代码更易于维护。在 Arrange 阶段设置测试环境和准备数据，可以减少在每个测试中重复的代码。 测试结果验证：Arrange/Act/Assert 模式明确了测试结果的验证过程。在 Assert 阶段使用断言语句来验证实际结果与预期结果的一致性，帮助你确保被测试代码的正确性。 需要注意的是，Arrange/Act/Assert 模式主要适用于单元测试，而对于集成测试或端到端测试等更大范围的测试，可能需要使用其他测试设计模式或框架来进行组织和管理测试代码。\n除了 Arrange/Act/Assert 模式，以下是一些适用于集成测试或端到端测试的设计模式或框架：\nPage Object 模式：Page Object 模式是一种用于管理用户界面元素和操作的设计模式。它将页面的元素和操作封装到可重用的对象中，使得测试代码更具可读性和可维护性。Page Object 模式特别适用于 Web 应用程序的端到端测试。 数据构建器模式：数据构建器模式用于生成测试数据，以便在集成测试或端到端测试中使用。它提供了一种灵活的方式来创建测试数据，包括复杂的数据结构和关联关系。 数据准备和清理模式：在集成测试或端到端测试中，通常需要准备测试数据和环境，并在测试完成后进行清理。数据准备和清理模式提供了一种结构化的方法来管理这些操作，确保测试的一致性和可重复性。 Mock 对象模式：Mock 对象模式用于模拟或替代外部依赖项，以便进行集成测试或端到端测试。通过使用 Mock 对象，你可以隔离被测试代码与外部系统的交互，使得测试更加可控和独立。 BDD（行为驱动开发）框架：BDD 框架（如 Cucumber、SpecFlow 等）提供了一种以自然语言编写测试用例和规范的方式。它将测试用例描述为可读性强的场景和步骤，帮助开发人员、测试人员和业务利益相关者之间的沟通和理解。 参考 Arrange, Act, Assert: What is AAA Testing?","title":"Java设计模式：Arrange/Act/Assert"},{"content":"前言 本篇是对 2023-07-10 到 2023-07-16 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这是我的第 27 篇周报，由于工作的原因，前两周的周报是一起发布的，所以第 27 篇周报被跳过去了。\n技术文档范例 以下是一个使用中文标题的技术文档范例：\n一、介绍 1.1 目的 1.2 范围 1.3 受众 1.4 定义、缩略语和术语 二、概述 2.1 系统架构 2.2 主要功能 2.3 系统要求 三、入门指南 3.1 安装 3.2 配置 3.3 第一步操作 四、用户指南 4.1 用户界面 4.2 导航 4.3 功能 五、管理指南 5.1 系统配置 5.2 用户管理 5.3 安全性 六、故障排除 6.1 常见问题 6.2 错误消息 七、附录 7.1 发行说明 7.2 术语表 7.3 参考文献 以下是一个使用数字标题的 Spring Cloud Gateway 教程示例：\n1. 介绍 1.1 目的 1.2 范围 1.3 受众 1.4 术语和定义 2. 概述 2.1 什么是 Spring Cloud Gateway 2.2 Spring Cloud Gateway 的优势 3. 快速入门 3.1 环境配置 3.2 创建Spring Cloud Gateway项目 3.3 配置路由规则 3.4 运行和测试 4. 路由配置 4.1 URI路由 4.2 断言路由 4.3 过滤器 5. 高级特性 5.1 熔断器 5.2 限流 5.3 日志和监控 6. 部署和管理 6.1 部署选项 6.2 容器化部署 6.3 管理和监控 7. 故障排除 7.1 常见问题 7.2 日志分析 8. 总结和参考资料 8.1 总结 8.2 参考资料 读书 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n理财 这周总计支出 5006 元，明细如下：\n7 月 16 日：4057 元，父亲出院支付 3475 元\n7 月 15 日：108 元\n7 月 14 日：86 元\n7 月 13 日：367 元\n7 月 12 日：179 元\n7 月 11 日：117 元\n7 月 10 日：92 元\n陪家人 工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成一篇博客：\n[译]使用 Spring Boot2 和 Spring Security 5 以及 JDBC 令牌存储进行 Oauth2 集中授权 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。\n📌2023-07-15 Mysql update 语句使用子查询 | CHEGVA #memos https://chegva.com/5744.html\n📌2023-07-15 一篇《OAuth2 概述》（英文），在很短的篇幅里面，清楚地介绍了 OAuth。#memos https://metacpan.org/dist/LWP-Authen-OAuth2/view/lib/LWP/Authen/OAuth2/Overview.pod\n📌2023-07-15 拥抱 TypeScript 的历程 | Usubeni Fantasy#memos https://ssshooter.com/typescript-tittle-tattle/\n📌2023-07-15 一个独立创造者的五年#memos http://hawstein.com/2023/07/12/five-years-of-an-indie-hacker/\n📌2023-07-15 一个短链接浏览器扩展插件，月收入 2.6K 美金 #memos https://www.ezindie.com/weekly/issue-95\n📌2023-07-15 配置轻量级 Linux 远程开发环境（Fedora 38）#memos https://rook1e.com/p/lightweight-remote-linux-devenv-fedora38/\n📌2023-07-11 React Design Patterns #memos https://anuradha.hashnode.dev/react-design-patterns\n📌2023-07-11 推荐：非常详细的 vite 开发笔记（7k 字）#memos https://juejin.cn/post/7251873578157113401\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/07/27/weekly_review_28/","summary":"前言 本篇是对 2023-07-10 到 2023-07-16 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这是我的第 27 篇周报，由于工作的原因，前两周的周报是一起发布的，所以第 27 篇周报被跳过去了。\n技术文档范例 以下是一个使用中文标题的技术文档范例：\n一、介绍 1.1 目的 1.2 范围 1.3 受众 1.4 定义、缩略语和术语 二、概述 2.1 系统架构 2.2 主要功能 2.3 系统要求 三、入门指南 3.1 安装 3.2 配置 3.3 第一步操作 四、用户指南 4.1 用户界面 4.2 导航 4.3 功能 五、管理指南 5.1 系统配置 5.2 用户管理 5.3 安全性 六、故障排除 6.1 常见问题 6.2 错误消息 七、附录 7.1 发行说明 7.2 术语表 7.3 参考文献 以下是一个使用数字标题的 Spring Cloud Gateway 教程示例：\n1. 介绍 1.1 目的 1.2 范围 1.3 受众 1.4 术语和定义 2. 概述 2.1 什么是 Spring Cloud Gateway 2.2 Spring Cloud Gateway 的优势 3. 快速入门 3.1 环境配置 3.2 创建Spring Cloud Gateway项目 3.3 配置路由规则 3.","title":"周报-28｜技术文档范例"},{"content":"概述 在本文中，我们将创建一个授权服务器，为任何客户端生成 access_token。这称为 OAuth2 的 client_credentials 流程。它主要用于服务间通信。\n我们将使用 spring boot oauth2 授权服务器依赖项来创建身份验证服务器。我们还将创建一个资源服务器和客户端来对其进行端到端测试。\nSpring 授权服务器 我们首先创建授权服务器。\n依赖项： 让我们将以下依赖项添加到我们的项目中。\nimplementation \u0026#39;org.springframework.security:spring-security-oauth2-authorization-server:1.0.0\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; testImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39; testImplementation \u0026#39;org.springframework.security:spring-security-test\u0026#39; 我们正在使用 spring oauth2 依赖项的最新（当时）稳定版本。\nJava 实现： 让我们创建一个名为 AuthorizationServerConfig 的配置类，并向该类添加 @Configuration 注解。现在让我们创建以下 bean 来完成配置：\nSecurityFilterChain @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SecurityFilterChain authServerSecurityFilterChain(HttpSecurity http) throws Exception { OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http); return http.build(); } 我们将把 bean 的顺序设置为最高，因为我们想首先执行它。\nRegisteredClientRepository @Bean public RegisteredClientRepository registeredClientRepository() { RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString()) .clientId(\u0026#34;oauth-client\u0026#34;) .clientSecret(\u0026#34;{noop}oauth-secret\u0026#34;) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) .scope(OidcScopes.OPENID) .scope(\u0026#34;articles.read\u0026#34;) .build(); return new InMemoryRegisteredClientRepository(registeredClient); } 现在让我们使用内存存储库对内容进行硬编码。我们可以根据我们的需要更新这些。\nJwtDecoder @Bean public JwtDecoder jwtDecoder(JWKSource\u0026lt;SecurityContext\u0026gt; jwkSource) { return OAuth2AuthorizationServerConfiguration.jwtDecoder(jwkSource); } 我们将使用它来解码令牌以进行验证。\nJWKSource @Bean public JWKSource\u0026lt;SecurityContext\u0026gt; jwkSource() throws NoSuchAlgorithmException { RSAKey rsaKey = generateRsa(); JWKSet jwkSet = new JWKSet(rsaKey); return (jwkSelector, securityContext) -\u0026gt; jwkSelector.select(jwkSet); } private static RSAKey generateRsa() throws NoSuchAlgorithmException { KeyPair keyPair = generateRsaKey(); RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); return new RSAKey.Builder(publicKey) .privateKey(privateKey) .keyID(UUID.randomUUID().toString()) .build(); } private static KeyPair generateRsaKey() throws NoSuchAlgorithmException { KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(\u0026#34;RSA\u0026#34;); keyPairGenerator.initialize(2048); return keyPairGenerator.generateKeyPair(); } 我们在解码器 bean 中使用这个源，所以我们需要定义它。我们使用 RSA 2048 密钥对，我们也可以在需要时更改它。\nAuthorizationServerSettings @Bean public AuthorizationServerSettings authorizationServerSettings() { return AuthorizationServerSettings.builder().build(); } 现在我们已经配置了一切，让我们尝试运行应用程序并获取令牌：\ncurl -X POST \u0026#39;http://localhost:9090/oauth2/token?grant_type=client_credentials\u0026#39; \\ --header \u0026#39;Authorization: Basic b2F1dGgtY2xpZW50Om9hdXRoLXNlY3JldA==\u0026#39; 注意：根据您的配置更新端口号。\n它应该给出如下响应：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;eyJraWQiOiJiYWM0ZmMxYS02MGJiLTQ0ZTAtODU4MC1iNzcwYWU2MjkwZWEiLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJvYXV0aC1jbGllbnQiLCJhdWQiOiJvYXV0aC1jbGllbnQiLCJuYmYiOjE2NzQ5ODYzNjcsImlzcyI6Imh0dHA6Ly9sb2NhbGhvc3Q6OTA5MCIsImV4cCI6MTY3NDk4NjY2NywiaWF0IjoxNjc0OTg2MzY3fQ.DxiIbV7jdRnW15WnnqcjFCLyfXmrU_trl1M3nxej_nIWK60Jx9Vm4HzpxBJugemhrMg-qizQ03TTNswfL9AgTIsLeh_D8TDjcQJy6XFWgElxfUYqUFeZmlXPmQKFmmPyIChlSAFbX1L8QvcgFE1c8GHC900RiKVgGLhT5MOZx5l1WBCbNQ_Rv2u9utcz7EqYTb0y_PjD4EC8UaGdGGlqvEAnKvRVIhxRqFarqh-OW4oUfwfwu1xQIvyWphSDegcOjIERFkhVcQeKO-a3zZS9sfJ03ppZhzAsa5O-qswtbzThO9SWQg7JUgyo7qd-zHIRhwPtEWxDGaBt2QGo7jjopw\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;Bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 299 } Spring 资源服务器 现在让我们创建一个受此身份验证服务器保护的 API 端点，其范围为我们在令牌创建中使用的 articles.read。\n依赖项： 让我们将以下依赖项添加到我们的项目中：\nimplementation \u0026#39;org.springframework.boot:spring-boot-starter-oauth2-resource-server\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; testImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39; testImplementation \u0026#39;org.springframework.security:spring-security-test\u0026#39; Java 实现： 让我们首先创建一个简单的 rest 控制器，然后创建一个配置，以在正确的范围内保护该 API。之后，我们将在 application.yml 文件中配置身份验证服务器设置。\nAPI 控制器 @RestController public class ArticlesController { @GetMapping(\u0026#34;/articles\u0026#34;) public String[] getArticles() { return new String[] { \u0026#34;Article 1\u0026#34;, \u0026#34;Article 2\u0026#34;, \u0026#34;Article 3\u0026#34; }; } } 我们创建了一个简单的 GET API 端点 /articles，它将返回文章列表。\nResourceServerConfig @EnableWebSecurity public class ResourceServerConfig { @Bean SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http .authorizeRequests() .requestMatchers(\u0026#34;/articles/**\u0026#34;) .access(\u0026#34;hasAuthority(\u0026#39;SCOPE_articles.read\u0026#39;)\u0026#34;) .and() .oauth2ResourceServer() .jwt(); return http.build(); } } 我们将创建一个配置类并使用@EnableWebSecurity 对其进行注释。我们将创建一个 SecurityFilterChain 的 bean，在其中定义 API 和所需的范围。\napplication.yml spring: security: oauth2: resourceserver: jwt: issuer-uri: http://localhost:9090 我们在这里定义 oauth2 配置，注意将 issuer-url 的端口更新为正确的端口。\n现在一切都已配置完毕，让我们启动该服务并向 API 发出带有或不带有令牌的请求。您应该得到一个没有令牌或带有无效令牌的 401 响应，并且您应该得到带有有效令牌的正确响应。\n客户端服务器 我们现在将创建一个简单的 Spring Boot 项目，它将使用资源服务器创建的 API。我们将在此处配置身份验证服务器详细信息，以便它在发出 API 请求之前自动获取令牌。\n依赖项： implementation \u0026#39;org.springframework.boot:spring-boot-starter-oauth2-client\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; implementation \u0026#39;org.springframework:spring-webflux\u0026#39; testImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39; testImplementation \u0026#39;org.springframework.security:spring-security-test\u0026#39; Java 实现： 我们首先创建配置类，然后创建一个测试 API 来向资源服务器发出请求。之后，我们将在 application.yml 文件中定义令牌配置。\n**SecurityConfig ** @Configuration public class SecurityConfig { @Bean SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { return http.oauth2Client().and().build(); } @Bean WebClient webClient(OAuth2AuthorizedClientManager authorizedClientManager) { ServletOAuth2AuthorizedClientExchangeFilterFunction oauth2Client = new ServletOAuth2AuthorizedClientExchangeFilterFunction(authorizedClientManager); return WebClient.builder() .apply(oauth2Client.oauth2Configuration()) .build(); } @Bean OAuth2AuthorizedClientManager authorizedClientManager(ClientRegistrationRepository clientRegistrationRepository, OAuth2AuthorizedClientService oAuth2AuthorizedClientService, OAuth2AccessTokenResponseClient\u0026lt;OAuth2ClientCredentialsGrantRequest\u0026gt; tokenResponseClient) { OAuth2AuthorizedClientProvider authorizedClientProvider = OAuth2AuthorizedClientProviderBuilder.builder() .clientCredentials(r -\u0026gt; r.accessTokenResponseClient(tokenResponseClient)).clientCredentials().build(); var authorizedClientManager = new AuthorizedClientServiceOAuth2AuthorizedClientManager( clientRegistrationRepository, oAuth2AuthorizedClientService); authorizedClientManager.setAuthorizedClientProvider(authorizedClientProvider); return authorizedClientManager; } @Bean OAuth2AccessTokenResponseClient\u0026lt;OAuth2ClientCredentialsGrantRequest\u0026gt; tokenResponseClient() { return new DefaultClientCredentialsTokenResponseClient(); } } application.yml spring: security: oauth2: client: registration: articles-client: client-id: oauth-client client-secret: oauth-secret authorization-grant-type: client_credentials scope: articles.read client-name: spring-client provider: articles-client: token-uri: http://localhost:9090/oauth2/token 客户端 API（向资源服务器发出请求） @RestController public class ArticlesController { @Autowired private WebClient webClient; @GetMapping(value = \u0026#34;/test\u0026#34;) public String[] test() { return this.webClient .get() .uri(\u0026#34;http://127.0.0.1:9091/articles\u0026#34;) .attributes(clientRegistrationId(\u0026#34;articles-client\u0026#34;)) .retrieve() .bodyToMono(String[].class) .block(); } } 我们可以在这里看到，当我们调用 /test API 时，它会从我们的身份验证服务器获取令牌，然后向我们的资源服务器 /articles 端点发出请求并返回响应。\n让我们运行所有三个服务器并向客户端服务器发出请求，它应该返回正确的响应。请注意更新所有位置的端口号。在示例中，我使用了以下端口：\n9090: auth-server 9090：认证服务器 9091: resource-server 9091：资源服务器 9092: client-server 9092：客户端-服务器 结论 在本文中，我们学习了如何使用 Spring Boot 创建授权服务器以及如何在资源服务器和客户端服务器中配置它。\n您可以在此 GitHub 存储库中找到此示例的代码。\n原文链接：https://blog.devgenius.io/spring-boot-authorization-server-825230ae0ed2\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/spring-boot-authorization-server/","summary":"概述 在本文中，我们将创建一个授权服务器，为任何客户端生成 access_token。这称为 OAuth2 的 client_credentials 流程。它主要用于服务间通信。\n我们将使用 spring boot oauth2 授权服务器依赖项来创建身份验证服务器。我们还将创建一个资源服务器和客户端来对其进行端到端测试。\nSpring 授权服务器 我们首先创建授权服务器。\n依赖项： 让我们将以下依赖项添加到我们的项目中。\nimplementation \u0026#39;org.springframework.security:spring-security-oauth2-authorization-server:1.0.0\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; implementation \u0026#39;org.springframework.boot:spring-boot-starter-web\u0026#39; testImplementation \u0026#39;org.springframework.boot:spring-boot-starter-test\u0026#39; testImplementation \u0026#39;org.springframework.security:spring-security-test\u0026#39; 我们正在使用 spring oauth2 依赖项的最新（当时）稳定版本。\nJava 实现： 让我们创建一个名为 AuthorizationServerConfig 的配置类，并向该类添加 @Configuration 注解。现在让我们创建以下 bean 来完成配置：\nSecurityFilterChain @Bean @Order(Ordered.HIGHEST_PRECEDENCE) public SecurityFilterChain authServerSecurityFilterChain(HttpSecurity http) throws Exception { OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http); return http.build(); } 我们将把 bean 的顺序设置为最高，因为我们想首先执行它。\nRegisteredClientRepository @Bean public RegisteredClientRepository registeredClientRepository() { RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString()) .clientId(\u0026#34;oauth-client\u0026#34;) .clientSecret(\u0026#34;{noop}oauth-secret\u0026#34;) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) .scope(OidcScopes.OPENID) .scope(\u0026#34;articles.read\u0026#34;) .build(); return new InMemoryRegisteredClientRepository(registeredClient); } 现在让我们使用内存存储库对内容进行硬编码。我们可以根据我们的需要更新这些。\nJwtDecoder @Bean public JwtDecoder jwtDecoder(JWKSource\u0026lt;SecurityContext\u0026gt; jwkSource) { return OAuth2AuthorizationServerConfiguration.jwtDecoder(jwkSource); } 我们将使用它来解码令牌以进行验证。\nJWKSource @Bean public JWKSource\u0026lt;SecurityContext\u0026gt; jwkSource() throws NoSuchAlgorithmException { RSAKey rsaKey = generateRsa(); JWKSet jwkSet = new JWKSet(rsaKey); return (jwkSelector, securityContext) -\u0026gt; jwkSelector.","title":"[译]Spring Boot授权服务器 - 使用 Java 的资源服务器和客户端凭证示例"},{"content":"处理异常是构建健壮应用程序的重要部分。 Spring Boot 提供了不止一种方法。\n本文将探讨这些方法，并提供一些关于何时某种给定方法可能优于另一种方法的指导。\n示例代码 本文附有 GitHub 上的工作代码示例。\n介绍 Spring Boot 为我们提供了处理异常的工具，而不仅仅是简单的“try-catch”块。为了使用这些工具，我们应用了一些注释，使我们能够将异常处理视为横切关注点：\n@ResponseStatus @ExceptionHandler @ControllerAdvice 在深入了解这些注释之前，我们将首先了解 Spring 如何处理 Web 控制器抛出的异常——这是捕获异常的最后一道防线。\n我们还将查看 Spring Boot 提供的一些配置来修改默认行为。\n我们将确定这样做时面临的挑战，然后我们将尝试使用这些注释来克服这些挑战。\nSpring Boot 默认的异常处理机制 假设我们有一个名为 ProductController 的控制器，当未找到具有给定 id 的 Product 时，其 getProduct(...) 方法会抛出 NoSuchElementFoundException 运行时异常：\n@RestController @RequestMapping(\u0026#34;/product\u0026#34;) public class ProductController { private final ProductService productService; //constructor omitted for brevity... @GetMapping(\u0026#34;/{id}\u0026#34;) public Response getProduct(@PathVariable String id){ // this method throws a \u0026#34;NoSuchElementFoundException\u0026#34; exception return productService.getProduct(id); } } 如果我们使用无效的 id 调用 /product API，服务将抛出 NoSuchElementFoundException 运行时异常，我们将得到以下响应：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-11-28T13:24:02.239+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/product/1\u0026#34; } 我们可以看到，除了格式良好的错误响应之外，有效负载没有为我们提供任何有用的信息。甚至 message 字段也是空的，我们可能希望包含“未找到 id 1 的项目”之类的内容。\n让我们从修复错误消息问题开始。\nSpring Boot 提供了一些属性，我们可以使用它们添加异常消息、异常类，甚至堆栈跟踪作为响应负载的一部分：\nserver: error: include-message: always include-binding-errors: always include-stacktrace: on_trace_param include-exception: false 在 application.yml 中使用这些 Spring Boot 服务器属性，我们可以在某种程度上改变错误响应。\n现在，如果我们使用无效的 id 再次调用 /product API，我们将得到以下响应：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-11-29T09:42:12.287+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Item with id 1 not found\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/product/1\u0026#34; } 请注意，我们已将属性 include-stacktrace 设置为 on_trace_param ，这意味着仅当我们在 URL ( ?trace=true ) 中包含 trace 参数时，我们才会在响应负载中获得堆栈跟踪：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-11-29T09:42:12.287+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Item with id 1 not found\u0026#34;, \u0026#34;trace\u0026#34;: \u0026#34;io.reflectoring.exception.exception.NoSuchElementFoundException: Item with id 1 not found...\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/product/1\u0026#34; } 我们可能希望将 include-stacktrace 标志的值保留为 never ，至少在生产中，因为它可能会揭示我们应用程序的内部工作原理。\n继续！状态和错误消息 - 500 - 表明我们的服务器代码有问题，但实际上这是客户端错误，因为客户端提供了无效的 ID。\n我们当前的状态代码没有正确反映这一点。不幸的是，这就是我们可以使用 server.error 配置属性的范围，因此我们必须查看 Spring Boot 提供的注释。\n@ResponseStatus 顾名思义， @ResponseStatus 允许我们修改响应的 HTTP 状态。它可以应用在以下地方：\n关于异常类本身 以及方法上的 @ExceptionHandler 注释 以及类上的 @ControllerAdvice 注释 在本节中，我们将仅讨论第一种情况。\n让我们回到当前的问题，即我们的错误响应总是给我们 HTTP 状态 500，而不是更具描述性的状态代码。\n为了解决这个问题，我们可以用 @ResponseStatus 注释我们的 Exception 类，并在其 value 属性中传入所需的 HTTP 响应状态：\n@ResponseStatus(value = HttpStatus.NOT_FOUND) public class NoSuchElementFoundException extends RuntimeException { ... } 如果我们使用无效 ID 调用控制器，此更改将带来更好的响应：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-11-29T09:42:12.287+00:00\u0026#34;, \u0026#34;status\u0026#34;: 404, \u0026#34;error\u0026#34;: \u0026#34;Not Found\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Item with id 1 not found\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/product/1\u0026#34; } 实现相同目的的另一种方法是扩展 ResponseStatusException 类：\npublic class NoSuchElementFoundException extends ResponseStatusException { public NoSuchElementFoundException(String message){ super(HttpStatus.NOT_FOUND, message); } @Override public HttpHeaders getResponseHeaders() { // return response headers } } 当我们想要操作响应头时，这种方法会派上用场，因为我们可以重写 getResponseHeaders() 方法。\n@ResponseStatus 与 server.error 配置属性相结合，使我们能够操作 Spring 定义的错误响应负载中的几乎所有字段。\n但是如果还想操纵响应负载的结构怎么办？\n让我们在下一节中看看如何实现这一目标。\n@ExceptionHandler @ExceptionHandler 注释在处理异常方面为我们提供了很大的灵活性。对于初学者来说，要使用它，我们只需在控制器本身或 @ControllerAdvice 类中创建一个方法，并用 @ExceptionHandler 注释它：\n@RestController @RequestMapping(\u0026#34;/product\u0026#34;) public class ProductController { private final ProductService productService; //constructor omitted for brevity... @GetMapping(\u0026#34;/{id}\u0026#34;) public Response getProduct(@PathVariable String id) { return productService.getProduct(id); } @ExceptionHandler(NoSuchElementFoundException.class) @ResponseStatus(HttpStatus.NOT_FOUND) public ResponseEntity\u0026lt;String\u0026gt; handleNoSuchElementFoundException( NoSuchElementFoundException exception ) { return ResponseEntity .status(HttpStatus.NOT_FOUND) .body(exception.getMessage()); } } 异常处理程序方法接受一个异常或异常列表作为我们要在定义的方法中处理的参数。我们用 @ExceptionHandler 和 @ResponseStatus 注释该方法来定义我们想要处理的异常和我们想要返回的状态代码。\n如果我们不想使用这些注释，那么只需将异常定义为方法的参数也可以：\n@ExceptionHandler public ResponseEntity\u0026lt;String\u0026gt; handleNoSuchElementFoundException( NoSuchElementFoundException exception) 尽管我们已经在方法签名中提到了它，但在注释中提及异常类是个好主意。它提供了更好的可读性。\n此外，处理程序方法上的注释 @ResponseStatus(HttpStatus.NOT_FOUND) 不是必需的，因为传递到 ResponseEnity 的 HTTP 状态将优先，但出于相同的可读性原因，我们仍然保留它。\n除了异常参数之外，我们还可以使用 HttpServletRequest 、 WebRequest 或 HttpSession 类型作为参数。\n同样，处理程序方法支持各种返回类型，例如 ResponseEntity 、 String 甚至 void 。\n在 @ExceptionHandler java 文档中查找更多输入和返回类型。\n在异常处理函数中，我们可以通过输入参数和返回类型的形式使用许多不同的选项，因此我们可以完全控制错误响应。\n现在，让我们最终确定 API 的错误响应负载。如果出现任何错误，客户通常会期望两件事：\n错误代码告诉客户端它是什么类型的错误。客户端可以在其代码中使用错误代码来驱动基于它的某些业务逻辑。通常，错误代码是标准的 HTTP 状态代码，但我也看到 API 返回自定义错误代码，例如 E001 。\n一条附加的人类可读消息，提供有关错误的更多信息，甚至提供有关如何修复错误的一些提示或 API 文档的链接。\n我们还将添加一个可选的 stackTrace 字段，这将帮助我们在开发环境中进行调试。\n最后，我们还想处理响应中的验证错误。您可以在这篇有关使用 Spring Boot 处理验证的文章中找到有关 bean 验证的更多信息。\n记住这些点，我们将为错误响应使用以下有效负载：\n@Getter @Setter @RequiredArgsConstructor @JsonInclude(JsonInclude.Include.NON_NULL) public class ErrorResponse { private final int status; private final String message; private String stackTrace; private List\u0026lt;ValidationError\u0026gt; errors; @Getter @Setter @RequiredArgsConstructor private static class ValidationError { private final String field; private final String message; } public void addValidationError(String field, String message){ if(Objects.isNull(errors)){ errors = new ArrayList\u0026lt;\u0026gt;(); } errors.add(new ValidationError(field, message)); } } 现在，让我们将所有这些应用到 NoSuchElementFoundException 处理程序方法中。\n@RestController @RequestMapping(\u0026#34;/product\u0026#34;) @AllArgsConstructor public class ProductController { public static final String TRACE = \u0026#34;trace\u0026#34;; @Value(\u0026#34;${reflectoring.trace:false}\u0026#34;) private boolean printStackTrace; private final ProductService productService; @GetMapping(\u0026#34;/{id}\u0026#34;) public Product getProduct(@PathVariable String id){ return productService.getProduct(id); } @PostMapping public Product addProduct(@RequestBody @Valid ProductInput input){ return productService.addProduct(input); } @ExceptionHandler(NoSuchElementFoundException.class) @ResponseStatus(HttpStatus.NOT_FOUND) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleItemNotFoundException( NoSuchElementFoundException exception, WebRequest request ){ log.error(\u0026#34;Failed to find the requested element\u0026#34;, exception); return buildErrorResponse(exception, HttpStatus.NOT_FOUND, request); } @ExceptionHandler(MethodArgumentNotValidException.class) @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleMethodArgumentNotValid( MethodArgumentNotValidException ex, WebRequest request ) { ErrorResponse errorResponse = new ErrorResponse( HttpStatus.UNPROCESSABLE_ENTITY.value(), \u0026#34;Validation error. Check \u0026#39;errors\u0026#39; field for details.\u0026#34; ); for (FieldError fieldError : ex.getBindingResult().getFieldErrors()) { errorResponse.addValidationError(fieldError.getField(), fieldError.getDefaultMessage()); } return ResponseEntity.unprocessableEntity().body(errorResponse); } @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public ResponseEntity\u0026lt;ErrorResponse\u0026gt; handleAllUncaughtException( Exception exception, WebRequest request){ log.error(\u0026#34;Unknown error occurred\u0026#34;, exception); return buildErrorResponse( exception, \u0026#34;Unknown error occurred\u0026#34;, HttpStatus.INTERNAL_SERVER_ERROR, request ); } private ResponseEntity\u0026lt;ErrorResponse\u0026gt; buildErrorResponse( Exception exception, HttpStatus httpStatus, WebRequest request ) { return buildErrorResponse( exception, exception.getMessage(), httpStatus, request); } private ResponseEntity\u0026lt;ErrorResponse\u0026gt; buildErrorResponse( Exception exception, String message, HttpStatus httpStatus, WebRequest request ) { ErrorResponse errorResponse = new ErrorResponse( httpStatus.value(), exception.getMessage() ); if(printStackTrace \u0026amp;\u0026amp; isTraceOn(request)){ errorResponse.setStackTrace(ExceptionUtils.getStackTrace(exception)); } return ResponseEntity.status(httpStatus).body(errorResponse); } private boolean isTraceOn(WebRequest request) { String [] value = request.getParameterValues(TRACE); return Objects.nonNull(value) \u0026amp;\u0026amp; value.length \u0026gt; 0 \u0026amp;\u0026amp; value[0].contentEquals(\u0026#34;true\u0026#34;); } } 这里需要注意几点：\n提供堆栈跟踪 在错误响应中提供堆栈跟踪可以使我们的开发人员和 QA 工程师免去爬行日志文件的麻烦。\n正如我们在 Spring Boot 的默认异常处理机制中看到的，Spring 已经为我们提供了这个功能。但现在，由于我们自己处理错误响应，因此这也需要我们自己处理。\n为了实现这一点，我们首先引入了一个名为 reflectoring.trace 的服务器端配置属性，如果将其设置为 true ，为了实现此目的，我们首先引入了一个名为 reflectoring.trace 的服务器端配置属性，如果将其设置为 true ，将启用响应中的 stackTrace 字段。要实际在 API 响应中获取 stackTrace ，我们的客户端还必须传递带有值 true 的 trace 参数：\ncurl --location --request GET \u0026#39;http://localhost:8080/product/1?trace=true\u0026#39; 现在，由于 stackTrace 的行为由属性文件中的功能标志控制，因此当我们在生产环境中部署时，我们可以将其删除或将其设置为 false 。\n捕获所有异常处理程序 需要把他们全都抓到：\ntry{ performSomeOperation(); } catch(OperationSpecificException ex){ //... } catch(Exception catchAllExcetion){ //... } 作为一项谨慎措施，我们经常用一个包罗万象的 try-catch 异常处理程序块包围顶级方法的主体，以避免任何不需要的副作用或行为。我们控制器中的 handleAllUncaughtException() 方法的行为类似。它将捕获我们没有特定处理程序的所有异常。\n我想在这里指出的一件事是，即使我们没有这个包罗万象的异常处理程序，Spring 也会处理它。但我们希望响应采用我们的格式而不是 Spring 的格式，因此我们必须自己处理异常。\n包罗万象的处理程序方法也是记录异常的好地方，因为它们可以深入了解可能的错误。我们可以跳过记录字段验证异常，例如 MethodArgumentNotValidException ，因为它们是由于语法上无效的输入而引发的，但我们应该始终在捕获所有处理程序中记录未知异常。\n异常处理程序的顺序 提及处理程序方法的顺序并不重要。 Spring 将首先寻找最具体的异常处理方法。\n如果找不到它，那么它将查找父异常的处理程序，在我们的例子中是 RuntimeException ，如果没有找到，则 handleAllUncaughtException() 方法将最终处理该异常。\n这应该可以帮助我们处理这个特定控制器中的异常，但是如果其他控制器也抛出这些相同的异常怎么办？我们如何处理这些？我们是否在所有控制器中创建相同的处理程序，或者创建具有公共处理程序的基类并在所有控制器中扩展它？\n幸运的是，我们不必这样做。 Spring 以“控制器建议”的形式为这个问题提供了一个非常优雅的解决方案。\n让我们研究一下它们。\n@ControllerAdvice 为什么称为“控制器建议”？\n“建议”一词来自面向方面编程 (AOP)，它允许我们围绕现有方法注入横切代码（称为“建议”）。控制器建议允许我们拦截和修改控制器方法的返回值，在我们的例子中是为了处理异常。\n控制器建议类允许我们将异常处理程序应用于应用程序中的多个或所有控制器：\n@ControllerAdvice public class GlobalExceptionHandler extends ResponseEntityExceptionHandler { public static final String TRACE = \u0026#34;trace\u0026#34;; @Value(\u0026#34;${reflectoring.trace:false}\u0026#34;) private boolean printStackTrace; @Override @ResponseStatus(HttpStatus.UNPROCESSABLE_ENTITY) protected ResponseEntity\u0026lt;Object\u0026gt; handleMethodArgumentNotValid( MethodArgumentNotValidException ex, HttpHeaders headers, HttpStatus status, WebRequest request ) { //Body omitted as it\u0026#39;s similar to the method of same name // in ProductController example... //..... } @ExceptionHandler(ItemNotFoundException.class) @ResponseStatus(HttpStatus.NOT_FOUND) public ResponseEntity\u0026lt;Object\u0026gt; handleItemNotFoundException( ItemNotFoundException itemNotFoundException, WebRequest request ){ //Body omitted as it\u0026#39;s similar to the method of same name // in ProductController example... //..... } @ExceptionHandler(RuntimeException.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public ResponseEntity\u0026lt;Object\u0026gt; handleAllUncaughtException( RuntimeException exception, WebRequest request ){ //Body omitted as it\u0026#39;s similar to the method of same name // in ProductController example... //..... } //.... @Override public ResponseEntity\u0026lt;Object\u0026gt; handleExceptionInternal( Exception ex, Object body, HttpHeaders headers, HttpStatus status, WebRequest request) { return buildErrorResponse(ex,status,request); } } 处理函数的主体和其他支持代码被省略，因为它们与我们在 @ExceptionHandler 部分看到的代码几乎相同。请在 Github Repo 的 GlobalExceptionHandler 类中找到完整的代码。\n有几件事是新的，我们稍后会讨论。这里的一个主要区别是这些处理程序将处理应用程序中所有控制器抛出的异常，而不仅仅是 ProductController 。\n如果我们想有选择地将控制器建议的范围应用或限制到特定控制器或包，我们可以使用注释提供的属性：\n@ControllerAdvice(\u0026quot;com.reflectoring.controller\u0026quot;) ：我们可以在注释的 value 或 basePackages 参数中传递包名称或包名称列表。这样，控制器建议将仅处理该包控制器的异常。 @ControllerAdvice(annotations = Advised.class) ：只有标有 @Advised 注释的控制器才会由控制器建议处理。 在 @ControllerAdvice 注释文档中查找其他参数。\nResponseEntityExceptionHandler ResponseEntityExceptionHandler 是控制器建议类的便捷基类。它为内部 Spring 异常提供异常处理程序。如果我们不扩展它，那么所有异常将被重定向到 DefaultHandlerExceptionResolver ，它返回一个 ModelAndView 对象。因为我们的使命是塑造我们自己的错误响应，所以我们不希望这样。\n正如您所看到的，我们重写了两个 ResponseEntityExceptionHandler 方法：\nhandleMethodArgumentNotValid() ：在 @ExceptionHandler 部分，我们自己实现了一个处理程序。在这里我们只是覆盖了它的行为。 handleExceptionInternal() ： ResponseEntityExceptionHandler 中的所有处理程序都使用此函数来构建类似于 buildErrorResponse() 的 ResponseEntity 。如果我们不重写此方法，那么客户端将仅收到响应标头中的 HTTP 状态，但由于我们也希望在响应正文中包含 HTTP 状态，因此我们重写了该方法。 处理 NoHandlerFoundException 需要一些额外的步骤 当您尝试调用系统中不存在的 API 时，会出现此异常。尽管我们通过 ResponseEntityExceptionHandler 类实现其处理程序，但异常仍被重定向到 DefaultHandlerExceptionResolver 。\n要将异常重定向到我们的建议，我们需要在属性文件中设置几个属性： spring.mvc.throw-exception-if-no-handler-found=true 和 spring.web.resources.add-mappings=false\n使用 @ControllerAdvice 时要记住的一些要点 为了简单起见，项目中始终只有一个控制器建议类。最好有一个应用程序中所有异常的单一存储库。如果您创建多个控制器建议，请尝试使用 basePackages 或 annotations 属性来明确它将建议哪些控制器。\nSpring 可以按任何顺序处理控制器建议类，除非我们使用 @Order 注释对其进行注释。因此，如果您有多个控制器建议，那么在编写一个包罗万象的处理程序时要小心。特别是当您没有在注释中指定 basePackages 或 annotations 时。\nSpring 如何处理异常？ 现在我们已经介绍了 Spring 中处理异常的可用机制，让我们简要了解 Spring 如何处理它以及何时一种机制优先于另一种机制。\n如果我们还没有构建自己的异常处理程序，请看下面的流程图，它跟踪了 Spring 异常处理的过程：\n结论 当异常跨越控制器的边界时，它注定会以 JSON 响应或 HTML 网页的形式到达客户端。\n在本文中，我们了解了 Spring Boot 如何将这些异常转换为客户友好的输出，以及配置和注释，使我们能够将它们进一步塑造成我们想要的形状。\n感谢您的阅读！您可以在 GitHub 上找到工作代码。\n原文链接：https://reflectoring.io/spring-boot-exception-handling/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/spring-boot-exception-handling/","summary":"处理异常是构建健壮应用程序的重要部分。 Spring Boot 提供了不止一种方法。\n本文将探讨这些方法，并提供一些关于何时某种给定方法可能优于另一种方法的指导。\n示例代码 本文附有 GitHub 上的工作代码示例。\n介绍 Spring Boot 为我们提供了处理异常的工具，而不仅仅是简单的“try-catch”块。为了使用这些工具，我们应用了一些注释，使我们能够将异常处理视为横切关注点：\n@ResponseStatus @ExceptionHandler @ControllerAdvice 在深入了解这些注释之前，我们将首先了解 Spring 如何处理 Web 控制器抛出的异常——这是捕获异常的最后一道防线。\n我们还将查看 Spring Boot 提供的一些配置来修改默认行为。\n我们将确定这样做时面临的挑战，然后我们将尝试使用这些注释来克服这些挑战。\nSpring Boot 默认的异常处理机制 假设我们有一个名为 ProductController 的控制器，当未找到具有给定 id 的 Product 时，其 getProduct(...) 方法会抛出 NoSuchElementFoundException 运行时异常：\n@RestController @RequestMapping(\u0026#34;/product\u0026#34;) public class ProductController { private final ProductService productService; //constructor omitted for brevity... @GetMapping(\u0026#34;/{id}\u0026#34;) public Response getProduct(@PathVariable String id){ // this method throws a \u0026#34;NoSuchElementFoundException\u0026#34; exception return productService.getProduct(id); } } 如果我们使用无效的 id 调用 /product API，服务将抛出 NoSuchElementFoundException 运行时异常，我们将得到以下响应：\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2020-11-28T13:24:02.239+00:00\u0026#34;, \u0026#34;status\u0026#34;: 500, \u0026#34;error\u0026#34;: \u0026#34;Internal Server Error\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/product/1\u0026#34; } 我们可以看到，除了格式良好的错误响应之外，有效负载没有为我们提供任何有用的信息。甚至 message 字段也是空的，我们可能希望包含“未找到 id 1 的项目”之类的内容。\n让我们从修复错误消息问题开始。\nSpring Boot 提供了一些属性，我们可以使用它们添加异常消息、异常类，甚至堆栈跟踪作为响应负载的一部分：","title":"[译]Spring Boot异常处理完整指南"},{"content":"NullPointerExceptions （通常缩写为“NPE”）对于每个 Java 程序员来说都是一场噩梦。\n我们可以在互联网上找到大量解释如何编写空安全代码的文章。空安全确保我们在代码中添加了适当的检查，以保证对象引用不能为空，或者毕竟在对象为空时采取可能的安全措施。\n由于 NullPointerException 是一个运行时异常，因此在代码编译过程中很难找出这种情况。 Java 的类型系统没有办法快速消除危险的空对象引用。\n幸运的是，Spring 框架提供了一些注释来解决这个问题。在本文中，我们将学习如何使用这些注释通过 Spring Boot 编写空安全代码。\n示例代码 本文附有 GitHub 上的工作代码示例。\nSpring 中的空安全注解 在 Spring 核心包 org.springframework.lang 下，有 4 个这样的注解：\n@NonNull, @NonNull ， @NonNullFields, @NonNullFields ， @Nullable, @NonNullApi. Eclipse 和 IntelliJ IDEA 等流行的 IDE 可以理解这些注释。它们可以在编译期间警告开发人员潜在的问题。\n我们将在本教程中使用 IntelliJ IDEA。让我们通过一些代码示例来了解更多信息。\n要创建基础项目，我们可以使用 Spring Initializr。 Spring Boot 启动器就是我们所需要的，不需要添加任何额外的依赖项。\nIDE 配置 请注意，并非所有开发工具都可以显示这些编译警告。如果您没有看到相关警告，请检查 IDE 中的编译器设置。\nIntelliJ 对于 IntelliJ，我们可以在“Build, Execution, Deployment -\u0026gt; Compiler”下激活注释检查：\nEclipse 对于 Eclipse，我们可以在“Java -\u0026gt; Compiler -\u0026gt; Errors/Warnings”下找到设置：\n示例代码 让我们使用一个简单的 Employee 类来理解注释：\npackage io.reflectoring.nullsafety; // imports class Employee { String id; String name; LocalDate joiningDate; String pastEmployment; // standard constructor, getters, setters } @NonNull 大多数情况下， id 字段（在 Employee 类中）将是一个不可为 null 的值。因此，为了避免任何潜在的 NullPointerException 我们可以将此字段标记为 @NonNull ：\nclass Employee { @NonNull String id; //... } 现在，如果我们不小心尝试在代码中的任何位置将 id 的值设置为 null，IDE 将显示编译警告：\n@NonNull 注释可以在方法、参数或字段级别使用。**\n此时，您可能会想“如果一个类有多个非空字段怎么办？”。如果我们必须在每一个之前添加 @NonNull 注释，是不是太罗嗦了？\n我们可以通过使用 @NonNullFields 注释来解决这个问题。\n以下是 @NonNull 的快速摘要：\n带注释的元素 影响 field 当字段为空时显示警告 parameter 当参数为空时显示警告 method 当方法返回 null 时显示警告 package 不适用 @NonNullFields 让我们创建一个 package-info.java 文件以在包级别应用非空字段检查。该文件将包含带有 @NonNullFields 注释的根包名称：\n@NonNullFields package io.reflectoring.nullsafety; import org.springframework.lang.NonNullFields; 现在，我们不再需要使用 @NonNull 注释来注释字段。因为默认情况下，该包中类的所有字段现在都被视为非空。而且，我们仍然会看到与以前相同的警告：\n这里要注意的另一点是，如果有任何未初始化的字段，那么我们将看到初始化这些字段的警告：\n以下是 @NonNullFields 的快速摘要：\n带注释的元素 影响 field 不适用 parameter 不适用 method 不适用 package 如果所应用的包的任何字段为空，则显示警告 @NonNullApi 到目前为止，您可能已经发现了另一个要求，即对方法参数或返回值进行类似的检查。 @NonNullApi 将会来拯救我们。\n与 @NonNullFields 类似，我们可以使用 package-info.java 文件并为目标包添加 @NonNullApi 注释：\n@NonNullApi package io.reflectoring.nullsafety; import org.springframework.lang.NonNullApi; 现在，如果我们编写方法返回 null 的代码：\npackage io.reflectoring.nullsafety; // imports class Employee { String getPastEmployment() { return null; } //... } 我们可以看到 IDE 现在警告我们有关不可为 null 的返回值：\n以下是 @NonNullApi 的快速摘要：\n带注释的元素 影响 field 不适用 parameter 不适用 method 不适用 package 如果所应用的包的任何参数或返回值为空，则显示警告 @Nullable 但这里有一个问题。在某些情况下，特定字段可能为空（无论我们多么想避免它）。\n例如， pastEmployment 字段在 Employee 类中可以为空（对于以前没有工作过的人）。但根据我们的安全检查，IDE 认为不可能。\n我们可以使用字段上的 @Nullable 注释来表达我们的意图。这将告诉 IDE 该字段在某些情况下可以为空，因此无需触发警报。正如 JavaDoc 所建议的：\n可以与 @NonNullApi 或 @NonNullFields 结合使用，将默认的不可为空语义覆盖为可为空。\n与 NonNull 类似， Nullable 注释可以应用于方法、参数或字段级别。\n我们现在可以将 pastEmployment 字段标记为可为空：\npackage io.reflectoring.nullsafety; // imports class Employee { @Nullable String pastEmployment; @Nullable String getPastEmployment() { return pastEmployment; } //... } 以下是 @Nullable 的快速摘要：\n带注释的元素 影响 field 表示该字段可以为空 parameter 表示参数可以为空 method 表示该方法可以返回 null package 不适用 自动构建检查 到目前为止，我们正在讨论现代 IDE 如何使编写空安全代码变得更容易。然而，如果我们想在构建管道中进行一些自动代码检查，这在某种程度上也是可行的。\nSpotBugs（著名但已废弃的 FindBugs 项目的转世）提供了一个 Maven/Gradle 插件，可以检测由于可空性而导致的代码异味。让我们看看如何使用它。\n对于 Maven 项目，我们需要更新 pom.xml 以添加 SpotBugs Maven 插件：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;com.github.spotbugs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spotbugs-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.2.0\u0026lt;/version\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- overwrite dependency on spotbugs if you want to specify the version of spotbugs --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.spotbugs\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spotbugs\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.5.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/plugin\u0026gt; 构建项目后，我们可以使用该插件的以下目标：\nspotbugs 目标分析目标项目。\ncheck 目标运行 spotbugs 目标，如果发现任何错误，则使构建失败。\n如果您使用 Gradle 而不是 Maven，则可以在 build.gradle 文件中配置 SpotBugs Gradle 插件：\ndependencies { spotbugsPlugins \u0026#39;com.h3xstream.findsecbugs:findsecbugs-plugin:1.11.0\u0026#39; } spotbugs { toolVersion = \u0026#39;4.5.3\u0026#39; } 项目更新后，我们可以使用 gradle check 命令运行检查。\nSpotBugs 提供了一些规则，通过在 Maven 构建期间处理 @NonNull 注释来标记潜在问题。您可以查看错误描述的详细列表。\n例如，如果任何用 @NonNull 注释的方法意外返回 null，则 SpotBugs 检查将失败，并显示类似以下内容的错误：\n[ERROR] High: io.reflectoring.nullsafety.Employee.getJoiningDate() may return null, but is declared @Nonnull [io.reflectoring.nullsafety.Employee] At Employee.java:[line 36] NP_NONNULL_RETURN_VIOLATION 结论 这些注解对于 Java 程序员来说确实是一个福音，可以减少运行时出现 NullPointerException 的可能性。但是请记住，这并不能保证完全的空安全。\nKotlin 使用这些注释来推断 Spring API 的可为空性。\n我希望您现在已经准备好在 Spring Boot 中编写 null 安全代码！\n原文链接：https://reflectoring.io/spring-boot-null-safety-annotations/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/spring-boot-null-safety-annotations/","summary":"NullPointerExceptions （通常缩写为“NPE”）对于每个 Java 程序员来说都是一场噩梦。\n我们可以在互联网上找到大量解释如何编写空安全代码的文章。空安全确保我们在代码中添加了适当的检查，以保证对象引用不能为空，或者毕竟在对象为空时采取可能的安全措施。\n由于 NullPointerException 是一个运行时异常，因此在代码编译过程中很难找出这种情况。 Java 的类型系统没有办法快速消除危险的空对象引用。\n幸运的是，Spring 框架提供了一些注释来解决这个问题。在本文中，我们将学习如何使用这些注释通过 Spring Boot 编写空安全代码。\n示例代码 本文附有 GitHub 上的工作代码示例。\nSpring 中的空安全注解 在 Spring 核心包 org.springframework.lang 下，有 4 个这样的注解：\n@NonNull, @NonNull ， @NonNullFields, @NonNullFields ， @Nullable, @NonNullApi. Eclipse 和 IntelliJ IDEA 等流行的 IDE 可以理解这些注释。它们可以在编译期间警告开发人员潜在的问题。\n我们将在本教程中使用 IntelliJ IDEA。让我们通过一些代码示例来了解更多信息。\n要创建基础项目，我们可以使用 Spring Initializr。 Spring Boot 启动器就是我们所需要的，不需要添加任何额外的依赖项。\nIDE 配置 请注意，并非所有开发工具都可以显示这些编译警告。如果您没有看到相关警告，请检查 IDE 中的编译器设置。\nIntelliJ 对于 IntelliJ，我们可以在“Build, Execution, Deployment -\u0026gt; Compiler”下激活注释检查：\nEclipse 对于 Eclipse，我们可以在“Java -\u0026gt; Compiler -\u0026gt; Errors/Warnings”下找到设置：\n示例代码 让我们使用一个简单的 Employee 类来理解注释：\npackage io.reflectoring.nullsafety; // imports class Employee { String id; String name; LocalDate joiningDate; String pastEmployment; // standard constructor, getters, setters } @NonNull 大多数情况下， id 字段（在 Employee 类中）将是一个不可为 null 的值。因此，为了避免任何潜在的 NullPointerException 我们可以将此字段标记为 @NonNull ：","title":"[译]使用 Spring 的 Null-Safety 注解保护您的代码免受 NullPointerExceptions 的影响"},{"content":"跨源资源共享 (CORS) 是一种基于 HTTP 标头的机制，允许服务器显式将某些源列入白名单，并帮助绕过同源策略。\n这是必需的，因为浏览器默认应用同源策略以确保安全。通过在 Web 应用程序中实施 CORS，网页可以请求额外的资源并从其他域加载到浏览器中。\n本文将重点介绍在基于 Spring 的应用程序中实现 CORS 的各种方式。要详细了解 CORS 的工作原理，请参阅这篇优秀的介绍性文章。\n示例代码 本文附有 GitHub 上的工作代码示例。\nCORS 特定 HTTP 响应标头概述 CORS 规范定义了服务器返回的一组响应标头，这将是后续部分的重点。\n响应头 描述 Access-Control-Allow-Origin 以逗号分隔的白名单来源列表或“*”。 Access-Control-Allow-Methods Web 服务器允许跨源请求的 HTTP 方法的逗号分隔列表。 Access-Control-Allow-Headers Web 服务器允许跨源请求的 HTTP 标头的逗号分隔列表。 Access-Control-Expose-Headers 客户端脚本认为可以安全显示的以逗号分隔的 HTTP 标头列表。 Access-Control-Allow-Credentials 如果浏览器通过传递凭据（以 cookie 或授权标头的形式）向服务器发出请求，则其值设置为 true 。 Access-Control-Max-Age 指示预检请求的结果可以缓存多长时间。 设置示例客户端应用程序 我们将使用一个简单的角度应用程序来调用 REST 端点，我们可以使用浏览器开发人员工具检查这些端点。您可以在 GitHub 上查看源代码。\nng serve --open 我们应该能够成功启动客户端应用程序。\n设置示例服务器应用程序 我们将使用一个基于 Spring 的示例应用程序，其中包含客户端应用程序可以调用的 GET 和 POST 请求。请注意，您会发现两个独立的应用程序：一个使用 Spring MVC (REST)，另一个使用 Spring Reactive 堆栈。\n为简单起见，两个应用程序之间的 CORS 配置相同，并且定义了相同的端点。两台服务器都从不同的端口 8091 和 8092 启动。\n与应用程序捆绑在一起的 Maven Wrapper 将用于启动服务。您可以查看 Spring REST 源代码和 Spring Reactive 源代码。\nmvnw clean verify spring-boot:run (for Windows) ./mvnw clean verify spring-boot:run (for Linux) 一旦 Spring 应用程序成功启动，客户端应用程序应该能够成功从服务器加载数据。\n调用 Spring REST 服务器：\n调用 Spring Reactive 服务器：\n了解 @CrossOrigin 属性 在 Spring Boot 应用程序中，我们使用 @CrossOrigin 注解来启用跨域调用。我们先了解一下 @CrossOrigin 支持的属性。\n属性 Description 描述 origins 允许您指定允许的来源列表。默认情况下，它允许所有来源。 该属性值将在预检响应和实际响应的 Access-Control-Allow-Origin 标头中设置。 用法示例： @CrossOrigin(origins = \u0026quot;http://localhost:8080\u0026quot;) @CrossOrigin(origins = {\u0026quot;http://localhost:8080\u0026quot;, \u0026quot;http://testserver:8087\u0026quot;}) allowedHeaders 允许您指定浏览器发出请求时将接受的标头列表。默认情况下，任何标头都将被允许。此属性中指定的值用于预检响应中的 Access-Control-Allow-Headers 中。 用法示例： @CrossOrigin(allowedHeaders = {\u0026quot;Authorization\u0026quot;, \u0026quot;Origin\u0026quot;}) exposedHeaders 在实际响应标头中设置的标头列表。如果未指定，则只有安全列表中的标头才会被认为可以安全地由客户端脚本公开。 用法示例： @CrossOrigin(exposedHeaders = {\u0026quot;Access-Control-Allow-Origin\u0026quot;,\u0026quot;Access-Control-Allow-Credentials\u0026quot;}) allowCredentials 当需要凭据来调用 API 时，请将 Access-Control-Allow-Credentials 标头值设置为 true。如果不需要凭据，请省略标头。 用法示例： @CrossOrigin(allowCredentials = true) maxAge 默认 maxAge 设置为 1800 秒（30 分钟）。指示预检响应可以缓存多长时间。 用法示例： @CrossOrigin(maxAge = 300) 如果不配置 CORS 怎么办？ 考虑我们的 Spring Boot 应用程序尚未配置为 CORS 支持。如果我们尝试访问在端口 4200 上运行的 Angular 应用程序，我们会在开发人员控制台上看到以下错误：\nAccess to XMLHttpRequest at http://localhost:8091 from origin http://localhost:4200 has been blocked by CORS policy: No \u0026#39;Access-Control-Allow-Origin` header is present on the requested resource 这是因为，即使两个应用程序均由 localhost 提供服务，但由于端口不同，它们不会被视为同一来源。\n在 Spring Web MVC 应用程序中配置 CORS 使用 Spring Initializr 创建的初始设置包含所有必需的 CORS 依赖项。无需添加外部依赖项。请参阅此示例 Spring Web 应用程序项目。\n在类级别定义 @CrossOrigin @CrossOrigin(maxAge = 3600) @RestController @RequestMapping(\u0026#34;cors-library/managed/books\u0026#34;) public class LibraryController {} 由于我们已经定义了 @CrossOrigin ：\n控制器中的所有 @RequestMapping 方法（以及使用速记注释 @GetMapping 、 @PostMapping 等的方法）都将接受跨域请求。 自 maxAge = 3600 起，所有飞行前响应将被缓存 60 分钟。 在方法级别定义 @CrossOrigin @CrossOrigin(origins = \u0026#34;http://localhost:4200\u0026#34;, allowedHeaders = \u0026#34;Requestor-Type\u0026#34;, exposedHeaders = \u0026#34;X-Get-Header\u0026#34;) @GetMapping public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getBooks(@RequestParam String type) { HttpHeaders headers = new HttpHeaders(); headers.set(\u0026#34;X-Get-Header\u0026#34;, \u0026#34;ExampleHeader\u0026#34;); return ResponseEntity.ok().headers(headers).body(libraryService.getAllBooks(type)); } 这将产生以下效果：\n仅接受来自来源 http://localhost:4200 的请求。\n如果我们希望只接受某些标头，则可以在 allowedHeaders 属性中指定这些标头。如果浏览器未发送 Requestor-Type 标头，则不会处理该请求。\n如果我们设置某些响应标头，为了让客户端应用程序能够使用它们，我们需要使用 exposedHeaders 属性显式设置要公开的响应标头列表。\n类和方法级别的 @CrossOrigin 组合 @CrossOrigin(maxAge = 3600) @RestController @RequestMapping(\u0026#34;cors-library/managed/books\u0026#34;) public class LibraryController { private static final Logger log = LoggerFactory.getLogger(LibraryController.class); private final LibraryService libraryService; public LibraryController(LibraryService libraryService) { this.libraryService = libraryService; } @CrossOrigin(origins = \u0026#34;http://localhost:4200\u0026#34;, allowedHeaders = \u0026#34;Requestor-Type\u0026#34;) @GetMapping public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getBooks(@RequestParam String type) { HttpHeaders headers = new HttpHeaders(); headers.set(\u0026#34;X-Get-Header\u0026#34;, \u0026#34;ExampleHeader\u0026#34;); return ResponseEntity.ok().headers(headers).body(libraryService.getAllBooks(type)); } } 通过在类和方法级别定义注释，其组合属性将应用于方法，即（ origins 、 allowedHeaders 、``）\n在上述所有情况下，我们可以使用 @CrossOrigin 定义全局 CORS cmaxAgeonconfiguration 和本地配置。对于接受多个值的属性，将应用全局值和本地值的组合（即它们被合并）。对于仅接受单个值的属性，本地值将优先于全局值。\n全局启用 CORS 我们可以定义一个适用于定义的所有资源的通用 CORS 配置，而不是分别向每个资源添加 CORS。\n在这里，我们将使用 WebMvcConfigurer ，它是 Spring Web MVC 库的一部分\n通过重写 addCorsMapping() 方法，我们将为 Spring Web MVC 处理的所有 URL 配置 CORS。\n为了全局定义相同的配置（如前几节所述），我们将使用 application.yml 中定义的配置参数来创建一个 bean，如下定义。\napplication.yml 中定义的属性（ allowed-origins 、 allowed-methods 、 max-age 、 allowed-headers 、 exposed-headers ) 是通过 @ConfigurationProperties(prefix = \u0026quot;web\u0026quot;) 映射到自定义类 Cors 的自定义属性\nweb: cors: allowed-origins: \u0026#34;http://localhost:4200\u0026#34; allowed-methods: GET, POST, PATCH, PUT, DELETE, OPTIONS, HEAD max-age: 3600 allowed-headers: \u0026#34;Requestor-Type\u0026#34; exposed-headers: \u0026#34;X-Get-Header\u0026#34; @Bean public WebMvcConfigurer corsMappingConfigurer() { return new WebMvcConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { WebConfigProperties.Cors cors = webConfigProperties.getCors(); registry.addMapping(\u0026#34;/**\u0026#34;) .allowedOrigins(cors.getAllowedOrigins()) .allowedMethods(cors.getAllowedMethods()) .maxAge(cors.getMaxAge()) .allowedHeaders(cors.getAllowedHeaders()) .exposedHeaders(cors.getExposedHeaders()); } }; } CorsConfiguration 默认值 如果未显式定义一个或多个方法（ allowedOrigins 、 allowedMethods 、 maxAge 、 allowedHeaders 、 exposedHeaders ），则 addMapping() 返回一个 CorsRegistration 对象，该对象应用默认的 CorsConfiguration 。请参阅 Spring 库方法 CorsConfiguration.applyPermitDefaultValues() 以了解应用的默认值。\n在 Spring Webflux 应用程序中配置 CORS 初始设置是使用 Spring Initializr 创建的，并使用 Spring Webflux、Spring Data R2DBC 和 H2 数据库。无需添加外部依赖项。请参阅此示例 Spring Webflux 项目。\n使用 @CrossOrigin 进行 Spring Webflux 的 CORS 配置 与 Spring MVC 类似，在 Spring Webflux 中我们可以在类级别或方法级别定义 @CrossOrigin 。前面几节中描述的相同 @CrossOrigin 属性将适用。此外，当在类和方法中都定义了注释时，其组合属性将应用于方法。\n@CrossOrigin(origins = \u0026#34;http://localhost:4200\u0026#34;, allowedHeaders = \u0026#34;Requestor-Type\u0026#34;, exposedHeaders = \u0026#34;X-Get-Header\u0026#34;) @GetMapping public ResponseEntity\u0026lt;Mono\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt;\u0026gt; getBooks(@RequestParam String type) { HttpHeaders headers = new HttpHeaders(); headers.set(\u0026#34;X-Get-Header\u0026#34;, \u0026#34;ExampleHeader\u0026#34;); return ResponseEntity.ok().headers(headers).body(libraryService.getAllBooks(type)); } 在 Spring Webflux 中全局启用 CORS 配置 要在 Spring Webflux 应用程序中全局定义 CORS，我们使用 WebfluxConfigurer 并覆盖 addCorsMappings() 。与 Spring MVC 类似，它使用带有默认值的 CorsConfiguration ，可以根据需要覆盖默认值。\n@Bean public WebFluxConfigurer corsMappingConfigurer() { return new WebFluxConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { WebConfigProperties.Cors cors = webConfigProperties.getCors(); registry.addMapping(\u0026#34;/**\u0026#34;) .allowedOrigins(cors.getAllowedOrigins()) .allowedMethods(cors.getAllowedMethods()) .maxAge(cors.getMaxAge()) .allowedHeaders(cors.getAllowedHeaders()) .exposedHeaders(cors.getExposedHeaders()); } }; } 使用 WebFilter 启用 CORS Webflux 框架允许通过 CorsWebFilter 全局设置 CORS 配置。我们可以使用 CorsConfiguration 对象来设置所需的配置并注册要与过滤器一起使用的 CorsConfigurationSource 。\n但是，默认情况下，过滤器中的 CorsConfiguration 不会将默认配置分配给端点！只能应用指定的配置。\n另一种选择是显式调用 CorsConfiguration.applyPermitDefaultValues() 。\n@Bean public CorsWebFilter corsWebFilter() { CorsConfiguration corsConfig = new CorsConfiguration(); corsConfig.setAllowedOrigins(Arrays.asList(\u0026#34;http://localhost:4200\u0026#34;)); corsConfig.setMaxAge(3600L); corsConfig.addAllowedMethod(\u0026#34;*\u0026#34;); corsConfig.addAllowedHeader(\u0026#34;Requestor-Type\u0026#34;); corsConfig.addExposedHeader(\u0026#34;X-Get-Header\u0026#34;); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, corsConfig); return new CorsWebFilter(source); } 使用 Spring Security 启用 CORS 如果 Spring Security 应用于 Spring 应用程序，则必须在 Spring Security 生效之前处理 CORS，因为预检请求不会包含 cookie，并且 Spring Security 将拒绝该请求，因为它将确定用户未经过身份验证。这里显示的示例将演示基本身份验证。\n为了应用 Spring 安全性，我们将添加以下依赖 Maven：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-security\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Gradle:\nimplementation \u0026#39;org.springframework.boot:spring-boot-starter-security\u0026#39; Spring Security 应用于 Spring Web MVC Spring security 默认保护每个端点。但是，这会导致 CORS 错误，因为浏览器的 OPTIONS 预检请求将被阻止。要使 Spring Security 绕过预检请求，我们需要将 http.cors() 添加到 HTTPSecurity 对象，如下所示：\n@Configuration @EnableConfigurationProperties(BasicAuthConfigProperties.class) @EnableWebSecurity public class SecurityConfiguration extends WebSecurityConfigurerAdapter { private final BasicAuthConfigProperties basicAuth; public SecurityConfiguration(BasicAuthConfigProperties basicAuth) { this.basicAuth = basicAuth; } protected void configure(HttpSecurity http) throws Exception { http.cors(); } } 要在绕过预检请求后使用 Spring Security 设置额外的 CORS 配置，我们可以使用 @CrossOrigin 注释来配置 CORS：\n@CrossOrigin(maxAge = 3600, allowCredentials = \u0026#34;true\u0026#34;) @RestController @RequestMapping(\u0026#34;cors-library/managed/books\u0026#34;) public class LibraryController { private static final Logger log = LoggerFactory.getLogger(LibraryController.class); private final LibraryService libraryService; public LibraryController(LibraryService libraryService) { this.libraryService = libraryService; } @CrossOrigin(origins = \u0026#34;http://localhost:4200\u0026#34;, allowedHeaders = {\u0026#34;Requestor-Type\u0026#34;, \u0026#34;Authorization\u0026#34;}, exposedHeaders = \u0026#34;X-Get-Header\u0026#34;) @GetMapping public ResponseEntity\u0026lt;List\u0026lt;BookDto\u0026gt;\u0026gt; getBooks(@RequestParam String type) { HttpHeaders headers = new HttpHeaders(); headers.set(\u0026#34;X-Get-Header\u0026#34;, \u0026#34;ExampleHeader\u0026#34;); return ResponseEntity.ok().headers(headers).body(libraryService.getAllBooks(type)); } } 或者，我们可以创建一个 CorsConfigurationSource bean：\n@Bean CorsConfigurationSource corsConfigurationSource() { CorsConfiguration configuration = new CorsConfiguration(); configuration.setAllowedOrigins(Arrays.asList(\u0026#34;http://localhost:4200\u0026#34;)); configuration.setAllowedMethods(Arrays.asList(\u0026#34;GET\u0026#34;,\u0026#34;POST\u0026#34;,\u0026#34;PATCH\u0026#34;, \u0026#34;PUT\u0026#34;, \u0026#34;DELETE\u0026#34;, \u0026#34;OPTIONS\u0026#34;, \u0026#34;HEAD\u0026#34;)); configuration.setAllowCredentials(true); configuration.setAllowedHeaders(Arrays.asList(\u0026#34;Authorization\u0026#34;, \u0026#34;Requestor-Type\u0026#34;)); configuration.setExposedHeaders(Arrays.asList(\u0026#34;X-Get-Header\u0026#34;)); configuration.setMaxAge(3600L); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, configuration); return source; } Spring Security 应用于 Spring Webflux 对于 Webflux，尽管使用 Spring Security，将 CORS 配置应用于传入请求的最首选方法是使用 CorsWebFilter 。我们可以禁用 CORS 与 Spring security 的集成，而是通过提供 CorsConfigurationSource 与 CorsWebFilter 集成：\n@Configuration @EnableWebFluxSecurity @EnableConfigurationProperties(BasicAuthConfigProperties.class) public class SecurityConfiguration { private final BasicAuthConfigProperties basicAuth; public SecurityConfiguration(BasicAuthConfigProperties basicAuth) { this.basicAuth = basicAuth; } @Bean public SecurityWebFilterChain securityWebFilterChain(ServerHttpSecurity http) { http.cors(cors -\u0026gt; cors.disable()) .securityMatcher(new PathPatternParserServerWebExchangeMatcher(\u0026#34;/**\u0026#34;)) .authorizeExchange() .anyExchange().authenticated().and() .httpBasic(); return http.build(); } @Bean public MapReactiveUserDetailsService userDetailsService() { UserDetails user = User.withDefaultPasswordEncoder() .username(basicAuth.getUsername()) .password(basicAuth.getPassword()) .roles(\u0026#34;USER\u0026#34;) .build(); return new MapReactiveUserDetailsService(user); } @Bean public CorsConfigurationSource corsConfiguration() { CorsConfiguration corsConfig = new CorsConfiguration(); corsConfig.applyPermitDefaultValues(); corsConfig.setAllowCredentials(true); corsConfig.addAllowedMethod(\u0026#34;GET\u0026#34;); corsConfig.addAllowedMethod(\u0026#34;PATCH\u0026#34;); corsConfig.addAllowedMethod(\u0026#34;POST\u0026#34;); corsConfig.addAllowedMethod(\u0026#34;OPTIONS\u0026#34;); corsConfig.setAllowedOrigins(Arrays.asList(\u0026#34;http://localhost:4200\u0026#34;)); corsConfig.setAllowedHeaders(Arrays.asList(\u0026#34;Authorization\u0026#34;, \u0026#34;Requestor-Type\u0026#34;)); corsConfig.setExposedHeaders(Arrays.asList(\u0026#34;X-Get-Header\u0026#34;)); UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(\u0026#34;/**\u0026#34;, corsConfig); return source; } @Bean public CorsWebFilter corsWebFilter() { return new CorsWebFilter(corsConfiguration()); } } 结论 简而言之，CORS 配置取决于多个因素：\nSpring Web / Spring Webflux 本地/全局 CORS 配置 是否使用 Spring Security 根据框架，我们可以决定哪种方法效果最好并且最容易实现，这样我们就可以避免 CORS 错误。您可以使用 GitHub 上的示例应用程序。\n原文链接：https://reflectoring.io/spring-cors/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/spring-cors/","summary":"跨源资源共享 (CORS) 是一种基于 HTTP 标头的机制，允许服务器显式将某些源列入白名单，并帮助绕过同源策略。\n这是必需的，因为浏览器默认应用同源策略以确保安全。通过在 Web 应用程序中实施 CORS，网页可以请求额外的资源并从其他域加载到浏览器中。\n本文将重点介绍在基于 Spring 的应用程序中实现 CORS 的各种方式。要详细了解 CORS 的工作原理，请参阅这篇优秀的介绍性文章。\n示例代码 本文附有 GitHub 上的工作代码示例。\nCORS 特定 HTTP 响应标头概述 CORS 规范定义了服务器返回的一组响应标头，这将是后续部分的重点。\n响应头 描述 Access-Control-Allow-Origin 以逗号分隔的白名单来源列表或“*”。 Access-Control-Allow-Methods Web 服务器允许跨源请求的 HTTP 方法的逗号分隔列表。 Access-Control-Allow-Headers Web 服务器允许跨源请求的 HTTP 标头的逗号分隔列表。 Access-Control-Expose-Headers 客户端脚本认为可以安全显示的以逗号分隔的 HTTP 标头列表。 Access-Control-Allow-Credentials 如果浏览器通过传递凭据（以 cookie 或授权标头的形式）向服务器发出请求，则其值设置为 true 。 Access-Control-Max-Age 指示预检请求的结果可以缓存多长时间。 设置示例客户端应用程序 我们将使用一个简单的角度应用程序来调用 REST 端点，我们可以使用浏览器开发人员工具检查这些端点。您可以在 GitHub 上查看源代码。\nng serve --open 我们应该能够成功启动客户端应用程序。\n设置示例服务器应用程序 我们将使用一个基于 Spring 的示例应用程序，其中包含客户端应用程序可以调用的 GET 和 POST 请求。请注意，您会发现两个独立的应用程序：一个使用 Spring MVC (REST)，另一个使用 Spring Reactive 堆栈。\n为简单起见，两个应用程序之间的 CORS 配置相同，并且定义了相同的端点。两台服务器都从不同的端口 8091 和 8092 启动。\n与应用程序捆绑在一起的 Maven Wrapper 将用于启动服务。您可以查看 Spring REST 源代码和 Spring Reactive 源代码。\nmvnw clean verify spring-boot:run (for Windows) ./mvnw clean verify spring-boot:run (for Linux) 一旦 Spring 应用程序成功启动，客户端应用程序应该能够成功从服务器加载数据。","title":"[译]使用 Spring Boot 和 Spring Security 配置 CORS"},{"content":"在分布式、快节奏的环境中，开发团队通常希望了解他们部署应用程序的时间、部署的应用程序版本、部署的 Git 提交等等。\nSpring Boot Actuator 帮助我们监控和管理应用程序。它公开了提供应用程序运行状况、指标和其他相关信息的各种端点。\n在本文中，我们将了解如何使用 Spring Boot Actuator 和 Maven/Gradle 构建插件将此类信息添加到我们的项目中。\n示例代码 本文附有 GitHub 上的工作代码示例。\n启用 Spring Boot 执行器 Spring Boot Actuator 是 Spring Boot 的一个子项目。在本节中，我们将快速了解如何引导示例项目并启用 /info 端点。如果您想了解更多有关 Spring Boot Actuator 的信息，已经有一个很棒的教程了。\n让我们使用 Spring Initializr 快速创建一个 Spring Boot 项目。我们将需要以下依赖项：\n依赖性 目的 Spring Boot Actuator 公开应用程序管理端点，例如 info 。 Spring Web 启用 Web 应用程序行为。 如果有帮助，这里是 Maven 和 Gradle 中预填充项目的链接。\n项目构建后，我们将通过 HTTP 公开内置的 /info 端点。默认情况下， /info Web 端点处于禁用状态。我们可以通过在 application.properties 配置中添加 management.endpoints.web.exposure.include 属性来简单地启用它：\nmanagement.endpoints.web.exposure.include=health,info 让我们运行 Spring Boot 应用程序并在浏览器中打开 URL http://localhost:8080/actuator/info 。目前还看不到任何有用的东西，因为我们仍然需要进行一些配置更改。在下一节中，我们将了解如何在此响应中添加信息丰富的构建信息。\n保护端点 如果您公开公开端点，请确保适当保护它们。我们不应在不知情的情况下泄露任何敏感信息。\nSpring Boot 应用程序信息 Spring 从应用程序上下文中定义的各种 InfoContributor bean 收集有用的应用程序信息。下面是默认 InfoContributor beans 的摘要：\nID Bean Name 用法 build BuildInfoContributor 公开构建信息。 env EnvironmentInfoContributor 公开 Environment 中名称以 info. 开头的任何属性 git GitInfoContributor 公开 Git 相关信息。 java JavaInfoContributor 公开 Java 运行时信息。 默认情况下， env 和 java 贡献者被禁用。\n首先，我们将通过在 application.properties 中添加以下键值对来启用 java 贡献者：\nmanagement.info.java.enabled=true 让我们重新运行该应用程序。如果我们在浏览器中再次打开执行器 /info 端点，我们会得到如下输出：\n{ \u0026#34;java\u0026#34;: { \u0026#34;vendor\u0026#34;: \u0026#34;Eclipse Adoptium\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;11.0.14\u0026#34;, \u0026#34;runtime\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;OpenJDK Runtime Environment\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;11.0.14+9\u0026#34; }, \u0026#34;jvm\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;OpenJDK 64-Bit Server VM\u0026#34;, \u0026#34;vendor\u0026#34;: \u0026#34;Eclipse Adoptium\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;11.0.14+9\u0026#34; } } } 根据安装的 Java 版本，您可能会看到不同的值。\n现在，是时候显示环境变量了。 Spring 会选取属性名称以 info 开头的任何环境变量。要查看实际效果，让我们在 application.properties 文件中添加以下属性：\nmanagement.info.env.enabled=true info.app.website=reflectoring.io 重新启动应用程序后，我们将开始看到添加到执行器 info 端点的以下信息：\n{ \u0026#34;app\u0026#34;: { \u0026#34;website\u0026#34;: \u0026#34;reflectoring.io\u0026#34; } } 请随意添加您想要的任意数量的信息变量:)\n在以下部分中，我们将了解如何添加 Git 和应用程序构建特定信息。\n添加构建信息 添加有用的构建信息有助于快速识别构建工件名称、版本、创建时间等。它可以方便地检查团队是否部署了应用程序的相关版本。 Spring Boot 允许使用 Maven 或 Gradle 构建插件轻松添加此内容。\n使用 Maven 插件 Spring Boot Maven 插件捆绑了许多有用的功能，例如创建可执行 jar 或 war 存档、运行应用程序等。它还提供了一种添加应用程序构建信息的方法。\n如果存在有效的 META-INF/build-info.properties 文件，Spring Boot Actuator 将显示构建详细信息。 Spring Boot Maven 插件的 build-info 目标是创建此文件。\n如果您使用 Spring Initializr 引导项目，则默认情况下该插件将出现在 pom.xml 中。我们只需添加 build-info 执行目标，如下所示：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.4\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;build-info\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 如果我们现在运行命令 ./mvnw spring-boot:run （对于 Linux/macOS）或 mvnw.bat spring-boot:run （对于 Windows），所需的文件将在 target/classes/META-INF/build-info.properties 中创建。\n文件内容将与此类似：\nbuild.artifact=spring-boot-build-info build.group=io.reflectoring build.name=spring-boot-build-info build.time=2022-03-06T05\\:53\\:45.236Z build.version=0.0.1-SNAPSHOT 我们还可以使用 additionalProperties 属性将自定义属性添加到此列表：\n\u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;build-info\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;additionalProperties\u0026gt; \u0026lt;custom.key1\u0026gt;value1\u0026lt;/custom.key1\u0026gt; \u0026lt;custom.key2\u0026gt;value2\u0026lt;/custom.key2\u0026gt; \u0026lt;/additionalProperties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; 如果我们现在运行应用程序并在浏览器中打开 http://localhost:8080/actuator/info 端点，我们将看到类似于以下内容的响应：\n{ \u0026#34;build\u0026#34;: { \u0026#34;custom\u0026#34;: { \u0026#34;key2\u0026#34;: \u0026#34;value2\u0026#34;, \u0026#34;key1\u0026#34;: \u0026#34;value1\u0026#34; }, \u0026#34;version\u0026#34;: \u0026#34;0.0.1-SNAPSHOT\u0026#34;, \u0026#34;artifact\u0026#34;: \u0026#34;spring-boot-build-info\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;spring-boot-build-info\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-03-06T06:34:30.306Z\u0026#34;, \u0026#34;group\u0026#34;: \u0026#34;io.reflectoring\u0026#34; } } 如果您想排除任何可以使用 excludeInfoProperties 配置的属性。让我们看看如何排除 artifact 属性：\n\u0026lt;configuration\u0026gt; \u0026lt;excludeInfoProperties\u0026gt; \u0026lt;infoProperty\u0026gt;artifact\u0026lt;/infoProperty\u0026gt; \u0026lt;/excludeInfoProperties\u0026gt; \u0026lt;/configuration\u0026gt; 请参阅 Spring Boot 官方文档了解更多信息。\n现在，是时候看看我们如何使用 Spring Boot Gradle 插件实现相同的输出了。\n使用 Gradle 插件 添加构建信息的最简单方法是使用插件 DSL。在 build.gradle 文件中，我们需要添加以下块：\nspringBoot { buildInfo() } 如果我们现在同步 Gradle 项目，我们可以看到一个新任务 bootBuildInfo 可供使用。运行该任务将生成带有构建信息的类似 build/resources/main/META-INF/build-info.properties 文件（源自项目）。使用 DSL，我们可以自定义现有值或添加新属性：\nspringBoot { buildInfo { properties { name = \u0026#39;Sample App\u0026#39; additional = [ \u0026#39;customKey\u0026#39;: \u0026#39;customValue\u0026#39; ] } } } 是时候使用 ./gradlew bootRun （对于 macOS/Linux）或 gradlew.bat bootRun （对于 Windows）命令运行应用程序了。应用程序运行后，我们可以在浏览器中打开 http://localhost:8080/actuator/info 端点并找到响应：\n{ \u0026#34;build\u0026#34;: { \u0026#34;customKey\u0026#34;: \u0026#34;customValue\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1-SNAPSHOT\u0026#34;, \u0026#34;artifact\u0026#34;: \u0026#34;spring-boot-build-info\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Sample App\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-03-06T09:11:53.380Z\u0026#34;, \u0026#34;group\u0026#34;: \u0026#34;io.reflectoring\u0026#34; } } 我们可以通过将其值设置为 null 来从生成的构建信息中排除任何默认属性。例如：\nproperties { group = null } 想了解更多关于该插件的信息，可以参考 Spring Boot 官方文档。\n添加 Git 信息 Git 信息可以方便地快速识别生产中是否存在相关代码或者分布式部署是否与预期同步。 Spring Boot 可以使用 Maven 和 Gradle 插件轻松地将 Git 属性包含在 Actuator 端点中。\n使用这个插件我们可以生成一个 git.properties 文件。此文件的存在将自动配置 GitProperties bean，供 GitInfoContributor bean 使用来整理相关信息。\n默认情况下，将公开以下信息：\ngit.branch git.commit.id git.commit.time 以下管理应用程序属性控制 Git 相关信息：\n应用属性 目的 management.info.git.enabled=false 完全从 info 端点禁用 Git 信息 management.info.git.mode=full 显示 git.properties 文件中的所有属性 使用 Maven 插件 Maven Git Commit ID 插件通过 spring-boot-starter-parent pom.xml 进行管理。要使用它，我们必须编辑 pom.xml 如下：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;pl.project13.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;git-commit-id-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; 如果我们运行该项目并在浏览器中打开 /actuator/info 端点，它将返回 Git 相关信息：\n{ \u0026#34;git\u0026#34;: { \u0026#34;branch\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;commit\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5404bdf\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-03-06T10:34:16Z\u0026#34; } } } 我们还可以检查 target/classes/git.properties 下生成的文件。这对我来说是这样的：\n#Generated by Git-Commit-Id-Plugin git.branch=main git.build.host=mylaptop git.build.time=2022-03-06T23\\:22\\:16+0530 git.build.user.email=user@email.com git.build.user.name=user git.build.version=0.0.1-SNAPSHOT git.closest.tag.commit.count= git.closest.tag.name= git.commit.author.time=2022-03-06T22\\:46\\:56+0530 git.commit.committer.time=2022-03-06T22\\:46\\:56+0530 git.commit.id=e9fa20d4914367c1632e3a0eb8ca4d2f32b31a89 git.commit.id.abbrev=e9fa20d git.commit.id.describe=e9fa20d-dirty git.commit.id.describe-short=e9fa20d-dirty git.commit.message.full=Update config git.commit.message.short=Update config git.commit.time=2022-03-06T22\\:46\\:56+0530 git.commit.user.email=saikat@email.com git.commit.user.name=Saikat git.dirty=true git.local.branch.ahead=NO_REMOTE git.local.branch.behind=NO_REMOTE git.remote.origin.url=Unknown git.tags= git.total.commit.count=2 这个插件带有很多配置选项。例如，要包含/排除特定属性，我们可以添加 configuration 部分，如下所示：\n\u0026lt;configuration\u0026gt; \u0026lt;excludeProperties\u0026gt; \u0026lt;excludeProperty\u0026gt;time\u0026lt;/excludeProperty\u0026gt; \u0026lt;/excludeProperties\u0026gt; \u0026lt;includeOnlyProperties\u0026gt; \u0026lt;property\u0026gt;git.commit.id\u0026lt;/property\u0026gt; \u0026lt;/includeOnlyProperties\u0026gt; \u0026lt;/configuration\u0026gt; 它将生成如下输出：\n{ \u0026#34;git\u0026#34;: { \u0026#34;commit\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5404bdf\u0026#34; } } } 译者备注：\n使用 4.9.10 版本时，如果想指定输出内容，需要这样设置：\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;pl.project13.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;git-commit-id-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.9.10\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;revision\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;generateGitPropertiesFile\u0026gt;true\u0026lt;/generateGitPropertiesFile\u0026gt; \u0026lt;dateFormat\u0026gt;yyyy-MM-dd HH:mm:ss\u0026lt;/dateFormat\u0026gt; \u0026lt;dateFormatTimeZone\u0026gt;GMT+8\u0026lt;/dateFormatTimeZone\u0026gt; \u0026lt;includeOnlyProperties\u0026gt;git.branch,git.build.time,git.build.version,git.commit.id,git.commit.time,git.commit.message.full\u0026lt;/includeOnlyProperties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 现在让我们看看 Gradle 用户可以使用哪些选项。\n使用 Gradle 插件 在 build.gradle 中，我们将添加 gradle-git-properties 插件：\nplugins { id \u0026#39;com.gorylenko.gradle-git-properties\u0026#39; version \u0026#39;2.4.0\u0026#39; } 现在让我们构建 Gradle 项目。我们可以看到 build/resources/main/git.properties 文件已创建。并且，执行器 info 端点将显示相同的数据：\n{ \u0026#34;git\u0026#34;: { \u0026#34;branch\u0026#34;: \u0026#34;main\u0026#34;, \u0026#34;commit\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5404bdf\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2022-03-06T10:34:16Z\u0026#34; } } } 该插件也提供了多种使用属性 gitProperties 配置输出的方法。例如，我们通过添加以下内容来限制要出现的键：\ngitProperties { keys = [\u0026#39;git.commit.id\u0026#39;] } 重新运行应用程序现在将显示有限的 Git 信息：\n{ \u0026#34;git\u0026#34;: { \u0026#34;commit\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5404bdf\u0026#34; } } } 结论 在本文中，我们学习了如何使用 Spring Actuator 来公开有关我们应用程序的相关信息。我们了解了如何将有关构建、环境、Git 和 Java 环境的信息添加到 Actuator /info 端点。我们还研究了如何通过 Maven/Gradle 构建插件配置和控制所有这些信息。\n您可以使用 GitHub 上的代码来尝试一个完整的应用程序来说明这些想法。\n原文链接：https://reflectoring.io/spring-boot-info-endpoint/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/spring-boot-info-endpoint/","summary":"在分布式、快节奏的环境中，开发团队通常希望了解他们部署应用程序的时间、部署的应用程序版本、部署的 Git 提交等等。\nSpring Boot Actuator 帮助我们监控和管理应用程序。它公开了提供应用程序运行状况、指标和其他相关信息的各种端点。\n在本文中，我们将了解如何使用 Spring Boot Actuator 和 Maven/Gradle 构建插件将此类信息添加到我们的项目中。\n示例代码 本文附有 GitHub 上的工作代码示例。\n启用 Spring Boot 执行器 Spring Boot Actuator 是 Spring Boot 的一个子项目。在本节中，我们将快速了解如何引导示例项目并启用 /info 端点。如果您想了解更多有关 Spring Boot Actuator 的信息，已经有一个很棒的教程了。\n让我们使用 Spring Initializr 快速创建一个 Spring Boot 项目。我们将需要以下依赖项：\n依赖性 目的 Spring Boot Actuator 公开应用程序管理端点，例如 info 。 Spring Web 启用 Web 应用程序行为。 如果有帮助，这里是 Maven 和 Gradle 中预填充项目的链接。\n项目构建后，我们将通过 HTTP 公开内置的 /info 端点。默认情况下， /info Web 端点处于禁用状态。我们可以通过在 application.properties 配置中添加 management.endpoints.web.exposure.include 属性来简单地启用它：\nmanagement.endpoints.web.exposure.include=health,info 让我们运行 Spring Boot 应用程序并在浏览器中打开 URL http://localhost:8080/actuator/info 。目前还看不到任何有用的东西，因为我们仍然需要进行一些配置更改。在下一节中，我们将了解如何在此响应中添加信息丰富的构建信息。\n保护端点 如果您公开公开端点，请确保适当保护它们。我们不应在不知情的情况下泄露任何敏感信息。\nSpring Boot 应用程序信息 Spring 从应用程序上下文中定义的各种 InfoContributor bean 收集有用的应用程序信息。下面是默认 InfoContributor beans 的摘要：\nID Bean Name 用法 build BuildInfoContributor 公开构建信息。 env EnvironmentInfoContributor 公开 Environment 中名称以 info.","title":"[译]使用Spring Boot Actuator公开有用的信息端点"},{"content":"我们在上一篇文章中了解了基本的 OAuth2 概念以及如何在 Spring 中实现和执行不同的授权。在这篇文章中，我们将介绍 OAuth2 的另一个重要概念：范围。\nOAuth 范围 保护对应用程序的访问通常分两个步骤进行：身份验证和授权。要理解这两个概念，假设您在绝密政府大楼工作。在开始之前，你会得到一张卡片，可以让你进入建筑物。 OAuth 令牌可以看作是允许您访问的卡片。\n一旦你进去，你决定去三楼见你的一位同事，在尝试使用你的卡打开三楼的门后，你听到一声嘟嘟声，告诉你你没有被授权。在 OAuth 中，范围是一种定义令牌可以访问哪些资源以及不能访问哪些资源的方法。范围允许访问控制，并且可以被视为相当于传统身份验证中的用户角色。\n实现 为了演示范围，我们将使用第 1 部分中的示例。\n在资源服务器的控制器中，我们有以下端点：\n@RestController(\u0026#34;/\u0026#34;) public class ResourceController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @PostMapping(\u0026#34;/bar\u0026#34;) public String bar(){ return \u0026#34;bar\u0026#34;; } @DeleteMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;test\u0026#34;; } } 第一步是使用所需的范围配置授权服务器：\nclients.inMemory().withClient(\u0026#34;my-trusted-client\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;, \u0026#34;refresh_token\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;client_credentials\u0026#34;, \u0026#34;authorization_code\u0026#34;) .authorities(\u0026#34;CLIENT\u0026#34;) .scopes(\u0026#34;read\u0026#34;, \u0026#34;write\u0026#34;, \u0026#34;trust\u0026#34;) .accessTokenValiditySeconds(60) .redirectUris(\u0026#34;http://localhost:8081/test.html\u0026#34;) .resourceIds(\u0026#34;resource\u0026#34;) .secret(\u0026#34;mysecret\u0026#34;); 要在资源服务器中启用范围检查，我们有两个选项：使用安全配置或使用方法安全性。\n使用安全配置： @Override public void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(HttpMethod.GET,\u0026#34;/hello\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.GET,\u0026#34;/foo\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.POST,\u0026#34;/bar\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.DELETE,\u0026#34;/test\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;trust\u0026#39;)\u0026#34;) .anyRequest().authenticated(). and().csrf().disable(); } 使用方法安全性： @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) @PostMapping(\u0026#34;/bar\u0026#34;) public String bar(){ return \u0026#34;bar\u0026#34;; } @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;trust\u0026#39;)\u0026#34;) @DeleteMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;test\u0026#34;; } 另外，我们需要将 @EnableGlobalMethodSecurity(prePostEnabled = true) 添加到 Spring 可以获取的任何类（ @Configuration 、 @Service 等）。在我们的示例中，我们已将其添加到 ResourceSecurityConfiguration 类中。 prePostEnabled = true 告诉 Spring 启用前注解和后注解，例如 @PreAuthorize 、 @PostFilter 等\u0026hellip;\u0026hellip;\n对于那些想了解 #oauth2.hasScope('trust') 这样的表达式的人来说，它们是使用 Spring 表达式语言（SpEL）构建的。\n行动范围 默认情况下，如果令牌请求中不存在范围，Spring 会假定令牌具有所有配置的范围。让我们首先请求一个具有 read 范围的令牌：\ncurl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;grant_type=client_credentials\u0026amp;client_id=my-trusted-client\u0026amp;scope=read\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;acadbb31-f126-411d-ae5b-6a278cee2ed6\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 60, \u0026#34;scope\u0026#34;: \u0026#34;read\u0026#34; } 现在，我们可以使用令牌来访问具有 read 范围访问权限的端点：\ncurl -XGET localhost:8989/hello -H \u0026#34;Authorization: Bearer acadbb31-f126-411d-ae5b-6a278cee2ed6\u0026#34; hello curl -XGET localhost:8989/foo -H \u0026#34;Authorization: Bearer acadbb31-f126-411d-ae5b-6a278cee2ed6\u0026#34; foo 现在，让我们尝试在仅接受 write 范围的端点上使用此令牌：\ncurl -XPOST localhost:8989/bar -H \u0026#34;Authorization: Bearer acadbb31-f126-411d-ae5b-6a278cee2ed6\u0026#34; 回复：\n{ \u0026#34;error\u0026#34;: \u0026#34;access_denied\u0026#34;, \u0026#34;error_description\u0026#34;: \u0026#34;Access is denied\u0026#34; } 由于令牌不具有所需的范围，因此访问被拒绝。让我们尝试获取一个具有 write 范围的新令牌，然后重试：\ncurl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;grant_type=client_credentials\u0026amp;client_id=my-trusted-client\u0026amp;scope=write\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;bf0fa83a-23bd-4633-ac6c-a06f40d53e5f\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 3599, \u0026#34;scope\u0026#34;: \u0026#34;write\u0026#34; } curl -XPOST localhost:8989/bar -H \u0026#34;Authorization: Bearer bf0fa83a-23bd-4633-ac6c-a06f40d53e5f\u0026#34; bar 总结 范围是 OAuth 的一个重要方面，因为令牌不携带有关其用户或请求者的信息。范围允许限制对资源的访问，以实现更好的访问控制和安全性。在下一篇文章中，我们将了解如何将 Google 和 Facebook 等外部 OAuth 提供商集成到流程中。\n原文链接：http://www.zakariaamine.com/2018-03-01/using-oauth2-in-spring-scopes/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/using-oauth2-in-spring-scopes/","summary":"我们在上一篇文章中了解了基本的 OAuth2 概念以及如何在 Spring 中实现和执行不同的授权。在这篇文章中，我们将介绍 OAuth2 的另一个重要概念：范围。\nOAuth 范围 保护对应用程序的访问通常分两个步骤进行：身份验证和授权。要理解这两个概念，假设您在绝密政府大楼工作。在开始之前，你会得到一张卡片，可以让你进入建筑物。 OAuth 令牌可以看作是允许您访问的卡片。\n一旦你进去，你决定去三楼见你的一位同事，在尝试使用你的卡打开三楼的门后，你听到一声嘟嘟声，告诉你你没有被授权。在 OAuth 中，范围是一种定义令牌可以访问哪些资源以及不能访问哪些资源的方法。范围允许访问控制，并且可以被视为相当于传统身份验证中的用户角色。\n实现 为了演示范围，我们将使用第 1 部分中的示例。\n在资源服务器的控制器中，我们有以下端点：\n@RestController(\u0026#34;/\u0026#34;) public class ResourceController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @PostMapping(\u0026#34;/bar\u0026#34;) public String bar(){ return \u0026#34;bar\u0026#34;; } @DeleteMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;test\u0026#34;; } } 第一步是使用所需的范围配置授权服务器：\nclients.inMemory().withClient(\u0026#34;my-trusted-client\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;, \u0026#34;refresh_token\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;client_credentials\u0026#34;, \u0026#34;authorization_code\u0026#34;) .authorities(\u0026#34;CLIENT\u0026#34;) .scopes(\u0026#34;read\u0026#34;, \u0026#34;write\u0026#34;, \u0026#34;trust\u0026#34;) .accessTokenValiditySeconds(60) .redirectUris(\u0026#34;http://localhost:8081/test.html\u0026#34;) .resourceIds(\u0026#34;resource\u0026#34;) .secret(\u0026#34;mysecret\u0026#34;); 要在资源服务器中启用范围检查，我们有两个选项：使用安全配置或使用方法安全性。\n使用安全配置： @Override public void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(HttpMethod.GET,\u0026#34;/hello\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.GET,\u0026#34;/foo\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.POST,\u0026#34;/bar\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.DELETE,\u0026#34;/test\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;trust\u0026#39;)\u0026#34;) .anyRequest().authenticated(). and().csrf().disable(); } 使用方法安全性： @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @PreAuthorize(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @PreAuthorize(\u0026#34;#oauth2.","title":"[译]在 Spring 中实现 OAuth2：使用范围（第 2 部分）"},{"content":"OAuth2 是一组规范，主要提供对 Rest API 的安全访问的方法。 OAuth 的主要目的是允许通过使用令牌来执行身份验证和授权，而不必为每个操作提供凭据。由于本文的重点是实现，并且为了不重新发明轮子，可以查看 OAuth RFC 或维基百科以获取更多理论背景。在这篇文章中，我们将深入探讨 Spring 中的 OAuth2 实现以及如何使用不同的授权类型，但在此之前值得提供一些重要概念的简要定义。\n访问令牌和刷新令牌 身份验证成功后将提供访问令牌以及刷新令牌。访问令牌有一个有限的有效期（标准为 1 小时），之后需要刷新令牌才能获取新的访问令牌和新的刷新令牌。 Referesh 令牌通常会在使用后过期。\n资源服务器和授权服务器 OAuth 引入了授权服务器的概念，授权服务器是发出访问和刷新令牌的实体，并在每个操作中进行咨询以查看令牌是否有效。资源服务器只是由不同客户端应用程序（前端应用程序、移动设备、其他后端服务\u0026hellip;\u0026hellip;）访问的实际 Rest API。资源服务器和授权服务器可以是不同的实体，也可以是同一实体。\n授权类型 OAuth 中最常用的授权有：客户端凭据、密码、授权码和隐式授权。每项资助都有特定的流程和用例，但由于本文的重点不是理论，因此我们将重点关注其实施。有关授权及其用途的更多详细信息，请参阅 OAuth RFC。\n实现 在实现方面，我们将使用 Spring Boot 来利用其自动配置和引导功能，并更多地关注我们的核心主题。\n资源服务器： 我们有一个资源服务器，其中包含我们希望保护的以下端点：\n@RestController(\u0026#34;/\u0026#34;) public class ResourceController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @GetMapping(\u0026#34;/bar\u0026#34;) public String bar(){ return \u0026#34;bar\u0026#34;; } @GetMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;test\u0026#34;; } } 为此，我们需要配置一个用 @EnableResourceServer 注释的 ResourceServerConfigurerAdapter bean：\n@Configuration @EnableResourceServer public class ResourceSecurityConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources.resourceId(\u0026#34;resource\u0026#34;); } @Override public void configure(HttpSecurity http) throws Exception { http .authorizeRequests().antMatchers(\u0026#34;/foo\u0026#34;, \u0026#34;/bar\u0026#34;, \u0026#34;/hello\u0026#34;, \u0026#34;/test\u0026#34;).authenticated(). and().csrf().disable(); } @Bean public RemoteTokenServices LocalTokenService() { final RemoteTokenServices tokenService = new RemoteTokenServices(); tokenService.setCheckTokenEndpointUrl(\u0026#34;http://localhost:8081/oauth/check_token\u0026#34;); tokenService.setClientId(\u0026#34;my-client\u0026#34;); tokenService.setClientSecret(\u0026#34;mysecret\u0026#34;); return tokenService; } } 我们已经告诉 spring 检查端点的身份验证（可以使用 \u0026quot;/*\u0026quot; 或 .anyRequest() 来表示所有端点）。此外，我们还配置了一个 RemoteTokenServices bean 来告诉 Spring 提供令牌检查端点（授权服务器），并配置了客户端 id 和密钥。这样我们的资源服务器就配置好了。最后，我们设置了资源 id，如果多个资源服务器使用该资源（这很常见），则该资源 id 可以在授权服务器中用作标识。\n授权服务器： 为了实现授权服务器，我们将使用内存客户端配置。 Spring Security 还提供了将 oauth 客户端配置存储在更适合生产应用程序的数据库中的可能性。\n@Configuration @EnableAuthorizationServer public class AuthorizationSecurityConfig extends AuthorizationServerConfigurerAdapter { @Autowired private AuthenticationManager authenticationManager; @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints.authenticationManager(authenticationManager); } @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.inMemory().withClient(\u0026#34;my-trusted-client\u0026#34;) .authorizedGrantTypes(\u0026#34;password\u0026#34;, \u0026#34;refresh_token\u0026#34;, \u0026#34;implicit\u0026#34;, \u0026#34;client_credentials\u0026#34;, \u0026#34;authorization_code\u0026#34;) .authorities(\u0026#34;ROLE_CLIENT\u0026#34;, \u0026#34;ROLE_TRUSTED_CLIENT\u0026#34;) .scopes(\u0026#34;read\u0026#34;, \u0026#34;write\u0026#34;, \u0026#34;trust\u0026#34;) .accessTokenValiditySeconds(60) .redirectUris(\u0026#34;http://localhost:8081/test.html\u0026#34;) .resourceIds(\u0026#34;resource\u0026#34;) .secret(\u0026#34;mysecret\u0026#34;); } @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) throws Exception { oauthServer .tokenKeyAccess(\u0026#34;permitAll()\u0026#34;) .checkTokenAccess(\u0026#34;permitAll()\u0026#34;); } } 除了我们在其中配置客户端、密钥、oauth 范围（下一篇文章中将详细介绍）、权限（与令牌关联的角色）、令牌有效性、资源 id 之外，我们还配置了对 Spring Boot 在 /oauth/check_token 处提供的检查令牌端点的访问，以及对也自动映射在 /oauth/token 处的令牌发行端点的访问。\nOAuth 的实际应用 我们已将授权服务器配置为在端口 8081 上运行，将资源服务器配置为在端口 8989 上运行。对于下面的所有示例，都使用 curl ，但客户端可以是任何应用程序。\n我们首先尝试访问资源服务器中的一个端点：\ncurl localhost:8989/foo { \u0026#34;error\u0026#34;: \u0026#34;unauthorized\u0026#34;, \u0026#34;error_description\u0026#34;: \u0026#34;Full authentication is required to access this resource\u0026#34; } 让我们获取一个令牌并重试。\n客户凭证授予： curl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;grant_type=client_credentials\u0026amp;client_id=my-trusted-client\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;3670fea1-eab3-4981-b80a-e5c57203b20e\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 51, \u0026#34;scope\u0026#34;: \u0026#34;read write trust\u0026#34; } 我们现在可以使用令牌来访问受保护的端点：\ncurl -v localhost:8989/foo -H \u0026#34;Authorization: Bearer 6bb86f18-e69e-4c2b-8fbf-85d7d5b800a4\u0026#34; foo 客户端凭据授予不支持刷新令牌。\n密码授予： 就获取令牌的流程而言，密码授予与客户端凭据类似，只是它使用实际的用户凭据。它还意味着需要为应用程序配置用户。 Web 安全配置如下：\n@Configuration @EnableWebSecurity public class WebSecurity extends WebSecurityConfigurerAdapter { @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.inMemoryAuthentication().withUser(\u0026#34;gwidgets\u0026#34;).password(\u0026#34;gwidgets\u0026#34;).authorities(\u0026#34;CLIENT\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests().anyRequest().authenticated().and().formLogin().defaultSuccessUrl(\u0026#34;/test.html\u0026#34;).and().csrf().disable(); } } 然后我们可以使用用户凭据来获取令牌，如下所示：\ncurl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;grant_type=password\u0026amp;username=gwidgets\u0026amp;password=gwidgets\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;3670fea1-eab3-4981-b80a-e5c57203b20e\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;expires_in\u0026#34;: 51, \u0026#34;scope\u0026#34;: \u0026#34;read write trust\u0026#34; } 密码授予不支持刷新令牌。\n隐式授予： 隐式授权最适合前端路由应用程序。隐式授权需要基本身份验证和 HTTP 会话。为了执行隐式授权，我们将向授权服务器添加一个简单的 http 页面（它可以位于不同的服务器上）：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;we are here\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 要执行隐式授予，我们需要在浏览器中导航到以下地址：http://localhost:8081/oauth/authorize?response_type=token\u0026amp;client_id=my-trusted-client\u0026amp;redirect-uri=http://localhost:8081/test.html\n登录后，我们得到一个 OAuth 审批页面（spring 默认提供，但可以自定义）：\n批准令牌的范围后，我们最终会重定向到我们的页面，在该页面中我们在 url 的哈希中找到令牌：\n授权码授予： 对于授权码授予，我们需要首先以与隐式流程相同的方式进行授权，只不过 response_type 现在是 code 。为此，我们需要导航到：http://localhost:8081/oauth/authorize?response_type=code\u0026amp;client_id=my-trusted-client\u0026amp;redirect-uri=http://localhost:8081/test.html\n然后我们被重定向到登录，登录后，我们被重定向到 OAuth 范围批准，如上一节中的隐式流程。之后，我们被重定向到以下地址：http://localhost:8081/test.html?code=bD0mVb，这是我们应用程序的欢迎页面，但带有一个特殊的查询参数： code 。我们将使用 curl 来获取令牌以进行演示，但也可以使用 JavaScript 在页面中完成此操作：\ncurl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;grant_type=authorization_code\u0026amp;code=bD0mVb\u0026amp;redirect_uri=http://localhost:8081/test.html\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;0abe701b-0f5a-4d25-81df-f2c4db2af555\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;cf6aa9db-3757-465e-af68-b7d59d1f0b77\u0026#34;, \u0026#34;expires_in\u0026#34;: 59, \u0026#34;scope\u0026#34;: \u0026#34;trust read write\u0026#34; } 刷新令牌： 我们已经看到授权授予是唯一支持刷新令牌的授予。使用访问令牌 60 秒后，它就会过期，我们得到以下响应：\n{ \u0026#34;error\u0026#34;: \u0026#34;invalid_token\u0026#34;, \u0026#34;error_description\u0026#34;: \u0026#34;0abe701b-0f5a-4d25-81df-f2c4db2af555\u0026#34; } 这意味着访问令牌已过期。要获取新令牌，我们需要使用刷新令牌：\ncurl -X POST --user my-trusted-client:mysecret localhost:8081/oauth/token -d \u0026#39;client_id=my-trusted-client\u0026amp;grant_type=refresh_token\u0026amp;refresh_token=cf6aa9db-3757-465e-af68-b7d59d1f0b77\u0026#39; -H \u0026#34;Accept: application/json\u0026#34; 回复：\n{ \u0026#34;access_token\u0026#34;: \u0026#34;2f9a6609-fc64-4b1e-93a3-8232827da881\u0026#34;, \u0026#34;token_type\u0026#34;: \u0026#34;bearer\u0026#34;, \u0026#34;refresh_token\u0026#34;: \u0026#34;cf6aa9db-3757-465e-af68-b7d59d1f0b77\u0026#34;, \u0026#34;expires_in\u0026#34;: 59, \u0026#34;scope\u0026#34;: \u0026#34;trust read write\u0026#34; } 每次令牌过期时都可以重复此过程。\n总结 Spring OAuth 提供开箱即用的 OAuth 端点和流程，并且可以成为以最小的努力设置 OAuth 的绝佳解决方案。然而，对于不熟悉 Spring 的开发人员来说，这可能有点令人畏惧，因为很多事情都在幕后发生。希望这篇文章可以帮助您了解全局。在下一篇文章中，我们将讨论使用 OAuth 范围来保护端点。\n完整的源代码可以在这里找到：https://github.com/zak905/oauth2-example\n原文链接：http://www.zakariaamine.com/2018-01-27/using-oauth2-in-spring/\n","permalink":"https://blog.chensoul.cc/posts/2023/07/26/using-oauth2-in-spring/","summary":"OAuth2 是一组规范，主要提供对 Rest API 的安全访问的方法。 OAuth 的主要目的是允许通过使用令牌来执行身份验证和授权，而不必为每个操作提供凭据。由于本文的重点是实现，并且为了不重新发明轮子，可以查看 OAuth RFC 或维基百科以获取更多理论背景。在这篇文章中，我们将深入探讨 Spring 中的 OAuth2 实现以及如何使用不同的授权类型，但在此之前值得提供一些重要概念的简要定义。\n访问令牌和刷新令牌 身份验证成功后将提供访问令牌以及刷新令牌。访问令牌有一个有限的有效期（标准为 1 小时），之后需要刷新令牌才能获取新的访问令牌和新的刷新令牌。 Referesh 令牌通常会在使用后过期。\n资源服务器和授权服务器 OAuth 引入了授权服务器的概念，授权服务器是发出访问和刷新令牌的实体，并在每个操作中进行咨询以查看令牌是否有效。资源服务器只是由不同客户端应用程序（前端应用程序、移动设备、其他后端服务\u0026hellip;\u0026hellip;）访问的实际 Rest API。资源服务器和授权服务器可以是不同的实体，也可以是同一实体。\n授权类型 OAuth 中最常用的授权有：客户端凭据、密码、授权码和隐式授权。每项资助都有特定的流程和用例，但由于本文的重点不是理论，因此我们将重点关注其实施。有关授权及其用途的更多详细信息，请参阅 OAuth RFC。\n实现 在实现方面，我们将使用 Spring Boot 来利用其自动配置和引导功能，并更多地关注我们的核心主题。\n资源服务器： 我们有一个资源服务器，其中包含我们希望保护的以下端点：\n@RestController(\u0026#34;/\u0026#34;) public class ResourceController { @GetMapping(\u0026#34;/hello\u0026#34;) public String hello(){ return \u0026#34;hello\u0026#34;; } @GetMapping(\u0026#34;/foo\u0026#34;) public String foo(){ return \u0026#34;foo\u0026#34;; } @GetMapping(\u0026#34;/bar\u0026#34;) public String bar(){ return \u0026#34;bar\u0026#34;; } @GetMapping(\u0026#34;/test\u0026#34;) public String test(){ return \u0026#34;test\u0026#34;; } } 为此，我们需要配置一个用 @EnableResourceServer 注释的 ResourceServerConfigurerAdapter bean：\n@Configuration @EnableResourceServer public class ResourceSecurityConfiguration extends ResourceServerConfigurerAdapter { @Override public void configure(ResourceServerSecurityConfigurer resources) throws Exception { resources.resourceId(\u0026#34;resource\u0026#34;); } @Override public void configure(HttpSecurity http) throws Exception { http .","title":"[译]在 Spring 中实现 OAuth2：第 1 部分"},{"content":"在这篇文章中，我们将了解如何使用 Spring Boot 2 和 Spring Security 5 OAuth2 来实现集中授权的授权服务器以及如何通过 GUI 对其进行管理，还将提供资源服务器演示以及 github 下的整个项目。\n很多示例涵盖了基于早期版本的 Spring boot 2 和 Spring Security 5 使用内存令牌实现 Oauth2，因此想法是使用 MySql 数据库作为令牌存储。\n为了深入探讨这个主题，我们必须：\n配置 Spring 安全。 配置数据库。 创建授权服务器。 创建资源服务器。 使用 curl 客户端使用访问令牌获取安全资源。 什么是 Oauth 2？ OAuth 2.0 是行业标准授权协议。 OAuth 2.0 取代了 2006 年创建的原始 OAuth 协议上所做的工作。OAuth 2.0 注重客户端开发人员的简单性，同时为 Web 应用程序、桌面应用程序、移动电话和客厅设备提供特定的授权流程。\n该规范及其扩展正在 IETF OAuth 工作组内开发。\nOauth 2 角色 OAuth2 定义了 4 个角色：\n资源所有者：通常是您自己。\n资源服务器：托管受保护数据的服务器（例如 Google 托管您的个人资料和个人信息）。\n客户端：请求访问资源服务器的应用程序（网站、Javascript 应用程序或移动应用程序\u0026hellip;\u0026hellip;）。\n授权服务器：向客户端颁发访问令牌的服务器。该令牌将用于客户端请求资源服务器。该服务器可以与资源服务器相同（相同的物理服务器和相同的应用程序），而且经常是这种情况。\n下图说明了角色流程：\n授权类型 OAuth 2 为不同的用例提供了多种“授权类型”。定义的授权类型型有：\n授权码：授权码授予是使用您的 Facebook 或 Google 帐户登录应用程序的功能。 密码：旨在用于基于用户代理的客户端。其次，授权服务器不会像授权代码授予那样返回授权代码来交换访问令牌，而是返回访问令牌。 客户端凭据：客户端可以仅使用其客户端凭据（或其他支持的身份验证方式）请求访问令牌，当客户端请求访问其下的受保护资源控制权，或先前已被其他资源所有者控制的与授权服务器安排。 隐式授权：隐式授权是一种简化的授权代码流，针对使用 JavaScript 等脚本语言在浏览器中实现的客户端进行了优化。在隐式流程中，而不是向客户端发出授权代码，直接向客户端颁发访问令牌。 示范 让我们动手吧\n业务层 为简单起见，我们的主要业务应用程序将是使用一个实体的产品 API，我们的访问规则将是：\nPRODUCT_CREATE PRODUCT_UPDATE PRODUCT_DISPLAY PRODUCT_ADMIN OAuth2 客户端设置 要设置 Oauth 2 客户端，我们需要创建下表 [有关更多详细信息，请参阅链接]\nOAUTH_CLIENT_DETAILS OAUTH_CLIENT_DETAILS OAUTH_CLIENT_TOKEN OAUTH_CLIENT_TOKEN OAUTH_ACCESS_TOKEN OAUTH_ACCESS_TOKEN OAUTH_REFRESH_TOKEN OAUTH_REFRESH_TOKEN OAUTHCODE OAUTH代码 OAUTH_APPROVALS OAUTH_APPROVALS 我们将调用像“product_api”这样的资源服务器 对于该服务器，我们定义一个客户端，称为：\n读-写-客户端（授权授权类型：读、写） INSERT INTO OAUTH_CLIENT_DETAILS(CLIENT_ID, RESOURCE_IDS, CLIENT_SECRET, SCOPE, AUTHORIZED_GRANT_TYPES, AUTHORITIES, ACCESS_TOKEN_VALIDITY, REFRESH_TOKEN_VALIDITY) VALUES (\u0026#39;read-write-client\u0026#39;, \u0026#39;product-api\u0026#39;,\u0026#39;$2a$10$BurTWIy5NTF9GJJH4magz.9Bd4bBurWYG8tmXxeQh1vs7r/wnCFG2\u0026#39;,\u0026#39;read,write\u0026#39;, \u0026#39;client_credentials\u0026#39;, \u0026#39;ROLE_PRODUCT_ADMIN\u0026#39;, 10800, 2592000); #password [hashed with BCCrypt] :user 权限和用户设置 Spring Security 附带两个有用的接口：\nUserDetails — 提供核心用户信息。\nGrantedAuthority — 表示授予身份验证对象的权限。\n下面的脚本将加载所有权限和凭据（用户）：\nINSERT INTO authority VALUES(1,\u0026#39;ROLE_OAUTH_ADMIN\u0026#39;); INSERT INTO authority VALUES(2,\u0026#39;ROLE_ADMIN_PRODUCT\u0026#39;); INSERT INTO authority VALUES(3,\u0026#39;ROLE_RESOURCE_ADMIN\u0026#39;); INSERT INTO credentials VALUES(1,b\u0026#39;1\u0026#39;,\u0026#39;oauth_admin\u0026#39;,\u0026#39;$2a$10$BurTWIy5NTF9GJJH4magz.9Bd4bBurWYG8tmXxeQh1vs7r/wnCFG2\u0026#39;,\u0026#39;0\u0026#39;); INSERT INTO credentials VALUES(2,b\u0026#39;1\u0026#39;,\u0026#39;resource_admin\u0026#39;,\u0026#39;$2a$10$BurTWIy5NTF9GJJH4magz.9Bd4bBurWYG8tmXxeQh1vs7r/wnCFG2\u0026#39;,\u0026#39;0\u0026#39;); INSERT INTO credentials VALUES(3,b\u0026#39;1\u0026#39;,\u0026#39;user\u0026#39;,\u0026#39;$2a$10$BurTWIy5NTF9GJJH4magz.9Bd4bBurWYG8tmXxeQh1vs7r/wnCFG2\u0026#39;,\u0026#39;0\u0026#39;); INSERT INTO credentials_authorities VALUES (1, 1); INSERT INTO credentials_authorities VALUES (2, 3); INSERT INTO credentials_authorities VALUES (3, 2); #Password : user API 层 对于演示，基于 Spring Boot 开发了 RESTful 应用程序并公开以下端点：\nSpring 安全配置 我们必须提供 UserDetailsService 接口的实现，以便获取用户凭据和权限，如下所示\n为了向应用程序提供安全性，我们将使用 @EnableWebSecurity 注解和 WebSecurityConfigurerAdapter\npackage com.aak.configuration; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.builders.WebSecurity; import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.JdbcUserDetailsManager; import org.springframework.security.web.util.matcher.AntPathRequestMatcher; /** * Created by ahmed on 20.5.18. */ @EnableWebSecurity @Configuration public class WebSecurityConfiguration extends WebSecurityConfigurerAdapter { @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } @Bean @Override public UserDetailsService userDetailsServiceBean() throws Exception { return new JdbcUserDetails(); } @Override public void configure(WebSecurity web) throws Exception { web.ignoring().antMatchers(\u0026#34;/webjars/**\u0026#34;); } @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() .antMatchers(\u0026#34;/login\u0026#34;,\u0026#34;/logout.do\u0026#34;).permitAll() .antMatchers(\u0026#34;/**\u0026#34;).authenticated() .and() .formLogin() .loginProcessingUrl(\u0026#34;/login.do\u0026#34;) .usernameParameter(\u0026#34;username\u0026#34;) .passwordParameter(\u0026#34;password\u0026#34;) .loginPage(\u0026#34;/login\u0026#34;) .and() .logout() .logoutRequestMatcher(new AntPathRequestMatcher(\u0026#34;/logout.do\u0026#34;)) .and() .userDetailsService(userDetailsServiceBean()); } @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception { auth.userDetailsService(userDetailsServiceBean()) .passwordEncoder(passwordEncoder()); } } OAuth2 配置 要设置 Oauth 2，需要实现两个组件\nAuthorization Server 授权服务器 Resource Server 资源服务器 授权服务器 授权服务器负责验证用户身份并提供令牌，使用@EnableAuthorizationServer 注解启用授权服务器配置\npackage com.aak.configuration; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer; import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter; import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer; import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer; import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerSecurityConfigurer; import org.springframework.security.oauth2.provider.approval.ApprovalStore; import org.springframework.security.oauth2.provider.approval.JdbcApprovalStore; import org.springframework.security.oauth2.provider.client.JdbcClientDetailsService; import org.springframework.security.oauth2.provider.code.AuthorizationCodeServices; import org.springframework.security.oauth2.provider.code.JdbcAuthorizationCodeServices; import org.springframework.security.oauth2.provider.token.TokenStore; import org.springframework.security.oauth2.provider.token.store.JdbcTokenStore; import javax.sql.DataSource; /** * Created by ahmed on 21.5.18. */ @Configuration @EnableAuthorizationServer public class AuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter { @Bean @ConfigurationProperties(prefix = \u0026#34;spring.datasource\u0026#34;) public DataSource oauthDataSource() { return DataSourceBuilder.create().build(); } @Bean public JdbcClientDetailsService clientDetailsService() { return new JdbcClientDetailsService(oauthDataSource()); } @Bean public TokenStore tokenStore() { return new JdbcTokenStore(oauthDataSource()); } @Bean public ApprovalStore approvalStore() { return new JdbcApprovalStore(oauthDataSource()); } @Bean public AuthorizationCodeServices authorizationCodeServices() { return new JdbcAuthorizationCodeServices(oauthDataSource()); } @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception { clients.withClientDetails(clientDetailsService()); } @Override public void configure(AuthorizationServerSecurityConfigurer oauthServer) throws Exception { } @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) throws Exception { endpoints .approvalStore(approvalStore()) .authorizationCodeServices(authorizationCodeServices()) .tokenStore(tokenStore()); } } 成功配置运行授权服务器后，您将获得登录页面来管理授权服务器\n使用 oauth_admin/user 作为用户名/密码访问 Oauth2 仪表板，您可以在其中创建服务器客户端\n资源服务器 资源服务器托管受 OAuth2 令牌保护的资源（基本上是我们的产品 API）\npackage com.aak.configuration; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.boot.jdbc.DataSourceBuilder; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.http.HttpMethod; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.oauth2.config.annotation.web.configuration.EnableResourceServer; import org.springframework.security.oauth2.config.annotation.web.configuration.ResourceServerConfigurerAdapter; import org.springframework.security.oauth2.config.annotation.web.configurers.ResourceServerSecurityConfigurer; import org.springframework.security.oauth2.provider.token.TokenStore; import org.springframework.security.oauth2.provider.token.store.JdbcTokenStore; import javax.sql.DataSource; /** * Created by ahmed on 30.5.18. */ @EnableResourceServer @Configuration public class ResourcesServerConfiguration extends ResourceServerConfigurerAdapter { @Bean @ConfigurationProperties(prefix=\u0026#34;spring.datasource\u0026#34;) public DataSource ouathDataSource(){return DataSourceBuilder.create().build();} @Override public void configure(ResourceServerSecurityConfigurer resources)throws Exception{ TokenStore tokenStore=new JdbcTokenStore(ouathDataSource()); resources.resourceId(\u0026#34;product_api\u0026#34;).tokenStore(tokenStore); } @Override public void configure(HttpSecurity http) throws Exception{ http .authorizeRequests() .antMatchers(HttpMethod.GET, \u0026#34;/**\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;read\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.POST, \u0026#34;/**\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.PATCH, \u0026#34;/**\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.PUT, \u0026#34;/**\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .antMatchers(HttpMethod.DELETE, \u0026#34;/**\u0026#34;).access(\u0026#34;#oauth2.hasScope(\u0026#39;write\u0026#39;)\u0026#34;) .and() .headers().addHeaderWriter((request, response) -\u0026gt; { response.addHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); if (request.getMethod().equals(\u0026#34;OPTIONS\u0026#34;)) { response.setHeader(\u0026#34;Access-Control-Allow-Methods\u0026#34;, request.getHeader(\u0026#34;Access-Control-Request-Method\u0026#34;)); response.setHeader(\u0026#34;Access-Control-Allow-Headers\u0026#34;, request.getHeader(\u0026#34;Access-Control-Request-Headers\u0026#34;)); } }); } } 使用以下 Curl 客户端测试产品列表端点：\n#!/bin/sh TOKEN=`curl -s -u curl_client:user -X POST localhost:8081/oauth/token\\?grant_type=client_credentials | egrep -o ‘[a-f0–9-]{20,}’` echo “ tGot token for curl client as :$TOKEN” curl localhost:8083/product/products -H “Authorization: Bearer $TOKEN” 运行 Curl 客户端 bash 脚本后得到响应：\n$ ./client.sh Got token for curl client as : 3be01519–0cab-4049-b87d-617c48bda502 [{“version”:0,”name”:”product_1\u0026#34;,”available”:false},{“version”:0,”name”:”product_2\u0026#34;,”available”:true}] 从 github 上查看整个代码：https://github.com/Akourtiim/oauth2-spring-boot-2.0.2.git\n参考：\nhttps://tools.ietf.org/html/rfc6749 https://dzone.com/articles/secure-spring-rest-with-spring-security-and-oauth2 http://www.bubblecode.net/en/2016/01/22/understanding-oauth2/ https://github.com/FrontierPsychiatrist/spring-oauth-example 原文链接：Oauth 2 Centralized Authorization with Spring Boot 2.0.2 and Spring Security 5 and JDBC token store\n","permalink":"https://blog.chensoul.cc/posts/2023/07/14/oauth-2-centralized-authorization-with-spring-boot-2-and-spring-security-5-and-jdbc-token-store/","summary":"在这篇文章中，我们将了解如何使用 Spring Boot 2 和 Spring Security 5 OAuth2 来实现集中授权的授权服务器以及如何通过 GUI 对其进行管理，还将提供资源服务器演示以及 github 下的整个项目。\n很多示例涵盖了基于早期版本的 Spring boot 2 和 Spring Security 5 使用内存令牌实现 Oauth2，因此想法是使用 MySql 数据库作为令牌存储。\n为了深入探讨这个主题，我们必须：\n配置 Spring 安全。 配置数据库。 创建授权服务器。 创建资源服务器。 使用 curl 客户端使用访问令牌获取安全资源。 什么是 Oauth 2？ OAuth 2.0 是行业标准授权协议。 OAuth 2.0 取代了 2006 年创建的原始 OAuth 协议上所做的工作。OAuth 2.0 注重客户端开发人员的简单性，同时为 Web 应用程序、桌面应用程序、移动电话和客厅设备提供特定的授权流程。\n该规范及其扩展正在 IETF OAuth 工作组内开发。\nOauth 2 角色 OAuth2 定义了 4 个角色：\n资源所有者：通常是您自己。\n资源服务器：托管受保护数据的服务器（例如 Google 托管您的个人资料和个人信息）。\n客户端：请求访问资源服务器的应用程序（网站、Javascript 应用程序或移动应用程序\u0026hellip;\u0026hellip;）。\n授权服务器：向客户端颁发访问令牌的服务器。该令牌将用于客户端请求资源服务器。该服务器可以与资源服务器相同（相同的物理服务器和相同的应用程序），而且经常是这种情况。\n下图说明了角色流程：\n授权类型 OAuth 2 为不同的用例提供了多种“授权类型”。定义的授权类型型有：\n授权码：授权码授予是使用您的 Facebook 或 Google 帐户登录应用程序的功能。 密码：旨在用于基于用户代理的客户端。其次，授权服务器不会像授权代码授予那样返回授权代码来交换访问令牌，而是返回访问令牌。 客户端凭据：客户端可以仅使用其客户端凭据（或其他支持的身份验证方式）请求访问令牌，当客户端请求访问其下的受保护资源控制权，或先前已被其他资源所有者控制的与授权服务器安排。 隐式授权：隐式授权是一种简化的授权代码流，针对使用 JavaScript 等脚本语言在浏览器中实现的客户端进行了优化。在隐式流程中，而不是向客户端发出授权代码，直接向客户端颁发访问令牌。 示范 让我们动手吧\n业务层 为简单起见，我们的主要业务应用程序将是使用一个实体的产品 API，我们的访问规则将是：\nPRODUCT_CREATE PRODUCT_UPDATE PRODUCT_DISPLAY PRODUCT_ADMIN OAuth2 客户端设置 要设置 Oauth 2 客户端，我们需要创建下表 [有关更多详细信息，请参阅链接]","title":"[译]使用Spring Boot2和Spring Security 5以及JDBC令牌存储进行Oauth2集中授权"},{"content":"前言 本篇是对 2023-06-26 到 2023-07-09 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这两周主要是忙于工作，Wekatime 上统计的上周每天平均编程时间达到了 6 hrs 52 mins，基本上每天都是早七晚七的上班节奏。于是，学习的时间都被工作占用了。工作的内容主要是整合多个系统实现 sso 登录，用到的技术有 SpringCloud、Spring Security Oauth2 等等。\n另外，本周完成了上半年的绩效总结，回顾了这半年的工作内容。\n绩效总结 1、项目方面的成果：\na、完成了智能安防多个项目的迭代开发和上线，包括用户切换租户、报表发送到飞书、华为车牌识别、夜收模块拆分、巡检场景功能优化等。同时，也完成了通知模块重构、大屏报表支持多租户和门店、Dmallai 导航等需求的开发。这些工作的完成，为系统的稳定性和功能扩展提供了有力的支持。\nb、共发布了 32 次版本，其中 7 次为功能迭代，25 次为 bug 修复。平均每月完成了 1 次项目迭代和 4 次 bug 修复，做到了及时响应和快速解决问题，提升了用户的使用体验和满意度，提高了系统的稳定性，降低系统的故障率和用户的投诉率，没有出现 P3 级别以上故障。\n2、技术方面的成果：\n利用空余时间学习新技术和框架，如 Pyhon、Rust、React，每周写周报和学习总结，总计输出 66 篇文章。\n不断优化和迭代 Rose 框架，并将 Rose 合并到 Cocktail cloud，方便代码管理和维护。同时，Cocktail cloud 还增加了一些新的功能和特性，如国际化、日志打印、华为云接口封装等。\n利用设计模式重构通知模块，提升代码质量，同时系统扩展性和并发也得到很大的提升。\n3、个人发展方面的成果：\n通过不断学习和实践，提高了自己的沟通能力和时间管理的能力。每天早上 7 点到公司学习，提高了个人工作效率和执行力。\n4、团队合作方面的成果：\n加强了和同事之间的沟通和协作，及时讨论项目需求和进度，保障项目按时上线。\n读书 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n理财 这周总计支出 1483 元，明细如下：\n7 月 2 日：1276 元，其中 1000 元加油\n7 月 1 日：32 元\n6 月 30 日：35 元\n6 月 29 日：15 元\n6 月 28 日：41 元\n6 月 27 日：41 元\n6 月 26 日：43 元\n陪家人 工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成三篇博客：\nJava 设计模式：Ambassador Python 学习 6：模块和包 Python 学习 7：输入和输出 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。\n📌2023-06-27 #工程师工具 有小伙伴开始玩这个牛逼的 AI PS 工具了吗？叫 DragGAN，代码开源了，CC-BY-NC 许可，简单来说就是通过拖动以及简单操作的方式对图中对象进行姿势、形状、表情和布局具有灵活而精确的控制，效果太牛逼了，可玩玩看。 https://github.com/XingangPan/DragGAN #memos https://twitter.com/hitw93/status/1673700825989013504?s=12\u0026amp;t=N9Km7vJe9ghZkB_zBEJh4A\n📌2023-06-27 Z-Library 发布桌面客户端，支持 Windows、macOS、Linux，针对中国连接稳定性优化 https://ift.tt/h8KyIdF #memos https://twitter.com/appinn/status/1673640410156093441?s=12\u0026amp;t=N9Km7vJe9ghZkB_zBEJh4A\n📌2023-06-27 能下载全网（Mac/Win 均可）所有音、视频的效率插件工具，是我自己多年来的收藏，也是我平常吃饭用的家伙，【搭配使用】效果更佳 1、浏览器下载插件图 1 https://cococut.net 2、网页在线下载图 2 https://y2mate.com/en640 3、B 站视频在线下载图 3 https://xbeibeix.com/api/bilibili/ #memos https://twitter.com/mooenychu/status/1673489537472008192?s=12\u0026amp;t=N9Km7vJe9ghZkB_zBEJh4A\n📌2023-06-27 Mac 其实还有一个万能下载器工具：Downie4，推特视频，油管视频，B 站视频等等，只要链接复制进去就可以自动下载内容和字幕，很好用，有需要的朋友找来安装使用。非苹果用户如果有这方面的需求，我可以把这几年一直在用能下所有场景下的吃饭家伙分享出来，需要的评论区留言吧，上班去了。videodownlaod #memos https://twitter.com/mooenychu/status/1673144297389174784?s=12\u0026amp;t=N9Km7vJe9ghZkB_zBEJh4A\n📌2023-06-27 告诉大家一个免费用 MySQL 云数据库的渠道： 直接用 TiDB Cloud 的 Serverless 实例当作免费云数据库就好了 提供 5GiB 免费存储和五千万请求单元(一种 Serverless 用量统计指标) 像是个人的博客 例如 wordpress 一些中小型企业网站的 CMS 系统 个人小项目用应该是足够了 region 覆盖东亚和北美 直连速度也还不错 #memos https://twitter.com/changwei1006/status/1673169925710700545?s=12\u0026amp;t=N9Km7vJe9ghZkB_zBEJh4A\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/07/11/weekly_review_26/","summary":"前言 本篇是对 2023-06-26 到 2023-07-09 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这两周主要是忙于工作，Wekatime 上统计的上周每天平均编程时间达到了 6 hrs 52 mins，基本上每天都是早七晚七的上班节奏。于是，学习的时间都被工作占用了。工作的内容主要是整合多个系统实现 sso 登录，用到的技术有 SpringCloud、Spring Security Oauth2 等等。\n另外，本周完成了上半年的绩效总结，回顾了这半年的工作内容。\n绩效总结 1、项目方面的成果：\na、完成了智能安防多个项目的迭代开发和上线，包括用户切换租户、报表发送到飞书、华为车牌识别、夜收模块拆分、巡检场景功能优化等。同时，也完成了通知模块重构、大屏报表支持多租户和门店、Dmallai 导航等需求的开发。这些工作的完成，为系统的稳定性和功能扩展提供了有力的支持。\nb、共发布了 32 次版本，其中 7 次为功能迭代，25 次为 bug 修复。平均每月完成了 1 次项目迭代和 4 次 bug 修复，做到了及时响应和快速解决问题，提升了用户的使用体验和满意度，提高了系统的稳定性，降低系统的故障率和用户的投诉率，没有出现 P3 级别以上故障。\n2、技术方面的成果：\n利用空余时间学习新技术和框架，如 Pyhon、Rust、React，每周写周报和学习总结，总计输出 66 篇文章。\n不断优化和迭代 Rose 框架，并将 Rose 合并到 Cocktail cloud，方便代码管理和维护。同时，Cocktail cloud 还增加了一些新的功能和特性，如国际化、日志打印、华为云接口封装等。\n利用设计模式重构通知模块，提升代码质量，同时系统扩展性和并发也得到很大的提升。\n3、个人发展方面的成果：\n通过不断学习和实践，提高了自己的沟通能力和时间管理的能力。每天早上 7 点到公司学习，提高了个人工作效率和执行力。\n4、团队合作方面的成果：\n加强了和同事之间的沟通和协作，及时讨论项目需求和进度，保障项目按时上线。\n读书 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n理财 这周总计支出 1483 元，明细如下：\n7 月 2 日：1276 元，其中 1000 元加油\n7 月 1 日：32 元\n6 月 30 日：35 元\n6 月 29 日：15 元\n6 月 28 日：41 元","title":"周报-26｜上半年的绩效总结"},{"content":"在 Python 中，可以使用 input() 函数从标准输入读取用户输入的数据，并使用 print() 函数将数据输出到标准输出。下面是一些常用的输入输出方法：\n1、使用 input() 函数读取用户输入\ninput() 函数会从标准输入读取用户输入的数据，并返回一个字符串类型的值。例如：\nname = input(\u0026#34;What\u0026#39;s your name? \u0026#34;) print(\u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34;) 在上面的例子中，使用 input() 函数读取用户输入的姓名，并使用 print() 函数输出问候语。\n2、使用 print() 函数输出字符串\nprint() 函数可以将字符串输出到标准输出。可以使用加号（+）将多个字符串连接起来，并使用逗号（,）将多个参数输出到同一行。例如：\nprint(\u0026#34;Hello, World!\u0026#34;) print(\u0026#34;The answer is\u0026#34;, 42) 在上面的例子中，使用 print() 函数输出了两个字符串，第二个字符串包含了一个数字。\n3、使用格式化字符串输出数据\n可以使用格式化字符串将变量的值插入到字符串中。可以使用花括号（{}）表示变量的位置，并使用 format() 方法将变量的值插入到花括号中。例如：\nname = \u0026#34;Alice\u0026#34; age = 25 print(\u0026#34;My name is {} and I\u0026#39;m {} years old.\u0026#34;.format(name, age)) 在上面的例子中，使用 format() 方法将变量 name 和 age 的值插入到字符串中。\n4、使用 f-字符串输出数据\n在 Python 3.6 及以后的版本中，可以使用 f-字符串来格式化字符串。f-字符串是一种特殊的字符串，以字母 f 或 F 开头，并以花括号表示变量的位置。在花括号中可以直接使用变量名，也可以使用表达式计算变量的值。例如：\nname = \u0026#34;Bob\u0026#34; age = 32 print(f\u0026#34;My name is {name.upper()} and I\u0026#39;m {age * 2} years old.\u0026#34;) 在上面的例子中，使用 f-字符串将变量 name 的值转换为大写字母，并将变量 age 的值乘以 2。\n5、使用文件读写数据\nPython 提供了多种方式读写文件，可以使用 open() 函数打开文件，并使用 read()、write() 和 close() 方法读写文件。例如：\nlivecodeserver\n# 读取文件 with open(\u0026#34;input.txt\u0026#34;, \u0026#34;r\u0026#34;) as f: data = f.read() print(data) # 写入文件 with open(\u0026#34;output.txt\u0026#34;, \u0026#34;w\u0026#34;) as f: f.write(\u0026#34;Hello, World!\u0026#34;) 在上面的例子中，使用 with 语句打开文件并读取或写入数据。使用 \u0026ldquo;r\u0026rdquo; 参数表示读取文件，使用 \u0026ldquo;w\u0026rdquo; 参数表示写入文件。使用 read() 方法读取文件内容，使用 write() 方法写入文件内容。\n6、使用标准错误输出错误信息\n除了使用 print() 函数输出字符串到标准输出外，还可以使用标准错误将错误信息输出到控制台。可以使用 sys 模块中的 stderr 属性来输出错误信息。例如：\nimport sys try: x = int(input(\u0026#34;Enter a number: \u0026#34;)) print(10 / x) except ValueError: print(\u0026#34;Invalid input.\u0026#34;, file=sys.stderr) except ZeroDivisionError: print(\u0026#34;Cannot divide by zero.\u0026#34;, file=sys.stderr) 在上面的例子中，使用 try-except 语句处理输入错误和除以零错误，并使用 print() 函数将错误信息输出到标准错误。\n7、使用格式化字符串的高级特性\n除了简单的格式化字符串外，还可以使用格式化字符串的高级特性来格式化输出。例如，可以使用 {name:width} 格式来指定字符串的宽度，使用 {name:.2f} 格式来指定浮点数的小数位数。例如：\nname = \u0026#34;Alice\u0026#34; age = 25 score = 85.1234 print(f\u0026#34;{\u0026#39;Name:\u0026#39;:\u0026lt;10}{name:\u0026gt;10}\u0026#34;) print(f\u0026#34;{\u0026#39;Age:\u0026#39;:\u0026lt;10}{age:\u0026gt;10}\u0026#34;) print(f\u0026#34;{\u0026#39;Score:\u0026#39;:\u0026lt;10}{score:\u0026gt;10.2f}\u0026#34;) 在上面的例子中，使用 f-字符串和 {} 格式指定字符串的宽度和对齐方式，并使用 {:.2f} 格式指定浮点数的小数位数。\n8、使用 pprint 模块美化输出\npprint 模块可以美化 Python 数据结构的输出，以便更好地查看和调试数据。可以使用 pprint 模块中的 pprint() 函数将数据结构输出为美化的格式。例如：\nimport pprint data = {\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 25, \u0026#34;scores\u0026#34;: [80, 85, 90]} pprint.pprint(data) 在上面的例子中，使用 pprint.pprint() 函数将数据结构 data 输出为美化的格式。\n9、使用 logging 模块输出日志信息\nlogging 模块可以用于输出日志信息，以便更好地理解程序的运行状态和错误信息。可以使用 logging 模块中的 getLogger() 方法创建 Logger 对象，并使用该对象的不同方法输出不同级别的日志信息。例如：\nimport logging logging.basicConfig(level=logging.DEBUG, format=\u0026#39;%(asctime)s %(levelname)s %(message)s\u0026#39;) logger = logging.getLogger(__name__) def divide(x, y): logger.info(f\u0026#34;Dividing {x} by {y}\u0026#34;) try: result = x / y except ZeroDivisionError: logger.error(\u0026#34;Division by zero!\u0026#34;) return None else: logger.info(f\u0026#34;Result is {result}\u0026#34;) return result 在上面的例子中，使用 logging.basicConfig() 方法配置日志级别和格式，使用 getLogger() 方法创建 Logger 对象，并使用 info()、error() 等方法输出不同级别的日志信息。\n10、使用 traceback 模块输出异常信息\ntraceback 模块可以用于输出异常信息，以便更好地定位和解决程序错误。可以使用 traceback 模块中的 print_exc() 函数输出异常信息。例如：\nimport traceback try: x = int(input(\u0026#34;Enter a number: \u0026#34;)) print(10 / x) except: traceback.print_exc() 在上面的例子中，使用 try-except 语句捕获所有异常，并使用 traceback.print_exc() 函数输出异常信息。\n11、使用 cProfile 模块分析程序性能\ncProfile 模块可以用于分析程序的性能，以便更好地优化程序运行效率。可以使用 cProfile 模块中的 run() 方法分析程序性能。例如：\nimport cProfile # 定义程序 def func(): for i in range(10000): for j in range(10000): k = i * j # 分析程序性能 cProfile.run(\u0026#39;func()\u0026#39;) 在上面的例子中，定义一个程序 func() 进行计算，使用 cProfile.run() 方法分析程序性能。\n12、使用 argparse 模块解析命令行参数\nargparse 模块可以用于解析命令行参数，以便更好地控制程序的行为和输入输出。可以使用 argparse 模块中的 ArgumentParser 类创建解析器对象，并使用该对象的 add_argument() 方法添加命令行参数。例如：\nimport argparse parser = argparse.ArgumentParser(description=\u0026#39;Process some integers.\u0026#39;) parser.add_argument(\u0026#39;integers\u0026#39;, metavar=\u0026#39;N\u0026#39;, type=int, nargs=\u0026#39;+\u0026#39;, help=\u0026#39;an integer for the accumulator\u0026#39;) parser.add_argument(\u0026#39;--sum\u0026#39;, dest=\u0026#39;accumulate\u0026#39;, action=\u0026#39;store_const\u0026#39;, const=sum, default=max, help=\u0026#39;sum the integers (default: find the max)\u0026#39;) args = parser.parse_args() print(args.accumulate(args.integers)) 在上面的例子中，使用 ArgumentParser 类创建解析器对象，使用 add_argument() 方法添加命令行参数，使用 parse_args() 方法解析命令行参数，并使用 argparse.Namespace 对象访问解析结果。\n13、使用 pprint 模块输出对象信息\npprint 模块可以用于输出 Python 对象的信息，以便更好地查看和调试对象。可以使用 pprint 模块中的 pprint() 函数将对象输出为美化的格式。例如：\nimport pprint class Person: def __init__(self, name, age): self.name = name self.age = age def __repr__(self): return f\u0026#34;Person(name=\u0026#39;{self.name}\u0026#39;, age={self.age})\u0026#34; person = Person(\u0026#34;Alice\u0026#34;, 25) pprint.pprint(person) 在上面的例子中，使用 pprint.pprint() 函数将对象 person 输出为美化的格式，使用 repr() 方法定义对象的表示形式。\n14、使用 csv 模块读写 CSV 文件\ncsv 模块可以用于读写 CSV 文件，以便更好地处理表格数据。可以使用 csv 模块中的 reader() 和 writer() 函数读写 CSV 文件。例如：\nimport csv # 读取 CSV 文件 with open(\u0026#34;data.csv\u0026#34;, \u0026#34;r\u0026#34;) as f: reader = csv.reader(f) for row in reader: print(row) # 写入 CSV 文件 with open(\u0026#34;data.csv\u0026#34;, \u0026#34;w\u0026#34;, newline=\u0026#34;\u0026#34;) as f: writer = csv.writer(f) writer.writerow([\u0026#34;Name\u0026#34;, \u0026#34;Age\u0026#34;, \u0026#34;Score\u0026#34;]) writer.writerow([\u0026#34;Alice\u0026#34;, 25, 85]) writer.writerow([\u0026#34;Bob\u0026#34;, 32, 90]) 在上面的例子中，使用 csv.reader() 函数读取 CSV 文件，使用 csv.writer() 函数写入 CSV 文件，并使用 newline=\u0026quot;\u0026quot; 参数指定行结束符。\n15、使用 json 模块读写 JSON 数据\njson 模块可以用于读写 JSON 数据，以便更好地处理数据交换和存储。可以使用 json 模块中的 loads() 和 dumps() 函数读写 JSON 数据。例如：\nimport json # 读取 JSON 数据 data = \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 25, \u0026#34;scores\u0026#34;: [80, 85, 90]}\u0026#39; json_data = json.loads(data) print(json_data) # 写入 JSON 数据 data = {\u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;age\u0026#34;: 32, \u0026#34;scores\u0026#34;: [90, 95, 100]} json_data = json.dumps(data) print(json_data) 在上面的例子中，使用 json.loads() 函数读取 JSON 数据，使用 json.dumps() 函数写入 JSON 数据。\n16、使用 xml.etree.ElementTree 模块读写 XML 数据\nxml.etree.ElementTree 模块可以用于读写 XML 数据，以便更好地处理数据交换和存储。可以使用 xml.etree.ElementTree 模块中的 ElementTree 类和 Element 类读写 XML 数据。例如：\nimport xml.etree.ElementTree as ET # 读取 XML 数据 tree = ET.parse(\u0026#34;data.xml\u0026#34;) root = tree.getroot() for child in root: print(child.tag, child.attrib) # 写入 XML 数据 root = ET.Element(\u0026#34;data\u0026#34;) child1 = ET.SubElement(root, \u0026#34;name\u0026#34;) child1.text = \u0026#34;Alice\u0026#34; child2 = ET.SubElement(root, \u0026#34;age\u0026#34;) child2.text = \u0026#34;25\u0026#34; tree = ET.ElementTree(root) tree.write(\u0026#34;data.xml\u0026#34;) 在上面的例子中，使用 ET.parse() 方法读取 XML 文件，使用 Element 对象和 SubElement() 方法创建 XML 元素，使用 ElementTree 对象和 write() 方法写入 XML 文件。\n17、使用 sqlite3 模块读写 SQLite 数据库\nsqlite3 模块可以用于读写 SQLite 数据库，以便更好地持久化数据。可以使用 sqlite3 模块中的 connect() 和 cursor() 方法连接数据库和执行 SQL 语句。例如：\nimport sqlite3 # 连接数据库 conn = sqlite3.connect(\u0026#34;data.db\u0026#34;) # 创建表格 c = conn.cursor() c.execute(\u0026#39;\u0026#39;\u0026#39;CREATE TABLE IF NOT EXISTS students (id INTEGER PRIMARY KEY, name TEXT, age INTEGER, score REAL)\u0026#39;\u0026#39;\u0026#39;) # 插入数据 c.execute(\u0026#34;INSERT INTO students (name, age, score) VALUES (?, ?, ?)\u0026#34;, (\u0026#34;Alice\u0026#34;, 25, 85)) c.execute(\u0026#34;INSERT INTO students (name, age, score) VALUES (?, ?, ?)\u0026#34;, (\u0026#34;Bob\u0026#34;, 32, 90)) # 查询数据 c.execute(\u0026#34;SELECT * FROM students\u0026#34;) rows = c.fetchall() for row in rows: print(row) # 关闭数据库 conn.commit() conn.close() 在上面的例子中，使用 sqlite3.connect() 方法连接数据库，使用 cursor() 方法执行 SQL 语句，使用 fetchall() 方法获取查询结果，使用 commit() 方法提交事务并关闭数据库。\n18、使用 Pillow 模块读写图片文件\nPillow 模块可以用于读写图片文件，以便更好地处理图像数据。可以使用 Pillow 模块中的 Image 类读写图片文件。例如：\nfrom PIL import Image # 读取图片文件 im = Image.open(\u0026#34;image.jpg\u0026#34;) print(im.format, im.size, im.mode) # 显示图片 im.show() # 保存图片文件 im.save(\u0026#34;image.png\u0026#34;) 在上面的例子中，使用 Image.open() 方法读取图片文件，使用 format、size 和 mode 属性获取图片信息，使用 show() 方法显示图片，使用 save() 方法保存图片文件。\n19、使用 matplotlib 模块绘制图表\nmatplotlib 模块可以用于绘制各种类型的图表，以便更好地展示数据分布和趋势。可以使用 matplotlib 模块中的 pyplot 模块绘制图表。例如：\nimport matplotlib.pyplot as plt # 绘制折线图 x = [1, 2, 3, 4, 5] y = [1, 4, 9, 16, 25] plt.plot(x, y) plt.xlabel(\u0026#34;X Label\u0026#34;) plt.ylabel(\u0026#34;Y Label\u0026#34;) plt.title(\u0026#34;Line Chart\u0026#34;) plt.show() # 绘制柱状图 x = [\u0026#34;Apple\u0026#34;, \u0026#34;Banana\u0026#34;, \u0026#34;Orange\u0026#34;] y = [50, 30, 70] plt.bar(x, y) plt.xlabel(\u0026#34;Fruit\u0026#34;) plt.ylabel(\u0026#34;Quantity\u0026#34;) plt.title(\u0026#34;Bar Chart\u0026#34;) plt.show() 在上面的例子中，使用 plt.plot() 方法绘制折线图，使用 plt.bar() 方法绘制柱状图，使用 xlabel、ylabel 和 title 方法设置图表标签，使用 show() 方法显示图表。\n20、使用 Pygame 模块绘制游戏界面\nPygame 模块可以用于绘制游戏界面，以便更好地实现游戏功能。可以使用 Pygame 模块中的各种类和方法绘制游戏界面和处理游戏事件。例如：\nimport pygame # 初始化 Pygame pygame.init() # 创建游戏窗口 screen = pygame.display.set_mode((400, 300)) pygame.display.set_caption(\u0026#34;My Game\u0026#34;) # 创建游戏循环 running = True while running: # 处理游戏事件 for event in pygame.event.get(): if event.type == pygame.QUIT: running = False # 绘制游戏界面 screen.fill((255, 255, 255)) pygame.draw.circle(screen, (255, 0, 0), (200, 150), 50) pygame.display.update() # 退出 Pygame pygame.quit() 在上面的例子中，使用 pygame.init() 初始化 Pygame，使用 pygame.display.set_mode() 创建游戏窗口，使用 pygame.event.get() 处理游戏事件，使用 pygame.draw.circle() 绘制游戏界面，使用 pygame.display.update() 更新游戏界面，使用 pygame.quit() 退出 Pygame。\n","permalink":"https://blog.chensoul.cc/posts/2023/07/08/python-input-and-output/","summary":"在 Python 中，可以使用 input() 函数从标准输入读取用户输入的数据，并使用 print() 函数将数据输出到标准输出。下面是一些常用的输入输出方法：\n1、使用 input() 函数读取用户输入\ninput() 函数会从标准输入读取用户输入的数据，并返回一个字符串类型的值。例如：\nname = input(\u0026#34;What\u0026#39;s your name? \u0026#34;) print(\u0026#34;Hello, \u0026#34; + name + \u0026#34;!\u0026#34;) 在上面的例子中，使用 input() 函数读取用户输入的姓名，并使用 print() 函数输出问候语。\n2、使用 print() 函数输出字符串\nprint() 函数可以将字符串输出到标准输出。可以使用加号（+）将多个字符串连接起来，并使用逗号（,）将多个参数输出到同一行。例如：\nprint(\u0026#34;Hello, World!\u0026#34;) print(\u0026#34;The answer is\u0026#34;, 42) 在上面的例子中，使用 print() 函数输出了两个字符串，第二个字符串包含了一个数字。\n3、使用格式化字符串输出数据\n可以使用格式化字符串将变量的值插入到字符串中。可以使用花括号（{}）表示变量的位置，并使用 format() 方法将变量的值插入到花括号中。例如：\nname = \u0026#34;Alice\u0026#34; age = 25 print(\u0026#34;My name is {} and I\u0026#39;m {} years old.\u0026#34;.format(name, age)) 在上面的例子中，使用 format() 方法将变量 name 和 age 的值插入到字符串中。\n4、使用 f-字符串输出数据\n在 Python 3.6 及以后的版本中，可以使用 f-字符串来格式化字符串。f-字符串是一种特殊的字符串，以字母 f 或 F 开头，并以花括号表示变量的位置。在花括号中可以直接使用变量名，也可以使用表达式计算变量的值。例如：\nname = \u0026#34;Bob\u0026#34; age = 32 print(f\u0026#34;My name is {name.upper()} and I\u0026#39;m {age * 2} years old.\u0026#34;) 在上面的例子中，使用 f-字符串将变量 name 的值转换为大写字母，并将变量 age 的值乘以 2。","title":"Python学习7：输入和输出"},{"content":"在 Python 中，模块（module）是指一个包含 Python 代码的文件，而包（package）则是指一个包含多个模块的文件夹。模块和包可以用来组织和管理 Python 代码，使得代码更加易于维护和扩展。\n以下是一些有关 Python 模块和包的基本知识：\n1、导入模块\n使用 import 语句可以导入一个模块（或包）中的代码。例如，要导入名为 \u0026ldquo;math\u0026rdquo; 的模块，可以使用以下语句：\nimport math 这会将 math 模块中的所有函数和变量导入到当前 Python 脚本中，您就可以在脚本中使用 math 模块中的函数和变量了。\n2、导入特定函数或变量\n有时候您只需要使用模块中的某个函数或变量，而不需要导入整个模块。在这种情况下，可以使用 from\u0026hellip;import 语句，例如：\nfrom math import sqrt 这会将 math 模块中的 sqrt 函数导入到当前 Python 脚本中，您就可以直接使用 sqrt 函数了。\n3、导入多个函数或变量\n如果您需要导入多个函数或变量，可以使用逗号分隔它们，例如：\nfrom math import sqrt, floor 这会将 math 模块中的 sqrt 函数和 floor 函数导入到当前 Python 脚本中，您就可以直接使用这两个函数了。\n4、导入所有函数和变量\n有时候，您可能需要导入模块中的所有函数和变量。在这种情况下，可以使用以下语句：\nfrom math import * 这会将 math 模块中的所有函数和变量导入到当前 Python 脚本中。但是，这种导入方式可能会导致命名冲突和代码可读性降低，因此最好只在一些小型程序中使用。\n5、创建包\n要创建一个包，您需要创建一个包含 init.py 文件的文件夹，并在该文件夹中添加其他 Python 模块。init.py 文件可以是一个空文件，或者包含一些初始化代码。\n例如，如果您想创建一个名为 \u0026ldquo;my_package\u0026rdquo; 的包，可以按照以下方式组织代码：\nmy_package/ __init__.py module1.py module2.py 这个包包含了 init.py 文件和两个模块（module1.py 和 module2.py）。您可以使用 import 语句来导入这个包中的模块，例如：\nimport my_package.module1 这会将 my_package 包中的 module1.py 文件导入到当前 Python 脚本中，您就可以使用其中定义的函数和变量了。\n6、导入自定义模块\n如果您想导入自己编写的模块，可以将模块文件保存在您的 Python 脚本所在的目录中，然后使用 import 语句导入模块。例如，如果您的模块文件名为 \u0026ldquo;mymodule.py\u0026rdquo;，可以使用以下语句导入模块：\nimport mymodule 如果您的模块文件不在 Python 脚本所在的目录中，您需要将模块文件所在的路径添加到 sys.path 列表中，例如：\nimport sys sys.path.append(\u0026#39;/path/to/mymodule/\u0026#39;) import mymodule 7、包的相对导入\n在一个包中，您可以使用相对导入来导入其他模块。例如，如果您在 my_package 包中的 module1.py 中想要导入 my_package 包中的 module2.py，可以使用以下语句：\nfrom . import module2 这里的 \u0026ldquo;.\u0026rdquo; 表示当前包，\u0026quot;.\u0026quot; 后面的 module2 表示要导入的模块。\n8、包的命名空间\n在一个包中，多个模块可能会定义相同的函数或变量名，这可能会导致命名冲突。为了避免这种情况，Python 使用包的命名空间来区分不同模块中的函数和变量。当您导入一个包时，只有包中的模块才会被导入到命名空间中。这意味着您需要使用模块名称来访问其中的函数和变量，例如：\nimport my_package.module1 my_package.module1.my_function() 这里的 my_function() 是 my_package 包中的 module1.py 模块中的一个函数。\n9、在模块中定义变量\n在一个模块中，您可以定义全局变量，这些变量可以在模块中的其他函数中使用。例如：\n# module1.py my_variable = 42 def my_function(): print(my_variable) 在上面的例子中，my_variable 是一个全局变量，可以在模块中的任何函数中使用。\n10、使用 name 变量\n在一个模块中，可以使用 name 变量来判断该模块是被导入还是直接运行。例如：\nCopy\n# module1.py def my_function(): print(\u0026#34;Hello, world!\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: my_function() 在上面的例子中，如果您直接运行 module1.py，将会执行 my_function() 函数。但是，如果您在其他 Python 脚本中导入了 module1.py，my_function() 函数不会被执行。\n11、模块的文档字符串\n在一个模块中，您可以使用文档字符串来描述模块的功能和使用方法。文档字符串是放置在模块开头的字符串，可以通过模块的 doc 属性访问。例如：\n# module1.py \u0026#34;\u0026#34;\u0026#34; 这是一个演示模块的示例。 该模块包含了一个名为 my_function() 的函数，可以输出一条简单的信息。 \u0026#34;\u0026#34;\u0026#34; def my_function(): \u0026#34;\u0026#34;\u0026#34; 该函数可以输出一条简单的信息。 \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Hello, world!\u0026#34;) 在上面的例子中，模块的文档字符串用三重双引号括起来，并描述了模块的功能和使用方法。函数 my_function() 的文档字符串用三重双引号括起来，并描述了该函数的功能和使用方法。\n12、使用 init.py 文件\n在一个包中，您可以使用 init.py 文件来执行初始化代码，也可以在其中定义包级别的变量和函数。例如：\n# my_package/__init__.py print(\u0026#34;my_package 已被导入\u0026#34;) my_variable = 42 def my_function(): print(\u0026#34;my_function 已被调用\u0026#34;) 在上面的例子中，当您导入 my_package 包时，将会执行 init.py 文件中的代码，输出 \u0026ldquo;my_package 已被导入\u0026rdquo;。您还可以在 init.py 文件中定义全局变量和函数，这些变量和函数可以在包中的其他模块中使用。\n13、使用 all 变量\n在一个模块中，如果您想明确导出哪些函数和变量，可以使用 all 变量。例如：\n# module1.py __all__ = [\u0026#34;my_function\u0026#34;] def my_function(): print(\u0026#34;my_function 已被调用\u0026#34;) def my_private_function(): print(\u0026#34;my_private_function 已被调用\u0026#34;) 在上面的例子中，all 变量指定了要导出的函数名称，这里只导出了 my_function()。如果您在其他 Python 脚本中导入了 module1.py，只有 my_function() 函数会被导入到当前命名空间中。\n14、使用 setup.py 文件\n如果您想将自己编写的 Python 模块或包发布到 PyPI（Python Package Index）上，可以使用 setup.py 文件来构建和打包您的代码。setup.py 文件通常包含一些元数据（例如模块名称、版本号、作者、许可证等）和构建脚本，可以使用 setuptools 或 distutils 模块执行构建和打包操作。\n15、常用的 Python 模块和包\nPython 标准库中包含了许多有用的模块和包，可以帮助您完成各种任务，例如处理文件、网络编程、日期和时间处理、数学计算等。一些常用的 Python 模块和包包括：\nos：提供了许多与操作系统交互的函数和变量。 sys：提供了一些与 Python 解释器交互的函数和变量。 datetime：提供了日期和时间处理功能。 math：提供了数学计算函数。 random：提供了生成随机数的函数。 re：提供了处理正则表达式的函数。 urllib、requests：提供了进行网络编程的功能。 json、pickle：提供了进行序列化和反序列化的功能。 16、使用 virtualenv\n如果您需要在同一台计算机上运行多个 Python 项目，每个项目可能都需要不同版本的 Python 和各种依赖库。在这种情况下，可以使用 virtualenv 来创建独立的 Python 环境，每个环境都可以安装不同版本的 Python 和依赖库，以避免版本冲突和依赖冲突。例如：\n# 创建一个名为 myenv 的虚拟环境 $ virtualenv myenv # 激活虚拟环境 $ source myenv/bin/activate # 安装依赖库 $ pip install package1 package2 # 运行 Python 脚本 $ python myscript.py # 退出虚拟环境 $ deactivate 在上面的例子中，使用 virtualenv 创建了一个名为 myenv 的虚拟环境，并使用 pip 安装了 package1 和 package2 两个依赖库。在激活虚拟环境后，运行 myscript.py 脚本时，将使用虚拟环境中的 Python 版本和依赖库。\n17、使用 pipenv\npipenv 是一个应用程序，可以管理 Python 项目的依赖关系和虚拟环境。它使用 Pipfile 和 Pipfile.lock 文件来跟踪项目的依赖关系，并使用 virtualenv 来创建和管理虚拟环境。例如：\n# 安装 pipenv $ pip install pipenv # 创建一个新项目并安装依赖库 $ mkdir myproject $ cd myproject $ pipenv install package1 package2 # 运行 Python 脚本 $ pipenv run python myscript.py # 退出虚拟环境 $ exit 在上面的例子中，使用 pipenv 创建了一个名为 myproject 的新项目，并使用 pipenv install 命令安装了 package1 和 package2 两个依赖库。在运行 myscript.py 脚本时，使用 pipenv run 命令来激活虚拟环境并运行脚本。\n18、使用 Anaconda\nAnaconda 是一个广泛使用的 Python 数据科学平台，它包含了许多常用的数据科学库和工具，例如 NumPy、SciPy、Pandas、Matplotlib 等。Anaconda 还提供了一个名为 conda 的虚拟环境管理器，可以轻松地创建和管理独立的 Python 环境。例如：\n# 创建一个名为 myenv 的虚拟环境 $ conda create --name myenv # 激活虚拟环境 $ conda activate myenv # 安装依赖库 $ conda install package1 package2 # 运行 Python 脚本 $ python myscript.py # 退出虚拟环境 $ conda deactivate 在上面的例子中，使用 conda create 命令创建了一个名为 myenv 的虚拟环境，并使用 conda install 命令安装了 package1 和 package2 两个依赖库。在激活虚拟环境后，运行 myscript.py 脚本时，将使用虚拟环境中的 Python 版本和依赖库。\n19、使用 pytest 进行单元测试\npytest 是一个流行的 Python 测试框架，可以帮助您编写并运行单元测试和集成测试。pytest 自动发现测试文件和测试函数，并提供丰富的断言函数和测试报告。例如：\n# test_module.py def test_addition(): assert 1 + 1 == 2 def test_subtraction(): assert 5 - 3 == 2 在上面的例子中，定义了两个测试函数 test_addition() 和 test_subtraction()，使用 assert 语句进行断言。使用 pytest 运行测试时，pytest 会自动发现并运行 test_module.py 文件，输出测试结果和测试报告。\n20、使用 logging 模块进行日志记录\nlogging 是 Python 标准库中的一个模块，可以帮助您记录和管理应用程序的日志。logging 模块提供了多个日志级别（例如 DEBUG、INFO、WARNING、ERROR 和 CRITICAL）和多个日志处理器（例如控制台处理器、文件处理器、网络处理器等），可以根据需要进行配置。例如：\n# my_module.py import logging # 创建一个名为 my_logger 的日志记录器 my_logger = logging.getLogger(\u0026#34;my_logger\u0026#34;) # 创建一个控制台处理器和一个文件处理器 console_handler = logging.StreamHandler() file_handler = logging.FileHandler(\u0026#34;my_log.log\u0026#34;) # 创建一个日志格式器和将其添加到处理器中 log_formatter = logging.Formatter(\u0026#34;%(asctime)s [%(levelname)s] %(message)s\u0026#34;) console_handler.setFormatter(log_formatter) file_handler.setFormatter(log_formatter) # 将处理器添加到日志记录器中 my_logger.addHandler(console_handler) my_logger.addHandler(file_handler) # 设置日志级别 my_logger.setLevel(logging.DEBUG) def my_function(): my_logger.debug(\u0026#34;debug message\u0026#34;) my_logger.info(\u0026#34;info message\u0026#34;) my_logger.warning(\u0026#34;warning message\u0026#34;) my_logger.error(\u0026#34;error message\u0026#34;) my_logger.critical(\u0026#34;critical message\u0026#34;) 在上面的例子中，使用 logging 模块创建了一个名为 my_logger 的日志记录器，并创建了一个控制台处理器和一个文件处理器。使用日志格式器将日志消息格式化后，将处理器添加到日志记录器中，并设置日志级别为 DEBUG。在 my_function() 函数中，使用 my_logger 记录了不同级别的日志消息。日志消息将同时输出到控制台和 my_log.log 文件中。\n","permalink":"https://blog.chensoul.cc/posts/2023/07/06/python-module-package/","summary":"在 Python 中，模块（module）是指一个包含 Python 代码的文件，而包（package）则是指一个包含多个模块的文件夹。模块和包可以用来组织和管理 Python 代码，使得代码更加易于维护和扩展。\n以下是一些有关 Python 模块和包的基本知识：\n1、导入模块\n使用 import 语句可以导入一个模块（或包）中的代码。例如，要导入名为 \u0026ldquo;math\u0026rdquo; 的模块，可以使用以下语句：\nimport math 这会将 math 模块中的所有函数和变量导入到当前 Python 脚本中，您就可以在脚本中使用 math 模块中的函数和变量了。\n2、导入特定函数或变量\n有时候您只需要使用模块中的某个函数或变量，而不需要导入整个模块。在这种情况下，可以使用 from\u0026hellip;import 语句，例如：\nfrom math import sqrt 这会将 math 模块中的 sqrt 函数导入到当前 Python 脚本中，您就可以直接使用 sqrt 函数了。\n3、导入多个函数或变量\n如果您需要导入多个函数或变量，可以使用逗号分隔它们，例如：\nfrom math import sqrt, floor 这会将 math 模块中的 sqrt 函数和 floor 函数导入到当前 Python 脚本中，您就可以直接使用这两个函数了。\n4、导入所有函数和变量\n有时候，您可能需要导入模块中的所有函数和变量。在这种情况下，可以使用以下语句：\nfrom math import * 这会将 math 模块中的所有函数和变量导入到当前 Python 脚本中。但是，这种导入方式可能会导致命名冲突和代码可读性降低，因此最好只在一些小型程序中使用。\n5、创建包\n要创建一个包，您需要创建一个包含 init.py 文件的文件夹，并在该文件夹中添加其他 Python 模块。init.py 文件可以是一个空文件，或者包含一些初始化代码。\n例如，如果您想创建一个名为 \u0026ldquo;my_package\u0026rdquo; 的包，可以按照以下方式组织代码：\nmy_package/ __init__.py module1.py module2.py 这个包包含了 init.py 文件和两个模块（module1.py 和 module2.py）。您可以使用 import 语句来导入这个包中的模块，例如：\nimport my_package.module1 这会将 my_package 包中的 module1.py 文件导入到当前 Python 脚本中，您就可以使用其中定义的函数和变量了。\n6、导入自定义模块","title":"Python学习6：模块和包"},{"content":"本文主要介绍 Ambassador 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 在客户端上提供帮助程序服务实例，并从共享资源上转移常用功能。\nAmbassador 设计模式的主要目的是将客户端应用程序与远程服务器之间的通信细节隔离开来，从而使客户端应用程序可以专注于自己的业务逻辑，而不必关注网络通信细节和错误处理。\n在传统的客户端应用程序中，通常需要处理大量的网络通信细节和错误处理，这会使代码变得复杂且难以维护。而使用 Ambassador 设计模式可以将这些细节和处理逻辑集中在一个单独的类中，从而使客户端应用程序的代码更加简洁、易于维护和扩展。\n此外，使用 Ambassador 设计模式还可以提高客户端应用程序与远程服务器之间的通信安全性和可靠性。例如，Ambassador 类可以负责统一处理所有的网络通信，从而可以更轻松地实现安全性和可靠性控制。\n解释 假设有一个旧版的远程服务，该服务提供了许多客户端访问的功能，但由于用户的大量请求，导致连接问题变得普遍。此外，新的请求频率规则需要同时实现延迟检测和客户端日志功能。为了解决这些问题，可以使用 Ambassador 设计模式。\n微软文档 做了如下阐述\n可以将大使服务视为与客户端位于同一位置的进程外代理。 此模式对于以语言不可知的方式减轻常见的客户端连接任务（例如监视，日志记录，路由，安全性（如 TLS）和弹性模式）的工作很有用。 它通常与旧版应用程序或其他难以修改的应用程序一起使用，以扩展其网络功能。 它还可以使专业团队实现这些功能。\n在该模式中，可以创建一个 Ambassador 类来充当客户端应用程序和远程服务之间的代理。Ambassador 类负责处理所有的网络通信细节和错误处理，并实现新的请求频率规则，包括延迟检测和客户端日志功能。\n具体来说，Ambassador 类可以实现以下功能：\n延迟检测：在请求到达远程服务之前，Ambassador 类可以检测请求的时间戳，并计算出请求的延迟时间。如果请求的延迟时间超过了预设的阈值，Ambassador 类可以将请求拒绝。 客户端日志功能：Ambassador 类可以记录请求的时间戳、请求的内容和响应的内容，并将这些信息保存到客户端的日志文件中。这样可以帮助客户端应用程序进行调试和故障排除。 连接问题处理：Ambassador 类可以监控远程服务的连接状态，并在连接出现问题时进行自动重试。同时，Ambassador 类还可以实现一些优化策略，例如使用连接池等，以提高连接的可靠性和性能。 程序示例\n有了上面的介绍我们将在这个例子中模仿功能。我们有一个用远程服务实现的接口，同时也是大使服务。\ninterface RemoteServiceInterface { long doRemoteFunction(int value) throws Exception; } 表示为单例的远程服务。\npublic class RemoteService implements RemoteServiceInterface { private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class); private static RemoteService service = null; static synchronized RemoteService getRemoteService() { if (service == null) { service = new RemoteService(); } return service; } private RemoteService() {} @Override public long doRemoteFunction(int value) { long waitTime = (long) Math.floor(Math.random() * 1000); try { sleep(waitTime); } catch (InterruptedException e) { LOGGER.error(\u0026#34;Thread sleep interrupted\u0026#34;, e); } return waitTime \u0026gt;= 200 ? value * 10 : -1; } } 服务大使添加了像日志和延迟检测的额外功能\npublic class ServiceAmbassador implements RemoteServiceInterface { private static final Logger LOGGER = LoggerFactory.getLogger(ServiceAmbassador.class); private static final int RETRIES = 3; private static final int DELAY_MS = 3000; ServiceAmbassador() { } @Override public long doRemoteFunction(int value) { return safeCall(value); } private long checkLatency(int value) { Long startTime = System.currentTimeMillis(); long result = RemoteService.getRemoteService().doRemoteFunction(value); Long timeTaken = System.currentTimeMillis() - startTime; LOGGER.info(\u0026#34;Time taken (ms): \u0026#34; + timeTaken); return result; } private long safeCall(int value) { int retries = 0; long result = (long) FAILURE; for (int i = 0; i \u0026lt; RETRIES; i++) { if (retries \u0026gt;= RETRIES) { return FAILURE; } if ((result = checkLatency(value)) == FAILURE) { LOGGER.info(\u0026#34;Failed to reach remote: (\u0026#34; + (i + 1) + \u0026#34;)\u0026#34;); retries++; try { sleep(DELAY_MS); } catch (InterruptedException e) { LOGGER.error(\u0026#34;Thread sleep state interrupted\u0026#34;, e); } } else { break; } } return result; } } 客户端具有用于与远程服务进行交互的本地服务大使：\npublic class Client { private static final Logger LOGGER = LoggerFactory.getLogger(Client.class); private final ServiceAmbassador serviceAmbassador = new ServiceAmbassador(); long useService(int value) { long result = serviceAmbassador.doRemoteFunction(value); LOGGER.info(\u0026#34;Service result: \u0026#34; + result); return result; } } 这是两个使用该服务的客户端。\npublic class App { public static void main(String[] args) { Client host1 = new Client(); Client host2 = new Client(); host1.useService(12); host2.useService(73); } } Here\u0026rsquo;s the output for running the example:\nTime taken (ms): 111 Service result: 120 Time taken (ms): 931 Failed to reach remote: (1) Time taken (ms): 665 Failed to reach remote: (2) Time taken (ms): 538 Failed to reach remote: (3) Service result: -1 类图 适用场景 Ambassador 设计模式适用于以下场景：\n当客户端应用程序需要与远程服务器进行通信，并且需要处理与网络通信相关的所有细节时。 当客户端应用程序需要隔离与远程服务器的通信细节时，以便更好地专注于自己的业务逻辑。 当客户端应用程序需要处理与远程服务器的通信错误时。 当客户端应用程序需要实现新的请求频率规则，例如延迟检测和客户端日志功能等。 当客户端应用程序需要在不更改旧版远程服务代码的情况下，对远程服务进行定制化扩展时。 典型用例 Ambassador 设计模式可以用于许多场景，以下是其中的一些典型用例：\n限流和熔断保护 在分布式系统中，服务之间的调用是通过网络进行的，网络延迟、故障和不可用性是常见的问题。当一个服务被频繁调用时，可能会导致其过载或崩溃，从而影响整个系统的稳定性和可用性。使用 Ambassador 设计模式可以实现对服务的请求流量和执行频率进行限制，同时也可以实现熔断保护，当一个服务出现故障或不可用时，自动切换到备用服务。\n限流 当使用 Ambassador 设计模式时，可以在 Ambassador 类中实现新的请求频率规则。以下是一个简单的例子，说明如何使用 Ambassador 设计模式来实现请求频率规则：\n假设有一个客户端应用程序需要向远程服务器发送请求，并且需要实现以下请求频率规则：每个客户端在 10 秒钟内只能发送 10 个请求。如果客户端发送的请求超过了这个限制，服务器将返回 429 Too Many Requests 错误。\n为了实现这个规则，可以创建一个 Ambassador 类来充当客户端应用程序和远程服务器之间的代理。在 Ambassador 类中，可以使用计数器和定时器来实现请求频率控制逻辑。\n具体来说，Ambassador 类可以实现以下功能：\n定义计数器和定时器：在 Ambassador 类的构造函数中，可以定义一个计数器和一个定时器。计数器用于记录客户端发送的请求次数，定时器用于在每个 10 秒钟后重置计数器的值。 处理请求：在 Ambassador 类的处理请求方法中，可以首先检查计数器的值是否超过了限制。如果超过了限制，则返回 429 Too Many Requests 错误；否则，将请求发送到远程服务器，并将计数器的值增加 1。 处理定时器：在 Ambassador 类中，可以使用定时器来定期重置计数器的值。当定时器触发时，将计数器的值设置为 0。 以下是一个基于 Java 8 的 Ambassador 设计模式的示例代码，使用了 Java 8 中的 HttpClient 类来发送 HTTP 请求：\nimport java.time.Instant; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.LongAdder; public class Ambassador { private final LongAdder counter = new LongAdder(); private final ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(); private Instant lastResetTime = Instant.now(); public String handleRequest(String url) { // 检查计数器是否超过了限制 if (counter.incrementAndGet() \u0026gt; 10) { // 返回“Too Many Requests”错误 counter.decrementAndGet(); return \u0026#34;429 Too Many Requests\u0026#34;; } else { // 发送请求到远程服务器 String response = sendRequest(url); // 检查是否需要重置计数器 Instant currentTime = Instant.now(); if (currentTime.getEpochSecond() - lastResetTime.getEpochSecond() \u0026gt;= 10) { counter.reset(); lastResetTime = currentTime; } // 返回响应结果 return response; } } private String sendRequest(String url) { // 发送 HTTP GET 请求并返回响应结果 HttpClient client = HttpClient.newHttpClient(); HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(url)) .GET() .build(); try { HttpResponse\u0026lt;String\u0026gt; response = client.send(request, HttpResponse.BodyHandlers.ofString()); return response.body(); } catch (IOException | InterruptedException e) { // 处理请求异常 return \u0026#34;500 Internal Server Error\u0026#34;; } } public Ambassador() { // 定时重置计数器 scheduler.scheduleAtFixedRate(() -\u0026gt; { counter.reset(); lastResetTime = Instant.now(); }, 10, 10, TimeUnit.SECONDS); } public void shutdown() { // 关闭定时器 scheduler.shutdown(); } } 在上述代码中，Ambassador 类使用了 LongAdder 类型的计数器和 ScheduledExecutorService 类型的定时器，并实现了处理请求的方法 handleRequest。当客户端调用 handleRequest 方法时，Ambassador 类会检查计数器的值是否超过了限制。如果超过了限制，则返回 429 Too Many Requests 错误；否则，将请求发送到远程服务器，并将计数器的值增加 1。同时，Ambassador 类还会使用 ScheduledExecutorService 来定期重置计数器的值。\n熔断 Ambassador 设计模式可以使用熔断模式来保护服务免受故障或不可用性的影响。熔断模式是一种防止故障扩散的机制，当服务出现故障或不可用时，熔断器会自动切换到备用服务，并在一段时间内停止发送请求。如果备用服务也出现故障或不可用，熔断器会重新启动并继续发送请求。以下是一个使用 Ambassador 设计模式实现熔断的示例代码：\nimport java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; import java.util.logging.Level; import java.util.logging.Logger; public class Ambassador { private final AtomicInteger failureCount = new AtomicInteger(0); private final AtomicBoolean circuitBreaker = new AtomicBoolean(false); private final Service primaryService; private final Service backupService; private final int failureThreshold; private final int timeout; private final ExecutorService executor; private final Logger logger; public Ambassador(Service primaryService, Service backupService, int failureThreshold, int timeout, int maxConcurrentRequests) { this.primaryService = primaryService; this.backupService = backupService; this.failureThreshold = failureThreshold; this.timeout = timeout; this.executor = Executors.newFixedThreadPool(maxConcurrentRequests); this.logger = Logger.getLogger(Ambassador.class.getName()); } public String handleRequest(String request) throws TimeoutException { // 检查熔断器状态 if (circuitBreaker.get()) { // 返回备用服务的响应 return backupService.process(request); } else { try { // 创建 Callable 对象，并设置超时时间 Callable\u0026lt;String\u0026gt; task = () -\u0026gt; primaryService.process(request); Future\u0026lt;String\u0026gt; future = executor.submit(task); String response = future.get(timeout, TimeUnit.MILLISECONDS); // 重置故障计数器 failureCount.set(0); return response; } catch (InterruptedException | ExecutionException e) { // 处理请求异常 // 增加故障计数器 failureCount.incrementAndGet(); // 检查故障计数器是否超过阈值 if (failureCount.get() \u0026gt;= failureThreshold) { // 启动熔断器 circuitBreaker.set(true); logger.log(Level.WARNING, \u0026#34;Circuit breaker is tripped, switching to backup service\u0026#34;); } // 返回备用服务的响应 return backupService.process(request); } catch (TimeoutException e) { // 处理请求超时异常 throw new TimeoutException(\u0026#34;Request timed out\u0026#34;); } finally { // 检查熔断器状态 if (circuitBreaker.get()) { // 创建定时任务，定时重置熔断器状态 ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(); scheduler.schedule(() -\u0026gt; { // 重置故障计数器和熔断器状态 failureCount.set(0); circuitBreaker.set(false); logger.log(Level.INFO, \u0026#34;Circuit breaker is reset, switching back to primary service\u0026#34;); // 关闭定时任务调度器 scheduler.shutdown(); }, timeout, TimeUnit.MILLISECONDS); } } } } } 需要注意的是，在实际应用中，我们需要根据业务需求和系统负载来设置故障计数器的阈值和熔断器的停止时间。如果故障计数器的值超过了阈值，熔断器会启动，并在一定时间内停止发送请求。在熔断器停止期间，Ambassador 类会将所有请求转发到备用服务。当熔断器停止时间到达后，Ambassador 类会重新启动熔断器，并将请求转发到主服务进行处理。同时，我们还需要考虑并发请求的数量和请求的响应时间，以便更好地保证系统的稳定性和性能。\n安全过滤器 在 Web 应用程序中，安全过滤器通常用于检查输入数据的合法性和防止攻击，如 SQL 注入、跨站脚本攻击等。使用 Ambassador 设计模式可以将安全过滤器部署在应用程序的前端，检查所有的输入数据，防止攻击和恶意行为。\n下面是一个简单的示例，演示如何使用 Ambassador 设计模式来实现安全过滤器：\nimport java.util.regex.Pattern; public class SecurityFilter implements Service { private final Service service; public SecurityFilter(Service service) { this.service = service; } @Override public String process(String request) { // 检查输入数据，防止攻击和恶意行为 if (!isValid(request)) { throw new IllegalArgumentException(\u0026#34;Invalid request\u0026#34;); } // 调用服务处理请求 return service.process(request); } private boolean isValid(String request) { // 检查输入数据是否包含恶意代码 Pattern pattern = Pattern.compile(\u0026#34;\u0026lt;script\u0026gt;(.*?)\u0026lt;/script\u0026gt;\u0026#34;, Pattern.CASE_INSENSITIVE); return !pattern.matcher(request).find(); } } 在上述代码中，我们创建了一个 SecurityFilter 类，实现了 Service 接口，并在构造函数中传入了一个服务对象。在 process 方法中，我们首先检查输入数据，防止攻击和恶意行为，然后调用服务处理请求。\n在 isValid 方法中，我们使用正则表达式检查输入数据是否包含恶意代码。在这个例子中，我们检查输入数据中是否包含 \u0026lt;script\u0026gt; 和 \u0026lt;/script\u0026gt; 标签，如果包含则认为是恶意代码。\n在实际应用中，我们可以根据具体的业务需求和安全策略，设计更加复杂和完善的安全过滤器。同时，我们还可以使用其他的设计模式和技术，如拦截器、过滤器链、黑白名单、加密算法等，来提高应用程序的安全性和可靠性。\n以下是更进一步优化后的 SecurityFilter 类示例代码，其中使用了过滤器链和黑白名单来实现更加灵活和可配置的安全过滤器，同时增加了日志记录和异常处理，以便更好地监控和调试系统：\nimport java.util.ArrayList; import java.util.List; import java.util.regex.Pattern; import java.util.logging.Level; import java.util.logging.Logger; public class SecurityFilter implements Service { private final Service service; private final List\u0026lt;Filter\u0026gt; filters; private final List\u0026lt;String\u0026gt; whiteList; private final List\u0026lt;String\u0026gt; blackList; private final Logger logger = Logger.getLogger(SecurityFilter.class.getName()); public SecurityFilter(Service service) { this.service = service; this.filters = new ArrayList\u0026lt;\u0026gt;(); this.whiteList = new ArrayList\u0026lt;\u0026gt;(); this.blackList = new ArrayList\u0026lt;\u0026gt;(); } public void addFilter(Filter filter) { filters.add(filter); } public void addWhiteList(String pattern) { whiteList.add(pattern); } public void addBlackList(String pattern) { blackList.add(pattern); } @Override public String process(String request) { // 检查白名单 if (!isAllowed(request, whiteList)) { logger.log(Level.WARNING, \u0026#34;Request not allowed: \u0026#34; + request); throw new IllegalArgumentException(\u0026#34;Request not allowed\u0026#34;); } // 检查黑名单 if (isBlocked(request, blackList)) { logger.log(Level.WARNING, \u0026#34;Request blocked: \u0026#34; + request); throw new IllegalArgumentException(\u0026#34;Request blocked\u0026#34;); } // 执行过滤器链 for (Filter filter : filters) { request = filter.doFilter(request); } // 调用服务处理请求 return service.process(request); } private boolean isAllowed(String request, List\u0026lt;String\u0026gt; patterns) { // 检查请求是否在白名单中 return patterns.stream().anyMatch(pattern -\u0026gt; Pattern.matches(pattern, request)); } private boolean isBlocked(String request, List\u0026lt;String\u0026gt; patterns) { // 检查请求是否在黑名单中 return patterns.stream().anyMatch(pattern -\u0026gt; Pattern.matches(pattern, request)); } public interface Filter { String doFilter(String request); } } 负载均衡 在分布式系统中，负载均衡通常用于将请求分发到多个服务器上，以实现高可用性和容错性。使用 Ambassador 设计模式可以实现负载均衡，将请求分发到多个服务实例上，从而提高系统的可用性和性能。\n下面是一个简单的示例，演示如何使用 Ambassador 设计模式来实现负载均衡：\nimport java.util.List; import java.util.concurrent.ThreadLocalRandom; public class LoadBalancer implements Service { private final List\u0026lt;Service\u0026gt; services; private final LoadBalancingStrategy strategy; public LoadBalancer(List\u0026lt;Service\u0026gt; services, LoadBalancingStrategy strategy) { this.services = services; this.strategy = strategy; } @Override public String process(String request) { // 根据负载均衡策略选择服务实例 Service service = strategy.select(services); // 调用选择的服务处理请求 return service.process(request); } public interface LoadBalancingStrategy { Service select(List\u0026lt;Service\u0026gt; services); } public static class RandomStrategy implements LoadBalancingStrategy { @Override public Service select(List\u0026lt;Service\u0026gt; services) { // 随机选择一个服务实例 int index = ThreadLocalRandom.current().nextInt(services.size()); return services.get(index); } } public static class RoundRobinStrategy implements LoadBalancingStrategy { private int index = 0; @Override public Service select(List\u0026lt;Service\u0026gt; services) { // 轮询选择服务实例 Service service = services.get(index); index = (index + 1) % services.size(); return service; } } } 在上述代码中，我们创建了一个 LoadBalancer 类，实现了 Service 接口，并在构造函数中传入了一个服务列表和一个负载均衡策略。在 process 方法中，我们根据负载均衡策略选择一个服务实例，然后调用选择的服务处理请求。\n在 LoadBalancingStrategy 接口中，我们定义了一个 select 方法，用于选择服务实例。在 RandomStrategy 类中，我们使用 ThreadLocalRandom 来随机选择一个服务实例。在 RoundRobinStrategy 类中，我们使用轮询算法来选择服务实例。\n在实际应用中，我们可以根据具体的业务需求和性能指标，选择合适的负载均衡策略和算法，如加权轮询、最少连接数、哈希算法等，来实现更加高效和灵活的负载均衡。同时，我们还可以使用其他的设计模式和技术，如缓存、异步处理、分布式锁等，来进一步提高系统的可用性和性能。需要注意的是，在设计负载均衡器时，我们需要根据实际情况和负载均衡算法的特点，合理地分配服务实例和请求，避免出现负载不均衡或性能瓶颈的问题。\n以下是经过优化后的负载均衡器的代码：\nimport java.util.ArrayList; import java.util.List; import java.util.concurrent.ConcurrentHashMap; import java.util.concurrent.ThreadLocalRandom; import java.util.concurrent.atomic.AtomicInteger; import java.util.function.Function; public class LoadBalancer { private final List\u0026lt;Service\u0026gt; services; private final LoadBalancingStrategy strategy; private final ConcurrentHashMap\u0026lt;Service, Integer\u0026gt; weights = new ConcurrentHashMap\u0026lt;\u0026gt;(); public LoadBalancer(List\u0026lt;Service\u0026gt; services, LoadBalancingStrategy strategy) { this.services = new ArrayList\u0026lt;\u0026gt;(services); this.strategy = strategy; for (Service service : services) { weights.put(service, 1); } } public Service getService() { return strategy.select(services, weights); } public void setWeight(Service service, int weight) { weights.put(service, weight); } public static LoadBalancer create(List\u0026lt;Service\u0026gt; services, LoadBalancingStrategy strategy) { return new LoadBalancer(services, strategy); } public static LoadBalancer createWithRoundRobin(List\u0026lt;Service\u0026gt; services) { return new LoadBalancer(services, LoadBalancingStrategy.ROUND_ROBIN); } public static LoadBalancer createWithRandom(List\u0026lt;Service\u0026gt; services) { return new LoadBalancer(services, LoadBalancingStrategy.RANDOM); } public enum LoadBalancingStrategy { RANDOM(services -\u0026gt; services.get(ThreadLocalRandom.current().nextInt(services.size()))), ROUND_ROBIN(services -\u0026gt; { AtomicInteger index = new AtomicInteger(0); return services.get(index.getAndIncrement() % services.size()); }); private final Function\u0026lt;List\u0026lt;Service\u0026gt;, Service\u0026gt; selector; LoadBalancingStrategy(Function\u0026lt;List\u0026lt;Service\u0026gt;, Service\u0026gt; selector) { this.selector = selector; } public Service select(List\u0026lt;Service\u0026gt; services, ConcurrentHashMap\u0026lt;Service, Integer\u0026gt; weights) { if (services == null || services.isEmpty()) { throw new IllegalArgumentException(\u0026#34;Services cannot be empty\u0026#34;); } if (services.size() == 1) { return services.get(0); } List\u0026lt;Service\u0026gt; candidates = new ArrayList\u0026lt;\u0026gt;(services.size() * 100); for (Service service : services) { int weight = weights.getOrDefault(service, 1); for (int i = 0; i \u0026lt; weight; i++) { candidates.add(service); } } return selector.apply(candidates); } } } 在上述代码中，我们进行了以下优化：\n使用了 ConcurrentHashMap 来代替 HashMap，确保在并发环境下的线程安全性。 使用了枚举类型来代替字符串常量，提高代码的可读性和安全性。 使用了 Lambda 表达式和方法引用来简化负载均衡策略的实现。 使用了静态工厂方法来创建负载均衡器对象，提高代码的可读性和灵活性。 重构了 select 方法，将其实现逻辑从 LoadBalancer 类中抽离出来，并优化了权重的处理逻辑。 缓存 缓存可以提高应用程序的性能和响应速度，减少对数据库等后端资源的访问。使用 Ambassador 设计模式可以将缓存部署在应用程序的前端，将请求转发给缓存服务器进行处理，减少对后端资源的访问，提高系统的性能和响应速度。\n以下是一个使用 Java 实现的简单示例，演示了如何使用 Ambassador 设计模式将请求转发给缓存服务器：\n假设我们有一个简单的电子商务应用程序，用户可以浏览商品、下单、支付等操作。为了提高系统的性能和响应速度，我们可以在应用程序的前端部署一个缓存服务器，并使用 Ambassador 设计模式将请求转发给缓存服务器进行处理。在这个应用程序中，我们假设有一个名为 ProductService 的服务，用于获取商品信息。我们可以在应用程序的前端部署一个缓存服务器，并使用 Ambassador 设计模式将请求转发给缓存服务器。\n首先，我们需要定义一个 ProductService 接口，用于获取商品信息：\npublic interface ProductService { Product getProductById(String id); } 接下来，我们定义一个 ProductServiceImpl 类，实现 ProductService 接口，并用于从后端数据库获取商品信息：\npublic class ProductServiceImpl implements ProductService { @Override public Product getProductById(String id) { // 从后端数据库获取商品信息 return new Product(id, \u0026#34;Product \u0026#34; + id); } } 然后，我们定义一个 ProductCache 类，用于缓存商品信息：\npublic class ProductCache { private final Map\u0026lt;String, Product\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); public Product getProductById(String id) { return cache.get(id); } public void putProduct(Product product) { cache.put(product.getId(), product); } } 接下来，我们定义一个 ProductCacheService 类，实现 ProductService 接口，并用于从缓存服务器获取商品信息。如果缓存服务器中没有所需的数据，那么就将请求转发给后端服务进行处理，并将处理结果缓存起来：\npublic class ProductCacheService implements ProductService { private final ProductService backendService; private final ProductCache cache; public ProductCacheService(ProductService backendService, ProductCache cache) { this.backendService = backendService; this.cache = cache; } @Override public Product getProductById(String id) { Product product = cache.getProductById(id); if (product == null) { // 缓存服务器中没有所需的数据，将请求转发给后端服务进行处理 product = backendService.getProductById(id); // 将处理结果缓存起来，以便后续的请求可以直接从缓存服务器获取数据 cache.putProduct(product); } return product; } } 最后，我们定义一个 ProductServiceAmbassador 类，用于接收来自应用程序的请求，并根据一定的规则将请求转发给缓存服务器或后端服务。\npublic class ProductServiceAmbassador implements ProductService { private final ProductService cacheService; private final ProductService backendService; private final Map\u0026lt;String, Long\u0026gt; cachedIds = new ConcurrentHashMap\u0026lt;\u0026gt;(); private final long cacheExpireTime = 60 * 1000L; // 缓存过期时间为 60 秒 @Autowired public ProductServiceAmbassador(ProductService cacheService, ProductService backendService) { this.cacheService = cacheService; this.backendService = backendService; } @Override public Product getProductById(String id) { Long cachedTime = cachedIds.get(id); // 如果商品 ID 在缓存中存在，并且缓存未过期，那么就直接返回缓存中的商品信息 if (cachedTime != null \u0026amp;\u0026amp; System.currentTimeMillis() - cachedTime \u0026lt; cacheExpireTime) { return cacheService.getProductById(id); } // 如果商品 ID 在缓存中不存在，或者缓存已过期，那么就将请求转发给后端服务进行处理，并将处理结果缓存起来 Product product = backendService.getProductById(id); cacheService.putProduct(product); cachedIds.put(id, System.currentTimeMillis()); return product; } } 服务发现和路由 在分布式系统中，服务发现和路由通常用于将请求路由到正确的服务实例上，以实现高可用性和容错性。使用 Ambassador 设计模式可以实现服务发现和路由，将请求路由到正确的服务实例上，从而提高系统的可用性和性能。\n以下是一个使用 Ambassador 设计模式实现服务发现和路由的 Java 示例代码：\npublic interface ProductService { Product getProductById(String id); } public class Product { private String id; private String name; public Product(String id, String name) { this.id = id; this.name = name; } public String getId() { return id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } public interface ProductDiscoveryClient { List\u0026lt;String\u0026gt; getInstances(); } public class ProductDiscoveryClientImpl implements ProductDiscoveryClient { @Override public List\u0026lt;String\u0026gt; getInstances() { // 假装从服务注册中心获取服务实例列表 return Arrays.asList(\u0026#34;http://localhost:8080\u0026#34;, \u0026#34;http://localhost:8081\u0026#34;, \u0026#34;http://localhost:8082\u0026#34;); } } public interface ProductRoutingStrategy { String getRoute(String productId, List\u0026lt;String\u0026gt; instances); } public class ProductRoutingStrategyImpl implements ProductRoutingStrategy { @Override public String getRoute(String productId, List\u0026lt;String\u0026gt; instances) { // 假装使用负载均衡算法选择一个服务实例 int index = new Random().nextInt(instances.size()); return instances.get(index) + \u0026#34;/product/\u0026#34; + productId; } } public class ProductServiceAmbassador implements ProductService { private final ProductDiscoveryClient discoveryClient; private final ProductRoutingStrategy routingStrategy; private final RestTemplate restTemplate; public ProductServiceAmbassador(ProductDiscoveryClient discoveryClient, ProductRoutingStrategy routingStrategy) { this.discoveryClient = discoveryClient; this.routingStrategy = routingStrategy; this.restTemplate = new RestTemplate(); } @Override public Product getProductById(String id) { List\u0026lt;String\u0026gt; instances = discoveryClient.getInstances(); String route = routingStrategy.getRoute(id, instances); ResponseEntity\u0026lt;Product\u0026gt; response = restTemplate.getForEntity(route, Product.class); return response.getBody(); } } 在这个示例中，我们定义了一个 ProductService 接口和一个 Product 类，用于表示商品服务和商品信息。然后，我们定义了一个 ProductDiscoveryClient 接口和一个 ProductDiscoveryClientImpl 类，用于获取服务实例列表。在 ProductDiscoveryClientImpl 类中，我们假装从服务注册中心获取服务实例列表，这里我们将服务实例列表硬编码为三个本地的 HTTP 地址。\n接下来，我们定义了一个 ProductRoutingStrategy 接口和一个 ProductRoutingStrategyImpl 类，用于选择服务实例。在 ProductRoutingStrategyImpl 类中，我们使用了随机负载均衡算法来选择一个服务实例，并将商品 ID 和服务实例的 URL 拼接在一起，形成最终的路由信息。\n在最后，我们定义了一个 ProductServiceAmbassador 类，用于实现商品服务的代理。在 ProductServiceAmbassador 类中，我们使用了依赖注入（DI）的方式来注入 ProductDiscoveryClient 和 ProductRoutingStrategy 的实现类。在 getProductById 方法中，我们首先通过 ProductDiscoveryClient 获取服务实例列表，然后使用 ProductRoutingStrategy 选择一个服务实例，并将商品 ID 和服务实例的 URL 拼接在一起，形成最终的路由信息。最后，我们使用 RestTemplate 发送 HTTP GET 请求，并将响应的 JSON 数据转换为 Product 对象返回。\n使用 Ambassador 设计模式可以实现服务发现和路由，从而提高系统的可用性和性能，使得服务消费者无需关心服务实例的具体位置和负载均衡算法，只需要通过代理对象来访问服务即可。\n日志记录和监控 在分布式系统中，日志记录和监控通常用于跟踪服务的运行状态和性能指标，以便进行故障排除和性能优化。使用 Ambassador 设计模式可以将日志记录和监控部署在应用程序的前端，监控服务的运行状态和性能指标，从而实现故障排除和性能优化。\n以下是一个使用 Ambassador 设计模式实现日志记录和监控的 Java 示例代码：\npublic interface ProductService { Product getProductById(String id); } public class Product { private String id; private String name; public Product(String id, String name) { this.id = id; this.name = name; } public String getId() { return id; } public String getName() { return name; } public void setName(String name) { this.name = name; } } public interface ProductLogger { void logRequest(String id); void logResponse(String id, Product product); } public class ProductLoggerImpl implements ProductLogger { private final Logger logger = LoggerFactory.getLogger(ProductLoggerImpl.class); @Override public void logRequest(String id) { logger.info(\u0026#34;Requesting product with ID: {}\u0026#34;, id); } @Override public void logResponse(String id, Product product) { logger.info(\u0026#34;Received product with ID: {}, Name: {}\u0026#34;, id, product.getName()); } } public interface ProductMonitor { void recordLatency(String id, long latency); void incrementCounter(String id); } public class ProductMonitorImpl implements ProductMonitor { private final StatsDClient statsd; public ProductMonitorImpl(String host, int port) { this.statsd = new NonBlockingStatsDClient(\u0026#34;product-service\u0026#34;, host, port); } @Override public void recordLatency(String id, long latency) { statsd.recordExecutionTime(\u0026#34;product.latency\u0026#34;, latency, \u0026#34;id:\u0026#34; + id); } @Override public void incrementCounter(String id) { statsd.increment(\u0026#34;product.counter\u0026#34;, \u0026#34;id:\u0026#34; + id); } } public class ProductServiceAmbassador implements ProductService { private final ProductService productService; private final ProductLogger logger; private final ProductMonitor monitor; public ProductServiceAmbassador(ProductService productService, ProductLogger logger, ProductMonitor monitor) { this.productService = productService; this.logger = logger; this.monitor = monitor; } @Override public Product getProductById(String id) { logger.logRequest(id); long startTime = System.currentTimeMillis(); Product product = productService.getProductById(id); long endTime = System.currentTimeMillis(); logger.logResponse(id, product); long latency = endTime - startTime; monitor.recordLatency(id, latency); monitor.incrementCounter(id); return product; } } 在这个示例中，我们定义了一个 ProductService 接口和一个 Product 类，用于表示商品服务和商品信息。然后，我们定义了一个 ProductLogger 接口和一个 ProductLoggerImpl 类，用于记录请求和响应的日志信息。在 ProductLoggerImpl 类中，我们使用了 SLF4J 日志框架来记录日志信息。\n接下来，我们定义了一个 ProductMonitor 接口和一个 ProductMonitorImpl 类，用于记录运行状态和性能指标。在 ProductMonitorImpl 类中，我们使用了 StatsD 客户端来记录运行状态和性能指标，例如请求的延迟和调用次数等。在 ProductMonitorImpl 的构造函数中，我们可以指定 StatsD 客户端的主机和端口。\n最后，我们定义了一个 ProductServiceAmbassador 类，用于实现商品服务的代理。在 ProductServiceAmbassador 类中，我们通过依赖注入（DI）的方式将 ProductService、ProductLogger 和 ProductMonitor 的实现类注入到构造函数中。在 getProductById 方法中，我们首先调用 ProductLogger 的 logRequest 方法来记录请求的日志信息。然后，我们使用 System.currentTimeMillis() 来记录请求的开始时间，然后调用 ProductService 的 getProductById 方法来获取商品信息。接下来，我们使用 System.currentTimeMillis() 来记录请求的结束时间，并调用 ProductLogger 的 logResponse 方法来记录响应的日志信息。最后，我们计算请求的延迟，并调用 ProductMonitor 的 recordLatency 方法来记录请求的延迟，调用 ProductMonitor 的 incrementCounter 方法来记录调用次数。\n使用 Ambassador 设计模式可以将日志记录和监控部署在应用程序的前端，从而监控服务的运行状态和性能指标，并提供实时的故障排除和性能优化。由于日志记录和监控是与业务逻辑解耦的，因此我们可以随时在运行时添加、删除或更改日志记录和监控的实现，而不影响应用程序的正常运行。\n已知使用 Ambassador 设计模式通常用于分布式系统中，用于解决服务间的通信问题和负载均衡问题。许多开源框架和工具都使用了 Ambassador 模式来实现服务代理和增强等功能。以下是一些常见的使用了 Ambassador 模式的开源框架和工具：\nIstio：Istio 是一个流行的服务网格框架，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如流量管理、安全认证、监控和日志等。 Envoy：Envoy 是一个高性能的代理服务器，它使用了 Ambassador 模式来实现负载均衡、流量转发和服务代理等功能。 Linkerd：Linkerd 是另一个流行的服务网格框架，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如负载均衡、故障恢复和流量管理等。 Open Service Mesh：Open Service Mesh 是一个开源的服务网格框架，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如流量管理、安全认证和监控等。 Consul：Consul 是一个流行的服务发现和配置工具，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如负载均衡、健康检查和故障恢复等。 Kubernetes：Kubernetes 是一个流行的容器编排平台，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如服务发现、负载均衡和流量管理等。 Nginx：Nginx 是一个高性能的 Web 服务器和反向代理服务器，它使用了 Ambassador 模式来实现负载均衡、流量转发和服务代理等功能。 Kong：Kong 是一个开源的 API 网关，它使用了 Ambassador 模式来实现流量管理、安全认证和监控等功能。 Traefik：Traefik 是一个流行的反向代理和负载均衡器，它使用了 Ambassador 模式来实现服务代理和增强等功能，例如动态配置、自动发现和流量转发等。 当然，Java 生态系统中也有许多开源框架和工具使用了 Ambassador 模式。以下是其中的一些：\nSpring Cloud Netflix：Spring Cloud Netflix 是一个流行的微服务框架，它使用了 Netflix OSS 中的 Ribbon 和 Zuul 组件来实现服务代理和增强等功能，例如负载均衡、服务发现和路由等。 Spring Cloud Gateway：Spring Cloud Gateway 是 Spring Cloud 生态系统中的一个新型 API 网关，它使用了 Reactor Netty 和 Spring WebFlux 等技术来实现服务代理和增强等功能，例如负载均衡、路由和限流等。 Netflix OSS：Netflix OSS 是 Netflix 开源的一组分布式系统工具，其中包括了许多使用了 Ambassador 模式的组件，例如 Ribbon、Hystrix、Zuul 和 Eureka 等。 Micronaut：Micronaut 是一个轻量级的 Java 框架，它使用了 Netty 和 Reactive Streams 等技术来实现服务代理和增强等功能，例如负载均衡、服务发现和路由等。 Vert.x：Vert.x 是一个高性能的异步编程框架，它使用了 Netty 和 Reactive Streams 等技术来实现服务代理和增强等功能，例如负载均衡、路由和限流等。 Spring Cloud Gateway Spring Cloud Gateway 是 Spring Cloud 生态系统中的一个新型 API 网关，它使用了 Reactor Netty 和 Spring WebFlux 等技术来实现服务代理和增强等功能。它的设计理念就是基于 Ambassador 模式来构建的，它将每个后端服务都看作一个独立的实体，通过一个中央入口点来统一管理和控制。\n下面通过代码来说明 Spring Cloud Gateway 如何使用 Ambassador 模式。假设我们有两个后端服务，一个是 user-service，一个是 order-service，我们希望通过 Spring Cloud Gateway 来实现负载均衡和路由的功能。\n首先，我们需要添加 Spring Cloud Gateway 依赖，可以在 Maven 中添加以下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 然后，我们需要在配置文件中配置 Spring Cloud Gateway，例如 application.yml 文件：\nspring: cloud: gateway: routes: - id: user-service uri: lb://user-service predicates: - Path=/users/** - id: order-service uri: lb://order-service predicates: - Path=/orders/** 这段配置代码的意思是，我们定义了两个路由规则，一个是对于 /users/** 的请求，将会被路由到 user-service 服务上，另一个是对于 /orders/** 的请求，将会被路由到 order-service 服务上。其中，uri 前缀的 lb:// 表示使用负载均衡的方式来路由请求，这里我们使用了 Spring Cloud LoadBalancer 组件来实现负载均衡的功能。\n最后，我们需要在启动类上添加 @EnableGateway 注解，来启用 Spring Cloud Gateway：\n@SpringBootApplication @EnableDiscoveryClient @EnableGateway public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 这样，我们就完成了 Spring Cloud Gateway 的配置和启用。通过以上的配置和代码，我们实现了 Ambassador 模式的基本功能，即通过一个中央入口点来统一管理和控制后端服务。同时，由于 Spring Cloud Gateway 基于 Reactor Netty 和 Spring WebFlux 等技术实现，它也具有非常高的性能和可扩展性。\nSpring Cloud Gateway 源码中的实现方式，主要是基于 Reactor Netty 和 Spring WebFlux 框架来实现的。它的核心组件是 GatewayFilter 和 RouteLocator，其中 GatewayFilter 用于实现各种过滤器，例如请求转发、重定向、限流和认证等，而 RouteLocator 用于实现动态路由和负载均衡等功能。\n具体来说，Spring Cloud Gateway 的工作原理如下：\nSpring Cloud Gateway 接收客户端的请求，然后根据配置文件中的路由规则，选择一个合适的路由器进行处理。 路由器会根据请求的 URL 和配置文件中的路由规则，选择一个或多个过滤器对请求进行处理。过滤器可以选择性地修改请求和响应，或者中断请求并返回响应。 过滤器将处理后的请求发送到后端服务，然后将响应返回给客户端。 在处理请求和响应的过程中，Spring Cloud Gateway 支持多种协议和格式，例如 HTTP、WebSocket、JSON 和 XML 等。 在 Spring Cloud Gateway 的源码中，它的核心组件是 GatewayFilter 和 RouteLocator。其中，GatewayFilter 是一个过滤器接口，它定义了一个过滤器的基本方法链，开发者可以通过实现 GatewayFilter 接口来实现自定义的过滤器。而 RouteLocator 则是一个路由规则接口，它定义了一个动态路由表，开发者可以通过实现 RouteLocator 接口来实现自定义的路由规则，例如基于服务发现的路由规则。\nSpring Cloud Gateway 支持 WebSocket 协议。WebSocket 是一种在单个 TCP 连接上进行全双工通信的协议，它允许客户端和服务器之间进行实时交互和通信。Spring Cloud Gateway 通过支持 WebSocket 协议，可以实现实时通信、推送和广播等功能。\n要在 Spring Cloud Gateway 中支持 WebSocket 协议，需要进行以下步骤：\n引入 Spring Cloud Gateway WebSocket 依赖，可以在 Maven 中添加以下依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-gateway-websocket\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 配置 Spring Cloud Gateway，需要在 application.yml 或 application.properties 文件中添加以下配置：\nspring: cloud: gateway: websockets: enabled: true 这段配置代码的意思是，启用 Spring Cloud Gateway 的 WebSocket 支持。 配置 WebSocket 路由，需要在 application.yml 或 application.properties 文件中添加以下配置：\nspring: cloud: gateway: routes: - id: ws-route uri: ws://localhost:8080 predicates: - Path=/ws/** 这段配置代码的意思是，将 /ws/** 的请求路由到 uri 为 ws://localhost:8080 的 WebSocket 服务上。\n实现 WebSocket 处理器，需要编写一个实现 WebSocketHandler 接口的处理器，例如：\n@Component public class EchoWebSocketHandler implements WebSocketHandler { @Override public Mono\u0026lt;Void\u0026gt; handle(WebSocketSession session) { // 处理 WebSocketSession return session.send(session.receive().map(msg -\u0026gt; session.textMessage(\u0026#34;Echo: \u0026#34; + msg.getPayloadAsText()))); } } 这段代码的意思是，实现一个处理器，用来处理 WebSocketSession。在此示例中，处理器会将接收到的消息进行回显，并返回给客户端。\n配置 WebSocket 处理器，需要在 application.yml 或 application.properties 文件中添加以下配置：\nspring: cloud: gateway: routes: - id: ws-route uri: ws://localhost:8080 predicates: - Path=/ws/** filters: - name: WebSocket args: handler: echoWebSocketHandler subprotocols: subprotocol1, subprotocol2 这段配置代码的意思是，将 WebSocket 处理器 echoWebSocketHandler 绑定到 WebSocket 路由上，并指定了子协议 subprotocol1 和 subprotocol2。\n这样，我们就完成了在 Spring Cloud Gateway 中支持 WebSocket 协议的配置和代码实现。通过以上的配置和代码，我们可以在 Spring Cloud Gateway 上实现 WebSocket 的功能，例如实时通信、推送和广播等。\n相关模式 Proxy 其他 Ambassador 和 AOP Ambassador 设计模式和 AOP（面向切面编程）都是用于实现横切关注点的设计模式。它们都可以在不修改现有代码的情况下，往程序中添加一些额外的行为，例如日志记录、性能监控、安全验证等。\nAmbassador 设计模式是一种结构型设计模式，它通过代理对象来隐藏底层服务的实现细节，并提供一些额外的功能，例如服务发现、负载均衡、日志记录和监控等。在 Ambassador 设计模式中，代理对象和原始对象都实现了同一个接口，代理对象负责将调用转发到原始对象，并在调用前后执行一些额外的逻辑。\nAOP 也是一种结构型设计模式，它通过将横切关注点从业务逻辑中分离出来，实现了一种基于切面的模块化设计。在 AOP 中，横切关注点被封装成切面，并通过切点和通知来定义切面的行为。在程序运行期间，AOP 框架会动态地将切面织入到目标对象的方法调用中，从而实现切面的功能。\n虽然 Ambassador 设计模式和 AOP 都可以实现横切关注点，但它们的应用场景和目的略有不同。Ambassador 设计模式通常用于实现与底层服务相关的功能，例如服务发现、负载均衡、日志记录和监控等。而 AOP 则更加通用，可以用于实现任何与业务逻辑无关的功能，例如事务管理、安全验证、性能监控等。此外，AOP 还可以通过切面的织入顺序来实现一些复杂的功能，例如事务嵌套和并发控制等。\n在实践中，Ambassador 设计模式和 AOP 可以结合使用，从而实现更加灵活和可扩展的应用程序设计。例如，在使用 Ambassador 设计模式实现服务调用时，我们可以使用 AOP 来记录请求和响应的日志信息，或者实现安全验证和性能监控等功能。在这种情况下，Ambassador 设计模式和 AOP 通常是相互补充的，可以在不同的层次上实现横切关注点的功能。\nAmbassador 和代理 Ambassador 设计模式和代理模式都是结构型设计模式，它们都使用代理对象来隐藏真实对象的实现细节，并提供一些额外的功能。然而，它们的目的和实现方式略有不同。\n代理模式是一种结构型设计模式，它通过代理对象来控制对真实对象的访问。在代理模式中，代理对象和真实对象实现相同的接口，代理对象负责将方法调用传递给真实对象，并在此基础上添加一些额外的逻辑，例如权限控制、缓存、远程访问等。代理模式可以在不修改现有代码的情况下，为真实对象提供额外的功能和保护。\nAmbassador 设计模式也是一种结构型设计模式，它通过代理对象来隐藏底层服务的实现细节，并提供一些额外的功能，例如服务发现、负载均衡、日志记录和监控等。在 Ambassador 设计模式中，代理对象和底层服务实现相同的接口，代理对象负责将调用转发到底层服务，并在此基础上添加一些额外的逻辑。Ambassador 设计模式通常用于实现与底层服务相关的功能。\nAmbassador 设计模式和代理模式在某些方面确实非常相似，它们都使用代理对象来隐藏真实对象的实现细节，并提供一些额外的功能。然而，它们的目的和应用场景略有不同，这也是它们的区别所在。\n代理模式通常用于控制对真实对象的访问，例如权限控制、缓存、远程访问等。它的重点在于实现对真实对象的保护和控制。代理模式的应用场景非常广泛，可以用于任何需要对真实对象进行访问控制和保护的场景。\nAmbassador 设计模式则更加专注于底层服务的代理和增强，例如服务发现、负载均衡、日志记录和监控等。它通常用于分布式系统中，用于解决服务间的通信问题和负载均衡问题。Ambassador 设计模式的重点在于为底层服务提供代理和增强功能，以便更好地管理和控制底层服务。\n虽然 Ambassador 设计模式和代理模式在某些方面非常相似，但它们在实际应用中通常被用于不同的场景和目的。在实践中，我们可以根据具体的需求和应用场景来选择使用哪种模式，或者将它们结合起来使用，以实现更加灵活和可扩展的应用程序设计。\n参考文章 Ambassador Pattern: 该文章介绍了 Ambassador 模式的概念和应用场景，并提供了一些实际案例供参考。 Design Patterns for Microservices: Ambassador, Anti-Corruption Layer, and Backends for Frontends : 这篇文章介绍了在微服务架构中使用的两种设计模式：Ambassador 模式和 Anti-corruption Layer 模式。。 The Ambassador pattern and Istio: 这篇文章介绍了如何使用 Istio 和 Ambassador 模式来实现微服务的边缘代理和服务网格。 Kubernetes — Learn Ambassador Container Pattern 介绍了如何在 Kubernetes 中使用 Ambassador 模式来解决微服务通信的问题。 Ambassador vs API Gateway: 该文章对比了 Ambassador 模式和传统的 API 网关的优缺点，分析了它们在不同场景下的应用和适用性。 ","permalink":"https://blog.chensoul.cc/posts/2023/07/06/java-design-patterns-ambassador/","summary":"本文主要介绍 Ambassador 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 在客户端上提供帮助程序服务实例，并从共享资源上转移常用功能。\nAmbassador 设计模式的主要目的是将客户端应用程序与远程服务器之间的通信细节隔离开来，从而使客户端应用程序可以专注于自己的业务逻辑，而不必关注网络通信细节和错误处理。\n在传统的客户端应用程序中，通常需要处理大量的网络通信细节和错误处理，这会使代码变得复杂且难以维护。而使用 Ambassador 设计模式可以将这些细节和处理逻辑集中在一个单独的类中，从而使客户端应用程序的代码更加简洁、易于维护和扩展。\n此外，使用 Ambassador 设计模式还可以提高客户端应用程序与远程服务器之间的通信安全性和可靠性。例如，Ambassador 类可以负责统一处理所有的网络通信，从而可以更轻松地实现安全性和可靠性控制。\n解释 假设有一个旧版的远程服务，该服务提供了许多客户端访问的功能，但由于用户的大量请求，导致连接问题变得普遍。此外，新的请求频率规则需要同时实现延迟检测和客户端日志功能。为了解决这些问题，可以使用 Ambassador 设计模式。\n微软文档 做了如下阐述\n可以将大使服务视为与客户端位于同一位置的进程外代理。 此模式对于以语言不可知的方式减轻常见的客户端连接任务（例如监视，日志记录，路由，安全性（如 TLS）和弹性模式）的工作很有用。 它通常与旧版应用程序或其他难以修改的应用程序一起使用，以扩展其网络功能。 它还可以使专业团队实现这些功能。\n在该模式中，可以创建一个 Ambassador 类来充当客户端应用程序和远程服务之间的代理。Ambassador 类负责处理所有的网络通信细节和错误处理，并实现新的请求频率规则，包括延迟检测和客户端日志功能。\n具体来说，Ambassador 类可以实现以下功能：\n延迟检测：在请求到达远程服务之前，Ambassador 类可以检测请求的时间戳，并计算出请求的延迟时间。如果请求的延迟时间超过了预设的阈值，Ambassador 类可以将请求拒绝。 客户端日志功能：Ambassador 类可以记录请求的时间戳、请求的内容和响应的内容，并将这些信息保存到客户端的日志文件中。这样可以帮助客户端应用程序进行调试和故障排除。 连接问题处理：Ambassador 类可以监控远程服务的连接状态，并在连接出现问题时进行自动重试。同时，Ambassador 类还可以实现一些优化策略，例如使用连接池等，以提高连接的可靠性和性能。 程序示例\n有了上面的介绍我们将在这个例子中模仿功能。我们有一个用远程服务实现的接口，同时也是大使服务。\ninterface RemoteServiceInterface { long doRemoteFunction(int value) throws Exception; } 表示为单例的远程服务。\npublic class RemoteService implements RemoteServiceInterface { private static final Logger LOGGER = LoggerFactory.getLogger(RemoteService.class); private static RemoteService service = null; static synchronized RemoteService getRemoteService() { if (service == null) { service = new RemoteService(); } return service; } private RemoteService() {} @Override public long doRemoteFunction(int value) { long waitTime = (long) Math.","title":"Java设计模式：Ambassador"},{"content":"前言 本篇是对 2023-06-19 到 2023-06-25 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这周因为端午节，只上三天班，放三天假。祝愿所有父母端午安康！\n读书 本周阅读时长 15 分钟，主要是阅读《Java 高并发核心编程：多线程、锁、JVM、JUC、高并发设计模式》。\n健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周尚未跑步。最近上班没有带饭，每天中午吃饭都超标了，每天也没有测量体重，严重怀疑体重又涨了几斤。这个月也快结束了，下个月继续减肥。\n理财 这周总计支出 1027 元，明细如下：\n6 月 25 日：30 元\n6 月 24 日：133 元\n6 月 23 日：462 元\n6 月 22 日：69 元\n6 月 21 日：147 元\n6 月 20 日：159 元\n6 月 19 日：27 元\n陪家人 农历 5 月 4 日，六舅走了。端午节的三天假期，主要是回去奔丧，送六舅最后一程。\n算了下日子，老爸来阳逻快一个月了，老婆放下手上的工作回来照顾老爸也有两周时间了。看得出来，老婆有效疲惫了。老爸现在可以走，但是走的不够利索。希望老爸恢复得再快些，让老婆回去上班。如有可能，下周末把老爸送回老家，让老爸自己在家照顾自己。农村的空气好些，不会憋得慌。但还是担心天气太热，老爸照顾不好自己。在照顾老爸的事情，除了能够依靠老婆，其他谁都靠不上。但是，老婆也有工作要处理，我的工作又不能辞掉。这大抵算是八零后的压力吧，父亲在买房买车结婚上没有帮上忙，反而还会因为自己不好好照顾自己而给子女增加负担。总是跟老爸说这该做那不该做，老爸就像个孩子似的，一点都不听话。\n周六，在黄石开牙医院的表哥的女儿考上墨尔本的研究生在老家办酒。也许是上了年纪的缘故，也许是老爸喜欢凑热闹，老爸想去喝酒。于是，成全了老爸的心愿。老爸年纪大了，尽可能的满足老爸的一些想法和心愿，尽可能的带老爸体验\u0026quot;新鲜\u0026quot;的事物，比如，看电影，旅游。于是，周四带老爸去看了电影《消失的她》。还有什么事情可以做呢？这样一想，老爸年纪越来越大了，腿脚越来越不利索，能够做的事情越来越少了。趁光阴还在，多陪陪父母，常回家看看。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成五篇博客：\n[译]微服务设计模式 Java 设计模式：Aggregator Microservices Python 学习 5：函数 [译]Python 模块和包-简介 [译]用 Bottle 开发 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。\n📌2023-06-24 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 6 月 24 日 星期六 农历五月初七 1. 内蒙古、上海、云南等地陆续公布 2023 高考分数线。 2. 全国多地仍有超 40℃ 高温，中国气象局启动四级应急响应。 3. 数字人民币无网无电支付，在全国轨道交通应用场景首次落地。 4. 迈入动车时代！7 月 1 日，复兴号将在青藏铁路上运营。 5. 深圳已收到 1635 件个人破产申请，原因包括超前消费、经营不善等。 6. 女篮亚洲杯最新实力榜，中国女篮反超日本升至第一位。 7. 银川烧烤店爆炸事故预估保险赔付超 1400 万元，首笔赔付款已到位。 8. 辽宁营口一钢铁厂烫伤事故，4 死 5 伤，专家组初步认定系设备故障所致。 9. 第 28 届白玉兰奖揭晓：演员雷佳音、吴越分获最佳男、女主角。 10. 巴菲特再捐 46 亿美元股票，承诺 99％以上的遗产将用于慈善。 11. 日本广岛和平纪念公园将与美国珍珠港公园结为“姐妹公园”。 12. 沙特宣布：退出 2030 年世界杯申办工作。 13. 莫迪在美国放出豪言：印度很快将是世界第三大经济体。 14. 美国“里根”号航母将停靠越南港口，越方称“正常友好交流”。 15. 西方官员称乌反攻早期\u0026quot;低于预期\u0026quot;，乌官员：主要反攻还没开始，秋冬再看成果。 【微语】心有万万念，一念一世界。静，不是耳边无声，而是心中无争。 新闻来源：https://www.163.com/dy/article/I7VSKUF90534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-06-22 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 6 月 22 日 星期四 农历五月初五 端午节 1. 三部门：新能源汽车免征购置税延续至 2025 年底，2026-2027 年减半征收。 2. 医保局：提速医保转移接续，将办理时长由 45 个工作日压缩为 15 个工作日。 3. 教育部：建立高校毕业生毕业去向登记制度。 4. 今年端午预计旅游人次达 1 亿，以周边游、近程游为主，民宿价格高于五一。 5. 高温黄色预警：预计今天白天，京津冀等地最高气温可达 40℃ 以上。 6. 中国台球协会：处罚 10 名打假球的球员，其中梁文博、李行被终身禁赛。 7. 厦门立法禁斑马线上刷手机，违者或被罚款 50 元，8 月 1 日起施行。 8. 浙江多地开放共享机关企事业单位服务资源，含会议室、健身房等。 9. 广州拟限行\u0026quot;电驴\u0026quot;：不到 6 人就拥有 1 辆，远超道路承载能力。 10. 福建大田移风易俗见成效：文明新风悄然兴起，结婚出现零彩礼。 11. 熊猫公园全面启动建设，北京将迎来近 50 只大熊猫。 12. 研究：喜马拉雅冰川或在本世纪末消融 80%，影响亚洲 20 亿人。 13. 中卡再签重磅天然气协议：27 年供气长协，中石油入股卡塔尔超大气田。 14. 英国债务超 2.5 万亿英镑，60 余年来首超国内生产总值。 15. 欧盟就对俄实施第 11 轮制裁达成一致。 【微语】端午佳节至，风摇艾草，粽叶飘香，愿你夏日清平，喜乐安康。 新闻来源：https://www.163.com/dy/article/I7QN8IJB0534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-06-21 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 6 月 21 日 星期三 农历五月初四 今日夏至 1. 降息来了：一年期 LPR 为 3.55%，五年期以上 LPR 为 4.2%，均下降 10 个基点。 2. 教育部发布全国高校名单，截至目前，全国高等学校共计 3072 所。 3. 大陆恢复台地区番荔枝输入，台农：期盼这天到来已等近 3 年。 4. 北京市未成年人保护宣教联盟成立，旨在推动北京市未成年人保护工作高质量发展。 5. 广州快递新规：快递入柜需收件人同意，虚假签收快递最高可罚三万。 6. 杭州拟立法传承发展老字号，鼓励职业学校开设传统技艺课程。 7. 沈阳：全日制中专以上毕业生购房可享受全额契税补贴。 8. 浙江：三年将培育千名省级乡村工匠名师，其子女教育、购房等可享优惠。 9. 内蒙古前五月安全生产事故死亡 160 人，新井煤矿事故失联者全部遇难。 10. 阿里集团宣布换帅：张勇 9 月卸任董事长和 CEO，蔡崇信和吴泳铭接任。 11. 国足热身赛 2-0 巴勒斯坦，终结 14 年不胜对手尴尬纪录。 12. 爱尔兰为减排拟在今后三年内宰杀约 20 万头牛，以达到其温室气体减排目标。 13. 统计：连续 3 年，韩国 60-69 岁就业人口数高于 20-29 岁年龄段。 14. 外媒：印度股市市值创新高，已超英法，位居全球第四。 15. 孟加拉国正式申请加入金砖国家，外交部：欢迎更多伙伴加入。 【微语】夏至蝉始鸣，万物皆繁盛，愿所有春天里的酝酿，都在这个夏天热烈绽放，一路芬芳，不负韶华。 新闻来源：https://www.163.com/dy/article/I7O5BKR40534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-06-20 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 6 月 19 日 星期一 农历五月初二 1. 气象台：预计 19 日至 21 日南方有大范围较强降水过程，东北等地高温天气减弱。 2. 国家防总：将防汛四级应急响应范围扩展至桂苏浙皖赣鄂湘黔八省份。 3. 农业农村部：全国已收获冬小麦面积超过 2.97 亿亩，收获进度过九成五。 4. 海关总署：去年，中国跨境电商进出口规模首次突破 2 万亿元人民币。 5. 618 最新调查：75%的人购物意愿比去年减少，60%的人预算不超过 500 元。 6. 京东 618 最新数据：广东人蝉联购买力全国第一。 7. 重庆：8 月 1 日起，餐饮业、旅游住宿业不得主动提供一次性用品。 8. 天津：拟提高首套房公积金贷款额度，最高 100 万元。 9. 华为轮值董事长胡厚崑：最新超快充技术可 15 分钟充满一辆新能源车。 10. 经济学家李实：我国中等收入群体或已达 4.6 亿，每月挣 3000 元左右就算。 11. 灯塔专业版数据：2023 年端午档新片预售总票房突破 3000 万。 12. 泰国将加快中国游客入境签证审批，争取 7 天内完成。 13. 印度北部遭受极端热浪侵袭：3 天内已有 98 人死于高温。 14. 阿富汗塔利班政府将美国撤军日定为全国假日，每年庆祝。 15. 乌方称基辅计划最大限度消灭俄罗斯人，克宫警告：俄罗斯人会就此实施惩罚。 【微语】努力的意义在于：以后日子里，放眼望去，全都是自己喜欢的人和事。 新闻来源：https://www.163.com/dy/article/I7IV8TLQ0534QBVQ.html?spss=dy_author #每日早报 #memos 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/28/weekly_review_25/","summary":"前言 本篇是对 2023-06-19 到 2023-06-25 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n这周因为端午节，只上三天班，放三天假。祝愿所有父母端午安康！\n读书 本周阅读时长 15 分钟，主要是阅读《Java 高并发核心编程：多线程、锁、JVM、JUC、高并发设计模式》。\n健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周尚未跑步。最近上班没有带饭，每天中午吃饭都超标了，每天也没有测量体重，严重怀疑体重又涨了几斤。这个月也快结束了，下个月继续减肥。\n理财 这周总计支出 1027 元，明细如下：\n6 月 25 日：30 元\n6 月 24 日：133 元\n6 月 23 日：462 元\n6 月 22 日：69 元\n6 月 21 日：147 元\n6 月 20 日：159 元\n6 月 19 日：27 元\n陪家人 农历 5 月 4 日，六舅走了。端午节的三天假期，主要是回去奔丧，送六舅最后一程。\n算了下日子，老爸来阳逻快一个月了，老婆放下手上的工作回来照顾老爸也有两周时间了。看得出来，老婆有效疲惫了。老爸现在可以走，但是走的不够利索。希望老爸恢复得再快些，让老婆回去上班。如有可能，下周末把老爸送回老家，让老爸自己在家照顾自己。农村的空气好些，不会憋得慌。但还是担心天气太热，老爸照顾不好自己。在照顾老爸的事情，除了能够依靠老婆，其他谁都靠不上。但是，老婆也有工作要处理，我的工作又不能辞掉。这大抵算是八零后的压力吧，父亲在买房买车结婚上没有帮上忙，反而还会因为自己不好好照顾自己而给子女增加负担。总是跟老爸说这该做那不该做，老爸就像个孩子似的，一点都不听话。\n周六，在黄石开牙医院的表哥的女儿考上墨尔本的研究生在老家办酒。也许是上了年纪的缘故，也许是老爸喜欢凑热闹，老爸想去喝酒。于是，成全了老爸的心愿。老爸年纪大了，尽可能的满足老爸的一些想法和心愿，尽可能的带老爸体验\u0026quot;新鲜\u0026quot;的事物，比如，看电影，旅游。于是，周四带老爸去看了电影《消失的她》。还有什么事情可以做呢？这样一想，老爸年纪越来越大了，腿脚越来越不利索，能够做的事情越来越少了。趁光阴还在，多陪陪父母，常回家看看。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成五篇博客：\n[译]微服务设计模式 Java 设计模式：Aggregator Microservices Python 学习 5：函数 [译]Python 模块和包-简介 [译]用 Bottle 开发 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。","title":"周报-25｜端午安康"},{"content":"基于微服务的应用程序的主要特征在 微服务、单体和 NoOps 中定义。它们是功能分解或领域驱动设计、定义良好的接口、明确发布的接口、单一责任原则和潜在的多语言。每项服务都是完全自主和全栈的。\n因此，更改服务实现不会影响其他服务，因为它们使用定义良好的接口进行通信。这种应用程序有几个优点，但它不是 免费的午餐，需要在 NoOps 方面付出大量努力。\n但是假设您了解构建此类应用程序所需的工作或至少其中的一部分，并且愿意跳槽。你做什么工作？您构建此类应用程序的方法是什么？\n是否有任何关于这些微服务如何相互协作的设计模式？\n应用程序和团队的功能分解是构建成功的微服务架构的关键。\n这允许您实现松耦合（REST 接口）和高内聚（多个服务可以相互组合以定义更高级别的服务或应用程序）。\n应用程序的动词（例如 Checkout）或名词（Product）是实现现有应用程序分解的有效方法之一。\n例如，产品、目录和结帐可以是三个独立的微服务，然后相互协作以提供完整的购物车体验。\n功能分解提供了敏捷性、灵活性、可扩展性和其他能力，但业务目标仍然是创建应用程序。因此，一旦识别出不同的微服务，您如何组合它们以提供应用程序的功能？\n本博客将讨论一些关于如何将微服务组合在一起的推荐模式。\n聚合微服务设计模式 第一个，也可能是最常见的，是聚合器微服务设计模式。\n在其最简单的形式中，聚合器将是一个简单的网页，它调用多个服务来实现应用程序所需的功能。由于每个服务（服务 A、服务 B 和服务 C）都使用轻量级 REST 机制公开，因此网页可以检索数据并相应地处理/显示数据。如果需要某种处理，比如将业务逻辑应用于从各个服务接收的数据，那么您可能有一个 CDI bean 可以转换数据，以便网页可以显示它。\n聚合器的另一个选择是不需要显示，它只是一个更高级别的复合微服务，可以被其他服务使用。\n在这种情况下，聚合器只需从每个单独的微服务收集数据，对其应用业务逻辑，然后将其进一步发布为 REST 端点。然后可以由需要它的其他服务使用。\n这种设计模式遵循 DRY 原则。\n如果有多个服务需要访问服务 A、B 和 C，那么建议将该逻辑抽象为一个复合微服务，并将该逻辑聚合到一个服务中。在此级别进行抽象的一个优点是各个服务，即服务 A、B 和 C，并且可以独立发展，业务需求仍然由组合微服务提供。\n请注意，每个单独的微服务都有自己的（可选）缓存和数据库。如果聚合器是一个复合微服务，那么它也可能有自己的缓存和数据库层。\n聚合器也可以在 X 轴和 Z 轴上独立缩放。因此，如果它是一个网页，那么您可以启动额外的 Web 服务器，或者如果它是一个使用 Java EE 的复合微服务，那么您可以启动额外的 WildFly 实例来满足不断增长的需求。\n代理微服务设计模式 代理微服务设计模式是聚合器的一种变体。在这种情况下，客户端不需要进行聚合，但可以根据业务需要调用不同的微服务。\n就像 Aggregator 一样，Proxy 也可以在 X 轴和 Z 轴上独立扩展。您可能喜欢这样做，因为每个单独的服务都不需要向消费者公开，而是应该通过一个界面。\n代理可能是一个哑代理，在这种情况下，它只是将请求委托给其中一项服务。或者，它可能是一个智能代理，在将响应提供给客户端之前应用一些数据转换。一个很好的例子就是可以将不同设备的表示层封装在智能代理中。\n链式微服务设计模式 链式微服务设计模式对请求产生单一的综合响应。在这种情况下，来自客户端的请求由服务 A 接收，然后服务 A 与服务 B 通信，而服务 B 又可能与服务 C 通信。\n所有服务都可能使用同步 HTTP 请求/响应消息传递。\n要记住的关键部分是客户端被阻塞，直到完成请求/响应链，即服务\u0026lt;-\u0026gt;服务 B 和服务 B\u0026lt;-\u0026gt;服务 C，完成。从服务 B 到服务 C 的请求可能看起来与从服务 A 到服务 B 的请求完全不同。\n同样，服务 B 对服务 A 的响应可能看起来与服务 C 对服务 B 的响应完全不同。无论如何，这就是不同服务增加其业务价值的全部要点。\n这里要理解的另一个重要方面是不要让链条太长。这一点很重要，因为链的同步特性在客户端看起来像是一个漫长的等待，特别是如果它是一个等待显示响应的网页。\n这个阻塞请求/响应有变通方法，并在后续设计模式中讨论。\n具有单个微服务的链称为单例链。这可能允许链在以后扩展。\n分支微服务设计模式 分支微服务设计模式扩展了聚合器设计模式，并允许同时处理来自两个可能互斥的微服务链的响应。此模式还可用于根据业务需求调用不同的链或单个链。\n服务 A（网页或复合微服务）可以同时调用两个不同的链，在这种情况下，这类似于聚合器设计模式。或者，服务 A 可以根据从客户端收到的请求仅调用一个链。\n这可以使用 JAX-RS 或 Camel 端点的路由进行配置，并且需要动态配置。\n共享数据微服务设计模式 微服务的设计原则之一是自治。这意味着该服务是全栈式的，并且可以控制所有组件——UI、中间件、持久性、事务。这允许服务是多语言的，并使用正确的工具来完成正确的工作。\n例如，如果可以使用 NoSQL 数据存储而不是将数据塞入 SQL 数据库中更合适的话。\n然而，一个典型的问题，尤其是在从现有的单体应用程序重构时，是数据库规范化，这样每个微服务都有正确数量的数据——仅此而已。\n即使在单体应用程序中仅使用 SQL 数据库，对数据库进行非规范化也会导致数据重复，并可能导致不一致。在过渡阶段，一些应用程序可能会受益于共享数据微服务设计模式。\n在这种设计模式中，一些微服务（可能在一个链中）可以共享缓存和数据库存储。\n这只有在两种服务之间存在强耦合时才有意义。有些人可能认为这是一种反模式，但在某些情况下业务需求可能需要遵循这一点。对于基于微服务设计的全新应用程序，这肯定是一种反模式。\n这也可以看作是一个过渡阶段，直到微服务过渡到完全自主。\n异步消息微服务设计模式 虽然 REST 设计模式非常普遍且易于理解，但它具有同步和阻塞的局限性。\n可以实现异步，但这是以特定于应用程序的方式完成的。因此，一些微服务架构可能会选择使用消息队列而不是 REST 请求/响应。\n在这种设计模式中，服务 A 可以同步调用服务 C，然后服务 C 使用共享消息队列与服务 B 和 D 异步通信。\n服务 A -\u0026gt; 服务 C 通信可能是异步的，可能使用 WebSockets，以实现所需的可伸缩性。\n可以使用 REST 请求/响应和发布/订阅消息传递的组合来完成业务需求。\nCoupling vs Autonomy in Microservices 是一本关于为您的微服务选择哪种消息传递模式的好读物。\n希望您发现这些设计模式很有用。\n您使用什么微服务设计模式？\n善于交际，分享！\n原文链接：http://web.archive.org/web/20190705163602/http://blog.arungupta.me/microservice-design-patterns/\n","permalink":"https://blog.chensoul.cc/posts/2023/06/26/microservice-design-patterns/","summary":"基于微服务的应用程序的主要特征在 微服务、单体和 NoOps 中定义。它们是功能分解或领域驱动设计、定义良好的接口、明确发布的接口、单一责任原则和潜在的多语言。每项服务都是完全自主和全栈的。\n因此，更改服务实现不会影响其他服务，因为它们使用定义良好的接口进行通信。这种应用程序有几个优点，但它不是 免费的午餐，需要在 NoOps 方面付出大量努力。\n但是假设您了解构建此类应用程序所需的工作或至少其中的一部分，并且愿意跳槽。你做什么工作？您构建此类应用程序的方法是什么？\n是否有任何关于这些微服务如何相互协作的设计模式？\n应用程序和团队的功能分解是构建成功的微服务架构的关键。\n这允许您实现松耦合（REST 接口）和高内聚（多个服务可以相互组合以定义更高级别的服务或应用程序）。\n应用程序的动词（例如 Checkout）或名词（Product）是实现现有应用程序分解的有效方法之一。\n例如，产品、目录和结帐可以是三个独立的微服务，然后相互协作以提供完整的购物车体验。\n功能分解提供了敏捷性、灵活性、可扩展性和其他能力，但业务目标仍然是创建应用程序。因此，一旦识别出不同的微服务，您如何组合它们以提供应用程序的功能？\n本博客将讨论一些关于如何将微服务组合在一起的推荐模式。\n聚合微服务设计模式 第一个，也可能是最常见的，是聚合器微服务设计模式。\n在其最简单的形式中，聚合器将是一个简单的网页，它调用多个服务来实现应用程序所需的功能。由于每个服务（服务 A、服务 B 和服务 C）都使用轻量级 REST 机制公开，因此网页可以检索数据并相应地处理/显示数据。如果需要某种处理，比如将业务逻辑应用于从各个服务接收的数据，那么您可能有一个 CDI bean 可以转换数据，以便网页可以显示它。\n聚合器的另一个选择是不需要显示，它只是一个更高级别的复合微服务，可以被其他服务使用。\n在这种情况下，聚合器只需从每个单独的微服务收集数据，对其应用业务逻辑，然后将其进一步发布为 REST 端点。然后可以由需要它的其他服务使用。\n这种设计模式遵循 DRY 原则。\n如果有多个服务需要访问服务 A、B 和 C，那么建议将该逻辑抽象为一个复合微服务，并将该逻辑聚合到一个服务中。在此级别进行抽象的一个优点是各个服务，即服务 A、B 和 C，并且可以独立发展，业务需求仍然由组合微服务提供。\n请注意，每个单独的微服务都有自己的（可选）缓存和数据库。如果聚合器是一个复合微服务，那么它也可能有自己的缓存和数据库层。\n聚合器也可以在 X 轴和 Z 轴上独立缩放。因此，如果它是一个网页，那么您可以启动额外的 Web 服务器，或者如果它是一个使用 Java EE 的复合微服务，那么您可以启动额外的 WildFly 实例来满足不断增长的需求。\n代理微服务设计模式 代理微服务设计模式是聚合器的一种变体。在这种情况下，客户端不需要进行聚合，但可以根据业务需要调用不同的微服务。\n就像 Aggregator 一样，Proxy 也可以在 X 轴和 Z 轴上独立扩展。您可能喜欢这样做，因为每个单独的服务都不需要向消费者公开，而是应该通过一个界面。\n代理可能是一个哑代理，在这种情况下，它只是将请求委托给其中一项服务。或者，它可能是一个智能代理，在将响应提供给客户端之前应用一些数据转换。一个很好的例子就是可以将不同设备的表示层封装在智能代理中。\n链式微服务设计模式 链式微服务设计模式对请求产生单一的综合响应。在这种情况下，来自客户端的请求由服务 A 接收，然后服务 A 与服务 B 通信，而服务 B 又可能与服务 C 通信。\n所有服务都可能使用同步 HTTP 请求/响应消息传递。\n要记住的关键部分是客户端被阻塞，直到完成请求/响应链，即服务\u0026lt;-\u0026gt;服务 B 和服务 B\u0026lt;-\u0026gt;服务 C，完成。从服务 B 到服务 C 的请求可能看起来与从服务 A 到服务 B 的请求完全不同。\n同样，服务 B 对服务 A 的响应可能看起来与服务 C 对服务 B 的响应完全不同。无论如何，这就是不同服务增加其业务价值的全部要点。","title":"[译]微服务设计模式"},{"content":"本文主要介绍 Aggregator Microservices 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n意图 用户对聚合器服务进行一次调用，然后聚合器将调用每个相关的微服务。\nAggregator Microservices 是一种微服务架构模式，用于解决大型分布式系统中的数据聚合问题。该模式通常用于有多个数据源的场景，例如电子商务网站中的产品列表页面，其中需要从多个服务中获取产品信息并组合在一起显示。\nAggregator Microservices 模式包括一个聚合器服务和多个后端服务。聚合器服务负责从多个后端服务中收集数据，并将数据组合成一个聚合的响应。后端服务则负责提供特定的数据源，例如产品信息、库存信息、价格信息等。\n解释 真实世界例子\n我们的网络市场需要有关产品及其当前库存的信息。 它调用聚合服务，聚合服务依次调用产品信息微服务和产品库存微服务，返回组合信息。\n通俗地说\n聚合器微服务从各种微服务中收集数据，并返回一个聚合数据以进行处理。\nStack Overflow 上说\n聚合器微服务调用多个服务以实现应用程序所需的功能。\n程序示例\n让我们从数据模型开始。 这是我们的产品。\npublic class Product { private String title; private int productInventories; // getters and setters -\u0026gt; ... } 接下来，我们将介绍我们的聚合器微服务。 它包含用于调用相应微服务的客户端ProductInformationClient和 ProductInventoryClient。\n@RestController public class Aggregator { @Resource private ProductInformationClient informationClient; @Resource private ProductInventoryClient inventoryClient; @RequestMapping(path = \u0026#34;/product\u0026#34;, method = RequestMethod.GET) public Product getProduct() { var product = new Product(); var productTitle = informationClient.getProductTitle(); var productInventory = inventoryClient.getProductInventories(); //Fallback to error message product.setTitle(requireNonNullElse(productTitle, \u0026#34;Error: Fetching Product Title Failed\u0026#34;)); //Fallback to default error inventory product.setProductInventories(requireNonNullElse(productInventory, -1)); return product; } } 这是产品信息微服务的精华实现。 库存微服务类似，它只返回库存计数。\n@RestController public class InformationController { @RequestMapping(value = \u0026#34;/information\u0026#34;, method = RequestMethod.GET) public String getProductTitle() { return \u0026#34;The Product Title.\u0026#34;; } } 现在调用我们的聚合器 REST API 会返回产品信息。\ncurl http://localhost:50004/product {\u0026#34;title\u0026#34;:\u0026#34;The Product Title.\u0026#34;,\u0026#34;productInventories\u0026#34;:5} 特点 以下是该模式的一些关键特点：\n多个后端服务：Aggregator Microservices 模式通常涉及多个后端服务，每个后端服务负责提供特定类型的数据。 数据聚合：聚合器服务负责从多个后端服务中收集数据，并将数据组合成一个聚合的响应。 透明的组合：聚合器服务应该尽可能透明地组合数据，使其对调用方看起来像是一个单一的数据源。 异步通信：由于后端服务可能位于不同的网络位置，聚合器服务通常使用异步通信来收集数据。 Aggregator Microservices 模式可以带来许多好处，例如：\n可伸缩性：由于聚合器服务可以并行地从多个后端服务中收集数据，因此该模式可以通过增加后端服务来实现可伸缩性。 低耦合性：后端服务和聚合器服务之间的低耦合性使得系统更加灵活，可以更轻松地添加、修改或删除后端服务。 可定制性：聚合器服务可以根据需要自定义数据聚合的逻辑，以满足特定的业务需求。 类图 适用性 Aggregator Microservices 模式可以应用于各种不同的场景，以下是一些常见的应用：\n电子商务平台：在电子商务平台中，通常需要从多个供应商那里获取产品信息和价格，并将其聚合到一个统一的产品列表中。Aggregator Microservices 可以用来处理这些数据源，并将数据聚合到一个共同的产品列表中。 新闻聚合平台：在新闻聚合平台中，需要从不同的新闻来源获取新闻内容，并将其聚合到一个统一的新闻列表中。Aggregator Microservices 可以用来处理这些新闻来源，并将新闻内容聚合到一个共同的新闻列表中。 金融数据分析：在金融数据分析中，需要从多个数据源中获取数据，例如股票市场数据、货币汇率数据、经济指标数据等，并将数据聚合到一个统一的数据分析工具中。Aggregator Microservices 可以用来处理这些数据源，并将数据聚合到一个共同的数据分析工具中。 物联网平台：在物联网平台中，需要从多个传感器获取数据，并将其聚合到一个统一的数据中心中。Aggregator Microservices 可以用来处理这些传感器数据源，并将数据聚合到一个共同的数据中心中。 Aggregator Microservices 可以使用多种实现方式来实现数据聚合，以下是一些常见的实现方式：\n同步阻塞方式：在这种方式下，聚合器服务按照顺序从多个后端服务中收集数据，每次收集完一个服务的数据后再收集下一个服务的数据，直到所有数据都被收集完毕。这种方式的缺点是效率较低，因为所有操作都是同步阻塞的。 异步非阻塞方式：在这种方式下，聚合器服务使用异步非阻塞的方式从多个后端服务中收集数据，这可以提高效率和性能。例如，聚合器服务可以使用 Java 8 的 CompletableFuture 和流式 API 来实现异步通信并行收集数据。 数据库方式：在这种方式下，每个后端服务负责将数据写入数据库中，聚合器服务再从数据库中读取数据并进行聚合。这种方式的优点是可以使用数据库的高效查询语句来聚合数据，但缺点是需要额外的数据库管理开销。 消息队列方式：在这种方式下，每个后端服务将数据发送到一个共享的消息队列中，聚合器服务再从队列中获取数据并进行聚合。这种方式的优点是可以实现异步通信，并且可以使用消息队列的高效消息传递机制来实现数据聚合，但缺点是需要额外的消息队列管理开销。 边缘计算方式：在这种方式下，聚合器服务可以在边缘设备中运行，直接从多个传感器或设备中收集数据并进行聚合。这种方式的优点是可以减少数据传输和存储的开销，但缺点是需要处理边缘设备的硬件和软件限制。 当使用消息队列方式来实现 Aggregator Microservices 时，可以应用于以下一些实际的场景：\n日志聚合：在一个分布式系统中，可能会生成大量的日志数据，如果将所有的日志数据发送到中心服务器上进行聚合，这会导致中心服务器的压力非常大。使用消息队列方式，可以将日志数据发送到消息队列中，再由聚合器服务从消息队列中获取数据来进行聚合，这样可以降低中心服务器的压力，提高系统的可伸缩性和性能。\n电商平台订单处理：在一个电商平台中，订单数据可能会分散在多个订单系统中，使用消息队列方式，可以将订单数据发送到消息队列中，再由聚合器服务从消息队列中获取数据来进行聚合，这样可以实现订单数据的统一处理，提高系统的可靠性和可维护性。\n物联网数据聚合：在一个物联网系统中，可能需要从多个传感器中获取数据，并将数据聚合到一个共同的数据中心中。使用消息队列方式，可以将传感器数据发送到消息队列中，再由聚合器服务从消息队列中获取数据来进行聚合，这样可以提高系统的可伸缩性和性能，并且缓解边缘设备的负载压力。\n实时数据处理：在一个实时数据处理系统中，可能需要从多个数据源中获取数据，并将数据聚合到一个共同的数据处理中心中。使用消息队列方式，可以将实时数据发送到消息队列中，再由聚合器服务从消息队列中获取数据来进行聚合，这样可以实现实时数据的快速处理和分析。\n一个异步聚合服务示例：\n// 聚合器服务类 public class AggregatorService { // 后端服务列表 private List\u0026lt;BackendService\u0026gt; backendServices; public AggregatorService(List\u0026lt;BackendService\u0026gt; backendServices) { this.backendServices = backendServices; } // 聚合数据的方法 public List\u0026lt;Product\u0026gt; getProducts() { List\u0026lt;Product\u0026gt; products = new ArrayList\u0026lt;\u0026gt;(); // 并行收集数据 List\u0026lt;CompletableFuture\u0026lt;List\u0026lt;Product\u0026gt;\u0026gt;\u0026gt; futures = backendServices.stream() .map(backendService -\u0026gt; CompletableFuture.supplyAsync(() -\u0026gt; backendService.getProducts())) .collect(Collectors.toList()); // 等待所有异步操作完成并聚合数据 CompletableFuture.allOf(futures.toArray(new CompletableFuture[futures.size()])) .join(); futures.stream() .map(CompletableFuture::join) .forEach(products::addAll); return products; } } // 后端服务接口 public interface BackendService { List\u0026lt;Product\u0026gt; getProducts(); } // 后端服务实现类1 public class BackendServiceA implements BackendService { @Override public List\u0026lt;Product\u0026gt; getProducts() { // 从数据库获取产品信息 List\u0026lt;Product\u0026gt; products = new ArrayList\u0026lt;\u0026gt;(); products.add(new Product(\u0026#34;Product A1\u0026#34;, 10.0)); products.add(new Product(\u0026#34;Product A2\u0026#34;, 20.0)); products.add(new Product(\u0026#34;Product A3\u0026#34;, 30.0)); return products; } } // 后端服务实现类2 public class BackendServiceB implements BackendService { @Override public List\u0026lt;Product\u0026gt; getProducts() { // 从API获取产品信息 List\u0026lt;Product\u0026gt; products = new ArrayList\u0026lt;\u0026gt;(); products.add(new Product(\u0026#34;Product B1\u0026#34;, 15.0)); products.add(new Product(\u0026#34;Product B2\u0026#34;, 25.0)); return products; } } // 产品类 public class Product { private String name; private double price; public Product(String name, double price) { this.name = name; this.price = price; } // 省略 getter 和 setter 方法 } 在上述示例代码中，我们定义了一个聚合器服务类 AggregatorService，它包含了多个后端服务接口 BackendService 的实现类 BackendServiceA 和 BackendServiceB。聚合器服务类的 getProducts() 方法负责从多个后端服务中收集产品数据，并将数据组合成一个聚合的响应。在收集数据时，我们使用了 Java 8 的 CompletableFuture 和流式 API 来实现异步通信并行收集数据。最后，我们定义了一个简单的产品类 Product，用于封装产品信息。\nAggregator Microservices 模式已经得到了广泛的应用和支持，以下是一些常见的开源框架和工具，它们提供了 Aggregator Microservices 模式的实现：\nApache Camel：是一个基于 Java 的开源框架，用于快速实现各种企业集成模式（EIP），包括聚合器模式。Apache Camel 提供了多种聚合器组件，例如 Aggregator、Splitter、Resequencer 等，可以灵活地聚合和处理数据。\nSpring Integration：是 Spring 生态系统中的一个集成框架，也支持 Aggregator Microservices 模式。Spring Integration 提供了多种聚合器组件，例如 Aggregator、Barrier、ReleaseStrategy 等，可以用来聚合和处理消息。\nApache Kafka：是一个分布式流处理平台，用于处理高吞吐量的实时数据流，也支持 Aggregator Microservices 模式。Apache Kafka 提供了消息队列和流处理功能，可以用来聚合和处理数据流。\nRabbitMQ：是一个开源的消息队列系统，支持多种消息协议和消息模式，也支持 Aggregator Microservices 模式。RabbitMQ 提供了多种消息协议和消息模式，可以用来聚合和处理消息。\nApache Spark：是一个分布式计算框架，用于处理大规模数据集，也支持 Aggregator Microservices 模式。Apache Spark 提供了多种数据处理和聚合功能，可以用来聚合和处理大规模数据集。\n参考文章 Microservice Design Patterns Microservices Patterns: With examples in Java Architectural Patterns: Uncover essential patterns in the most indispensable realm of enterprise architecture ","permalink":"https://blog.chensoul.cc/posts/2023/06/26/java-design-patterns-aggregator-microservices/","summary":"本文主要介绍 Aggregator Microservices 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n意图 用户对聚合器服务进行一次调用，然后聚合器将调用每个相关的微服务。\nAggregator Microservices 是一种微服务架构模式，用于解决大型分布式系统中的数据聚合问题。该模式通常用于有多个数据源的场景，例如电子商务网站中的产品列表页面，其中需要从多个服务中获取产品信息并组合在一起显示。\nAggregator Microservices 模式包括一个聚合器服务和多个后端服务。聚合器服务负责从多个后端服务中收集数据，并将数据组合成一个聚合的响应。后端服务则负责提供特定的数据源，例如产品信息、库存信息、价格信息等。\n解释 真实世界例子\n我们的网络市场需要有关产品及其当前库存的信息。 它调用聚合服务，聚合服务依次调用产品信息微服务和产品库存微服务，返回组合信息。\n通俗地说\n聚合器微服务从各种微服务中收集数据，并返回一个聚合数据以进行处理。\nStack Overflow 上说\n聚合器微服务调用多个服务以实现应用程序所需的功能。\n程序示例\n让我们从数据模型开始。 这是我们的产品。\npublic class Product { private String title; private int productInventories; // getters and setters -\u0026gt; ... } 接下来，我们将介绍我们的聚合器微服务。 它包含用于调用相应微服务的客户端ProductInformationClient和 ProductInventoryClient。\n@RestController public class Aggregator { @Resource private ProductInformationClient informationClient; @Resource private ProductInventoryClient inventoryClient; @RequestMapping(path = \u0026#34;/product\u0026#34;, method = RequestMethod.GET) public Product getProduct() { var product = new Product(); var productTitle = informationClient.","title":"Java设计模式：Aggregator Microservices"},{"content":" 本文探讨了 Python 模块和 Python 包，这两种机制有助于模块化编程。\n模块化编程是指将大型、笨重的编程任务分解为单独的、更小的、更易于管理的子任务或模块的过程。然后可以像构建块一样将各个模块拼凑在一起以创建更大的应用程序。\n在大型应用程序中模块化代码有几个优点：\n简单性：模块通常不会专注于手头的整个问题，而是专注于问题的一个相对较小的部分。如果您正在处理单个模块，那么您将有一个较小的问题域来解决问题。这使得开发更容易并且更不容易出错。\n可维护性：模块通常设计为在不同问题域之间强制执行逻辑边界。如果模块是以最小化相互依赖的方式编写的，那么对单个模块的修改对程序的其他部分产生影响的可能性就会降低。（您甚至可以在不了解该模块之外的应用程序的情况下对该模块进行更改。）这使得由许多程序员组成的团队在大型应用程序上协同工作变得更加可行。\n可重用性：在单个模块中定义的功能可以很容易地被应用程序的其他部分重用（通过适当定义的接口）。这消除了重复代码的需要。\n作用域：模块通常定义一个单独的名称空间，这有助于避免程序不同区域中标识符之间的冲突。 （Python 之禅的信条之一是命名空间是一个非常棒的想法——让我们做更多这样的事情吧！）\n函数、模块和包都是 Python 中促进代码模块化的构造。\nPython 模块：概述 在 Python 中实际上有三种不同的方式来定义模块：\n模块可以用 Python 本身编写。\n模块可以用 C 语言编写并在运行时动态加载，例如 re （正则表达式）模块。\n内置模块本质上包含在解释器中，例如 itertools 模块。\n在所有三种情况下，模块的内容都以相同的方式访问：使用 import 语句。\n在这里，重点将主要放在用 Python 编写的模块上。用 Python 编写的模块的妙处在于它们的构建非常简单。\n您需要做的就是创建一个包含合法 Python 代码的文件，然后为该文件指定一个带有 .py 扩展名的名称。就是这样！不需要特殊的语法或巫术。\n例如，假设您创建了一个名为 mod.py 的文件，其中包含以下内容：\nmod.py\ns = \u0026#34;If Comrade Napoleon says it, it must be right.\u0026#34; a = [100, 200, 300] def foo(arg): print(f\u0026#39;arg = {arg}\u0026#39;) class Foo: pass mod.py 中定义了几个对象：\ns （字符串） a （列表） foo() （函数） Foo （类） 假设 mod.py 位于适当的位置（您很快就会了解更多信息），可以通过导入模块来访问这些对象，如下所示：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; print(mod.s) If Comrade Napoleon says it, it must be right. \u0026gt;\u0026gt;\u0026gt; mod.a [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; mod.foo([\u0026#39;quux\u0026#39;, \u0026#39;corge\u0026#39;, \u0026#39;grault\u0026#39;]) arg = [\u0026#39;quux\u0026#39;, \u0026#39;corge\u0026#39;, \u0026#39;grault\u0026#39;] \u0026gt;\u0026gt;\u0026gt; x = mod.Foo() \u0026gt;\u0026gt;\u0026gt; x \u0026lt;mod.Foo object at 0x03C181F0\u0026gt; 模块搜索路径 继续上面的例子，我们来看看 Python 执行语句时会发生什么：\nimport mod 当解释器执行上述 import 语句时，它会在由以下来源组装的目录列表中搜索 mod.py ：\n运行输入脚本的目录或当前目录（如果解释器正在交互式运行） PYTHONPATH 环境变量中包含的目录列表（如果已设置）。 （ PYTHONPATH 的格式取决于操作系统，但应模仿 PATH 环境变量。） 安装 Python 时配置的依赖于安装的目录列表 生成的搜索路径可在 Python 变量 sys.path 中访问，该变量是从名为 sys 的模块获取的：\n\u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.path [\u0026#39;\u0026#39;, \u0026#39;C:\\\\Users\\\\john\\\\Documents\\\\Python\\\\doc\u0026#39;, \u0026#39;C:\\\\Python36\\\\Lib\\\\idlelib\u0026#39;, \u0026#39;C:\\\\Python36\\\\python36.zip\u0026#39;, \u0026#39;C:\\\\Python36\\\\DLLs\u0026#39;, \u0026#39;C:\\\\Python36\\\\lib\u0026#39;, \u0026#39;C:\\\\Python36\u0026#39;, \u0026#39;C:\\\\Python36\\\\lib\\\\site-packages\u0026#39;] 注意： sys.path 的具体内容取决于安装。几乎可以肯定，上面的内容在您的计算机上看起来会略有不同。\n因此，为确保找到您的模块，您需要执行以下操作之一：\n将 mod.py 放入输入脚本所在目录或当前目录，如果是交互式的 在启动解释器之前修改 PYTHONPATH 环境变量以包含 mod.py 所在目录 或者：将 mod.py 放入 PYTHONPATH 变量中已包含的目录之一 将 mod.py 放入依赖于安装的目录之一，您可能有也可能没有写入权限，具体取决于操作系统 实际上还有一个附加选项：您可以将模块文件放在您选择的任何目录中，然后在运行时修改 sys.path 以使其包含该目录。例如，在这种情况下，您可以将 mod.py 放入目录 C:\\Users\\john 中，然后发出以下语句：\n\u0026gt;\u0026gt;\u0026gt; sys.path.append(r\u0026#39;C:\\Users\\john\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sys.path [\u0026#39;\u0026#39;, \u0026#39;C:\\\\Users\\\\john\\\\Documents\\\\Python\\\\doc\u0026#39;, \u0026#39;C:\\\\Python36\\\\Lib\\\\idlelib\u0026#39;, \u0026#39;C:\\\\Python36\\\\python36.zip\u0026#39;, \u0026#39;C:\\\\Python36\\\\DLLs\u0026#39;, \u0026#39;C:\\\\Python36\\\\lib\u0026#39;, \u0026#39;C:\\\\Python36\u0026#39;, \u0026#39;C:\\\\Python36\\\\lib\\\\site-packages\u0026#39;, \u0026#39;C:\\\\Users\\\\john\u0026#39;] \u0026gt;\u0026gt;\u0026gt; import mod 导入模块后，您可以使用模块的 __file__ 属性确定找到它的位置：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; mod.__file__ \u0026#39;C:\\\\Users\\\\john\\\\mod.py\u0026#39; \u0026gt;\u0026gt;\u0026gt; import re \u0026gt;\u0026gt;\u0026gt; re.__file__ \u0026#39;C:\\\\Python36\\\\lib\\\\re.py\u0026#39; __file__ 的目录部分应该是 sys.path 中的目录之一。\nimport 声明 模块内容可通过 import 语句提供给调用者。 import 语句有多种不同的形式，如下所示。\nimport \u0026lt;module_name\u0026gt; 最简单的形式是上面已经显示的形式：\nimport \u0026lt;module_name\u0026gt; 请注意，这不会使调用者直接访问模块内容。每个模块都有自己的私有符号表，作为模块中定义的所有对象的全局符号表。因此，如前所述，模块创建了一个单独的名称空间。\n语句 import \u0026lt;module_name\u0026gt; 仅将 \u0026lt;module_name\u0026gt; 放入调用者的符号表中。模块中定义的对象保留在模块的私有符号表中。\n对于调用者来说，只有通过点符号以 \u0026lt;module_name\u0026gt; 为前缀时才能访问模块中的对象，如下所示。\n在以下 import 语句之后， mod 被放入本地符号表中。因此， mod 在调用者的本地上下文中有意义：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; mod \u0026lt;module \u0026#39;mod\u0026#39; from \u0026#39;C:\\\\Users\\\\john\\\\Documents\\\\Python\\\\doc\\\\mod.py\u0026#39;\u0026gt; 但是 s 和 foo 保留在模块的私有符号表中，并且在本地上下文中没有意义：\n\u0026gt;\u0026gt;\u0026gt; s NameError: name \u0026#39;s\u0026#39; is not defined \u0026gt;\u0026gt;\u0026gt; foo(\u0026#39;quux\u0026#39;) NameError: name \u0026#39;foo\u0026#39; is not defined 要在本地上下文中访问，模块中定义的对象名称必须以 mod 为前缀：\n\u0026gt;\u0026gt;\u0026gt; mod.s \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; \u0026gt;\u0026gt;\u0026gt; mod.foo(\u0026#39;quux\u0026#39;) arg = quux 可以在单个 import 语句中指定多个以逗号分隔的模块：\nimport \u0026lt;module_name\u0026gt;[, \u0026lt;module_name\u0026gt; ...] from \u0026lt;module_name\u0026gt; import \u0026lt;name(s)\u0026gt; import 语句的另一种形式允许将模块中的各个对象直接导入到调用者的符号表中：\nfrom \u0026lt;module_name\u0026gt; import \u0026lt;name(s)\u0026gt; 执行上述语句后，可以在调用者的环境中引用 \u0026lt;name(s)\u0026gt; ，而无需使用 \u0026lt;module_name\u0026gt; 前缀：\n\u0026gt;\u0026gt;\u0026gt; from mod import s, foo \u0026gt;\u0026gt;\u0026gt; s \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; \u0026gt;\u0026gt;\u0026gt; foo(\u0026#39;quux\u0026#39;) arg = quux \u0026gt;\u0026gt;\u0026gt; from mod import Foo \u0026gt;\u0026gt;\u0026gt; x = Foo() \u0026gt;\u0026gt;\u0026gt; x \u0026lt;mod.Foo object at 0x02E3AD50\u0026gt; 因为这种形式的 import 将对象名称直接放入调用者的符号表中，因此任何已存在的同名对象都将被覆盖：\n\u0026gt;\u0026gt;\u0026gt; a = [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from mod import a \u0026gt;\u0026gt;\u0026gt; a [100, 200, 300] 甚至可以不加区别地一次性 import 模块中的所有内容：\nfrom \u0026lt;module_name\u0026gt; import * 这会将 \u0026lt;module_name\u0026gt; 中的所有对象的名称放入本地符号表中，但以下划线 ( _ ) 字符开头的对象除外。\n例如：\n\u0026gt;\u0026gt;\u0026gt; from mod import * \u0026gt;\u0026gt;\u0026gt; s \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; \u0026gt;\u0026gt;\u0026gt; a [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; foo \u0026lt;function foo at 0x03B449C0\u0026gt; \u0026gt;\u0026gt;\u0026gt; Foo \u0026lt;class \u0026#39;mod.Foo\u0026#39;\u0026gt; 在大规模生产代码中不一定推荐这样做。这有点危险，因为您正在将名称一起输入到本地符号表中。除非您非常了解它们并且可以确信不会发生冲突，否则您很有可能会无意中覆盖现有名称。\n但是，当您只是为了测试或发现目的而使用交互式解释器时，这种语法非常方便，因为它可以让您快速访问模块必须提供的所有内容，而无需进行大量输入。\nfrom \u0026lt;module_name\u0026gt; import \u0026lt;name\u0026gt; as \u0026lt;alt_name\u0026gt; 也可以 import 单个对象，但使用备用名称将它们输入到本地符号表中：\nfrom \u0026lt;module_name\u0026gt; import \u0026lt;name\u0026gt; as \u0026lt;alt_name\u0026gt;[, \u0026lt;name\u0026gt; as \u0026lt;alt_name\u0026gt; …] 这使得将名称直接放入本地符号表成为可能，但避免与以前存在的名称发生冲突：\n\u0026gt;\u0026gt;\u0026gt; s = \u0026#39;foo\u0026#39; \u0026gt;\u0026gt;\u0026gt; a = [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from mod import s as string, a as alist \u0026gt;\u0026gt;\u0026gt; s \u0026#39;foo\u0026#39; \u0026gt;\u0026gt;\u0026gt; string \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; \u0026gt;\u0026gt;\u0026gt; a [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt;\u0026gt;\u0026gt; alist [100, 200, 300] import \u0026lt;module_name\u0026gt; as \u0026lt;alt_name\u0026gt; 您还可以使用备用名称导入整个模块：\nimport \u0026lt;module_name\u0026gt; as \u0026lt;alt_name\u0026gt; \u0026gt;\u0026gt;\u0026gt; import mod as my_module \u0026gt;\u0026gt;\u0026gt; my_module.a [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; my_module.foo(\u0026#39;qux\u0026#39;) arg = qux 模块内容可以从函数定义中导入。在这种情况下，在调用该函数之前， import 不会发生：\n\u0026gt;\u0026gt;\u0026gt; def bar(): ... from mod import foo ... foo(\u0026#39;corge\u0026#39;) ... \u0026gt;\u0026gt;\u0026gt; bar() arg = corge 然而，Python 3 不允许函数内不加区别地使用 import * 语法：\n\u0026gt;\u0026gt;\u0026gt; def bar(): ... from mod import * ... SyntaxError: import * only allowed at module level 最后，带有 except ImportError 子句的 try 语句可用于防止不成功的 import 尝试：\n\u0026gt;\u0026gt;\u0026gt; try: ... # Non-existent module ... import baz ... except ImportError: ... print(\u0026#39;Module not found\u0026#39;) ... Module not found \u0026gt;\u0026gt;\u0026gt; try: ... # Existing module, but non-existent object ... from mod import baz ... except ImportError: ... print(\u0026#39;Object not found in module\u0026#39;) ... Object not found in module dir() 函数 内置函数 dir() 返回命名空间中已定义名称的列表。如果没有参数，它会在当前本地符号表中生成按字母顺序排序的名称列表：\n\u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; qux = [1, 2, 3, 4, 5] \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;qux\u0026#39;] \u0026gt;\u0026gt;\u0026gt; class Bar(): ... pass ... \u0026gt;\u0026gt;\u0026gt; x = Bar() \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;Bar\u0026#39;, \u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;qux\u0026#39;, \u0026#39;x\u0026#39;] 请注意上面对 dir() 的第一次调用如何列出解释器启动时自动定义且已在命名空间中的几个名称。当定义新名称（ qux 、 Bar 、 x ）时，它们会出现在 dir() 的后续调用中。\n这对于识别 import 语句到底添加到命名空间中的内容非常有用：\n\u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;mod\u0026#39;] \u0026gt;\u0026gt;\u0026gt; mod.s \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; \u0026gt;\u0026gt;\u0026gt; mod.foo([1, 2, 3]) arg = [1, 2, 3] \u0026gt;\u0026gt;\u0026gt; from mod import a, Foo \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;Foo\u0026#39;, \u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;mod\u0026#39;] \u0026gt;\u0026gt;\u0026gt; a [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; x = Foo() \u0026gt;\u0026gt;\u0026gt; x \u0026lt;mod.Foo object at 0x002EAD50\u0026gt; \u0026gt;\u0026gt;\u0026gt; from mod import s as string \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;Foo\u0026#39;, \u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;mod\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;x\u0026#39;] \u0026gt;\u0026gt;\u0026gt; string \u0026#39;If Comrade Napoleon says it, it must be right.\u0026#39; 当给定一个模块名称的参数时， dir() 列出模块中定义的名称：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; dir(mod) [\u0026#39;Foo\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__cached__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__file__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;s\u0026#39;] \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from mod import * \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;Foo\u0026#39;, \u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;s\u0026#39;] 从脚本执行模块 任何包含模块的 .py 文件本质上也是一个 Python 脚本，并且没有任何理由不能像脚本一样执行。\n这里又是上面定义的 mod.py ：\nmod.py\ns = \u0026#34;If Comrade Napoleon says it, it must be right.\u0026#34; a = [100, 200, 300] def foo(arg): print(f\u0026#39;arg = {arg}\u0026#39;) class Foo: pass 这可以作为脚本运行：\nC:\\Users\\john\\Documents\u0026gt;python mod.py C:\\Users\\john\\Documents\u0026gt; 没有错误，所以它显然有效。当然，这并不是很有趣。正如它所写的，它只定义了对象。它不会对它们做任何事情，也不会生成任何输出。\n让我们修改上面的 Python 模块，以便它在作为脚本运行时生成一些输出：\nmod.py\ns = \u0026#34;If Comrade Napoleon says it, it must be right.\u0026#34; a = [100, 200, 300] def foo(arg): print(f\u0026#39;arg = {arg}\u0026#39;) class Foo: pass print(s) print(a) foo(\u0026#39;quux\u0026#39;) x = Foo() print(x) 现在应该更有趣了：\nC:\\Users\\john\\Documents\u0026gt;python mod.py If Comrade Napoleon says it, it must be right. [100, 200, 300] arg = quux \u0026lt;__main__.Foo object at 0x02F101D0\u0026gt; 不幸的是，现在它在作为模块导入时也会生成输出：\n\u0026gt;\u0026gt;\u0026gt; import mod If Comrade Napoleon says it, it must be right. [100, 200, 300] arg = quux \u0026lt;mod.Foo object at 0x0169AD50\u0026gt; 这可能不是您想要的。模块在导入时通常不会生成输出。\n如果您能够区分文件何时作为模块加载以及何时作为独立脚本运行，岂不是很好？\n祈求，你们就会收到。\n当 .py 文件作为模块导入时，Python 会将特殊的 dunder 变量 __name__ 设置为模块的名称。但是，如果文件作为独立脚本运行，则 __name__ （创造性地）设置为字符串 '__main__' 。利用这一事实，您可以辨别运行时的情况并相应地改变行为：\nmod.py\ns = \u0026#34;If Comrade Napoleon says it, it must be right.\u0026#34; a = [100, 200, 300] def foo(arg): print(f\u0026#39;arg = {arg}\u0026#39;) class Foo: pass if (__name__ == \u0026#39;__main__\u0026#39;): print(\u0026#39;Executing as standalone script\u0026#39;) print(s) print(a) foo(\u0026#39;quux\u0026#39;) x = Foo() print(x) 现在，如果您作为脚本运行，您将得到输出：\nC:\\Users\\john\\Documents\u0026gt;python mod.py Executing as standalone script If Comrade Napoleon says it, it must be right. [100, 200, 300] arg = quux \u0026lt;__main__.Foo object at 0x03450690\u0026gt; 但如果您作为模块导入，则不会：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; mod.foo(\u0026#39;grault\u0026#39;) arg = grault 模块通常设计为能够作为独立脚本运行，以测试模块中包含的功能。这称为单元测试。例如，假设您创建了一个包含阶乘函数的模块 fact.py ，如下所示：\nfact.py\ndef fact(n): return 1 if n == 1 else n * fact(n-1) if (__name__ == \u0026#39;__main__\u0026#39;): import sys if len(sys.argv) \u0026gt; 1: print(fact(int(sys.argv[1]))) 该文件可以被视为一个模块，并导入 fact() 函数：\n\u0026gt;\u0026gt;\u0026gt; from fact import fact \u0026gt;\u0026gt;\u0026gt; fact(6) 720 但它也可以通过在命令行上传递整数参数来独立运行以进行测试：\nC:\\Users\\john\\Documents\u0026gt;python fact.py 6 720 重新加载模块 出于效率原因，每个解释器会话仅加载一个模块一次。这对于函数和类定义来说很好，它们通常构成了模块的大部分内容。但模块也可以包含可执行语句，通常用于初始化。\n请注意，这些语句仅在第一次导入模块时执行。\n考虑以下文件 mod.py ：\nmod.py\na = [100, 200, 300] print(\u0026#39;a =\u0026#39;, a) \u0026gt;\u0026gt;\u0026gt; import mod a = [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; mod.a [100, 200, 300] 后续导入时不会执行 print() 语句。 （就此而言，赋值语句也不是，但正如 mod.a 值的最终显示所示，这并不重要。一旦进行赋值，它就会保留。）\n如果您对模块进行更改并需要重新加载它，则需要重新启动解释器或使用模块 importlib 中名为 reload() 的函数：\n\u0026gt;\u0026gt;\u0026gt; import mod a = [100, 200, 300] \u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; import importlib \u0026gt;\u0026gt;\u0026gt; importlib.reload(mod) a = [100, 200, 300] \u0026lt;module \u0026#39;mod\u0026#39; from \u0026#39;C:\\\\Users\\\\john\\\\Documents\\\\Python\\\\doc\\\\mod.py\u0026#39;\u0026gt; Python 包 假设您开发了一个非常大的应用程序，其中包含许多模块。随着模块数量的增加，如果将它们转储到一个位置，则很难跟踪所有模块。如果它们具有相似的名称或功能，则尤其如此。\n您可能希望有一种对它们进行分组和组织的方法。\n包允许使用点表示法对模块名称空间进行分层结构。就像模块有助于避免全局变量名称之间的冲突一样，包也有助于避免模块名称之间的冲突。\n创建包非常简单，因为它利用了操作系统固有的分层文件结构。考虑以下安排：\n这里有一个名为 pkg 的目录，其中包含两个模块： mod1.py 和 mod2.py 。模块的内容是：\nmod1.py\ndef foo(): print(\u0026#39;[mod1] foo()\u0026#39;) class Foo: pass mod2.py\ndef bar(): print(\u0026#39;[mod2] bar()\u0026#39;) class Bar: pass 给定此结构，如果 pkg 目录位于可以找到它的位置（ sys.path 中包含的目录之一），则可以用点符号引用这两个模块（ pkg.mod1 、 pkg.mod2 ) 并使用您已经熟悉的语法导入它们：\nimport \u0026lt;module_name\u0026gt;[, \u0026lt;module_name\u0026gt; ...] \u0026gt;\u0026gt;\u0026gt; import pkg.mod1, pkg.mod2 \u0026gt;\u0026gt;\u0026gt; pkg.mod1.foo() [mod1] foo() \u0026gt;\u0026gt;\u0026gt; x = pkg.mod2.Bar() \u0026gt;\u0026gt;\u0026gt; x \u0026lt;pkg.mod2.Bar object at 0x033F7290\u0026gt; from \u0026lt;module_name\u0026gt; import \u0026lt;name(s)\u0026gt; \u0026gt;\u0026gt;\u0026gt; from pkg.mod1 import foo \u0026gt;\u0026gt;\u0026gt; foo() [mod1] foo() from \u0026lt;module_name\u0026gt; import \u0026lt;name\u0026gt; as \u0026lt;alt_name\u0026gt; \u0026gt;\u0026gt;\u0026gt; from pkg.mod2 import Bar as Qux \u0026gt;\u0026gt;\u0026gt; x = Qux() \u0026gt;\u0026gt;\u0026gt; x \u0026lt;pkg.mod2.Bar object at 0x036DFFD0\u0026gt; 您也可以使用这些语句导入模块：\nfrom \u0026lt;package_name\u0026gt; import \u0026lt;modules_name\u0026gt;[, \u0026lt;module_name\u0026gt; ...] from \u0026lt;package_name\u0026gt; import \u0026lt;module_name\u0026gt; as \u0026lt;alt_name\u0026gt; \u0026gt;\u0026gt;\u0026gt; from pkg import mod1 \u0026gt;\u0026gt;\u0026gt; mod1.foo() [mod1] foo() \u0026gt;\u0026gt;\u0026gt; from pkg import mod2 as quux \u0026gt;\u0026gt;\u0026gt; quux.bar() [mod2] bar() 从技术上讲，您也可以导入该包：\n\u0026gt;\u0026gt;\u0026gt; import pkg \u0026gt;\u0026gt;\u0026gt; pkg \u0026lt;module \u0026#39;pkg\u0026#39; (namespace)\u0026gt; 但这收效甚微。虽然严格来说，这是一个语法正确的 Python 语句，但它并没有做任何有用的事情。特别是，它不会将 pkg 中的任何模块放入本地命名空间中：\n\u0026gt;\u0026gt;\u0026gt; pkg.mod1 Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#34\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; pkg.mod1 AttributeError: module \u0026#39;pkg\u0026#39; has no attribute \u0026#39;mod1\u0026#39; \u0026gt;\u0026gt;\u0026gt; pkg.mod1.foo() Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#35\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; pkg.mod1.foo() AttributeError: module \u0026#39;pkg\u0026#39; has no attribute \u0026#39;mod1\u0026#39; \u0026gt;\u0026gt;\u0026gt; pkg.mod2.Bar() Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#36\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; pkg.mod2.Bar() AttributeError: module \u0026#39;pkg\u0026#39; has no attribute \u0026#39;mod2\u0026#39; 要实际导入模块或其内容，您需要使用上面显示的表单之一。\n包初始化 如果包目录中存在名为 __init__.py 的文件，则在导入包或包中的模块时会调用该文件。这可用于执行包初始化代码，例如包级数据的初始化。\n例如，考虑以下 __init__.py 文件：\ninit.py\nprint(f\u0026#39;Invoking __init__.py for {__name__}\u0026#39;) A = [\u0026#39;quux\u0026#39;, \u0026#39;corge\u0026#39;, \u0026#39;grault\u0026#39;] 我们将此文件添加到上面示例中的 pkg 目录中：\n现在，当导入包时，全局列表 A 被初始化：\n\u0026gt;\u0026gt;\u0026gt; import pkg Invoking __init__.py for pkg \u0026gt;\u0026gt;\u0026gt; pkg.A [\u0026#39;quux\u0026#39;, \u0026#39;corge\u0026#39;, \u0026#39;grault\u0026#39;] 包中的模块可以通过依次导入来访问全局变量：\nmod1.py\ndef foo(): from pkg import A print(\u0026#39;[mod1] foo() / A = \u0026#39;, A) class Foo: pass \u0026gt;\u0026gt;\u0026gt; from pkg import mod1 Invoking __init__.py for pkg \u0026gt;\u0026gt;\u0026gt; mod1.foo() [mod1] foo() / A = [\u0026#39;quux\u0026#39;, \u0026#39;corge\u0026#39;, \u0026#39;grault\u0026#39;] __init__.py 还可以用于实现从包中自动导入模块。例如，之前您看到语句 import pkg 仅将名称 pkg 放入调用者的本地符号表中，并且不导入任何模块。但如果 pkg 目录中的 __init__.py 包含以下内容：\ninit.py\nprint(f\u0026#39;Invoking __init__.py for {__name__}\u0026#39;) import pkg.mod1, pkg.mod2 然后当您执行 import pkg 时，会自动导入模块 mod1 和 mod2 ：\n\u0026gt;\u0026gt;\u0026gt; import pkg Invoking __init__.py for pkg \u0026gt;\u0026gt;\u0026gt; pkg.mod1.foo() [mod1] foo() \u0026gt;\u0026gt;\u0026gt; pkg.mod2.bar() [mod2] bar() 注意：许多 Python 文档都指出，创建包时，包目录中必须存在 __init__.py 文件。这曾经是真的。过去， __init__.py 的存在对于 Python 来说就意味着正在定义一个包。该文件可以包含初始化代码，甚至可以为空，但它必须存在。\n从 Python 3.3 开始，引入了隐式命名空间包。这些允许创建没有任何 __init__.py 文件的包。当然，如果需要包初始化，它仍然可以存在。但不再需要了。查看什么是 Python 命名空间包，它有什么用？了解更多。\n从包中导入 * 为了以下讨论的目的，先前定义的包被扩展以包含一些附加模块：\n现在 pkg 目录中定义了四个模块。它们的内容如下所示：\nmod1.py\ndef foo(): print(\u0026#39;[mod1] foo()\u0026#39;) class Foo: pass mod2.py\ndef bar(): print(\u0026#39;[mod2] bar()\u0026#39;) class Bar: pass mod3.py\ndef baz(): print(\u0026#39;[mod3] baz()\u0026#39;) class Baz: pass mod4.py\ndef qux(): print(\u0026#39;[mod4] qux()\u0026#39;) class Qux: pass 那有什么作用？\n\u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from pkg import * \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] 哼。不多。您可能期望（假设您有任何期望）Python 会深入到包目录中，找到它能找到的所有模块，并将它们全部导入。但正如您所看到的，默认情况下不会发生这种情况。\n相反，Python 遵循此约定：如果包目录中的 __init__.py 文件包含名为 __all__ 的列表，则在遇到语句 from \u0026lt;package_name\u0026gt; import * 时，它被视为应导入的模块列表。\n对于本示例，假设您在 pkg 目录中创建一个 __init__.py ，如下所示：\npkg/init.py\n__all__ = [ \u0026#39;mod1\u0026#39;, \u0026#39;mod2\u0026#39;, \u0026#39;mod3\u0026#39;, \u0026#39;mod4\u0026#39; ] 现在 from pkg import * 导入所有四个模块：\n\u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from pkg import * \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;mod1\u0026#39;, \u0026#39;mod2\u0026#39;, \u0026#39;mod3\u0026#39;, \u0026#39;mod4\u0026#39;] \u0026gt;\u0026gt;\u0026gt; mod2.bar() [mod2] bar() \u0026gt;\u0026gt;\u0026gt; mod4.Qux \u0026lt;class \u0026#39;pkg.mod4.Qux\u0026#39;\u0026gt; 使用 import * 仍然不被认为是一种很好的形式，对于包来说比对于模块来说更是如此。但此功能至少使包的创建者可以对指定 import * 时发生的情况进行一些控制。 （事实上，它提供了完全禁止它的功能，只需完全拒绝定义 __all__ 即可。正如您所看到的，包的默认行为是不导入任何内容。）\n顺便说一句， __all__ 也可以在模块中定义，并具有相同的目的：控制使用 import * 导入的内容。例如，修改 mod1.py 如下：\npkg/mod1.py\n__all__ = [\u0026#39;foo\u0026#39;] def foo(): print(\u0026#39;[mod1] foo()\u0026#39;) class Foo: pass 现在，来自 pkg.mod1 的 import * 语句将仅导入 __all__ 中包含的内容：\n\u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt;\u0026gt;\u0026gt; from pkg.mod1 import * \u0026gt;\u0026gt;\u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__loader__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;, \u0026#39;foo\u0026#39;] \u0026gt;\u0026gt;\u0026gt; foo() [mod1] foo() \u0026gt;\u0026gt;\u0026gt; Foo Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#37\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; Foo NameError: name \u0026#39;Foo\u0026#39; is not defined foo() （函数）现在定义在本地命名空间中，但 Foo （类）不是，因为后者不在 __all__ 中。\n总之，包和模块都使用 __all__ 来控制指定 import * 时导入的内容。但默认行为有所不同：\n对于包来说，当 __all__ 未定义时， import * 不会导入任何内容。 对于模块，当未定义 __all__ 时， import * 会导入所有内容（除了——你猜对了——以下划线开头的名称）。 子包 包可以包含任意深度的嵌套子包。例如，我们对示例包目录再做一个修改，如下：\n四个模块（ mod1.py 、 mod2.py 、 mod3.py 和 mod4.py ）的定义如前。但现在，它们不再被集中到 pkg 目录中，而是分成两个子包目录： sub_pkg1 和 sub_pkg2 。\n导入仍然与之前所示的一样。语法类似，但使用额外的点符号将包名称与子包名称分开：\n\u0026gt;\u0026gt;\u0026gt; import pkg.sub_pkg1.mod1 \u0026gt;\u0026gt;\u0026gt; pkg.sub_pkg1.mod1.foo() [mod1] foo() \u0026gt;\u0026gt;\u0026gt; from pkg.sub_pkg1 import mod2 \u0026gt;\u0026gt;\u0026gt; mod2.bar() [mod2] bar() \u0026gt;\u0026gt;\u0026gt; from pkg.sub_pkg2.mod3 import baz \u0026gt;\u0026gt;\u0026gt; baz() [mod3] baz() \u0026gt;\u0026gt;\u0026gt; from pkg.sub_pkg2.mod4 import qux as grault \u0026gt;\u0026gt;\u0026gt; grault() [mod4] qux() 此外，一个子包中的模块可以引用同级子包中的对象（如果同级子包包含您需要的某些功能）。例如，假设您想从模块 mod3 中导入并执行函数 foo() （在模块 mod1 中定义）。您可以使用绝对导入：\npkg/sub__pkg2/mod3.py\ndef baz(): print(\u0026#39;[mod3] baz()\u0026#39;) class Baz: pass from pkg.sub_pkg1.mod1 import foo foo() \u0026gt;\u0026gt;\u0026gt; from pkg.sub_pkg2 import mod3 [mod1] foo() \u0026gt;\u0026gt;\u0026gt; mod3.foo() [mod1] foo() 或者您可以使用相对导入，其中 .. 指的是上一级的包。从子包 sub_pkg2 中的 mod3.py 中，\n.. 计算父包 ( pkg )，并且\n..sub_pkg1 计算为父包的子包 sub_pkg1 。\npkg/sub__pkg2/mod3.py\ndef baz(): print(\u0026#39;[mod3] baz()\u0026#39;) class Baz: pass from .. import sub_pkg1 print(sub_pkg1) from ..sub_pkg1.mod1 import foo foo() \u0026gt;\u0026gt;\u0026gt; from pkg.sub_pkg2 import mod3 \u0026lt;module \u0026#39;pkg.sub_pkg1\u0026#39; (namespace)\u0026gt; [mod1] foo() 结论 在本教程中，您涵盖了以下主题：\n如何创建 Python 模块\nPython 解释器搜索模块的位置\n如何使用 import 语句获取对模块中定义的对象的访问权限\n如何创建可作为独立脚本执行的模块\n如何将模块组织成包和子包\n如何控制包初始化\n这有望让您更好地了解如何访问 Python 中可用的许多第三方和内置模块中可用的功能。\n此外，如果您正在开发自己的应用程序，创建自己的模块和包将帮助您组织和模块化代码，从而使编码、维护和调试更加容易。\n如果您想了解更多信息，请查看 Python.org 上的以下文档：\nThe import system The Python tutorial: Modules 快乐的 Python！\n原文链接：https://realpython.com/python-modules-packages\n","permalink":"https://blog.chensoul.cc/posts/2023/06/25/python-modules-packages/","summary":"本文探讨了 Python 模块和 Python 包，这两种机制有助于模块化编程。\n模块化编程是指将大型、笨重的编程任务分解为单独的、更小的、更易于管理的子任务或模块的过程。然后可以像构建块一样将各个模块拼凑在一起以创建更大的应用程序。\n在大型应用程序中模块化代码有几个优点：\n简单性：模块通常不会专注于手头的整个问题，而是专注于问题的一个相对较小的部分。如果您正在处理单个模块，那么您将有一个较小的问题域来解决问题。这使得开发更容易并且更不容易出错。\n可维护性：模块通常设计为在不同问题域之间强制执行逻辑边界。如果模块是以最小化相互依赖的方式编写的，那么对单个模块的修改对程序的其他部分产生影响的可能性就会降低。（您甚至可以在不了解该模块之外的应用程序的情况下对该模块进行更改。）这使得由许多程序员组成的团队在大型应用程序上协同工作变得更加可行。\n可重用性：在单个模块中定义的功能可以很容易地被应用程序的其他部分重用（通过适当定义的接口）。这消除了重复代码的需要。\n作用域：模块通常定义一个单独的名称空间，这有助于避免程序不同区域中标识符之间的冲突。 （Python 之禅的信条之一是命名空间是一个非常棒的想法——让我们做更多这样的事情吧！）\n函数、模块和包都是 Python 中促进代码模块化的构造。\nPython 模块：概述 在 Python 中实际上有三种不同的方式来定义模块：\n模块可以用 Python 本身编写。\n模块可以用 C 语言编写并在运行时动态加载，例如 re （正则表达式）模块。\n内置模块本质上包含在解释器中，例如 itertools 模块。\n在所有三种情况下，模块的内容都以相同的方式访问：使用 import 语句。\n在这里，重点将主要放在用 Python 编写的模块上。用 Python 编写的模块的妙处在于它们的构建非常简单。\n您需要做的就是创建一个包含合法 Python 代码的文件，然后为该文件指定一个带有 .py 扩展名的名称。就是这样！不需要特殊的语法或巫术。\n例如，假设您创建了一个名为 mod.py 的文件，其中包含以下内容：\nmod.py\ns = \u0026#34;If Comrade Napoleon says it, it must be right.\u0026#34; a = [100, 200, 300] def foo(arg): print(f\u0026#39;arg = {arg}\u0026#39;) class Foo: pass mod.py 中定义了几个对象：\ns （字符串） a （列表） foo() （函数） Foo （类） 假设 mod.py 位于适当的位置（您很快就会了解更多信息），可以通过导入模块来访问这些对象，如下所示：\n\u0026gt;\u0026gt;\u0026gt; import mod \u0026gt;\u0026gt;\u0026gt; print(mod.s) If Comrade Napoleon says it, it must be right.","title":"[译]Python模块和包-简介"},{"content":"函数的定义 在 Python 中，函数是一段可重复使用的代码块，它接受一些输入（也称为参数）并产生一些输出。函数可以通过 def 关键字来定义，语法如下：\ndef function_name(parameters): \u0026#34;\u0026#34;\u0026#34;This is a function\u0026#34;\u0026#34;\u0026#34; # function body return value 其中，function_name 是函数的名称，parameters 是函数的参数列表，function body 是函数的主体部分，包括需要执行的代码和可能的返回语句，return value 是函数的返回值（如果有的话）。\n下列代码创建一个可以输出限定数值内的斐波那契数列函数：\ndef fib(n): # write Fibonacci series up to n \u0026#34;\u0026#34;\u0026#34;Print a Fibonacci series up to n.\u0026#34;\u0026#34;\u0026#34; a, b = 0, 1 while a \u0026lt; n: print(a, end=\u0026#39; \u0026#39;) a, b = b, a+b print() fib(2000) # 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 159 定义 函数使用关键字 def，后跟函数名与括号内的形参列表。函数语句从下一行开始，并且必须缩进。\n函数内的第一条语句是字符串时，该字符串就是文档字符串，也称为 docstring。利用文档字符串可以自动生成在线文档或打印版文档，还可以让开发者在浏览代码时直接查阅文档；Python 开发者最好养成在代码中加入文档字符串的好习惯。\n函数在 执行 时使用函数局部变量符号表，所有函数变量赋值都存在局部符号表中；引用变量时，首先，在局部符号表里查找变量，然后，是外层函数局部符号表，再是全局符号表，最后是内置名称符号表。因此，尽管可以引用全局变量和外层函数的变量，但最好不要在函数内直接赋值（除非是 global 语句定义的全局变量，或 nonlocal 语句定义的外层函数变量）。\n在调用函数时会将实际参数（实参）引入到被调用函数的局部符号表中；因此，实参是使用 按值调用 来传递的（其中的 值 始终是对象的 引用 而不是对象的值）。 1 当一个函数调用另外一个函数时，会为该调用创建一个新的局部符号表。\n函数定义在当前符号表中把函数名与函数对象关联在一起。解释器把函数名指向的对象作为用户自定义函数。还可以使用其他名称指向同一个函数对象，并访问访该函数：\nfib f = fib f(100) # 0 1 1 2 3 5 8 13 21 34 55 89 fib 不返回值，因此，其他语言不把它当作函数，而是当作过程。事实上，没有 return 语句的函数也返回值，只不过这个值比较是 None （是一个内置名称）。一般来说，解释器不会输出单独的返回值 None ，如需查看该值，可以使用 print()：\nfib(0) print(fib(0)) 函数参数 默认值参数 在 Python 中，函数参数可以具有默认值，这意味着如果在函数调用期间未提供该参数的值，则使用默认值。定义具有默认值的函数参数的语法如下：\ndef function_name(param1, param2=default_value): # function body return value 其中，param1 是必需的参数，它没有默认值；param2 是可选参数，如果未提供，则使用默认值 default_value。如果调用函数时提供了 param2 的值，则使用提供的值覆盖默认值。\n以下是一个使用默认参数值的 Python 函数示例：\ndef greet(name, greeting=\u0026#34;Hello\u0026#34;): print(f\u0026#34;{greeting}, {name}!\u0026#34;) greet(\u0026#34;Alice\u0026#34;) # output: Hello, Alice! greet(\u0026#34;Bob\u0026#34;, \u0026#34;Hi\u0026#34;) # output: Hi, Bob! 需要注意的是，当函数参数具有默认值时，应该将具有默认值的参数放在参数列表的末尾。这样可以使函数更加易于使用，并避免在调用函数时出现混淆。\n以下是一个具有多个默认参数值的 Python 函数的示例：\ndef create_user(name, age=18, gender=\u0026#34;male\u0026#34;, email=None): user = {\u0026#34;name\u0026#34;: name, \u0026#34;age\u0026#34;: age, \u0026#34;gender\u0026#34;: gender} if email: user[\u0026#34;email\u0026#34;] = email return user user1 = create_user(\u0026#34;Alice\u0026#34;) user2 = create_user(\u0026#34;Bob\u0026#34;, 20) user3 = create_user(\u0026#34;Charlie\u0026#34;, gender=\u0026#34;female\u0026#34;, email=\u0026#34;charlie@example.com\u0026#34;) print(user1) # output: {\u0026#39;name\u0026#39;: \u0026#39;Alice\u0026#39;, \u0026#39;age\u0026#39;: 18, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;} print(user2) # output: {\u0026#39;name\u0026#39;: \u0026#39;Bob\u0026#39;, \u0026#39;age\u0026#39;: 20, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;} print(user3) # output: {\u0026#39;name\u0026#39;: \u0026#39;Charlie\u0026#39;, \u0026#39;age\u0026#39;: 18, \u0026#39;gender\u0026#39;: \u0026#39;female\u0026#39;, \u0026#39;email\u0026#39;: \u0026#39;charlie@example.com\u0026#39;} 关键字参数 kwarg=value 形式的关键字参数也可以用于调用函数。函数示例如下：\ndef parrot(voltage, state=\u0026#39;a stiff\u0026#39;, action=\u0026#39;voom\u0026#39;, type=\u0026#39;Norwegian Blue\u0026#39;): print(\u0026#34;-- This parrot wouldn\u0026#39;t\u0026#34;, action, end=\u0026#39; \u0026#39;) print(\u0026#34;if you put\u0026#34;, voltage, \u0026#34;volts through it.\u0026#34;) print(\u0026#34;-- Lovely plumage, the\u0026#34;, type) print(\u0026#34;-- It\u0026#39;s\u0026#34;, state, \u0026#34;!\u0026#34;) 该函数接受一个必选参数（voltage）和三个可选参数（state, action 和 type）。该函数可用下列方式调用：\nparrot(1000) # 1 positional argument parrot(voltage=1000) # 1 keyword argument parrot(voltage=1000000, action=\u0026#39;VOOOOOM\u0026#39;) # 2 keyword arguments parrot(action=\u0026#39;VOOOOOM\u0026#39;, voltage=1000000) # 2 keyword arguments parrot(\u0026#39;a million\u0026#39;, \u0026#39;bereft of life\u0026#39;, \u0026#39;jump\u0026#39;) # 3 positional arguments parrot(\u0026#39;a thousand\u0026#39;, state=\u0026#39;pushing up the daisies\u0026#39;) # 1 positional, 1 keyword 以下调用函数的方式都无效：\nparrot() # required argument missing parrot(voltage=5.0, \u0026#39;dead\u0026#39;) # non-keyword argument after a keyword argument parrot(110, voltage=220) # duplicate value for the same argument parrot(actor=\u0026#39;John Cleese\u0026#39;) # unknown keyword argument 函数调用时，关键字参数必须跟在位置参数后面。所有传递的关键字参数都必须匹配一个函数接受的参数（比如，actor 不是函数 parrot 的有效参数），关键字参数的顺序并不重要。这也包括必选参数，（比如，parrot(voltage=1000) 也有效）。不能对同一个参数多次赋值，下面就是一个因此限制而失败的例子：\ndef function(a): pass function(0, a=0) #Traceback (most recent call last): # File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; #TypeError: function() got multiple values for argument \u0026#39;a\u0026#39; 最后一个形参为 **name 形式时，接收一个字典，该字典包含与函数中已定义形参对应之外的所有关键字参数。**name 形参可以与 *name 形参（下一小节介绍）组合使用（*name 必须在 **name 前面）， *name 形参接收一个元组，该元组包含形参列表之外的位置参数。例如，可以定义下面这样的函数：\ndef cheeseshop(kind, *arguments, **keywords): print(\u0026#34;-- Do you have any\u0026#34;, kind, \u0026#34;?\u0026#34;) print(\u0026#34;-- I\u0026#39;m sorry, we\u0026#39;re all out of\u0026#34;, kind) for arg in arguments: print(arg) print(\u0026#34;-\u0026#34; * 40) for kw in keywords: print(kw, \u0026#34;:\u0026#34;, keywords[kw]) 该函数可以用如下方式调用：\ncheeseshop(\u0026#34;Limburger\u0026#34;, \u0026#34;It\u0026#39;s very runny, sir.\u0026#34;, \u0026#34;It\u0026#39;s really very, VERY runny, sir.\u0026#34;, shopkeeper=\u0026#34;Michael Palin\u0026#34;, client=\u0026#34;John Cleese\u0026#34;, sketch=\u0026#34;Cheese Shop Sketch\u0026#34;) 输出结果如下：\n-- Do you have any Limburger ? -- I\u0026#39;m sorry, we\u0026#39;re all out of Limburger It\u0026#39;s very runny, sir. It\u0026#39;s really very, VERY runny, sir. ---------------------------------------- shopkeeper : Michael Palin client : John Cleese sketch : Cheese Shop Sketch 注意，关键字参数在输出结果中的顺序与调用函数时的顺序一致。\n特殊参数 默认情况下，参数可以按位置或显式关键字传递给 Python 函数。为了让代码易读、高效，最好限制参数的传递方式，这样，开发者只需查看函数定义，即可确定参数项是仅按位置、按位置或关键字，还是仅按关键字传递。\n函数定义如下：\ndef f(pos1, pos2, /, pos_or_kwd, *, kwd1, kwd2): ----------- ---------- ---------- | | | | Positional or keyword | | - Keyword only -- Positional only / 和 * 是可选的。这些符号表明形参如何把参数值传递给函数：位置、位置或关键字、关键字。关键字形参也叫作命名形参。\n位置或关键字参数。函数定义中未使用 / 和 * 时，参数可以按位置或关键字传递给函数。\n仅位置参数。特定形参可以标记为 仅限位置。仅限位置 时，形参的顺序很重要，且这些形参不能用关键字传递。仅限位置形参应放在 / （正斜杠）前。/ 用于在逻辑上分割仅限位置形参与其它形参。如果函数定义中没有 /，则表示没有仅限位置形参。/ 后可以是 位置或关键字 或 仅限关键字 形参。\n仅限关键字参数。把形参标记为 仅限关键字，表明必须以关键字参数形式传递该形参，应在参数列表中第一个 仅限关键字 形参前添加 *。\n请看下面的函数定义示例，注意 / 和 * 标记：\ndef standard_arg(arg): print(arg) def pos_only_arg(arg, /): print(arg) def kwd_only_arg(*, arg): print(arg) def combined_example(pos_only, /, standard, *, kwd_only): print(pos_only, standard, kwd_only) 第一个函数定义 standard_arg 是最常见的形式，对调用方式没有任何限制，可以按位置也可以按关键字传递参数：\nstandard_arg(2) # 2 standard_arg(arg=2) # 2 第二个函数 pos_only_arg 的函数定义中有 /，仅限使用位置形参：\npos_only_arg(1) # 1 第三个函数 kwd_only_args 的函数定义通过 * 表明仅限关键字参数：\nkwd_only_arg(arg=3) # 3 最后一个函数在同一个函数定义中，使用了全部三种调用惯例：\ncombined_example(1, 2, kwd_only=3) # 1 2 3 combined_example(1, standard=2, kwd_only=3) #1 2 3 下面的函数定义中，kwds 把 name 当作键，因此，可能与位置参数 name 产生潜在冲突：\ndef foo(name, **kwds): return \u0026#39;name\u0026#39; in kwds 调用该函数不可能返回 True，因为关键字 'name' 总与第一个形参绑定。例如：\nfoo(1, **{\u0026#39;name\u0026#39;: 2}) #Traceback (most recent call last): # File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; #TypeError: foo() got multiple values for argument \u0026#39;name\u0026#39; 加上 / （仅限位置参数）后，就可以了。此时，函数定义把 name 当作位置参数，'name' 也可以作为关键字参数的键：\ndef foo(name, /, **kwds): return \u0026#39;name\u0026#39; in kwds foo(1, **{\u0026#39;name\u0026#39;: 2}) # True 换句话说，仅限位置形参的名称可以在 **kwds 中使用，而不产生歧义。\n任意实参列表 调用函数时，使用任意数量的实参是最少见的选项。这些实参包含在元组中。在可变数量的实参之前，可能有若干个普通参数：\ndef write_multiple_items(file, separator, *args): file.write(separator.join(args)) variadic 参数用于采集传递给函数的所有剩余参数，因此，它们通常在形参列表的末尾。*args 形参后的任何形式参数只能是仅限关键字参数，即只能用作关键字参数，不能用作位置参数：\ndef concat(*args, sep=\u0026#34;/\u0026#34;): return sep.join(args) concat(\u0026#34;earth\u0026#34;, \u0026#34;mars\u0026#34;, \u0026#34;venus\u0026#34;) concat(\u0026#34;earth\u0026#34;, \u0026#34;mars\u0026#34;, \u0026#34;venus\u0026#34;, sep=\u0026#34;.\u0026#34;) 解包实参列表 函数调用要求独立的位置参数，但实参在列表或元组里时，要执行相反的操作。例如，内置的 range() 函数要求独立的 start 和 stop 实参。如果这些参数不是独立的，则要在调用函数时，用 * 操作符把实参从列表或元组解包出来：\nlist(range(3, 6)) # normal call with separate arguments args = [3, 6] list(range(*args)) # call with arguments unpacked from a list 同样，字典可以用 ** 操作符传递关键字参数：\ndef parrot(voltage, state=\u0026#39;a stiff\u0026#39;, action=\u0026#39;voom\u0026#39;): print(\u0026#34;-- This parrot wouldn\u0026#39;t\u0026#34;, action, end=\u0026#39; \u0026#39;) print(\u0026#34;if you put\u0026#34;, voltage, \u0026#34;volts through it.\u0026#34;, end=\u0026#39; \u0026#39;) print(\u0026#34;E\u0026#39;s\u0026#34;, state, \u0026#34;!\u0026#34;) d = {\u0026#34;voltage\u0026#34;: \u0026#34;four million\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;bleedin\u0026#39; demised\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;VOOM\u0026#34;} parrot(**d) Lambda 函数 Python 中还有一种特殊的函数称为 lambda 函数，它是一种匿名函数，用于创建简短的函数。以下是一个 lambda 函数示例：\nadd_numbers = lambda x, y: x + y result = add_numbers(2, 3) print(result) 在上面的示例中，我们使用 lambda 关键字创建了一个匿名函数 add_numbers，它接受两个参数 x 和 y，并返回它们的和。我们可以使用 add_numbers(2, 3) 调用这个匿名函数，并将结果存储在变量 result 中。\n函数注解 Python 函数注解是一种在函数定义中添加元数据的功能。这些注解可以用于指定函数参数和返回值的类型、参数的默认值、函数的文档字符串等信息。虽然注解并不会影响 Python 函数的行为，但它们可以提供有用的信息，使代码更加清晰易读。\nPython 函数注解使用的语法是在函数定义的参数列表后面添加冒号和注解。以下是一个函数注解的示例：\ndef add_numbers(x: int, y: int) -\u0026gt; int: return x + y 在上面的示例中，我们使用注解指定了函数 add_numbers() 的两个参数 x 和 y 的类型为 int，并指定函数返回值的类型也为 int。在函数体中，我们使用加法运算符将这两个参数相加，并返回结果。\n函数注解还可以包含参数的默认值、参数的可变性和函数的文档字符串等信息。以下是一个包含这些信息的函数注解示例：\ndef greet(name: str = \u0026#34;World\u0026#34;, *, times: int = 1) -\u0026gt; str: \u0026#34;\u0026#34;\u0026#34; Greet a person by name and optionally repeat the greeting multiple times. :param name: The name of the person to greet. Default is \u0026#34;World\u0026#34;. :param times: The number of times to repeat the greeting. Default is 1. :return: A string containing the greeting message. \u0026#34;\u0026#34;\u0026#34; message = \u0026#34;Hello, \u0026#34; + name + \u0026#34;!\\n\u0026#34; * times return message 在上面的示例中，我们使用注解指定了函数 greet() 的参数 name 和 times 的类型为 str 和 int，并指定了参数 name 的默认值为 \u0026quot;World\u0026quot;，参数 times 的默认值为 1。我们还使用了函数的文档字符串来提供更详细的函数说明。\n标注 以字典的形式存放在函数的 __annotations__ 属性中，并且不会影响函数的任何其他部分。 形参标注的定义方式是在形参名后加冒号，后面跟一个表达式，该表达式会被求值为标注的值。 返回值标注的定义方式是加组合符号 -\u0026gt;，后面跟一个表达式，该标注位于形参列表和表示 def 语句结束的冒号之间。 下面的示例有一个必须的参数，一个可选的关键字参数以及返回值都带有相应的标注:\ndef f(ham: str, eggs: str = \u0026#39;eggs\u0026#39;) -\u0026gt; str: print(\u0026#34;Annotations:\u0026#34;, f.__annotations__) print(\u0026#34;Arguments:\u0026#34;, ham, eggs) return ham + \u0026#39; and \u0026#39; + eggs f(\u0026#39;spam\u0026#39;) ","permalink":"https://blog.chensoul.cc/posts/2023/06/25/python-function/","summary":"函数的定义 在 Python 中，函数是一段可重复使用的代码块，它接受一些输入（也称为参数）并产生一些输出。函数可以通过 def 关键字来定义，语法如下：\ndef function_name(parameters): \u0026#34;\u0026#34;\u0026#34;This is a function\u0026#34;\u0026#34;\u0026#34; # function body return value 其中，function_name 是函数的名称，parameters 是函数的参数列表，function body 是函数的主体部分，包括需要执行的代码和可能的返回语句，return value 是函数的返回值（如果有的话）。\n下列代码创建一个可以输出限定数值内的斐波那契数列函数：\ndef fib(n): # write Fibonacci series up to n \u0026#34;\u0026#34;\u0026#34;Print a Fibonacci series up to n.\u0026#34;\u0026#34;\u0026#34; a, b = 0, 1 while a \u0026lt; n: print(a, end=\u0026#39; \u0026#39;) a, b = b, a+b print() fib(2000) # 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 159 定义 函数使用关键字 def，后跟函数名与括号内的形参列表。函数语句从下一行开始，并且必须缩进。\n函数内的第一条语句是字符串时，该字符串就是文档字符串，也称为 docstring。利用文档字符串可以自动生成在线文档或打印版文档，还可以让开发者在浏览代码时直接查阅文档；Python 开发者最好养成在代码中加入文档字符串的好习惯。\n函数在 执行 时使用函数局部变量符号表，所有函数变量赋值都存在局部符号表中；引用变量时，首先，在局部符号表里查找变量，然后，是外层函数局部符号表，再是全局符号表，最后是内置名称符号表。因此，尽管可以引用全局变量和外层函数的变量，但最好不要在函数内直接赋值（除非是 global 语句定义的全局变量，或 nonlocal 语句定义的外层函数变量）。\n在调用函数时会将实际参数（实参）引入到被调用函数的局部符号表中；因此，实参是使用 按值调用 来传递的（其中的 值 始终是对象的 引用 而不是对象的值）。 1 当一个函数调用另外一个函数时，会为该调用创建一个新的局部符号表。","title":"Python学习5：函数"},{"content":" 我喜欢 bottle。它是一个简单、快速且功能强大的 Python 微框架，非常适合小型 Web 应用程序和快速原型设计。对于那些刚刚开始 Web 开发的人来说，它也是一个出色的学习工具。\n让我们看一个简单的例子。\n注意：本教程假设您正在运行基于 Unix 的环境 - 例如 Mac OS X、Linux 版本或通过虚拟机支持的 Linux 版本。\n06/13/2015 更新：更新了代码示例和解释。\n启动 首先，让我们创建一个工作目录：\n$ mkdir bottle \u0026amp;\u0026amp; cd bottle 接下来，您需要安装 pip、virtualenv 和 git。\nvirtualenv 是一个 Python 工具，可以轻松管理特定项目所需的 Python 包；它可以防止一个项目中的包与其他项目中的包发生冲突。同时，pip 是一个包管理器，用于管理 Python 包的安装。\n如需在 Unix 环境中安装 pip（及其依赖项）的帮助，请按照 此 Gist 中的说明进行操作。如果您使用的是 Windows 环境，请观看此视频以获取帮助。\n安装 pip 后，运行以下命令来安装 virtualenv：\n$ pip install virtualenv==12.0.7 现在我们可以轻松设置本地环境：\n$ virtualenv venv $ source venv/bin/activate 安装 bottle：\n$ pip install bottle==0.12.8 $ pip freeze \u0026gt; requirements.txt 最后，让我们使用 Git 将我们的应用程序置于版本控制之下。有关 Git 的更多信息，请 查看本文，其中还包括安装说明。\n编写你的应用程序 我们准备好编写我们的瓶子应用程序了。打开 Sublime Text 3 或您选择的文本编辑器。创建您的应用程序文件 app.py，它将保存我们第一个应用程序的全部内容：\nimport os from bottle import route, run, template index_html = \u0026#39;\u0026#39;\u0026#39;My first web app! By \u0026lt;strong\u0026gt;{{ author }}\u0026lt;/strong\u0026gt;.\u0026#39;\u0026#39;\u0026#39; @route(\u0026#39;/\u0026#39;) def index(): return template(index_html, author=\u0026#39;Real Python\u0026#39;) @route(\u0026#39;/name/\u0026lt;name\u0026gt;\u0026#39;) def name(name): return template(index_html, author=name) if __name__ == \u0026#39;__main__\u0026#39;: port = int(os.environ.get(\u0026#39;PORT\u0026#39;, 8080)) run(host=\u0026#39;0.0.0.0\u0026#39;, port=port, debug=True) 保存文件。\n现在您可以在本地运行您的应用程序：\n$ python app.py 您应该能够连接到 http://localhost:8080/ 并看到您的应用程序正在运行！\nMy first web app! By RealPython. 因此， @route 装饰器将一个函数绑定到路由。在第一个路由 / 中， index() 函数绑定到该路由，该路由渲染 index_html 模板并传入变量 author 作为关键字参数。然后可以在模板中访问该变量。\n现在导航到下一条路由，确保在路由末尾添加您的名字 - 即 http://localhost:8080/name/Michael。您应该看到类似以下内容：\nMy first web app! By Michael. 这是怎么回事？\n同样， @route 装饰器将一个函数绑定到路由。在本例中，我们使用包含通配符 \u0026lt;name\u0026gt; 的动态路由。\n然后，该通配符作为参数传递给视图函数 - def name(name) 。\n然后我们将其作为关键字参数传递给模板 - author=name\n然后模板渲染作者变量 - {{ author }} 。\nShell 脚本 想快速入门吗？使用此 Shell 脚本在几秒钟内生成入门应用程序。\nmkdir bottle cd bottle pip install virtualenv==12.0.7 virtualenv venv source venv/bin/activate pip install bottle==0.12.8 pip freeze \u0026gt; requirements.txt git init git add . git commit -m \u0026#34;initial commit\u0026#34; cat \u0026gt;app.py \u0026lt;\u0026lt;EOF import os from bottle import route, run, template index_html = \u0026#39;\u0026#39;\u0026#39;My first web app! By \u0026lt;strong\u0026gt;{{ author }}\u0026lt;/strong\u0026gt;.\u0026#39;\u0026#39;\u0026#39; @route(\u0026#39;/\u0026#39;) def index(): return template(index_html, author=\u0026#39;Real Python\u0026#39;) @route(\u0026#39;/name/\u0026lt;name\u0026gt;\u0026#39;) def name(name): return template(index_html, author=name) if __name__ == \u0026#39;__main__\u0026#39;: port = int(os.environ.get(\u0026#39;PORT\u0026#39;, 8080)) run(host=\u0026#39;0.0.0.0\u0026#39;, port=port, debug=True) EOF chmod a+x app.py git init git add . git commit -m \u0026#34;Updated\u0026#34; 从此要点下载此脚本，然后使用以下命令运行它：\n$ bash bottle.sh 下一步 从这一点来看，创建新页面就像添加新的 @route 装饰函数一样简单。\n创建 HTML 很简单：在上面的应用程序中，我们只是将 HTML 内联到文件本身中。修改它以从文件加载模板很容易。例如：\n@route(\u0026#39;/main\u0026#39;) def main(name): return template(\u0026#39;main_template\u0026#39;) 这将加载模板文件 main_template.tpl ，该文件必须放置在项目结构中的 views 文件夹中，并将其呈现给最终用户。\n有关详细信息，请参阅 bottle 文档。\n基本设置 首先从第 1 部分下载此 Gist，然后使用以下命令运行它：\n$ bash bottle.sh 这将创建一个基本的项目结构：\n├── app.py ├── requirements.txt └── testenv 激活虚拟环境：\n$ cd bottle $ source testenv/bin/activate 安装要求：\n$ pip install -r requirements.txt 导航到 https://www.plot.ly/api，注册一个新帐户，登录，然后创建一个新的 API 密钥：\n复制该密钥。\n安装 plot.ly：\n$ pip install plotly==1.2.6 接下来更新 app.py 中的代码：\nimport os from bottle import run, template, get, post, request import plotly.plotly as py from plotly.graph_objs import * # add your username and api key py.sign_in(\u0026#34;realpython\u0026#34;, \u0026#34;lijlflx93\u0026#34;) @get(\u0026#39;/plot\u0026#39;) def form(): return \u0026#39;\u0026#39;\u0026#39;\u0026lt;h2\u0026gt;Graph via Plot.ly\u0026lt;/h2\u0026gt; \u0026lt;form method=\u0026#34;POST\u0026#34; action=\u0026#34;/plot\u0026#34;\u0026gt; Name: \u0026lt;input name=\u0026#34;name1\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt; Age: \u0026lt;input name=\u0026#34;age1\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt;\u0026lt;br/\u0026gt; Name: \u0026lt;input name=\u0026#34;name2\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt; Age: \u0026lt;input name=\u0026#34;age2\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt;\u0026lt;br/\u0026gt; Name: \u0026lt;input name=\u0026#34;name3\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt; Age: \u0026lt;input name=\u0026#34;age3\u0026#34; type=\u0026#34;text\u0026#34; /\u0026gt;\u0026lt;br/\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt;\u0026#39;\u0026#39;\u0026#39; @post(\u0026#39;/plot\u0026#39;) def submit(): # grab data from form name1 = request.forms.get(\u0026#39;name1\u0026#39;) age1 = request.forms.get(\u0026#39;age1\u0026#39;) name2 = request.forms.get(\u0026#39;name2\u0026#39;) age2 = request.forms.get(\u0026#39;age2\u0026#39;) name3 = request.forms.get(\u0026#39;name3\u0026#39;) age3 = request.forms.get(\u0026#39;age3\u0026#39;) data = Data([ Bar( x=[name1, name2, name3], y=[age1, age2, age3] ) ]) # make api call response = py.plot(data, filename=\u0026#39;basic-bar\u0026#39;) if response: return template(\u0026#39;\u0026#39;\u0026#39; \u0026lt;h1\u0026gt;Congrats!\u0026lt;/h1\u0026gt; \u0026lt;div\u0026gt; View your graph here: \u0026lt;a href=\u0026#34;{{response}}\u0026#34;\u0026lt;/a\u0026gt;{{response}} \u0026lt;/div\u0026gt; \u0026#39;\u0026#39;\u0026#39;, response=response ) if __name__ == \u0026#39;__main__\u0026#39;: port = int(os.environ.get(\u0026#39;PORT\u0026#39;, 8080)) run(host=\u0026#39;0.0.0.0\u0026#39;, port=port, debug=True) 这里发生了什么？\n第一个函数 form() 创建一个 HTML 表单，用于捕获制作简单条形图所需的数据。 与此同时，第二个函数 submit() 抓取表单输入，将它们分配给变量，然后调用 plot.ly API，传递我们的凭据和数据，以生成新图表。确保将我的用户名和 API 密钥替换为您自己的凭据。不要使用我的。不起作用。 测试 在本地运行您的应用程序， python app.py ，并将浏览器指向 http://localhost:8080/plot。\n输入三个人的姓名及其各自的年龄。按“提交”，如果一切顺利，您应该会看到一条祝贺消息和一个 URL。单击 URL 查看您的图表：\n如果您收到此消息的 500 错误 - Aw, snap! Looks like you supplied the wrong API key. Want to try again? You can always view your key at https://plot.ly/api/key. When you display your key at https://plot.ly/api/key, make sure that you're logged in as realpython. - 您需要更新您的 API 密钥。\n另外，如果这是一个真正的、面向客户端的应用程序，您会希望比这更优雅地处理错误。仅供参考。\n群组分析 接下来，让我们看一个更复杂的示例，为以下队列分析统计数据创建图表：\nCohort 2011 2012 2013 2014 0 310 348 228 250 1 55 157 73 34 2 18 37 33 34 3 2 4 4 3 我们将基于同一个应用程序 - app.py 进行构建，但创建一个新文件：打开 app.py，然后“另存为”cohort.py。\n首先升级到简单模板引擎，这样我们就可以将样式和 Javascript 文件添加到我们的模板中。添加一个名为“views”的新文件夹，然后在该目录中创建一个名为 template.tpl 的新文件。将以下代码添加到该文件中：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;{{ title }}\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; media=\u0026#34;screen\u0026#34;\u0026gt; \u0026lt;style\u0026gt; body { padding: 60px 0px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Graph via Plot.ly\u0026lt;/h1\u0026gt; \u0026lt;form role=\u0026#34;form\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;/plot\u0026#34;\u0026gt; \u0026lt;table\u0026gt; \u0026lt;td\u0026gt; \u0026lt;h3\u0026gt;2011\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;form-group\u0026#34; \u0026#34;col-md-2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y01\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 0\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y02\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 1\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y03\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y04\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 3\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;h3\u0026gt;2012\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;form-group\u0026#34; \u0026#34;col-md-2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y11\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 0\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y12\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 1\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y13\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y44\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 3\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;h3\u0026gt;2013\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;form-group\u0026#34; \u0026#34;col-md-2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y21\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 0\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y22\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 1\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y23\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y24\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 3\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;td\u0026gt; \u0026lt;h3\u0026gt;2014\u0026lt;/h3\u0026gt; \u0026lt;div class=\u0026#34;form-group\u0026#34; \u0026#34;col-md-2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y31\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 0\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y32\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 1\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y33\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 2\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;Y34\u0026#34; class=\u0026#34;form-control\u0026#34; placeholder=\u0026#34;Cohort 3\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; class=\u0026#34;btn btn-default\u0026#34;\u0026gt;Submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;http://code.jquery.com/jquery-1.10.2.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 您可能知道，这看起来就像一个 HTML 文件。不同之处在于我们可以使用语法 - {{ python_variable }} 将 Python 变量传递到文件。\n创建 data.json 文件并添加您的 Plot.ly 用户名和 API 密钥。您可以在 此处 查看示例文件。\n将以下代码添加到 cohort.py 中，以便在我们进行 API 调用时访问 data.json 以使用凭据：\nimport os from bottle import run, template, get, post, request import plotly.plotly as py from plotly.graph_objs import * import json # grab username and key from config/data file with open(\u0026#39;data.json\u0026#39;) as config_file: config_data = json.load(config_file) username = config_data[\u0026#34;user\u0026#34;] key = config_data[\u0026#34;key\u0026#34;] py.sign_in(username, key) 现在我们不必将我们的密钥暴露给整个宇宙。只要确保使其不受版本控制即可。\n接下来更新功能：\nimport os from bottle import run, template, get, post, request import plotly.plotly as py from plotly.graph_objs import * import json # grab username and key from config/data file with open(\u0026#39;data.json\u0026#39;) as config_file: config_data = json.load(config_file) username = config_data[\u0026#34;user\u0026#34;] key = config_data[\u0026#34;key\u0026#34;] py.sign_in(username, key) @get(\u0026#39;/plot\u0026#39;) def form(): return template(\u0026#39;template\u0026#39;, title=\u0026#39;Plot.ly Graph\u0026#39;) @post(\u0026#39;/plot\u0026#39;) def submit(): # grab data from form Y01 = request.forms.get(\u0026#39;Y01\u0026#39;) Y02 = request.forms.get(\u0026#39;Y02\u0026#39;) Y03 = request.forms.get(\u0026#39;Y03\u0026#39;) Y04 = request.forms.get(\u0026#39;Y04\u0026#39;) Y11 = request.forms.get(\u0026#39;Y11\u0026#39;) Y12 = request.forms.get(\u0026#39;Y12\u0026#39;) Y13 = request.forms.get(\u0026#39;Y13\u0026#39;) Y14 = request.forms.get(\u0026#39;Y14\u0026#39;) Y21 = request.forms.get(\u0026#39;Y21\u0026#39;) Y22 = request.forms.get(\u0026#39;Y22\u0026#39;) Y23 = request.forms.get(\u0026#39;Y23\u0026#39;) Y24 = request.forms.get(\u0026#39;Y24\u0026#39;) Y31 = request.forms.get(\u0026#39;Y31\u0026#39;) Y32 = request.forms.get(\u0026#39;Y32\u0026#39;) Y33 = request.forms.get(\u0026#39;Y33\u0026#39;) Y34 = request.forms.get(\u0026#39;Y34\u0026#39;) trace1 = Scatter( x=[1, 2, 3, 4], y=[Y01, Y02, Y03, Y04] ) trace2 = Scatter( x=[1, 2, 3, 4], y=[Y11, Y12, Y13, Y14] ) trace3 = Scatter( x=[1, 2, 3, 4], y=[Y21, Y22, Y23, Y24] ) trace4 = Scatter( x=[1, 2, 3, 4], y=[Y31, Y32, Y33, Y34] ) data = Data([trace1, trace2, trace3, trace4]) # api call plot_url = py.plot(data, filename=\u0026#39;basic-line\u0026#39;) return template(\u0026#39;template2\u0026#39;, title=\u0026#39;Plot.ly Graph\u0026#39;, plot_url=str(plot_url)) if __name__ == \u0026#39;__main__\u0026#39;: port = int(os.environ.get(\u0026#39;PORT\u0026#39;, 8080)) run(host=\u0026#39;0.0.0.0\u0026#39;, port=port, debug=True) 请注意 return 声明。我们传入模板的名称以及任何变量。让我们创建一个名为 template2.tpl 的新模板：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;{{ title }}\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;link href=\u0026#34;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; media=\u0026#34;screen\u0026#34; /\u0026gt; \u0026lt;style\u0026gt; body { padding: 60px 0px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Graph via Plot.ly\u0026lt;/h1\u0026gt; \u0026lt;br /\u0026gt; \u0026lt;a href=\u0026#34;/plot\u0026#34;\u0026gt;\u0026lt;button class=\u0026#34;btn btn-default\u0026#34;\u0026gt;Back\u0026lt;/button\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;iframe id=\u0026#34;igraph\u0026#34; src=\u0026#34;{{plot_url}}\u0026#34; width=\u0026#34;900\u0026#34; height=\u0026#34;450\u0026#34; seamless=\u0026#34;seamless\u0026#34; scrolling=\u0026#34;no\u0026#34; \u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;http://code.jquery.com/jquery-1.10.2.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 因此，iframe 允许我们更新表单，然后显示实际内容/图表以及更新后的更改。换句话说，我们不必离开站点即可查看图表。\n运行。将值添加到表单中。然后提交。您的图表现在应如下所示：\n结论 您可以从此存储库中获取所有文件。\n下次见！\n原文链接：\nhttps://realpython.com/developing-with-bottle-part-1/ https://realpython.com/developing-with-bottle-part-2-plot-ly-api ","permalink":"https://blog.chensoul.cc/posts/2023/06/25/developing-with-bottle/","summary":"我喜欢 bottle。它是一个简单、快速且功能强大的 Python 微框架，非常适合小型 Web 应用程序和快速原型设计。对于那些刚刚开始 Web 开发的人来说，它也是一个出色的学习工具。\n让我们看一个简单的例子。\n注意：本教程假设您正在运行基于 Unix 的环境 - 例如 Mac OS X、Linux 版本或通过虚拟机支持的 Linux 版本。\n06/13/2015 更新：更新了代码示例和解释。\n启动 首先，让我们创建一个工作目录：\n$ mkdir bottle \u0026amp;\u0026amp; cd bottle 接下来，您需要安装 pip、virtualenv 和 git。\nvirtualenv 是一个 Python 工具，可以轻松管理特定项目所需的 Python 包；它可以防止一个项目中的包与其他项目中的包发生冲突。同时，pip 是一个包管理器，用于管理 Python 包的安装。\n如需在 Unix 环境中安装 pip（及其依赖项）的帮助，请按照 此 Gist 中的说明进行操作。如果您使用的是 Windows 环境，请观看此视频以获取帮助。\n安装 pip 后，运行以下命令来安装 virtualenv：\n$ pip install virtualenv==12.0.7 现在我们可以轻松设置本地环境：\n$ virtualenv venv $ source venv/bin/activate 安装 bottle：\n$ pip install bottle==0.12.8 $ pip freeze \u0026gt; requirements.txt 最后，让我们使用 Git 将我们的应用程序置于版本控制之下。有关 Git 的更多信息，请 查看本文，其中还包括安装说明。\n编写你的应用程序 我们准备好编写我们的瓶子应用程序了。打开 Sublime Text 3 或您选择的文本编辑器。创建您的应用程序文件 app.py，它将保存我们第一个应用程序的全部内容：\nimport os from bottle import route, run, template index_html = \u0026#39;\u0026#39;\u0026#39;My first web app!","title":"[译]用 Bottle 开发"},{"content":"前言 本篇是对 2023-06-12 到 2023-06-18 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n读书 本周尚未读书。\n健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周尚未跑步。\n理财 这周总计支出 1264 元，明细如下：\n6 月 18 日：338 元\n6 月 17 日：508 元\n6 月 16 日：262 元\n6 月 15 日：27 元\n6 月 14 日：41 元\n6 月 13 日：40 元\n6 月 12 日：48 元\n陪家人 本周因为老爸出院后需要人照料，所以我每天早晚往返于家（阳逻）和公司（光谷）之间。每天早上五点多就醒了，然后煮粥、招呼老爸吃饭喝药，六点半出门开车走三环去上班。这周请婶娘白天帮忙照顾老爸，主要是中午和晚上老爸要吃饭和喝药。我早上出门晚、晚上下班回来再照顾老爸。老爸胃溃疡，需要修养一个多月，另外最近痛风发作，身体多处关节疼痛。因为吃西药和打针都会伤胃，所以只能吃中药。中药见效慢，需要时间。而婶娘身上也有病，不能长期照顾，如果老爸这周痛风不能恢复，那下周只能老婆放下手上工作回来照顾老爸。老婆工作也是非常忙碌，也不能照顾太久，估计也就一个星期。如果过了一个星期，老爸还是不能恢复、不能生活自理，真不知道该怎么办了！很久之前就想到老爸可能会成为我的负担，影响我的工作，没有想到会来的这么快。有时候想抱怨，但抱怨有什么用？面对眼前的这一切，只能迎难面对。造成眼前这样的现状，我自己有一部分责任。都只怪我平时没有关心老爸，没有叮嘱老爸不要喝酒，在老爸身边陪伴的时间太少了。\n周六去给岳父岳母送端午节，周日回去看望癌症转移到全身的六舅。六舅是乳腺癌，在经历了去年新冠疫情之后，癌细胞转移到肺部。年后没有引起足够的重视，直到痛的不行的时候才去医院做手术，错过了最佳治疗时机。上一次见到六舅还是四月份的时候，我开车带老婆一起回去看望老爸。那时候六舅还在菜园里面朝黄土背朝天，六舅给了我一些莴笋、包菜，老婆给六舅 3 百块钱，六舅硬是不要，拉扯了半天。走之前，六舅还叫何舅塞了 20 多个鸡蛋给我们。这次，再见六舅，六舅躺在床上全身疼痛，只能吃些流食，意识模糊，知道谁来看望她，却不能说话。每次开车上下班的时候，想起六舅这样子，心里就很难受，眼泪直打转。面对生老病死，成年人的崩溃只在一瞬间。昨日还在你面前混蹦乱跳的人，明天可能就不在了。为了不留遗憾，要善待身边的每一位亲人，常回家看看。感谢老婆总是提醒我要回家看望老爸，正是因为这个，每次回家看望老爸的时候，我都会去看下六舅。\n如果没有疼痛，老爸和六舅就不会痛苦了，身边的人也就不会心痛。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成四篇博客：\n[译]为恐龙解释现代 CSS\n[译]为恐龙解释现代 HTML\n[译]为恐龙解释现代 JavaScript\n《Effective Java 3》笔记 15：尽量减少类和成员的可访问性\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。\n📌2023-06-14 现代 JavaScript 教程，以最新的 JavaScript 标准为基准。通过简单但足够详细的内容，为你讲解从基础到高阶的 JavaScript 相关知识。 https://zh.javascript.info/ #memos #javascript 📌2023-06-14 推荐几个远程办公招聘网站，国外的 https://nomadlist.com/ https://remotive.com/ https://remoteok.com/ https://www.huntsbot.com/ https://www.freelancer.cn/jobs #memos 📌2023-06-14 拒绝 996，谈谈远程办公一年多的感受 https://www.v2ex.com/t/947355 #memos 📌2023-06-14 新手入门 Python 该如何学，学什么，学多久？看完这些你就明白了#memos #python https://blog.csdn.net/libaiup/article/details/131083707 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/21/weekly_review_24/","summary":"前言 本篇是对 2023-06-12 到 2023-06-18 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n读书 本周尚未读书。\n健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周尚未跑步。\n理财 这周总计支出 1264 元，明细如下：\n6 月 18 日：338 元\n6 月 17 日：508 元\n6 月 16 日：262 元\n6 月 15 日：27 元\n6 月 14 日：41 元\n6 月 13 日：40 元\n6 月 12 日：48 元\n陪家人 本周因为老爸出院后需要人照料，所以我每天早晚往返于家（阳逻）和公司（光谷）之间。每天早上五点多就醒了，然后煮粥、招呼老爸吃饭喝药，六点半出门开车走三环去上班。这周请婶娘白天帮忙照顾老爸，主要是中午和晚上老爸要吃饭和喝药。我早上出门晚、晚上下班回来再照顾老爸。老爸胃溃疡，需要修养一个多月，另外最近痛风发作，身体多处关节疼痛。因为吃西药和打针都会伤胃，所以只能吃中药。中药见效慢，需要时间。而婶娘身上也有病，不能长期照顾，如果老爸这周痛风不能恢复，那下周只能老婆放下手上工作回来照顾老爸。老婆工作也是非常忙碌，也不能照顾太久，估计也就一个星期。如果过了一个星期，老爸还是不能恢复、不能生活自理，真不知道该怎么办了！很久之前就想到老爸可能会成为我的负担，影响我的工作，没有想到会来的这么快。有时候想抱怨，但抱怨有什么用？面对眼前的这一切，只能迎难面对。造成眼前这样的现状，我自己有一部分责任。都只怪我平时没有关心老爸，没有叮嘱老爸不要喝酒，在老爸身边陪伴的时间太少了。\n周六去给岳父岳母送端午节，周日回去看望癌症转移到全身的六舅。六舅是乳腺癌，在经历了去年新冠疫情之后，癌细胞转移到肺部。年后没有引起足够的重视，直到痛的不行的时候才去医院做手术，错过了最佳治疗时机。上一次见到六舅还是四月份的时候，我开车带老婆一起回去看望老爸。那时候六舅还在菜园里面朝黄土背朝天，六舅给了我一些莴笋、包菜，老婆给六舅 3 百块钱，六舅硬是不要，拉扯了半天。走之前，六舅还叫何舅塞了 20 多个鸡蛋给我们。这次，再见六舅，六舅躺在床上全身疼痛，只能吃些流食，意识模糊，知道谁来看望她，却不能说话。每次开车上下班的时候，想起六舅这样子，心里就很难受，眼泪直打转。面对生老病死，成年人的崩溃只在一瞬间。昨日还在你面前混蹦乱跳的人，明天可能就不在了。为了不留遗憾，要善待身边的每一位亲人，常回家看看。感谢老婆总是提醒我要回家看望老爸，正是因为这个，每次回家看望老爸的时候，我都会去看下六舅。\n如果没有疼痛，老爸和六舅就不会痛苦了，身边的人也就不会心痛。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成四篇博客：\n[译]为恐龙解释现代 CSS\n[译]为恐龙解释现代 HTML\n[译]为恐龙解释现代 JavaScript\n《Effective Java 3》笔记 15：尽量减少类和成员的可访问性\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。","title":"周报-24｜如果没有疼痛"},{"content":" 奇怪的是，CSS 被认为是作为 Web 开发人员最容易学习和最难学习的语言之一。开始使用它当然很容易 - 您可以定义样式属性和值以应用于特定元素，然后\u0026hellip;\u0026hellip;这几乎就是您开始所需的一切！但是，对于大型项目，以有意义的方式组织 CSS 会变得纠结和复杂。更改任何一行 CSS 以设置一个页面上元素的样式通常会导致其他页面上的元素发生意外更改。\n为了处理 CSS 固有的复杂性，已经建立了各种不同的最佳实践。问题在于，对于哪些最佳实践实际上是最好的，没有任何强烈的共识，其中许多似乎完全相互矛盾。如果你是第一次尝试学习 CSS，至少可以说这可能会让人迷失方向。\n本文的目的是提供一个历史背景，说明 CSS 方法和工具如何在 2018 年发展到今天的样子。通过了解这段历史，将更容易理解每种方法以及如何使用它们来为您带来好处。让我们开始吧！\n更新：我制作了本文的新视频课程版本，该版本更深入地介绍了材料，请在此处查看： https://firstclass.actualize.co/p/modern-css-explained-for-dinosaurs\n使用 CSS 进行基本样式设置 让我们从一个基本网站开始，仅使用一个简单的 index.html 文件链接到一个单独的 index.css 文件：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Modern CSS\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header\u0026gt;This is the header.\u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;h1\u0026gt;This is the main content.\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;h4\u0026gt;This is the navigation section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;aside\u0026gt; \u0026lt;h4\u0026gt;This is an aside section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;footer\u0026gt;This is the footer.\u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在我们在 HTML 中没有使用任何类或 ID，只是 语义标签。没有任何 CSS，网站看起来像这样（使用占位符文本）：\n功能齐全，但不是很漂亮。我们可以添加 CSS 来改进 index.css 中的基本排版：\n/* BASIC TYPOGRAPHY */ /* from https://github.com/oxalorg/sakura */ html { font-size: 62.5%; font-family: serif; } body { font-size: 1.8rem; line-height: 1.618; max-width: 38em; margin: auto; color: #4a4a4a; background-color: #f9f9f9; padding: 13px; } @media (max-width: 684px) { body { font-size: 1.53rem; } } @media (max-width: 382px) { body { font-size: 1.35rem; } } h1, h2, h3, h4, h5, h6 { line-height: 1.1; font-family: Verdana, Geneva, sans-serif; font-weight: 700; overflow-wrap: break-word; word-wrap: break-word; -ms-word-break: break-all; word-break: break-word; -ms-hyphens: auto; -moz-hyphens: auto; -webkit-hyphens: auto; hyphens: auto; } h1 { font-size: 2.35em; } h2 { font-size: 2em; } h3 { font-size: 1.75em; } h4 { font-size: 1.5em; } h5 { font-size: 1.25em; } h6 { font-size: 1em; } 在这里，大多数 CSS 都是样式排版（具有大小，行高等的字体），并带有一些颜色样式和居中布局。你必须研究设计才能知道要为每个属性选择的好值（这些样式来自 sakura.css），但这里应用的 CSS 本身并不太复杂。结果如下所示：\n如此不同！这就是 CSS 的承诺 - 一种向文档添加样式的简单方法，无需编程或复杂的逻辑。不幸的是，当我们使用 CSS 不仅仅是排版和颜色时，事情开始变得更加毛茸茸（我们将在下面解决）。\n使用 CSS 进行布局 在 1990 年代，在 CSS 被广泛采用之前，在页面上布局内容的选项并不多。HTML 最初被设计为一种创建普通文档的语言，而不是带有侧边栏，列等的动态网站。在早期，布局通常使用 HTML 表格完成——整个网页将位于一个表格中，可用于在行和列中组织内容。这种方法奏效了，但缺点是内容和呈现的紧密耦合——如果你想改变网站的布局，就需要重写大量的 HTML。\n一旦 CSS 进入场景，就强烈推动将内容（用 HTML 编写）与演示（用 CSS 编写）分开。因此，人们找到了将所有布局代码从 HTML（不再有表格）移动到 CSS 中的方法。需要注意的是，与 HTML 一样，CSS 也不是真正设计为在页面上布局内容，因此早期尝试这种关注点分离很难优雅地实现。\n让我们通过上面的例子来看看这在实践中是如何工作的。在我们定义任何 CSS 布局之前，我们将首先重置任何边距和填充（这会影响布局计算），并为部分提供不同的颜色（不是为了让它漂亮，而是为了让每个部分在测试不同的布局时在视觉上脱颖而出）。\n/* RESET LAYOUT AND ADD COLORS */ body { margin: 0; padding: 0; max-width: inherit; background: #fff; color: #4a4a4a; } header, footer { font-size: large; text-align: center; padding: 0.3em 0; background-color: #4a4a4a; color: #f9f9f9; } nav { background: #eee; } main { background: #f9f9f9; } aside { background: #eee; } 现在网站暂时看起来像：\n单击此处查看实时示例 现在，我们已准备好使用 CSS 在页面上布局内容。我们将按时间顺序介绍三种不同的方法，从经典的基于 float 的布局开始。\n基于 float 的布局 CSS float 属性最初是为了在左侧或右侧的文本列内浮动图像（您经常在报纸上看到的）。2000 年代初期的 Web 开发人员利用了这样一个事实，即您不仅可以浮动图像，还可以浮动任何元素，这意味着您可以通过浮动整个内容 div 来创建行和列的错觉。但同样，浮动不是为此目的而设计的，因此很难以一致的方式创造这种错觉。\n2006 年，A List Apart 发表了一篇受欢迎的文章《寻找圣杯》，其中概述了一种详细而彻底的方法来创建所谓的圣杯布局 - 一个页眉，三列和一个页脚。认为听起来相当简单的布局被称为圣杯是相当疯狂的，但这确实是当时使用纯 CSS 创建一致的布局是多么困难。\n下面是基于该文章中描述的技术的示例的基于 float 的布局：\n/* FLOAT-BASED LAYOUT */ body { padding-left: 200px; padding-right: 190px; min-width: 240px; } header, footer { margin-left: -200px; margin-right: -190px; } main, nav, aside { position: relative; float: left; } main { padding: 0 20px; width: 100%; } nav { width: 180px; padding: 0 10px; right: 240px; margin-left: -100%; } aside { width: 130px; padding: 0 10px; margin-right: -100%; } footer { clear: both; } * html nav { left: 150px; } 看看 C SS，你可以看到有很多技巧需要让它工作（负边距， clear: both 属性，硬编码宽度计算等）——这篇 文章 很好地详细解释了每个原因。结果如下所示：\n单击此处查看实时示例 这很好，但您可以从颜色中看到三列的高度不相等，并且页面没有填满屏幕的高度。这些问题是基于浮动的方法所固有的。浮动所能做的就是将内容放在一个部分的左侧或右侧——CSS 无法推断其他部分中内容的高度。这个问题直到多年后才有了直接的解决方案，采用了基于弹性框的布局。\n基于弹性框的布局 flexbox CSS 属性于 2009 年首次提出，但直到 2015 年左右才被广泛采用。Flexbox 旨在定义空间在单个列或行中的分布方式，与使用浮动相比，这使其成为定义布局的更好候选项。这意味着在使用基于浮动的布局大约十年之后，Web 开发人员终于能够使用 CSS 进行布局，而无需使用浮动所需的技巧。\n下面是基于弹性框的示例布局，基于站点上描述的技术 由弹性框解决 （一个展示不同弹性框示例的流行资源）。请注意，为了使 flexbox 工作，我们需要在 HTML 中的三列周围增加一个包装器 div：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Modern CSS\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header\u0026gt;This is the header.\u0026lt;/header\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;main\u0026gt; \u0026lt;h1\u0026gt;This is the main content.\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;h4\u0026gt;This is the navigation section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;aside\u0026gt; \u0026lt;h4\u0026gt;This is an aside section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;footer\u0026gt;This is the footer.\u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这是 CSS 中的弹性框代码：\n/* FLEXBOX-BASED LAYOUT */ body { min-height: 100vh; display: flex; flex-direction: column; } .container { display: flex; flex: 1; } main { flex: 1; padding: 0 20px; } nav { flex: 0 0 180px; padding: 0 10px; order: -1; } aside { flex: 0 0 130px; padding: 0 10px; } 也就是说，与基于浮动的布局方法相比，更紧凑！flexbox 的属性和值乍一看有点令人困惑，但它消除了对许多技巧的需求，例如基于浮动的布局所必需的负边距——这是一个巨大的胜利。结果如下所示：\n单击此处查看实时示例 好多了！这些列的高度都相等，并占据页面的整个高度。从某种意义上说，这似乎是完美的，但这种方法有几个小缺点。一个是浏览器支持 - 目前每个现代浏览器都支持 f lexbox，但一些较旧的浏览器永远不会。幸运的是，浏览器供应商正在加大力度终止对这些旧浏览器的支持，为网页设计师提供更一致的开发体验。另一个缺点是我们需要将 \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; 添加到标记中——避免它会很好。在理想的世界中，任何 CSS 布局都根本不需要更改 HTML 标记。\n最大的缺点是 CSS 本身的代码 - flexbox 消除了许多浮动黑客，但代码并不像定义布局那样富有表现力。很难阅读 flexbox CSS 并直观地理解所有元素在页面上的布局方式。这会导致在编写基于 flexbox 的布局时进行大量猜测和检查。\n再次需要注意的是，flexbox 旨在将元素间隔在单个列或行内 - 它不是为整个页面布局设计的！尽管它做了一个有用的工作（比基于浮动的布局好得多），但专门开发了不同的规范来处理具有多行和多列的布局。此规范称为 CSS 网格。\n基于网格的布局 CSS 网格于 2011 年首次提出（在 flexbox 提案之后不久），但花了很长时间才在浏览器中得到广泛采用。截至 2018 年初，大多数现代浏览器都支持 CSS 网格（甚至比一两年前有了巨大的改进）。\n下面是基于此 CSS 技巧文章 中的第一种方法的示例的基于网格的布局。请注意，对于此示例，我们可以摆脱必须为基于 flexbox 的布局添加的 \u0026lt;div class=\u0026quot;container\u0026quot;\u0026gt; — 我们可以简单地使用原始 HTML，而无需修改。以下是 CSS 的外观：\n/* GRID-BASED LAYOUT */ body { display: grid; min-height: 100vh; grid-template-columns: 200px 1fr 150px; grid-template-rows: min-content 1fr min-content; } header { grid-row: 1; grid-column: 1 / 4; } nav { grid-row: 2; grid-column: 1 / 2; padding: 0 10px; } main { grid-row: 2; grid-column: 2 / 3; padding: 0 20px; } aside { grid-row: 2; grid-column: 3 / 4; padding: 0 10px; } footer { grid-row: 3; grid-column: 1 / 4; } 结果在视觉上与基于弹性框的布局相同。但是，这里的 CSS 在清楚地表达所需布局的意义上得到了很大的改进。列和行的大小和形状在正文选择器中定义，网格中的每个项目都由其位置直接定义。\n可能令人困惑的一件事是 grid-column 属性，它定义了列的起点/终点。这可能会令人困惑，因为在此示例中，有 3 列，但数字范围从 1 到 4。当你看下面的图片时，它会变得更加清晰：\n单击此处查看实时示例 第一列从 1 开始，到 2 结束，第二列从 2 开始，到 3 结束，第三列从 3 开始，到 4 结束。标题的 grid-column 为 1 / 4 以跨越整个页面，导航具有 grid-column of 1 / 2 以跨越第一列，依此类推。\n一旦你习惯了网格语法，它显然成为在 CSS 中表达布局的理想方式。基于网格的布局唯一真正的缺点是浏览器支持，在过去一年中再次有了很大的改进。CSS 网格作为 CSS 中第一个真正为布局而设计的工具的重要性怎么强调都不为过。从某种意义上说，网页设计师在制作创意布局时总是必须非常保守，因为到目前为止的工具一直很脆弱，使用各种黑客和解决方法。现在 CSS 网格已经存在，有可能出现以前从未有过的创意布局设计的新浪潮 - 激动人心的时代！\n将 CSS 预处理器用于新语法 到目前为止，我们已经介绍了使用 CSS 进行基本样式和布局。现在，我们将介绍为帮助改善将 CSS 作为语言本身使用的体验而创建的工具，从 CSS 预处理器开始。\nCSS 预处理器允许您使用不同的语言编写样式，该语言被转换为浏览器可以理解的 CSS。这在浏览器实现新功能非常缓慢的时代至关重要。第一个主要的 CSS 预处理器是 Sass，于 2006 年发布。它具有新的简洁语法（缩进而不是括号，没有分号等），并添加了 CSS 中缺少的高级功能，例如变量，帮助程序函数和计算。下面是我们前面示例的颜色部分使用带有变量的 Sass 的样子：\n$dark-color: #4a4a4a $light-color: #f9f9f9 $side-color: #eee body color: $dark-color header, footer background-color: $dark-color color: $light-color main background: $light-color nav, aside background: $side-color 请注意如何使用 $ 符号定义可重用变量，并删除括号和分号，从而使语法看起来更简洁。Sass 中更简洁的语法很好，但是像变量这样的功能在当时是革命性的，因为它们为编写干净和可维护的 CSS 开辟了新的可能性。\n要使用 Sass，您需要 安装 Ruby，这是一种用于将 Sass 代码编译为常规 CSS 的编程语言。然后，您需要安装 Sass gem，然后在命令行中运行命令以将 .sass 文件转换为 .css 文件。下面是命令的外观示例：\nsass --watch index.sass index.css 此命令会将编写在名为 index.sass 的文件中的 Sass 代码转换为名为 index.css 的文件中的常规 CSS（ --watch 参数告诉它在保存时输入更改时随时运行，这很方便）。\n这个过程被称为构建步骤，这在 2006 年是一个相当大的进入障碍。如果您习惯了像 Ruby 这样的编程语言，那么这个过程非常简单。但是当时许多前端开发人员只使用 HTM L 和 CSS，不需要任何这样的工具。因此，让某人学习整个生态系统以获得 CSS 预处理器提供的功能是一个很大的要求。\n2009 年，Less CSS 预处理器发布。它也是用 Ruby 编写的，并提供了与 Sass 类似的功能。关键的区别在于语法，它被设计为尽可能接近 CSS。这意味着任何 CSS 代码都是有效的 Less 代码。下面是使用 Less 语法编写的相同示例：\n@dark-color: #4a4a4a; @light-color: #f9f9f9; @side-color: #eee; body { color: @dark-color; } header, footer { background-color: @dark-color; color: @light-color; } main { background: @light-color; } nav, aside { background: @side-color; } 它几乎相同（变量的前缀为 @ 而不是 $ ），但不像 Sass 示例那样漂亮，具有与 CSS 相同的大括号和分号。然而，它更接近 CSS 的事实使开发人员更容易采用它。2012 年，Less 被重写为使用 JavaScript（特别是 Node.js）而不是 Ruby 进行编译。这使得 Less 比它的 Ruby 同行更快，并且对已经在工作流程中使用 Node.js 的开发人员更具吸引力。\n要将此代码转换为常规 CSS，您首先需要 安装 Node.js，然后 安装 Less，然后运行如下命令：\nlessc index.less index.css 此命令会将在名为 index.less 的文件中编写的较少代码转换为名为 index.css 的文件中的常规 CSS。请注意， lessc 命令没有监视文件更改的方法（与 sass 命令不同），这意味着您需要安装不同的工具来自动监视和编译 .less 个文件，这增加了过程的复杂性。同样，对于习惯使用命令行工具的程序员来说，这并不困难，但对于只想使用 CSS 预处理器的其他人来说，这是一个重要的进入障碍。\n随着 Less 获得思想份额，Sass 开发人员在 2010 年通过添加一个名为 SCSS 的新语法（这是一个类似于 Less 的 CSS 超集）进行了调整。他们还发布了 LibSass，这是 Ruby Sass 引擎的 C/C++ 端口，这使得它更快，能够在各种语言中使用。\n另一个替代的 CSS 预处理器是 Stylus，它于 2010 年问世，用 Node.js 编写，与 Sass or Less 相比，它专注于更简洁的语法。通常关于 CSS 预处理器的讨论集中在这三种最流行的（Sass，Less 和 Stylus）上。最后，它们在提供的功能方面都非常相似，因此选择它们中的任何一个都不会出错。\n然而，有些人认为 CSS 预处理器变得越来越不必要，因为浏览器终于开始实现它们的一些功能（如变量和计算）。此外，还有一种称为 CSS 后处理的不同方法，它有可能使 CSS 预处理器过时（显然并非没有争议），我们接下来将讨论。\n将 CSS 后处理器用于变革性功能 CSS 后处理器使用 JavaScript 来分析您的 CSS 并将其转换为有效的 CSS。从这个意义上说，它与 CSS 预处理器非常相似 - 您可以将其视为解决相同问题的不同方法。关键的区别在于，虽然 CSS 预处理器使用特殊语法来标识需要转换的内容，但 CSS 后处理器可以解析常规 CSS 并转换它，而无需任何特殊语法。最好用一个例子来说明这一点。让我们看一下我们最初在上面定义的用于设置标题标签样式的 CSS 的一部分：\nh1, h2, h3, h4, h5, h6 { -ms-hyphens: auto; -moz-hyphens: auto; -webkit-hyphens: auto; hyphens: auto; } 粗体中的项目称为供应商前缀。浏览器在实验性地添加新的 CSS 功能时会使用供应商前缀，从而为开发人员提供了一种在最终实现时使用这些新 CSS 属性的方法。这里的前缀 -ms 代表 Microsoft Internet Explorer， -moz 前缀代表 Mozilla Firefox， -webkit 前缀代表使用 webkit 渲染引擎的浏览器（如 Google Chrome、Safari 和较新版本的 Opera）。\n记住输入所有这些不同的供应商前缀来使用这些 CSS 属性是非常烦人的。拥有一个可以根据需要自动放入供应商前缀的工具会很好。我们可以用 CSS 预处理器来实现这一点。例如，您可以使用 SCSS 执行以下操作：\n@mixin hyphens($value) { -ms-hyphens: $value; -moz-hyphens: $value; -webkit-hyphens: $value; hyphens: $value; } h1, h2, h3, h4, h5, h6 { @include hyphens(auto); } 在这里，我们使用 Sass 的 mixin 功能，它允许您定义一次 CSS 块并在其他任何地方重用它。当此文件编译为常规 CSS 时，任何 @include 语句都将替换为匹配 @mixin 的 CSS。总的来说，这不是一个糟糕的解决方案，但您负责在第一次为任何需要供应商前缀的 CSS 属性定义每个 mixin。这些 mixin 定义将需要维护，因为您可能希望在浏览器更新其 CSS 兼容性时删除不再需要的特定供应商前缀。\n与其使用 mixins，不如简单地编写普通的 CSS 并让工具自动识别需要前缀的属性并相应地添加它们。CSS 后处理器能够做到这一点。例如，如果您将 PostCSS 与 自动前缀插件 一起使用，则可以编写完全正常的 CSS，而无需任何供应商前缀，并让后处理器完成其余的工作：\nh1, h2, h3, h4, h5, h6 { hyphens: auto; } 当您在此代码上运行 CSS 后处理器时，结果是 hyphens: auto; 行被替换为所有适当的供应商前缀（如自动前缀插件中定义的那样，您不需要直接管理）。这意味着您可以编写常规 CSS，而不必担心任何兼容性或特殊语法，这很好！\n除了 PostCSS 的自动前缀之外，还有一些插件可以让你做非常酷的事情。cssnext 插件允许您使用实验性的 CSS 功能。CSS 模块 插件会自动更改类以避免名称冲突。stylelint 插件可识别 CSS 中的错误和不一致的约定。这些工具在过去一两年才真正开始起飞，展示了以前从未有过的开发人员工作流程！\n然而，这一进展是要付出代价的。与使用 CSS 预处理器相比，安装和使用 CSS 后处理器（如 PostCSS）更为复杂。您不仅必须使用命令行安装和运行工具，还需要安装和配置单个插件并定义一组更复杂的规则（例如您要针对的浏览器等）。许多开发人员不是直接从命令行运行 PostCSS，而是将其集成到可配置的构建系统中，如 Grunt，Gulp 或 webpack，这有助于管理您可能在前端工作流程中使用的所有不同构建工具。\n注意：如果您以前从未使用过现代前端构建系统，那么学习使现代前端构建系统工作的所有必要部分可能会非常不知所措。如果你想从头开始，请查看我的文章 Modern JavaScript Explain For Dinosaurs，其中介绍了前端开发人员利用这些现代功能所需的所有 JavaScript 工具。\n值得注意的是，围绕 CSS 后处理器存在一些争论。有些人认为这个术语令人困惑（一种观点认为它们都应该被称为 CSS 预处理器，另一种观点是它们应该简单地称为 CSS 处理器等）。有些人认为 CSS 后处理器完全消除了对 CSS 预处理器的需求，有些人认为它们应该一起使用。无论如何，很明显，如果你有兴趣推动 CSS 的可能性，那么学习如何使用 CSS 后处理器是值得的。\n使用 CSS 方法实现可维护性 像 CSS 预处理器和 CSS 后处理器这样的工具在改善 CSS 开发体验方面大有帮助。但是仅靠这些工具不足以解决维护大型 CSS 代码库的问题。为了解决这个问题，人们开始记录关于如何编写 CSS 的不同指南，通常称为 CSS 方法。\n在我们深入研究任何特定的 CSS 方法之前，重要的是要了解是什么让 CSS 随着时间的推移难以维护。关键问题是 CSS 的全局性质 — 您定义的每个样式都全局应用于页面的每个部分。你的工作是提出一个详细的命名约定来维护唯一的类名，或者与 特异性规则 争论，以确定应用哪种样式来应用任何给定的元素。CSS 方法提供了一种有组织的方式来编写 CSS，以避免这些带有大型代码库的痛点。让我们按时间顺序大致看一下一些流行的方法。\nOOCSS OOCSS（面向对象的 CSS）于 2009 年首次提出，是一种围绕两个主要原则组织的方法论。第一个原则是分离结构和皮肤。这意味着定义结构（如布局）的 CSS 不应与定义皮肤的 CSS （如颜色、字体等）混合在一起。这样可以更轻松地“重新换肤”应用程序。第二个原则是单独的容器和内容。这意味着将元素视为可重用的对象，其关键思想是无论对象在页面上的位置如何，它都应该看起来相同。\nOOCSS 提供了经过深思熟虑的指导方针，但对方法的细节不是很规范。后来的方法，如 SMACSS 采用了核心概念，并添加了更多细节，使其更容易上手。\nSMACSS SMACSS（CSS 的可扩展和模块化架构）于 2011 年推出，作为一种基于在 5 个不同类别中编写 CSS 的方法——基本规则、布局规则、模块、状态规则和主题规则。SMACSS 方法还推荐了一些命名约定。对于布局规则，应在类名前面加上 l- 或 layout- 。对于状态规则，应在描述状态的类名（如 is-hidden 或 is-collapsed ）前面添加前缀。\n与 OOCSS 相比，SMACSS 的方法有更多的细节，但在决定哪些 CSS 规则应该归入哪个类别时，它仍然需要仔细考虑。后来像 BEM 这样的方法取消了一些决策，使其更容易采用。\nBEM BEM（块，元素，修饰符）于 2010 年推出，作为一种围绕将用户界面划分为独立块的想法组织的方法。块是可重用的组件（例如搜索表单，定义为 \u0026lt;form class=\u0026quot;search-form\u0026quot;\u0026gt;\u0026lt;/form\u0026gt; ）。元素是块的较小部分，不能单独重用（例如搜索表单中的按钮，定义为 \u0026lt;button class=\u0026quot;search-form__button\u0026quot;\u0026gt;Search\u0026lt;/button\u0026gt; ）。修饰符是定义块或元素的外观、状态或行为的实体（例如，定义为 \u0026lt;button class=\u0026quot;search-form__button search-form__button--disabled\u0026quot;\u0026gt;Search\u0026lt;/button\u0026gt; 的禁用搜索表单按钮）。\nBEM 方法易于理解，具有特定的命名约定，允许新手应用它，而无需做出复杂的决策。某些人的缺点是类名可能非常冗长，并且不遵循 编写语义类名 的传统规则。后来的方法，如 Atomic CSS，将把这种非传统的方法带到一个全新的层次！\nAtomic CSS Atomic CSS（也称为函数式 CSS）于 2014 年推出，作为一种围绕创建小型单一用途类（名称基于视觉功能）的想法进行组织的方法。这种方法与 OOCSS，SMACS S 和 BEM 完全相反 - Atomic CSS 不是将页面上的元素视为可重用的对象，而是完全忽略这些对象，并使用可重用的单一用途实用程序类来设置每个元素的样式。因此，您将拥有类似 \u0026lt;button class=\u0026quot;f6 br3 ph3 pv2 white bg-purple hover-bg-light-purple\u0026quot;\u0026gt;Search\u0026lt;/button\u0026gt; 的东西，而不是 \u0026lt;button class=\u0026quot;search-form__button\u0026quot;\u0026gt;Search\u0026lt;/button\u0026gt; 之类的东西。\n如果你对这个例子的第一反应是惊恐地退缩，你并不孤单——许多人认为这种方法完全违反了既定的 CSS 最佳实践。但是，围绕质疑这些最佳实践在不同场景中的有效性的想法，已经有很多很好的讨论。本文很好地强调了传统的关注点分离最终如何创建依赖于 HTML 的 CSS（即使使用 BEM 等方法），而原子或函数式方法是创建依赖于 CSS 的 HTML。两者都没有错，但仔细检查后，您会发现 CSS 和 HTML 之间的真正关注点分离永远无法完全实现！\n其他 CSS 方法论，如 JS 中的 CSS ，实际上接受了 CSS 和 HTML 将始终相互依赖的概念，导致了迄今为止最具争议的方法之一。\nJS 中的 CSS JS 中的 CSS 于 2014 年引入，作为一种围绕定义 CSS 样式而不是在单独的样式表中而是直接在每个组件本身中定义的方法。它是作为 React JavaScript 框架 的一种方法引入的（它已经采用了有争议的方法，即直接在 JavaScript 中定义组件的 HTML，而不是单独的 HTML 文件）。最初该方法使用内联样式，但后来的实现使用 JavaScript 生成 CSS（具有基于组件的唯一类名）并将其插入到带有样式标签的文档中。\nJS 方法中的 CSS 再次完全违背了既定的 CSS 关注点分离最佳实践。这是因为随着时间的推移，我们使用网络的方式发生了巨大变化。最初， Web 主要由静态网站组成 - 在这里，HTML 内容与 CSS 表示的分离很有意义。如今，Web 用于创建动态 Web 应用程序 - 在这里，通过可重用的组件将事物分离出来是有意义的。\nJS 中的 CSS 的目标是能够定义具有硬边界的组件，这些边界由它们自己封装的 HTML/CSS/JS 组成，这样一个组件中的 CSS 就没有机会影响任何其他组件。React 是最早被广泛采用的框架之一，它推动了这些具有硬边界的组件，影响了其他主要框架，如 Angular、Ember 和 Vue.js 效仿。需要注意的是，JS 方法中的 CSS 是相对较新的，在这个领域有很多实验正在进行，因为开发人员试图在 Web 应用程序组件时代为 CSS 建立新的最佳实践。\n很容易被许多不同的 CSS 方法所淹没，但重要的是要记住，没有一种正确的方法 - 你应该将它们视为不同的可能工具，当你有一个足够复杂的 CSS 代码库时，你可以使用。有不同的经过深思熟虑的选项可供选择，从长远来看，这个领域发生的所有实验都会使每个开发人员受益！\n结论 简而言之，这就是现代 CSS。我们介绍了使用 CSS 进行具有排版属性的基本样式，使用 CSS 进行布局（使用基于浮点、弹性框和网格的方法），使用 CSS 预处理器处理新语法（如变量和 mixins），使用 CSS 后处理器实现变革性功能（如添加供应商前缀），以及使用 CSS 方法实现可维护性以克服 CSS 样式的全局性质。我们没有机会深入研究 CSS 提供的许多其他功能，例如高级选择器，过渡，动画，形状，动态变量 - 列表不胜枚举。CSS 有很多内容需要涵盖 - 任何说它很容易的人可能都不知道它的一半！\n现代 CSS 的使用肯定会令人沮丧，因为它继续快速变化和发展。但重要的是要记住 Web 如何随着时间的推移而发展的历史背景，很高兴知道有很多聪明的人愿意构建具体的工具和方法来帮助 CSS 最佳实践与 Web 一起发展。作为一名开发人员，这是一个激动人心的时刻，我希望这些信息可以作为路线图，在您的旅程中为您提供帮助！\n再次特别感谢 @ryanqnorth 的 恐龙漫画，自 2003 年以来（当恐龙统治网络时），它提供了一些最好的荒诞幽默。\n原文链接：https://peterxjang.com/blog/modern-css-explained-for-dinosaurs.html\n","permalink":"https://blog.chensoul.cc/posts/2023/06/21/modern-css-explained-for-dinosaurs/","summary":"奇怪的是，CSS 被认为是作为 Web 开发人员最容易学习和最难学习的语言之一。开始使用它当然很容易 - 您可以定义样式属性和值以应用于特定元素，然后\u0026hellip;\u0026hellip;这几乎就是您开始所需的一切！但是，对于大型项目，以有意义的方式组织 CSS 会变得纠结和复杂。更改任何一行 CSS 以设置一个页面上元素的样式通常会导致其他页面上的元素发生意外更改。\n为了处理 CSS 固有的复杂性，已经建立了各种不同的最佳实践。问题在于，对于哪些最佳实践实际上是最好的，没有任何强烈的共识，其中许多似乎完全相互矛盾。如果你是第一次尝试学习 CSS，至少可以说这可能会让人迷失方向。\n本文的目的是提供一个历史背景，说明 CSS 方法和工具如何在 2018 年发展到今天的样子。通过了解这段历史，将更容易理解每种方法以及如何使用它们来为您带来好处。让我们开始吧！\n更新：我制作了本文的新视频课程版本，该版本更深入地介绍了材料，请在此处查看： https://firstclass.actualize.co/p/modern-css-explained-for-dinosaurs\n使用 CSS 进行基本样式设置 让我们从一个基本网站开始，仅使用一个简单的 index.html 文件链接到一个单独的 index.css 文件：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Modern CSS\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;header\u0026gt;This is the header.\u0026lt;/header\u0026gt; \u0026lt;main\u0026gt; \u0026lt;h1\u0026gt;This is the main content.\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;nav\u0026gt; \u0026lt;h4\u0026gt;This is the navigation section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;aside\u0026gt; \u0026lt;h4\u0026gt;This is an aside section.\u0026lt;/h4\u0026gt; \u0026lt;p\u0026gt;...\u0026lt;/p\u0026gt; \u0026lt;/aside\u0026gt; \u0026lt;footer\u0026gt;This is the footer.\u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在我们在 HTML 中没有使用任何类或 ID，只是 语义标签。没有任何 CSS，网站看起来像这样（使用占位符文本）：\n功能齐全，但不是很漂亮。我们可以添加 CSS 来改进 index.css 中的基本排版：\n/* BASIC TYPOGRAPHY */ /* from https://github.com/oxalorg/sakura */ html { font-size: 62.","title":"[译]为恐龙解释现代CSS"},{"content":" 在三种主要的前端技术（ HTML，CSS 和 JavaScript ）中，HTML 仍然是最一致的。如果您唯一关心的是创建内容，那么 1990 年代的 HTML 文档看起来与 2018 年创建的文档非常相似：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello there!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 你有带有标签和内容的元素，带有属性的标签——除了第一行的简化文档类型外，没有太大变化！然而，多年来，Web 开发已经发生了巨大的转变，从创建静态网站（专注于内容）到创建动态 Web 应用程序（专注于交互）——这是 Web 最初设计的目的。创建仍然语义和可访问的自定义用户界面，使用属性和工具提高性能，组织代码以进行重用和可维护性 - 现在有一组全新的问题在起作用。\n本文的目的是提供一个历史背景，说明 HTML 如何在 2018 年演变成今天的语言。我们将从结构良好且易于访问的 HTML 的基础知识开始，就像古代的恐龙一样。然后，我们将介绍不同的技术来提高性能、响应能力和可维护性。CSS 和 JavaScript 将不可避免地进入这个对话；出于本文的目的，将从它们如何影响 HTML 本身编写的角度来介绍它们。通过了解这段历史，您将能够充分利用该语言经常被忽视的新旧功能。让我们开始吧！\n使用语义元素编写内容 让我们向前面的 HTML 示例添加更多内容。现在，我们将创建一个基本网站，其中包含一个带有链接和搜索输入的导航部分，一个用于显示一般网站信息的大型展示部分（通常称为英雄部分或 巨型屏幕 ），文章的三列部分和一个版权信息的页脚部分。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;navbar\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hero\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Hello there!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;General info about the page goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Learn more\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;First Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Second Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Third Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Copyright info goes here\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 在这里，我们使用带有 \u0026lt;div\u0026gt; 、 \u0026lt;h1\u0026gt; 、 \u0026lt;h2\u0026gt; 、 \u0026lt;p\u0026gt; 等标签的基本元素来标记内容。这里的 HTML 是有效的，但它不是完全语义的——也就是说，标签不能尽可能地传达内容的含义。\n当 HTML5 在 2008 年推出时，它提供了新的元素来改进文档语义。以下是使 HTML 更具语义性的尝试：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;author\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;!--[if lt IE 9]\u0026gt; \u0026lt;script src=\u0026#34;(https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;![endif]--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav role=\u0026#34;navigation\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;section class=\u0026#34;hero\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Hello there!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;General info about the page goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Learn more\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;grid\u0026#34;\u0026gt; \u0026lt;article class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;First Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;article class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Second Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;article class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Third Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer role=\u0026#34;contentinfo\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Copyright info goes here\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 让我们来看看其中的一些变化：\n\u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; 指定文档的语言，这有助于搜索引擎和浏览器识别适当的内容。 额外的 \u0026lt;meta\u0026gt; 标记提供有关搜索引擎和其他服务在页面上不直接可见的网站的信息。它们还提供有关如何调整不同设备上的内容大小的信息。 \u0026lt;nav\u0026gt; 、 \u0026lt;main\u0026gt; 、 \u0026lt;section\u0026gt; 、 \u0026lt;article\u0026gt; 和 \u0026lt;footer\u0026gt; 标记为 HTML 文档提供了更易于访问的结构（与通用的 \u0026lt;div\u0026gt; 标记相比）。这些标签是在 HTML5 中引入的。 \u0026lt;!-- [if lt IE 9]\u0026gt;...--\u0026gt; 注释添加了一个 JavaScript 文件，该文件仅适用于旧版本的 Internet Explorer，因为它们不支持上述 HTML5 标签。请注意，如今许多最近的网站都没有包含该评论，因为支持这些浏览器的网站越来越少。 role 属性还提供辅助功能信息。请注意，使用 \u0026lt;nav\u0026gt; 标记通常足以确保可访问性，如果无法识别 \u0026lt;nav\u0026gt; 标记，则使用额外的 role=\u0026quot;navigation\u0026quot; 。 编写语义 HTML 似乎并不重要，尤其是当它不影响网站的视觉外观时。但是，您的网站不仅被人类查看 - 网络浏览器，搜索引擎，屏幕阅读器都依赖于语义 HTML 才能正常运行。\n使用 WAI-ARIA 属性改进可访问性 让我们看一下上面示例中导航栏中的搜索输入：\n\u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 此输入元素使用 placeholder 属性而不是标签元素让用户知道其用途。这适用于人类，但它不是正确的语义 HTML，屏幕阅读器和其他技术可能会错过。使其可访问的方法是使用 aria-label 属性：\n\u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; aria-label=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; WAI-ARIA 代表“Web 可访问性倡议 — 可访问的富互联网应用程序”（通常简称为 ARIA），是一组属性，当语义标记不够时，使 HTML 更易于访问。上一节中看到的 role 属性是 ARIA 属性。到目前为止，这些属性似乎是很小的变化，但是当我们使用 HTML 来处理基本文档之外的事情时，它变得更加重要。\n让我们看一个更复杂的例子——假设我们想在 HTML 中添加一些选项卡式内容，以提供有关如何在 Windows，Mac 和 Linux 上安装某些程序的说明。由于没有在 HTML 中构建选项卡的本机方法，因此我们必须使用无序列表、链接和 div 之类的东西来构建我们自己的选项卡标记。在这里，我们可以使用 role 、 aria-controls 、 aria-selected 和 aria-labelledby 等可访问性属性来标记 HTML，如下所示：\n\u0026lt;ul role=\u0026#34;tablist\u0026#34;\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a id=\u0026#34;windows-tab\u0026#34; href=\u0026#34;#windows\u0026#34; role=\u0026#34;tab\u0026#34; aria-controls=\u0026#34;windows\u0026#34; aria-selected=\u0026#34;true\u0026#34; \u0026gt;Windows\u0026lt;/a \u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a id=\u0026#34;mac-tab\u0026#34; href=\u0026#34;#mac\u0026#34; role=\u0026#34;tab\u0026#34; aria-controls=\u0026#34;mac\u0026#34; aria-selected=\u0026#34;false\u0026#34; \u0026gt;Mac\u0026lt;/a \u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a id=\u0026#34;linux-tab\u0026#34; href=\u0026#34;#linux\u0026#34; role=\u0026#34;tab\u0026#34; aria-controls=\u0026#34;linux\u0026#34; aria-selected=\u0026#34;false\u0026#34; \u0026gt;Linux\u0026lt;/a \u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;div\u0026gt; \u0026lt;div id=\u0026#34;windows\u0026#34; role=\u0026#34;tabpanel\u0026#34; aria-labelledby=\u0026#34;windows-tab\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;http://1000logos.net/wp-content/uploads/2017/04/Microsoft-Logo.png\u0026#34; alt=\u0026#34;microsoft logo\u0026#34; /\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;mac\u0026#34; role=\u0026#34;tabpanel\u0026#34; aria-labelledby=\u0026#34;mac-tab\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;https://i.ytimg.com/vi/ipOzBWuYZvg/maxresdefault.jpg\u0026#34; alt=\u0026#34;apple logo\u0026#34; /\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;linux\u0026#34; role=\u0026#34;tabpanel\u0026#34; aria-labelledby=\u0026#34;linux-tab\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;https://noware.tech/wp-content/uploads/sites/140/2018/04/linux-1024x565.jpg\u0026#34; alt=\u0026#34;linux logo\u0026#34; /\u0026gt; ... \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; 如果没有这些辅助功能属性，选项卡式内容将与选项卡控件没有可识别的关系。具有这些属性有助于屏幕阅读器识别内容，启用具有正确制表符的键盘快捷键等。使用适当的 ARIA 属性本身就是一项完整的研究——要更深入地了解，请查看 官方指南。\n所有这些似乎都是为了提高网站的可访问性而做很多工作。重要的是要承认可访问性是网络的一个组成部分，网络被设计为一个与每个人自由共享信息的平台，而不仅仅是少数人。使网站可访问可以改善每个访问者的体验 - 例如，可访问的键盘快捷键可以帮助那些永远无法使用鼠标的人，那些暂时无法使用鼠标的人，以及那些不喜欢不使用鼠标的人（也就是大多数程序员）。在处理其他功能时，可访问性很容易被忽视，但不应忽视。\n如果您有兴趣改善网站的可访问性，那么有 A11Y 项目 中的清单，这是 一个 很好的起点。然而，使网站可访问不仅仅是检查项目——它总是可以改进的，就像用户体验的任何方面一样。使您的网站可访问的最佳方法是实际使用您的网站，就像受众中的不同人一样 - 使用屏幕阅读器进行测试，尝试仅使用键盘而不是鼠标，使用 色盲过滤器 查看您的网站等。\n用 CSS 和 JavaScript 让它变得漂亮 如果我们到目前为止看一下网站，它看起来就像你期望的那样光秃秃的：\n为了美化它，我们将添加一个 CSS 文件来应用样式。现在，如果你不是特别擅长 CSS，可能需要很多天才能使这个网站看起来很漂亮。与其编写自己的 CSS，不如始终使用 CSS 框架，该框架本质上是其他人以可重用的方式编写的 CSS。\n一个流行的 CSS 框架是 Bootstrap，它于 2011 年问世，并迅速被 数百万个网站 采用和使用。让我们看看使用 Bootstrap 的一些代码会是什么样子：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;author\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;!--[if lt IE 9]\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;![endif]--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026#34;navbar navbar-expand-lg navbar-light bg-light\u0026#34; role=\u0026#34;navigation\u0026#34; \u0026gt; \u0026lt;ul class=\u0026#34;navbar-nav mr-auto\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;nav-item active\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form class=\u0026#34;form-inline my-2 my-lg-0\u0026#34;\u0026gt; \u0026lt;input class=\u0026#34;form-control mr-sm-2\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; aria-label=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button class=\u0026#34;btn btn-outline-success my-2 my-sm-0\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt; Search \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer class=\u0026#34;navbar navbar-dark bg-secondary\u0026#34; role=\u0026#34;contentinfo\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Copyright info goes here\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 您可以在 此处 查看完整的代码示例。\n让我们检查一下这些更改：\n\u0026lt;head\u0026gt; 标签中的 \u0026lt;link\u0026gt; 将 Bootstrap CSS 添加到我们的网站。请注意，我们链接到在线托管的文件，这可能会带来一些安全风险 - integrity 和 crossorigin 属性有助于确保链接到的文件正确无误。\n添加的类都是特定于 Bootstrap 的 — 添加的 Bootstrap CSS 具有针对具有特定 HTML 结构的特定类名的样式。\n在三篇文章周围添加了一个额外的 \u0026lt;div class=\u0026quot;row\u0026quot;\u0026gt; ，以利用 Bootstrap 的网格布局系统（它使用这种特定的 HTML 结构）。\n以下是该网站现在的样子：\n不错！请注意，为了使用像 Bootstrap 这样的 CSS 框架，您实际上根本不需要编写任何 CSS 即可开始使用 — 您只需要在 HTML 中添加适当的类即可利用框架附带的 CSS。\n这里要注意的一件事是，虽然选项卡的样式正确（任何时候只有一个选项卡可见），但它们还没有正常工作——单击选项卡不会执行任何操作。这是因为在这种情况下，这种类型的自定义交互不是由 CSS 处理的，而是由 JavaScript 处理的。在这种情况下，我们可以通过在 \u0026lt;head\u0026gt; 标签中添加 Bootstrap 框架附带的 JavaScript 文件来让 Bootstrap 选项卡工作：\n\u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.3.1.slim.min.js\u0026#34; integrity=\u0026#34;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js\u0026#34; integrity=\u0026#34;sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; 最后一个脚本是 Bootstrap 的 JavaScript。前两个是 Bootstrap 使用的依赖项（jQuery 和 Popper），在加载 Bootstrap 脚本之前必须先加载它们。如果您查看 此实时示例，您可以看到选项卡现在可以工作了！\nBootstrap 被广泛使用，因为它帮助解决了当时 CSS 的主要痛点，例如浏览器不一致和缺乏适当的网格系统。使用像 Bootstrap 这样的 CSS 框架有一些缺点——特别是，与从头开始编写 CSS 相比，它们可能难以定制，这可能会使您的网站与其他网站相比显得通用。\n此外，随着智能手机和移动流量的增加，减少 CSS 和 JS 文件大小变得越来越重要 - 任何超过几千字节的东西都会显着影响较慢的互联网连接的性能。在上面的例子中使用 Bootstrap 的方式，我们要求用户下载整个 Bootstrap 框架与站点一起，即使我们只使用几种样式和功能。在下一节中，我们将介绍几种有助于解决这些性能问题的技术。\n注意：对 CSS 和 JavaScript 的扎实掌握与使用 HTML 制作复杂的网站有着内在的联系;但是，深入研究这些语言超出了本文的范围。如果你想了解更多关于 CSS 和 JavaScript 的基础知识，MDN Web Docs 总是一个不错的起点。如果你想更好地了解 CSS 的所有新功能（flexbox，grid，SASS 等）如何与所涉及的所有工具和技术结合在一起，请查看我的文章 Modern CSS Explain For Dinosaurs。\n使用 HTML 属性提高性能 在这一点上，我们有一个网站，具有相当好的组织，语义 HTML。如果这就是我们正在考虑的全部内容，那么我们的网站就会完成！然而，在性能（网站为用户加载的速度）和可维护性（开发人员更改代码的难易程度）方面，网站有许多方面可以改进。\n脚本的 defer 属性 对于我们的网站，一个主要的优化是解决标题中加载的 JavaScript 文件。这些文件足够大，实际上会减慢网站的速度。为了呈现页面，Web 浏览器读取给定的 HTML 并将其转换为它理解的格式 - 文档对象模型或 DOM。如您所料，Web 浏览器从 HTML 文档的顶部开始，然后向下工作。这意味着如果它看到 \u0026lt;script\u0026gt; 标记，它将下载并执行脚本，然后再转到下一行。您可以在此处查看此过程的插图：\n来自 hacks.mozilla.org 一个常见的优化技巧是将所有 JavaScript \u0026lt;script\u0026gt; 标签移出 \u0026lt;head\u0026gt; 标签并移到 \u0026lt;body\u0026gt; 标签的末尾。你可以在 Bootstrap 自己的入门模板中看到这一点：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Hello, world!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, world!\u0026lt;/h1\u0026gt; \u0026lt;!-- Optional JavaScript --\u0026gt; \u0026lt;!-- jQuery first, then Popper.js, then Bootstrap JS --\u0026gt; \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.3.1.slim.min.js\u0026#34; integrity=\u0026#34;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js\u0026#34; integrity=\u0026#34;sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 从某种意义上说，这是一种优化，因为这不是 HTML 的设计方式 - CSS 和 JavaScript 文件应该在标签中定义，如前所述。但是，将所有内容保留在 \u0026lt;head\u0026gt; 标记中会产生降低页面呈现性能的意外副作用。将所有 \u0026lt;script\u0026gt; 个标记移动到 \u0026lt;body\u0026gt; 个标记的底部是提高性能的一种方法。\n在 2018 年，许多网站仍然使用这种将所有 \u0026lt;script\u0026gt; 标签移动到 \u0026lt;body\u0026gt; 标签底部的技巧。然而，浏览器已经支持了一种不那么黑客的方法近 10 年—— defer 属性。通过将此属性添加到 \u0026lt;script\u0026gt; 标记中，浏览器将下载外部文件而不会阻止构建 DOM 的其余部分，并将在 DOM 构建完成后执行脚本。您可以在此处查看此过程的插图：\n在许多情况下，在 \u0026lt;head\u0026gt; 中保留 \u0026lt;script\u0026gt; 个标签和 defer 属性将导致更快的页面加载速度，因为文件可以与正在构建的 DOM 并行下载。这就是 Bootstrap 的初学者模板使用 defer 属性的样子：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;!-- Required meta tags --\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;!-- Bootstrap CSS --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;!-- Optional JavaScript --\u0026gt; \u0026lt;!-- jQuery first, then Popper.js, then Bootstrap JS --\u0026gt; \u0026lt;script defer src=\u0026#34;https://code.jquery.com/jquery-3.3.1.slim.min.js\u0026#34; integrity=\u0026#34;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js\u0026#34; integrity=\u0026#34;sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js\u0026#34; integrity=\u0026#34;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;title\u0026gt;Hello, world!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello, world!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这样做的好处是网站会渲染得更快，并且它会按预期使用 \u0026lt;head\u0026gt; 标记中的脚本组织 HTML。为了更精细地控制哪些文件以什么顺序下载和执行，还有 async 属性以及 \u0026lt;link\u0026gt; 个标签的 rel=\u0026quot;preload\u0026quot; 属性（您可以在 此处 阅读更多相关信息）。\n图像的 srcset 属性 对于我们的网站，另一个主要的性能优化是图像。现在，这些图像正在被“热链接”，这意味着它们被直接链接到其他人的网站上。这不仅从维护的角度来看是有问题的（如果其他人改变他们的形象，就会破坏我们的网站），从性能的角度来看，它也可能是有问题的。\n我们可以下载文件并在本地链接到它们，而不是直接链接文件。此外，我们可以通过将图像文件大小调整为适当的分辨率来优化图像文件大小。而不是直接链接到另一个网站上的单个图像的图像标签：\n\u0026lt;img class=\u0026#34;img-fluid\u0026#34; src=\u0026#34;http://1000logos.net/wp-content/uploads/2017/04/Microsoft-Logo.png\u0026#34; alt=\u0026#34;microsoft logo\u0026#34; /\u0026gt; 我们可以在本地创建图像的多个版本，并响应式地链接到它们：\n\u0026lt;img class=\u0026#34;img-fluid\u0026#34; src=\u0026#34;microsoft-logo-small.png\u0026#34; srcset=\u0026#34;microsoft-logo-medium.png 1000w, microsoft-logo-large.png 2000w\u0026#34; alt=\u0026#34;microsoft logo\u0026#34; /\u0026gt; 在这里，我们使用徽标的小型、中型和大型版本。 srcset 属性告诉浏览器根据浏览器宽度加载适当的版本。 srcset 属性是在 2013 年左右引入的，但浏览器花了几年时间才完全支持它。截至 2018 年，它具有 相当不错的浏览器支持 ，因此绝对值得将其作为工作流程的一部分。\n对于许多网站来说，优化图像大小通常是最大的性能提升——图像下载大小通常比任何 JavaScript 和 CSS 文件大几个数量级。您可以使用 \u0026lt;picture\u0026gt; 元素对图像进行更精细的控制;但是，对于大多数用例来说，使用简单的 srcset 属性 通常绰绰有余。\n其他 HTML 属性 作为一种语言，HTML 具有 许多属性 ，并继续添加可用于提高性能的新属性（如 importance 和 lazyload ）。虽然这可能令人生畏，但专注于下载大小（图像和脚本）方面的最大资源，无论它们可能适用于您的特定网站，通常是最好的起点。\n请注意，就像可访问性一样，没有一套全面的性能规则始终适用于每个网站——您应该对您的网站进行基准测试以确定最有效的方法（Chrome 和 Firefox 等浏览器提供此类工具）。同样，最好的方法是简单地在慢速网络条件下使用您的网站（浏览器的开发工具可以模拟）——如果您在慢速网络条件下使用自己的网站即使只是一周，您很可能会找到大量性能修复来改善其体验。\n使用工具提高性能 到目前为止，我们一直在使用 HTML 语言提供的工具来优化性能。您还可以使用外部工具获得更多性能优势。让我们来看看几种常用的方法。\n代码缩小 一个重要的性能优化是 JavaScript 和 CSS 代码的缩小（有时称为丑化）。这涉及使用程序来分析和删除代码中不必要或冗余的数据，从简单的事情（如删除不需要的空格）到复杂的事情，如尽可能将长变量重命名为单个字符。下面是 Douglas Crockford 在 2003 年发布 的第一个 JavaScript 缩减器的示例。示例未缩小的代码如下所示：\n// is.js // (c) 2001 Douglas Crockford // 2001 June 3 // is // The -is- object is used to identify the browser. Every browser edition // identifies itself, but there is no standard way of doing it, and some of // the identification is deceptive. This is because the authors of web // browsers are liars. For example, Microsoft\u0026#39;s IE browsers claim to be // Mozilla 4. Netscape 6 claims to be version 5. var is = { ie: navigator.appName == \u0026#34;Microsoft Internet Explorer\u0026#34;, java: navigator.javaEnabled(), ns: navigator.appName == \u0026#34;Netscape\u0026#34;, ua: navigator.userAgent.toLowerCase(), version: parseFloat(navigator.appVersion.substr(21)) || parseFloat(navigator.appVersion), win: navigator.platform == \u0026#34;Win32\u0026#34;, }; is.mac = is.ua.indexOf(\u0026#34;mac\u0026#34;) \u0026gt;= 0; if (is.ua.indexOf(\u0026#34;opera\u0026#34;) \u0026gt;= 0) { is.ie = is.ns = false; is.opera = true; } if (is.ua.indexOf(\u0026#34;gecko\u0026#34;) \u0026gt;= 0) { is.ie = is.ns = false; is.gecko = true; } 缩小后的代码如下所示：\nvar is = { ie: navigator.appName == \u0026#34;Microsoft Internet Explorer\u0026#34;, java: navigator.javaEnabled(), ns: navigator.appName == \u0026#34;Netscape\u0026#34;, ua: navigator.userAgent.toLowerCase(), version: parseFloat(navigator.appVersion.substr(21)) || parseFloat(navigator.appVersion), win: navigator.platform == \u0026#34;Win32\u0026#34;, }; is.mac = is.ua.indexOf(\u0026#34;mac\u0026#34;) \u0026gt;= 0; if (is.ua.indexOf(\u0026#34;opera\u0026#34;) \u0026gt;= 0) { is.ie = is.ns = false; is.opera = true; } if (is.ua.indexOf(\u0026#34;gecko\u0026#34;) \u0026gt;= 0) { is.ie = is.ns = false; is.gecko = true; } 这些更改确实加起来 — 从我们之前的示例来看，未缩小的 bootstrap.js 的大小为 124 KB，而缩小的 bootstrap.min.js 的大小为 51 KB。这还不到原来尺寸的一半——使用Grabthar’s hammer，真是省钱！但说真的，它在网站下载和显示的速度方面有很大的不同，尤其是在互联网连接速度较慢的情况下。\n我们在前面的例子中使用的 Bootstrap CSS 和 JavaScript 已经缩小了，但如果你想缩小自己的代码，你可以使用 JavaScript Minifier 或 Minify 等在线工具，有很多可供选择。或者，您可以使用命令行工具，该工具可以节省将代码复制到网站的过程。\n文件串联 另一个相关的性能优化是串联，它将多个 JavaScript 文件（或 CSS 文件）转换为单个文件。浏览器下载单个文件的速度比下载多个小文件更快，这是基于浏览器自 1999 年以来使用的 HTTP/1.1 协议。\n需要注意的是，新版本的协议 HTTP/2 于 2015 年发布，可能会改变此优化。HTTP / 2 允许多个同时连接，因此理论上最好有多个小文件，而不是一个大级联文件。然而，在实践中，它 似乎并不那么简单，因为串联仍然有重要的好处。截至 2018 年，连接 JavaScript 和 CSS 文件仍然是常见的做法。\n要连接您的文件，理论上您可以手动完成 - 将每个 JavaScript 文件的内容复制到单个文件中，对 CSS 文件重复此操作，等等。然后修改 HTML 以链接到单个串联的 JavaScript 文件和单个串联的 CSS 文件。每次部署应用程序时都必须执行此操作，维护起来会非常痛苦 - 最好使用一些自动化过程（更多内容见下文）。\n关键 CSS 近年来流行的另一个优化是内联页面的关键 CSS。这涉及使用工具来识别用户在访问网页时首先看到的所有 HTML 元素：\n来自 https://www.smashingmagazine.com/2015/08/understanding-critical-css/ 一旦识别出这些 HTML 元素，该工具将找到影响这些元素的所有 CSS，并将它们直接添加到 HTML 文件中。通过这种方式，浏览器能够显示一个完全样式的网站，而无需等待剩余的 CSS 下载！\n有不同的工具可以帮助您识别 关键 CSS，从 Addy Osmani 的基于节点的关键库到 Jonas Ohlsson Aden 的基于 Web 的关键路径 CSS 生成器。下面是我们之前 Bootstrap 示例中的 HTML \u0026lt;head\u0026gt; 元素在通过关键工具分析后的外观示例：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;author\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; :root { --blue: #007bff; --indigo: #6610f2; --purple: #6f42c1; --pink: #e83e8c; --red: #dc3545; --orange: #fd7e14; --yellow: #ffc107; --green: #28a745; --teal: #20c997; --cyan: #17a2b8; --white: #fff; --gray: #6c757d; --gray-dark: #343a40; --primary: #007bff; --secondary: #6c757d; --success: #28a745; --info: #17a2b8; --warning: #ffc107; --danger: #dc3545; --light: #f8f9fa; --dark: #343a40; --breakpoint-xs: 0; --breakpoint-sm: 576px; --breakpoint-md: 768px; --breakpoint-lg: 992px; --breakpoint-xl: 1200px; --font-family-sans-serif: -apple-system, BlinkMacSystemFont, \u0026#34;Segoe UI\u0026#34;, Roboto, \u0026#34;Helvetica Neue\u0026#34;, Arial, sans-serif, \u0026#34;Apple Color Emoji\u0026#34;, \u0026#34;Segoe UI Emoji\u0026#34;, \u0026#34;Segoe UI Symbol\u0026#34;, \u0026#34;Noto Color Emoji\u0026#34;; --font-family-monospace: SFMono-Regular, Menlo, Monaco, Consolas, \u0026#34;Liberation Mono\u0026#34;, \u0026#34;Courier New\u0026#34;, monospace; } \\*, ::after, ::before { box-sizing: border-box; } html { font-family: sans-serif; line-height: 1.15; -webkit-text-size-adjust: 100%; -ms-text-size-adjust: 100%; -ms-overflow-style: scrollbar; } @-ms-viewport { width: device-width; } article, footer, main, nav, section { display: block; } body { margin: 0; font-family: -apple-system, BlinkMacSystemFont, \u0026#34;Segoe UI\u0026#34;, Roboto, \u0026#34;Helvetica Neue\u0026#34;, Arial, sans-serif, \u0026#34;Apple Color Emoji\u0026#34;, \u0026#34;Segoe UI Emoji\u0026#34;, \u0026#34;Segoe UI Symbol\u0026#34;, \u0026#34;Noto Color Emoji\u0026#34;; font-size: 1rem; font-weight: 400; line-height: 1.5; color: #212529; text-align: left; background-color: #fff; } h1, h2 { margin-top: 0; margin-bottom: 0.5rem; } p { margin-top: 0; margin-bottom: 1rem; } ul { margin-top: 0; margin-bottom: 1rem; } a { color: #007bff; text-decoration: none; background-color: transparent; -webkit-text-decoration-skip: objects; } img { vertical-align: middle; border-style: none; } button { border-radius: 0; } button, input { margin: 0; font-family: inherit; font-size: inherit; line-height: inherit; } button, input { overflow: visible; } button { text-transform: none; } [type=\u0026#34;submit\u0026#34;], button { -webkit-appearance: button; } [type=\u0026#34;submit\u0026#34;]::-moz-focus-inner, button::-moz-focus-inner { padding: 0; border-style: none; } ::-webkit-file-upload-button { font: inherit; -webkit-appearance: button; } h1, h2 { margin-bottom: 0.5rem; font-family: inherit; font-weight: 500; line-height: 1.2; color: inherit; } h1 { font-size: 2.5rem; } h2 { font-size: 2rem; } .lead { font-size: 1.25rem; font-weight: 300; } .display-4 { font-size: 3.5rem; font-weight: 300; line-height: 1.2; } .img-fluid { max-width: 100%; height: auto; } .container { width: 100%; padding-right: 15px; padding-left: 15px; margin-right: auto; margin-left: auto; } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:576px) { .container { max-width: 540px; } } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:768px) { .container { max-width: 720px; } } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:992px) { .container { max-width: 960px; } } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:1200px) { .container { max-width: 1140px; } } .row { display: -ms-flexbox; display: flex; -ms-flex-wrap: wrap; flex-wrap: wrap; margin-right: -15px; margin-left: -15px; } .col-4 { position: relative; width: 100%; min-height: 1px; padding-right: 15px; padding-left: 15px; } .col-4 { -ms-flex: 0 0 33.333333%; flex: 0 0 33.333333%; max-width: 33.333333%; } .form-control { display: block; width: 100%; height: calc(2.25rem + 2px); padding: 0.375rem 0.75rem; font-size: 1rem; line-height: 1.5; color: #495057; background-color: #fff; background-clip: padding-box; border: 1px solid #ced4da; border-radius: 0.25rem; } .form-control::-ms-expand { background-color: transparent; border: 0; } .form-control::-webkit-input-placeholder { color: #6c757d; opacity: 1; } .form-control::-moz-placeholder { color: #6c757d; opacity: 1; } .form-control:-ms-input-placeholder { color: #6c757d; opacity: 1; } .form-control::-ms-input-placeholder { color: #6c757d; opacity: 1; } .form-inline { display: -ms-flexbox; display: flex; -ms-flex-flow: row wrap; flex-flow: row wrap; -ms-flex-align: center; align-items: center; } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:576px) { .form-inline .form-control { display: inline-block; width: auto; vertical-align: middle; } } .btn { display: inline-block; font-weight: 400; text-align: center; white-space: nowrap; vertical-align: middle; border: 1px solid transparent; padding: 0.375rem 0.75rem; font-size: 1rem; line-height: 1.5; border-radius: 0.25rem; } .btn-primary { color: #fff; background-color: #007bff; border-color: #007bff; } .btn-outline-success { color: #28a745; background-color: transparent; background-image: none; border-color: #28a745; } .btn-lg { padding: 0.5rem 1rem; font-size: 1.25rem; line-height: 1.5; border-radius: 0.3rem; } .fade:not(.show) { opacity: 0; } .nav { display: -ms-flexbox; display: flex; -ms-flex-wrap: wrap; flex-wrap: wrap; padding-left: 0; margin-bottom: 0; list-style: none; } .nav-link { display: block; padding: 0.5rem 1rem; } .nav-tabs { border-bottom: 1px solid #dee2e6; } .nav-tabs .nav-item { margin-bottom: -1px; } .nav-tabs .nav-link { border: 1px solid transparent; border-top-left-radius: 0.25rem; border-top-right-radius: 0.25rem; } .nav-tabs .nav-link.active { color: #495057; background-color: #fff; border-color: #dee2e6 #dee2e6 #fff; } .tab-content \u0026gt; .tab-pane { display: none; } .tab-content \u0026gt; .active { display: block; } .navbar { position: relative; display: -ms-flexbox; display: flex; -ms-flex-wrap: wrap; flex-wrap: wrap; -ms-flex-align: center; align-items: center; -ms-flex-pack: justify; justify-content: space-between; padding: 0.5rem 1rem; } .navbar-nav { display: -ms-flexbox; display: flex; -ms-flex-direction: column; flex-direction: column; padding-left: 0; margin-bottom: 0; list-style: none; } .navbar-nav .nav-link { padding-right: 0; padding-left: 0; } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:992px) { .navbar-expand-lg { -ms-flex-flow: row nowrap; flex-flow: row nowrap; -ms-flex-pack: start; justify-content: flex-start; } .navbar-expand-lg .navbar-nav { -ms-flex-direction: row; flex-direction: row; } .navbar-expand-lg .navbar-nav .nav-link { padding-right: 0.5rem; padding-left: 0.5rem; } } .navbar-light .navbar-nav .nav-link { color: rgba(0, 0, 0, 0.5); } .navbar-light .navbar-nav .active \u0026gt; .nav-link { color: rgba(0, 0, 0, 0.9); } .jumbotron { padding: 2rem 1rem; margin-bottom: 2rem; background-color: #e9ecef; border-radius: 0.3rem; } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:576px) { .jumbotron { padding: 4rem 2rem; } } .bg-secondary { background-color: #6c757d !important; } .bg-light { background-color: #f8f9fa !important; } .my-2 { margin-top: 0.5rem !important; } .my-2 { margin-bottom: 0.5rem !important; } .mr-auto { margin-right: auto !important; } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:576px) { .my-sm-0 { margin-top: 0 !important; } .my-sm-0 { margin-bottom: 0 !important; } .mr-sm-2 { margin-right: 0.5rem !important; } } [@media](http://twitter.com/media \u0026#34;Twitter profile for @media\u0026#34;) (min-width:992px) { .my-lg-0 { margin-top: 0 !important; } .my-lg-0 { margin-bottom: 0 !important; } } \u0026lt;/style\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; href=\u0026#34;[https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css](https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css)\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; as=\u0026#34;style\u0026#34; onload=\u0026#34;this.onload=null;this.rel=\u0026#39;stylesheet\u0026#39;\u0026#34; /\u0026gt; \u0026lt;noscript \u0026gt;\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;[https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css](https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css)\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt;\u0026lt;/noscript\u0026gt; \u0026lt;script\u0026gt; !(function (n) { \u0026#34;use strict\u0026#34;; n.loadCSS || (n.loadCSS = function () {}); var o = (loadCSS.relpreload = {}); if ( ((o.support = (function () { var e; try { e = n.document.createElement(\u0026#34;link\u0026#34;).relList.supports(\u0026#34;preload\u0026#34;); } catch (t) { e = !1; } return function () { return e; }; })()), (o.bindMediaToggle = function (t) { var e = t.media || \u0026#34;all\u0026#34;; function a() { t.media = e; } t.addEventListener ? t.addEventListener(\u0026#34;load\u0026#34;, a) : t.attachEvent \u0026amp;\u0026amp; t.attachEvent(\u0026#34;onload\u0026#34;, a), setTimeout(function () { (t.rel = \u0026#34;stylesheet\u0026#34;), (t.media = \u0026#34;only x\u0026#34;); }), setTimeout(a, 3e3); }), (o.poly = function () { if (!o.support()) for ( var t = n.document.getElementsByTagName(\u0026#34;link\u0026#34;), e = 0; e \u0026lt; t.length; e++ ) { var a = t[e]; \u0026#34;preload\u0026#34; !== a.rel || \u0026#34;style\u0026#34; !== a.getAttribute(\u0026#34;as\u0026#34;) || a.getAttribute(\u0026#34;data-loadcss\u0026#34;) || (a.setAttribute(\u0026#34;data-loadcss\u0026#34;, !0), o.bindMediaToggle(a)); } }), !o.support()) ) { o.poly(); var t = n.setInterval(o.poly, 500); n.addEventListener ? n.addEventListener(\u0026#34;load\u0026#34;, function () { o.poly(), n.clearInterval(t); }) : n.attachEvent \u0026amp;\u0026amp; n.attachEvent(\u0026#34;onload\u0026#34;, function () { o.poly(), n.clearInterval(t); }); } \u0026#34;undefined\u0026#34; != typeof exports ? (exports.loadCSS = loadCSS) : (n.loadCSS = loadCSS); })(\u0026#34;undefined\u0026#34; != typeof global ? global : this); \u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;[https://code.jquery.com/jquery-3.3.1.slim.min.js](https://code.jquery.com/jquery-3.3.1.slim.min.js)\u0026#34; integrity=\u0026#34;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;[https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js](https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js)\u0026#34; integrity=\u0026#34;sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;[https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js](https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js)\u0026#34; integrity=\u0026#34;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!--[if lt IE 9]\u0026gt; \u0026lt;script src=\u0026#34;[https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js](https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js)\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;![endif]--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 如您所见，该工具添加了一个带有大量 CSS 的内联 \u0026lt;style\u0026gt; 元素。请注意，这不是 Bootstrap 的全部 CSS，只是该工具分析的 CSS 对于此页面的初始视图是必需的。仅 Bootstrap 的缩小 CSS 就有 51 KB;这个新的 HTML 文件包括所有 HTML 以及新内联的 CSS 和 JavaScript，是 12 KB。这种减小的大小比看起来更重要 - 将初始 HTML/CSS/JS 置于 14 KB 以下可以使您的网站在某些最慢的连接上以毫秒为单位呈现。这是因为浏览器和服务器之间的每次往返一次可以发送大约 14 KB - 通过将所有内容放入一次往返中，您可以避免额外往返的开销（此处提供更多详细信息）。\n该工具还在 CSS link 元素上添加了 rel=\u0026quot;preload\u0026quot; 属性，使 CSS 文件能够异步加载。这通常是您不想做的事情 - 尽管它会加快网站速度，但用户会首先看到无样式的纯 HTML，然后在加载 CSS 文件时看到样式正确的网站。但是，在我们的例子中，由于我们正在内联关键的 CSS，这不是问题，因此异步加载剩余的 CSS 可以完美地工作！\n实现构建步骤 此时，您可以执行诸如每次部署网站时手动缩小和连接文件之类的操作，但这将是一个巨大的痛苦。理想情况下，您将使用单个命令自动执行这组任务，这称为生成步骤。缩小和串联只是两个可能的任务 - 任何可以自动化的重复性任务。下面是生成步骤中的一些典型任务：\n缩小 HTML、CSS 和 JavaScript\n连接 JavaScript 文件和 CSS 文件\n优化图像（通过调整大小、删除未使用的元数据等）\n添加 CSS 供应商前缀以实现浏览器兼容性\n转译代码（从 SASS 到 CSS，或从 CoffeeScript 到 JS，等等）\n运行代码测试\n要实现构建步骤，您需要选择一个工具，并且有很多工具可供选择。一个流行的选择是 Grunt，它于 2012 年发布。紧随其后的是 Gulp，以及 Broccoli.js，Brunch 和 webpack。截至 2018 年，webpack 似乎是最受欢迎的选择，但最终这些工具中的任何一个都将用于很好地实现构建步骤的目的。\n注意：从头开始学习使用工具进行构建步骤可能非常令人生畏。大多数工具都要求您使用命令行 — 如果您以前从未使用过，您可以阅读本教程以获得入门的良好概述。2018 年许多流行的 Web 开发人员构建工具都是基于 node.js 的——如果你不熟悉 node.js 生态系统及其在前端开发中的使用，你可以阅读我的文章 Modern JavaScript Explain For Dinosaurs，了解这方面的概述。\n模板和组件提高可维护性 到目前为止，我们有一个不错的网页，既有相当的吸引力，又有性能。现在它看起来像这样：\n在导航栏中，有一个指向“关于”页面的链接，但它目前没有转到任何地方。如果我们想制作这个关于页面怎么办？最直接的答案是复制名为 about.html 的 index.html ，并相应地更新内容。具体来说， \u0026lt;main\u0026gt; 元素中的内容将更改，HTML 的其余部分将保持不变。下面是一个简单的 about.html 页面的样子：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1, shrink-to-fit=no\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;author\u0026#34; content=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;[https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css](https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css)\u0026#34; integrity=\u0026#34;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; /\u0026gt; \u0026lt;script defer src=\u0026#34;[https://code.jquery.com/jquery-3.3.1.slim.min.js](https://code.jquery.com/jquery-3.3.1.slim.min.js)\u0026#34; integrity=\u0026#34;sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;[https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js](https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js)\u0026#34; integrity=\u0026#34;sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script defer src=\u0026#34;[https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js](https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js)\u0026#34; integrity=\u0026#34;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!--[if lt IE 9]\u0026gt; \u0026lt;script src=\u0026#34;[https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js](https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.js)\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;![endif]--\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;nav class=\u0026#34;navbar navbar-expand-lg navbar-light bg-light\u0026#34; role=\u0026#34;navigation\u0026#34; \u0026gt; \u0026lt;ul class=\u0026#34;navbar-nav mr-auto\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;nav-item active\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form class=\u0026#34;form-inline my-2 my-lg-0\u0026#34;\u0026gt; \u0026lt;input class=\u0026#34;form-control mr-sm-2\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; aria-label=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button class=\u0026#34;btn btn-outline-success my-2 my-sm-0\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt; Search \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;About\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Info about this site\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer class=\u0026#34;navbar navbar-dark bg-secondary\u0026#34; role=\u0026#34;contentinfo\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Copyright info goes here\u0026lt;/p\u0026gt; \u0026lt;/footer\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 请注意，除了突出显示的内容外， about.html 中的所有内容都与 index.html 相同。虽然这有效，但从维护的角度来看，它变得有问题。如果我们使用这种技术制作 7 个不同的页面，那将是大量重复的代码。如果我们以后想对导航栏进行更改，则必须将更改复制到所有 7 个文件中。这违反了众所周知的软件原则，称为 DRY（不要重复自己）。\n在服务器上构建模板 此问题的一个解决方案是使用模板引擎。这涉及在 HTML 中编写非标准 HTML，然后将其输入到一个单独的程序中，该程序将用标准 HTML 替换非标准 HTML。最好用一个例子来解释这一点。\n假设你正在使用 PHP，这是最早设计用于 HTML 的语言之一（今天仍然被许多大公司使用）。您将创建一个 head.php 文件（包含 \u0026lt;head\u0026gt; 元素中的内容）、 header.php 文件（包含导航栏元素）和 footer.php （包含页脚元素）。\n拥有这些文件后，您可以创建一个 index.php 文件，如下所示：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;?php include(\u0026#34;head.php\u0026#34;);?\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;?php include(\u0026#34;header.php\u0026#34;);?\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;section class=\u0026#34;jumbotron\u0026#34;\u0026gt;...\u0026lt;/section\u0026gt; \u0026lt;section class=\u0026#34;container\u0026#34;\u0026gt;...\u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;?php include(\u0026#34;footer.php\u0026#34;);?\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; about.php 文件如下所示：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;?php include(\u0026#34;head.php\u0026#34;);?\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;?php include(\u0026#34;header.php\u0026#34;);?\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;About\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Info about this site\u0026lt;/p\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;?php include(\u0026#34;footer.php\u0026#34;);?\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 所以在这里你可以看到唯一改变的部分是中间的内容。如果需要更新页眉、页脚或外部依赖项，则只需更改一次。\n上面的代码显然不是有效的 HTML — 您需要某种构建步骤来将 include 语句替换为单独文件中的 HTML。我们实际上可以将其合并到我们之前看到的构建步骤中（用于代码缩小、文件连接、关键 CSS 等）。但是，从模板生成 HTML 的这一步传统上是在服务器上动态完成的。\n来自 wikipedia.org 服务器是接收 Web 请求并将 HTML/CSS/JS 作为 Web 响应发送回的计算机（与客户端相反，具有启动 Web 请求的 Web 浏览器的计算机）。服务器通常负责基于数据库中的数据创建动态 HTML。例如，如果您在 www.google.com 上搜索“红色香蕉”，则不会有一些关于红色香蕉的唯一 HTML 文件从服务器发送给您。相反，服务器运行代码以根据您的搜索词动态创建 HTML 响应。所以在这里你可以用一块石头杀死两只鸟——因为你已经有一个步骤在服务器上生成动态 HTML，你可以使用模板来定义生成的 HTML 来保持你的代码干燥。\n在服务器上使用模板构建 HTML 是一种解决方案，在相当长的一段时间内一直是事实上的标准。除了 PHP，还有 Ruby on Rails 框架的 ERB，Python 的 Django 框架的 Django 模板语言，Node\u0026rsquo;s Express 框架的EJS等。这种方法可能非常令人生畏——为了利用模板引擎编写可维护的代码，您基本上首先必须学习整个编程语言和 Web 框架！如果您已经计划使用服务器和数据库，那么这是很自然的选择。但是，如果您只是对在前端编写 HTML 感兴趣，那么老实说，这是一个巨大的进入障碍。\n注意：如果您的网站不需要数据库，则可以改用静态网站生成器，该生成器使用模板来构建静态 HTML 文件（Jekyll，Hugo 和 Gatsby 是一些流行的选择）。与服务器端 Web 框架相比，静态站点生成器可能更易于使用;但是，您仍然需要学习单独的编程语言或环境，因此与编写纯 HTML 相比，进入仍然存在障碍。\n在客户端上使用 Web 组件 Web 组件于 2011 年首次引入，作为解决 HTML 可维护性问题的完全不同的方法。Web 组件是在客户端而不是服务器上构建的，这消除了必须学习服务器端编程语言和 Web 框架来编写可维护的 HTML 的障碍。\nWeb 组件的总体目标是能够创建可重用的小部件。回顾前面的示例，您可以创建导航栏组件、页眉组件和页脚组件。更进一步，您可以为页面中的内容创建一个巨型组件和一个文章组件。然后，您可以使用 index.html 中的组件，如下所示：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; ... \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;navbar-component\u0026gt;\u0026lt;/navbar-component\u0026gt; \u0026lt;main role=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;jumbotron-component\u0026gt;\u0026lt;/jumbotron-component\u0026gt; \u0026lt;section class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;articles-component\u0026gt;\u0026lt;/articles-component\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;/main\u0026gt; \u0026lt;footer-component\u0026gt;\u0026lt;/footer-component\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 为了使其正常工作，我们需要创建自定义元素，其中我们基本上是为 HTML 语言定义新元素（仅适用于此特定网站）。要创建自定义元素，您必须使用 JavaScript。下面是创建导航栏自定义元素所需的 JavaScript 示例：\nwindow.customElements.define( \u0026#34;navbar-component\u0026#34;, class extends HTMLElement { connectedCallback() { this.innerHTML = ` \u0026lt;nav class=\u0026#34;navbar navbar-expand-lg navbar-light bg-light\u0026#34; role=\u0026#34;navigation\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;navbar-nav mr-auto\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;nav-item active\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a class=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form class=\u0026#34;form-inline my-2 my-lg-0\u0026#34;\u0026gt; \u0026lt;input class=\u0026#34;form-control mr-sm-2\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; aria-label=\u0026#34;Search\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;btn btn-outline-success my-2 my-sm-0\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/nav\u0026gt; `; } } ); JavaScript 看起来有点复杂（它使用新的 ES2015 语言功能），但它在这个例子中所做的只是为导航栏定义 HTML（上面以粗体显示）并将名称 navbar-component 注册为自定义元素。请注意，HTML 是使用模板文字在 JavaScript 文件中定义的，本质上是一个巨大的字符串——如果你更喜欢将其移回常规 HTML 文件，我们将需要一个不同的机制，我们将在稍后讨论。如果您将此 JavaScript 添加到页面，您现在可以在普通 HTML 元素之外创建 \u0026lt;navbar-component\u0026gt; 个元素。\n到目前为止，在此示例中，此方法与服务器端模板方法相比没有太大优势。但是，当您开始向每个组件添加 JavaScript 功能和 CSS 样式时，好处变得更加明显。Web 组件提供了隔离功能和样式的功能，以保留在每个组件中，使它们可重用 — 不仅用于此站点，而且理论上可以在多个项目中重用。这个概念可以在现有的 HTML 元素（如 \u0026lt;video\u0026gt; 元素）中看到。如果你像这样写 HTML：\n\u0026lt;video width=\u0026#34;320\u0026#34; height=\u0026#34;240\u0026#34; controls loop muted\u0026gt; \u0026lt;source src=\u0026#34;movie.mp4\u0026#34; type=\u0026#34;video/mp4\u0026#34; /\u0026gt; \u0026lt;source src=\u0026#34;movie.ogg\u0026#34; type=\u0026#34;video/ogg\u0026#34; /\u0026gt; \u0026lt;p\u0026gt; Your browser doesn\u0026#39;t support HTML5 video. Here is a \u0026lt;a href=\u0026#34;movie.mp4\u0026#34;\u0026gt;link to the video\u0026lt;/a\u0026gt; instead. \u0026lt;/p\u0026gt; \u0026lt;/video\u0026gt; 你会得到一个看起来像这样的视频播放器：\n*（这是视频的图片，不是实际的视频）* 元素带有自己的 JavaScript 交互式控件和 CSS 样式，它们与页面的其余部分隔离。这意味着当您使用 元素时，您不必担心它会影响您网站的样式或功能，也不必担心来自网站的任何 CSS 或 JavaScript 会破坏视频组件。\nWeb 组件的目标是使开发人员能够创建自己的自定义组件，类似于 \u0026lt;video\u0026gt; 元素，并具有所有隔离和可重用性优势。以下是 Web 组件规范的所有部分如何协同工作：\n您可以在 JavaScript 中创建自定义元素，如前所述。然后，您可以在 JavaScript 中定义自定义功能，并将属性从 HTML 传递到自定义元素中。\n您可以使用影子 DOM 使用 CSS 设置自定义元素的样式，该样式仅适用于元素而不是整个文档（解决 CSS 最困难的方面之一）。\n如果你不想直接用 JavaScript 编写所有的 HTML，你可以使用 HTML 模板，在 \u0026lt;template\u0026gt; 标记中将组件的 HTML 写入普通 HTML 文件中，在被 JavaScript 调用之前不会呈现。\n要组织代码，您可以使用 HTML 导入，您可以在其中将定义组件所需的所有 HTML、CSS 和 JavaScript 放入名为 navbar-component.html 的文件中，然后将其导入主 HTML 文件中，就像导入外部 CSS 文件一样：\u0026lt;link rel=\u0026quot;import\u0026quot; href=\u0026quot;navbar-component.html\u0026quot;\u0026gt;.\n当 Web 组件在 2011 年首次发布时，许多开发人员对这些可能性感到兴奋。虽然服务器端模板化方法有助于解决 HTML 的一些可维护性问题，但 Web 组件提供了完全不同的东西 - 扩展 HTML 的承诺将具有完整的可重用小部件。这是使 Web 平台成为可以开发复杂应用程序的地方所缺少的部分，而不是最初设计的简单静态内容站点。\n那么发生了什么？在接下来的几年里，很明显，浏览器并没有就 Web 组件作为标准达成一致。截至 2018 年，几乎没有浏览器完全支持上述 Web 组件的四个主要功能，这是由于实现性能的潜在问题，标准冲突和不同的公司利益。这让开发人员处于一个有趣的位置 - 几乎每个人都同意组件样式方法是将 Web 从静态站点转移到复杂应用程序的必要部分，但等待浏览器支持似乎是徒劳的。怎么办？\n在客户端上使用 JavaScript 框架 当 HTML Web 组件规范不会很快实现时，JavaScript 已经是一种足够强大的语言来弥补这一缺陷。开发人员一直在使用 jQuery 库（2006 年发布）制作复杂的应用程序，尽管很难为大规模应用程序组织代码。Backbone.js（2010 年发布）是最早的流行库之一，旨在为大型单页应用程序提供组织代码的框架，其次是 AngularJS，Ember.js 等。\n所有这些框架都与现有的 JavaScript 功能一起工作 - 它们不必依赖于等待浏览器来实现 Web 组件规范。但是没有一个框架使用真正的孤立和可重用的组件；如果没有 Web 组件规范的 4 个部分（自定义元素、影子 DOM、HTML 模板和 HTML 导入），这似乎是不可能的。\n2013 年，一个名为 React 的框架发布，它对这种情况有一个有趣的看法。他们能够使用以下方法在没有 Web 组件规范的情况下制作一个真正的基于组件的框架：\nReact 没有使用 Web 组件的自定义元素规范，而是采用了在 JavaScript 中定义所有 HTML 的方法。从本质上讲，您将定义 JavaScript 函数以使用称为 JSX 的特殊语法输出所需的 HTML（它看起来像 HTML，但使用构建步骤转换为 JavaScript 函数）。 React 没有使用 Web 组件的 HTML 模板规范，而是没有提供在 JavaScript 之外编写 HTML 的方法。 React 没有使用 Web 组件的 HTML 导入规范，而是采用了将 JavaScript 导入 JavaScript 的方法。这在当时实际上并不直接可行，但像Browserify 和 webpack这样的工具允许开发人员在 他们的 JavaScript 中编写 require 或 import 语句，这些语句将在构建时转换为单个 JavaScript 包。 从本质上讲，这里的见解是，您可以通过在 JavaScript 中执行所有操作来使组件工作。请注意，这里缺少 Web 组件规范的一部分，即影子 DOM——React 在首次发布时没有隔离样式的解决方案。尽管如此，它足以为今天使用组件构建应用程序提供一个框架。\n这就是 JavaScript 使用 React 制作导航栏组件的样子：\nimport React, { Component } from \u0026#34;react\u0026#34;; class Navbar extends Component { render() { return ( \u0026lt;nav className=\u0026#34;navbar navbar-expand-lg navbar-light bg-light\u0026#34; role=\u0026#34;navigation\u0026#34; \u0026gt; \u0026lt;ul className=\u0026#34;navbar-nav mr-auto\u0026#34;\u0026gt; \u0026lt;li className=\u0026#34;nav-item active\u0026#34;\u0026gt; \u0026lt;a className=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt; Home \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li className=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a className=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt; Info \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li className=\u0026#34;nav-item\u0026#34;\u0026gt; \u0026lt;a className=\u0026#34;nav-link\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt; About \u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form className=\u0026#34;form-inline my-2 my-lg-0\u0026#34;\u0026gt; \u0026lt;input className=\u0026#34;form-control mr-sm-2\u0026#34; type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; aria-label=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button className=\u0026#34;btn btn-outline-success my-2 my-sm-0\u0026#34; type=\u0026#34;submit\u0026#34; \u0026gt; Search \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/nav\u0026gt; ); } } export default Navbar; 这与前面显示的自定义元素示例没有太大区别（尽管 JSX 语法在大多数开发人员第一次看到它时都感到不安）。React 中的想法是将其分解为进一步的子组件，这样每个组件只做一件事。\n当 React 首次发布时，它遭到了很多批评，特别是因为它似乎缺乏关注点分离（开发人员被教导将 HTML、CSS 和 JS 完全分开以实现可维护性）。然而，React 提出了这样一个观点，即对于复杂的 Web 应用程序，关注点的分离不是关于技术（HTML，CSS 和 JS）之间的边界，而是关于功能单元（换句话说，组件）之间的边界。\n除了作为一个基于组件的框架之外，React 还带来了关于如何使用声明性方法管理应用程序中数据的强烈意见。这意味着使用 React，您无需编写代码即可直接更新接口。相反，你定义接口应该是什么样子（使用 JSX），编写代码来更新数据，然后让 React 弄清楚如何使用其虚拟 DOM 实现有效地更新和渲染接口（不要与影子 DOM 混淆）。这是 Web 框架设计的一个重大转变，影响力大到每个主要框架都公开借用了 React 使用 虚拟 DOM 实现的声明式方法 — Ember、Angular、Vue.js，等等。截至 2018 年，Web 开发社区已在很大程度上接受这种范式作为构建现代 Web 应用程序的方式。\n请注意，以清晰且可维护的方式编写 HTML 的愿望使我们进入了一个需要大量编程知识的地方;几乎不可能特别避免 JavaScript。从某种意义上说，这打破了 HTML 的承诺，HTML 被设计成一种不需要理解编程就可以有效使用的语言。未来可能会有开发人员可以在纯 HTML 中共享预先构建的 Web 组件，但未来可能需要相当长的时间才能到来。\n本节仅简要概述了 React 和其他类似框架采用的前端方法。如果你想要更完整的解释和教程，关于如何使用各种 JavaScript 框架和方法构建一个工作的应用程序，请查看我的系列比较前端方法：看看 jQuery，Vue.js，React 和 Elm。\n结论 简而言之，这就是现代 HTML。我们介绍了使用适当的标签和 aria 属性编写语义和可访问的内容，使用 CSS 和 JavaScript 添加样式和动态功能，使用 HTML 属性和工具提高性能，最后使用模板和组件来提高可维护性。在此过程中，我们可以看到，要充分利用现代 HTML，几乎不可能避免使用构建过程以及某种形式的独立编程语言，对于大多数方法来说，这通常是 JavaScript。\n从高层次来看它有时会令人沮丧——过去是一个简单易用的工作（用 HTML 制作网站）现在变得复杂且似乎难以接近（使用 JavaScript 前端框架制作 Web 应用程序，使用具有数千个潜在脆弱依赖项的构建过程）。然而，重要的是要注意，Web 开发作为一个行业只存在了大约 30 年 - 与其他行业（例如已经存在了许多世纪的建筑）相比，这只是历史的一小部分。就好像 Web 开发人员刚刚学会了如何用粘土建造房屋，现在被要求使用相同的工具来建造摩天大楼。我们的工具和流程不断发展是很自然的;我们只需要确保它以一种包容网络作为民主平台的最初愿景的方式发展。\n现代 HTML 的使用肯定会令人沮丧，因为它继续快速变化和发展。然而，我们现在能够做的比以往任何时候都多，而且我们基本上都处于一个新行业的底层，有可能将其塑造成我们希望它成为的平台。作为一名开发人员，这是一个激动人心的时刻，我希望这些信息可以作为路线图，在您的旅程中为您提供帮助！\n特别感谢 @ryanqnorth 的 恐龙漫画，自 2003 年以来（恐龙统治网络）以来，它提供了一些最好的荒诞幽默。\n对这种学习方式感兴趣？请务必查看 Actualize 编码训练营（我是教学主任和首席讲师）。我们在芝加哥提供 面对面的课程 以及 实时在线课程，以帮助人们过渡到现代网络开发人员的新职业！\n原文链接：https://peterxjang.com/blog/modern-html-explained-for-dinosaurs.html\n","permalink":"https://blog.chensoul.cc/posts/2023/06/20/modern-html-explained-for-dinosaurs/","summary":"在三种主要的前端技术（ HTML，CSS 和 JavaScript ）中，HTML 仍然是最一致的。如果您唯一关心的是创建内容，那么 1990 年代的 HTML 文档看起来与 2018 年创建的文档非常相似：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello there!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 你有带有标签和内容的元素，带有属性的标签——除了第一行的简化文档类型外，没有太大变化！然而，多年来，Web 开发已经发生了巨大的转变，从创建静态网站（专注于内容）到创建动态 Web 应用程序（专注于交互）——这是 Web 最初设计的目的。创建仍然语义和可访问的自定义用户界面，使用属性和工具提高性能，组织代码以进行重用和可维护性 - 现在有一组全新的问题在起作用。\n本文的目的是提供一个历史背景，说明 HTML 如何在 2018 年演变成今天的语言。我们将从结构良好且易于访问的 HTML 的基础知识开始，就像古代的恐龙一样。然后，我们将介绍不同的技术来提高性能、响应能力和可维护性。CSS 和 JavaScript 将不可避免地进入这个对话；出于本文的目的，将从它们如何影响 HTML 本身编写的角度来介绍它们。通过了解这段历史，您将能够充分利用该语言经常被忽视的新旧功能。让我们开始吧！\n使用语义元素编写内容 让我们向前面的 HTML 示例添加更多内容。现在，我们将创建一个基本网站，其中包含一个带有链接和搜索输入的导航部分，一个用于显示一般网站信息的大型展示部分（通常称为英雄部分或 巨型屏幕 ），文章的三列部分和一个版权信息的页脚部分。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;My test page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;navbar\u0026#34;\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Info\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;li\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;form\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; placeholder=\u0026#34;Search\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;Search\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;hero\u0026#34;\u0026gt; \u0026lt;h1\u0026gt;Hello there!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;General info about the page goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Learn more\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;grid\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;First Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Second Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;column\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Third Heading\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;Article content goes here\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;View details\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Copyright info goes here\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 在这里，我们使用带有 \u0026lt;div\u0026gt; 、 \u0026lt;h1\u0026gt; 、 \u0026lt;h2\u0026gt; 、 \u0026lt;p\u0026gt; 等标签的基本元素来标记内容。这里的 HTML 是有效的，但它不是完全语义的——也就是说，标签不能尽可能地传达内容的含义。","title":"[译]为恐龙解释现代HTML"},{"content":" 图片来自Ryan North的Dinosaur Comics。 如果你从一开始就没有去过那里，那么学习现代 JavaScript 是很困难的。生态系统的发展和变化如此之快，以至于很难理解不同工具试图解决的问题。我从 1998 年开始编程，但直到 2014 年才开始认真学习 JavaScript。当时我记得遇到 Browserify 并盯着它的标语：\nBrowserify 通过捆绑所有依赖项，让你在浏览器中导入（\u0026lsquo;模块\u0026rsquo;）。\n我几乎听不懂这句话中的任何单词，并且努力理解这对我作为开发人员有什么帮助。\n本文的目的是提供一个历史背景，说明 JavaScript 工具如何在 2017 年发展到今天的样子。我们将从头开始，像恐龙一样构建一个示例网站 - 没有工具，只有普通的 HTML 和 JavaScript。然后，我们将逐步介绍不同的工具，以查看它们一次解决一个问题。有了这个历史背景，你将能够更好地学习和适应未来不断变化的 JavaScript 环境。让我们开始吧！\n更新：我制作了本文的视频课程版本，为了更清晰，我逐步浏览了每个部分，请在此处查看： https://firstclass.actualize.co/p/modern-javascript-explained-for-dinosaurs\n以\u0026quot;老派\u0026quot;的方式使用 JavaScript \u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;JavaScript Example\u0026lt;/title\u0026gt; ** \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; ** \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from HTML!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 第 \u0026lt;script src=\u0026quot;index.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 行引用同一目录中名为 index.js 的单独 JavaScript 文件：\n// index.js console.log(\u0026#34;Hello from JavaScript!\u0026#34;); 这就是制作网站所需的全部内容！现在，假设您想添加一个其他人编写的库，例如 moment.js（一个可以帮助以人类可读的方式格式化日期的库）。例如，您可以在 JavaScript 中使用 moment 函数，如下所示：\nmoment().startOf(\u0026#34;day\u0026#34;).fromNow(); // 20 hours ago 但这只是假设您在网站上包含 moment.js！在 moment.js 主页 上您会看到以下说明：\n嗯，右侧的\u0026quot;安装\u0026quot;部分有很多内容。但是现在让我们忽略它 - 我们可以通过在同一目录中下载 moment.min.js 文件并将其包含在我们的 index.html 文件中来为我们的网站添加 moment.js。\n\u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Example\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;moment.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from HTML!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 请注意， moment.min.js 在 index.js 之前加载，这意味着您可以在 index.js 中使用 moment 函数，如下所示：\n// index.js console.log(\u0026#34;Hello from JavaScript!\u0026#34;); console.log(moment().startOf(\u0026#34;day\u0026#34;).fromNow()); 这就是我们过去使用 JavaScript 库制作网站的方式！好消息是它很容易理解。不好的是，每次更新时查找和下载新版本的库都很烦人。\n使用 JavaScript 包管理器 （npm） 从 2010 年左右开始，出现了几个相互竞争的 JavaScript 包管理器，以帮助自动化从中央存储库下载和升级库的过程。Bower 可以说是 2013 年最受欢迎的，但最终在 2015 年左右被 npm 超越。（值得注意的是，从 2016 年末开始，yarn 作为 npm 接口的替代品获得了很大的关注，但它仍然在引擎盖下使用 npm 包。\n请注意，npm 最初是专门为 node.js 制作的包管理器，这是一个旨在在服务器上运行的 JavaScript 运行时，而不是前端。因此，对于打算在浏览器中运行的库的前端 JavaScript 包管理器来说，这是一个非常奇怪的选择。\n注意：使用包管理器通常涉及使用命令行，过去前端开发从不需要命令行。如果您从未使用过，可以阅读本教程以获取入门的良好概述。无论好坏，知道如何使用命令行是现代 JavaScript 的重要组成部分（它也为其他开发领域打开了大门）。\n让我们看看如何使用 npm 自动安装 moment.js 包，而不是手动下载它。如果您安装了 node.js，则您已经安装了 npm，这意味着您可以将命令行导航到包含 index.html 文件的文件夹并输入：\n$ npm init 这将提示您几个问题（默认值很好，您可以为每个问题点击“Enter”）并生成一个名为 package.json 的新文件。这是 npm 用来保存所有项目信息的配置文件。使用默认值时， package.json 的内容应如下所示：\n{ \u0026#34;name\u0026#34;: \u0026#34;your-project-name\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34; } 要安装 moment.js JavaScript 包，我们现在可以通过在命令行中输入以下命令来按照其主页上的 npm 说明进行操作：\n$ npm install moment --save 此命令执行两件事 — 首先，它从 moment.js 包 下载所有代码名为 node_modules 的文件夹中。其次，它会自动修改 package.json 文件以跟踪 moment.js 作为项目依赖项。\n{ \u0026#34;name\u0026#34;: \u0026#34;modern-javascript-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;moment\u0026#34;: \u0026#34;^2.22.2\u0026#34; } } 这在以后与他人共享项目时很有用 - 而不是共享 node_modules 文件夹（可能会变得非常大），您只需要共享 package.json 文件，其他开发人员可以使用命令 npm install 自动安装所需的包。\n所以现在我们不再需要从网站上手动下载 momentjs，我们可以使用 npm 自动下载和更新它。查看 node_modules 文件夹内部，我们可以看到 moment.min.js 目录中的 node_modules/moment/min 文件。这意味着我们可以链接到 index.html 文件中的 npm 下载版本，如下所示：\n\u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;JavaScript Example\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;node_modules/moment/min/moment.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from HTML!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 所以好消息是我们现在可以使用 npm 通过命令行下载和更新我们的包。不好的是，现在我们正在挖掘 node_modules 文件夹以查找每个包的位置，并手动将其包含在我们的 HTML 中。这很不方便，所以接下来我们将看看如何自动化该过程。\n使用 JavaScript 模块捆绑器（webpack)　大多数编程语言都提供了一种将代码从一个文件导入另一个文件的方法。JavaScript 最初并不是使用此功能设计的，因为 JavaScript 被设计为仅在浏览器中运行，无法访问客户端计算机的文件系统（出于安全原因）。因此，在很长一段时间内，在多个文件中组织 JavaScript 代码需要您使用全局共享的变量加载每个文件。\n这实际上是我们在上面所做的 moment.js 示例 — 整个 moment.min.js 文件加载到 HTML 中，HTML 定义了一个全局变量 moment ，然后可用于在 moment.min.js 之后加载的任何文件（无论它是否需要访问它）。\n2009 年，一个名为 CommonJS 的项目启动，目标是在浏览器之外为 JavaScript 指定一个生态系统。CommonJS 的很大一部分是它的模块规范，它最终允许 JavaScript 像大多数编程语言一样跨文件导入和导出代码，而无需诉诸全局变量。最著名的 CommonJS 模块实现是 node.js。\n如前所述，node.js 是一个设计用于在服务器上运行的 JavaScript 运行时。下面是前面的示例使用 node.js 模块的样子。与其使用 HTML 脚本标记加载所有 moment.min.js ，不如直接将其加载到 JavaScript 文件中，如下所示：\n// index.js var moment = require(\u0026#34;moment\u0026#34;); console.log(\u0026#34;Hello from JavaScript!\u0026#34;); console.log(moment().startOf(\u0026#34;day\u0026#34;).fromNow()); 同样，这就是模块加载在 node.js 中的工作方式，由于 node.js 是一种可以访问计算机文件系统的服务器端语言，因此效果很好。Node.js 也知道每个 npm 模块路径的位置，所以你不必写 require('./node_modules/moment/min/moment.min.js) ，你可以简单地写 require('moment') — 非常甜蜜。\n这对于 node.js 来说都很棒，但是如果您尝试在浏览器中使用上述代码，则会收到一条错误消息，指出未定义浏览器无法访问文件系统，这意味着以这种方式加载模块非常棘手 - 加载文件必须动态完成，同步（这会减慢执行速度）或异步（可能存在计时问题）。\n这就是模块捆绑器的用武之地。JavaScript 模块捆绑器是一种工具，它通过构建步骤（可以访问文件系统）来解决问题，以创建与浏览器兼容的最终输出（不需要访问文件系统）。在这种情况下，我们需要一个模块捆绑器来查找所有 require 语句（这是无效的浏览器 JavaScript 语法），并将它们替换为每个所需文件的实际内容。最终结果是一个捆绑的 JavaScript 文件（没有 require 语句）！\n最流行的模块捆绑器是 Browserify，它于 2011 年发布，率先在前端使用 node.js 样式的需求语句（这本质上是使 npm 成为首选前端包管理器的原因）。大约在 2015 年，webpack 最终成为使用更广泛的模块捆绑器（受到 React 前端框架的普及的推动，它充分利用了 webpack 的各种功能）。\n让我们来看看如何使用 webpack 让上面的 require('moment') 示例在浏览器中工作。首先，我们需要将 webpack 安装到项目中。Webpack 本身是一个 npm 包，所以我们可以从命令行安装它：\n$ npm install webpack webpack-cli --save-dev 请注意，我们正在安装两个软件包 — webpack 和 webpack-cli（它使您能够从命令行使用 webpack）。另请注意 --save-dev 参数 — 这会将其保存为开发依赖项，这意味着它是开发环境中需要的包，而不是生产服务器上需要的包。您可以在自动更新的 package.json 文件中看到这反映在：\n{ \u0026#34;name\u0026#34;: \u0026#34;modern-javascript-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;moment\u0026#34;: \u0026#34;^2.19.1\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;webpack\u0026#34;: \u0026#34;^4.17.1\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^3.1.0\u0026#34; } } 现在我们已经将 webpack 和 webpack-cli 作为包安装在 node_modules 文件夹中。您可以从命令行使用 webpack-cli，如下所示：\n$ ./node_modules/.bin/webpack index.js --mode=development 此命令将运行安装在 node_modules 文件夹中的 webpack 工具，从 index.js 文件开始，找到任意 require 语句，并将它们替换为适当的代码以创建单个输出文件（默认为 dist/main.js ）。 --mode=development 参数是为了让开发人员保持 JavaScript 的可读性，而不是参数 --mode=production 的缩小输出。\n现在我们有了 webpack 的 dist/main.js 输出，我们将在浏览器中使用它而不是 index.js ，因为它包含无效的 require 语句。这将反映在 index.html 文件中，如下所示：\n\u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;JavaScript Example\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;dist/main.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from HTML!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 如果您刷新浏览器，您应该会看到一切都像以前一样工作！\n请注意，每次更改 index.js 时，我们都需要运行 webpack 命令。这很乏味，当我们使用 webpack 更高级的功能（例如生成源映射以帮助从转译的代码调试原始代码）时，这将变得更加乏味。Webpack 可以从名为 webpack.config.js 的项目根目录中的配置文件中读取选项，在我们的例子中，它看起来像：\n// webpack.config.js module.exports = { mode: \u0026#34;development\u0026#34;, entry: \u0026#34;./index.js\u0026#34;, output: { filename: \u0026#34;main.js\u0026#34;, publicPath: \u0026#34;dist\u0026#34;, }, }; 现在每次我们更改 index.js 时，我们都可以使用以下命令运行 webpack：\n$ ./node_modules/.bin/webpack 我们不再需要指定 index.js 和 --mode=development 选项，因为 webpack 正在从 webpack.config.js 文件中加载这些选项。这更好，但为每个代码更改输入此命令仍然很乏味 - 我们将使此过程更顺畅。\n总的来说，这可能看起来不多，但这个工作流程有一些巨大的优势。我们不再通过全局变量加载外部脚本。任何新的 JavaScript 库都将在 JavaScript 中使用 require 语句添加，而不是在 HTML 中添加新的 \u0026lt;script\u0026gt; 标签。拥有单个 JavaScript 捆绑包文件通常对性能更好。现在我们添加了构建步骤，我们可以将其他一些强大的功能添加到我们的开发工作流程中！\n为新的语言功能转译代码 （babel） 转译代码意味着将一种语言的代码转换为另一种类似语言的代码。这是前端开发的一个重要部分——由于浏览器添加新功能的速度很慢，因此使用实验性功能创建了新语言，这些功能可以转换为浏览器兼容语言。\n对于 CSS，有 Sass，Less 和 Stylus，仅举几例。对于 JavaScript，一段时间内最流行的转译器是 CoffeeScript（2010 年左右发布），而现在大多数人使用 babel 或 TypeScript。CoffeeScript 是一种专注于通过显著改变语言来改进 JavaScript 的语言——可选的括号、重要的空格等。Babel 不是一门新语言，而是一种转译器，它将尚未适用于所有浏览器（ES2015 及更高版本）的下一代 JavaScript 转译为更兼容的旧 JavaScript （ES5）。Typescript 是一种与下一代 JavaScript 基本相同的语言，但也添加了可选的静态类型。许多人选择使用 babel，因为它最接近原版 JavaScript。\n让我们看一个如何在我们现有的 webpack 构建步骤中使用 babel 的示例。首先，我们将从命令行将 babel（这是一个 npm 包）安装到项目中：\n$ npm install @babel/core @babel/preset-env babel-loader --save-dev 请注意，我们正在安装 3 个单独的包作为开发依赖项 — @babel/core 是 babel 的主要部分， @babel/preset-env 是定义要转译的新 JavaScript 功能的预设， babel-loader 是使 babel 能够使用 webpack 的包。我们可以通过编辑 webpack.config.js 文件将 webpack 配置为使用 babel-loader ，如下所示：\n// webpack.config.js module.exports = { mode: \u0026#34;development\u0026#34;, entry: \u0026#34;./index.js\u0026#34;, output: { filename: \u0026#34;main.js\u0026#34;, publicPath: \u0026#34;dist\u0026#34;, }, module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, use: { loader: \u0026#34;babel-loader\u0026#34;, options: { presets: [\u0026#34;@babel/preset-env\u0026#34;], }, }, }, ], }, }; 这种语法可能会令人困惑（幸运的是，这不是我们经常编辑的东西）。基本上，我们告诉 webpack 查找任何 .js 文件（不包括 node_modules 文件夹中的文件），并使用 babel-loader 和 @babel/preset-env 预设应用 babel 转译。您可以在此处阅读有关 webpack 配置语法的更多信息。\n现在一切都设置好了，我们可以开始用我们的 JavaScript 编写 ES2015 功能了！下面是 index.js 文件中的 ES2015 模板字符串示例：\n// index.js var moment = require(\u0026#34;moment\u0026#34;); console.log(\u0026#34;Hello from JavaScript!\u0026#34;); console.log(moment().startOf(\u0026#34;day\u0026#34;).fromNow()); var name = \u0026#34;Bob\u0026#34;, time = \u0026#34;today\u0026#34;; console.log(`Hello ${name}, how are you ${time}?`); 我们还可以使用 ES2015 import 语句 代替 require 来加载模块，这就是您今天在很多代码库中看到的内容：\n// index.js import moment from \u0026#34;moment\u0026#34;; console.log(\u0026#34;Hello from JavaScript!\u0026#34;); console.log(moment().startOf(\u0026#34;day\u0026#34;).fromNow()); var name = \u0026#34;Bob\u0026#34;, time = \u0026#34;today\u0026#34;; console.log(`Hello ${name}, how are you ${time}?`); 在此示例中， import 语法与 require 语法没有太大区别，但 import 对于更高级的情况具有额外的灵活性。由于我们更改了 index.js ，我们需要在命令行中再次运行 webpack：\n$ ./node_modules/.bin/webpack 现在您可以在浏览器中刷新 index.html 。在撰写本文时，大多数现代浏览器都支持所有 ES2015 功能，因此很难判断 babel 是否完成了它的工作。您可以在 IE9 等较旧的浏览器中对其进行测试，也可以在 main.js 中搜索以查找转译的代码行：\n// main.js // ... console.log(\u0026#34;Hello \u0026#34; + name + \u0026#34;, how are you \u0026#34; + time + \u0026#34;?\u0026#34;); // ... 在这里你可以看到 babel 将 ES2015 模板字符串转换为常规的 JavaScript 字符串连接，以保持浏览器兼容性。虽然这个特殊的例子可能不太令人兴奋，但转译代码的能力是非常强大的。JavaScript 中有一些令人兴奋的语言功能，如 async/await，你可以立即开始使用它们来编写更好的代码。虽然音译有时可能看起来乏味和痛苦，但它在过去几年中导致了语言的巨大改进，因为人们今天正在测试明天的功能。\n我们几乎完成了，但我们的工作流程中仍有一些未打磨的边缘。如果我们担心性能，我们应该缩小捆绑文件，这应该很容易，因为我们已经合并了一个构建步骤。每次更改 JavaScript 时，我们还需要重新运行 webpack 命令，这会很快变旧。因此，接下来我们要看的是解决这些问题的一些便捷工具。\n使用任务运行程序（npm 脚本） 现在我们已经投资使用构建步骤来处理 JavaScript 模块，使用任务运行器是有意义的，这是一个自动执行构建过程不同部分的工具。对于前端开发，任务包括缩小代码、优化图像、运行测试等。\n2013 年，Grunt 是最受欢迎的前端任务运行者，Gulp 紧随其后。两者都依赖于包装其他命令行工具的插件。如今，最流行的选择似乎是使用 npm 包管理器本身内置的脚本功能，它不使用插件，而是直接与其他命令行工具一起使用。\n让我们编写一些 npm 脚本，以便更轻松地使用 webpack。这涉及简单地更改 package.json 文件，如下所示：\n{ \u0026#34;name\u0026#34;: \u0026#34;modern-javascript-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;webpack --progress --mode=production\u0026#34;, \u0026#34;watch\u0026#34;: \u0026#34;webpack --progress --watch\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;moment\u0026#34;: \u0026#34;^2.22.2\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@babel/core\u0026#34;: \u0026#34;^7.0.0\u0026#34;, \u0026#34;@babel/preset-env\u0026#34;: \u0026#34;^7.0.0\u0026#34;, \u0026#34;babel-loader\u0026#34;: \u0026#34;^8.0.2\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;^4.17.1\u0026#34;, \u0026#34;webpack-cli\u0026#34;: \u0026#34;^3.1.0\u0026#34; } } 在这里，我们添加了两个新脚本， build 和 watch 。要运行构建脚本，您可以在命令行中输入：\n$ npm run build 这将运行 webpack（使用我们之前所做的 webpack.config.js 中的配置），其中 --progress 选项显示进度百分比， --mode=production 选项最小化生产代码。要运行 watch 脚本，请执行以下操作：\n$ npm run watch 它使用 --watch 选项代替，以便在每次任何 JavaScript 文件更改时自动重新运行 webpack，这对于开发非常有用。\n请注意， package.json 中的脚本可以在不必指定完整路径 ./node_modules/.bin/webpack 的情况下运行 webpack，因为 node.js 知道每个 npm 模块路径的位置。这很甜！我们可以通过安装 webpack-dev-server 来让事情变得更加甜蜜，这是一个单独的工具，它提供了一个简单的 Web 服务器和实时重新加载。要将其安装为开发依赖项，请输入以下命令：\n$ npm install webpack-dev-server --save-dev 然后将一个 npm 脚本添加到 package.json ：\n{ \u0026#34;name\u0026#34;: \u0026#34;modern-javascript-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;echo \\\u0026#34;Error: no test specified\\\u0026#34; \u0026amp;\u0026amp; exit 1\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;webpack --progress -p\u0026#34;, \u0026#34;watch\u0026#34;: \u0026#34;webpack --progress --watch\u0026#34;, \u0026#34;serve\u0026#34;: \u0026#34;webpack-dev-server --open\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;license\u0026#34;: \u0026#34;ISC\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;moment\u0026#34;: \u0026#34;^2.19.1\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;@babel/core\u0026#34;: \u0026#34;^7.0.0\u0026#34;, \u0026#34;@babel/preset-env\u0026#34;: \u0026#34;^7.0.0\u0026#34;, \u0026#34;babel-loader\u0026#34;: \u0026#34;^8.0.2\u0026#34;, \u0026#34;webpack\u0026#34;: \u0026#34;^3.7.1\u0026#34;, \u0026#34;webpack-dev-server\u0026#34;: \u0026#34;^3.1.6\u0026#34; } } 现在，您可以通过运行以下命令来启动开发服务器：\n$ npm run serve 这将在您的浏览器中自动打开地址为 localhost:8080 的 index.html 网站（默认情况下）。每当你在 index.js 中更改 JavaScript 时，webpack-dev-server 都会重建它自己的捆绑 JavaScript 并自动刷新浏览器。这是一个非常有用的时间节省，因为它允许您将注意力集中在代码上，而不必在代码和浏览器之间不断切换上下文以查看新的更改。\n这只是表面，webpack 和 webpack-dev-server 还有更多选项（你可以在这里阅读）。当然，你也可以制作 npm 脚本来运行其他任务，例如将 Sass 转换为 CSS、压缩图像、运行测试 — 任何具有命令行工具的东西都是公平的游戏。npm 脚本本身也有一些很棒的高级选项和技巧——Kate Hudson 的这个演讲是一个很好的起点：\nhttps://youtu.be/0RYETb9YVrk\n结论 简而言之，这就是现代 JavaScript。我们从纯 HTML 和 JS 转向使用包管理器自动下载第三方包，使用模块捆绑器创建单个脚本文件，使用转译器使用未来的 JavaScript 功能，以及任务运行器来自动化构建过程的不同部分。这里肯定有很多移动的部分，特别是对于初学者。对于刚接触编程的人来说，Web 开发曾经是一个很好的切入点，正是因为它很容易启动和运行;如今，这可能非常令人生畏，特别是因为各种工具往往会迅速变化。\n不过，它并不像看起来那么糟糕。事情正在安定下来，特别是随着节点生态系统作为与前端合作的可行方式的采用。使用 npm 作为包管理器，将节点 require 或 import 语句用于模块，使用 npm 脚本来运行任务，这很好且一致。与一两年前相比，这是一个大大简化的工作流程！\n对于初学者和有经验的开发人员来说，更好的是，如今的框架通常带有使该过程更容易上手的工具。Ember 有 ember-cli ，这对 Angular 的 angular-cli 、React 的 create-react-app、Vue 的 vue-cli 等产生了巨大的影响。所有这些工具都将设置一个包含您需要的所有项目——您需要做的就是开始编写代码。然而，这些工具并不神奇，它们只是以一种一致和工作的方式设置了所有内容——你可能经常需要对 webpack、babel 等进行一些额外的配置。因此，了解我们在本文中介绍的每个部分的作用仍然非常关键。\n现代 JavaScript 在使用时肯定会令人沮丧，因为它继续快速变化和发展。但是，尽管有时看起来像是重新发明轮子，但 JavaScript 的快速发展有助于推动诸如热重载，实时 linting 和时间旅行调试等创新。作为一名开发人员，这是一个激动人心的时刻，我希望这些信息可以作为路线图，在您的旅程中为您提供帮助！\n特别感谢@ryanqnorth的恐龙漫画，自 2003 年以来（恐龙统治网络）以来，它提供了一些最好的荒诞幽默。\n原文链接：https://peterxjang.com/blog/modern-javascript-explained-for-dinosaurs.html\n译者备注：\nGithub 上有一个关于这篇文章源代码的仓库：https://github.com/scherler/Modern-JavaScript-Explained-For-Dinosaurs\n","permalink":"https://blog.chensoul.cc/posts/2023/06/19/modern-javascript-explained-for-dinosaurs/","summary":"图片来自Ryan North的Dinosaur Comics。 如果你从一开始就没有去过那里，那么学习现代 JavaScript 是很困难的。生态系统的发展和变化如此之快，以至于很难理解不同工具试图解决的问题。我从 1998 年开始编程，但直到 2014 年才开始认真学习 JavaScript。当时我记得遇到 Browserify 并盯着它的标语：\nBrowserify 通过捆绑所有依赖项，让你在浏览器中导入（\u0026lsquo;模块\u0026rsquo;）。\n我几乎听不懂这句话中的任何单词，并且努力理解这对我作为开发人员有什么帮助。\n本文的目的是提供一个历史背景，说明 JavaScript 工具如何在 2017 年发展到今天的样子。我们将从头开始，像恐龙一样构建一个示例网站 - 没有工具，只有普通的 HTML 和 JavaScript。然后，我们将逐步介绍不同的工具，以查看它们一次解决一个问题。有了这个历史背景，你将能够更好地学习和适应未来不断变化的 JavaScript 环境。让我们开始吧！\n更新：我制作了本文的视频课程版本，为了更清晰，我逐步浏览了每个部分，请在此处查看： https://firstclass.actualize.co/p/modern-javascript-explained-for-dinosaurs\n以\u0026quot;老派\u0026quot;的方式使用 JavaScript \u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;JavaScript Example\u0026lt;/title\u0026gt; ** \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; ** \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello from HTML!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 第 \u0026lt;script src=\u0026quot;index.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; 行引用同一目录中名为 index.js 的单独 JavaScript 文件：\n// index.js console.log(\u0026#34;Hello from JavaScript!\u0026#34;); 这就是制作网站所需的全部内容！现在，假设您想添加一个其他人编写的库，例如 moment.js（一个可以帮助以人类可读的方式格式化日期的库）。例如，您可以在 JavaScript 中使用 moment 函数，如下所示：\nmoment().startOf(\u0026#34;day\u0026#34;).fromNow(); // 20 hours ago 但这只是假设您在网站上包含 moment.js！在 moment.js 主页 上您会看到以下说明：\n嗯，右侧的\u0026quot;安装\u0026quot;部分有很多内容。但是现在让我们忽略它 - 我们可以通过在同一目录中下载 moment.min.js 文件并将其包含在我们的 index.html 文件中来为我们的网站添加 moment.js。\n\u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;Example\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.","title":"[译]为恐龙解释现代JavaScript"},{"content":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：尽量减少类和成员的可访问性。\n类和接口是 Java 编程语言的核心。它们是抽象的基本单位。该语言提供了许多强大的元素，你可以使用它们来设计类和接口。\n介绍 《Effective Java, Third Edition》这本书中的第四章主要讲述了如何尽量减少类和成员的可访问性，以提高代码的封装性、安全性和可维护性。\n尽量减少类和成员的可访问性是面向对象编程中的一个基本原则，也被称为 \u0026ldquo;最小化可访问性原则\u0026rdquo;。这个原则的核心思想是，将类和成员的访问级别限制在最小范围内，从而提高代码的安全性、可维护性和可复用性。\n在 Java 中，类和成员的访问级别有四种：public、protected、default 和 private。其中，public 级别是最高的，可以被任何类访问；private 级别是最低的，只能被同一个类内部的成员访问。在应用最小化可访问性原则时，应该尽可能地将类和成员的访问级别设置为最低的级别，即 private 或 default 级别。\n尽量减少类和成员的可访问性是一种良好的编程实践，可以提高代码的安全性和可维护性。以下是一些建议：\n将类和成员的可见性设置为最小化的级别，即只有必要的代码可以访问它们。这将减少不必要的依赖关系，并使代码更加模块化和可重用。\n使用访问修饰符以限制类和成员的可见性。例如，如果一个成员只能在类内部使用，可以考虑将其转换为私有静态嵌套类。如果一个成员需要在类的子类中使用，可以使用 protected 修饰符。\n下面是一个示例，演示如何将包级私有顶级类转换为私有静态嵌套类：\n// 包级私有顶级类 class MyTopLevelClass { // ... } public class MyClass { private static class MyPrivateNestedClass { // 使用 MyTopLevelClass 的代码 } // 使用 MyPrivateNestedClass 的代码 } 在上面的示例中，MyTopLevelClass 被转换为了 MyPrivateNestedClass，它被声明为 MyClass 的私有静态嵌套类。这样，MyTopLevelClass 就只能被 MyPrivateNestedClass 使用，而 MyPrivateNestedClass 只能被 MyClass 使用，达到了安全和清晰的目标。\n避免使用公共成员或公共方法。公共成员和方法可以被任何代码访问，这可能会导致安全问题和不必要的代码耦合。相反，应该使用封装的方式来隐藏类的实现细节，并在需要时提供公共接口。\n在需要使用公共接口时，使用接口或抽象类来定义公共契约。这样可以使代码更加灵活，并使实现细节能够独立于公共契约进行修改。\n使用 final 关键字来限制类和成员的可变性。这可以提高代码的安全性和可维护性，并避免在不必要的情况下修改代码。\n扩展 设计公共接口需要考虑接口的简洁性、易用性和一致性，同时避免暴露过多的底层实现细节。下面是一个简单的示例，展示了如何设计一个公共接口。\n/** * This interface provides a simple way to perform arithmetic operations. * @author chensoul * @since 1.0.0 */ public interface Arithmetic { /** * Adds two integers and returns the result. * * @param a the first integer * @param b the second integer * @return the sum of a and b */ int add(int a, int b); /** * Subtracts two integers and returns the result. * * @param a the first integer * @param b the second integer * @return the difference of a and b */ int subtract(int a, int b); /** * Multiplies two integers and returns the result. * * @param a the first integer * @param b the second integer * @return the product of a and b */ int multiply(int a, int b); /** * Divides two integers and returns the result. * * @param a the numerator * @param b the denominator * @return the quotient of a and b * @throws ArithmeticException if b is zero */ int divide(int a, int b) throws ArithmeticException; } 在上面的示例中，我们设计了一个名为 Arithmetic 的接口，它提供了四个基本的算术操作：加法、减法、乘法和除法。每个方法都有清晰的文档注释，描述了方法的用途、参数和返回值。此外，除法方法还声明了一个异常，以防止除以零的情况。\n以下是一些关于如何设计公共 API 的最佳实践：\n最小化公共 API：尽可能地减少公共 API 的规模和复杂度，只暴露必要的接口和行为。这样可以保持 API 的简单性和稳定性，避免意外的依赖和耦合。 保护不可变性：对于公共静态 final 字段引用的对象，应该确保它们是不可变的，以避免意外修改公共状态。 使用接口和抽象类：使用接口和抽象类来定义公共 API，从而使得实现类可以灵活地选择自己的实现方式。同时，接口和抽象类可以隐藏实现细节，保持 API 的简单性和稳定性。 使用枚举类型：枚举类型可以在定义一组常量时提供类型安全性，并且可以避免意外的实例化和修改。 文档化 API：提供详细的文档和示例代码，以便开发人员能够正确地使用公共 API。 当设计一个公共 API 时，文档化是非常重要的。以下是一些关于如何文档化 API 的最佳实践：\n提供 API 文档：为 API 提供详细的文档，包括 API 的使用方法、接口、参数、返回值、异常和示例代码等。API 文档应该清晰、简单、易于理解，并且应该提供足够的上下文和解释。 为 API 提供示例代码：为 API 提供详细的示例代码，以便开发人员能够快速地理解和使用 API。示例代码应该清晰、简单、易于理解，并且应该提供足够的注释和解释。 使用标准注释：使用标准注释格式，例如 Javadoc 或者 Doxygen，以便生成 API 文档。标准注释格式可以提高文档的一致性和可读性，并且可以使用自动化工具来生成 API 文档。 为 API 提供版本号：为 API 提供版本号，以便开发人员可以跟踪 API 的演变和变化。版本号应该清晰、简单、易于理解，并且应该遵循一定的命名规则。 提供 API 更新日志：为 API 提供更新日志，以便开发人员可以了解 API 的变化和演变。更新日志应该清晰、简单、易于理解，并且应该提供足够的上下文和解释。 避免使用过时的 API：避免使用过时的 API，以避免出现不必要的问题和错误。如果必须使用过时的 API，应该提供警告和替代方案，以便开发人员能够了解风险和替代方案。 以下是一个使用 Javadoc 注释格式为 Java 类和方法文档化的示例代码：\n/** * The BasicArithmetic class provides a basic implementation of the Arithmetic interface. * This implementation is not recommended for use in production code, and will be removed in a future release. * * @deprecated This class is for demonstration purposes only. * Use {@link AdvancedArithmetic} for more advanced arithmetic operations. * For basic arithmetic operations, use the {@link java.lang.Math} class instead. * @see Arithmetic * @see AdvancedArithmetic * @see java.lang.Math * @since 1.0.0 */ @Deprecated public class BasicArithmetic implements Arithmetic { /** * {@inheritDoc} * * @param a the first integer to be added * @param b the second integer to be added * @return the sum of a and b */ @Override public int add(int a, int b) { return a + b; } /** * {@inheritDoc} * * @param a the integer to be subtracted from * @param b the integer to subtract * @return the difference of a and b */ @Override public int subtract(int a, int b) { return a - b; } /** * {@inheritDoc} * * @param a the first integer to be multiplied * @param b the second integer to be multiplied * @return the product of a and b */ @Override public int multiply(int a, int b) { return a * b; } /** * {@inheritDoc} * * @param a the numerator to be divided * @param b the denominator to divide by * @return the quotient of a and b * @throws ArithmeticException if b is zero */ @Override public int divide(int a, int b) throws ArithmeticException { if (b == 0) { throw new ArithmeticException(\u0026#34;Cannot divide by zero.\u0026#34;); } return a / b; } } 在上面的示例中，我们添加了@autho、@since、@see、@link 、@deprecated 和 @inheritDoc 标记。\n@author 标记指定了类的作者，可以是单个人或组织。\n@since 标记指定了类最初被引入的版本。\n@see 标记提供了一个链接到其他相关的类或接口。\n@link 标记提供了一个链接到其他相关的类、方法、字段或包。\n@deprecated 标记指示该类或方法已过时，不推荐使用，并会在将来的版本中被删除。\n@inheritDoc 继承父类的 Javadoc 注释。但是需要注意的是，@inheritDoc 标记不能继承任何其他的注释信息，如参数、返回值或异常。如果子类方法有自己的参数、返回值或异常，则需要在子类方法中添加对应的 Javadoc 注释。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/15/minimize-the-accessibility-of-classes-and-members/","summary":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：尽量减少类和成员的可访问性。\n类和接口是 Java 编程语言的核心。它们是抽象的基本单位。该语言提供了许多强大的元素，你可以使用它们来设计类和接口。\n介绍 《Effective Java, Third Edition》这本书中的第四章主要讲述了如何尽量减少类和成员的可访问性，以提高代码的封装性、安全性和可维护性。\n尽量减少类和成员的可访问性是面向对象编程中的一个基本原则，也被称为 \u0026ldquo;最小化可访问性原则\u0026rdquo;。这个原则的核心思想是，将类和成员的访问级别限制在最小范围内，从而提高代码的安全性、可维护性和可复用性。\n在 Java 中，类和成员的访问级别有四种：public、protected、default 和 private。其中，public 级别是最高的，可以被任何类访问；private 级别是最低的，只能被同一个类内部的成员访问。在应用最小化可访问性原则时，应该尽可能地将类和成员的访问级别设置为最低的级别，即 private 或 default 级别。\n尽量减少类和成员的可访问性是一种良好的编程实践，可以提高代码的安全性和可维护性。以下是一些建议：\n将类和成员的可见性设置为最小化的级别，即只有必要的代码可以访问它们。这将减少不必要的依赖关系，并使代码更加模块化和可重用。\n使用访问修饰符以限制类和成员的可见性。例如，如果一个成员只能在类内部使用，可以考虑将其转换为私有静态嵌套类。如果一个成员需要在类的子类中使用，可以使用 protected 修饰符。\n下面是一个示例，演示如何将包级私有顶级类转换为私有静态嵌套类：\n// 包级私有顶级类 class MyTopLevelClass { // ... } public class MyClass { private static class MyPrivateNestedClass { // 使用 MyTopLevelClass 的代码 } // 使用 MyPrivateNestedClass 的代码 } 在上面的示例中，MyTopLevelClass 被转换为了 MyPrivateNestedClass，它被声明为 MyClass 的私有静态嵌套类。这样，MyTopLevelClass 就只能被 MyPrivateNestedClass 使用，而 MyPrivateNestedClass 只能被 MyClass 使用，达到了安全和清晰的目标。\n避免使用公共成员或公共方法。公共成员和方法可以被任何代码访问，这可能会导致安全问题和不必要的代码耦合。相反，应该使用封装的方式来隐藏类的实现细节，并在需要时提供公共接口。\n在需要使用公共接口时，使用接口或抽象类来定义公共契约。这样可以使代码更加灵活，并使实现细节能够独立于公共契约进行修改。\n使用 final 关键字来限制类和成员的可变性。这可以提高代码的安全性和可维护性，并避免在不必要的情况下修改代码。\n扩展 设计公共接口需要考虑接口的简洁性、易用性和一致性，同时避免暴露过多的底层实现细节。下面是一个简单的示例，展示了如何设计一个公共接口。\n/** * This interface provides a simple way to perform arithmetic operations. * @author chensoul * @since 1.0.0 */ public interface Arithmetic { /** * Adds two integers and returns the result.","title":"《Effective Java 3》笔记15：尽量减少类和成员的可访问性"},{"content":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：在公共类中，使用访问器方法，而不是公共字段。\n介绍 与其直接将类的内部字段公开为公共字段，推荐使用访问器方法（也称为 getter 和 setter）来访问和修改对象的状态。这样可以使类对其内部表示保持控制，并为类的客户端提供一种抽象程度。\n通过使用访问器方法，您可以实现以下目标：\n封装内部表示（Encapsulate Internal Representation）： Getter 方法：Getter 方法用于获取私有字段的值。通过使用 getter 方法，可以将字段的访问限制在类的内部，从而隐藏了字段的具体实现细节。客户端只能通过调用 getter 方法来获取字段的值，而无法直接访问字段本身。 Setter 方法：Setter 方法用于设置私有字段的值。使用 setter 方法，可以对字段进行验证、约束和逻辑处理。这样，类可以对字段的修改进行控制，并确保只有经过验证的值才能被设置。 控制访问和修改（Control Access and Modification）： Getter 方法：通过 getter 方法，可以对字段的访问进行控制。例如，可以在 getter 方法中添加权限检查，只允许特定的用户或角色获取字段的值。还可以在 getter 方法中进行计算或转换，以便返回不同于字段本身的值。 Setter 方法：Setter 方法允许对字段的修改进行控制。在 setter 方法中，可以进行输入验证、范围检查和其他逻辑处理。这样可以确保只有符合规定的值才能被设置到字段中，从而保持类的状态的一致性和完整性。 促进演化和兼容性：如果使用公共字段，并且以后需要更改表示方式或添加附加逻辑，则很难保持向后兼容性。然而，通过使用访问器方法，可以修改内部表示或添加新行为，而不会影响类的客户端。 反例 Java 库中的几个类违反了公共类不应该直接公开字段的建议。突出的例子包括 java.awt 包中的 Point 和 Dimension。\n在 Java 的早期版本中，一些类设计并没有遵循现代的面向对象设计原则和最佳实践。这些类中的字段被直接声明为公共（public），而没有提供相应的访问器方法。\n例如，java.awt 包中的 Point 类和 Dimension 类提供了公共的 x、y 和 width、height 字段来表示点的坐标和矩形的宽度和高度。这意味着客户端代码可以直接访问和修改这些字段，绕过了封装和控制的机制。\n这种设计方式存在一些问题：\n缺乏封装：直接公开字段破坏了封装的原则，使得类的内部表示暴露给外部，导致了不可预测的行为和潜在的错误。 限制扩展性：如果需要在这些类中添加验证逻辑、计算属性或实现其他行为，会面临困难，因为不能在字段被直接访问的情况下进行控制和修改。 除了 java.awt 包中的 Point 和 Dimension 类之外，还有其他一些 Java 库中的类违反了\u0026quot;公共类不应该直接公开字段\u0026quot;的建议。以下是一些例子：\njava.util 包中的 Date 类：在早期版本的 Java 中，Date 类的字段（如年、月、日、小时等）是公共的，可以直接访问和修改。这种设计导致了 Date 类的可变性和线程安全性问题。随后，Java 引入了新的日期和时间 API（java.time 包），其中封装了更好的设计原则，遵循了使用访问器方法的建议。 java.util 包中的 Vector 类：Vector 类是一个动态数组，它在早期版本中使用了公共字段来表示元素数量（elementCount）和容量（capacity）。这种设计违反了封装性和控制访问的原则。随着 Java 集合框架的发展，推荐使用 ArrayList 等更现代的集合类，它们使用私有字段并提供了相应的访问器方法。 扩展 如何确保字段的可见性限定为包级私有？ 在一些特定的情况下，对于包级私有或私有嵌套类，有时候需要公开字段，无论这个类是可变的还是不可变的。以下是这种情况的一些例子：\n不可变类的常量字段：对于不可变类（Immutable Class），其中的字段一旦被初始化就不会再改变。在这种情况下，将字段声明为公共（public）且不可变的常量是可以接受的。这样可以提供方便的访问和使用方式。例如，java.lang 包中的 String 类就有一个公共的常量字段：public static final String EMPTY = \u0026quot;\u0026quot;;。 公共常量字段：有些类可能包含一些公共的常量字段，这些字段在整个包或模块中都是可见的。这样的字段通常是不可变的，并且在设计中被视为公共的 API 的一部分。例如，java.awt 包中的 Color 类具有一些预定义的公共常量字段，如 RED、GREEN、BLUE 等。 需要注意的是，这些情况是例外而不是常规规则。在一般情况下，尽量避免直接公开字段，并使用访问器方法（getter 和 setter）来访问和修改类的状态。这样可以提供更好的封装性和控制访问的能力，同时保护类的内部表示和不变性。\n在编写和设计代码时，应该根据具体情况来判断是否需要公开字段。如果确定有必要公开字段，确保字段的可见性限定为包级私有（package-private），以限制对字段的访问范围，并遵循最小暴露原则。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/15/minimize-the-accessibility-of-classes-and-members/","summary":"本文是 《Effective Java 3》第四章《类和接口》的学习笔记：在公共类中，使用访问器方法，而不是公共字段。\n介绍 与其直接将类的内部字段公开为公共字段，推荐使用访问器方法（也称为 getter 和 setter）来访问和修改对象的状态。这样可以使类对其内部表示保持控制，并为类的客户端提供一种抽象程度。\n通过使用访问器方法，您可以实现以下目标：\n封装内部表示（Encapsulate Internal Representation）： Getter 方法：Getter 方法用于获取私有字段的值。通过使用 getter 方法，可以将字段的访问限制在类的内部，从而隐藏了字段的具体实现细节。客户端只能通过调用 getter 方法来获取字段的值，而无法直接访问字段本身。 Setter 方法：Setter 方法用于设置私有字段的值。使用 setter 方法，可以对字段进行验证、约束和逻辑处理。这样，类可以对字段的修改进行控制，并确保只有经过验证的值才能被设置。 控制访问和修改（Control Access and Modification）： Getter 方法：通过 getter 方法，可以对字段的访问进行控制。例如，可以在 getter 方法中添加权限检查，只允许特定的用户或角色获取字段的值。还可以在 getter 方法中进行计算或转换，以便返回不同于字段本身的值。 Setter 方法：Setter 方法允许对字段的修改进行控制。在 setter 方法中，可以进行输入验证、范围检查和其他逻辑处理。这样可以确保只有符合规定的值才能被设置到字段中，从而保持类的状态的一致性和完整性。 促进演化和兼容性：如果使用公共字段，并且以后需要更改表示方式或添加附加逻辑，则很难保持向后兼容性。然而，通过使用访问器方法，可以修改内部表示或添加新行为，而不会影响类的客户端。 反例 Java 库中的几个类违反了公共类不应该直接公开字段的建议。突出的例子包括 java.awt 包中的 Point 和 Dimension。\n在 Java 的早期版本中，一些类设计并没有遵循现代的面向对象设计原则和最佳实践。这些类中的字段被直接声明为公共（public），而没有提供相应的访问器方法。\n例如，java.awt 包中的 Point 类和 Dimension 类提供了公共的 x、y 和 width、height 字段来表示点的坐标和矩形的宽度和高度。这意味着客户端代码可以直接访问和修改这些字段，绕过了封装和控制的机制。\n这种设计方式存在一些问题：\n缺乏封装：直接公开字段破坏了封装的原则，使得类的内部表示暴露给外部，导致了不可预测的行为和潜在的错误。 限制扩展性：如果需要在这些类中添加验证逻辑、计算属性或实现其他行为，会面临困难，因为不能在字段被直接访问的情况下进行控制和修改。 除了 java.awt 包中的 Point 和 Dimension 类之外，还有其他一些 Java 库中的类违反了\u0026quot;公共类不应该直接公开字段\u0026quot;的建议。以下是一些例子：\njava.util 包中的 Date 类：在早期版本的 Java 中，Date 类的字段（如年、月、日、小时等）是公共的，可以直接访问和修改。这种设计导致了 Date 类的可变性和线程安全性问题。随后，Java 引入了新的日期和时间 API（java.time 包），其中封装了更好的设计原则，遵循了使用访问器方法的建议。 java.util 包中的 Vector 类：Vector 类是一个动态数组，它在早期版本中使用了公共字段来表示元素数量（elementCount）和容量（capacity）。这种设计违反了封装性和控制访问的原则。随着 Java 集合框架的发展，推荐使用 ArrayList 等更现代的集合类，它们使用私有字段并提供了相应的访问器方法。 扩展 如何确保字段的可见性限定为包级私有？ 在一些特定的情况下，对于包级私有或私有嵌套类，有时候需要公开字段，无论这个类是可变的还是不可变的。以下是这种情况的一些例子：","title":"《Effective Java 3》笔记16：在公共类中，使用访问器方法，而不是公共字段"},{"content":"前言 本篇是对 2023-06-05 到 2023-06-11 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n以后周报的主题，会包括这几个部分：读书、健身、投资、帮朋友、陪家人，再加上工作和本周分享两块内容。\n读书 本周阅读统计，总计阅读 31 分钟：\n本周阅读摘抄：\n人是周围 6 个人的平均值，如果你身边没有特别出色的年轻人与你为伍，你就找先贤们的书籍，他们把一生的所有思考、智慧、经历和情感，都倾注在那些书里头了。 如果有一天跟你共鸣的，全都是古往今来、古今中外那些最智慧、最深刻、最敏锐、最丰富、最博学的大脑，你大概率不会太差，你的精神世界也大概率会非常丰富。 “we are all in the gutter ，but some of us are looking at stars。” 这句话来自一个爱尔兰的诗人，叫做奥斯卡·王尔德：“我们都身处在阴沟里，但总有人仰望星空。” “ Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. ” 这是来自于罗素的一个演讲，叫做《我为什么而活着》，意思是：对知识的渴望，对爱情的追求，对人类苦难难以遏制的同情心，这三种简单而强烈的激情，苦苦支配我的一生 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n这周因为父亲住院需要照顾他，所以跑步暂停。\n理财 这周总计支出 5006 元，明细如下：\n6 月 11 日：4057 元，父亲出院支付 3475 元\n6 月 10 日：108 元\n6 月 9 日：86 元\n6 月 8 日：367 元\n6 月 7 日：179 元\n6 月 6 日：117 元\n6 月 5 日：92 元\n陪家人 本周的工作和生活都因为老爸住院而打乱了原来的节奏。起因是老爸因为痛风关节疼痛而服用了双氯芬酸钠缓释片导致胃溃疡和出血，另外最近两个月大便呈黑色、血液流失过多，导致严重贫血。周六先是去武汉中心医院做胃镜检查，医生看到老爸的脸色苍白，建议做个血液检测。检查结果出来之后，心有余悸，如果再晚点带老爸来医院做检查，不知道老爸会因贫血而出现怎样的事情。根据检查结果，医生建议立即住院。在经过考虑之后，决定回阳逻住院。住院期间，需要亲属陪护，于是周一到周三请了三天假，周四和周五换老婆过来照顾。\n住院期间，老爸心里烦，因为痛风发作，腿脚走路没力气，大小便不方便。作为儿子的我也在反思，老爸成这样，都怪我平时没有关心他的健康和生活。老爸今天让我吃的苦都是因为过去在老爸身上的付出不够。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成三篇博客：\nJava 设计模式：Adapter Python 学习 2：数据类型 Python 学习 3：运算符和表达式 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 Memos 中。我写了一个 Python 脚本从 Memos 读取最近一周带有 #memos 标签的记录，分享到这里。\n📌2023-06-10 如何用 ChatGPT 助力开发: 已经有 15 万人看过的经验分享#memos http://luolei.org/chatgpt-in-development/\n📌2023-06-09 Rust 语言实战，视频和教程 https://www.youtube.com/watch?v=BpPEoZW5IiY https://zh.practice.rs/why-exercise.html #memos #rust\n📌2023-06-09 基于 Spring Cloud 使用一致性哈希算法实现分布式 WebSocket. / 基于 RabbitMQ 广播实现分布式 WebSocket. https://lawrenceli.me/blog/websocket-cluster #memos #java #skill\n📌2023-06-09 REST 和 gRPC 是 API 的两种最流行的实现方法，本文详细比较它们的差异。 https://kreya.app/blog/rest-vs-grpc/ #memos\n📌2023-06-08 痛苦是对的，焦虑也是对的，痛苦的本质来源于你对现状的不满，然后焦虑的本质来源于你成长速度太慢。#memos\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/14/weekly_review_23/","summary":"前言 本篇是对 2023-06-05 到 2023-06-11 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、投资、帮朋友、陪家人。\n以后周报的主题，会包括这几个部分：读书、健身、投资、帮朋友、陪家人，再加上工作和本周分享两块内容。\n读书 本周阅读统计，总计阅读 31 分钟：\n本周阅读摘抄：\n人是周围 6 个人的平均值，如果你身边没有特别出色的年轻人与你为伍，你就找先贤们的书籍，他们把一生的所有思考、智慧、经历和情感，都倾注在那些书里头了。 如果有一天跟你共鸣的，全都是古往今来、古今中外那些最智慧、最深刻、最敏锐、最丰富、最博学的大脑，你大概率不会太差，你的精神世界也大概率会非常丰富。 “we are all in the gutter ，but some of us are looking at stars。” 这句话来自一个爱尔兰的诗人，叫做奥斯卡·王尔德：“我们都身处在阴沟里，但总有人仰望星空。” “ Three passions, simple but overwhelmingly strong, have governed my life: the longing for love, the search for knowledge, and unbearable pity for the suffering of mankind. ” 这是来自于罗素的一个演讲，叫做《我为什么而活着》，意思是：对知识的渴望，对爱情的追求，对人类苦难难以遏制的同情心，这三种简单而强烈的激情，苦苦支配我的一生 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n这周因为父亲住院需要照顾他，所以跑步暂停。\n理财 这周总计支出 5006 元，明细如下：\n6 月 11 日：4057 元，父亲出院支付 3475 元\n6 月 10 日：108 元\n6 月 9 日：86 元\n6 月 8 日：367 元\n6 月 7 日：179 元","title":"周报-23｜读书、健身、定投、帮朋友、陪家人"},{"content":"在 Python 中，流程控制语句包括条件语句（if-elif-else）、循环语句（for 和 while）、跳转语句（break、continue 和 return）和异常处理语句。\n条件语句 条件语句用于在不同的条件下执行不同的代码块。Python 中的条件语句是 if-elif-else 结构。\n# 条件语句示例 x = 10 if x \u0026lt; 0: print(\u0026#34;x is negative\u0026#34;) elif x == 0: print(\u0026#34;x is zero\u0026#34;) else: print(\u0026#34;x is positive\u0026#34;) 循环语句 循环语句用于重复执行一段代码，直到满足某个条件或达到某个条件次数为止。Python 中的循环语句包括 for 和 while 两种结构。\n# for 循环示例 my_list = [1, 2, 3, 4, 5] for item in my_list: print(item) # while 循环示例 x = 10 while x \u0026gt; 0: print(x) x -= 1 遍历集合时修改集合的内容，会很容易生成错误的结果。因此不能直接进行循环，而是应遍历该集合的副本或创建新的集合：\n# Create a sample collection users = {\u0026#39;Hans\u0026#39;: \u0026#39;active\u0026#39;, \u0026#39;Éléonore\u0026#39;: \u0026#39;inactive\u0026#39;, \u0026#39;景太郎\u0026#39;: \u0026#39;active\u0026#39;} # Strategy: Iterate over a copy for user, status in users.copy().items(): if status == \u0026#39;inactive\u0026#39;: del users[user] # Strategy: Create a new collection active_users = {} for user, status in users.items(): if status == \u0026#39;active\u0026#39;: active_users[user] = status 跳转语句 跳转语句用于在循环或函数中跳过一些代码或终止循环。Python 中的跳转语句包括 break、continue 和 return。\n# break 示例 my_list = [1, 2, 3, 4, 5] for item in my_list: if item == 3: break print(item) # continue 示例 my_list = [1, 2, 3, 4, 5] for item in my_list: if item == 3: continue print(item) # return 示例 def my_function(x): if x \u0026lt; 0: return None return x * 2 在这个示例中，我们使用 break 关键字来终止一个 for 循环，使用 continue 关键字来跳过一个循环迭代，使用 return 关键字来从函数中返回一个值。\npass 语句 pass 语句不执行任何操作。语法上需要一个语句，但程序不实际执行任何动作时，可以使用该语句。例如：\n# pass 语句 while True: pass # Busy-wait for keyboard interrupt (Ctrl+C) def function(): # to be implemented pass class MyEmptyClass: pass match 语句 match 语句接受一个表达式，并将其值与一个或多个 case 块中给定的模式进行比较。这在表面上类似于 C、Java 或 JavaScript（以及许多其他语言）中的 switch 语句，但它更类似于 Rust 或 Haskell 等语言中的模式匹配。只有第一个匹配的模式会被执行，并且它还可以从值中提取组件（序列元素或对象属性）到变量中。\n最简单的形式是将一个目标值与一个或多个字面值进行比较：\ndef http_error(status): match status: case 400: return \u0026#34;Bad request\u0026#34; case 404: return \u0026#34;Not found\u0026#34; case 418: return \u0026#34;I\u0026#39;m a teapot\u0026#34; case _: return \u0026#34;Something\u0026#39;s wrong with the internet\u0026#34; 注意最后一个代码块：“变量名” _ 被作为 通配符 并必定会匹配成功。 如果没有 case 语句匹配成功，则不会执行任何分支。\n使用 | （“ or ”）在一个模式中可以组合多个字面值：\ncase 401 | 403 | 404: return \u0026#34;Not allowed\u0026#34; 模式的形式类似解包赋值，并可被用于绑定变量：\n# point is an (x, y) tuple match point: case (0, 0): print(\u0026#34;Origin\u0026#34;) case (0, y): print(f\u0026#34;Y={y}\u0026#34;) case (x, 0): print(f\u0026#34;X={x}\u0026#34;) case (x, y): print(f\u0026#34;X={x}, Y={y}\u0026#34;) case _: raise ValueError(\u0026#34;Not a point\u0026#34;) 请仔细研究此代码！ 第一个模式有两个字面值，可以看作是上面所示字面值模式的扩展。但接下来的两个模式结合了一个字面值和一个变量，而变量 绑定 了一个来自目标的值（point）。第四个模式捕获了两个值，这使得它在概念上类似于解包赋值 (x, y) = point。\n如果使用类实现数据结构，可在类名后加一个类似于构造器的参数列表，这样做可以把属性放到变量里：\nclass Point: x: int y: int def where_is(point): match point: case Point(x=0, y=0): print(\u0026#34;Origin\u0026#34;) case Point(x=0, y=y): print(f\u0026#34;Y={y}\u0026#34;) case Point(x=x, y=0): print(f\u0026#34;X={x}\u0026#34;) case Point(): print(\u0026#34;Somewhere else\u0026#34;) case _: print(\u0026#34;Not a point\u0026#34;) 可在 dataclass 等支持属性排序的内置类中使用位置参数。还可在类中设置 __match_args__ 特殊属性为模式的属性定义指定位置。如果它被设为 (\u0026ldquo;x\u0026rdquo;, \u0026ldquo;y\u0026rdquo;)，则以下模式均为等价的，并且都把 y 属性绑定到 var 变量：\nPoint(1, var) Point(1, y=var) Point(x=1, y=var) Point(y=var, x=1) 读取模式的推荐方式是将它们看做是你会在赋值操作左侧放置的内容的扩展形式，以便理解各个变量将会被设置的值。 只有单独的名称（例如上面的 var）会被 match 语句所赋值。 带点号的名称 (例如 foo.bar)、属性名称（例如上面的 x= 和 y=）或类名称（通过其后的 \u0026ldquo;(\u0026hellip;)\u0026rdquo; 来识别，例如上面的 Point）都绝不会被赋值。\n模式可以任意地嵌套。例如，如果有一个由点组成的短列表，则可使用如下方式进行匹配：\nmatch points: case []: print(\u0026#34;No points\u0026#34;) case [Point(0, 0)]: print(\u0026#34;The origin\u0026#34;) case [Point(x, y)]: print(f\u0026#34;Single point {x}, {y}\u0026#34;) case [Point(0, y1), Point(0, y2)]: print(f\u0026#34;Two on the Y axis at {y1}, {y2}\u0026#34;) case _: print(\u0026#34;Something else\u0026#34;) 为模式添加成为守护项的 if 子句。如果守护项的值为假，则 match 继续匹配下一个 case 语句块。注意，值的捕获发生在守护项被求值之前：\nmatch point: case Point(x, y) if x == y: print(f\u0026#34;Y=X at {x}\u0026#34;) case Point(x, y): print(f\u0026#34;Not on the diagonal\u0026#34;) match 语句的其他特性：\n与解包赋值类似，元组和列表模式具有完全相同的含义，并且实际上能匹配任意序列。 但它们不能匹配迭代器或字符串。\n序列模式支持扩展解包操作：[x, y, *rest] 和 (x, y, *rest) 的作用类似于解包赋值。 在 * 之后的名称也可以为 _，因此，(x, y, *_) 可以匹配包含至少两个条目的序列，而不必绑定其余的条目。\n映射模式：{\u0026quot;bandwidth\u0026quot;: b, \u0026quot;latency\u0026quot;: l} 从字典中捕获 \u0026quot;bandwidth\u0026quot; 和 \u0026quot;latency\u0026quot; 的值。与序列模式不同，额外的键会被忽略。**rest 等解包操作也支持。但 **_ 是冗余的，不允许使用。\n使用 as 关键字可以捕获子模式：\ncase (Point(x1, y1), Point(x2, y2) as p2): ... 将把输入的第二个元素捕获为 p2 (只要输入是包含两个点的序列)\n大多数字面值是按相等性比较的，但是单例对象 True, False 和 None 则是按标识号比较的。\n模式可以使用命名常量。 这些命名常量必须为带点号的名称以防止它们被解读为捕获变量:\nfrom enum import Enum class Color(Enum): RED = \u0026#39;red\u0026#39; GREEN = \u0026#39;green\u0026#39; BLUE = \u0026#39;blue\u0026#39; color = Color(input(\u0026#34;Enter your choice of \u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39; or \u0026#39;green\u0026#39;: \u0026#34;)) match color: case Color.RED: print(\u0026#34;I see red!\u0026#34;) case Color.GREEN: print(\u0026#34;Grass is green\u0026#34;) case Color.BLUE: print(\u0026#34;I\u0026#39;m feeling the blues :(\u0026#34;) 异常处理语句 异常处理语句：用于处理程序执行过程中可能出现的异常情况，Python 中的异常处理语句包括 try、except、finally 和 raise 语句。\ntry: x = int(input(\u0026#34;Please enter a number: \u0026#34;)) y = 10 / x print(y) except ValueError: print(\u0026#34;Invalid input\u0026#34;) except ZeroDivisionError: print(\u0026#34;Cannot divide by zero\u0026#34;) else: print(\u0026#34;No exception occurred\u0026#34;) finally: print(\u0026#34;Execution completed\u0026#34;) # raise 语句 x = -1 if x \u0026lt; 0: raise ValueError(\u0026#34;x must be non-negative\u0026#34;) ","permalink":"https://blog.chensoul.cc/posts/2023/06/14/python-flow-control/","summary":"在 Python 中，流程控制语句包括条件语句（if-elif-else）、循环语句（for 和 while）、跳转语句（break、continue 和 return）和异常处理语句。\n条件语句 条件语句用于在不同的条件下执行不同的代码块。Python 中的条件语句是 if-elif-else 结构。\n# 条件语句示例 x = 10 if x \u0026lt; 0: print(\u0026#34;x is negative\u0026#34;) elif x == 0: print(\u0026#34;x is zero\u0026#34;) else: print(\u0026#34;x is positive\u0026#34;) 循环语句 循环语句用于重复执行一段代码，直到满足某个条件或达到某个条件次数为止。Python 中的循环语句包括 for 和 while 两种结构。\n# for 循环示例 my_list = [1, 2, 3, 4, 5] for item in my_list: print(item) # while 循环示例 x = 10 while x \u0026gt; 0: print(x) x -= 1 遍历集合时修改集合的内容，会很容易生成错误的结果。因此不能直接进行循环，而是应遍历该集合的副本或创建新的集合：\n# Create a sample collection users = {\u0026#39;Hans\u0026#39;: \u0026#39;active\u0026#39;, \u0026#39;Éléonore\u0026#39;: \u0026#39;inactive\u0026#39;, \u0026#39;景太郎\u0026#39;: \u0026#39;active\u0026#39;} # Strategy: Iterate over a copy for user, status in users.copy().items(): if status == \u0026#39;inactive\u0026#39;: del users[user] # Strategy: Create a new collection active_users = {} for user, status in users.","title":"Python学习4：流程控制"},{"content":"在 Python 中，运算符是用于执行各种操作的符号或关键字；表达式是由操作符、变量、常量和函数调用等组成的，它们可以被计算求值并返回一个结果。\n以下是一些常用的运算符和表达式：\n算术运算符 Python 中的算术运算符用于执行基本的算术运算，包括加、减、乘、除、取模和幂运算。以下是一些常用的算术运算符：\n+：加法运算 -：减法运算 *：乘法运算 /：除法运算 %：取模运算，返回两个数相除的余数 **：幂运算，返回一个数的指定次幂 例如：\nx + y # 加法 x - y # 减法 x * y # 乘法 x / y # 除法 x % y # 取模 在这个例子中，我们使用算术运算符执行基本的算术运算，例如将变量x和y相加、相减、相乘、相除和取模。\n比较运算符 Python 中的比较运算符用于比较两个值的大小关系，返回一个布尔值。以下是一些常用的比较运算符：\n==：等于运算符，如果两个值相等，则返回True，否则返回False !=：不等于运算符，如果两个值不相等，则返回True，否则返回False \u0026gt;：大于运算符，如果左边的值大于右边的值，则返回True，否则返回False \u0026lt;：小于运算符，如果左边的值小于右边的值，则返回True，否则返回False \u0026gt;=：大于等于运算符，如果左边的值大于等于右边的值，则返回True，否则返回False \u0026lt;=：小于等于运算符，如果左边的值小于等于右边的值，则返回True，否则返回False 例如：\nx == y # 等于 x != y # 不等于 x \u0026gt; y # 大于 x \u0026lt; y # 小于 x \u0026gt;= y # 大于等于 x \u0026lt;= y # 小于等于 在这个例子中，我们使用比较运算符比较变量x和y的大小关系，例如判断x是否等于y、是否大于y等。\n逻辑运算符 Python 中的逻辑运算符用于执行逻辑操作，包括与、或和非运算。以下是一些常用的逻辑运算符：\nand：逻辑与运算符，如果两个操作数都为True，则返回True，否则返回False or：逻辑或运算符，如果两个操作数中至少有一个为True，则返回True，否则返回False not：逻辑非运算符，如果操作数为True，则返回False，否则返回True 例如：\nx and y # 与 x or y # 或 not x # 非 在这个例子中，我们使用逻辑运算符执行逻辑运算，例如判断变量x和y是否都为True、判断变量x和y是否至少一个为True等。\n赋值运算符 Python 中的赋值运算符用于将一个值赋给一个变量。以下是一些常用的赋值运算符：\n=：简单赋值运算符，将右边的值赋给左边的变量 +=：加等于运算符，将右边的值加到左边的变量上，并将结果赋给左边的变量 -=：减等于运算符，将右边的值从左边的变量上减去，并将结果赋给左边的变量 *=：乘等于运算符，将左边的变量乘以右边的值，并将结果赋给左边的变量 /=：除等于运算符，将左边的变量除以右边的值，并将结果赋给左边的变量 %=：取模等于运算符，将左边的变量取模右边的值，并将结果赋给左边的变量 **=：幂等于运算符，将左边的变量的值的指定次幂赋给左边的变量 例如：\nx = 10 # 等于号 x += 5 # 加等于 x -= 5 # 减等于 x *= 2 # 乘等于 x /= 3 # 除等于 x %= 2 # 取模等于 在这个例子中，我们使用赋值运算符将一个值赋给变量x，以及使用加等于、减等于、乘等于、除等于和取模等于运算符对变量x进行更新。\n位运算符 Python 中的位运算符用于对整数进行位运算，包括按位与、按位或、按位异或、按位取反和左右移位运算。以下是一些常用的位运算符：\n\u0026amp;：按位与运算符，对两个操作数的每个位执行逻辑与操作，返回一个新的整数 |：按位或运算符，对两个操作数的每个位执行逻辑或操作，返回一个新的整数 ^：按位异或运算符，对两个操作数的每个位执行逻辑异或操作，返回一个新的整数 ~：按位取反运算符，对操作数的每个位执行逻辑取反操作，返回一个新的整数 \u0026lt;\u0026lt;：左移位运算符，将一个整数的所有位向左移动指定的位数，返回一个新的整数 \u0026gt;\u0026gt;：右移位运算符，将一个整数的所有位向右移动指定的位数，返回一个新的整数 例如：\nx \u0026amp; y # 按位与 x | y # 按位或 x ^ y # 按位异或 ~x # 按位取反 x \u0026lt;\u0026lt; 2 # 左移2位 x \u0026gt;\u0026gt; 2 # 右移2位 在这个例子中，我们使用位运算符对二进制数进行位操作，例如将变量x和y进行按位与、按位或、按位异或，以及对变量x进行按位取反、左移和右移。\n三元运算符 Python 中的三元运算符可以用于在一行代码中实现简单的条件语句。它的语法如下：\nvalue_if_true if condition else value_if_false 其中condition是一个布尔表达式，如果它的值为True，则返回value_if_true，否则返回value_if_false。例如：\nx = 5 y = 10 max_value = x if x \u0026gt; y else y print(max_value) # 输出：10 在这个例子中，我们使用三元运算符来比较x和y的值，并将较大的值赋给变量max_value。\n成员运算符 Python 中的成员运算符用于检查一个值是否是另一个值的成员，包括in和not in运算符。以下是一个例子：\nmy_list = [1, 2, 3, 4, 5] if 3 in my_list: print(\u0026#34;3 is in my_list\u0026#34;) 在这个例子中，我们使用in运算符来检查3是否是my_list中的成员。如果是，则打印出3 is in my_list。\n身份运算符 Python 中的身份运算符用于比较两个对象的内存地址，包括is和is not运算符。以下是一个例子：\nx = [1, 2, 3] y = [1, 2, 3] if x is y: print(\u0026#34;x and y have the same identity\u0026#34;) else: print(\u0026#34;x and y have different identities\u0026#34;) 在这个例子中，我们使用is运算符来比较x和y的内存地址。由于x和y是两个不同的列表对象，所以它们的内存地址不同，程序会打印出x and y have different identities。\n切片运算符 Python 中的切片运算符用于从序列中获取一个子序列，包括从开始位置到结束位置的切片和步长切片。以下是一个例子：\nmy_list = [1, 2, 3, 4, 5] print(my_list[1:4]) # 输出：[2, 3, 4] print(my_list[::2]) # 输出：[1, 3, 5] 在这个例子中，我们使用切片运算符从列表my_list中获取一个子序列。第一个切片my_list[1:4]返回从下标1到下标3的元素，第二个切片my_list[::2]返回每隔一个元素的子序列。\n格式化运算符 Python 中的格式化运算符用于将一个值插入到一个字符串中。它的语法如下：\n\u0026#34;format string\u0026#34; % values 其中\u0026quot;format string\u0026quot;是一个字符串，包含格式化代码，values是一个元组，包含要插入的值。例如：\nname = \u0026#34;Alice\u0026#34; age = 25 print(\u0026#34;My name is %s, and I am %d years old.\u0026#34; % (name, age)) 在这个例子中，我们使用格式化运算符将变量name和age插入到字符串中，生成一条包含变量值的消息。\n拼接运算符 Python 中的拼接运算符用于将两个字符串或序列连接起来，包括+运算符和*运算符。以下是一个例子：\nstr1 = \u0026#34;Hello\u0026#34; str2 = \u0026#34;world\u0026#34; print(str1 + \u0026#34; \u0026#34; + str2) # 输出：Hello world my_list = [1, 2, 3] print(my_list * 3) # 输出：[1, 2, 3, 1, 2, 3, 1, 2, 3] 在这个例子中，我们使用拼接运算符将两个字符串连接起来，以及将一个列表复制多次生成一个新的列表。\n解包运算符 Python 中的解包运算符包括两种：*和**。\n*解包运算符 *解包运算符用于将可迭代对象（如列表、元组、集合等）解包成单独的元素。例如：\nmy_list = [1, 2, 3, 4, 5] print(*my_list) # 输出: 1 2 3 4 5 在这个例子中，我们使用*解包运算符将my_list列表解包成一个个单独的元素，然后通过print函数输出。\n**解包运算符 **解包运算符用于将字典解包成关键字参数。例如：\nmy_dict = {\u0026#34;x\u0026#34;: 1, \u0026#34;y\u0026#34;: 2, \u0026#34;z\u0026#34;: 3} print(**my_dict) # 输出: x=1 y=2 z=3 在这个例子中，我们使用**解包运算符将my_dict字典解包成关键字参数，并通过print函数输出。\n除了上面的用法，*和**解包运算符还可以用于函数定义和调用中。例如：\ndef my_func(a, b, c): print(a, b, c) my_list = [1, 2, 3] my_func(*my_list) # 输出: 1 2 3 my_dict = {\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;: 3} my_func(**my_dict) # 输出: 1 2 3 在这个例子中，我们定义了一个函数my_func，然后使用*和**解包运算符将列表和字典中的值作为函数的参数传递进去。\n@运算符 @运算符用于执行矩阵乘法。例如：\nimport numpy as np a = np.array([[1, 2], [3, 4]]) b = np.array([[5, 6], [7, 8]]) c = a @ b # 矩阵乘法 print(c) # 输出: [[19 22] [43 50]] 在这个例子中，我们使用@运算符对两个矩阵进行乘法运算，并将结果保存在变量c中。\nlambda 表达式 Python 中的 lambda 表达式可以用于创建匿名函数。它的语法如下：\nlambda arguments : expression 其中arguments是函数的参数列表，expression是一个表达式，表示函数的返回值。例如：\nf = lambda x, y: x + y print(f(2, 3)) # 输出：5 在这个例子中，我们使用 lambda 表达式创建了一个函数f，它接受两个参数x和y，并返回它们的和。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/11/python-operator-and-expression/","summary":"在 Python 中，运算符是用于执行各种操作的符号或关键字；表达式是由操作符、变量、常量和函数调用等组成的，它们可以被计算求值并返回一个结果。\n以下是一些常用的运算符和表达式：\n算术运算符 Python 中的算术运算符用于执行基本的算术运算，包括加、减、乘、除、取模和幂运算。以下是一些常用的算术运算符：\n+：加法运算 -：减法运算 *：乘法运算 /：除法运算 %：取模运算，返回两个数相除的余数 **：幂运算，返回一个数的指定次幂 例如：\nx + y # 加法 x - y # 减法 x * y # 乘法 x / y # 除法 x % y # 取模 在这个例子中，我们使用算术运算符执行基本的算术运算，例如将变量x和y相加、相减、相乘、相除和取模。\n比较运算符 Python 中的比较运算符用于比较两个值的大小关系，返回一个布尔值。以下是一些常用的比较运算符：\n==：等于运算符，如果两个值相等，则返回True，否则返回False !=：不等于运算符，如果两个值不相等，则返回True，否则返回False \u0026gt;：大于运算符，如果左边的值大于右边的值，则返回True，否则返回False \u0026lt;：小于运算符，如果左边的值小于右边的值，则返回True，否则返回False \u0026gt;=：大于等于运算符，如果左边的值大于等于右边的值，则返回True，否则返回False \u0026lt;=：小于等于运算符，如果左边的值小于等于右边的值，则返回True，否则返回False 例如：\nx == y # 等于 x != y # 不等于 x \u0026gt; y # 大于 x \u0026lt; y # 小于 x \u0026gt;= y # 大于等于 x \u0026lt;= y # 小于等于 在这个例子中，我们使用比较运算符比较变量x和y的大小关系，例如判断x是否等于y、是否大于y等。\n逻辑运算符 Python 中的逻辑运算符用于执行逻辑操作，包括与、或和非运算。以下是一些常用的逻辑运算符：\nand：逻辑与运算符，如果两个操作数都为True，则返回True，否则返回False or：逻辑或运算符，如果两个操作数中至少有一个为True，则返回True，否则返回False not：逻辑非运算符，如果操作数为True，则返回False，否则返回True 例如：\nx and y # 与 x or y # 或 not x # 非 在这个例子中，我们使用逻辑运算符执行逻辑运算，例如判断变量x和y是否都为True、判断变量x和y是否至少一个为True等。","title":"Python学习3：运算符和表达式"},{"content":"Python 中的数据类型包括：\n数字类型：包括整型、浮点型、复数型和布尔类型：只有两个取值，True 和 False，用于表示逻辑值。 字符串类型：由一系列字符组成，可以是单引号、双引号或三引号括起来的文本。 列表类型：由一系列有序的元素组成，可以包含任何类型的数据。 元组类型：与列表类似，但是元素不能被修改。 集合类型：由一组唯一的元素组成，支持集合的基本操作，如并集、交集和差集等。 字典类型：由一组键值对组成，其中键是唯一的，用于查找和存储值。 None 类型：表示空值或缺失值。 数字 在 Python 中，数字类型包括整数（int）、浮点数（float）、复数（complex）和布尔值（bool）。\n整数（int）是不带小数的数字，可以使用十进制、二进制、八进制或十六进制表示。在 Python 3 中，整数的长度不再受限于机器的位数，可以表示任意大的整数。 例如：\na = 123 # 十进制整数 b = 0b1010 # 二进制整数，等于十进制的 10 c = 0o12 # 八进制整数，等于十进制的 10 d = 0x0A # 十六进制整数，等于十进制的 10 浮点数（float）是带小数的数字，可以使用科学计数法表示。在 Python 中，浮点数采用 IEEE 754 标准表示，具有双精度（64 位）和单精度（32 位）两种形式。例如：\na = 3.14e-2 # 科学计数法表示的浮点数，等于 0.0314 b = 1.23 # 普通的浮点数 复数（complex）是具有实部和虚部的数字，可以使用 a+bj 或 complex(a, b) 的形式表示，其中 j 表示虚数单位。例如：\na = 1+2j # 复数 b = complex(3, 4) # 复数，等于 3+4j 布尔值（bool）只有两个取值，True 和 False，用于表示真和假。在 Python 中，布尔值可以和数值进行运算，True 转换为 1，False 转换为 0。例如：\na = True b = False c = 1 + True # c 的值为 2 d = 3 * False # d 的值为 0 数字的操作和运算：\n整数除法、取模、幂运算 在 Python 中，使用 / 运算符进行除法运算得到的结果是浮点数，如果想要得到整数结果，可以使用 // 运算符进行整数除法运算。例如：\na = 7 / 2 # a 的值为 3.5 b = 7 // 2 # b 的值为 3 同时，使用 % 运算符可以进行取模运算，即计算除法的余数。例如：\nc = 7 % 2 # c 的值为 1 **是一种运算符，称为“双星号运算符”或“幂运算符”。它可以用于计算一个数的幂。\nd = 2 ** 3 # 计算2的3次方，结果为8 数字类型的转换 在 Python 中，可以使用 int()、float() 和 complex() 函数将其他类型的数据转换为整数、浮点数和复数类型。例如：\na = int(\u0026#34;123\u0026#34;) # 将字符串 \u0026#34;123\u0026#34; 转换为整数类型 b = float(\u0026#34;3.14\u0026#34;) # 将字符串 \u0026#34;3.14\u0026#34; 转换为浮点数类型 c = complex(\u0026#34;1+2j\u0026#34;) # 将字符串 \u0026#34;1+2j\u0026#34; 转换为复数类型 print(a, b, c) # 123 3.14 (1+2j) 同时，可以使用 str()、repr() 和 format() 函数将数字转换为字符串类型。例如：\na = str(123) # 将整数 123 转换为字符串类型 b = repr(3.1415926) # 将浮点数 3.1415926 转换为字符串类型，使用 repr() 函数可以保留小数点后的精度 c = \u0026#34;{:.2f}\u0026#34;.format(3.1415926) # 将浮点数 3.1415926 转换为字符串类型，保留小数点后两位 print(a, b, c) # 123 3.1415926 3.14 随机数生成 在 Python 中，可以使用 random 模块中的函数生成随机数。常用的函数包括：\nrandom.random()：生成一个 0 到 1 之间的随机浮点数。 random.randint(a, b)：生成一个在 a 和 b 之间（包括 a 和 b）的随机整数。 random.choice(seq)：从序列 seq 中随机选择一个元素并返回。 random.shuffle(seq)：将序列 seq 中的元素随机排序。 例如，可以使用 random 模块中的 randint() 函数生成一个随机整数：\nimport random a = random.randint(1, 10) # 生成一个在 1 和 10 之间的随机整数 print(a) 字符串 在 Python 中，字符串是一种不可变序列类型 ，用于表示文本数据。字符串是由一系列 Unicode 字符组成的，可以包含任何字符，包括字母、数字、标点符号、空格等。\n定义字符串可以使用 单引号、双引号或三引号。例如：\nstr1 = \u0026#39;Hello, world!\u0026#39; str2 = \u0026#34;Hello, Python!\u0026#34; str3 = \u0026#34;\u0026#34;\u0026#34;This is a long string that spans multiple lines.\u0026#34;\u0026#34;\u0026#34; 字符串支持一些常用的操作，例如：\n拼接字符串：使用加号（+）运算符\nstr4 = str1 + \u0026#39; \u0026#39; + str2 # str4 = \u0026#39;Hello, world! Hello, Python!\u0026#39; 访问字符串中的字符：使用 下标（索引）运算符或切片运算符\nch = str1[0] # ch = \u0026#39;H\u0026#39; substr = str2[7:13] # substr = \u0026#39;Python\u0026#39; 获取字符串的长度：使用 len() 函数\nlength = len(str3) # length = 45 查找子字符串：使用 find() 或 index() 函数\npos1 = str1.find(\u0026#39;world\u0026#39;) # pos1 = 7 pos2 = str2.index(\u0026#39;Python\u0026#39;) # pos2 = 7 替换子字符串：使用 replace() 函数\nnew_str = str1.replace(\u0026#39;world\u0026#39;, \u0026#39;Python\u0026#39;) # new_str = \u0026#39;Hello, Python!\u0026#39; 分割字符串：使用 split() 函数\nwords = str3.split() # words = [\u0026#39;This\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;long\u0026#39;, \u0026#39;string\u0026#39;, \u0026#39;that\u0026#39;, \u0026#39;spans\u0026#39;, \u0026#39;multiple\u0026#39;, \u0026#39;lines.\u0026#39;] 连接字符串列表：使用 join() 函数\nnew_str = \u0026#39;-\u0026#39;.join(words) # new_str = \u0026#39;This-is-a-long-string-that-spans-multiple-lines.\u0026#39; 判断字符串是否包含某个子字符串：使用 in 或 not in 运算符\nflag1 = \u0026#39;world\u0026#39; in str1 # flag1 = True flag2 = \u0026#39;Python\u0026#39; not in str2 # flag2 = False 判断字符串是否以某个子字符串开头或结尾：使用 startswith() 和 endswith() 方法\nflag3 = str1.startswith(\u0026#39;Hello\u0026#39;) # flag3 = True flag4 = str2.endswith(\u0026#39;!\u0026#39;) # flag4 = True 大小写转换：使用 upper() 和 lower() 方法\nupper_str = str1.upper() # upper_str = \u0026#39;HELLO, WORLD!\u0026#39; lower_str = str2.lower() # lower_str = \u0026#39;hello, python!\u0026#39; 去除字符串两端的空白字符：使用 strip()、lstrip() 和 rstrip() 方法\nstr5 = \u0026#39; Hello, Python! \u0026#39; new_str1 = str5.strip() # new_str1 = \u0026#39;Hello, Python!\u0026#39; new_str2 = str5.lstrip() # new_str2 = \u0026#39;Hello, Python! \u0026#39; new_str3 = str5.rstrip() # new_str3 = \u0026#39; Hello, Python!\u0026#39; 字符串转换为数字类型：使用 int()、float() 或 complex() 函数\nnum1 = int(\u0026#39;123\u0026#39;) # num1 = 123 num2 = float(\u0026#39;3.14\u0026#39;) # num2 = 3.14 num3 = complex(\u0026#39;1+2j\u0026#39;) # num3 = (1+2j) 判断字符串是否全部由数字组成：使用 isnumeric() 方法\nstr6 = \u0026#39;123456\u0026#39; flag5 = str6.isnumeric() # flag5 = True 判断字符串是否全部由字母组成：使用 isalpha() 方法\nstr7 = \u0026#39;HelloWorld\u0026#39; flag6 = str7.isalpha() # flag6 = True 判断字符串是否全部由字母和数字组成：使用 isalnum() 方法\nstr8 = \u0026#39;Hello123\u0026#39; flag7 = str8.isalnum() # flag7 = True 计算字符串中某个字符出现的次数：使用 count() 方法\nstr9 = \u0026#39;Hello, Python!\u0026#39; count = str9.count(\u0026#39;o\u0026#39;) # count = 2 将字符串按指定的宽度进行对齐：使用 ljust()、rjust() 和 center() 方\nstr10 = \u0026#39;Hello\u0026#39; new_str4 = str10.ljust(10) # new_str4 = \u0026#39;Hello \u0026#39; new_str5 = str10.rjust(10) # new_str5 = \u0026#39; Hello\u0026#39; new_str6 = str10.center(10) # new_str6 = \u0026#39; Hello \u0026#39; 将字符串中的某个子字符串替换为另一个字符串：使用 translate() 方法\nstr11 = \u0026#39;Hello, Python!\u0026#39; table = str.maketrans(\u0026#39;lo\u0026#39;, \u0026#39;12\u0026#39;) new_str7 = str11.translate(table) # new_str7 = \u0026#39;He22, Pyth2n!\u0026#39; 这段代码使用了字符串的 translate() 方法，用于将字符串中的某个子字符串替换为另一个字符串。具体来说，它的作用是将字符串 str11 中的所有字符 \u0026rsquo;l\u0026rsquo; 替换为 \u0026lsquo;1\u0026rsquo;，将所有字符 \u0026lsquo;o\u0026rsquo; 替换为 \u0026lsquo;2\u0026rsquo;，生成一个新的字符串 new_str7。\n这里用到了 str.maketrans() 方法，它用于生成一个转换表，将字符串中的某些字符转换为其他字符。这个方法接受两个参数，两个参数都是字符串，第一个参数是需要被替换的字符，第二个参数是替换为的字符。生成的转换表可以用于字符串的 translate() 方法。\n具体来说，这里的代码使用 str.maketrans(\u0026rsquo;lo\u0026rsquo;, \u0026lsquo;12\u0026rsquo;) 生成了一个转换表，将字符 \u0026rsquo;l\u0026rsquo; 转换为 \u0026lsquo;1\u0026rsquo;，将字符 \u0026lsquo;o\u0026rsquo; 转换为 \u0026lsquo;2\u0026rsquo;。然后使用 translate() 方法将字符串 str11 中的字符按照转换表进行替换，生成了一个新的字符串 new_str7，它的值为 \u0026lsquo;He22, Pyth2n!\u0026rsquo;。\n需要注意的是，这种字符串的替换方式只是按照字符进行替换，不是按照子字符串进行替换。如果需要按照子字符串进行替换，可以使用字符串的 replace() 方法。\n将字符串从左侧或右侧填充指定的字符：使用 lstrip() 和 rstrip() 方法\nstr12 = \u0026#39;Hello\u0026#39; new_str8 = str12.lstrip(\u0026#39;H\u0026#39;) # new_str8 = \u0026#39;ello\u0026#39; new_str9 = str12.rstrip(\u0026#39;o\u0026#39;) # new_str9 = \u0026#39;Hell\u0026#39; Python 中字符串的知识点还有很多，包括但不限于：\n格式化字符串：Python 3.6 以后的版本支持 f-string，可以在字符串中直接使用表达式和变量，非常方便。例如：\nname = \u0026#39;John\u0026#39; age = 25 greeting = f\u0026#39;My name is {name}, and I am {age} years old.\u0026#39; # greeting = \u0026#39;My name is John, and I am 25 years old.\u0026#39; 字符串的格式化输出：Python 中的 format() 方法可以对字符串进行格式化输出，支持各种格式控制符和占位符。例如：\npi = 3.141592653589793 print(\u0026#39;pi = {:.2f}\u0026#39;.format(pi)) # 输出 \u0026#39;pi = 3.14\u0026#39; 正则表达式：Python 中内置了 re 模块，可以使用正则表达式进行字符串匹配和替换操作，非常强大。例如：\nimport re str13 = \u0026#39;Hello, world!\u0026#39; pattern = r\u0026#39;w\\w+\u0026#39; match = re.search(pattern, str13) if match: print(match.group()) # 输出 \u0026#39;world\u0026#39; 字符串的编码和解码：Python 中的字符串是 Unicode 字符串，可以使用 encode() 方法将字符串编码成字节串，使用 decode() 方法将字节串解码成字符串。例如：\nstr14 = \u0026#39;你好，世界！\u0026#39; utf8_bytes = str14.encode(\u0026#39;utf-8\u0026#39;) gb2312_bytes = str14.encode(\u0026#39;gb2312\u0026#39;) utf8_str = utf8_bytes.decode(\u0026#39;utf-8\u0026#39;) gb2312_str = gb2312_bytes.decode(\u0026#39;gb2312\u0026#39;) 字符串的比较和排序：Python 中的字符串可以进行比较和排序操作，使用的是按照 Unicode 码点进行比较和排序的规则。例如：\nstr_list = [\u0026#39;world\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;java\u0026#39;] str_list.sort() print(str_list) # 输出 [\u0026#39;Python\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;java\u0026#39;, \u0026#39;world\u0026#39;] # 对列表进行降序排序 str_list.sort(reverse=True) print(str_list) # 输出 [\u0026#39;world\u0026#39;, \u0026#39;java\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;Python\u0026#39;] 这段代码用于对一个字符串列表进行排序，它使用了列表的 sort() 方法，将列表中的元素按照一定的规则进行排序。具体来说，它的作用是将字符串列表 str_list 按照字典序进行升序排序，生成一个新的排序后的列表。\n在 Python 中，字符串是可以进行比较操作的，比较的规则是按照 Unicode 码点进行比较。因此，对于字符串列表的排序，实际上就是按照字符串的字典序进行排序。具体来说，对于两个字符串 s1 和 s2，按照字典序进行比较的规则是：\n如果 s1 在 s2 的前面，则 s1 \u0026lt; s2； 如果 s1 在 s2 的后面，则 s1 \u0026gt; s2； 如果 s1 和 s2 相等，则 s1 == s2。 因此，对于这段代码中的字符串列表 str_list，它的排序结果为 [\u0026lsquo;Python\u0026rsquo;, \u0026lsquo;hello\u0026rsquo;, \u0026lsquo;java\u0026rsquo;, \u0026lsquo;world\u0026rsquo;]，其中 \u0026lsquo;Python\u0026rsquo; 在字典序中排在最前面，\u0026lsquo;world\u0026rsquo; 在字典序中排在最后面。\n需要注意的是，列表的 sort() 方法会直接修改原有的列表，如果不想修改原有列表，可以使用 sorted() 函数。例如：\nstr_list = [\u0026#39;world\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;java\u0026#39;] new_str_list = sorted(str_list) print(new_str_list) # 输出 [\u0026#39;Python\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;java\u0026#39;, \u0026#39;world\u0026#39;] # 对列表生成器进行降序排序 new_str_list = sorted(str_list, reverse=True) print(new_str_list) # 输出 [\u0026#39;world\u0026#39;, \u0026#39;java\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;Python\u0026#39;] 这样做可以生成一个新的排序后的列表，不会修改原有的列表。\n需要注意的是，由于字符串是不可变的，因此对字符串进行修改会创建一个新的字符串对象。\n列表 在 Python 中，列表（list）是一种可变序列类型，用于存储一组有序的元素。列表中的元素可以是任意类型的数据，包括数字、字符串、布尔值、列表、元组、字典等。列表使用方括号 [] 表示，元素之间使用逗号分隔。例如：\nmy_list = [1, 2, \u0026#34;hello\u0026#34;, True, [3, 4, 5], {\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 20}] 列表中的元素可以通过索引（下标）进行访问和修改。列表的索引从 0 开始，可以使用正整数和负整数来表示。正整数表示从左往右数的索引，负整数表示从右往左数的索引，例如：\nmy_list = [1, 2, 3, 4, 5] print(my_list[0]) # 输出 1，第一个元素的索引为 0 print(my_list[-1]) # 输出 5，最后一个元素的索引为 -1 可以使用切片运算符 : 来获取列表的子列表。切片运算符表示从起始索引到终止索引之间的所有元素，不包括终止索引对应的元素。例如：\nmy_list = [1, 2, 3, 4, 5] print(my_list[1:3]) # 输出 [2, 3] print(my_list[:3]) # 输出 [1, 2, 3] print(my_list[3:]) # 输出 [4, 5] 列表是一种可变类型，可以通过索引和切片操作来修改列表中的元素。此外，还可以使用列表的方法来添加、删除和修改元素。常用的列表方法包括：\nappend(x)：在列表末尾添加元素 x。 insert(i, x)：在列表的第 i 个位置插入元素 x。 extend(iterable)：在列表末尾添加可迭代对象 iterable 中的所有元素。 remove(x)：删除列表中第一个值为 x 的元素。 pop([i])：删除列表中索引为 i 的元素，并返回该元素的值。如果省略 i，则默认删除最后一个元素。 clear()：删除列表中的所有元素。 index(x)：返回列表中第一个值为 x 的元素的索引。如果列表中不存在值为 x 的元素，则抛出 ValueError 异常。 count(x)：返回列表中值为 x 的元素的个数。 sort()：对列表中的元素进行排序。默认按照升序排列，可以使用 reverse=True 参数进行降序排列。 reverse()：将列表中的元素反转。 例如，可以使用 append() 方法向列表中添加元素：\nmy_list = [1, 2, 3] my_list.append(4) print(my_list) # 输出 [1, 2, 3, 4] 需要注意的是，列表是一种可变类型，修改一个列表会影响到所有引用该列表的变量。如果需要复制一个列表并独立使用，可以使用 copy() 方法或切片运算符进行复制。例如：\nmy_list = [1, 2, 3] new_list = my_list.copy() # 复制一个新的列表 new_list.append(4) print(my_list) # 输出 [1, 2, 3] print(new_list) # 输出 [1, 2, 3, 4] 除了上面提到的基本操作和常用方法，Python 列表还有一些其他的特性和用法，如下：\n列表推导式 列表推导式（list comprehension）是一种快速创建列表的方式。列表推导式由一对方括号和一个表达式构成，表达式可以包含一个或多个循环和条件语句。例如，下面的列表推导式生成了一个包含 1 到 10 的平方值的列表：\nsquares = [x ** 2 for x in range(1, 11)] print(squares) # 输出 [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] zip() 函数 zip() 函数用于将多个列表中对应位置的元素合并成元组。zip() 函数返回一个 zip 对象，可以使用 tuple() 函数将其转换为元组列表。例如：\nnames = [\u0026#34;Alice\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Charlie\u0026#34;] ages = [20, 25, 30] zipped = zip(names, ages) print(list(zipped)) # 输出 [(\u0026#39;Alice\u0026#39;, 20), (\u0026#39;Bob\u0026#39;, 25), (\u0026#39;Charlie\u0026#39;, 30)] 列表的复制和浅拷贝 当使用赋值语句将一个列表赋值给另一个变量时，实际上是将该列表的引用赋值给了新变量，两个变量指向同一个列表对象。如果修改其中一个变量对应的列表，另一个变量也会受到影响。例如：\na = [1, 2, 3] b = a b.append(4) print(a) # 输出 [1, 2, 3, 4] print(b) # 输出 [1, 2, 3, 4] 为了避免这种情况，可以使用 copy() 方法或切片运算符进行复制。但是需要注意的是，这种复制方式只是进行了浅拷贝，即只复制了列表中的元素的引用，而不是元素本身。如果列表中的元素是可变对象（如列表、字典等），修改其中一个元素的值会影响到所有引用该元素的变量。例如：\na = [[1, 2], [3, 4]] b = a.copy() b[0].append(3) print(a) # 输出 [[1, 2, 3], [3, 4]] print(b) # 输出 [[1, 2, 3], [3, 4]] 可以看到，修改 b 中的第一个元素也影响到了 a 中的元素。如果需要完全独立的复制一个列表，需要使用深拷贝（deep copy）方式，可以使用 copy 模块中的 deepcopy() 函数。例如：\nimport copy a = [[1, 2], [3, 4]] b = copy.deepcopy(a) b[0].append(3) print(a) # 输出 [[1, 2], [3, 4]] print(b) # 输出 [[1, 2, 3], [3, 4]] 列表解包 列表解包（list unpacking）是一种快速将列表中的元素分别赋值给多个变量的方式。列表解包使用一对方括号和多个变量名构成，变量名之间使用逗号分隔。例如：\nmy_list = [1, 2, 3] a, b, c = my_list print(a, b, c) # 输出 1 2 3 列表的判断和比较 可以使用 in 和 not in 运算符判断一个元素是否在列表中，可以使用 == 和 != 运算符比较两个列表是否相等。例如：\nmy_list = [1, 2, 3] print(2 in my_list) # 输出 True print(4 not in my_list) # 输出 True other_list = [1, 2, 3] print(my_list == other_list) # 输出 True print(my_list is other_list) # 输出 False，两个列表不是同一个对象 需要注意的是，列表的比较是按照元素的顺序和值进行的，如果两个列表包含相同的元素但顺序不同，则它们不相等。例如：\na = [1, 2, 3] b = [3, 2, 1] print(a == b) # 输出 False 列表的迭代和生成器 可以使用 for 循环对列表进行迭代，也可以使用列表推导式或生成器表达式生成一个生成器（generator）。生成器是一种特殊的迭代器，可以逐个产生列表中的元素，避免一次性加载整个列表到内存中。例如：\nmy_list = [1, 2, 3, 4, 5] # 列表迭代 for x in my_list: print(x) # 生成器表达式 gen = (x ** 2 for x in my_list) for x in gen: print(x) 列表的高级排序 除了 sort() 方法之外，Python 还提供了一些高级的排序方法，如 sorted() 函数和 sort() 方法的 key 参数和 cmp 参数。sorted() 函数可以对任意可迭代对象进行排序，返回一个新的有序列表。key 参数指定一个函数，用于对每个元素进行排序，cmp 参数可以指定一个比较函数，用于比较两个元素。例如：\nmy_list = [\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;orange\u0026#34;, \u0026#34;grape\u0026#34;] # 按照字符串长度排序 sorted_list = sorted(my_list, key=len) print(sorted_list) # 输出 [\u0026#39;apple\u0026#39;, \u0026#39;grape\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;orange\u0026#39;] # 按照字母顺序排序 my_list.sort(key=str.lower) print(my_list) # 输出 [\u0026#39;apple\u0026#39;, \u0026#39;banana\u0026#39;, \u0026#39;grape\u0026#39;, \u0026#39;orange\u0026#39;] 元组 在 Python 中，元组（tuple）是一种不可变的序列类型，用于存储一组有序的对象。元组与列表类似，但元组一旦创建就不能被修改，也没有添加、删除、修改等操作的方法，因此元组更加轻量级，而且更加安全。元组使用一对圆括号和逗号分隔的对象列表构成，如下所示：\nmy_tuple = (1, 2, 3) 可以使用索引和切片运算符对元组进行访问和切片。元组支持所有的序列操作，如 len()、in、+、* 等。元组也可以包含任意类型的对象，包括其他元组。例如：\nt1 = (\u0026#34;apple\u0026#34;, 1, True) t2 = (t1, \u0026#34;banana\u0026#34;, 2.5) print(t2) # 输出 ((\u0026#39;apple\u0026#39;, 1, True), \u0026#39;banana\u0026#39;, 2.5) print(t2[0][1]) # 输出 1 元组的不可变性可以保证元组中的对象不会被修改，从而增强程序的安全性和稳定性。元组通常用于表示一些不可变的数据，如坐标、日期、时间等。元组也可以用于函数的返回值，将多个值打包成一个元组返回。例如：\ndef get_rectangle_area_and_perimeter(length, width): area = length * width perimeter = 2 * (length + width) return area, perimeter area, perimeter = get_rectangle_area_and_perimeter(10, 5) print(area, perimeter) # 输出 50 30 需要注意的是，如果元组中只有一个元素，需要在元素后面加上逗号，否则会被解释为其他类型。例如：\nmy_tuple = (1,) # 包含一个元素的元组 not_a_tuple = (1) # 一个整数，而不是元组 下面是 Python 元组的一些其他特性和用法：\n元组解包 和列表解包类似，可以使用元组解包（tuple unpacking）将元组中的元素依次赋值给多个变量，变量名之间使用逗号分隔。例如：\nmy_tuple = (1, 2, 3) a, b, c = my_tuple print(a, b, c) # 输出 1 2 3 元组的比较和排序 和列表一样，元组也支持比较运算符（==、!=、\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;=）和排序方法（sorted()、sort()）。元组的比较是按照元素的顺序和值进行的，如果两个元组包含相同的元素但顺序不同，则它们不相等。例如：\na = (1, 2, 3) b = (3, 2, 1) print(a == b) # 输出 False 元组作为不可变字典的键 由于元组是不可变的，可以用作字典的键。如果要使用列表作为字典的键，则需要先将列表转换为元组。例如：\nmy_dict = {(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;): 1, (\u0026#34;orange\u0026#34;, \u0026#34;grape\u0026#34;): 2} print(my_dict[(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;)]) # 输出 1 * 运算符 可以使用 * 运算符将多个元组合并成一个元组。例如：\nt1 = (1, 2, 3) t2 = (4, 5, 6) t3 = (*t1, *t2) print(t3) # 输出 (1, 2, 3, 4, 5, 6) 元组的生成器 和列表一样，元组也可以使用生成器表达式生成一个生成器（generator）。生成器是一种特殊的迭代器，可以逐个产生元组中的元素，避免一次性加载整个元组到内存中。例如：\nmy_tuple = (1, 2, 3, 4, 5) # 生成器表达式 gen = (x ** 2 for x in my_tuple) for x in gen: print(x) 集合 Python 中的集合类型是 set（集合）和 frozenset（不可变集合）。\nset 是一种无序、可变的集合类型，其中不允许有重复元素。可以使用大括号{}或set()函数来创建一个集合。例如：\nmy_set = {1, 2, 3} print(my_set) # 输出 {1, 2, 3} my_set = set([1, 2, 3, 2]) print(my_set) # 输出 {1, 2, 3} 可以使用 add()方法向集合中添加元素，使用remove()方法删除元素。可以使用in关键字来检查元素是否在集合中。例如：\nmy_set = {1, 2, 3} my_set.add(4) print(my_set) # 输出 {1, 2, 3, 4} my_set.remove(2) print(my_set) # 输出 {1, 3, 4} print(2 in my_set) # 输出 False 集合支持各种集合运算，如并集、交集、差集等。例如：\nset1 = {1, 2, 3} set2 = {3, 4, 5} # 并集 print(set1 | set2) # 输出 {1, 2, 3, 4, 5} # 交集 print(set1 \u0026amp; set2) # 输出 {3} # 差集 print(set1 - set2) # 输出 {1, 2} # 对称差集 print(set1 ^ set2) # 输出 {1, 2, 4, 5} frozenset 是一种不可变的集合类型，可以使用frozenset()函数来创建。frozenset 和 set 具有相似的操作，但是不支持添加、删除元素等操作。例如：\nmy_fset = frozenset([1, 2, 3]) print(my_fset) # 输出 frozenset({1, 2, 3}) 下面是 Python 中集合类型的一些其他特性和用法：\n列表、元组转换为集合 可以使用set()函数将列表或元组转换为集合。集合会自动去除重复元素。例如：\nmy_list = [1, 2, 2, 3, 3, 3] my_set = set(my_list) print(my_set) # 输出 {1, 2, 3} my_tuple = (4, 5, 5, 6, 6, 6) my_set = set(my_tuple) print(my_set) # 输出 {4, 5, 6} 集合的长度 可以使用len()函数获取集合的长度（即集合中元素的个数）。例如：\nmy_set = {1, 2, 3} print(len(my_set)) # 输出 3 集合的迭代 可以使用for循环迭代集合中的元素。由于集合是无序的，每次迭代的顺序可能不同。例如：\nmy_set = {1, 2, 3} for x in my_set: print(x) 集合解析 和列表解析类似，可以使用集合解析（set comprehension）快速生成一个集合。例如：\nmy_set = {x for x in range(1, 6)} print(my_set) # 输出 {1, 2, 3, 4, 5} frozenset 作为字典键 由于frozenset是不可变的，可以作为字典的键。例如：\nmy_dict = {frozenset({1, 2}): \u0026#34;A\u0026#34;, frozenset({3, 4}): \u0026#34;B\u0026#34;} print(my_dict[frozenset({1, 2})]) # 输出 \u0026#34;A\u0026#34; 集合的类型 可以使用type()函数查看集合的类型，也可以使用isinstance()函数判断集合是否属于某种类型。例如：\nmy_set = {1, 2, 3} print(type(my_set)) # 输出 \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; print(isinstance(my_set, set)) # 输出 True 集合的复制 集合可以使用copy()方法进行复制。复制后的集合和原集合具有不同的内存地址，互不影响。例如：\nmy_set = {1, 2, 3} new_set = my_set.copy() print(new_set) # 输出 {1, 2, 3} new_set.add(4) print(new_set) # 输出 {1, 2, 3, 4} print(my_set) # 输出 {1, 2, 3} 集合的更新 可以使用update()方法将一个集合的元素添加到另一个集合中。例如：\nset1 = {1, 2, 3} set2 = {3, 4, 5} set1.update(set2) print(set1) # 输出 {1, 2, 3, 4, 5} 集合的删除 可以使用discard()方法或remove()方法来删除集合中的元素。如果要删除的元素不存在，discard()方法不会报错，而remove()方法会抛出 KeyError 异常。例如：\nmy_set = {1, 2, 3} my_set.discard(2) print(my_set) # 输出 {1, 3} my_set.remove(3) print(my_set) # 输出 {1} my_set.discard(3) # 不会报错 my_set.remove(3) # 抛出KeyError异常 集合的清空 可以使用clear()方法清空集合中的所有元素。例如：\nmy_set = {1, 2, 3} my_set.clear() print(my_set) # 输出 set() 字典 在 Python 中，字典是一种可变的数据类型，用于存储键-值对。字典用大括号{}表示，每个键值对之间用逗号分隔。字典中的键必须是不可变的，如整数、字符串或元组，而值可以是任意的 Python 对象。\n下面是一个简单的字典示例：\nmy_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} 在上面的例子中，键\u0026rsquo;name\u0026rsquo;、\u0026lsquo;age\u0026rsquo;和\u0026rsquo;city\u0026rsquo;分别与值\u0026rsquo;John\u0026rsquo;、30 和\u0026rsquo;New York\u0026rsquo;相关联。可以使用键来访问字典中的值，例如：\nprint(my_dict[\u0026#39;name\u0026#39;]) # 输出：John print(my_dict[\u0026#39;age\u0026#39;]) # 输出：30 您还可以使用dict()函数从其他序列或映射创建字典，如下所示：\nmy_dict2 = dict([(\u0026#39;name\u0026#39;, \u0026#39;Mary\u0026#39;), (\u0026#39;age\u0026#39;, 25), (\u0026#39;city\u0026#39;, \u0026#39;Los Angeles\u0026#39;)]) print(my_dict2) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;age\u0026#39;: 25, \u0026#39;city\u0026#39;: \u0026#39;Los Angeles\u0026#39;} 字典支持许多有用的方法，如keys()、values()和items()，这些方法返回字典的键、值和键-值对的视图。字典的视图可用于按照特定的顺序访问字典中的元素，或对字典进行迭代操作。例如：\n# 获取字典的键列表 print(list(my_dict.keys())) # 输出：[\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;city\u0026#39;] # 获取字典的值列表 print(list(my_dict.values())) # 输出：[\u0026#39;John\u0026#39;, 30, \u0026#39;New York\u0026#39;] # 获取字典的键-值对列表 print(list(my_dict.items())) # 输出：[(\u0026#39;name\u0026#39;, \u0026#39;John\u0026#39;), (\u0026#39;age\u0026#39;, 30), (\u0026#39;city\u0026#39;, \u0026#39;New York\u0026#39;)] # 使用for循环迭代字典的键和值 for key, value in my_dict.items(): print(key, value) 以下是一些进阶的字典操作：\n向字典中添加或更新键值对 可以使用[key]索引或update()方法向字典中添加或更新键值对。例如：\n# 添加新的键值对 my_dict[\u0026#39;gender\u0026#39;] = \u0026#39;male\u0026#39; print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;} # 更新现有的键值对 my_dict[\u0026#39;age\u0026#39;] = 40 print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 40, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;} 可以使用update()方法将一个字典合并到另一个字典中。如果键相同，则后一个字典的值将覆盖前一个字典的值。例如：\nmy_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} my_dict2 = {\u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;USA\u0026#39;} my_dict.update(my_dict2) print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;USA\u0026#39;} 删除字典中的键值对 可以使用del语句或pop()方法从字典中删除键值对。例如：\n# 使用del删除键值对 del my_dict[\u0026#39;gender\u0026#39;] print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 40, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} # 使用pop删除键值对 my_dict.pop(\u0026#39;age\u0026#39;) print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} 使用items()方法遍历字典的键值对 可以使用items()方法遍历字典的键值对。例如：\nmy_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} for key, value in my_dict.items(): print(f\u0026#34;{key}: {value}\u0026#34;) 在这个例子中，items()方法返回一个由键值对组成的元组，然后使用for循环遍历这个元组并打印出每个键值对。\n使用字典推导式创建字典 可以使用字典推导式从其他序列或字典创建新的字典。例如：\n# 从列表创建字典 my_list = [(\u0026#39;name\u0026#39;, \u0026#39;John\u0026#39;), (\u0026#39;age\u0026#39;, 30), (\u0026#39;city\u0026#39;, \u0026#39;New York\u0026#39;)] my_dict = {key: value for key, value in my_list} print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} # 从另一个字典创建字典 my_dict2 = {\u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;USA\u0026#39;} my_dict3 = {**my_dict, **my_dict2} print(my_dict3) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;, \u0026#39;country\u0026#39;: \u0026#39;USA\u0026#39;} 使用defaultdict创建默认值字典 defaultdict是一个字典子类，它允许您指定一个默认值，以便在访问不存在的键时返回该值。例如：\nfrom collections import defaultdict my_dict = defaultdict(int) # 默认值为0 my_dict[\u0026#39;age\u0026#39;] += 1 print(my_dict) # 输出：{\u0026#39;age\u0026#39;: 1} my_dict2 = defaultdict(list) # 默认值为[] my_dict2[\u0026#39;names\u0026#39;].append(\u0026#39;John\u0026#39;) print(my_dict2) # 输出：{\u0026#39;names\u0026#39;: [\u0026#39;John\u0026#39;]} 使用sorted()函数按照键或值排序字典 可以使用sorted()函数按照字典的键或值对字典进行排序。例如：\n# 按照键排序字典 my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} sorted_dict = dict(sorted(my_dict.items(), key=lambda x: x[0])) print(sorted_dict) # 输出：{\u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;} # 按照值排序字典 my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} sorted_dict = dict(sorted(my_dict.items(), key=lambda x: x[1])) print(sorted_dict) # 输出：{\u0026#39;age\u0026#39;: 30, \u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} 使用zip()函数将两个序列合并为字典 可以使用zip()函数将两个序列合并为一个字典。例如：\nkeys = [\u0026#39;name\u0026#39;, \u0026#39;age\u0026#39;, \u0026#39;city\u0026#39;] values = [\u0026#39;John\u0026#39;, 30, \u0026#39;New York\u0026#39;] my_dict = dict(zip(keys, values)) print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} 使用json模块将字典转换为 JSON 格式 可以使用json模块将 Python 字典转换为 JSON 格式的字符串。例如：\nimport json my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} json_str = json.dumps(my_dict) print(json_str) # 输出：{\u0026#34;name\u0026#34;: \u0026#34;John\u0026#34;, \u0026#34;age\u0026#34;: 30, \u0026#34;city\u0026#34;: \u0026#34;New York\u0026#34;} 使用pprint模块打印出漂亮的字典输出 可以使用pprint模块打印出漂亮的、易于阅读的字典输出。例如：\nfrom pprint import pprint my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} pprint(my_dict) 使用copy()方法或dict()构造函数创建字典副本 可以使用copy()方法或dict()构造函数创建字典的副本。例如：\nmy_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} my_dict_copy = my_dict.copy() # 使用copy()方法创建副本 my_dict_copy[\u0026#39;age\u0026#39;] = 40 print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} print(my_dict_copy) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 40, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} my_dict2 = dict(my_dict) # 使用dict()构造函数创建副本 my_dict2[\u0026#39;name\u0026#39;] = \u0026#39;Mary\u0026#39; print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} print(my_dict2) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;Mary\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} 使用setdefault()方法获取字典的值 可以使用setdefault()方法获取字典的值。如果键存在，则返回键的值。如果键不存在，则返回默认值并将其添加到字典中。例如：\nmy_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} name = my_dict.setdefault(\u0026#39;name\u0026#39;, \u0026#39;Unknown\u0026#39;) gender = my_dict.setdefault(\u0026#39;gender\u0026#39;, \u0026#39;male\u0026#39;) print(name) # 输出：John print(gender) # 输出：male print(my_dict) # 输出：{\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;, \u0026#39;gender\u0026#39;: \u0026#39;male\u0026#39;} 字典解包 字典解包是一种将字典转换为关键字参数的技术。字典解包使用一个或两个星号运算符（*或**）来实现。\n具体来说，当使用单个星号运算符*将一个字典解包时，它会将字典的键解包为一个可迭代对象，可以在函数调用中作为位置参数传递。例如：\ndef print_info(name, age, city): print(f\u0026#34;Name: {name}\u0026#34;) print(f\u0026#34;Age: {age}\u0026#34;) print(f\u0026#34;City: {city}\u0026#34;) my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} print_info(*my_dict) # 输出：TypeError: print_info() takes 3 positional arguments but 6 were given 在这个例子中，由于print_info()函数需要 3 个关键字参数name、age和city，而字典my_dict中有 3 个键name、age和city，因此它们被解包为一个可迭代对象('name', 'age', 'city')，然后作为位置参数传递给print_info()函数。但是，由于print_info()函数需要的是关键字参数而不是位置参数，因此出现了TypeError异常。\n为了解决这个问题，可以使用双星号运算符**将字典解包为关键字参数。例如：\ndef print_info(name, age, city): print(f\u0026#34;Name: {name}\u0026#34;) print(f\u0026#34;Age: {age}\u0026#34;) print(f\u0026#34;City: {city}\u0026#34;) my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30, \u0026#39;city\u0026#39;: \u0026#39;New York\u0026#39;} print_info(**my_dict) # 输出：Name: John Age: 30 City: New York 在这个例子中，双星号运算符**将字典my_dict解包为关键字参数name='John'、age=30和city='New York'，然后将它们作为关键字参数传递给print_info()函数，这样就能够成功地打印出字典中的值了。\n需要注意的是，只有在函数定义中明确指定了这些关键字参数时，才能使用字典解包。否则，将会引发TypeError异常。\nNone 在 Python 中，None是一个特殊的对象，表示一个空值或缺失值。None是 Python 中唯一的空值对象，用于表示没有值的情况。它是一个单例对象，也就是说，Python 中的所有None引用都指向同一个对象。\nNone类型可以用于多种情况，例如：\n表示函数没有返回值 表示变量尚未被赋值 表示一个字典中没有指定的键 表示一个类的属性尚未被赋值 以下是一些使用None的例子：\ndef print_hello(): print(\u0026#34;Hello, world!\u0026#34;) # 函数没有返回值，所以可以不写return语句 x = None if x is None: print(\u0026#34;x is not defined\u0026#34;) my_dict = {\u0026#39;name\u0026#39;: \u0026#39;John\u0026#39;, \u0026#39;age\u0026#39;: 30} city = my_dict.get(\u0026#39;city\u0026#39;) if city is None: print(\u0026#34;No city found in my_dict\u0026#34;) class Person: def __init__(self, name=None, age=None): self.name = name self.age = age p = Person(\u0026#34;John\u0026#34;) if p.age is None: print(\u0026#34;Age not specified\u0026#34;) 在这些例子中，我们可以看到None被用于表示函数没有返回值、变量尚未被赋值、一个字典中没有指定的键以及一个类的属性尚未被赋值等情况。\nPython 中None类型的一些补充说明：\nNoneType 类型 在 Python 中，None是一个特殊的对象，其类型为NoneType。可以使用type()函数来检查一个对象的类型。例如：\nx = None print(type(x)) # 输出：\u0026lt;class \u0026#39;NoneType\u0026#39;\u0026gt; 在这个例子中，type()函数返回变量x的类型，即NoneType。\n避免与其他类型混淆 在 Python 中，None类型只能与自身进行比较，不能与其他类型进行比较。如果不小心将None与其他类型混淆，可能会导致一些奇怪的行为。例如：\nx = None if x == \u0026#39;\u0026#39;: print(\u0026#34;x is an empty string\u0026#34;) 在这个例子中，由于==操作符将None与空字符串进行比较，所以程序不会打印任何内容。如果想检查一个变量是否为字符串，应该使用isinstance()函数。例如：\nx = None if isinstance(x, str): print(\u0026#34;x is a string\u0026#34;) 在这个例子中，isinstance()函数检查变量x是否为字符串类型。\n使用is not None检查变量是否存在 在 Python 中，如果想检查一个变量是否存在，应该使用is not None表达式。例如：\nx = None if x is not None: print(\u0026#34;x is defined\u0026#34;) 在这个例子中，is not None表达式检查变量x是否存在。如果存在，则打印出x is defined。这种写法比使用if x:更明确，可以避免一些潜在的问题。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/10/python-data-type/","summary":"Python 中的数据类型包括：\n数字类型：包括整型、浮点型、复数型和布尔类型：只有两个取值，True 和 False，用于表示逻辑值。 字符串类型：由一系列字符组成，可以是单引号、双引号或三引号括起来的文本。 列表类型：由一系列有序的元素组成，可以包含任何类型的数据。 元组类型：与列表类似，但是元素不能被修改。 集合类型：由一组唯一的元素组成，支持集合的基本操作，如并集、交集和差集等。 字典类型：由一组键值对组成，其中键是唯一的，用于查找和存储值。 None 类型：表示空值或缺失值。 数字 在 Python 中，数字类型包括整数（int）、浮点数（float）、复数（complex）和布尔值（bool）。\n整数（int）是不带小数的数字，可以使用十进制、二进制、八进制或十六进制表示。在 Python 3 中，整数的长度不再受限于机器的位数，可以表示任意大的整数。 例如：\na = 123 # 十进制整数 b = 0b1010 # 二进制整数，等于十进制的 10 c = 0o12 # 八进制整数，等于十进制的 10 d = 0x0A # 十六进制整数，等于十进制的 10 浮点数（float）是带小数的数字，可以使用科学计数法表示。在 Python 中，浮点数采用 IEEE 754 标准表示，具有双精度（64 位）和单精度（32 位）两种形式。例如：\na = 3.14e-2 # 科学计数法表示的浮点数，等于 0.0314 b = 1.23 # 普通的浮点数 复数（complex）是具有实部和虚部的数字，可以使用 a+bj 或 complex(a, b) 的形式表示，其中 j 表示虚数单位。例如：\na = 1+2j # 复数 b = complex(3, 4) # 复数，等于 3+4j 布尔值（bool）只有两个取值，True 和 False，用于表示真和假。在 Python 中，布尔值可以和数值进行运算，True 转换为 1，False 转换为 0。例如：\na = True b = False c = 1 + True # c 的值为 2 d = 3 * False # d 的值为 0 数字的操作和运算：","title":"Python学习2：数据类型"},{"content":"本文主要介绍 Adapter 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 将一个接口转换成另一个客户所期望的接口。适配器让那些本来因为接口不兼容的类可以合作无间。\n适配器模式(Adapter Pattern)是一种结构型设计模式，它允许将一个类的接口转换成客户端所期望的另一种接口。适配器模式通常用于连接两个不兼容的接口或类，以便它们可以协同工作。\n解释 现实世界例子\n考虑有这么一种情况，在你的存储卡中有一些照片，你想将其传到你的电脑中。为了传送数据，你需要某种能够兼容你电脑接口的适配器以便你的储存卡能连上你的电脑。在这种情况下，读卡器就是一个适配器。 另一个例子就是注明的电源适配器；三脚插头不能插在两脚插座上，需要一个电源适配器来使其能够插在两脚插座上。 还有一个例子就是翻译官，他翻译一个人对另一个人说的话。\n用直白的话来说\n适配器模式让你可以把不兼容的对象包在适配器中，以让其兼容其他类。\n维基百科中说\n在软件工程中，适配器模式是一种可以让现有类的接口把其作为其他接口来使用的设计模式。它经常用来使现有的类和其他类能够工作并且不用修改其他类的源代码。\n适配器模式由三个主要角色组成：\n目标接口(Target Interface)：客户端所期望的接口。适配器模式会创建一个实现目标接口的新类，以便客户端可以通过该接口调用它。\n适配器(Adapter)：该类实现了目标接口，并将客户端的请求转换为对适配者的调用。适配器通常会聚合一个适配者对象，以便将请求委托给它。\n适配者(Adapteree)：适配器模式的实际工作内容。适配者是客户端所期望的接口之外的类，它实现了客户端需要的功能，但其接口与客户端所期望的接口不兼容。\n编程样例(对象适配器)\n假如有一个船长他只会划船，但不会航行。\n首先我们有接口RowingBoat和FishingBoat\npublic interface RowingBoat { void row(); } @Slf4j public class FishingBoat { public void sail() { LOGGER.info(\u0026#34;The fishing boat is sailing\u0026#34;); } } 船长希望有一个RowingBoat接口的实现，这样就可以移动\npublic class Captain { private final RowingBoat rowingBoat; // default constructor and setter for rowingBoat public Captain(RowingBoat rowingBoat) { this.rowingBoat = rowingBoat; } public void row() { rowingBoat.row(); } } 现在海盗来了，我们的船长需要逃跑但是只有一个渔船可用。我们需要创建一个可以让船长使用其划船技能来操作渔船的适配器。\n@Slf4j public class FishingBoatAdapter implements RowingBoat { private final FishingBoat boat; public FishingBoatAdapter() { boat = new FishingBoat(); } @Override public void row() { boat.sail(); } } 现在 船长 可以使用FishingBoat接口来逃离海盗了。\nvar captain = new Captain(new FishingBoatAdapter()); captain.row(); 类图 优缺点 适配器模式的主要优点是，它可以将不兼容的类和接口连接起来，以便它们可以协同工作。适配器模式还可以减少代码重复，因为它可以将现有的类重用在新的上下文中。此外，适配器模式可以帮助应对不稳定的接口，因为它可以将接口变化隔离到适配器中。\n适配器模式的主要缺点是，它可能会导致系统调用链的增加，因为它需要添加额外的对象来进行转换。此外，适配器模式可能会导致性能下降，因为它需要执行额外的处理来进行转换。\n应用 适配器模式通常用于以下场景：\n将现有的类或接口与新的代码集成：适配器可以将现有的类或接口与新的代码集成，以便它们可以协同工作。 与第三方库或组件集成：适配器可以将第三方库或组件的接口与应用程序的接口进行转换，以便它们可以协同工作。 应对不稳定的接口：适配器可以将不稳定的接口封装在一个适配器中，以便将来接口变化时只需要更改适配器即可。 实现多个接口：适配器可以实现多个接口，以便一个对象可以同时被多个类使用。 在测试中使用：适配器可以在测试中模拟接口的行为，以便测试程序的各种用例。 兼容不同版本：如果应用程序需要与多个版本的同一接口进行交互，可以使用适配器模式来处理不同版本之间的差异。 重用现有代码：如果需要重用现有的代码，但其接口与所需接口不兼容，则可以使用适配器模式来重用代码。 数据库驱动程序：数据库驱动程序通常使用适配器模式，以便将数据库的不同接口转换为 Java JDBC 接口。 日志记录：日志记录库通常使用适配器模式，以便将不同的日志记录接口转换为通用的接口。 扩展现有功能：如果需要扩展现有功能，但其接口与所需接口不兼容，则可以使用适配器模式来扩展现有功能。 以下是一个使用适配器模式的日志记录库的示例：\n目标接口：定义通用的日志记录器接口。 public interface Logger { void log(String message); } 适配器：定义一个适配器类，实现目标接口，并聚合不同日志框架的对象。 public class LogAdapter implements Logger { private Log4j log; public LogAdapter(Log4j log) { this.log = log; } @Override public void log(String message) { log.trace(message); } } 适配者：定义一个 Log4j 日志框架的类。 public class Log4j { public void trace(String message) { // 使用Log4j进行日志记录 } } 现在，我们可以使用适配器来将不同的日志框架转换为通用的 Logger 接口：\nLog4j log4j = new Log4j(); Logger logger = new LogAdapter(log4j); logger.log(\u0026#34;This is a log message\u0026#34;); 在上面的示例中，适配器模式允许我们将 Log4j 框架的接口转换为通用的 Logger 接口，以便我们可以使用 Logger 接口记录日志而不必关心具体使用的日志框架。如果我们需要切换到其他日志框架，只需要创建一个新的适配器即可。\n除了适配器模式的应用场景和常见开源框架中的使用示例外，适配器还有其他一些相关的概念和技术：\n对象适配器和类适配器：适配器模式可以分为对象适配器和类适配器两种。对象适配器使用组合的方式来实现适配器模式，而类适配器使用继承的方式来实现适配器模式。 双向适配器：在一些情况下，需要将两个不兼容的接口互相适配。这种情况下，可以使用双向适配器模式来实现双向的适配。 接口适配器：当一个接口中有太多的方法，而实现该接口的类只需要其中的一部分方法时，可以使用接口适配器模式来解决这个问题。接口适配器模式将一个接口拆分成多个接口，并提供一个默认的空实现，使得实现该接口的类可以只实现自己需要的方法。 下面是一个双向适配器的示例：\n假设有两个接口，分别是 Shape 和 IRectangle，其中 Shape 表示一个形状，IRectangle 表示一个矩形。Shape 接口有两个方法 draw() 和 resize()，而 IRectangle 接口有三个方法 setOrigin(), setWidth() 和 setHeight()。\n现在，我们需要将这两个接口互相适配。我们可以定义一个双向适配器 ShapeToRectangleAdapter，它实现了这两个接口，并且可以将一个 Shape 对象适配到一个 IRectangle 对象中，也可以将一个 IRectangle 对象适配到一个 Shape 对象中。具体实现如下：\npublic interface Shape { void draw(); void resize(int width, int height); void move(int x, int y); } public interface IRectangle { void setOrigin(int x, int y); void setWidth(int width); void setHeight(int height); void paint(); void stretch(); } public class ShapeToRectangleAdapter implements Shape, IRectangle { private Shape shape; private IRectangle rectangle; public ShapeToRectangleAdapter(Shape shape) { this.shape = shape; } public ShapeToRectangleAdapter(IRectangle rectangle) { this.rectangle = rectangle; } // 将 Shape 适配到 IRectangle 中 public void setOrigin(int x, int y) { shape.move(x, y); } public void setWidth(int width) { shape.resize(width, shape.getHeight()); } public void setHeight(int height) { shape.resize(shape.getWidth(), height); } // 将 IRectangle 适配到 Shape 中 public void draw() { rectangle.paint(); } public void resize(int width, int height) { rectangle.setWidth(width); rectangle.setHeight(height); } public void move(int x, int y) { rectangle.setOrigin(x, y); } public int getWidth() { return rectangle.getWidth(); } public int getHeight() { return rectangle.getHeight(); } public void paint() { shape.draw(); } public void stretch() { shape.resize(shape.getWidth() * 2, shape.getHeight() * 2); } } 在上面的代码中，ShapeToRectangleAdapter 适配器实现了 Shape 和 IRectangle 接口，并且在构造函数中接收一个 Shape 对象或 IRectangle 对象作为参数，以便将其适配到另一个接口中。\n当需要将一个 Shape 对象适配到一个 IRectangle 对象中时，适配器实现了 setOrigin()、setWidth() 和 setHeight() 方法，将 Shape 对象的位置和大小适配到 IRectangle 对象中。\n当需要将一个 IRectangle 对象适配到一个 Shape 对象中时，适配器实现了 draw() 和 resize() 方法，将 IRectangle 对象的绘制和大小调整适配到 Shape 对象中。\n这样，通过双向适配器，我们可以将 Shape 和 IRectangle 接口互相适配，使得它们可以在需要的时候互相调用。\n对比 适配器模式和装饰器模式都是常见的结构型设计模式，它们的作用都是为了增强类的功能。虽然这两种模式具有某些相似之处，但它们之间也存在一些重要的区别。下面是适配器模式和装饰器模式之间的区别：\n目的不同：适配器模式的目的是将一个类的接口转换为另一个类的接口，以便这两个类可以协同工作。而装饰器模式的目的是为一个对象添加新的功能，同时不改变其原有的接口和实现。 适配方式不同：适配器模式通常使用对象适配器或类适配器来实现。对象适配器使用组合关系将适配器包装在另一个对象中，而类适配器使用多重继承来实现适配器。而装饰器模式始终使用对象组合来实现。 使用场景不同：适配器模式通常用于集成第三方类或接口，或是将不兼容的接口转换为兼容的接口。而装饰器模式通常用于在运行时动态地为一个对象添加新的功能。 对象的关系不同：适配器模式中，适配器与被适配者之间是一种静态关系，它们之间的关系在编译时就已经确定。而装饰器模式中，装饰器与被装饰者之间是一种动态关系，它们之间的关系在运行时才能确定。 适配器模式的应用场景：\n在集成第三方类或接口时，可以使用适配器模式将其接口转换为应用程序所需的接口。 当需要使用某个类的方法，但该类的接口与应用程序的接口不兼容时，可以使用适配器模式将该类的接口转换为应用程序所需的接口。 当需要将一种数据格式转换为另一种数据格式时，可以使用适配器模式将数据格式转换为应用程序所需的格式。 例如，将一个电器插头插入到墙上的插座中，这两个接口是不兼容的。我们可以使用一个插头适配器，将电器插头的接口转换为墙上插座的接口，以便电器可以与墙上的插座协同工作。\n装饰器模式的应用场景：\n当需要为一个对象动态地添加新的功能时，可以使用装饰器模式。 当需要为一个对象添加的多个功能具有不同的组合方式时，可以使用装饰器模式。 例如，在一个在线商店中，用户可以购买商品并进行支付。我们可以使用装饰器模式来为订单对象添加新的功能，例如添加优惠券、添加礼品包装、添加快递保险等。这些功能可以根据用户的需求进行组合，并且可以在运行时动态地添加或删除。\n总之，适配器模式和装饰器模式都是为了增强类的功能，但它们的目的和实现方式不同。适配器模式是为了解决接口不兼容的问题，而装饰器模式是为了动态地为一个对象添加新的功能。\n举例 以下是常见开源框架中使用适配器模式的一些示例：\nSpring 框架：Spring 框架中的 HandlerAdapter 接口就是一个适配器模式的应用。不同的 HandlerAdapter 实现类可以将不同类型的控制器（如 Servlet、Struts、JSF）适配到 Spring MVC 框架中。 Hibernate 框架：Hibernate 框架中的 ConnectionProvider 接口也是一个适配器模式的应用。不同的 ConnectionProvider 实现类可以将不同类型的数据源（如 JDBC、JTA）适配到 Hibernate 框架中。 Log4j 框架：Log4j 框架中的 Appender 接口也是一个适配器模式的应用。不同的 Appender 实现类可以将不同类型的日志输出适配到 Log4j 框架中。 JUnit 框架：JUnit 框架中的 Test 接口也是一个适配器模式的应用。不同的 Test 实现类可以将不同类型的测试用例适配到 JUnit 框架中。 Java Swing 框架：Java Swing 框架中的 JList 组件也是一个适配器模式的应用。JList 组件可以使用适配器将不同类型的数据源（如数组、集合）适配到 JList 组件中。 Apache Commons 框架：Apache Commons 框架中的 FileFilter 接口也是一个适配器模式的应用。不同的 FileFilter 实现类可以将不同类型的文件过滤器适配到 Apache Commons 框架中。 Apache Shiro 框架：Apache Shiro 框架中的 Realm 接口也是一个适配器模式的应用。不同的 Realm 实现类可以将不同类型的身份验证和授权机制适配到 Apache Shiro 框架中。 Apache Struts 框架：Apache Struts 框架中的 Action 接口也是一个适配器模式的应用。不同的 Action 实现类可以将不同类型的请求处理适配到 Apache Struts 框架中。 Android 框架：Android 框架中的 ArrayAdapter 类也是一个适配器模式的应用。ArrayAdapter 类可以使用适配器将不同类型的数据源（如数组、集合）适配到 Android UI 组件中。 Spring Boot 框架：Spring Boot 框架中的 CommandLineRunner 接口也是一个适配器模式的应用。不同的 CommandLineRunner 实现类可以将不同类型的命令行参数适配到 Spring Boot 框架中。 Apache Camel 框架：Apache Camel 框架中的 Component 接口也是一个适配器模式的应用。不同的 Component 实现类可以将不同类型的消息传输协议（如 HTTP、FTP 等）适配到 Apache Camel 框架中。 Jersey 框架：Jersey 框架中的 MessageBodyReader 和 MessageBodyWriter 接口也是适配器模式的应用。这两个接口可以将不同类型的请求或响应消息适配到 Jersey 框架中。 Retrofit 框架：Retrofit 框架中的 Converter 接口也是一个适配器模式的应用。不同的 Converter 实现类可以将不同类型的响应消息转换为 Java 对象，并适配到 Retrofit 框架中。 Logback 框架：Logback 框架中的 Appender 接口也是适配器模式的应用。不同的 Appender 实现类可以将不同类型的日志输出适配到 Logback 框架中。 Apache Kafka 框架：Apache Kafka 框架中的 Consumer 和 Producer 接口也是适配器模式的应用。不同的 Consumer 和 Producer 实现类可以将不同类型的消息传输协议适配到 Apache Kafka 框架中。 以下是 jdk 中使用适配器模式的例子：\njava.util.Arrays#asList() 该方法将数组转换为 List 集合。由于数组和 List 集合的接口不兼容，所以该方法使用了适配器模式将数组转换为 List 集合。 java.util.Collections#list() 该方法接受一个 Enumeration 对象作为参数，并将该 Enumeration 对象转换为一个 List。 java.util.Collections#enumeration() 该方法接受一个 Collection 对象作为参数，并将该 Collection 对象转换为一个 Enumeration 对象。 javax.xml.bind.annotation.adapters.XMLAdapter 该类是用于 XML 序列化和反序列化的适配器。它可以将 Java 对象转换为 XML 元素，并在反序列化时将 XML 元素转换回 Java 对象。 java.io.InputStreamReader 和 java.io.OutputStreamWriter 类：这两个类是用于读写字符流的包装器类。它们使用适配器模式将字节流转换为字符流，以便读写字符数据。 javax.servlet.ServletRequestWrapper 和 javax.servlet.ServletResponseWrapper 类：这两个类是用于 HTTP 请求和响应的包装器类。它们使用适配器模式将 HTTP 请求和响应转换为 Servlet API 中定义的接口，以便在 Servlet 中使用。 ","permalink":"https://blog.chensoul.cc/posts/2023/06/10/java-design-patterns-adapter/","summary":"本文主要介绍 Adapter 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 将一个接口转换成另一个客户所期望的接口。适配器让那些本来因为接口不兼容的类可以合作无间。\n适配器模式(Adapter Pattern)是一种结构型设计模式，它允许将一个类的接口转换成客户端所期望的另一种接口。适配器模式通常用于连接两个不兼容的接口或类，以便它们可以协同工作。\n解释 现实世界例子\n考虑有这么一种情况，在你的存储卡中有一些照片，你想将其传到你的电脑中。为了传送数据，你需要某种能够兼容你电脑接口的适配器以便你的储存卡能连上你的电脑。在这种情况下，读卡器就是一个适配器。 另一个例子就是注明的电源适配器；三脚插头不能插在两脚插座上，需要一个电源适配器来使其能够插在两脚插座上。 还有一个例子就是翻译官，他翻译一个人对另一个人说的话。\n用直白的话来说\n适配器模式让你可以把不兼容的对象包在适配器中，以让其兼容其他类。\n维基百科中说\n在软件工程中，适配器模式是一种可以让现有类的接口把其作为其他接口来使用的设计模式。它经常用来使现有的类和其他类能够工作并且不用修改其他类的源代码。\n适配器模式由三个主要角色组成：\n目标接口(Target Interface)：客户端所期望的接口。适配器模式会创建一个实现目标接口的新类，以便客户端可以通过该接口调用它。\n适配器(Adapter)：该类实现了目标接口，并将客户端的请求转换为对适配者的调用。适配器通常会聚合一个适配者对象，以便将请求委托给它。\n适配者(Adapteree)：适配器模式的实际工作内容。适配者是客户端所期望的接口之外的类，它实现了客户端需要的功能，但其接口与客户端所期望的接口不兼容。\n编程样例(对象适配器)\n假如有一个船长他只会划船，但不会航行。\n首先我们有接口RowingBoat和FishingBoat\npublic interface RowingBoat { void row(); } @Slf4j public class FishingBoat { public void sail() { LOGGER.info(\u0026#34;The fishing boat is sailing\u0026#34;); } } 船长希望有一个RowingBoat接口的实现，这样就可以移动\npublic class Captain { private final RowingBoat rowingBoat; // default constructor and setter for rowingBoat public Captain(RowingBoat rowingBoat) { this.rowingBoat = rowingBoat; } public void row() { rowingBoat.","title":"Java设计模式：Adapter"},{"content":"前言 本篇是对 2023-05-29 到 2023-06-04 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、定投、帮朋友、陪家人，本周周报增加一块内容：读书，记录每周读书的时间。\n微信读书笔记助手 最近注销了微信阅读账号，清空了历史数据。本着宁缺毋滥的原则，书架重新添加了几本书。计划是重新使用微信阅读养成读书的习惯。\n在 chrome 浏览器添加了一个插件 微信读书笔记助手 ，可以将读书笔记一键导出为 markdown 格式。\n导出的内容标注是一个标注一个段落，段落之间有一个换行。段落后面可以添加自己的思考（比如，用红色标注颜色）。\n读书 本周阅读统计（图片来自微信阅读 app 分享）：\n理财 这周总计支出 2528 元，明细如下：\n6 月 4 日：138 元 6 月 3 日：1650 元，医院看病 1600 6 月 2 日：61 元 6 月 1 日：0 元 5 月 31 日：108 元 5 月 30 日：625 元，公司停车场费用 600 5 月 29 日：41 元 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周跑步 42.66 公里，最长跑步距离为 9.2 公里。\n明细数据如下：\n在朋友圈发了一个 5 月跑步 500 公里动态，一个高中同学建议我不要过度跑步，最好是跑步一天休息一天，以免伤了膝盖。受他影响，受他影响，6 月 1 日没有跑步，6 月 3 日和 4 日，带老爸去医院做检查，所以没有跑步。照此看来，6 月连续跑步 30 天、累计 200 公里的目标铁定是完成不了，所以及时调整目标和计划，还是以长期主义的思路保持跑步的习惯，不求数量。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成四篇博客：\nJava 设计模式：Visitor\nJava 设计模式：Acyclic Visitor\n[译]使用 Python 的 pip 管理项目的依赖关系\n[译]什么是 Python Wheels，你为什么要关心它？\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n📌2023-05-31 看到一个很适合新手入门「数据结构与算法」的开源书《Hello 算法》，通过动画图解结构化地讲解数据结构和算法知识，内容清晰易懂、学习曲线挺平滑，代码上支持 Java,C++, Python, Go, JS, TS, CSharp, Swift 一键运行看效果，比市面上卖的普通书好不少。 🤖 https://hello-algo.com #memos #skill 📌2023-05-31 今日重磅开源库推荐 - Plane https://github.com/makeplane/plane Jira 的开源版平替，有很多人都讨厌 Jira，觉得它复杂难用。 Plane 完全开源，而且界面要简洁舒服易用很多。 部署方便快捷, 支持 Docker 部署。 还很贴心的支持从 Github 以及 Jira 直接导入。 想尝试新的项目管理工具的朋友可以尝试一下。#memos #tool 📌2023-05-31 「Next.js 应用开发实践」 https://nextjs-in-action-cn.taonan.lu/ #memos #web 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/09/weekly_review_22/","summary":"前言 本篇是对 2023-05-29 到 2023-06-04 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n读书、健身、定投、帮朋友、陪家人，本周周报增加一块内容：读书，记录每周读书的时间。\n微信读书笔记助手 最近注销了微信阅读账号，清空了历史数据。本着宁缺毋滥的原则，书架重新添加了几本书。计划是重新使用微信阅读养成读书的习惯。\n在 chrome 浏览器添加了一个插件 微信读书笔记助手 ，可以将读书笔记一键导出为 markdown 格式。\n导出的内容标注是一个标注一个段落，段落之间有一个换行。段落后面可以添加自己的思考（比如，用红色标注颜色）。\n读书 本周阅读统计（图片来自微信阅读 app 分享）：\n理财 这周总计支出 2528 元，明细如下：\n6 月 4 日：138 元 6 月 3 日：1650 元，医院看病 1600 6 月 2 日：61 元 6 月 1 日：0 元 5 月 31 日：108 元 5 月 30 日：625 元，公司停车场费用 600 5 月 29 日：41 元 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在我的 跑步 主页。\n本周跑步 42.66 公里，最长跑步距离为 9.2 公里。\n明细数据如下：\n在朋友圈发了一个 5 月跑步 500 公里动态，一个高中同学建议我不要过度跑步，最好是跑步一天休息一天，以免伤了膝盖。受他影响，受他影响，6 月 1 日没有跑步，6 月 3 日和 4 日，带老爸去医院做检查，所以没有跑步。照此看来，6 月连续跑步 30 天、累计 200 公里的目标铁定是完成不了，所以及时调整目标和计划，还是以长期主义的思路保持跑步的习惯，不求数量。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成四篇博客：","title":"周报-22｜微信读书笔记助手"},{"content":"本文主要介绍 Visitor 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 表示要在对象结构的元素上执行的操作。访问者可让你定义新操作，而无需更改其所操作元素的类。\n访问者模式的主要目的是在不改变对象结构的前提下，对对象结构中的元素进行新的操作。它通过将操作从对象结构中分离出来，使得可以独立地添加、修改或删除对元素的操作，而不需要修改元素类或对象结构。\n访问者模式的另一个目的是将对象结构与操作解耦。在访问者模式中，元素和操作分别由不同的类来实现，并且元素只暴露出接受访问者对象的接口，而不是暴露出具体的实现细节。这样可以避免在元素类中添加过多的行为，从而提高代码的可扩展性和可维护性。\n最后，访问者模式还可以用于实现对复杂对象结构的遍历。通过访问者对象的递归调用，可以遍历整个对象结构，并对每个元素执行相应的操作。这种遍历方式可以方便地实现对复杂对象结构的分析和处理。\n解释 真实世界例子\n考虑有一个带有军队单位的树形结构。指挥官下有两名中士，每名中士下有三名士兵。基于这个层级结构实现访问者模式，我们可以轻松创建与指挥官，中士，士兵或所有人员互动的新对象\n通俗的说\n访问者模式定义可以在数据结构的节点上执行的操作。\n维基百科说\n在面向对象的程序设计和软件工程中，访问者设计模式是一种将算法与操作对象的结构分离的方法。这种分离的实际结果是能够在不修改结构的情况下向现有对象结构添加新操作。\n访问者模式是一种行为型设计模式，它允许在不改变对象结构的情况下定义新的操作。该模式的核心思想是将操作从对象结构中分离出来，并在独立的访问者对象中进行实现。\n访问者模式由以下几个关键元素组成：\n抽象访问者（Visitor）：定义可以访问不同类型元素的方法，该方法的参数类型为具体元素类型。 具体访问者（ConcreteVisitor）：实现抽象访问者中定义的方法，以实现对元素的不同操作。 抽象元素（Element）：定义接受访问者对象的方法。 具体元素（ConcreteElement）：实现抽象元素中定义的方法，以便可以接受访问者对象的访问。 对象结构（Object Structure）：包含一组具体元素，可以被访问者对象遍历。 程序示例\n使用上面的军队单元的例子，我们首先由单位和单位访问器类型。\npublic abstract class Unit { private final Unit[] children; public Unit(Unit... children) { this.children = children; } public void accept(UnitVisitor visitor) { Arrays.stream(children).forEach(child -\u0026gt; child.accept(visitor)); } } public interface UnitVisitor { void visitSoldier(Soldier soldier); void visitSergeant(Sergeant sergeant); void visitCommander(Commander commander); } 然后我们有具体的单元。\npublic class Commander extends Unit { public Commander(Unit... children) { super(children); } @Override public void accept(UnitVisitor visitor) { visitor.visitCommander(this); super.accept(visitor); } @Override public String toString() { return \u0026#34;commander\u0026#34;; } } public class Sergeant extends Unit { public Sergeant(Unit... children) { super(children); } @Override public void accept(UnitVisitor visitor) { visitor.visitSergeant(this); super.accept(visitor); } @Override public String toString() { return \u0026#34;sergeant\u0026#34;; } } public class Soldier extends Unit { public Soldier(Unit... children) { super(children); } @Override public void accept(UnitVisitor visitor) { visitor.visitSoldier(this); super.accept(visitor); } @Override public String toString() { return \u0026#34;soldier\u0026#34;; } } 然后有一些具体的访问者。\npublic class CommanderVisitor implements UnitVisitor { private static final Logger LOGGER = LoggerFactory.getLogger(CommanderVisitor.class); @Override public void visitSoldier(Soldier soldier) { // Do nothing } @Override public void visitSergeant(Sergeant sergeant) { // Do nothing } @Override public void visitCommander(Commander commander) { LOGGER.info(\u0026#34;Good to see you {}\u0026#34;, commander); } } public class SergeantVisitor implements UnitVisitor { private static final Logger LOGGER = LoggerFactory.getLogger(SergeantVisitor.class); @Override public void visitSoldier(Soldier soldier) { // Do nothing } @Override public void visitSergeant(Sergeant sergeant) { LOGGER.info(\u0026#34;Hello {}\u0026#34;, sergeant); } @Override public void visitCommander(Commander commander) { // Do nothing } } public class SoldierVisitor implements UnitVisitor { private static final Logger LOGGER = LoggerFactory.getLogger(SoldierVisitor.class); @Override public void visitSoldier(Soldier soldier) { LOGGER.info(\u0026#34;Greetings {}\u0026#34;, soldier); } @Override public void visitSergeant(Sergeant sergeant) { // Do nothing } @Override public void visitCommander(Commander commander) { // Do nothing } } 最后，来看看实践中访问者模式的力量。\ncommander.accept(new SoldierVisitor()); commander.accept(new SergeantVisitor()); commander.accept(new CommanderVisitor()); 程序输出:\nGreetings soldier Greetings soldier Greetings soldier Greetings soldier Greetings soldier Greetings soldier Hello sergeant Hello sergeant Good to see you commander 类图 优缺点 访问者模式的优点：\n扩展性好：访问者模式可以通过增加新的访问者类来扩展对对象结构的操作，而无需修改对象结构或元素类。 分离关注点：访问者模式将对象结构和对对象结构的操作分离开来，使得对象结构和访问者类可以独立发展。这样可以提高代码的复用性和可维护性。 灵活性高：访问者模式可以支持不同的访问者对象对同一对象结构进行不同的遍历和操作，从而可以实现多种不同的处理方式。 符合开闭原则：访问者模式可以通过增加新的元素类和访问者类来扩展系统的功能，而不需要修改现有的代码。 访问者模式的缺点：\n实现复杂：访问者模式的实现比较复杂，需要定义多个接口和类，并且需要对对象结构进行重构。 违反封装原则：访问者模式需要将访问者对象暴露给元素类，从而破坏了元素类的封装性。 可能会导致性能问题：访问者模式需要对整个对象结构进行遍历，可能会导致性能问题。 不易理解：访问者模式的实现比较抽象，可能会导致代码的可读性和可维护性降低。 总之，访问者模式可以提高系统的扩展性和灵活性，但是需要注意实现的复杂性和性能问题，并且需要权衡封装性和可读性之间的关系。在实际开发中，应该根据具体的需求和场景来选择是否使用访问者模式。\n对比 访问者模式和 Acyclic Visitor 设计模式都是用于处理对象结构中的元素，但它们的实现方式和应用场景有所不同。\n访问者模式通过在元素类中定义一个 accept 方法，接受一个访问者对象作为参数，从而将元素的处理委托给访问者对象来完成。访问者对象通常定义了多个 visit 方法，分别对应不同类型的元素，从而可以根据元素的类型来执行不同的操作。\nAcyclic Visitor 设计模式是访问者模式的一种变种，它通过在访问者类中定义抽象访问者类和具体访问者类来实现。抽象访问者类定义了 visit 方法，但不包含任何具体的 visit 方法实现，而具体访问者类则实现了具体的 visit 方法。这样可以避免访问者对象对元素类的依赖，从而实现松耦合。\nAcyclic Visitor 设计模式通常用于处理多继承的对象结构，因为多继承可能会导致访问者对象对元素类的依赖。在多继承的情况下，元素类可能同时继承了多个接口或父类，这样访问者对象就需要对每个接口或父类都定义一个 visit 方法，从而导致访问者对象对元素类的依赖性增加。\n总之，访问者模式和 Acyclic Visitor 设计模式都是用于处理对象结构中的元素，但它们的实现方式和应用场景有所不同。访问者模式适用于处理单继承的对象结构，而 Acyclic Visitor 设计模式适用于处理多继承的对象结构。在实际应用中，应该根据具体的需求和场景来选择使用哪种模式。\n适用场景 访问者模式适用于以下情况：\n对象结构复杂，包含多种类型的元素，并且需要对这些元素进行不同的操作。 需要在不改变对象结构的前提下，增加、修改或删除对元素的操作。 对象结构中的元素类经常发生变化，而访问者类的变化较少。 需要对对象结构进行多种不同的遍历方式，并且每种遍历方式需要执行不同的操作。 对象结构中的元素类不希望暴露出太多的行为，而是希望将行为封装在访问者类中。 需要注意的是，访问者模式的实现比较复杂，因此只有在确实需要对对象结构进行复杂操作时才应该考虑使用该模式。如果仅需要对对象结构进行简单的遍历或操作，则可以考虑使用其他模式，如迭代器模式或组合模式。\n以下是一些访问者模式在实际开发中的应用场景：\n编译器和解释器：访问者模式可以用于实现编译器和解释器。编译器和解释器都需要对抽象语法树（AST）进行遍历，并根据不同的节点类型执行不同的操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对 AST 的遍历和处理。 数据库查询：访问者模式可以用于实现数据库查询。数据库查询需要对查询语句进行解析，并将查询转换为对数据库中的表进行操作的语句。访问者模式可以将查询解析和转换操作封装在不同的访问者类中，从而实现对查询语句的处理。 GUI 框架：访问者模式可以用于实现 GUI 框架。GUI 框架需要对各种 GUI 组件进行遍历，并根据不同的组件类型执行不同的操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对 GUI 组件的遍历和处理。 订单处理系统：访问者模式可以用于实现订单处理系统。订单处理系统需要对订单中的各种项进行遍历，并根据不同的项类型执行不同的操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对订单的遍历和处理。 机器学习：访问者模式可以用于实现机器学习算法。机器学习算法需要对数据集进行遍历，并根据不同的数据类型执行不同的操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对数据集的遍历和处理。 虚拟机：访问者模式可以用于实现虚拟机。虚拟机需要对字节码或中间代码进行遍历，并根据不同的指令类型执行不同的操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对字节码或中间代码的遍历和处理。 多媒体编解码器：访问者模式可以用于实现多媒体编解码器。多媒体编解码器需要对音视频数据进行遍历，并根据不同的数据类型执行不同的编解码操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对音视频数据的遍历和处理。 图像处理软件：访问者模式可以用于实现图像处理软件。图像处理软件需要对图像进行遍历，并根据不同的像素类型执行不同的处理操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对图像的遍历和处理。 网络协议解析器：访问者模式可以用于实现网络协议解析器。网络协议解析器需要对网络数据包进行遍历，并根据不同的协议类型执行不同的解析操作。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对网络数据包的遍历和处理。 CAD 软件：访问者模式可以用于实现 CAD 软件。CAD 软件需要对绘图元素进行遍历，并根据不同的元素类型执行不同的操作，比如绘制线条、填充颜色等。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对绘图元素的遍历和处理。 代码生成器：访问者模式可以用于实现代码生成器。代码生成器需要对抽象语法树（AST）进行遍历，并根据不同的节点类型生成不同的代码。访问者模式可以将代码生成操作封装在不同的访问者类中，从而实现对 AST 的遍历和代码生成。 环境监测系统：访问者模式可以用于实现环境监测系统。环境监测系统需要对多个传感器采集的数据进行遍历，并根据不同的传感器类型执行不同的处理操作，比如温度校准、数据存储等。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对传感器数据的遍历和处理。 数字信号处理系统：访问者模式可以用于实现数字信号处理系统。数字信号处理系统需要对数字信号进行遍历，并根据不同的信号类型执行不同的处理操作，比如滤波、降噪等。访问者模式可以将这些操作封装在不同的访问者类中，从而实现对数字信号的遍历和处理。 访问者模式在 JDK 中有多个应用，以下是其中一些例子：\nJava 中的 java.nio.file.FileVisitor 接口和 java.nio.file.Files#walkFileTree 方法，其中的 FileVisitor 接口定义了多个 visit 方法，用于访问文件树中的各个节点对象。Files#walkFileTree 方法可以通过访问者模式来实现遍历文件树并对每个文件进行处理。 javax.lang.model.element.AnnotationValueVisitor 接口，用于访问注解值的各种类型，例如基本类型、字符串、枚举类型、数组类型和嵌套注解类型等。该接口中定义了多个 visit 方法，用于处理不同类型的注解值。 javax.lang.model.element.ElementVisitor 接口，用于访问程序元素的各种类型，例如包、类、方法、字段、注解和注解值等。该接口中定义了多个 visit 方法，用于处理不同类型的程序元素。 javax.lang.model.type.TypeVisitor 接口，用于访问类型的各种类型，例如基本类型、对象类型、数组类型和泛型类型等。该接口中定义了多个 visit 方法，用于处理不同类型的类型。 总之，访问者模式可以适用于各种不同的领域和场景，只要需要对对象结构进行遍历和处理，都可以考虑使用该模式。\n举例 计算图形面积和周长 假设我们有一个图形类 Shape，它有两个子类 Circle 和 Rectangle，我们需要对它们进行面积和周长的计算。我们可以使用访问者模式来实现这个功能。\n我们首先定义一个抽象访问者类 ShapeVisitor，它包含了两个抽象方法 visitCircle 和 visitRectangle，分别用于访问 Circle 和 Rectangle 对象。\n// 抽象访问者类 interface ShapeVisitor { void visitCircle(Circle circle); void visitRectangle(Rectangle rectangle); } 然后我们定义一个抽象的图形类 Shape，它包含一个 accept 方法，用于接受一个访问者对象作为参数。\n// 抽象图形类 abstract class Shape { abstract void accept(ShapeVisitor visitor); } 接着我们定义两个具体的图形类 Circle 和 Rectangle，它们实现了 accept 方法，并在其中调用访问者对象的 visitCircle 和 visitRectangle 方法。\n// 具体图形类 Circle class Circle extends Shape { private double radius; Circle(double radius) { this.radius = radius; } double getRadius() { return radius; } @Override void accept(ShapeVisitor visitor) { visitor.visitCircle(this); } } // 具体图形类 Rectangle class Rectangle extends Shape { private double width; private double height; Rectangle(double width, double height) { this.width = width; this.height = height; } double getWidth() { return width; } double getHeight() { return height; } @Override void accept(ShapeVisitor visitor) { visitor.visitRectangle(this); } } 最后我们定义一个具体的访问者类 ShapeCalculator，它实现了 ShapeVisitor 接口，并在其中实现了 visitCircle 和 visitRectangle 方法，用于计算图形的面积和周长。\n// 具体访问者类 ShapeCalculator class ShapeCalculator implements ShapeVisitor { private double area; private double perimeter; @Override public void visitCircle(Circle circle) { double radius = circle.getRadius(); area = Math.PI * radius * radius; perimeter = 2 * Math.PI * radius; } @Override public void visitRectangle(Rectangle rectangle) { double width = rectangle.getWidth(); double height = rectangle.getHeight(); area = width * height; perimeter = 2 * (width + height); } double getArea() { return area; } double getPerimeter() { return perimeter; } } 现在我们可以使用访问者模式来计算图形的面积和周长了。我们先创建一个 ShapeCalculator 对象，然后分别创建一个 Circle 对象和一个 Rectangle 对象，并调用它们的 accept 方法，将 ShapeCalculator 作为参数传入。\npublic class Main { public static void main(String[] args) { ShapeCalculator calculator = new ShapeCalculator(); Circle circle = new Circle(5.0); circle.accept(calculator); System.out.println(\u0026#34;Circle area: \u0026#34; + calculator.getArea()); System.out.println(\u0026#34;Circle perimeter: \u0026#34; + calculator.getPerimeter()); Rectangle rectangle = new Rectangle(3.0, 4.0); rectangle.accept(calculator); System.out.println(\u0026#34;Rectangle area: \u0026#34; + calculator.getArea()); System.out.println(\u0026#34;Rectangle perimeter: \u0026#34; + calculator.getPerimeter()); } } 输出结果如下：\nCircle area: 78.53981633974483 Circle perimeter: 31.41592653589793 Rectangle area: 12.0 Rectangle perimeter: 14.0 这个例子展示了如何使用访问者模式来计算图形的面积和周长，我们将计算的逻辑封装在了 ShapeCalculator 类中，并通过访问者模式将它们应用于不同的图形对象。这样可以实现代码的重用和可维护性。\n实现代码生成器 访问者模式可以用于实现代码生成器，下面是一个简单的例子：\n假设我们需要根据一个语法树生成相应的代码，语法树中包含了不同类型的节点，每个节点代表一个语法结构。我们可以使用访问者模式来实现这个功能，将语法树中的每个节点都作为一个元素，访问者对象则负责生成相应的代码。\n我们首先定义一个抽象访问者类 CodeGenerator，它包含了多个抽象方法，每个方法对应一个节点类型，用于生成相应的代码。\n// 抽象访问者类 interface CodeGenerator { void generate(ProgramNode node); void generate(StatementNode node); void generate(ExpressionNode node); // ... } 然后我们定义一个抽象的节点类 Node，它包含一个 accept 方法，用于接受一个访问者对象作为参数。\n// 抽象节点类 abstract class Node { abstract void accept(CodeGenerator generator); } 接着我们定义多个具体的节点类 ProgramNode、StatementNode 和 ExpressionNode，它们实现了 accept 方法，并在其中调用访问者对象的相应方法。\n// 具体节点类 ProgramNode class ProgramNode extends Node { private List\u0026lt;Node\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); void add(Node node) { children.add(node); } @Override void accept(CodeGenerator generator) { generator.generate(this); for (Node child : children) { child.accept(generator); } } } // 具体节点类 StatementNode class StatementNode extends Node { private String statement; StatementNode(String statement) { this.statement = statement; } @Override void accept(CodeGenerator generator) { generator.generate(this); } String getStatement() { return statement; } } // 具体节点类 ExpressionNode class ExpressionNode extends Node { private String expression; ExpressionNode(String expression) { this.expression = expression; } @Override void accept(CodeGenerator generator) { generator.generate(this); } String getExpression() { return expression; } } 最后我们定义一个具体的访问者类 JavaCodeGenerator，它实现了 CodeGenerator 接口，并在其中实现了各个节点类型的生成方法，用于生成 Java 代码。\n// 具体访问者类 JavaCodeGenerator class JavaCodeGenerator implements CodeGenerator { private StringBuilder codeBuilder = new StringBuilder(); @Override public void generate(ProgramNode node) { codeBuilder.append(\u0026#34;public class Main {\\n\u0026#34;); } @Override public void generate(StatementNode node) { codeBuilder.append(\u0026#34; \u0026#34;).append(node.getStatement()).append(\u0026#34;;\\n\u0026#34;); } @Override public void generate(ExpressionNode node) { codeBuilder.append(\u0026#34; \u0026#34;).append(node.getExpression()).append(\u0026#34;;\\n\u0026#34;); } String getCode() { codeBuilder.append(\u0026#34;}\\n\u0026#34;); return codeBuilder.toString(); } } 现在我们可以使用访问者模式来生成 Java 代码了。我们先创建一个 ProgramNode 对象，并向其中添加多个 StatementNode 和 ExpressionNode 对象，然后创建一个 JavaCodeGenerator 对象，调用 ProgramNode 的 accept 方法，并将 JavaCodeGenerator 作为参数传入。\npublic class Main { public static void main(String[] args) { ProgramNode programNode = new ProgramNode(); programNode.add(new StatementNode(\u0026#34;int a = 1\u0026#34;)); programNode.add(new ExpressionNode(\u0026#34;a++\u0026#34;)); programNode.add(new StatementNode(\u0026#34;System.out.println(a)\u0026#34;)); JavaCodeGenerator codeGenerator = new JavaCodeGenerator(); programNode.accept(codeGenerator); System.out.println(codeGenerator.getCode()); } } 输出结果如下：\npublic class Main { int a = 1; a++; System.out.println(a); } 这个例子展示了如何使用访问者模式来生成 Java 代码，我们将生成代码的逻辑封装在了 JavaCodeGenerator 类中，并通过访问者模式将它们应用于语法树中的每个节点。这样可以实现代码的快速生成和可维护性。\n","permalink":"https://blog.chensoul.cc/posts/2023/06/02/java-design-patterns-visitor/","summary":"本文主要介绍 Visitor 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 表示要在对象结构的元素上执行的操作。访问者可让你定义新操作，而无需更改其所操作元素的类。\n访问者模式的主要目的是在不改变对象结构的前提下，对对象结构中的元素进行新的操作。它通过将操作从对象结构中分离出来，使得可以独立地添加、修改或删除对元素的操作，而不需要修改元素类或对象结构。\n访问者模式的另一个目的是将对象结构与操作解耦。在访问者模式中，元素和操作分别由不同的类来实现，并且元素只暴露出接受访问者对象的接口，而不是暴露出具体的实现细节。这样可以避免在元素类中添加过多的行为，从而提高代码的可扩展性和可维护性。\n最后，访问者模式还可以用于实现对复杂对象结构的遍历。通过访问者对象的递归调用，可以遍历整个对象结构，并对每个元素执行相应的操作。这种遍历方式可以方便地实现对复杂对象结构的分析和处理。\n解释 真实世界例子\n考虑有一个带有军队单位的树形结构。指挥官下有两名中士，每名中士下有三名士兵。基于这个层级结构实现访问者模式，我们可以轻松创建与指挥官，中士，士兵或所有人员互动的新对象\n通俗的说\n访问者模式定义可以在数据结构的节点上执行的操作。\n维基百科说\n在面向对象的程序设计和软件工程中，访问者设计模式是一种将算法与操作对象的结构分离的方法。这种分离的实际结果是能够在不修改结构的情况下向现有对象结构添加新操作。\n访问者模式是一种行为型设计模式，它允许在不改变对象结构的情况下定义新的操作。该模式的核心思想是将操作从对象结构中分离出来，并在独立的访问者对象中进行实现。\n访问者模式由以下几个关键元素组成：\n抽象访问者（Visitor）：定义可以访问不同类型元素的方法，该方法的参数类型为具体元素类型。 具体访问者（ConcreteVisitor）：实现抽象访问者中定义的方法，以实现对元素的不同操作。 抽象元素（Element）：定义接受访问者对象的方法。 具体元素（ConcreteElement）：实现抽象元素中定义的方法，以便可以接受访问者对象的访问。 对象结构（Object Structure）：包含一组具体元素，可以被访问者对象遍历。 程序示例\n使用上面的军队单元的例子，我们首先由单位和单位访问器类型。\npublic abstract class Unit { private final Unit[] children; public Unit(Unit... children) { this.children = children; } public void accept(UnitVisitor visitor) { Arrays.stream(children).forEach(child -\u0026gt; child.accept(visitor)); } } public interface UnitVisitor { void visitSoldier(Soldier soldier); void visitSergeant(Sergeant sergeant); void visitCommander(Commander commander); } 然后我们有具体的单元。\npublic class Commander extends Unit { public Commander(Unit.","title":"Java设计模式：Visitor"},{"content":"本文主要介绍 Acyclic Visitor 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 允许将新功能添加到现有的类层次结构中，而不会影响这些层次结构，也不会有四人帮访客模式中那样循环依赖的问题。\n在 Acyclic Visitor 模式中，我们通过引入一个可选操作接口来实现这一点。当数据结构类需要访问访问者类的某些操作时，它可以通过调用 visit 方法来访问可选操作接口中定义的操作，而不需要直接依赖于访问者类中的成员变量。\n解释 真实世界例子\n我们有一个调制解调器类的层次结构。 需要使用基于过滤条件的外部算法（是 Unix 或 DOS 兼容的调制解调器）来访问此层次结构中的调制解调器。\n程序示例\n这是调制解调器的层次结构。\npublic interface Modem { void accept(ModemVisitor modemVisitor); } public class Hayes implements Modem { @Override public void accept(ModemVisitor modemVisitor) { if (modemVisitor instanceof HayesVisitor) { ((HayesVisitor) modemVisitor).visit(this); } else { System.out.println(\u0026#34;Only HayesVisitor is allowed to visit Hayes modem\u0026#34;); } } } public class Zoom implements Modem { @Override public void accept(ModemVisitor modemVisitor) { if (modemVisitor instanceof ZoomVisitor) { ((ZoomVisitor) modemVisitor).visit(this); } } } 下面我们介绍调制解调器访问者类结构。\npublic interface ModemVisitor { } public interface HayesVisitor extends ModemVisitor { void visit(Hayes hayes); } public interface ZoomVisitor extends ModemVisitor { void visit(Zoom zoom); } public interface AllModemVisitor extends ZoomVisitor, HayesVisitor { } public class ConfigureForDosVisitor implements AllModemVisitor { @Override public void visit(Hayes hayes) { System.out.println(hayes + \u0026#34; used with Dos configurator.\u0026#34;); } @Override public void visit(Zoom zoom) { System.out.println(zoom + \u0026#34; used with Dos configurator.\u0026#34;); } } public class ConfigureForUnixVisitor implements ZoomVisitor { @Override public void visit(Zoom zoom) { System.out.println(zoom + \u0026#34; used with Unix configurator.\u0026#34;); } } 最后，这里是访问者的实践。\npublic class Client { public static void main(String[] args) { Modem[] modems = { new Hayes(), new Zoom(), new Hayes() }; ModemVisitor dosVisitor = new ConfigureForDosVisitor(); ModemVisitor unixVisitor = new ConfigureForUnixVisitor(); for (Modem modem : modems) { modem.accept(dosVisitor); modem.accept(unixVisitor); } } } 类图 以下是对 Acyclic Visitor 模式的解释：\nElement（元素）：在上面的代码中，Modem 接口表示一个元素，定义了一个 accept 方法，用于接受访问者的访问。 ConcreteElement（具体元素）：在上面的代码中，Hayes 类和 Zoom 类表示具体的元素，实现了 Modem 接口中定义的 accept 方法。 Visitor（访问者）：在上面的代码中，ModemVisitor 接口表示一个访问者，定义了一个空的接口，用于扩展具体的访问者接口。 ConcreteVisitor（具体访问者）：在上面的代码中，ConfigureForDosVisitor 和 ConfigureForUnixVisitor 类表示具体的访问者，实现了 HayesVisitor 和 ZoomVisitor 接口中定义的 visit 方法，用于访问具体的元素。 OptionalOperations（可选操作）：在上面的代码中，AllModemVisitor 接口表示一个可选操作接口，它继承了所有具体访问者接口，用于扩展访问者类的操作。在 ConfigureForDosVisitor 类中，它实现了 AllModemVisitor 接口，同时实现了 visit 方法，用于访问所有具体的元素。在 ConfigureForUnixVisitor 类中，它实现了 ZoomVisitor 接口，同时实现了 visit 方法，用于访问 Zoom 元素。 在 Acyclic Visitor 模式中，元素和访问者之间是相互独立的，它们之间没有任何依赖关系。在访问元素时，访问者通过 accept 方法访问元素，并根据元素的类型自动调用对应的 visit 方法。由于访问者并没有直接依赖于元素，而是通过访问者接口和可选操作接口来访问元素，因此可以避免循环依赖的问题。同时，由于可选操作是一个接口，访问者可以根据需要实现其中的部分操作，从而动态地添加新的操作，而不会影响现有的类层次结构。这样，Acyclic Visitor 模式可以使代码更加灵活和可扩展，同时也提高了代码的可维护性和可扩展性。\n适用性 以下情况可以使用此模式：\n需要在现有层次结构中添加新功能而无需更改或影响该层次结构时。 当某些功能在层次结构上运行，但不属于层次结构本身时。 例如 ConfigureForDOS / ConfigureForUnix / ConfigureForX 问题。 当您需要根据对象的类型对对象执行非常不同的操作时。 当访问的类层次结构将经常使用元素类的新派生进行扩展时。在 Acyclic Visitor 模式中，新的元素类可以通过继承现有的 Element 类来实现，而不需要修改访问者类的代码。这样，可以避免因添加新元素而导致的访问者类的修改和重新编译。 当重新编译，重新链接，重新测试或重新分发派生元素非常昂贵时。 对比 Acyclic Visitor 模式是 Visitor 模式的一个变体，它解决了 Visitor 模式可能导致的循环依赖问题。下面是 Acyclic Visitor 模式和 Visitor 模式的一些对比：\n目的不同 Visitor 模式的主要目的是将数据结构和操作分离开来，并将操作封装在访问者类中。这使得我们可以在不修改数据结构代码的情况下添加新的操作。而 Acyclic Visitor 模式则更注重解决 Visitor 模式中可能出现的循环依赖问题。\n实现方式不同 在 Visitor 模式中，访问者类通常会维护一个数据结构类的引用，以便在 visit 方法中访问数据结构类的成员。这可能会导致循环依赖问题。而在 Acyclic Visitor 模式中，我们引入了一个额外的接口，即可选操作接口，它包含数据结构类可能需要调用的方法。这样，数据结构类就可以通过调用 visit 方法来访问访问者类中的部分操作，而不必直接依赖于访问者类中的成员，从而避免了循环依赖问题。\n可扩展性不同 由于 Visitor 模式中数据结构类和访问者类之间存在强耦合关系，因此添加新的数据结构类或访问者类可能会导致代码修改。而 Acyclic Visitor 模式通过引入可选操作接口，使得数据结构类和访问者类之间的耦合关系更加灵活，从而提高了代码的可扩展性。\n实现复杂度不同 Acyclic Visitor 模式相比 Visitor 模式，增加了一个可选操作接口，因此实现上可能会更加复杂。但是，这也使得 Acyclic Visitor 模式更加灵活和可扩展。\n优缺点 下面是 Acyclic Visitor 模式的优点和缺点：\n优点：\n解决了 Visitor 模式可能出现的循环依赖问题，使得代码更加健壮和可维护。 可选操作接口使得访问者类的扩展更加灵活，可以根据具体需求选择实现不同的操作。 将数据结构和操作分离开来，提高了代码的可扩展性和可维护性。 在需要添加新的数据结构类或访问者类时，可以避免对现有代码进行修改，符合开闭原则。 缺点：\n相对于 Visitor 模式，Acyclic Visitor 模式的实现会更加复杂，因为需要引入一个可选操作接口。 由于 Acyclic Visitor 模式在实现上更加复杂，可能会降低代码的可读性和可理解性。 如果数据结构类需要访问访问者类的成员，Acyclic Visitor 模式并不能很好地解决这个问题，需要考虑其他设计模式的使用。 使用场景 Acyclic Visitor 模式通常用于以下场景：\n类层次结构中存在多种类型的对象，并且需要对它们进行不同的操作，但不想在类层次结构中添加新的方法或修改现有方法。 不同的操作需要访问对象的不同部分，而不是整个对象本身。 类层次结构之间存在依赖关系，但不希望引入循环依赖问题。 需要在类层次结构中添加新的操作，而不影响现有的类。 需要支持多个访问者，且访问者之间可能存在依赖关系。 需要避免在访问者中使用 instanceof 运算符来检查元素的类型。 具体的使用场景如下：\n解析器（Parser）：在解析器中，可以使用 Acyclic Visitor 模式来实现不同类型的节点的访问。例如，可以使用 Acyclic Visitor 模式来实现语法树的遍历，以实现语法分析、类型检查等功能。 编译器（Compiler）：在编译器中，可以使用 Acyclic Visitor 模式来实现不同阶段的分析。例如，可以使用 Acyclic Visitor 模式来实现词法分析器、语法分析器、类型检查器、代码生成器等。 图形用户界面（GUI）：在图形用户界面中，可以使用 Acyclic Visitor 模式来实现不同类型的控件的访问。例如，可以使用 Acyclic Visitor 模式来实现窗口、按钮、菜单等控件的事件处理逻辑。 数据库访问（Database Access）：在数据库访问中，可以使用 Acyclic Visitor 模式来实现不同类型的对象的访问。例如，可以使用 Acyclic Visitor 模式来实现对关系型数据库中的表、视图、存储过程、触发器等对象的访问。 游戏开发（Game Development）：在游戏开发中，可以使用 Acyclic Visitor 模式来实现不同类型的游戏对象的访问。例如，可以使用 Acyclic Visitor 模式来实现对角色、道具、怪物等游戏对象的访问。 打印机驱动程序（Printer Driver）：在打印机驱动程序中，可以使用 Acyclic Visitor 模式来实现不同类型的打印作业的访问。例如，可以使用 Acyclic Visitor 模式来实现对文本、图片、表格等打印作业的访问。 音频处理（Audio Processing）：在音频处理中，可以使用 Acyclic Visitor 模式来实现不同类型的音频文件的访问。例如，可以使用 Acyclic Visitor 模式来实现对 MP3、WAV、FLAC 等音频文件的访问。 网络协议（Network Protocol）：在网络协议中，可以使用 Acyclic Visitor 模式来实现不同类型的协议数据包的访问。例如，可以使用 Acyclic Visitor 模式来实现对 TCP、UDP、HTTP、SMTP 等协议数据包的访问。 机器人控制（Robot Control）：在机器人控制中，可以使用 Acyclic Visitor 模式来实现不同类型的机器人动作的访问。例如，可以使用 Acyclic Visitor 模式来实现对移动、转向、抓取、放置等机器人动作的访问。 系统监控（System Monitoring）：在系统监控中，可以使用 Acyclic Visitor 模式来实现不同类型的监测数据的访问。例如，可以使用 Acyclic Visitor 模式来实现对 CPU 占用率、内存使用量、网络流量等监测数据的访问。 机器学习（Machine Learning）：在机器学习中，可以使用 Acyclic Visitor 模式来实现不同类型的训练数据的访问。例如，可以使用 Acyclic Visitor 模式来实现对图像、声音、文本等训练数据的访问。 金融交易（Financial Trading）：在金融交易中，可以使用 Acyclic Visitor 模式来实现不同类型的交易数据的访问。例如，可以使用 Acyclic Visitor 模式来实现对股票、期货、外汇等交易数据的访问。 电子商务（E-commerce）：在电子商务中，可以使用 Acyclic Visitor 模式来实现不同类型的商品数据的访问。例如，可以使用 Acyclic Visitor 模式来实现对产品、订单、客户等商品数据的访问。 硬件控制（Hardware Control）：在硬件控制中，可以使用 Acyclic Visitor 模式来实现不同类型的硬件设备的访问。例如，可以使用 Acyclic Visitor 模式来实现对传感器、电机、执行器等硬件设备的访问。 一个更具体的例子是使用 Acyclic Visitor 模式来实现图像处理功能。假设我们有一个图像处理程序，它可以处理多种类型的图像，如 JPEG、PNG、BMP 等。我们需要为该程序添加一个新的功能，即将图像转换为黑白图像。\n为实现这一功能，我们可以使用 Acyclic Visitor 模式来设计图像处理类层次结构。类层次结构包括多种类型的图像，如 JPEGImage、PNGImage、BMPImage 等。对于每种类型的图像，我们定义一个相应的图像处理器类，如 JPEGImageHandler、PNGImageHandler、BMPImageHandler 等。每个图像处理器类都实现一个 Visitor 接口的子接口，如 JPEGImageVisitor、PNGImageVisitor、BMPImageVisitor，该子接口定义了一些 visit 方法，用于处理图像中的像素数据。\n定义 Visitor 接口及其子接口：\npublic interface Visitor { } public interface JPEGImageVisitor extends Visitor { void visit(JPEGImage image); } public interface PNGImageVisitor extends Visitor { void visit(PNGImage image); } public interface BMPImageVisitor extends Visitor { void visit(BMPImage image); } 定义图像类及其子类：\npublic interface Image { void accept(Visitor visitor); } public class JPEGImage implements Image { private byte[] data; public JPEGImage(byte[] data) { this.data = data; } public byte[] getData() { return data; } @Override public void accept(Visitor visitor) { if (visitor instanceof JPEGImageVisitor) { ((JPEGImageVisitor) visitor).visit(this); } } } public class PNGImage implements Image { private byte[] data; public PNGImage(byte[] data) { this.data = data; } public byte[] getData() { return data; } @Override public void accept(Visitor visitor) { if (visitor instanceof PNGImageVisitor) { ((PNGImageVisitor) visitor).visit(this); } } } public class BMPImage implements Image { private byte[] data; public BMPImage(byte[] data) { this.data = data; } public byte[] getData() { return data; } @Override public void accept(Visitor visitor) { if (visitor instanceof BMPImageVisitor) { ((BMPImageVisitor) visitor).visit(this); } } } 定义黑白图像处理器类：\npublic class BlackWhiteImageProcessor implements JPEGImageVisitor, PNGImageVisitor,BMPImageVisitor { @Override public void visit(JPEGImage image) { // 将 JPEG 图像转换为黑白图像 // 处理像素数据 byte[] data = image.getData(); // ... } @Override public void visit(PNGImage image) { // 将 PNG 图像转换为黑白图像 // 处理像素数据 byte[] data = image.getData(); // ... } @Override public void visit(BMPImage image) { // 将 BMP 图像转换为黑白图像 // 处理像素数据 byte[] data = image.getData(); // ... } } 最后，我们可以通过以下方式使用 Acyclic Visitor 模式来实现图像处理功能：\npublic class Client { public static void main(String[] args) { List\u0026lt;Image\u0026gt; images = new ArrayList\u0026lt;\u0026gt;(); images.add(new JPEGImage(jpegData)); images.add(new PNGImage(pngData)); images.add(new BMPImage(bmpData)); BlackWhiteImageProcessor processor = new BlackWhiteImageProcessor(); for (Image image : images) { image.accept(processor); } } } 在这个例子中，Acyclic Visitor 模式使我们能够实现对多种类型的图像进行不同的处理，同时保持代码的可扩展性和可维护性。我们可以轻松地添加新的图像处理器类，如 SepiaImageProcessor、BlurImageProcessor 、RotateImageProcessor 等，而无需修改图像类层次结构的代码。同时，我们可以避免在图像类层次结构中添加处理方法，而是将处理逻辑封装在访问者类中，从而提高代码的可扩展性和可维护性。\n下面我给出一个简单的示例代码来演示如何使用 Acyclic Visitor 模式来实现对 CPU 占用率、内存使用量、网络流量等监测数据的访问。\n首先，我们定义一个 Visitor 接口及其子接口：\npublic interface Visitor { } public interface CPUUsageVisitor extends Visitor { void visit(CPUUsage cpuUsage); } public interface MemoryUsageVisitor extends Visitor { void visit(MemoryUsage memoryUsage); } public interface NetworkTrafficVisitor extends Visitor { void visit(NetworkTraffic networkTraffic); } 然后，我们定义三个监测数据类：CPUUsage、MemoryUsage 和 NetworkTraffic。这些类实现了 Visitor 接口，并且定义了一个 accept 方法，该方法接受一个 Visitor 对象，并调用 Visitor 对象的 visit 方法：\npublic interface Usages { void accept(Visitor visitor); } public class CPUUsage implements Usages { private double usage; public CPUUsage(double usage) { this.usage = usage; } public double getUsage() { return usage; } public void accept(Visitor visitor) { if (visitor instanceof CPUUsageVisitor) { ((CPUUsageVisitor) visitor).visit(this); } } } public class MemoryUsage implements Visitor { private long used; private long total; public MemoryUsage(long used, long total) { this.used = used; this.total = total; } public long getUsed() { return used; } public long getTotal() { return total; } public void accept(Visitor visitor) { if (visitor instanceof MemoryUsageVisitor) { ((MemoryUsageVisitor) visitor).visit(this); } } } public class NetworkTraffic implements Visitor { private long sent; private long received; public NetworkTraffic(long sent, long received) { this.sent = sent; this.received = received; } public long getSent() { return sent; } public long getReceived() { return received; } public void accept(Visitor visitor) { if (visitor instanceof NetworkTrafficVisitor) { ((NetworkTrafficVisitor) visitor).visit(this); } } } 接下来，我们定义三个 Visitor 实现类：CPUUsageLoggerVistor、MemoryUsageLoggerVistor 和 NetworkTrafficLoggerVistor。这些类实现了 CPUUsageVisitor、MemoryUsageVisitor 和 NetworkTrafficVisitor 接口，并实现了 visit 方法，该方法用于记录监测数据：\npublic class CPUUsageLoggerVistor implements CPUUsageVisitor { public void visit(CPUUsage cpuUsage) { double usage = cpuUsage.getUsage(); System.out.println(\u0026#34;CPU Usage: \u0026#34; + usage); } } public class MemoryUsageLoggerVistor implements MemoryUsageVisitor { public void visit(MemoryUsage memoryUsage) { long used = memoryUsage.getUsed(); long total = memoryUsage.getTotal(); double usage = (double) used / total * 100; System.out.println(\u0026#34;Memory Usage: \u0026#34; + usage + \u0026#34;%\u0026#34;); } } public class NetworkTrafficLoggerVistor implements NetworkTrafficVisitor { public void visit(NetworkTraffic networkTraffic) { long sent = networkTraffic.getSent(); long received = networkTraffic.getReceived(); System.out.println(\u0026#34;Network Traffic: Sent=\u0026#34; + sent + \u0026#34; bytes, Received=\u0026#34; + received + \u0026#34; bytes\u0026#34;); } } 最后，我们定义一个监测数据源类：SystemMonitor。该类维护三个监测数据：CPUUsage、MemoryUsage 和 NetworkTraffic，并提供相应的方法用于更新监测数据。该类还提供一个 accept 方法，该方法接受一个 Visitor 对象，并将该 Visitor 对象传递给各个监测数据对象：\npublic class SystemMonitor { private CPUUsage cpuUsage; private MemoryUsage memoryUsage; private NetworkTraffic networkTraffic; public void updateCPUUsage(double usage) { cpuUsage = new CPUUsage(usage); } public void updateMemoryUsage(long used, long total) { memoryUsage = new MemoryUsage(used, total); } public void updateNetworkTraffic(long sent,long received) { networkTraffic = new NetworkTraffic(sent, received); } public void accept(Visitor visitor) { if (cpuUsage != null) { cpuUsage.accept(visitor); } if (memoryUsage != null) { memoryUsage.accept(visitor); } if (networkTraffic != null) { networkTraffic.accept(visitor); } } } 现在，我们可以使用上述类来实现对 CPU 占用率、内存使用量、网络流量等监测数据的访问。首先，我们创建一个 SystemMonitor 对象，并更新监测数据：\nSystemMonitor monitor = new SystemMonitor(); monitor.updateCPUUsage(0.75); monitor.updateMemoryUsage(1024, 2048); monitor.updateNetworkTraffic(1024, 2048); 然后，我们可以创建三个 Visitor 对象：CPUUsageLoggerVistor、MemoryUsageLoggerVistor 和 NetworkTrafficLoggerVistor，用于记录监测数据：\nCPUUsageLoggerVistor cpuUsageLogger = new CPUUsageLoggerVistor(); MemoryUsageLoggerVistor memoryUsageLogger = new MemoryUsageLoggerVistor(); NetworkTrafficLoggerVistor networkTrafficLogger = new NetworkTrafficLoggerVistor(); 最后，我们可以将这些 Visitor 对象传递给 SystemMonitor 对象，并调用 accept 方法来访问监测数据：\nmonitor.accept(cpuUsageLogger); monitor.accept(memoryUsageLogger); monitor.accept(networkTrafficLogger); 这样，我们就可以通过 Acyclic Visitor 模式来实现对 CPU 占用率、内存使用量、网络流量等监测数据的访问。\n参考文章 Acyclic Visitor by Robert C. Martin\nAcyclic Visitor in WikiWikiWeb\n","permalink":"https://blog.chensoul.cc/posts/2023/06/01/java-design-patterns-acyclic-visitor/","summary":"本文主要介绍 Acyclic Visitor 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 允许将新功能添加到现有的类层次结构中，而不会影响这些层次结构，也不会有四人帮访客模式中那样循环依赖的问题。\n在 Acyclic Visitor 模式中，我们通过引入一个可选操作接口来实现这一点。当数据结构类需要访问访问者类的某些操作时，它可以通过调用 visit 方法来访问可选操作接口中定义的操作，而不需要直接依赖于访问者类中的成员变量。\n解释 真实世界例子\n我们有一个调制解调器类的层次结构。 需要使用基于过滤条件的外部算法（是 Unix 或 DOS 兼容的调制解调器）来访问此层次结构中的调制解调器。\n程序示例\n这是调制解调器的层次结构。\npublic interface Modem { void accept(ModemVisitor modemVisitor); } public class Hayes implements Modem { @Override public void accept(ModemVisitor modemVisitor) { if (modemVisitor instanceof HayesVisitor) { ((HayesVisitor) modemVisitor).visit(this); } else { System.out.println(\u0026#34;Only HayesVisitor is allowed to visit Hayes modem\u0026#34;); } } } public class Zoom implements Modem { @Override public void accept(ModemVisitor modemVisitor) { if (modemVisitor instanceof ZoomVisitor) { ((ZoomVisitor) modemVisitor).","title":"Java设计模式：Acyclic Visitor"},{"content":" Python .whl 文件或 wheels 是 Python 中很少被讨论的部分，但它们对 Python 包的安装过程大有裨益。如果您使用 pip 安装了 Python 包，那么 Wheels 很可能使安装更快、更高效。\nWheels 是 Python 生态系统的一个组件，有助于使包安装正常工作。它们允许更快的安装和更稳定的包分发过程。在本教程中，您将深入了解 Wheels 是什么，它们有什么好处，以及它们如何获得牵引力并使 Python 使用起来更加愉快。\n在本教程中，您将学习：\n什么是 Wheels 以及它们与源代码分发的比较 如何使用 Wheels 来控制包安装过程 如何为您自己的 Python 包创建和分发 Wheels 您将从用户和开发人员的角度看到使用流行的开源 Python 包的示例。\n免费赠品：单击此处获取 Python 备忘单并学习 Python 3 的基础知识，例如使用数据类型、字典、列表和 Python 函数。\n安装 接下来，激活虚拟环境并确保安装了最新版本的 pip 、 wheel 和 setuptools ：\n$ python -m venv env \u0026amp;\u0026amp; source ./env/bin/activate $ python -m pip install -U pip wheel setuptools Successfully installed pip 20.1 setuptools-46.1.3 wheel-0.34.2 这就是您尝试安装和构建 Wheels 所需的全部内容！\nPython 打包变得更好：Python Wheels 简介 在学习如何将项目打包到 wheel 之前，从用户的角度了解使用 wheel 的样子会很有帮助。这听起来可能有点落后，但了解 Wheels 如何工作的一个好方法是从安装一个不是 Wheels 的东西开始。\n您可以像往常一样，通过将 Python 包安装到您的环境中来开始这个实验。在这种情况下，安装 uWSGI 版本 2.0.x：\n$ python -m pip install \u0026#39;uwsgi==2.0.*\u0026#39; Collecting uwsgi==2.0.* Downloading uwsgi-2.0.18.tar.gz (801 kB) |████████████████████████████████| 801 kB 1.1 MB/s Building wheels for collected packages: uwsgi Building wheel for uwsgi (setup.py) ... done Created wheel for uwsgi ... uWSGI-2.0.18-cp38-cp38-macosx_10_15_x86_64.whl Stored in directory: /private/var/folders/jc/8_hqsz0x1tdbp05 ... Successfully built uwsgi Installing collected packages: uwsgi Successfully installed uwsgi-2.0.18 为了完全安装 uWSGI， pip 通过几个不同的步骤进行：\n在第 3 行，它下载了一个名为 uwsgi-2.0.18.tar.gz 的 TAR 文件 (tarball)，该文件已使用 gzip 压缩。\n在第 6 行，它获取 tarball 并通过调用 setup.py 构建一个 .whl 文件。\n在第 7 行，它将 wheel 标记为 uWSGI-2.0.18-cp38-cp38-macosx_10_15_x86_64.whl 。\n在第 10 行，它在构建 wheel 后安装实际的包。\npip 检索到的 tar.gz tarball 是源代码分发版或 sdist ，而不是 wheel。在某些方面， sdist 与 wheel 相反。\n注意：如果您看到 uWSGI 安装错误，您可能需要安装 Python 开发头文件。\n源代码分发包含源代码。这不仅包括 Python 代码，还包括与包捆绑在一起的任何扩展模块（通常是 C 或 C++）的源代码。对于源代码分发，扩展模块是在用户端而不是开发人员端编译的。\n源分发版还包含一组元数据，位于名为 \u0026lt;package-name\u0026gt;.egg-info 的目录中。此元数据有助于构建和安装包，但用户实际上不需要对其执行任何操作。\n从开发人员的角度来看，源代码分发是在您运行以下命令时创建的：\n$ python setup.py sdist 现在尝试安装不同的包 chardet：\n$ python -m pip install \u0026#39;chardet==3.*\u0026#39; Collecting chardet Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB) |████████████████████████████████| 133 kB 1.5 MB/s Installing collected packages: chardet Successfully installed chardet-3.0.4 您可以看到与 uWSGI 安装明显不同的输出。\n安装 chardet 会直接从 PyPI 下载一个 .whl 文件。 Wheels 名称 chardet-3.0.4-py2.py3-none-any.whl 遵循您稍后将看到的特定命名约定。从用户的角度来看，更重要的是当 pip 在 PyPI 上找到兼容的 wheel 时，没有构建阶段。\n从开发人员的角度来看，wheel 是运行以下命令的结果：\n$ python setup.py bdist_wheel 为什么 uWSGI 给你一个源代码分发而 chardet 提供一个 wheel？您可以通过查看 PyPI 上每个项目的页面并导航到下载文件区域来了解其原因。本节将向您展示 pip 在 PyPI 索引服务器上实际看到的内容：\n出于与项目复杂性相关的原因，uWSGI 仅提供了一个源代码分发（ uwsgi-2.0.18.tar.gz ）。\nchardet 提供了 wheel 和源代码分发，但如果它与您的系统兼容， pip 会更喜欢 wheel。稍后您将看到如何确定兼容性。\n用于 wheel 安装的兼容性检查的另一个示例是 psycopg2 ，它为 Windows 提供了广泛的 wheels，但不为 Linux 或 macOS 客户端提供任何 wheels。这意味着 pip install psycopg2 可以根据您的特定设置获取 Wheels 或源代码分发。\n为了避免这些类型的兼容性问题，一些包提供了多个 wheels，每个 wheels 都针对特定的 Python 实现和底层操作系统。\n到目前为止，您已经看到了 wheel 和 sdist 之间的一些明显区别，但更重要的是这些差异对安装过程的影响。\nWheels 让事情变得快速 在上面，您看到了获取预制 wheels 的安装与下载 sdist 的安装的比较。 Wheels 使 Python 包的端到端安装更快，原因有二：\n在其他条件相同的情况下，wheels 的尺寸通常比源分发小，这意味着它们可以在网络中更快地移动。 直接从 wheels 安装避免了从源分发构建包的中间步骤。 几乎可以保证 chardet 安装只用了 uWSGI 所需时间的一小部分。然而，这可以说是一个不公平的苹果与橘子的比较，因为 chardet 是一个小得多且不那么复杂的包。\n使用不同的命令，您可以创建更直接的比较，以证明 wheels 的差异有多大。\n您可以通过传递 --no-binary 选项让 pip 忽略它对 wheels 的倾斜：\n$ time python -m pip install \\ --no-cache-dir \\ --force-reinstall \\ --no-binary=:all: \\ cryptography 此命令计时 cryptography 包的安装，告诉 pip 使用源代码分发，即使有合适的 Wheels 可用。包含 :all: 会使规则适用于 cryptography 及其所有依赖项。\n在我的机器上，这从开始到结束大约需要 32 秒。不仅安装需要很长时间，而且构建 cryptography 还需要您拥有 OpenSSL 开发标头并可供 Python 使用。\n注意：对于 --no-binary ，您很可能会看到有关缺少 cryptography 安装所需的头文件的错误，这是使用源代码分发令人沮丧的部分原因。如果是这样， cryptography 文档的安装部分会就特定操作系统需要哪些库和头文件提供建议。\n现在您可以重新安装 cryptography ，但这次要确保 pip 使用 PyPI 的 Wheels 。因为 pip 更喜欢 Wheels ，这类似于不带任何参数调用 pip install 。但在这种情况下，您可以通过要求带有 --only-binary 的 Wheels 来明确意图：\n$ time python -m pip install \\ --no-cache-dir \\ --force-reinstall \\ --only-binary=cryptography \\ cryptography 此选项只需要四秒多一点，或者是仅使用 cryptography 及其依赖项的源代码分发时所用时间的八分之一。\n什么是 Python Wheel？ Python .whl 文件本质上是一个 ZIP ( .zip ) 存档，带有特制的文件名，告诉安装者 Wheels 将支持哪些 Python 版本和平台。\nWheels 是一种内置分发。在这种情况下，built 意味着 wheel 以可立即安装的格式出现，并允许您跳过源代码分发所需的构建阶段。\n注意：值得一提的是，尽管使用了术语构建，但 Wheels 不包含 .pyc 文件或编译的 Python 字节码。\nwheel 文件名被分成由连字符分隔的部分：\n{dist}-{version}(-{build})?-{python}-{abi}-{platform}.whl {brackets} 中的每个部分都是一个标签，或者是 wheel 名称的一个组成部分，它带有一些关于 wheel 包含的内容以及 wheel 将在何处工作或不工作的含义。\n这是一个使用 cryptography Wheels 的说明性示例：\ncryptography-2.9.2-cp35-abi3-macosx_10_9_x86_64.whl cryptography 分配多个 Wheels 。每个 Wheels 都是一个平台 Wheels ，这意味着它仅支持 Python 版本、Python ABI、操作系统和机器架构的特定组合。您可以将命名约定分解为多个部分：\ncryptography 是包名。 2.9.2 是 cryptography 的包版本。版本是符合 PEP 440 的字符串，例如 2.9.2 、 3.4 或 3.9.0.a3 。 cp35 是 Python 标签，表示 Wheels 需要的 Python 实现和版本。 cp 代表 CPython，Python 的参考实现，而 35 代表 Python 3.5。例如，这个 Wheels 与 Jython 不兼容。 abi3 是 ABI 标签。 ABI 代表应用程序二进制接口。你真的不需要担心它需要什么，但是 abi3 是一个单独的版本，用于 Python C API 的二进制兼容性。 macosx_10_9_x86_64 是平台标签，正好比较啰嗦。在这种情况下，它可以进一步细分为子部分： macosx 是 macOS 操作系统。 10_9 是用于编译 Python 的 macOS 开发人员工具 SDK 版本，而 Python 又构建了这个 Wheels 。 x86_64 是对 x86-64 指令集架构的引用。 最后一个组件在技术上不是标签，而是标准的 .whl 文件扩展名。组合起来，上述组件表明此 cryptography Wheels 设计的目标机器。\n现在让我们转向另一个例子。以下是您在上述 chardet 案例中看到的内容：\nchardet-3.0.4-py2.py3-none-any.whl 您可以将其分解为标签：\nchardet 是包名。 3.0.4 是 chardet 的包版本。 py2.py3 是 Python 标签，这意味着 Wheels 支持 Python 2 和 3 以及任何 Python 实现。 none 是 ABI 标签，意味着 ABI 不是一个因素。 any 是平台。这个 Wheels 几乎可以在任何平台上运行。 Wheels 名称的 py2.py3-none-any.whl 段很常见。这是一个万能 Wheels ，可以在具有任何 ABI 的任何平台上与 Python 2 或 3 一起安装。如果 Wheels 以 none-any.whl 结尾，那么它很可能是一个不关心特定 Python ABI 或 CPU 架构的纯 Python 包。\n另一个例子是 jinja2 模板引擎。如果您导航到 Jinja 3.x alpha 版本的下载页面，您将看到以下 Wheels ：\nJinja2-3.0.0a1-py3-none-any.whl 注意这里缺少 py2 。这是一个纯 Python 项目，可以在任何 Python 3.x 版本上运行，但它不是万能 Wheels ，因为它不支持 Python 2。相反，它被称为纯 Python Wheels 。\n注意：在 2020 年，许多项目也放弃了对 Python 2 的支持，Python 2 于 2020 年 1 月 1 日达到生命周期结束 (EOL)。Jinja 版本 3.x 于 2020 年 2 月放弃了对 Python 2 的支持。\n以下是为一些流行的开源包分发的 .whl 名称的更多示例：\nWheel What It Is 这是什么 PyYAML-5.3.1-cp38-cp38-win_amd64.whl PyYAML for CPython 3.8 on Windows with AMD64 (x86-64) architecture numpy-1.18.4-cp38-cp38-win32.whl NumPy for CPython 3.8 on Windows 32-bit scipy-1.4.1-cp36-cp36m-macosx_10_6_intel.whl SciPy for CPython 3.6 on macOS 10.6 SDK with fat binary (multiple instruction sets) 现在您已经彻底了解什么是 Wheels ，是时候谈谈它们有什么好处了。\nWheels 的优势 这是来自 Python Packaging Authority (PyPA) 的 wheels 证明：\n并非所有开发人员都有正确的工具或经验来构建这些用这些编译语言编写的组件，因此 Python 创造了 wheel，这是一种旨在运送带有编译工件的库的包格式。事实上，Python 的包安装程序 pip 总是更喜欢 wheel，因为安装总是更快，所以即使是纯 Python 包也能更好地使用 wheel。 （ 来源）\n更完整的描述是，wheels 在以下几个方面使 Python 包的用户和维护者都受益：\n对于纯 Python 包和扩展模块，Wheels 的安装速度比源代码分发快。 Wheels 比源分布小。例如， six Wheels 大约是相应源分布大小的三分之一。当您考虑到单个包的 pip install 实际上可能会开始下载依赖项链时，这种差异变得更加重要。 Wheels 将 setup.py 执行排除在外。从源分发版安装会运行该项目的 setup.py 中包含的任何内容。正如 PEP 427 所指出的，这相当于任意代码执行。 Wheels 完全避免了这种情况。 编译器不需要安装包含已编译扩展模块的 Wheels 。扩展模块包含在针对特定平台和 Python 版本的 wheel 中。 pip 自动在 wheel 中生成与正确的 Python 解释器匹配的 .pyc 文件。 Wheels 通过减少安装软件包时涉及的许多变量来提供一致性。 您可以使用 PyPI 上项目的下载文件选项卡来查看可用的不同发行版。例如，pandas 分发了各种各样的 Wheels 。\n告诉 pip 要下载什么 可以对 pip 进行细粒度控制并告诉它首选或避免哪种格式。您可以使用 --only-binary 和 --no-binary 选项来执行此操作。您在前面有关安装 cryptography 包的部分中看到了它们的使用，但值得仔细研究一下它们的作用：\n$ pushd \u0026#34;$(mktemp -d)\u0026#34; $ python -m pip download --only-binary :all: --dest . --no-cache six Collecting six Downloading six-1.14.0-py2.py3-none-any.whl (10 kB) Saved ./six-1.14.0-py2.py3-none-any.whl Successfully downloaded six 在此示例中，您更改为一个临时目录以存储带有 pushd \u0026quot;$(mktemp -d)\u0026quot; 的下载。您使用 pip download 而不是 pip install 以便您可以检查生成的 Wheels ，但您可以将 download 替换为 install 同时保持相同的选项集。\n您下载带有几个标志的 six 模块：\n--only-binary :all: 告诉 pip 限制自己使用 Wheels 并忽略源代码分发。如果没有这个选项， pip 只会更喜欢 Wheels ，但在某些情况下会退回到源代码分发。 --dest . 告诉 pip 将 six 下载到当前目录。 --no-cache 告诉 pip 不要查看其本地下载缓存。你使用这个选项只是为了说明从 PyPI 的实时下载，因为你可能在某处有一个 six 缓存。 我之前提到过，wheel 文件本质上是一个 .zip 存档。你可以从字面上理解这个陈述，并这样对待 Wheels 。例如，如果你想查看一个 Wheels 的内容，你可以使用 unzip ：\n$ unzip -l six*.whl Archive: six-1.14.0-py2.py3-none-any.whl Length Date Time Name --------- ---------- ----- ---- 34074 01-15-2020 18:10 six.py 1066 01-15-2020 18:10 six-1.14.0.dist-info/LICENSE 1795 01-15-2020 18:10 six-1.14.0.dist-info/METADATA 110 01-15-2020 18:10 six-1.14.0.dist-info/WHEEL 4 01-15-2020 18:10 six-1.14.0.dist-info/top_level.txt 435 01-15-2020 18:10 six-1.14.0.dist-info/RECORD --------- ------- 37484 6 files six 是一个特例：它实际上是一个单独的 Python 模块，而不是一个完整的包。 Wheel 文件也可以复杂得多，稍后您将看到。\n与 --only-binary 相反，你可以使用 --no-binary 来做相反的事情：\n$ python -m pip download --no-binary :all: --dest . --no-cache six Collecting six Downloading six-1.14.0.tar.gz (33 kB) Saved ./six-1.14.0.tar.gz Successfully downloaded six $ popd 此示例中的唯一更改是切换到 --no-binary :all: 。这告诉 pip 忽略 Wheels ，即使它们可用，而是下载源分发。\n--no-binary 什么时候有用？以下是几个案例：\n对应的 Wheels 坏了。这是对 Wheels 的讽刺。它们旨在减少故障的发生，但在某些情况下， Wheels 可能会配置错误。在这种情况下，为自己下载和构建源代码分发可能是一个可行的选择。 您想要对项目应用一个小的更改或补丁文件，然后安装它。这是从版本控制系统 URL 克隆项目的替代方法。 您还可以将上述标志与 pip install 一起使用。此外，与 :all: 不同， --only-binary 规则不仅适用于您正在安装的包，还适用于它的所有依赖项，您可以传递特定包的列表 --only-binary 和 --no-binary 来应用该规则规则到。\n下面是几个安装 URL 库 yarl 的例子。它包含 Cython 代码并依赖于 multidict ，其中包含纯 C 代码。有几个选项可以严格使用或严格忽略 yarl 及其依赖项的 Wheels ：\n$ # Install `yarl` and use only wheels for yarl and all dependencies $ python -m pip install --only-binary :all: yarl $ # Install `yarl` and use wheels only for the `multidict` dependency $ python -m pip install --only-binary multidict yarl $ # Install `yarl` and don\u0026#39;t use wheels for yarl or any dependencies $ python -m pip install --no-binary :all: yarl $ # Install `yarl` and don\u0026#39;t use wheels for the `multidict` dependency $ python -m pip install --no-binary multidict yarl 在本节中，您大致了解了如何微调 pip install 将使用的分发类型。虽然常规的 pip install 应该没有任何选项，但了解这些用于特殊情况的选项会很有帮助。\nWheel manylinux 标签 Linux 有许多变体和风格，例如 Debian、CentOS、Fedora 和 Pacman。其中每一个都可能在共享库（例如 libncurses ）和核心 C 库（例如 glibc ）中使用细微的变化。\n如果您正在编写 C/C++ 扩展，那么这可能会产生问题。用 C 编写并在 Ubuntu Linux 上编译的源文件不能保证在 CentOS 机器或 Arch Linux 发行版上可执行。\n您是否需要为每个 Linux 变体构建一个单独的 Wheels ？\n幸运的是，答案是否定的，这要归功于一组专门设计的标签，称为 manylinux 平台标签系列。目前有以下三种变体：\nmanylinux1 是 PEP 513 中指定的原始格式。 manylinux2010 是 PEP 571 中指定的更新，它升级到 CentOS 6 作为 Docker 镜像所基于的底层操作系统。理由是 CentOS 5.11，即 manylinux1 中允许的库列表的来源，于 2017 年 3 月达到 EOL 并停止接收安全补丁和错误修复。 manylinux2014 是 PEP 599 中指定的升级到 CentOS 7 的更新，因为 CentOS 6 计划于 2020 年 11 月达到 EOL。 您可以在 pandas 项目中找到 manylinux 分布的示例。以下是 PyPI 的可用 pandas 下载列表中的两个（最多的）：\npandas-1.0.3-cp37-cp37m-manylinux1_x86_64.whl pandas-1.0.3-cp37-cp37m-manylinux1_i686.whl 在这种情况下，pandas 为支持 x86-64 和 i686 架构的 CPython 3.7 构建了 manylinux1 wheels。\nmanylinux 的核心是基于特定版本的 CentOS 操作系统构建的 Docker 镜像。它捆绑了一个编译器套件、多个版本的 Python 和 pip ，以及一组允许的共享库。\n注意：术语 allowed 表示默认情况下假定存在于几乎所有 Linux 系统上的低级库。这个想法是，依赖项应该存在于基本操作系统上，而不需要额外安装。\n截至 2020 年年中， manylinux1 仍然是主要的 manylinux 标签。原因之一可能只是习惯。另一个可能是客户端（用户）端对 manylinux2010 及更高版本的支持仅限于更新版本的 pip ：\nTag Requirement manylinux1 pip 8.1.0 或更高版本 manylinux2010 pip 19.0 或更高版本 manylinux2014 pip 19.3 或更高版本 换句话说，如果您是构建 manylinux2010 wheels 的包开发人员，那么使用您的包的人将需要 pip 19.0（2019 年 1 月发布）或更高版本才能让 pip 从 PyPI 找到并安装 manylinux2010 wheels .\n幸运的是，虚拟环境变得越来越普遍，这意味着开发人员可以在不接触系统 pip 的情况下更新虚拟环境的 pip 。然而，情况并非总是如此，一些 Linux 发行版仍然附带 pip 的过时版本。\n这就是说，如果您要在 Linux 主机上安装 Python 包，那么如果包维护者不遗余力地创建 manylinux Wheels ，您就认为自己很幸运。这几乎可以保证无论您的特定 Linux 变体或版本如何，都可以轻松安装软件包。\n警告：请注意 PyPI wheels 不能在 Alpine Linux（或 BusyBox）上运行。这是因为 Alpine 使用 musl 代替标准的 glibc 。 musl libc 库自称是“一个新的 libc ，力求快速、简单、轻量级、免费和正确”。不幸的是，说到 Wheels ， glibc 不是。\n平台 Wheels 的安全注意事项 从用户安全的角度来看，wheels 的一个值得考虑的特性是 wheels 可能会受到版本腐烂的影响，因为它们捆绑了二进制依赖项，而不是允许系统包管理器更新该依赖项。\n例如，如果一个 wheel 合并了 libfortran 共享库，那么即使您使用包管理器（如 @ 3#、 yum 或 brew 。\n如果您在安全防范措施得到加强的环境中进行开发，则需要注意某些平台 Wheels 的这一特性。\n召集所有开发人员：构建您的 Wheels 本教程的标题是“你为什么要关心？”作为一名开发人员，如果您打算向社区分发 Python 包，那么您应该非常关心为您的项目分发 Wheels ，因为它们使最终用户的安装过程更简洁、更简单。\n您可以使用兼容的 Wheels 支持的目标平台越多，您看到的标题为“安装在 XYZ 平台上损坏”之类的 GitHub 问题就越少。为您的 Python 包分发 wheel 客观上降低了包的用户在安装过程中遇到问题的可能性。\n要在本地构建 Wheels ，您需要做的第一件事是安装 wheel 。确保 setuptools 也是最新的也没什么坏处：\n$ python -m pip install -U wheel setuptools 接下来的几节将引导您完成为各种不同场景构建 Wheels 的过程。\n不同类型的 Wheels 正如本教程中提到的， Wheels 有几种不同的变体， Wheels 的类型反映在它的文件名中：\n万向 Wheels 包含 py2.py3-none-any.whl 。它在任何操作系统和平台上都支持 Python 2 和 Python 3。 Python Wheels 网站上列出的大多数 Wheels 都是通用 Wheels 。 纯 Python Wheels 包含 py3-none-any.whl 或 py2.none-any.whl 。它支持 Python 3 或 Python 2，但不支持两者。它在其他方面与万向 Wheels 相同，但它会标有 py2 或 py3 而不是 py2.py3 标签。 平台 Wheels 支持特定的 Python 版本和平台。它包含指示特定 Python 版本、ABI、操作系统或体系结构的段。 wheel 类型之间的差异取决于它们支持的 Python 版本以及它们是否针对特定平台。以下是 Wheels 变体之间差异的简要总结：\nWheel Type 支持 Python 2 和 3 支持每个 ABI、操作系统和平台 Universal ✓ ✓ Pure-Python ✓ Platform 正如您接下来将看到的，您可以通过相对较少的设置构建通用 Wheels 和纯 Python Wheels ，但平台 Wheels 可能需要一些额外的步骤。\n构建一个纯 Python Wheels 您可以使用 setuptools 为任何项目构建纯 Python Wheels 或通用 Wheels ，只需一个命令：\n$ python setup.py sdist bdist_wheel 这将创建一个源代码分发 ( sdist ) 和一个 Wheels ( bdist_wheel )。默认情况下，两者都会放在当前目录下的 dist/ 中。要亲眼看看，您可以为 HTTPie 构建一个 Wheels ，一个用 Python 编写的命令行 HTTP 客户端，以及一个 sdist 。\n下面是为 HTTPie 包构建两种类型的发行版的结果：\n$ git clone -q git@github.com:jakubroztocil/httpie.git $ cd httpie $ python setup.py -q sdist bdist_wheel $ ls -1 dist/ httpie-2.2.0.dev0-py3-none-any.whl httpie-2.2.0.dev0.tar.gz 仅此而已。您克隆该项目，移至其根目录，然后调用 python setup.py sdist bdist_wheel 。您可以看到 dist/ 包含一个 Wheels 和一个源代码分发。\n默认情况下，生成的分布放在 dist/ 中，但您可以使用 -d / --dist-dir 选项更改它。您可以将它们放在一个临时目录中，而不是用于构建隔离：\n$ tempdir=\u0026#34;$(mktemp -d)\u0026#34; # Create a temporary directory $ file \u0026#34;$tempdir\u0026#34; /var/folders/jc/8_kd8uusys7ak09_lpmn30rw0000gk/T/tmp.GIXy7XKV: directory $ python setup.py sdist -d \u0026#34;$tempdir\u0026#34; $ python setup.py bdist_wheel --dist-dir \u0026#34;$tempdir\u0026#34; $ ls -1 \u0026#34;$tempdir\u0026#34; httpie-2.2.0.dev0-py3-none-any.whl httpie-2.2.0.dev0.tar.gz 您可以将 sdist 和 bdist_wheel 步骤合二为一，因为 setup.py 可以采用多个子命令：\n$ python setup.py sdist -d \u0026#34;$tempdir\u0026#34; bdist_wheel -d \u0026#34;$tempdir\u0026#34; 如此处所示，您需要将 -d 等选项传递给每个子命令。\n指定通用 Wheel 通用 Wheels 是用于同时支持 Python 2 和 3 的纯 Python 项目的 Wheels 。有多种方法可以告诉 setuptools 和 distutils Wheels 应该是通用的。\n选项 1 是在项目的 setup.cfg 文件中指定选项：\n[bdist_wheel] universal = 1 选项 2 是在命令行传递恰当命名的 --universal 标志：\n$ python setup.py bdist_wheel --universal 选项 3 是使用其 options 参数告诉 setup() 本身有关该标志的信息：\n# setup.py from setuptools import setup setup( # .... options={\u0026#34;bdist_wheel\u0026#34;: {\u0026#34;universal\u0026#34;: True}} # .... ) 虽然这三个选项中的任何一个都应该有效，但前两个选项最常用。您可以在 chardet 设置配置中看到这样的示例。之后，您可以使用 bdist_wheel 命令，如前所示：\n$ python setup.py sdist bdist_wheel 无论您选择哪个选项，生成的 Wheels 都是等效的。选择在很大程度上取决于开发人员的偏好以及最适合您的工作流程。\n构建平台 Wheels （macOS 和 Windows） 二进制发行版是包含已编译扩展的构建发行版的子集。扩展是非 Python 依赖项或 Python 包的组件。\n通常，这意味着您的包包含扩展模块或依赖于用静态类型语言（例如 C、C++、Fortran，甚至 Rust 或 Go）编写的库。平台 Wheels 的存在主要是因为它们包含或依赖于扩展模块。\n综上所述，是时候构建平台 Wheels 了！\n根据您现有的开发环境，您可能需要完成一个或两个额外的先决条件步骤来构建平台 Wheels 。下面的步骤将帮助您设置构建 C 和 C++ 扩展模块，这是迄今为止最常见的类型。\n在 macOS 上，您需要通过 xcode 获得的命令行开发人员工具：\n$ xcode-select --install 在 Windows 上，您需要安装 Microsoft Visual C++：\n在浏览器中打开 Visual Studio 下载页面。 选择 Visual Studio 工具 → Visual Studio 构建工具 → 下载。 运行生成的 .exe 安装程序。 在安装程序中，选择 C++ Build Tools → Install。 重新启动机器。 在 Linux 上，您需要一个编译器，例如 gcc 或 g++ / c++ 。\n有了这些，您就可以为 UltraJSON ( ujson ) 构建一个平台 Wheels ，UltraJSON 是一个用纯 C 语言编写并带有 Python 3 绑定的 JSON 编码器和解码器。使用 ujson 是一个很好的玩具示例，因为它涵盖了几个基础：\n它包含一个扩展模块， ujson 。 它依赖于 Python 开发标头进行编译 ( #include \u0026lt;Python.h\u0026gt; )，但并不过分复杂。 ujson 旨在做一件事并且做好，就是读写 JSON！ 您可以从 GitHub 克隆该项目，导航到其目录并构建它：\n$ git clone -q --branch 2.0.3 git@github.com:ultrajson/ultrajson.git $ cd ultrajson $ python setup.py bdist_wheel 您应该会看到大量输出。这是 macOS 上的精简版，其中使用了 Clang 编译器驱动程序：\nclang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g ... ... creating \u0026#39;dist/ujson-2.0.3-cp38-cp38-macosx_10_15_x86_64.whl\u0026#39; adding \u0026#39;ujson.cpython-38-darwin.so\u0026#39; 以 clang 开头的行显示了对编译器的实际调用，其中包含大量编译标志。您可能还会看到诸如 MSVC (Windows) 或 gcc (Linux) 之类的工具，具体取决于操作系统。\n如果在执行上述代码后遇到 fatal error ，请不要担心。您可以展开下面的框以了解如何处理此问题。\nsetup.py bdist_wheel 对 ujson 的调用需要 Python 开发头文件，因为 ujson.c 引入了 \u0026lt;Python.h\u0026gt; 。如果您没有将它们放在可搜索的位置，那么您可能会看到如下错误：\nfatal error: \u0026#39;Python.h\u0026#39; file not found #include \u0026lt;Python.h\u0026gt; 要编译扩展模块，您需要将开发标头保存在编译器可以找到的地方。\n如果您使用的是最新版本的 Python 3 和虚拟环境工具（如 venv ），则 Python 开发标头可能会默认包含在编译和链接中。\n如果没有，那么您可能会看到一个错误，表明找不到头文件：\nfatal error: \u0026#39;Python.h\u0026#39; file not found #include \u0026lt;Python.h\u0026gt; 在这种情况下，您可以通过设置 CFLAGS 来告诉 setup.py 还可以在哪里查找头文件。要查找头文件本身，可以使用 python3-config ：\n$ python3-config --include -I/Users/\u0026lt;username\u0026gt;/.pyenv/versions/3.8.2/include/python3.8 这告诉您 Python 开发标头位于显示的目录中，您现在可以将其与 python setup.py bdist_wheel 一起使用：\n$ CFLAGS=\u0026#34;$(python3-config --include)\u0026#34; python setup.py bdist_wheel 更一般地说，您可以传递您需要的任何路径：\n$ CFLAGS=\u0026#39;-I/path/to/include\u0026#39; python setup.py bdist_wheel 在 Linux 上，您可能还需要单独安装头文件：\n$ apt-get install -y python3-dev # Debian, Ubuntu $ yum install -y python3-devel # CentOS, Fedora, RHEL 如果你检查 UltraJSON 的 setup.py ，你会看到它自定义了一些编译器标志，例如 -D_GNU_SOURCE 。通过 setup.py 控制编译过程的复杂性超出了本教程的范围，但您应该知道可以对编译和链接的发生方式进行细粒度控制。\n如果您查看 dist ，那么您应该会看到创建的 Wheels ：\n$ ls dist/ ujson-2.0.3-cp38-cp38-macosx_10_15_x86_64.whl 请注意，名称可能因您的平台而异。例如，您会在 64 位 Windows 上看到 win_amd64.whl 。\n您可以查看 wheel 文件并看到它包含已编译的扩展名：\n$ unzip -l dist/ujson-*.whl ... Length Date Time Name --------- ---------- ----- ---- 105812 05-10-2020 19:47 ujson.cpython-38-darwin.so ... 此示例显示 macOS 的输出， ujson.cpython-38-darwin.so ，这是一个共享对象 ( .so ) 文件，也称为动态库。\n构建 manylinux Wheels 作为软件包开发人员，您很少会希望为单个 Linux 变体构建 Wheels 。 Linux wheels 需要一套专门的约定和工具，以便它们可以跨不同的 Linux 环境工作。\n与 macOS 和 Windows 的 wheel 不同，构建在一个 Linux 变体上的 wheel 不能保证在另一个 Linux 变体上工作，即使是具有相同机器架构的 Linux 变体。\n事实上，如果您在开箱即用的 Linux 容器上构建一个 Wheels ，那么如果您尝试上传它，PyPI 甚至不会接受该 Wheels ！\n如果您希望您的包在一系列 Linux 客户端上可用，那么您需要一个 manylinux Wheels 。 manylinux wheel 是一种特殊类型的平台 wheel，被大多数 Linux 变体接受。它必须在特定环境中构建，并且需要一个名为 auditwheel 的工具来重命名 wheel 文件以表明它是一个 manylinux wheel。\n注意：即使您是从开发人员而不是用户的角度来学习本教程，请确保您在继续本节之前已阅读有关 manylinux wheel 标签的部分。\n构建一个 manylinux Wheels 可以让你瞄准更广泛的用户平台。 PEP 513 指定了一个特定的（和古老的）CentOS 版本，其中包含一系列可用的 Python 版本。 CentOS 和 Ubuntu 或任何其他发行版之间的选择没有任何特殊区别。\n重点是构建环境由一个普通的 Linux 操作系统和一组有限的外部共享库组成，这些共享库对于不同的 Linux 变体是通用的。\n值得庆幸的是，您不必自己执行此操作。 PyPA 提供了一组 Docker 镜像，只需单击几下鼠标即可为您提供此环境：\n选项 1 是从您的开发机器运行 docker 并使用 Docker 卷挂载您的项目，以便它可以在容器文件系统中访问。 选项 2 是使用 CI/CD 解决方案，例如 CircleCI、GitHub Actions、Azure DevOps 或 Travis-CI，这将拉取您的项目并在推送或标记等操作上运行构建。 为不同的 manylinux 风格提供了 Docker 镜像：\nmanylinux Tag Architecture Docker Image manylinux1 x86-64 quay.io/pypa/manylinux1_x86_64 manylinux1 i686 quay.io/pypa/manylinux1_i686 manylinux2010 x86-64 quay.io/pypa/manylinux2010_x86_64 manylinux2010 i686 quay.io/pypa/manylinux2010_i686 manylinux2014 x86-64 quay.io/pypa/manylinux2014_x86_64 manylinux2014 i686 quay.io/pypa/manylinux2014_i686 manylinux2014 aarch64 quay.io/pypa/manylinux2014_aarch64 manylinux2014 ppc64le quay.io/pypa/manylinux2014_ppc64le manylinux2014 s390x quay.io/pypa/manylinux2014_s390x 首先，PyPA 还提供了一个示例存储库 python-manylinux-demo，这是一个用于与 Travis-CI 一起构建 manylinux wheels 的演示项目。\n虽然构建 wheels 作为远程托管 CI 解决方案的一部分很常见，但您也可以在本地构建 manylinux wheels。为此，您需要安装 Docker。 Docker Desktop 适用于 macOS、Windows 和 Linux。\n首先，克隆演示项目：\n$ git clone -q git@github.com:pypa/python-manylinux-demo.git $ cd python-manylinux-demo 接下来，分别为 manylinux1 Docker 镜像和平台定义几个 shell 变量：\n$ DOCKER_IMAGE=\u0026#39;quay.io/pypa/manylinux1_x86_64\u0026#39; $ PLAT=\u0026#39;manylinux1_x86_64\u0026#39; DOCKER_IMAGE 变量是由 PyPA 维护的用于构建 manylinux Wheels 的图像，托管在 Quay.io。平台 ( PLAT ) 是提供给 auditwheel 的必要信息，让它知道要应用哪个平台标签。\n现在您可以拉取 Docker 镜像并在容器中运行 wheel-builder 脚本：\n$ docker pull \u0026#34;$DOCKER_IMAGE\u0026#34; $ docker container run -t --rm \\ -e PLAT=$PLAT \\ -v \u0026#34;$(pwd)\u0026#34;:/io \\ \u0026#34;$DOCKER_IMAGE\u0026#34; /io/travis/build-wheels.sh 这告诉 Docker 在 manylinux1_x86_64 Docker 容器内运行 build-wheels.sh shell 脚本，将 PLAT 作为容器中可用的环境变量传递。由于您使用 -v （或 --volume ）绑定挂载卷，因此容器中生成的 Wheels 现在可以在主机上的 wheelhouse 目录中访问：\n$ ls -1 wheelhouse python_manylinux_demo-1.0-cp27-cp27m-manylinux1_x86_64.whl python_manylinux_demo-1.0-cp27-cp27mu-manylinux1_x86_64.whl python_manylinux_demo-1.0-cp35-cp35m-manylinux1_x86_64.whl python_manylinux_demo-1.0-cp36-cp36m-manylinux1_x86_64.whl python_manylinux_demo-1.0-cp37-cp37m-manylinux1_x86_64.whl python_manylinux_demo-1.0-cp38-cp38-manylinux1_x86_64.whl 在几个简短的命令中，您拥有一组适用于 CPython 2.7 到 3.8 的 manylinux1 Wheels 。一种常见的做法是迭代不同的架构。例如，您可以对 quay.io/pypa/manylinux1_i686 Docker 映像重复此过程。这将构建针对 32 位 (i686) 架构的 manylinux1 Wheels 。\n如果您想更深入地研究造 Wheels ，那么下一步就是向最好的人学习。从 Python Wheels 页面开始，选择一个项目，导航到它的源代码（在 GitHub、GitLab 或 Bitbucket 等地方），然后亲眼看看它是如何构建 Wheels 的。\nPython Wheels 页面上的许多项目都是纯 Python 项目并分发通用 Wheels 。如果您正在寻找更复杂的案例，请留意使用扩展模块的包。这里有两个例子可以激发你的胃口：\nlxml 使用从 manylinux1 Docker 容器中调用的单独构建脚本。 ultrajson 做同样的事情并使用 GitHub Actions 调用构建脚本。 如果您有兴趣构建 manylinux Wheels ，这两个都是著名的项目，它们提供了很好的示例供您学习。\n捆绑共享库 另一个挑战是为依赖于外部共享库的包构建 Wheels 。 manylinux 图像包含一组预筛选的库，例如 libpthread.so.0 和 libc.so.6 。但是，如果您依赖该列表之外的东西怎么办，例如 ATLAS 或 GFortran？\n在这种情况下，有几种解决方案可以解决问题：\nauditwheel 会将外部库捆绑到一个已经构建好的 Wheels 中。 delocate 在 macOS 上做同样的事情。 方便的是， auditwheel 出现在 manylinux Docker 镜像上。使用 auditwheel 和 delocate 只需一个命令。只需告诉他们有关 wheel 文件的信息，他们就会完成剩下的工作：\n$ auditwheel repair \u0026lt;path-to-wheel.whl\u0026gt; # For manylinux $ delocate-wheel \u0026lt;path-to-wheel.whl\u0026gt; # For macOS 这将通过项目的 setup.py 检测所需的外部库，并将它们捆绑到 wheel 中，就好像它们是项目的一部分一样。\n利用 auditwheel 和 delocate 的项目示例是 pycld3 ，它为 Compact Language Detector v3 (CLD3) 提供 Python 绑定。\npycld3 包依赖于 libprotobuf ，它不是一个通常安装的库。如果你查看 pycld3 macOS Wheels 内部，你会看到 libprotobuf.22.dylib 包含在那里。这是一个捆绑到 Wheels 中的动态链接共享库：\n$ unzip -l pycld3-0.20-cp38-cp38-macosx_10_15_x86_64.whl ... 51 04-10-2020 11:46 cld3/__init__.py 939984 04-10-2020 07:50 cld3/_cld3.cpython-38-darwin.so 2375836 04-10-2020 07:50 cld3/.dylibs/libprotobuf.22.dylib --------- ------- 3339279 8 files Wheels 预包装有 libprotobuf 。 .dylib 类似于 Unix .so 文件或 Windows .dll 文件，但我承认我不知道除此之外的具体区别。\nauditwheel 和 delocate 知道包含 libprotobuf 因为 setup.py 通过 libraries 参数告诉他们：\nsetup( # ... libraries=[\u0026#34;protobuf\u0026#34;], # ... ) 这意味着 auditwheel 和 delocate 为用户省去了安装 protobuf 的麻烦，只要他们从具有匹配 Wheels 的平台和 Python 组合进行安装即可。\n如果您要分发的包具有这样的外部依赖项，那么您可以通过使用 auditwheel 或 delocate 来帮您的用户一个忙，让他们省去自己安装依赖项的额外步骤。\n在持续集成中构建 Wheels 在本地机器上构建 Wheels 的替代方法是在项目的 CI 管道中自动构建它们。\n有无数与主要代码托管服务集成的 CI 解决方案。其中包括 Appveyor、Azure DevOps、BitBucket Pipelines、Circle CI、GitLab、GitHub Actions、Jenkins 和 Travis CI，仅举几例。\n本教程的目的不是要判断哪种 CI 服务最适合构建 Wheels ，以及考虑到 CI 支持的发展速度，任何支持哪些容器的 CI 服务列表很快就会过时。\n但是，本节可以帮助您入门。\n如果你正在开发一个纯 Python 包， bdist_wheel 一步是一个幸福的单行：它在很大程度上与你在哪个容器操作系统和平台上构建 Wheels 无关。几乎所有主要的 CI 服务都应该使您能够通过在项目内的特殊 YAML 文件中定义步骤来以简洁的方式执行此操作。\n例如，这是您可以用于 GitHub Actions 的语法：\nname: Python wheels on: release: types: - created jobs: wheels: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Set up Python 3.x uses: actions/setup-python@v2 with: python-version: \u0026#34;3.x\u0026#34; - name: Install dependencies run: python -m pip install --upgrade setuptools wheel - name: Build wheels run: python setup.py bdist_wheel - uses: actions/upload-artifact@v2 with: name: dist path: dist 在此配置文件中，您使用以下步骤构建一个 Wheels ：\n在第 8 行，您指定该作业应在 Ubuntu 机器上运行。 在第 10 行中，您使用 checkout 操作来设置您的项目存储库。 在第 14 行，您告诉 CI 运行器使用最新稳定版本的 Python 3。 在第 21 行中，您请求将生成的 Wheels 作为工件提供，您可以在作业完成后从 UI 下载该工件。 但是，如果您有一个复杂的项目（可能是一个带有 C 扩展或 Cython 代码的项目）并且您正在努力构建一个 CI/CD 管道以自动构建 Wheels ，那么可能会涉及额外的步骤。以下是一些您可以通过示例学习的项目：\nyarl msgpack markupsafe cryptography 许多项目推出了自己的 CI 配置。然而，一些解决方案已经出现，用于减少配置文件中指定的代码量来构建 Wheels 。您可以直接在 CI 服务器上使用 cibuildwheel 工具来减少构建多个平台 Wheels 所需的代码行和配置。还有 multibuild，它提供了一组 shell 脚本，用于协助在 Travis CI 和 AppVeyor 上构建 Wheels 。\n确保你的 Wheels 旋转正确 构建结构正确的 Wheels 可能是一项精细的操作。例如，如果您的 Python 包使用 src 布局而您忘记在 setup.py 中正确指定它，那么生成的 Wheels 可能包含错误位置的目录。\n您可以在 bdist_wheel 之后使用的一项检查是 check-wheel-contents 工具。它查找常见问题，例如包目录结构异常或存在重复文件：\n$ check-wheel-contents dist/*.whl dist/ujson-2.0.3-cp38-cp38-macosx_10_15_x86_64.whl: OK 在本例中， check-wheel-contents 表示带 ujson Wheels 的所有内容都已检出。如果不是， stdout 将显示可能问题的摘要，就像 flake8 之类的 linter。\n另一种确认您构建的 Wheels 是否正确的方法是使用 TestPyPI。首先，您可以在那里上传包：\n$ python -m twine upload \\ --repository-url https://test.pypi.org/legacy/ \\ dist/* 然后，您可以下载相同的包进行测试，就好像它是真实的一样：\n$ python -m pip install \\ --index-url https://test.pypi.org/simple/ \\ \u0026lt;pkg-name\u0026gt; 这允许您通过上传然后下载您自己的项目来测试您的 Wheels 。\n将 Python Wheels 上传到 PyPI 现在是时候上传你的 Python 包了。由于 sdist 和 wheel 默认情况下都放在 dist/ 目录中，您可以使用 twine 工具上传它们，这是一个用于将包发布到 PyPI 的实用程序：\n$ python -m pip install -U twine $ python -m twine upload dist/* 由于默认情况下 sdist 和 bdist_wheel 都输出到 dist/ ，您可以安全地告诉 twine 使用 shell 通配符( dist/* ) 上传 dist/ 下的所有内容。\n结论 了解 Wheels 在 Python 生态系统中扮演的关键角色可以让您作为 Python 包的用户和开发人员的生活更轻松。\n此外，在 Wheels 方面提高你的 Python 素养将帮助你更好地理解安装包时发生了什么，以及在越来越罕见的情况下，该操作何时出错。\n在本教程中，您学习了：\n什么是 Wheels 以及它们与源代码分布的比较 如何使用 Wheels 来控制包安装过程 通用 Wheels 、纯 Python Wheels 和平台 Wheels 之间有什么区别 如何为您自己的 Python 包创建和分发 Wheels 您现在已经从用户和开发人员的角度对 Wheels 有了深入的了解。您完全有能力构建自己的 Wheels ，并使项目的安装过程快速、方便和稳定。\n请参阅下面的部分以获取一些额外的阅读材料，以更深入地了解快速扩展的 wheel 生态系统。\n资源 Python Wheels页面专门跟踪 PyPI 上下载次数最多的 360 个包中对 wheels 的支持。在编写本教程时，采用率非常可观，为 360 分之 331，即 91% 左右。\n已经有许多 Python 增强提案 (PEP) 帮助了 wheel 格式的规范和发展：\nPEP 425 - Compatibility Tags for Built Distributions PEP 427 - The Wheel Binary Package Format 1.0 PEP 491 - The Wheel Binary Package Format 1.9 PEP 513 - A Platform Tag for Portable Linux Built Distributions PEP 571 - The manylinux2010 Platform Tag PEP 599 - The manylinux2014 Platform Tag 以下是本教程中提到的各种 wheel 打包工具的候选清单：\npypa/wheel pypa/auditwheel pypa/manylinux pypa/python-manylinux-demo jwodder/check-wheel-contents matthew-brett/delocate matthew-brett/multibuild joerick/cibuildwheel Python 文档有几篇文章涵盖了 Wheels 和源代码分发：\nGenerating Distribution Archives Creating a Source Distribution 最后，这里有一些来自 PyPA 的更有用的链接：\nPackaging your Project An Overview of Packaging for Python 原文地址：https://realpython.com/python-wheels/\n","permalink":"https://blog.chensoul.cc/posts/2023/06/01/python-wheels/","summary":"Python .whl 文件或 wheels 是 Python 中很少被讨论的部分，但它们对 Python 包的安装过程大有裨益。如果您使用 pip 安装了 Python 包，那么 Wheels 很可能使安装更快、更高效。\nWheels 是 Python 生态系统的一个组件，有助于使包安装正常工作。它们允许更快的安装和更稳定的包分发过程。在本教程中，您将深入了解 Wheels 是什么，它们有什么好处，以及它们如何获得牵引力并使 Python 使用起来更加愉快。\n在本教程中，您将学习：\n什么是 Wheels 以及它们与源代码分发的比较 如何使用 Wheels 来控制包安装过程 如何为您自己的 Python 包创建和分发 Wheels 您将从用户和开发人员的角度看到使用流行的开源 Python 包的示例。\n免费赠品：单击此处获取 Python 备忘单并学习 Python 3 的基础知识，例如使用数据类型、字典、列表和 Python 函数。\n安装 接下来，激活虚拟环境并确保安装了最新版本的 pip 、 wheel 和 setuptools ：\n$ python -m venv env \u0026amp;\u0026amp; source ./env/bin/activate $ python -m pip install -U pip wheel setuptools Successfully installed pip 20.1 setuptools-46.1.3 wheel-0.34.2 这就是您尝试安装和构建 Wheels 所需的全部内容！\nPython 打包变得更好：Python Wheels 简介 在学习如何将项目打包到 wheel 之前，从用户的角度了解使用 wheel 的样子会很有帮助。这听起来可能有点落后，但了解 Wheels 如何工作的一个好方法是从安装一个不是 Wheels 的东西开始。\n您可以像往常一样，通过将 Python 包安装到您的环境中来开始这个实验。在这种情况下，安装 uWSGI 版本 2.0.x：\n$ python -m pip install \u0026#39;uwsgi==2.","title":"[译]什么是 Python Wheels，你为什么要关心它？"},{"content":" Python 的标准包管理器是 pip 。它允许您安装和管理不属于 Python 标准库的包。如果您正在寻找 pip 的介绍，那么您来对地方了！\n在本教程中，您将学习如何：\n在您的工作环境中设置 pip 修复与使用 pip 相关的常见错误 使用 pip 安装和卸载包 使用需求文件管理项目的依赖关系 pip 可以做很多事情，但是 Python 社区非常活跃，已经创建了一些 pip 的巧妙替代品。您将在本教程的后面部分了解这些内容。\n从 pip 开始 那么，pip 具体是做什么的呢？ pip 是 Python 的包管理器。这意味着它是一个允许您安装和管理未作为标准库的一部分分发的库和依赖项的工具。 pip 这个名字是由 Ian Bicking 在 2008 年引入的：\n我已经将 pyinstall 重命名为新名称：pip。pip 是 pip install package 首字母缩写。 （ 来源）\n包管理非常重要，Python 的安装程序从 3.4 版和 2.7.9 版开始分别为 Python 3 和 Python 2 包含了 pip 。许多 Python 项目都使用 pip ，这使它成为每个 Pythonista 的必备工具。\n如果您来自另一种编程语言，您可能会熟悉包管理器的概念。 JavaScript 使用 npm 进行包管理，Ruby 使用 gem，.NET 平台使用 NuGet。在 Python 中， pip 已成为标准包管理器。\n在您的系统上查找 pip Python 3 安装程序为您提供了在系统上安装 Python 时安装 pip 的选项。事实上， pip 与 Python 一起安装的选项默认是勾选的，所以 pip 应该在安装完 Python 之后就可以使用了。\n注意：在某些 Linux (Unix) 系统（如 Ubuntu）上， pip 位于一个名为 python3-pip 的单独包中，您需要使用 sudo apt install python3-pip 安装它。默认情况下，它不会随解释器一起安装。\n您可以通过在您的系统上查找 pip3 可执行文件来验证 pip 是否可用。在下面选择您的操作系统并相应地使用您的平台特定命令：\nWindows：\nC:\\\u0026gt; where pip3 Linux + macOS：\n$ which pip3 Linux 系统和 macOS 上的 which 命令显示 pip3 二进制文件所在的位置。\n在 Windows 和 Unix 系统上， pip3 可能位于多个位置。当您安装了多个 Python 版本时，可能会发生这种情况。如果您在系统的任何位置都找不到 pip ，那么您可以考虑重新安装 pip。\n除了直接运行您的系统 pip ，您还可以将其作为 Python 模块运行。在下一节中，您将了解如何操作。\n作为模块运行 pip 当您直接运行系统 pip 时，命令本身不会显示 pip 属于哪个 Python 版本。不幸的是，这意味着您可以在不注意的情况下使用 pip 将包安装到旧 Python 版本的站点包中。为防止这种情况发生，您可以将 pip 作为 Python 模块运行：\n$ python3 -m pip 请注意，您使用 python3 -m 来运行 pip 。 -m 开关告诉 Python 将模块作为 python3 解释器的可执行文件运行。这样，您可以确保系统默认的 Python 3 版本运行 pip 命令。如果您想了解更多关于这种运行 pip 的方式，那么您可以阅读 Brett Cannon 关于使用 python3 -m pip 的优势的有见地的文章。\n有时您可能希望更加明确并将包限制到特定项目。在这种情况下，您应该在虚拟环境中运行 pip 。\n在 Python 虚拟环境中使用 pip 为避免将包直接安装到系统 Python 安装中，您可以使用虚拟环境。虚拟环境为您的项目提供独立的 Python 解释器。您在此环境中使用的任何包都将独立于您的系统解释器。\n这意味着您可以将项目的依赖项与其他项目和整个系统分开。\n在虚拟环境中使用 pip 具有三个主要优点。你可以：\n确保您为手头的项目使用正确的 Python 版本 确保在运行 pip 或 pip3 时引用的是正确的 pip 实例 在不影响其他项目的情况下为您的项目使用特定的包版本 Python 3 具有用于创建虚拟环境的内置 venv 模块。此模块可帮助您使用独立的 Python 安装创建虚拟环境。一旦你激活了虚拟环境，你就可以将包安装到这个环境中。\n您安装到一个虚拟环境中的软件包与系统上的所有其他环境隔离开来。\n您可以按照以下步骤创建虚拟环境并验证您是否在新创建的环境中使用 pip 模块：\nWindows：\nC:\\\u0026gt; python -m venv venv C:\\\u0026gt; venv\\Scripts\\activate.bat (venv) C:\\\u0026gt; pip3 --version pip 21.2.3 from ...\\lib\\site-packages\\pip (python 3.10) (venv) C:\\\u0026gt; pip --version pip 21.2.3 from ...\\lib\\site-packages\\pip (python 3.10) Linux + macOS：\n$ python3 -m venv venv $ source venv/bin/activate (venv) $ pip3 --version pip 21.2.3 from .../python3.10/site-packages/pip (python 3.10) (venv) $ pip --version pip 21.2.3 from .../python3.10/site-packages/pip (python 3.10) 在这里，您使用 Python 的内置 venv 模块创建了一个名为 venv 的虚拟环境。然后使用 source 命令激活它。 venv 名称周围的括号 ( () ) 表示您已成功激活虚拟环境。\n最后，您检查激活的虚拟环境中 pip3 和 pip 可执行文件的版本。两者都指向相同的 pip 模块，因此一旦您的虚拟环境被激活，您就可以使用 pip 或 pip3 。\n出现错误时重新安装 pip 当您运行 pip 命令时，在某些情况下您可能会遇到错误。您的特定错误消息将取决于您的操作系统：\nOperating System Error Message Windows 'pip' is not recognized as an internal or external command, operable program or batch file. Linux bash: pip: command not found macOS zsh: command not found: pip 注意：在 pip 命令不起作用时开始任何故障排除之前，您可以尝试使用最后带有 3 的 pip3 命令。\n出现如上所示的错误可能会令人沮丧，因为 pip 对于安装和管理外部包至关重要。 pip 的一些常见问题与此工具在您的系统上的安装方式有关。\n尽管各种系统的错误消息不同，但它们都指向同一个问题：您的系统无法在您的 PATH 变量中列出的位置找到 pip 。在 Windows 上， PATH 是系统变量的一部分。在 macOS 和 Linux 上， PATH 是环境变量的一部分。您可以使用以下命令检查 PATH 变量的内容：\nWindows：\nC:\\\u0026gt; echo %PATH% Linux + macOS：\n$ echo $PATH 此命令的输出将显示磁盘上操作系统查找可执行程序的位置（目录）列表。根据您的系统，位置可以用冒号 ( : ) 或分号 ( ; ) 分隔。\n默认情况下，在安装 Python 或创建虚拟环境后，包含 pip 可执行文件的目录应该出现在 PATH 中。但是，缺少 pip 是一个常见问题。两种支持的方法可以帮助您再次安装 pip 并将其添加到您的 PATH ：\nensurepip 模块 get-pip.py 脚本 ensurepip 模块从 Python 3.4 开始就是标准库的一部分。添加它是为了提供一种直接的方式让您重新安装 pip ，例如，如果您在安装 Python 时跳过它或在某个时候卸载了 pip 。在下面选择您的操作系统并相应地运行 ensurepip ：\nWindows：\nC:\\\u0026gt; python -m ensurepip --upgrade Linux + macOS：\n$ python3 -m ensurepip --upgrade 如果尚未安装 pip ，则此命令会将其安装在您当前的 Python 环境中。如果您处于活动的虚拟环境中，则该命令会将 pip 安装到该环境中。否则，它会在您的系统上全局安装 pip 。 --upgrade 选项确保 pip 版本与 ensurepip 中声明的版本相同。\n注意： ensurepip 模块不访问互联网。 ensurepip 可以安装的最新版本的 pip 是捆绑在您环境的 Python 安装中的版本。例如，使用 Python 3.10.0 运行 ensurepip 将安装 pip 21.2.3。如果你想要更新的 pip 版本，那么你需要先运行 ensurepip 。之后，您可以手动将 pip 更新到其最新版本。\n修复 pip 安装的另一种方法是使用 get-pip.py 脚本。 get-pip.py 文件包含作为编码 ZIP 文件的 pip 的完整副本。您可以直接从 PyPA 引导页面下载 get-pip.py 。一旦你的机器上有了脚本，你就可以像这样运行 Python 脚本：\nWindows：\nC:\\\u0026gt; python get-pip.py Linux + macOS：\n$ python3 get-pip.py 此脚本将在您当前的 Python 环境中安装最新版本的 pip 、 setuptools 和 wheel 。如果只想安装 pip ，则可以将 --no-setuptools 和 --no-wheel 选项添加到命令中。\n如果上述方法都不起作用，那么可能值得尝试为您当前的平台下载最新的 Python 版本。您可以按照 Python 3 安装和设置指南来确保 pip 已正确安装并且可以正常工作。\n使用 pip 安装包 Python 被认为是一种包含电池的语言。这意味着 Python 标准库包含一组广泛的包和模块来帮助开发人员完成他们的编码项目。\n同时，Python 有一个活跃的社区，它贡献了更广泛的包集，可以帮助您满足您的开发需求。这些包发布到 Python 包索引，也称为 PyPI（发音为 Pie Pea Eye）。\n注意：当你安装第三方包时，你必须小心。查看如何评估 Python 包的质量以获得确保您的包值得信赖的完整指南。\nPyPI 拥有广泛的包集合，包括开发框架、工具和库。其中许多包都为 Python 标准库的功能提供了友好的接口。\n使用 Python 包索引 (PyPI) PyPI 托管的众多包之一称为 requests 。 requests 库通过抽象化 HTTP 请求的复杂性来帮助您与 Web 服务交互。您可以在其官方文档站点上了解有关 requests 的所有信息。\n当你想在你的项目中使用 requests 包时，你必须先将它安装到你的环境中。如果你不想把它安装在你的系统 Python site-packages 中，那么你可以先创建一个虚拟环境，如上所示。\n创建虚拟环境并激活它后，命令行提示符会在括号内显示虚拟环境的名称。您从现在开始执行的任何 pip 命令都将在您的虚拟环境中执行。\n要安装包， pip 提供了一个 install 命令。您可以运行它来安装 requests 包：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install requests Linux + macOS：\n(venv) $ python3 -m pip install requests 在此示例中，您运行 pip 和 install 命令，后跟要安装的包的名称。 pip 命令在 PyPI 中查找包，解析其依赖关系，并在当前 Python 环境中安装所有内容，以确保 requests 能够正常工作。\npip install \u0026lt;package\u0026gt; 命令总是寻找最新版本的包并安装它。它还搜索包元数据中列出的依赖项并安装它们以确保包具有所需的所有要求。\n也可以在一个命令中安装多个包：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install rptree codetiming Linux + macOS：\n(venv) $ python3 -m pip install rptree codetiming 通过在 pip install 命令中链接包 rptree 和 codetiming ，您可以同时安装这两个包。您可以向 pip install 命令添加任意数量的包。在这种情况下， requirements.txt 文件可以派上用场。在本教程的后面，您将学习如何使用 requirements.txt 文件一次安装多个包。\n注意：除非包的特定版本号与本教程相关，否则您会注意到版本字符串采用通用形式 x.y.z 。这是一种占位符格式，可以代表 3.1.4 、 2.9 或任何其他版本号。当您继续操作时，终端中的输出将显示您的实际包版本号。\n您可以使用 list 命令显示环境中安装的包及其版本号：\nWindows：\n(venv) C:\\\u0026gt; python -m pip list Package Version ------------------ --------- certifi x.y.z charset-normalizer x.y.z codetiming x.y.z idna x.y.z pip x.y.z requests x.y.z rptree x.y.z setuptools x.y.z urllib3 x.y.z Linux + macOS：\n(venv) $ python3 -m pip list Package Version ------------------ --------- certifi x.y.z charset-normalizer x.y.z idna x.y.z pip x.y.z requests x.y.z setuptools x.y.z urllib3 x.y.z pip list 命令呈现一个表格，显示当前环境中所有已安装的包。上面的输出显示了使用 x.y.z 占位符格式的包的版本。当您在您的环境中运行 pip list 命令时， pip 会显示您为每个包安装的特定版本号。\n现在您已经安装了 requests 及其依赖项，您可以像导入 Python 代码中的任何其他常规包一样导入它。启动交互式 Python 解释器并导入 requests 包：\n\u0026gt;\u0026gt;\u0026gt; import requests \u0026gt;\u0026gt;\u0026gt; requests.__version__ \u0026#34;x.y.z\u0026#34; 启动交互式 Python 解释器后，您导入了 requests 模块。通过调用 requests.__version__ ，您验证了您在虚拟环境中使用了 requests 模块。\n使用自定义包索引 默认情况下， pip 使用 PyPI 来查找包。但 pip 还为您提供了定义自定义包索引的选项。\n当 PyPI 域在您的网络上被阻止或者如果您想要使用非公开可用的包时，将 pip 与自定义索引一起使用会很有帮助。\n有时系统管理员还创建自己的内部包索引，以更好地控制哪些包版本可供公司网络上的 pip 用户使用。\n自定义包索引必须符合 PEP 503 – 简单存储库 API 才能与 pip 一起使用。您可以通过访问 PyPI 简单索引了解这样一个 API（应用程序编程接口）的外观——但请注意，这是一个包含大量难以解析内容的大页面。任何遵循相同 API 的自定义索引都可以使用 --index-url 选项作为目标。除了输入 --index-url ，您还可以使用 -i 速记。\n例如，要从 TestPyPI 包索引安装 rptree 工具，您可以运行以下命令：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install -i https://test.pypi.org/simple/ rptree Linux + macOS：\n(venv) $ python3 -m pip install -i https://test.pypi.org/simple/ rptree 使用 -i 选项，您告诉 pip 查看不同的包索引而不是默认的 PyPI。在这里，您从 TestPyPI 而不是 PyPI 安装 rptree 。您可以使用 TestPyPI 微调 Python 包的发布过程，而不会弄乱 PyPI 上的生产包索引。\n如果需要永久使用替代索引，则可以在 pip 配置文件中设置 index-url 选项。该文件名为 pip.conf ，您可以通过运行以下命令找到它的位置：\nWindows：\n(venv) C:\\\u0026gt; python -m pip config list -vv Linux + macOS：\n(venv) $ python3 -m pip config list -vv 使用 pip config list 命令，您可以列出活动配置。当您设置了自定义配置时，此命令仅输出一些内容。否则，输出为空。这就是加法 --verbose 或 -vv 选项会有所帮助的时候。添加 -vv 时， pip 会向您显示它在何处查找不同的配置级别。\n如果要添加 pip.conf 文件，则可以选择 pip config list -vv 列出的位置之一。带有自定义包索引的 pip.conf 文件如下所示：\n# pip.conf [global] index-url = https://test.pypi.org/simple/ 当你有一个这样的 pip.conf 文件时， pip 将使用定义的 index-url 来查找包。使用此配置，您无需在 pip install 命令中使用 --index-url 选项来指定您只需要可以在 TestPyPI 的简单 API 中找到的包。\n从 GitHub 存储库安装包 您不限于托管在 PyPI 或其他包索引上的包。 pip 还提供了从 GitHub 存储库安装包的选项。但即使包托管在 PyPI 上，如 Real Python 目录树生成器，您也可以选择从其 Git 存储库安装它：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install git+https://github.com/realpython/rptree Linux + macOS：\n(venv) $ python3 -m pip install git+https://github.com/realpython/rptree 使用 git+https 方案，您可以指向包含可安装包的 Git 存储库。您可以通过运行交互式 Python 解释器并导入 rptree 来验证您是否正确安装了包：\n\u0026gt;\u0026gt;\u0026gt; import rptree \u0026gt;\u0026gt;\u0026gt; rptree.__version__ \u0026#34;x.y.z\u0026#34; 启动交互式 Python 解释器后，导入 rptree 模块。通过调用 rptree.__version__ ，您可以验证您正在使用基于虚拟环境的 rptree 模块。\n注意：如果您使用的是 Git 以外的版本控制系统 (VCS)， pip 可以满足您的要求。要了解如何将 pip 与 Mercurial、Subversion 或 Bazaar 一起使用，请查看 pip 文档的 VCS 支持章节。\n如果包未托管在 PyPI 上但具有远程 Git 存储库，则从 Git 存储库安装包会很有帮助。您指向 pip 的远程存储库甚至可以托管在您公司内部网上的内部 Git 服务器上。当您位于防火墙后面或对您的 Python 项目有其他限制时，这会很有用。\n以可编辑模式安装包以简化开发 在您自己的包上工作时，以可编辑模式安装它是有意义的。通过这样做，您可以像在任何其他包中一样使用命令行来处理源代码。典型的工作流程是首先克隆存储库，然后使用 pip 将其作为可编辑包安装在您的环境中：\nWindows：\nC:\\\u0026gt; git clone https://github.com/realpython/rptree C:\\\u0026gt; cd rptree C:\\rptree\u0026gt; python3 -m venv venv C:\\rptree\u0026gt; venv\\Scripts\\activate.bat (venv) C:\\rptree\u0026gt; python -m pip install -e . Linux + macOS：\n$ git clone https://github.com/realpython/rptree $ cd rptree $ python3 -m venv venv $ source venv/bin/activate (venv) $ python3 -m pip install -e . 使用上面的命令，您将 rptree 包安装为可编辑模块。以下是您刚刚执行的操作的逐步细分：\n第 1 行克隆了 rptree 包的 Git 存储库。\n第 2 行将工作目录更改为 rptree/ 。\n第 3 行和第 4 行创建并激活了一个虚拟环境。\n第 5 行将当前目录的内容安装为一个可编辑的包。\n-e 选项是 --editable 选项的简写。当您将 -e 选项与 pip install 一起使用时，您告诉 pip 您想要以可编辑模式安装包。您不使用包名称，而是使用点 ( . ) 将 pip 指向当前目录。\n如果您没有使用 -e 标志， pip 会正常将包安装到您环境的 site-packages/ 文件夹中。当您以可编辑模式安装包时，您将在站点包中创建一个指向本地项目路径的链接：\n~/rptree/venv/lib/python3.10/site-packages/rptree.egg-link 使用带有 -e 标志的 pip install 命令只是 pip install 提供的众多选项之一。您可以查看 pip 文档中的 pip install 示例。在那里，您将学习如何安装包的特定版本或将 pip 指向非 PyPI 的不同索引。\n在下一节中，您将了解需求文件如何帮助您完成 pip 工作流。\n使用需求文件 pip install 命令始终安装包的最新发布版本，但有时您的代码需要特定的包版本才能正常工作。\n您想要创建用于开发和测试应用程序的依赖项和版本的规范，以便在生产中使用该应用程序时不会出现意外。\n固定需求 当您与其他开发人员共享您的 Python 项目时，您可能希望他们使用您正在使用的相同版本的外部包。\n也许某个特定版本的软件包包含您所依赖的新功能，或者您正在使用的软件包版本与以前的版本不兼容。\n这些外部依赖项也称为需求。您经常会发现 Python 项目将其需求固定在名为 requirements.txt 或类似文件的文件中。需求文件格式允许您精确指定应安装哪些包和版本。\n运行 pip help 显示有一个 freeze 命令以需求格式输出已安装的包。您可以使用此命令，将输出重定向到文件以生成需求文件：\nWindows：\n(venv) C:\\\u0026gt; python -m pip freeze \u0026gt; requirements.txt Linux + macOS：\n(venv) $ python3 -m pip freeze \u0026gt; requirements.txt 此命令在您的工作目录中创建一个 requirements.txt 文件，其中包含以下内容：\ncertifi==x.y.z charset-normalizer==x.y.z idna==x.y.z requests==x.y.z urllib3==x.y.z 请记住，上面显示的 x.y.z 是包版本的占位符格式。您的 requirements.txt 文件将包含真实的版本号。\nfreeze 命令将当前安装的包的名称和版本转储到标准输出。您可以将输出重定向到一个文件，稍后您可以使用该文件将您的确切要求安装到另一个系统中。您可以随意命名需求文件。\n但是，广泛采用的约定是将其命名为 requirements.txt 。\n当你想在另一个系统中复制环境时，你可以运行 pip install ，使用 -r 开关来指定需求文件：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install -r requirements.txt Linux + macOS：\n(venv) $ python3 -m pip install -r requirements.txt 在上面的命令中，您告诉 pip 将 requirements.txt 中列出的包安装到您当前的环境中。包版本将匹配 requirements.txt 文件包含的版本约束。您可以运行 pip list 来显示您刚刚安装的包及其版本号：\nWindows：\n(venv) C:\\\u0026gt; python -m pip list Package Version ------------------ --------- certifi x.y.z charset-normalizer x.y.z idna x.y.z pip x.y.z requests x.y.z setuptools x.y.z urllib3 x.y.z Linux + macOS：\n(venv) $ python3 -m pip list Package Version ------------------ --------- certifi x.y.z charset-normalizer x.y.z idna x.y.z pip x.y.z requests x.y.z setuptools x.y.z urllib3 x.y.z 现在您可以分享您的项目了！您可以将 requirements.txt 提交到像 Git 这样的版本控制系统中，并使用它在其他机器上复制相同的环境。但是等等，如果为这些软件包发布新的更新会怎样？\n微调需求 对包的版本和依赖项进行硬编码的问题在于，包会经常更新错误和安全修复程序。您可能希望在更新发布后立即利用这些更新。\n需求文件格式允许您使用比较运算符指定依赖项版本，这为您提供了一些灵活性，以确保更新包，同时仍然定义包的基本版本。\n在您喜欢的编辑器中打开 requirements.txt ，并将相等运算符 ( == ) 转换为大于或等于运算符 ( \u0026gt;= )，如下例所示：\n# requirements.txt certifi\u0026gt;=x.y.z charset-normalizer\u0026gt;=x.y.z idna\u0026gt;=x.y.z requests\u0026gt;=x.y.z urllib3\u0026gt;=x.y.z 您可以将比较运算符更改为 \u0026gt;= 以告知 pip 安装已发布的精确或更高版本。当您使用 requirements.txt 文件设置新环境时， pip 会查找满足要求的最新版本并进行安装。\n接下来，您可以通过运行带有 --upgrade 开关或 -U 简写的 install 命令来升级需求文件中的包：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install -U -r requirements.txt Linux + macOS：\n(venv) $ python3 -m pip install -U -r requirements.txt 如果列出的软件包有新版本可用，则该软件包将被升级。\n在理想的世界中，新版本的包将向后兼容并且永远不会引入新的错误。不幸的是，新版本可能会引入会破坏您的应用程序的更改。为了微调您的需求，需求文件语法支持额外的版本说明符。\n想象一下， requests 的新版本 3.0 已发布，但引入了破坏应用程序的不兼容更改。您可以修改需求文件以防止安装 3.0 或更高版本：\n# requirements.txt certifi==x.y.z charset-normalizer==x.y.z idna==x.y.z requests\u0026gt;=x.y.z, \u0026lt;3.0 urllib3==x.y.z 更改 requests 包的版本说明符可确保不会安装任何大于或等于 3.0 的版本。 pip 文档提供了有关需求文件格式的大量信息，您可以查阅它以了解更多信息。\n分离生产和开发依赖 并非您在应用程序开发期间安装的所有包都是生产依赖项。例如，您可能想要测试您的应用程序，因此您需要一个测试框架。一个流行的测试框架是 pytest 。你想在开发环境中安装它，但不想在生产环境中安装它，因为它不是生产依赖项。\n您创建第二个需求文件 requirements_dev.txt ，以列出用于设置开发环境的其他工具：\n# requirements_dev.txt pytest\u0026gt;=x.y.z 拥有两个需求文件将要求您使用 pip 来安装它们， requirements.txt 和 requirements_dev.txt 。幸运的是， pip 允许您在需求文件中指定其他参数，因此您可以修改 requirements_dev.txt 以同时安装来自生产环境的 requirements.txt 文件中的需求：\n# requirements_dev.txt -r requirements.txt pytest\u0026gt;=x.y.z 请注意，您使用相同的 -r 开关来安装生产 requirements.txt 文件。现在，在您的开发环境中，您只需运行这条命令即可安装所有要求：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install -r requirements_dev.txt Linux + macOS：\n(venv) $ python3 -m pip install -r requirements_dev.txt 因为 requirements_dev.txt 包含 -r requirements.txt 行，所以您不仅要安装 pytest ，还要安装 requirements.txt 的固定要求。在生产环境中，仅安装生产要求就足够了：\nWindows：\n(venv) C:\\\u0026gt; python -m pip install -r requirements.txt Linux + macOS：\n(venv) $ python3 -m pip install -r requirements.txt 使用此命令，您可以安装 requirements.txt 中列出的要求。与您的开发环境相比，您的生产环境不会安装 pytest 。\n为生产环境冷冻需求 您创建了生产和开发需求文件并将它们添加到源代码管理中。这些文件使用灵活的版本说明符来确保您利用依赖项发布的错误修复。\n您还测试了您的应用程序，现在可以将其部署到生产环境中了。\n您知道所有测试都通过了并且应用程序可以使用您在开发过程中使用的依赖项，因此您可能希望确保将相同版本的依赖项部署到生产环境中。\n当前的版本说明符不能保证将相同的版本部署到生产环境中，因此您希望在发布项目之前冻结生产需求。\n根据当前需求完成开发后，创建当前项目新版本的工作流程如下所示：\nStep Command Explanation 1 pytest 运行您的测试并验证您的代码是否正常工作。 2 pip install -U -r requirements.txt 将您的要求升级到与 requirements.txt 文件中的约束相匹配的版本。 3 pytest 运行您的测试并考虑降级任何向您的代码引入错误的依赖项。 4 pip freeze \u0026gt; requirements_lock.txt 项目正常运行后，将依赖项冻结到 requirements_lock.txt 文件中。 使用这样的工作流程， requirements_lock.txt 文件将包含准确的版本说明符，可用于复制您的环境。您已确保当您的用户将 requirements_lock.txt 中列出的软件包安装到他们自己的环境中时，他们将使用您希望他们使用的版本。\n冻结您的需求是确保您的 Python 项目在您的用户环境中以与在您的环境中相同的方式工作的重要步骤。\n使用 pip 卸载软件包 有时，您必须卸载一个包。要么你找到了一个更好的库来替换它，要么它是你不需要的东西。卸载软件包可能有点棘手。\n请注意，当您安装 requests 时，您也获得了 pip 来安装其他依赖项。安装的包越多，多个包依赖相同依赖项的可能性就越大。这就是 pip 中的 show 命令派上用场的地方。\n在卸载包之前，请确保为该包运行 show 命令：\nWindows：\n(venv) C:\\\u0026gt; python -m pip show requests Name: requests Version: 2.26.0 Summary: Python HTTP for Humans. Home-page: https://requests.readthedocs.io Author: Kenneth Reitz Author-email: me@kennethreitz.org License: Apache 2.0 Location: .../python3.9/site-packages Requires: certifi, idna, charset-normalizer, urllib3 Required-by: Linux + macOS：\n(venv) $ python3 -m pip show requests Name: requests Version: 2.26.0 Summary: Python HTTP for Humans. Home-page: https://requests.readthedocs.io Author: Kenneth Reitz Author-email: me@kennethreitz.org License: Apache 2.0 Location: .../python3.9/site-packages Requires: certifi, idna, charset-normalizer, urllib3 Required-by: 注意最后两个字段， Requires 和 Required-by 。 show 命令告诉您 requests 需要 certifi 、 idna 、 charset-normalizer 和 urllib3 。您可能也想卸载它们。请注意， requests 不是任何其他包所必需的。所以卸载它是安全的。\n您应该针对所有 requests 依赖项运行 show 命令，以确保没有其他库也依赖于它们。一旦了解了要卸载的包的依赖顺序，就可以使用 uninstall 命令删除它们：\nWindows：\n(venv) C:\\\u0026gt; python -m pip uninstall certifi Linux + macOS：\n(venv) $ python3 -m pip uninstall certifi uninstall 命令显示将要删除的文件并要求确认。如果您确定要删除该包，因为您已经检查了它的依赖关系并且知道没有其他东西在使用它，那么您可以传递一个 -y 开关来抑制文件列表和确认对话框：\nWindows：\n(venv) C:\\\u0026gt; python -m pip uninstall certifi -y Linux + macOS：\n(venv) $ python3 -m pip uninstall certifi -y 这里卸载 urllib3 。使用 -y 开关，您可以取消询问您是否要卸载此包的确认对话框。\n在一次调用中，您可以指定要卸载的所有包：\nWindows：\n(venv) C:\\\u0026gt; python -m pip uninstall -y charset-normalizer idna requests Linux + macOS：\n(venv) $ python3 -m pip uninstall -y charset-normalizer idna requests 您可以将多个包传递给 pip uninstall 命令。如果您没有添加任何额外的开关，那么您需要确认卸载每个包。通过 -y 开关，您可以在没有任何确认对话框的情况下将它们全部卸载。\n您还可以通过提供 -r \u0026lt;requirements file\u0026gt; 选项来卸载需求文件中列出的所有包。此命令将提示对每个包的确认请求，但您可以使用 -y 开关抑制它：\nWindows：\n(venv) C:\\\u0026gt; python -m pip uninstall -r requirements.txt -y Linux + macOS：\n(venv) $ python3 -m pip uninstall -r requirements.txt -y 请记住始终检查要卸载的软件包的依赖项。您可能想卸载所有依赖项，但卸载其他人使用的包会破坏您的工作环境。因此，您的项目可能无法再正常工作。\n如果您在虚拟环境中工作，那么创建一个新的虚拟环境可能会更省力。然后你可以安装你需要的包而不是尝试卸载你不需要的包。但是，当您需要从系统 Python 安装中卸载包时， pip uninstall 会非常有用。如果您不小心在系统范围内安装了软件包，使用 pip uninstall 是整理系统的好方法。\n探索 pip 的替代品 Python 社区提供了出色的工具和库，供您在 pip 之外使用。这些包括尝试简化和改进包管理的 pip 的替代方案。\n以下是一些可用于 Python 的其他包管理工具：\nTool Description Conda Conda 是许多语言（包括 Python）的包、依赖项和环境管理器。它来自 Anaconda，Anaconda 最初是 Python 的数据科学包。因此，它被广泛用于数据科学和机器学习应用程序。 Conda 运行自己的索引来托管兼容包。 Poetry 如果您来自 JavaScript 和 npm，Poetry 对您来说会非常熟悉。 Poetry 超越了包管理，帮助您为您的应用程序和库构建分发并将它们部署到 PyPI。 Pipenv Pipenv 是另一个包管理工具，它将虚拟环境和包管理合并到一个工具中。 Pipenv：新 Python 打包工具指南是开始学习 Pipenv 及其包管理方法的好地方。 只有 pip 捆绑在标准 Python 安装中。如果您想使用上面列出的任何替代方案，则必须按照其文档中的安装指南进行操作。有这么多选项，您一定会找到适合您的编程之旅的工具！\n结论 许多 Python 项目使用 pip 包管理器来管理它们的依赖项。它包含在 Python 安装程序中，是 Python 中依赖管理的重要工具。\n在本教程中，您学习了如何：\n在您的工作环境中设置并运行 pip 修复与使用 pip 相关的常见错误 使用 pip 安装和卸载包 定义项目和应用程序的要求 在需求文件中固定依赖项 此外，您还了解了使依赖项保持最新的重要性以及可以帮助您管理这些依赖项的 pip 的替代方法。\n通过仔细查看 pip ，您已经探索了 Python 开发工作流中的一个基本工具。使用 pip ，您可以安装和管理您在 PyPI 上找到的任何其他包。您可以使用来自其他开发人员的外部包作为需求，并专注于使您的项目独一无二的代码。\n原文链接：https://realpython.com/what-is-pip\n","permalink":"https://blog.chensoul.cc/posts/2023/06/01/what-is-pip/","summary":"Python 的标准包管理器是 pip 。它允许您安装和管理不属于 Python 标准库的包。如果您正在寻找 pip 的介绍，那么您来对地方了！\n在本教程中，您将学习如何：\n在您的工作环境中设置 pip 修复与使用 pip 相关的常见错误 使用 pip 安装和卸载包 使用需求文件管理项目的依赖关系 pip 可以做很多事情，但是 Python 社区非常活跃，已经创建了一些 pip 的巧妙替代品。您将在本教程的后面部分了解这些内容。\n从 pip 开始 那么，pip 具体是做什么的呢？ pip 是 Python 的包管理器。这意味着它是一个允许您安装和管理未作为标准库的一部分分发的库和依赖项的工具。 pip 这个名字是由 Ian Bicking 在 2008 年引入的：\n我已经将 pyinstall 重命名为新名称：pip。pip 是 pip install package 首字母缩写。 （ 来源）\n包管理非常重要，Python 的安装程序从 3.4 版和 2.7.9 版开始分别为 Python 3 和 Python 2 包含了 pip 。许多 Python 项目都使用 pip ，这使它成为每个 Pythonista 的必备工具。\n如果您来自另一种编程语言，您可能会熟悉包管理器的概念。 JavaScript 使用 npm 进行包管理，Ruby 使用 gem，.NET 平台使用 NuGet。在 Python 中， pip 已成为标准包管理器。\n在您的系统上查找 pip Python 3 安装程序为您提供了在系统上安装 Python 时安装 pip 的选项。事实上， pip 与 Python 一起安装的选项默认是勾选的，所以 pip 应该在安装完 Python 之后就可以使用了。","title":"[译]使用 Python 的 pip 管理项目的依赖关系"},{"content":"前言 公司价值观 本篇是对 2023-05-22 到 2023-05-28 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n周一，休产假的产品经理回来上班，得知她被优化之后，内心有些不舍和伤感。中午，组长请大家一起吃了饭。晚上，产品经理交割完办公用户之后，就没来上班了。自此，过完年后，公司至少有三位女同事修完产假之后就离职了，有的是主动，更多的应该是被动。虽然有 N+1 赔偿，但是，这个社会对女性还是不够公平。\n还有 3 个月就要到端午节，老婆买了粽叶包粽子，我也动手包了一部分。虽然包的不好看，但心里还是很满足的。自己包的粽子送节，显然更有意义。结婚之后的第一个端午节，周末开车去给长辈送了端午节。看着长辈们的头发日渐斑白，不禁感叹岁月无情。趁着年轻的时候，要对身边的亲人好一些。不要等到来不及了才知道后悔。\n这周在 docker 里部署了 Plausible ，使用过程中发现 Plausible 架构过于复杂，使用了 postgres 和 clickhouse 数据库，docker-compose 启动了 4 个容器，所以最后还是放弃了使用 Plausible。umami 的 postgres 数据库只包括几张表，操作起来比较容易，比如：时不时地，我会把来自 localhost 的访问记录删除掉，这样统计数据更加真实准确。\nPython 之禅 这是最近的一个 PyTricks：在 python REPL 里面输入 import this 会输出 The Zen of Python, by Tim Peters：\n英文：\nThe Zen of Python, by Tim Peters\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren\u0026rsquo;t special enough to break the rules.\nAlthough practicality beats purity.\nErrors should never pass silently.\nUnless explicitly silenced.\nIn the face of ambiguity, refuse the temptation to guess.\nThere should be one\u0026ndash; and preferably only one \u0026ndash;obvious way to do it.\nAlthough that way may not be obvious at first unless you\u0026rsquo;re Dutch.\nNow is better than never.\nAlthough never is often better than right now.\nIf the implementation is hard to explain, it\u0026rsquo;s a bad idea.\nIf the implementation is easy to explain, it may be a good idea.\nNamespaces are one honking great idea \u0026ndash; let\u0026rsquo;s do more of those!\n中文：\nPython 之禅，作者为 Tim Peters\n美丽胜于丑陋。\n明确胜于含蓄。\n简单胜于复杂。\n复杂胜于繁琐。\n扁平胜于嵌套。\n宽松胜于紧凑。\n可读性很重要。\n特例并不足以打破规则。\n虽然实用性优先于纯粹性。\n错误绝不能悄悄地通过。\n除非明确地沉默。\n面对模棱两可，拒绝猜测。\n应该有一种\u0026ndash; 最好只有一种 \u0026ndash;显而易见的方法来做到这一点。\n虽然这种方法可能一开始并不明显，除非你是荷兰人。\n现在比永远好。\n虽然永远不如 现在就做 好。\n如果实现很难解释，那这是个坏主意。\n如果实现容易解释，那可能是个好主意。\n名称空间是一个非常好的想法 \u0026ndash; 让我们做更多的这样的事情！\nPython 之禅是一组编写 Python 语言程序的指导原则，由著名 Python 开发者 Tim Peters 撰写而成，这些格言反映了 Python 社区的哲学。\n第一原则“美丽胜于丑陋”强调编写美学上令人愉悦且易于阅读的代码的重要性，包括使用适当的缩进、命名规范和格式化。\n第二原则“明确胜于含蓄”强调在代码中要清晰明确，避免捷径并尽可能具体地定义代码。\n第三原则“简单胜于复杂”强调编写易于理解和维护的代码的重要性，包括避免不必要的复杂性并尽可能使用简单的解决方案。\n第四原则“复杂胜于繁琐”强调在必要时使用复杂的解决方案，但避免过度复杂。\n第五原则“扁平胜于嵌套”强调保持代码简单，避免深度嵌套结构。\n第六原则“宽松胜于紧凑”强调使用空格和格式化使代码更易读。\n第七原则“可读性很重要”强调编写易于阅读和理解的代码的重要性。\n第八原则“特例并不足以打破规则”强调即使在可能会偏离规则的情况下，也要遵循最佳实践和已有约定。\n第九原则“虽然实用性优先于纯粹性”强调平衡实用考虑与对优雅和纯粹代码的渴望。\n第十原则“错误绝不能悄悄地通过”强调捕捉和处理代码中的错误，而不是忽略它们。\n第十一原则“除非明确地沉默”强调在适当情况下允许有意地消除错误信息。\n第十二原则“面对模棱两可，拒绝猜测”强调要在代码中清晰明确，即使在存在歧义或不确定性的情况下也要如此。\n第十三原则“应该有一种\u0026ndash; 最好只有一种 \u0026ndash;显而易见的方法来做到这一点”强调遵循已有的约定和规范，避免不必要的复杂或曲折的解决方案。\n第十四原则“虽然这种方法可能一开始并不明显，除非你是荷兰人”是对 Python 的创建者 Guido van Rossum 是荷兰人这一事实的玩味性致敬。\n第十五原则“现在比永远好”强调采取行动并推进你的代码，而不是拖延或拖沓。\n第十六原则“虽然永远不如 现在就做 好”强调要花时间仔细考虑你的代码，避免匆忙解决可能不是最优解的问题。\n第十七原则“如果实现很难解释，那这是个坏主意”强调编写易于理解和解释给他人的代码的重要性。\n第十八原则“如果实现容易解释，那可能是个好主意”强调编写简单明了、易于解释的代码的重要性。\n第十九原则“名称空间是一个非常好的想法 \u0026ndash; 让我们做更多的这样的事情！”强调使用名称空间以清晰易懂的方式组织和结构化你的代码。名称空间有助于避免命名冲突，并使查找和重用代码更容易。\n理财 这周总计支出 1939 元，明细如下：\n5 月 28 日：1064 元，加油充值 1000 元 5 月 27 日：642 元，端午节送节买酒 540 元 5 月 26 日：173 元 5 月 25 日：17 元 5 月 24 日：7 元 5 月 23 日：20 元 5 月 22 日：16 元 健身 我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在跑步主页。\n本周跑步 39 公里，最长跑步距离为 6 公里。\n明细数据如下：\n5 月份即将结束，目前这个月跑了 24 天，累计 178 公里，比 4 月的 125 公里多了 53 公里。再跑个 12 公里，这个月跑步里程就可以达到 190 公里了，给自己加油！最长连续跑步时间为 7 天，每次都是到了周末就中断了，有点遗憾。回过头来想想，跑步是一个长期的事情，比起跑的远，更重要的是跑的久。争取每天都跑，不管跑几公里，只要坚持下去就是成功。\n工作 最近在学习的内容清单：\nEffective Java（第 3 版） Java Design Patterns (中文) Real Python 本周完成四篇博客：\n《Effective Java 3》笔记 12：当覆盖 equals 方法时，总要覆盖 hashCode 方法 《Effective Java 3》笔记 13：明智地覆盖 clone 方法 《Effective Java 3》笔记 14：考虑实现 Comparable 接口 Java 设计模式：Active Object 至此，《Effective Java 3》第三章学习完了。第三章介绍了 Java 中对象的创建和销毁，其中第三章讲述了所有对象通用的方法，主要内容如下：\nequals 方法：用于比较两个对象是否相等，需要遵循一些通用约定，包括自反性、对称性、传递性、一致性和非空性等。 hashCode 方法：用于返回对象的哈希码，需要与 equals 方法一起实现，保证相等的对象具有相等的哈希码。 toString 方法：用于返回对象的字符串表示形式，方便调试和日志记录等。 clone 方法：用于复制对象，需要实现 Cloneable 接口，并覆盖 Object 类中的 clone 方法。 finalize 方法：用于在对象被垃圾回收前执行一些清理操作，但是该方法的使用非常危险，应该尽量避免使用。 本章重点介绍了所有对象通用的方法，这些方法在 Java 中非常重要，需要程序员掌握。equals 和 hashCode 方法是一对重要的方法，需要同时实现，保证对象的相等和哈希码的正确性。toString 方法可以方便地输出对象的信息，方便调试和日志记录等。clone 方法可以用于复制对象，但需要注意实现 Cloneable 接口，并覆盖 Object 类中的 clone 方法。最后，finalize 方法虽然可以用于对象清理，但是使用非常危险，应该尽量避免使用。\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n📌2023-05-27 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 5 月 26 日 星期五 农历四月初八 1、工信部等十四部门：部署推进新一轮电信基础设施共建共享工作。 2、两高两部：对在校园等场所对未成年人实施猥亵等犯罪的，加重处罚。 3、国家疾控局：4 月全国报告法定传染病超 210 万例。 4、集体婚礼走红，民政部推行婚俗改革，高价彩礼得到有效遏制。 5、广东出台办法：失信联合惩戒对象不得报名参加事业单位招聘。 6、北京：新冠连续 4 周列传染病榜首，上周报告发病数是 4 月底的近 4 倍。 7、天津：在津无房家庭首次公积金贷款还清后，仍可按首套房贷款。 8、上海部分社区开打 mRNA 新冠疫苗，可通过“健康云”预约。 9、17 级超强台风\u0026quot;玛娃\u0026quot;已成今年以来全球风王，下周将影响我国南方。 10、长城汽车公开举报比亚迪：两款车型污染物排放不达标，比亚迪回应：检测报告无效，反对任何形式不正当竞争。 11、微信电脑版新增锁定功能，只能通过手机端解锁。 12、韩自研运载火箭“世界”号载星发射成功。 13、造假数量超 2 亿件！最长可追溯 40 年前！本田合资零部件厂商承认造假。 14、普京：俄罗斯正减少不友好国家货币在贸易结算中的份额。 15、美情报披露：克宫遭无人机袭击幕后黑手为乌克兰。 【微语】真正的贫穷，不是金钱上的匮乏，而是认知上的贫瘠。 新闻来源：https://www.163.com/dy/article/I5L6PQL30534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-05-26 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 5 月 25 日 星期四 农历四月初七 1、教育部：2023 年为中西部乡镇定向免费培养本科医学生 6150 人。 2、中国互联网协会：警惕 AI 换脸新骗局，远程转账务必多重验证。 3、交通运输部在南沙群岛火艾礁、牛轭礁和南薰礁附近海域布设 3 座灯浮标。 4、数据显示：今年以来全国已有超 40 城调整首套房贷利率下限至 4%以下。 5、财政部：4 月份全国共销售彩票 503.26 亿元，同比增长 62.0%。 6、吉林省印发公务接待新办法：不得安排群众迎送，公务接待工作餐每人不超 120 元。 7、香港：调整签证及进入许可申请流程，外佣及学生等须申报刑事记录。 8、广东海珠：举报电动车进出租屋充电等，最高奖励 1 万元。 9、韩国三大运营商夸大 5G 网速被罚 336 亿韩元：号称 20G 实际 800M。 10、51 岁马斯克公开回应：已确定特斯拉接班人，若我出现意外，可以确保公司继续运营下去。 11、微软发布重磅更新：Windows 系统全面接入 AI 助手，ChatGPT 内置必应搜索最新答案。 12、岸田文雄称日本正考虑设立北约联络处但不会加入北约，中方回应：不欢迎军事集团。 13、俄罗斯：俄中之间 70％的跨境结算已用本币完成。 14、英国首相苏纳克拒绝停火呼吁，称乌克兰应该继续战斗。 15、俄媒：乌克兰最高将领在俄军攻击中受重伤，可能将无法继续指挥。 【微语】放弃不难，但坚持一定很酷。撑住，才有后来的一切。 新闻来源：https://www.163.com/dy/article/I5IJEHQK0534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-05-25 365 资讯简报，每天精选 15 条热点新闻简报 1 条微语，每天一分钟，知晓天下事！ 2023 年 5 月 25 日 星期四 农历四月初七 1、教育部：2023 年为中西部乡镇定向免费培养本科医学生 6150 人。 2、中国互联网协会：警惕 AI 换脸新骗局，远程转账务必多重验证。 3、交通运输部在南沙群岛火艾礁、牛轭礁和南薰礁附近海域布设 3 座灯浮标。 4、数据显示：今年以来全国已有超 40 城调整首套房贷利率下限至 4%以下。 5、财政部：4 月份全国共销售彩票 503.26 亿元，同比增长 62.0%。 6、吉林省印发公务接待新办法：不得安排群众迎送，公务接待工作餐每人不超 120 元。 7、香港：调整签证及进入许可申请流程，外佣及学生等须申报刑事记录。 8、广东海珠：举报电动车进出租屋充电等，最高奖励 1 万元。 9、韩国三大运营商夸大 5G 网速被罚 336 亿韩元：号称 20G 实际 800M。 10、51 岁马斯克公开回应：已确定特斯拉接班人，若我出现意外，可以确保公司继续运营下去。 11、微软发布重磅更新：Windows 系统全面接入 AI 助手，ChatGPT 内置必应搜索最新答案。 12、岸田文雄称日本正考虑设立北约联络处但不会加入北约，中方回应：不欢迎军事集团。 13、俄罗斯：俄中之间 70％的跨境结算已用本币完成。 14、英国首相苏纳克拒绝停火呼吁，称乌克兰应该继续战斗。 15、俄媒：乌克兰最高将领在俄军攻击中受重伤，可能将无法继续指挥。 【微语】放弃不难，但坚持一定很酷。撑住，才有后来的一切。 新闻来源：https://www.163.com/dy/article/I5IJEHQK0534QBVQ.html?spss=dy_author #每日早报 #memos 📌2023-05-25 前后端均基于 vercel 的每日早报项目 https://icodeq.com/2022/5fe2010403bb/ #memos 📌2023-05-24 GitHub - resumejob/awesome-resume: Resume，Resume Templates，程序员简历例句，简历模版#memos https://github.com/resumejob/awesome-resume 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/31/weekly_review_21/","summary":"前言 公司价值观 本篇是对 2023-05-22 到 2023-05-28 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n周一，休产假的产品经理回来上班，得知她被优化之后，内心有些不舍和伤感。中午，组长请大家一起吃了饭。晚上，产品经理交割完办公用户之后，就没来上班了。自此，过完年后，公司至少有三位女同事修完产假之后就离职了，有的是主动，更多的应该是被动。虽然有 N+1 赔偿，但是，这个社会对女性还是不够公平。\n还有 3 个月就要到端午节，老婆买了粽叶包粽子，我也动手包了一部分。虽然包的不好看，但心里还是很满足的。自己包的粽子送节，显然更有意义。结婚之后的第一个端午节，周末开车去给长辈送了端午节。看着长辈们的头发日渐斑白，不禁感叹岁月无情。趁着年轻的时候，要对身边的亲人好一些。不要等到来不及了才知道后悔。\n这周在 docker 里部署了 Plausible ，使用过程中发现 Plausible 架构过于复杂，使用了 postgres 和 clickhouse 数据库，docker-compose 启动了 4 个容器，所以最后还是放弃了使用 Plausible。umami 的 postgres 数据库只包括几张表，操作起来比较容易，比如：时不时地，我会把来自 localhost 的访问记录删除掉，这样统计数据更加真实准确。\nPython 之禅 这是最近的一个 PyTricks：在 python REPL 里面输入 import this 会输出 The Zen of Python, by Tim Peters：\n英文：\nThe Zen of Python, by Tim Peters\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nFlat is better than nested.\nSparse is better than dense.\nReadability counts.\nSpecial cases aren\u0026rsquo;t special enough to break the rules.","title":"周报-21｜Python之禅、产品经理被优化、端午节送节"},{"content":"本文主要介绍 Active Object 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 活动对象（Active Object）是一种设计模式，其主要目的是将并发和异步处理的问题从客户端代码中分离出来，从而提高系统的性能、可靠性和可维护性。活动对象模式是一种能够帮助开发人员处理多线程、异步和并发问题的设计模式。\n在传统的并发编程模型中，客户端代码需要直接管理线程和锁等细节，这样会导致代码复杂度和维护成本的增加，同时也容易出现各种问题，如死锁、竞态条件等。活动对象模式通过引入活动对象来解决这些问题，活动对象将客户端代码发送的消息添加到内部的消息队列中，并使用单独的线程异步处理这些消息。这种模式可以提高系统的性能和可扩展性，同时使得客户端代码更加简单和易于维护。\n活动对象模式的目的包括：\n将并发和异步处理的问题从客户端代码中分离出来，从而使得客户端代码更加简单和易于维护。客户端代码只需要发送消息即可，不需要关心异步处理的细节，活动对象将并发和异步处理的问题封装起来，提供简单的接口供客户端使用。 提高系统的性能和可扩展性。活动对象使用单独的线程池异步处理消息，可以更好地利用系统资源，提高系统的性能和可扩展性。 提高系统的可靠性和健壮性。活动对象将消息添加到内部的消息队列中，避免了竞态条件和死锁等问题，从而提高了系统的可靠性和健壮性。 将多线程和异步处理的细节封装起来，使得客户端代码更加抽象和通用。客户端代码可以使用相同的接口来访问不同的服务，从而提高代码的复用性和可维护性。 解释 活动对象模式的核心思想是将并发和异步处理的问题从客户端代码中分离出来。具体来说，活动对象模式包含以下几个关键组件：\n活动对象（Active Object）：活动对象是一个封装了某种服务的对象，它将客户端代码发送的消息添加到内部的消息队列中，并使用单独的线程异步处理这些消息。活动对象通常包含一个消息队列和一个线程池，用于异步处理消息。 方法调用请求（Method Invocation Request）：客户端代码向活动对象发送方法调用请求，包括方法名和参数列表等信息。活动对象将方法调用请求封装为一个消息对象，并添加到内部的消息队列中。 消息队列（Message Queue）：消息队列是活动对象内部用于存储方法调用请求的队列。活动对象将客户端代码发送的消息添加到消息队列中，并使用单独的线程异步处理这些消息。 线程池（Thread Pool）：线程池是活动对象用于异步处理消息的线程池。活动对象从消息队列中取出消息，并使用线程池中的线程异步处理这些消息。 程序示例\npublic abstract class ActiveCreature{ private final Logger logger = LoggerFactory.getLogger(ActiveCreature.class.getName()); private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private Thread thread; public ActiveCreature(String name) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(); thread = new Thread(new Runnable() { @Override public void run() { while (true) { try { requests.take().run(); } catch (InterruptedException e) { logger.error(e.getMessage()); } } } } ); thread.start(); } public void eat() throws InterruptedException { requests.put(new Runnable() { @Override public void run() { logger.info(\u0026#34;{} is eating!\u0026#34;,name()); logger.info(\u0026#34;{} has finished eating!\u0026#34;,name()); } } ); } public void roam() throws InterruptedException { requests.put(new Runnable() { @Override public void run() { logger.info(\u0026#34;{} has started to roam and the wastelands.\u0026#34;,name()); } } ); } public String name() { return this.name; } } 在该示例代码中，ActiveCreature 类封装了一个消息队列，用于异步处理客户端代码发送的消息。具体来说，该示例代码包含以下几个关键组件：\nBlockingQueue\u0026lt;Runnable\u0026gt; 类型的 requests 属性：该属性表示消息队列，用于存储客户端代码发送的消息。客户端代码可以通过 eat() 和 roam() 方法向消息队列中添加消息。 Thread 类型的 thread 属性：该属性表示活动对象的线程，用于异步处理消息队列中的消息。 String 类型的 name 属性：该属性表示活动对象的名称。 ActiveCreature(String name) 构造方法：该方法用于创建一个活动对象，初始化消息队列和线程等属性。在该方法中，我们创建了一个新的线程，并使用 requests.take().run() 从消息队列中取出消息并异步处理。 eat() 和 roam() 方法：这两个方法用于向消息队列中添加消息，表示活动对象正在吃和漫游。在这两个方法中，我们将一个 Runnable 对象添加到消息队列中，并在其 run() 方法中执行相应的操作，如输出日志等。 name() 方法：该方法用于获取活动对象的名称。 在总体上，该示例代码实现了活动对象模式的基本功能，将并发和异步处理的问题从客户端代码中分离出来，并提供了简单的接口供客户端调用。客户端代码只需要调用 eat() 和 roam() 方法即可，不需要关心异步处理的细节，活动对象将并发和异步处理的问题封装起来，提供简单的接口供客户端使用。\n需要注意的是，在该示例代码中，我们使用了阻塞队列 BlockingQueue\u0026lt;Runnable\u0026gt; 来实现消息队列，该队列提供了线程安全的添加和移除操作，保证了消息的有序性和正确性。同时，在活动对象的线程中使用了 requests.take().run() 操作来从消息队列中取出消息并异步处理，这种方式可以保证消息的有序性和正确性，并避免了竞态条件和死锁等问题。\n我们可以看到，任何将扩展 ActiveCreature 的类都将具有自己的控制线程来执行和调用方法。\n例如，兽人类：\npublic class Orc extends ActiveCreature { public Orc(String name) { super(name); } } 现在，我们可以创建多个生物，例如兽人，告诉他们吃东西和散步，然后他们将在自己的控制线程上执行它：\npublic static void main(String[] args) { var app = new App(); app.run(); } @Override public void run() { ActiveCreature creature; try { for (int i = 0;i \u0026lt; creatures;i++) { creature = new Orc(Orc.class.getSimpleName().toString() + i); creature.eat(); creature.roam(); } Thread.sleep(1000); } catch (InterruptedException e) { logger.error(e.getMessage()); } Runtime.getRuntime().exit(1); } 类图 举例 以下是一个简单的活动对象示例代码：\nimport java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.Future; public class ActiveObject { private final ExecutorService executor = Executors.newSingleThreadExecutor(); public Future\u0026lt;String\u0026gt; process(String message) { // 创建一个异步任务，并将其提交到线程池中 return executor.submit(() -\u0026gt; { // 模拟复杂的处理逻辑 Thread.sleep(1000); // 返回处理结果 return \u0026#34;Processed message: \u0026#34; + message; }); } public void shutdown() { // 关闭线程池 executor.shutdown(); } } 在上面的示例代码中，ActiveObject 类封装了一个异步处理服务，客户端代码可以使用该服务异步处理消息。ActiveObject 类中的 process() 方法接收一个消息，并将其封装为一个异步任务，然后提交到线程池中异步处理。process() 方法返回一个 Future 对象，可以用于获取异步处理的结果。在该示例代码中，异步任务只是简单地模拟了处理逻辑，实际上可以根据需要编写更加复杂的异步处理逻辑。\n下面是一个使用 ActiveObject 类的示例代码：\nimport java.util.concurrent.ExecutionException; import java.util.concurrent.Future; public class Client { public static void main(String[] args) throws InterruptedException, ExecutionException { ActiveObject activeObject = new ActiveObject(); // 发送消息到活动对象 Future\u0026lt;String\u0026gt; future = activeObject.process(\u0026#34;Hello, world!\u0026#34;); // 等待异步处理完成，并获取处理结果 String result = future.get(); System.out.println(result); // 关闭活动对象 activeObject.shutdown(); } } 在上面的示例代码中，客户端代码使用 ActiveObject 类异步处理了一条消息，并等待异步处理完成后获取处理结果。需要注意的是，在使用 ActiveObject 类时，客户端代码只需要发送消息即可，不需要关心异步处理的细节，从而使得客户端代码更加简单和易于维护。\n下面是一个复杂的活动对象示例代码，该代码模拟了一个银行账户系统，支持存款、取款和查询余额等操作。\nimport java.util.concurrent.CompletableFuture; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class BankAccount { private final ExecutorService executor = Executors.newSingleThreadExecutor(); private double balance; public BankAccount(double initialBalance) { this.balance = initialBalance; } public CompletableFuture\u0026lt;Double\u0026gt; deposit(double amount) { CompletableFuture\u0026lt;Double\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); executor.submit(() -\u0026gt; { balance += amount; future.complete(balance); }); return future; } public CompletableFuture\u0026lt;Double\u0026gt; withdraw(double amount) { CompletableFuture\u0026lt;Double\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); executor.submit(() -\u0026gt; { if (balance \u0026gt;= amount) { balance -= amount; future.complete(balance); } else { future.completeExceptionally(new InsufficientFundsException(\u0026#34;Insufficient funds\u0026#34;)); } }); return future; } public CompletableFuture\u0026lt;Double\u0026gt; getBalance() { CompletableFuture\u0026lt;Double\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); executor.submit(() -\u0026gt; { future.complete(balance); }); return future; } public void shutdown() { executor.shutdown(); } } class InsufficientFundsException extends RuntimeException { public InsufficientFundsException(String message) { super(message); } } 缺点 虽然活动对象模式具有许多优点，但也存在一些缺点，如下所述：\n复杂性：活动对象模式需要使用异步处理和事件驱动机制，这增加了系统的复杂性。在设计、实现和测试时，需要考虑许多因素，如并发控制、锁定、死锁、线程池大小、任务队列大小等。 性能下降：在处理大量请求时，活动对象模式可能会导致性能下降。这是因为活动对象模式需要创建许多线程和任务，这会增加系统的负载和开销。此外，如果任务队列或线程池过大，会导致内存和 CPU 资源的浪费。 调试难度：由于活动对象模式使用异步处理和事件驱动机制，因此在调试时可能会出现难以预测的行为。例如，多个线程可能会同时访问共享资源，导致死锁或竞态条件，从而导致应用程序崩溃或出现其他问题。 状态管理：由于活动对象模式使用异步处理和事件驱动机制，因此在处理请求时需要管理对象的状态。这可能会导致状态同步和状态不一致的问题，从而影响系统的正确性和可靠性。 缺乏标准化：活动对象模式没有标准化的实现方式，因此在不同的应用程序和框架中可能会有不同的实现方式和限制。这使得活动对象模式在不同的环境中难以移植和重用。 总的来说，活动对象模式是一种强大的设计模式，可以用于实现异步处理、事件驱动、高性能、可伸缩和可靠的应用程序。但是，它也存在一些缺点，需要仔细考虑和权衡。在使用活动对象模式时，需要关注系统的复杂性、性能、调试难度、状态管理和标准化等问题。\n应用 在开源框架中的应用 活动对象设计模式在许多开源框架中都得到了广泛应用，以下是几个常见的例子：\nAkka 框架：Akka 是一个轻量级的 Actor 模型框架，通过将并发和异步处理的问题从客户端代码中分离出来，提高了系统的性能、可靠性和可维护性。在 Akka 中，每个 Actor 都是一个活动对象，通过消息传递的方式进行通信和协作。Akka 提供了丰富的 API 和工具，可以方便地创建和管理 Actor，实现高性能和可扩展的系统。 Vert.x 框架：Vert.x 是一个基于事件驱动的异步框架，提供了多种语言的 API 和工具，支持构建高性能和可扩展的应用程序。在 Vert.x 中，每个组件都是一个活动对象，可以通过 Vert.x 的事件总线进行通信和协作。Vert.x 提供了丰富的异步 API 和工具，可以方便地处理并发和异步问题。 RxJava 框架：RxJava 是一个基于响应式编程的异步框架，提供了丰富的操作符和工具，支持构建高性能和可维护的应用程序。在 RxJava 中，每个 Observable 都是一个活动对象，可以通过异步流的方式进行通信和协作。RxJava 提供了丰富的操作符和工具，可以方便地处理并发和异步问题，并支持响应式编程的多种特性，如响应式流、背压控制等。 Netty 框架：Netty 是一个基于事件驱动的异步网络通信框架，提供了丰富的 API 和工具，支持构建高性能和可扩展的网络应用程序。在 Netty 中，每个 Channel 都是一个活动对象，可以通过事件的方式进行通信和协作。Netty 提供了丰富的异步 API 和工具，可以方便地处理网络通信和异步问题，并支持多种协议和编解码器。 Spring 框架：Spring 是一个广泛使用的企业级 Java 框架，提供了丰富的 API 和工具，支持构建高性能和可维护的应用程序。在 Spring 中，可以使用异步处理、响应式编程和事件驱动等方式实现活动对象模式。Spring 提供了丰富的异步 API 和工具，可以方便地处理异步和并发问题。 JMS 框架：JMS 是 Java 消息服务的标准，提供了异步消息传递的方式，支持构建可靠、高性能和可扩展的消息系统。在 JMS 中，可以使用活动对象模式实现异步消息的处理和分发。JMS 提供了丰富的 API 和工具，可以方便地处理异步消息的生产和消费。 Apache Camel 框架：Apache Camel 是一个基于企业级集成模式的开源框架，提供了丰富的组件和工具，支持构建可扩展、高性能和可靠的应用程序。在 Camel 中，可以使用活动对象模式实现异步消息的处理和路由。Camel 提供了丰富的组件和工具，可以方便地处理异步消息的路由和转换。 下面是一个使用 Spring 异步处理和事件驱动机制实现活动对象模式的示例代码，该示例代码使用了 Spring Boot 框架和 Spring Reactor 库：\nimport org.springframework.beans.factory.annotation.Autowired; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.stereotype.Component; import reactor.core.publisher.Flux; import reactor.core.publisher.Mono; import reactor.core.scheduler.Schedulers; @Configuration public class AppConfig { @Bean public MessageHandler messageHandler() { return new MessageHandler(); } } @Component public class MessageHandler { @Autowired private MessageRepository messageRepository; public Mono\u0026lt;Void\u0026gt; handleMessage(String message) { return Mono.fromCallable(() -\u0026gt; { // 处理消息 System.out.println(\u0026#34;Received message: \u0026#34; + message); messageRepository.save(new Message(message)); return null; }).subscribeOn(Schedulers.boundedElastic()); } public Flux\u0026lt;Message\u0026gt; getAllMessages() { return Flux.defer(() -\u0026gt; Flux.fromIterable(messageRepository.findAll())) .subscribeOn(Schedulers.boundedElastic()); } } @Entity public class Message { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String content; public Message() {} public Message(String content) { this.content = content; } public Long getId() { return id; } } 在上述示例代码中，我们定义了一个 MessageHandler 类作为活动对象，用于异步处理消息的接收和存储。该类使用了 Spring 异步处理和事件驱动机制来实现活动对象模式，客户端代码只需要调用相应的方法即可，不需要关心异步处理的细节。\n具体来说，该示例代码包含以下几个部分：\nAppConfig 配置类：该类用于配置 Spring Bean，定义了一个 messageHandler() 方法，返回一个 MessageHandler 对象。\nMessageHandler 活动对象类：该类包含了两个方法：handleMessage() 和 getAllMessages()。handleMessage() 方法用于处理消息，将消息存储到数据库中；getAllMessages() 方法用于获取所有的消息。这两个方法都使用了 Spring 的异步处理机制和事件驱动机制，使用了 Reactor 库中的 Mono 和 Flux 类。\nMessage JPA 实体类：该类用于表示消息对象，使用了 JPA 注解。\n在 handleMessage() 方法中，我们使用了 Mono.fromCallable() 方法来异步处理消息的接收和存储，将处理操作提交到线程池中执行，然后返回 Mono\u0026lt;Void\u0026gt; 对象，以便客户端代码可以等待处理操作完成。我们还使用了 subscribeOn() 方法来指定异步处理的线程池，以提高系统的性能和可伸缩性。\n在 getAllMessages() 方法中，我们使用了 Flux.defer() 方法来异步获取所有的消息，将获取操作提交到线程池中执行，然后返回 Flux\u0026lt;Message\u0026gt; 对象，以便客户端代码可以异步获取消息。我们同样使用了 subscribeOn() 方法来指定异步处理的线程池。\n通过使用 Spring 异步处理和事件驱动机制，我们可以实现高性能、可靠和可扩展的活动对象模式，提高系统的性能和可维护性。\n下面是一个使用活动对象模式实现异步消息处理和分发的 JMS 示例代码，该示例代码使用了 ActiveMQ 作为 JMS 消息中间件：\nimport javax.jms.*; import org.apache.activemq.ActiveMQConnectionFactory; import java.util.concurrent.CompletableFuture; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class JMSMessageHandler implements MessageListener { private final ExecutorService executor = Executors.newSingleThreadExecutor(); private Connection connection; private Session session; private Destination destination; public JMSMessageHandler(String brokerUrl, String destinationName) throws JMSException { ConnectionFactory connectionFactory = new ActiveMQConnectionFactory(brokerUrl); connection = connectionFactory.createConnection(); connection.start(); session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); destination = session.createQueue(destinationName); MessageConsumer consumer = session.createConsumer(destination); consumer.setMessageListener(this); } public CompletableFuture\u0026lt;Void\u0026gt; send(String message) { CompletableFuture\u0026lt;Void\u0026gt; future = new CompletableFuture\u0026lt;\u0026gt;(); executor.submit(() -\u0026gt; { try { TextMessage textMessage = session.createTextMessage(message); MessageProducer producer = session.createProducer(destination); producer.send(textMessage); future.complete(null); } catch (JMSException e) { future.completeExceptionally(e); } }); return future; } public void onMessage(Messagemessage) { CompletableFuture.runAsync(() -\u0026gt; { try { if (message instanceof TextMessage) { TextMessage textMessage = (TextMessage) message; String text = textMessage.getText(); // 处理消息 System.out.println(\u0026#34;Received message: \u0026#34; + text); } } catch (JMSException e) { e.printStackTrace(); } }); } public void close() throws JMSException { connection.close(); executor.shutdown(); } } 在上述示例代码中，JMSMessageHandler 类表示一个 JMS 消息处理器，可以异步处理来自 JMS 队列的消息，并将处理结果发送回 JMS 队列。该类使用了活动对象模式来实现异步消息的处理和分发，客户端代码只需要发送消息即可，不需要关心异步处理的细节。\n具体来说，该类包含以下几个方法：\nJMSMessageHandler(String brokerUrl, String destinationName) 构造方法：该方法用于创建一个 JMS 消息处理器对象，连接到指定的 JMS 消息中间件并订阅指定的队列。\nsend(String message) 方法：该方法用于发送消息到 JMS 队列中，客户端代码可以调用该方法将消息发送到指定的队列。\nonMessage(Message message) 方法：该方法是 MessageListener 接口的回调方法，用于异步处理队列中的消息，并将处理结果发送回 JMS 队列。\nclose() 方法：该方法用于关闭 JMS 连接和线程池，释放资源。\n在 send() 方法中，我们使用了 CompletableFuture 对象来异步处理消息的发送，将发送操作提交到线程池中执行，然后返回 CompletableFuture 对象，以便客户端代码可以等待发送操作完成。\n在 onMessage() 方法中，我们使用了 CompletableFuture.runAsync() 方法来异步处理消息的处理，将处理操作提交到线程池中执行，然后返回 CompletableFuture 对象，以便客户端代码可以等待处理操作完成。\n通过使用活动对象模式和异步处理技术，我们可以实现高性能、可靠和可扩展的 JMS 消息处理器，提高系统的性能和可维护性。\n在项目中的使用 在公司的项目中，用到过活动对象这个设计模式，只是之前并不清楚这个模式。使用场景是，发送飞书通知和拨打语音电话时，将请求添加到一个内部阻塞队列，然后单独启动一个线程去消费这个队列。\n以下是拨打语音电话的代码：\n/** * Tencent Cloud Vms SendTtsVoice * https://cloud.tencent.com/document/product/1128/51558 */ @Slf4j @AllArgsConstructor public class VmsServiceImpl implements VmsService { public static final String PREFIX_PHONE = \u0026#34;86\u0026#34;; private static final BlockingQueue\u0026lt;VoiceSenderRequest\u0026gt; queue = new LinkedBlockingQueue\u0026lt;\u0026gt;(); private TtsVoiceSender ttsVoiceSender; private final AsyncVmsThread asyncVmsThread = new AsyncVmsThread(); @PostConstruct public void init() { asyncVmsThread.start(); } @PreDestroy public void destroy() { asyncVmsThread.shutdown(); } public void sendAsync(Collection\u0026lt;NoticeTarget\u0026gt; noticeUsers, Integer templateId, String[] params) { if (templateId == null || CollectionUtils.isEmpty(noticeUsers)) { return; } for (NoticeTarget noticeUser : noticeUsers) { if (!noticeUser.getType().equals(NoticeTargetTypeEnum.PHONE)) { continue; } try { queue.put(new VoiceSenderRequest().setNoticeUser(noticeUser).setTemplateId(templateId).setParams(params)); } catch (InterruptedException e) { throw new BusinessException(\u0026#34;线程被中断\u0026#34;); } } } public Boolean send(String phone, Integer templateId, String[] params) { if (templateId == null || StringUtils.isBlank(phone)) { throw new BusinessException(\u0026#34;参数不能为空\u0026#34;); } TtsVoiceSenderResult ttsVoiceSenderResult = null; try { ttsVoiceSenderResult = ttsVoiceSender.send(PREFIX_PHONE, phone, templateId, params, 2, \u0026#34;\u0026#34;); } catch (Exception e) { throw new RuntimeException(e); } if (ttsVoiceSenderResult.result != 0) { throw new BusinessException(ttsVoiceSenderResult.errMsg); } return ttsVoiceSenderResult.result == 0; } public class AsyncVmsThread extends Thread { AtomicBoolean isRunning = new AtomicBoolean(true); public AsyncVmsThread() { super(\u0026#34;vmsSender\u0026#34;); } @Override public void run() { while (isRunning.get()) { ThreadUtil.sleep(2000L); VoiceSenderRequest voiceSenderRequest = null; try { voiceSenderRequest = queue.take(); send(voiceSenderRequest.getNoticeUser().getId(), voiceSenderRequest.getTemplateId(), voiceSenderRequest.getParams()); } catch (Exception e) { log.warn(\u0026#34;{}\u0026#34;, String.format(\u0026#34;发送语音电话给[%s]出现异常: %s\u0026#34;, voiceSenderRequest.getNoticeUser(), e.getMessage()), e); } } } public void shutdown() { isRunning.set(false); } } @Data @Accessors(chain = true) public class VoiceSenderRequest { private NoticeTarget noticeUser; private Integer templateId; private String[] params; } } 优化之后的代码：\n@Slf4j public abstract class ActiveObject { private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private Thread thread; private volatile boolean isAcceptingRequests = true; private volatile boolean isProcessingRequests = true; public ActiveObject(String name) { this(name, 16, null); } public ActiveObject(String name, int queueSize, Long sleepMillis) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;\u0026gt;(queueSize); thread = new Thread(() -\u0026gt; { while (isProcessingRequests) { try { processRequest(requests.take()); if (sleepMillis != null) { Thread.sleep(sleepMillis); } } catch (InterruptedException e) { log.warn(\u0026#34;Active Object thread interrupted, reason: {}\u0026#34;, e.getMessage()); } } }, name); thread.start(); } private void processRequest(Runnable task) { try { task.run(); } catch (Exception e) { log.error(\u0026#34;Error processing request: {}\u0026#34;, e.getMessage()); // 发送告警信息 } } public void shutdown() { isAcceptingRequests = false; while (!requests.isEmpty()) { try { Thread.sleep(100); } catch (InterruptedException e) { // Ignore exception } } isProcessingRequests = false; thread.interrupt(); } public void run(Runnable runnable) { if (isAcceptingRequests) { requests.offer(runnable); } else { throw new IllegalStateException(\u0026#34;Active object is no longer accepting requests\u0026#34;); } } public String name() { return this.name; } } 该类具有构造函数，用于创建具有给定名称和指定大小阻塞请求队列的 Active Object。Active Object 在后台的单独线程上运行，该线程在循环中执行，直到被中断。它使用run方法执行添加到请求队列中的请求。run方法接受一个Runnable对象，并将其添加到请求队列中。如果 Active Object 不再接受请求，则抛出IllegalStateException。\nshutdown方法用于停止 Active Object。它首先将isAcceptingRequests标志设置为 false，这将防止将任何进一步的请求添加到队列中。然后等待队列变为空，然后将isProcessingRequests标志设置为 false，并中断 Active Object 的线程。\n这个类本身已经是一个很好的 Active Object 模式的实现了，但是如果需要更高的性能或更好的扩展性，还可以进行一些优化：\n使用线程池：当前的实现中，每个 Active Object 都有一个单独的线程来处理请求。如果需要处理大量的 Active Object，这将会产生很多线程，从而影响系统的性能和稳定性。可以使用线程池来管理线程，从而更好地控制线程的数量和资源的使用。\n如果在使用 ActiveObject 时要执行耗时的任务，可以将任务放到一个单独的线程池中执行，以避免阻塞 ActiveObject 实例的请求处理线程。\n@Slf4j public abstract class ActiveObject { private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private ExecutorService executorService; private Thread thread; private volatile boolean isAcceptingRequests = true; private volatile boolean isProcessingRequests = true; public ActiveObject(String name) { this(name, 16, null); } public ActiveObject(String name, int queueSize, Long sleepMillis) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;\u0026gt;(queueSize); this.executorService = Executors.newFixedThreadPool(5); thread = new Thread(() -\u0026gt; { while (isProcessingRequests) { try { processRequest(requests.take(), executorService); if (sleepMillis != null) { Thread.sleep(sleepMillis); } } catch (InterruptedException e) { log.warn(\u0026#34;Active Object thread interrupted, reason: {}\u0026#34;, e.getMessage()); } } }, name); thread.start(); } private void processRequest(Runnable task, ExecutorService executorService) { try { executorService.submit(task).get(); } catch (Exception e) { log.error(\u0026#34;Error processing request: {}\u0026#34;, e.getMessage()); // 发送告警信息 } } public void shutdown() { isAcceptingRequests = false; while (!requests.isEmpty()) { try { Thread.sleep(100); } catch (InterruptedException e) { // Ignore exception } } isProcessingRequests = false; executorService.shutdown(); thread.interrupt(); } public void run(Runnable runnable) { if (isAcceptingRequests) { requests.offer(runnable); } else { throw new IllegalStateException(\u0026#34;Active object is no longer accepting requests\u0026#34;); } } public String name() { return this.name; } } 在修改后的代码中，添加了一个私有变量 executorService，用于存储一个线程池对象，其中线程池的大小为 5。在构造方法中，创建了一个新的 FixedThreadPoolExecutor 实例，并将其作为 executorService 的值。该线程池会在 ActiveObject 实例中处理耗时任务，避免阻塞请求队列的处理。\n在 processRequest 方法中，使用 executorService.submit(task).get()来提交并执行任务。在执行任务时，使用了 get()方法来同步获取任务的执行结果，以确保任务执行完成后再处理下一个请求。\n在 shutdown 方法中，添加了 executorService.shutdown()来关闭线程池。该方法会等待所有任务执行完成后关闭线程池，并防止新任务被提交。这样可以确保所有任务都被处理完毕后才关闭 ActiveObject 实例。\n需要注意的是，在使用线程池时，要根据具体的业务需求和系统资源情况选择合适的线程池大小和类型，避免线程池过大或过小，从而影响系统性能或导致线程池拥堵。\n优化请求的处理：当前实现中，每个请求都会在执行完毕后等待 100 毫秒。如果请求处理较快，这将浪费很多时间。可以根据实际情况优化请求的处理方式，例如设置一个最小执行时间，或者使用更高效的数据结构来管理请求队列。\n在当前的实现中，使用了一个阻塞队列 LinkedBlockingQueue 来管理请求队列。这种数据结构的优点是可以保证线程安全，但是在高并发场景下可能会成为瓶颈，因为它是基于链表实现的，每次添加或删除元素时都需要进行同步操作，可能会影响性能。\n如果需要更高效的请求队列管理方式，可以考虑使用无锁的并发队列，例如 Disruptor 或 ConcurrentLinkedQueue。这些数据结构可以在高并发场景下提供更好的性能和可扩展性，但是需要更加复杂的实现和使用方法，需要根据具体的场景进行权衡和选择。如果使用 Disruptor，需要进行更加细致的配置和调优，以便发挥最大的性能优势。如果使用 ConcurrentLinkedQueue，需要考虑并发问题，例如使用 CAS 操作来保证线程安全。\n如果使用 ConcurrentLinkedQueue 来管理请求队列，需要考虑并发问题，因为该数据结构是非阻塞的，多个线程可以同时对其进行操作，可能会导致并发问题，例如竞态条件和内存一致性问题。\n为了保证线程安全，可以使用 CAS（Compare and Swap）操作来实现原子性的元素插入和删除。CAS 操作可以保证只有一个线程能够成功修改共享变量的值，其他线程需要重试或者等待。\n例如，在 ActiveObject 类中，可以将请求队列声明为 ConcurrentLinkedQueue 类型，并使用 CAS 操作来实现元素的插入和删除：\npublic abstract class ActiveObject { private ConcurrentLinkedQueue\u0026lt;Runnable\u0026gt; requests; // ... public ActiveObject(String name, int queueSize) { this.name = name; this.requests = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); thread = new Thread(() -\u0026gt; { while (isProcessingRequests) { Runnable task = requests.poll(); if (task != null) { task.run(); } try { Thread.sleep(100); } catch (InterruptedException e) { log.warn(\u0026#34;Active Object thread interrupted, reason: {}\u0026#34;, e.getMessage()); } } }, name); thread.start; } } 在上面的代码中，使用了 ConcurrentLinkedQueue 来替换了原有的阻塞队列 LinkedBlockingQueue，并使用了 poll 方法来获取队列中的下一个元素，而不是 take 方法，这样可以避免线程阻塞。然后使用 CAS 操作来实现元素的添加，使用了 offer 方法，并检查返回值是否为 true，如果为 false 则表示 CAS 操作失败，需要重试或者等待。\n需要注意的是，ConcurrentLinkedQueue 并不能保证元素的顺序，因此在处理请求时需要注意顺序问题，不能保证先进先出的顺序。如果需要保证顺序，可以使用其他的数据结构，例如 BlockingQueue。\n上面的代码已经很不错了，但还有一些可以优化的地方：\n使用工厂方法来创建 ActiveObject 实例 可以将 ActiveObject 类中的构造方法改为私有的，然后提供一个工厂方法来创建 ActiveObject 实例。这样可以将 ActiveObject 的创建逻辑与客户端代码分离，使得客户端代码更加简洁和易于维护。\n将日志记录器作为静态变量 可以将日志记录器作为静态变量，以便在整个类中共享。这样可以避免在每个方法中都创建一个日志记录器，提高代码的可读性和性能。\n使用线程安全的单例模式 可以使用线程安全的单例模式来确保 ActiveObject 实例的唯一性。这样可以避免在多个地方创建多个 ActiveObject 实例，从而导致系统资源浪费或数据不一致。\n修改后的代码如下：\npublic abstract class ActiveObject { private static final Logger log = LoggerFactory.getLogger(ActiveObject.class); private static final Map\u0026lt;String, ActiveObject\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private ExecutorService executorService; private Thread thread; private volatile boolean isAcceptingRequests = true; private volatile boolean isProcessingRequests = true; private ActiveObject(String name, int queueSize, Long sleepMillis) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;\u0026gt;(queueSize); this.executorService = Executors.newFixedThreadPool(5); thread = new Thread(() -\u0026gt; { while (isProcessingRequests) { try { processRequest(requests.take(), executorService); if (sleepMillis != null) { Thread.sleep(sleepMillis); } } catch (InterruptedException e) { log.warn(\u0026#34;Active Object thread interrupted, reason: {}\u0026#34;, e.getMessage()); } } }, name); thread.start(); } private void processRequest(Runnable task, ExecutorService executorService) { try { executorService.submit(task).get(); } catch (Exception e) { log.error(\u0026#34;Error processing request: {}\u0026#34;, e.getMessage()); // 发送告警信息 } } public static synchronized ActiveObject getInstance(String name) { return getInstance(name, 16, null); } publicvoid submit(Runnable task) { if (isAcceptingRequests) { try { requests.put(task); } catch (InterruptedException e) { log.error(\u0026#34;Error submitting request: {}\u0026#34;, e.getMessage()); // 发送告警信息 } } else { log.warn(\u0026#34;Active Object is not accepting requests\u0026#34;); // 发送告警信息 } } public static synchronized ActiveObject getInstance(String name, int queueSize, Long sleepMillis) { ActiveObject instance = INSTANCES.get(name); if (instance == null) { instance = new ActiveObject(name, queueSize, sleepMillis); INSTANCES.put(name, instance); } return instance; } public void shutdown() { isAcceptingRequests = false; while (!requests.isEmpty()) { try { Thread.sleep(100); } catch (InterruptedException e) { // Ignore exception } } isProcessingRequests = false; executorService.shutdown(); thread.interrupt(); } } 上面的代码已经很不错了，但还有一些可以进一步优化的地方：\n使用线程池来管理线程，而不是每次创建一个新的线程。这样可以减少线程的创建和销毁的开销，提高代码的性能。 使用 Lambda 表达式简化代码，使代码更加简洁和易于理解。例如，可以将线程中的 while 循环改为 Lambda 表达式，简化代码。\n使用 CompletableFuture 来实现异步处理，将请求的处理过程和结果的返回分离开来。这样可以提高代码的可读性和可维护性，同时也可以提高代码的性能。\n使用 ThreadFactory 来命名线程，以便更好地跟踪线程的执行情况以及排查问题。\n使用 CompletableFuture 的 exceptionally 方法处理异常，以避免在处理请求时出现异常而导致整个线程停止。\npublic class ActiveObject { private static final Logger log = LoggerFactory.getLogger(ActiveObject.class); private static final Map\u0026lt;String, ActiveObject\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private static final int THREAD_POOL_SIZE = 5; private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private ExecutorService executorService; private CompletableFuture\u0026lt;Void\u0026gt; processingFuture; private volatile boolean isAcceptingRequests = true; private ActiveObject(String name, int queueSize, Long sleepMillis) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;\u0026gt;(queueSize); this.executorService = Executors.newFixedThreadPool(THREAD_POOL_SIZE, new ThreadFactory() { private AtomicInteger count = new AtomicInteger(0); public Thread newThread(Runnable r) { return new Thread(r, \u0026#34;ActiveObject-\u0026#34; + name + \u0026#34;-\u0026#34; + count.getAndIncrement()); } }); processingFuture = CompletableFuture.runAsync(() -\u0026gt; { while (isAcceptingRequests) { try { executorService.execute(requests.take()); if (sleepMillis != null) { Thread.sleep(sleepMillis); } } catch (InterruptedException e) { Thread.currentThread().interrupt(); log.warn(\u0026#34;Active Object thread interrupted, reason: {}\u0026#34;, e.getMessage()); } catch (Exception e) { log.error(\u0026#34;Error processing request: {}\u0026#34;, e.getMessage()); // 发送告警信息 } } }).exceptionally(e -\u0026gt; { log.error(\u0026#34;Exception occurred in ActiveObject thread: {}\u0026#34;, e.getMessage()); return null; }); } public void submit(Runnable task) { requests.offer(task); } public void stop() { isAcceptingRequests = false; processingFuture.cancel(true); executorService.shutdown(); } public static synchronized ActiveObject getInstance(String name) { return getInstance(name, 16, null); } public static synchronized ActiveObject getInstance(String name, int queueSize, Long sleepMillis) { ActiveObject instance = INSTANCES.get(name); if (instance == null) { instance = new ActiveObject(name, queueSize, sleepMillis); INSTANCES.put(name, instance); } return instance; } public String getName() { return name; } } 总结 活动对象模式是一种支持异步处理和事件驱动的设计模式，适用于一些需要高性能、可伸缩和可靠的应用场景。以下是几个适用于活动对象模式的使用场景：\n大规模并发处理：在大规模并发的情况下，使用传统的同步处理方式会导致系统性能下降和响应时间延长。使用活动对象模式可以将并发请求转换成异步事件，通过事件驱动机制实现高性能和可伸缩。 高吞吐量数据处理：在需要处理大量数据的情况下，使用活动对象模式可以利用多核 CPU 和异步处理技术，提高系统的处理能力和吞吐量。 异步消息传递：在需要异步处理消息的情况下，使用活动对象模式可以实现异步消息的处理和分发，提高系统的可靠性和可维护性。 分布式系统：在分布式系统中，使用活动对象模式可以实现异步消息传递和事件驱动，提高系统的可靠性和可伸缩性。同时，活动对象模式还可以通过分布式锁和分布式计算等技术实现分布式并发控制和计算，提高系统的性能和可靠性。 UI 和后台逻辑分离：在需要将 UI 和后台逻辑分离的情况下，使用活动对象模式可以实现 UI 和后台逻辑的解耦和异步处理，提高系统的可维护性和可扩展性。 异步 IO 操作：在需要进行异步 IO 操作的情况下，使用活动对象模式可以实现非阻塞 IO 和异步事件处理，提高系统的性能和响应时间。 总的来说，活动对象模式适用于一些需要异步处理、事件驱动、高性能、可伸缩和可靠的应用场景。通过使用活动对象模式，可以提高系统的性能和可维护性，同时降低系统的复杂度和成本。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/26/java-design-patterns-active-object/","summary":"本文主要介绍 Active Object 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 活动对象（Active Object）是一种设计模式，其主要目的是将并发和异步处理的问题从客户端代码中分离出来，从而提高系统的性能、可靠性和可维护性。活动对象模式是一种能够帮助开发人员处理多线程、异步和并发问题的设计模式。\n在传统的并发编程模型中，客户端代码需要直接管理线程和锁等细节，这样会导致代码复杂度和维护成本的增加，同时也容易出现各种问题，如死锁、竞态条件等。活动对象模式通过引入活动对象来解决这些问题，活动对象将客户端代码发送的消息添加到内部的消息队列中，并使用单独的线程异步处理这些消息。这种模式可以提高系统的性能和可扩展性，同时使得客户端代码更加简单和易于维护。\n活动对象模式的目的包括：\n将并发和异步处理的问题从客户端代码中分离出来，从而使得客户端代码更加简单和易于维护。客户端代码只需要发送消息即可，不需要关心异步处理的细节，活动对象将并发和异步处理的问题封装起来，提供简单的接口供客户端使用。 提高系统的性能和可扩展性。活动对象使用单独的线程池异步处理消息，可以更好地利用系统资源，提高系统的性能和可扩展性。 提高系统的可靠性和健壮性。活动对象将消息添加到内部的消息队列中，避免了竞态条件和死锁等问题，从而提高了系统的可靠性和健壮性。 将多线程和异步处理的细节封装起来，使得客户端代码更加抽象和通用。客户端代码可以使用相同的接口来访问不同的服务，从而提高代码的复用性和可维护性。 解释 活动对象模式的核心思想是将并发和异步处理的问题从客户端代码中分离出来。具体来说，活动对象模式包含以下几个关键组件：\n活动对象（Active Object）：活动对象是一个封装了某种服务的对象，它将客户端代码发送的消息添加到内部的消息队列中，并使用单独的线程异步处理这些消息。活动对象通常包含一个消息队列和一个线程池，用于异步处理消息。 方法调用请求（Method Invocation Request）：客户端代码向活动对象发送方法调用请求，包括方法名和参数列表等信息。活动对象将方法调用请求封装为一个消息对象，并添加到内部的消息队列中。 消息队列（Message Queue）：消息队列是活动对象内部用于存储方法调用请求的队列。活动对象将客户端代码发送的消息添加到消息队列中，并使用单独的线程异步处理这些消息。 线程池（Thread Pool）：线程池是活动对象用于异步处理消息的线程池。活动对象从消息队列中取出消息，并使用线程池中的线程异步处理这些消息。 程序示例\npublic abstract class ActiveCreature{ private final Logger logger = LoggerFactory.getLogger(ActiveCreature.class.getName()); private BlockingQueue\u0026lt;Runnable\u0026gt; requests; private String name; private Thread thread; public ActiveCreature(String name) { this.name = name; this.requests = new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;(); thread = new Thread(new Runnable() { @Override public void run() { while (true) { try { requests.","title":"Java设计模式：Active Object"},{"content":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：考虑实现 Comparable 接口。\n介绍 与本章讨论的其他方法不同，compareTo 方法不是在 Object 中声明的。相反，它是 Comparable 接口中的唯一方法。它在性质上类似于 Object 的 equals 方法，除了简单的相等比较之外，它还允许顺序比较，而且它是通用的。一个类实现 Comparable，表明实例具有自然顺序。对实现 Comparable 的对象数组进行排序非常简单：\nArrays.sort(a); 类似地，搜索、计算极值和维护 Comparable 对象的自动排序集合也很容易。例如，下面的程序依赖于 String 实现 Comparable 这一事实，将命令行参数列表按字母顺序打印出来，并消除重复：\npublic class WordList { public static void main(String[] args) { Set\u0026lt;String\u0026gt; s = new TreeSet\u0026lt;\u0026gt;(); Collections.addAll(s, args); System.out.println(s); } } 通过让类实现 Comparable，就可与依赖于此接口的所有通用算法和集合实现进行互操作。你只需付出一点点努力就能获得强大的功能。实际上，Java 库中的所有值类以及所有枚举类型都实现了 Comparable。如果编写的值类具有明显的自然顺序，如字母顺序、数字顺序或时间顺序，则应实现 Comparable 接口：\npublic interface Comparable\u0026lt;T\u0026gt; { int compareTo(T t); } compareTo 方法的一般约定类似于 equals 方法：\n将一个对象与指定的对象进行顺序比较。当该对象小于、等于或大于指定对象时，对应返回一个负整数、零或正整数。如果指定对象的类型阻止它与该对象进行比较，则抛出 ClassCastException。\n在下面的描述中，sgn(expression) 表示数学中的符号函数，它被定义为：根据传入表达式的值是负数、零或正数，对应返回 -1、0 或 1。\n实现者必须确保所有 x 和 y 满足 sgn(x.compareTo(y)) == -sgn(y.compareTo(x))（这意味着 x.compareTo(y) 当且仅当 y.compareTo(x) 抛出异常时才抛出异常）。 实现者还必须确保关系是可传递的：(x.compareTo(y) \u0026gt; 0 \u0026amp;\u0026amp; y.compareTo(z) \u0026gt; 0) 意味着 x.compareTo(z) \u0026gt; 0。 最后，实现者必须确保 x.compareTo(y) == 0 时，所有的 z 满足 sgn(x.compareTo(z)) == sgn(y.compareTo(z))。 强烈建议 (x.compareTo(y)== 0) == (x.equals(y)) 成立，但不是必需的。一般来说，任何实现 Comparable 接口并违反此条件的类都应该清楚地注明这一事实。推荐使用的表述是「注意：该类的自然顺序与 equals 不一致。」 不要被这些约定的数学性质所影响。就像 equals 约定一样，这个约定并不像看起来那么复杂。与 equals 方法不同，equals 方法对所有对象都施加了全局等价关系，compareTo 不需要跨越不同类型的对象工作：当遇到不同类型的对象时，compareTo 允许抛出 ClassCastException。通常，它就是这么做的。该约定确实允许类型间比较，这种比较通常在被比较对象实现的接口中定义。\n就像违反 hashCode 约定的类可以破坏依赖 hash 的其他类一样，违反 compareTo 约定的类也可以破坏依赖 Comparable 的其他类。依赖 Comparable 的类包括排序集合 TreeSet 和 TreeMap，以及实用工具类 Collections 和 Arrays，它们都包含搜索和排序算法。\n让我们看一下 compareTo 约定的细节。第一个规定指出，如果你颠倒两个对象引用之间的比较的方向，就应当发生这样的情况：如果第一个对象小于第二个对象，那么第二个对象必须大于第一个；如果第一个对象等于第二个对象，那么第二个对象一定等于第一个对象；如果第一个对象大于第二个对象，那么第二个对象一定小于第一个对象。第二个规定指出，如果一个对象大于第二个，第二个大于第三个，那么第一个对象一定大于第三个对象。最后一个规定指出，所有 compareTo 结果为相等的对象分别与任何其他对象相比，必须产生相同的结果。\n这三种规定的一个结果是，由 compareTo 方法进行的相等性检验必须遵守由 equals 约定进行的相同的限制：反身性、对称性和传递性。因此，同样的警告也适用于此：除非你愿意放弃面向对象的抽象优点，否则无法在保留 compareTo 约定的同时使用新值组件扩展可实例化类。同样的解决方案也适用。如果要向实现 Comparable 的类中添加值组件，不要继承它；编写一个不相关的类，其中包含第一个类的实例。然后提供返回所包含实例的「视图」方法。这使你可以自由地在包含类上实现你喜欢的任何 compareTo 方法，同时允许它的客户端在需要时将包含类的实例视为包含类的实例。\ncompareTo 约定的最后一段是一个强烈的建议，而不是一个真正的要求，它只是简单地说明了 compareTo 方法所施加的同等性检验通常应该与 equals 方法返回相同的结果。如果遵守了这一规定，则 compareTo 方法所施加的排序与 equals 方法一致。如果违反这条建议，那么它的顺序就与 equals 不一致。如果一个类的 compareTo 方法强加了一个与 equals 不一致的顺序，那么这个类仍然可以工作，但是包含该类元素的有序集合可能无法遵守集合接口（Collection、Set 或 Map）的一般约定。这是因为这些接口的一般约定是根据 equals 方法定义的，但是有序集合使用 compareTo 代替了 equals 实施同等性检验。如果发生这种情况，这不是一场灾难，但这是需要注意的。\n例如，考虑 BigDecimal 类，它的 compareTo 方法与 equals 不一致。如果你创建一个空的 HashSet 实例，然后添加 new BigDecimal(\u0026quot;1.0\u0026quot;) 和 new BigDecimal(\u0026quot;1.00\u0026quot;)，那么该 HashSet 将包含两个元素，因为添加到该集合的两个 BigDecimal 实例在使用 equals 方法进行比较时结果是不相等的。但是，如果你使用 TreeSet 而不是 HashSet 执行相同的过程，那么该集合将只包含一个元素，因为使用 compareTo 方法比较两个 BigDecimal 实例时结果是相等的。（有关详细信息，请参阅 BigDecimal 文档。）\n编写 compareTo 方法类似于编写 equals 方法，但是有一些关键的区别。因为 Comparable 接口是参数化的，compareTo 方法是静态类型的，所以不需要进行类型检查或强制转换它的参数。如果参数类型错误，则该调用将不能编译。如果参数为 null，则调用应该抛出 NullPointerException，并且在方法尝试访问其成员时抛出该异常。\n在 compareTo 方法中，字段是按顺序而不是按同等性来比较的。要比较对象引用字段，要递归调用 compareTo 方法。如果一个字段没有实现 Comparable，或者需要一个非标准的排序，那么应使用 Comparator。可以编写自定义的比较器，或使用现有的比较器，如 CaseInsensitiveString 的 compareTo 方法：\n// Single-field Comparable with object reference field public final class CaseInsensitiveString implements Comparable\u0026lt;CaseInsensitiveString\u0026gt; { public int compareTo(CaseInsensitiveString cis) { return String.CASE_INSENSITIVE_ORDER.compare(s, cis.s); } ... // Remainder omitted } 注意 CaseInsensitiveString 实现了 Comparable\u0026lt;CaseInsensitiveString\u0026gt;。这意味着 CaseInsensitiveString 引用只能与另一个 CaseInsensitiveString 引用进行比较。这是在声明实现 Comparable 的类时要遵循的常规模式。\n本书的旧版本建议 compareTo 方法使用关系运算符 \u0026lt; 和 \u0026gt; 来比较整数基本类型字段，使用静态方法 Double.compare 和 Float.compare 来比较浮点基本类型字段。在 Java 7 中，静态比较方法被添加到所有 Java 的包装类中。在 compareTo 方法中使用关系运算符 \u0026lt; 和 \u0026gt; 冗长且容易出错，因此不再推荐使用。\n如果一个类有多个重要字段，那么比较它们的顺序非常关键。从最重要的字段开始，一步步往下。如果比较的结果不是 0（用 0 表示相等），那么就完成了；直接返回结果。如果最重要的字段是相等的，就比较下一个最重要的字段，以此类推，直到找到一个不相等的字段或比较到最不重要的字段为止。下面是 PhoneNumber 类的 compareTo 方法，演示了这种技术：\n// Multiple-field Comparable with primitive fields public int compareTo(PhoneNumber pn) { int result = Short.compare(areaCode, pn.areaCode); if (result == 0) { result = Short.compare(prefix, pn.prefix); if (result == 0) result = Short.compare(lineNum, pn.lineNum); } return result; } 在 Java 8 中，Comparator 接口配备了一组比较器构造方法，可以流畅地构造比较器。然后可以使用这些比较器来实现 Comparator 接口所要求的 compareTo 方法。许多程序员更喜欢这种方法的简明，尽管它存在一些性能成本：在我的机器上，PhoneNumber 实例的数组排序要慢 10% 左右。在使用这种方法时，请考虑使用 Java 的静态导入功能，这样你就可以通过静态比较器构造方法的简单名称来引用它们，以获得清晰和简洁。下面是 PhoneNumber 类的 compareTo 方法改进后的样子：\n// Comparable with comparator construction methods private static final Comparator\u0026lt;PhoneNumber\u0026gt; COMPARATOR = comparingInt((PhoneNumber pn) -\u0026gt; pn.areaCode) .thenComparingInt(pn -\u0026gt; pn.prefix) .thenComparingInt(pn -\u0026gt; pn.lineNum); public int compareTo(PhoneNumber pn) { return COMPARATOR.compare(this, pn); } 这个实现在类初始化时使用两个比较器构造方法构建一个比较器。第一个是 comparingInt。它是一个静态方法，接受一个 key 提取器函数，该函数将对象引用映射到 int 类型的 key ，并返回一个比较器，比较器根据该 key 对实例进行排序。在上述的示例中，comparingInt 使用 lambda 表达式从 PhoneNumber 中提取 areaCode，并返回 Comparator\u0026lt;PhoneNumber\u0026gt;，按区号来排序电话号码。注意，lambda 表达式显式地指定其输入参数的类型为 PhoneNumber。事实证明，在这种情况下，Java 的类型推断并没有强大到足以自己判断类型，因此我们不得不帮助它来编译程序。\n如果两个电话号码有相同的区号，我们需要进一步改进比较，这正是第二个 comparator 构造方法 thenComparingInt 所做的。它是 Comparator 上的一个实例方法，它接受一个 int 类型的 key 提取函数，并返回一个比较器，该比较器首先应用原始比较器，然后使用提取的 key 来断开连接。你可以任意堆叠对 thenComparingInt 的调用，从而形成字典顺序。在上面的例子中，我们将两个对 thenComparingInt 的调用叠加起来，得到一个排序，它的第二个 key 是 prefix，而第三个 key 是 lineNum。注意，我们不必指定传递给两个调用 thenComparingInt 的 key 提取器函数的参数类型：Java 的类型推断足够智能，可以自行解决这个问题。\nComparator 类具有完整的构造方法。对于 long 和 double 的基本类型，有类似 comparingInt 和 thenComparingInt 的方法。int 版本还可以用于范围更小的整数类型，如 PhoneNumber 示例中的 short。double 版本也可以用于 float。Comparator 类提供的构造方法覆盖了所有 Java 数值基本类型。\n也有对象引用类型的比较器构造方法。静态方法名为 compare，它有两个重载。一个是使用 key 提取器并使用 key 的自然顺序。第二种方法同时使用 key 提取器和比较器对提取的 key 进行比较。实例方法有三种重载，称为 thenComparing。一个重载只需要一个比较器并使用它来提供一个二级顺序。第二个重载只接受一个 key 提取器，并将 key 的自然顺序用作二级顺序。最后的重载需要一个 key 提取器和一个比较器来对提取的 key 进行比较。\n有时候，你可能会看到 compareTo 或 compare 方法，它们依赖于以下事实：如果第一个值小于第二个值，则两个值之间的差为负；如果两个值相等，则为零；如果第一个值大于零，则为正。下面是一个例子：\n// BROKEN difference-based comparator - violates transitivity! static Comparator\u0026lt;Object\u0026gt; hashCodeOrder = new Comparator\u0026lt;\u0026gt;() { public int compare(Object o1, Object o2) { return o1.hashCode() - o2.hashCode(); } }; 不要使用这种技术。它充满了来自整数溢出和 IEEE 754 浮点运算构件的危险 [JLS 15.20.1, 15.21.1]。此外，生成的方法不太可能比使用本项目中描述的技术编写的方法快得多。应使用静态比较方法：\n// Comparator based on static compare method static Comparator\u0026lt;Object\u0026gt; hashCodeOrder = new Comparator\u0026lt;\u0026gt;() { public int compare(Object o1, Object o2) { return Integer.compare(o1.hashCode(), o2.hashCode()); } }; 或比较器构造方法：\n// Comparator based on Comparator construction method static Comparator\u0026lt;Object\u0026gt; hashCodeOrder = Comparator .comparingInt(o -\u0026gt; o.hashCode()); 总之，无论何时实现具有排序性质的值类，都应该让类实现 Comparable 接口，这样就可以轻松地对实例进行排序、搜索，并与依赖于此接口的集合实现进行互操作。在 compareTo 方法的实现中比较字段值时，避免使用 \u0026lt; 和 \u0026gt; 操作符，应使用包装类中的静态比较方法或 Comparator 接口中的 comparator 构造方法。\n总结 建议在实现比较功能时，应该考虑实现 Comparable 接口。Comparable 接口是一个泛型接口，其中只包含一个方法 compareTo(T o)，用于比较当前对象和另一个对象的大小关系。实现 Comparable 接口可以使得一个类具有可比性，从而可以进行排序等操作。\n以下是在实现 Comparable 接口时需要注意的一些问题：\n首先，需要确保类实现了 Comparable 接口，并实现了 compareTo 方法。在实现 compareTo 方法时，需要考虑到对象的比较顺序，并返回一个整数值表示两个对象之间的大小关系。 在实现 compareTo 方法时，需要确保比较结果的一致性、对称性和传递性。具体来说，如果 a.compareTo(b) 返回正整数，那么 b.compareTo(a) 应该返回负整数；如果 a.compareTo(b) 和 b.compareTo(c) 的返回值都是正整数，那么 a.compareTo(c) 的返回值也应该是正整数。 如果一个类有多个可以比较的属性，那么在实现 compareTo 方法时需要按照比较的优先级进行比较。通常，可以先比较第一个属性，如果相等再比较第二个属性，以此类推。 如果一个类实现了 Comparable 接口，那么通常也应该同时实现 equals 和 hashCode 方法。在实现 equals 方法时，需要考虑到比较的对象是否为 null、对象类型是否相同等因素。在实现 hashCode 方法时，通常需要使用类中可比较属性的哈希值，以确保哈希表等数据结构能够正确地处理该类的对象。 如果一个类需要支持多种比较方式，那么可以考虑使用策略模式或者比较器（Comparator）接口来实现。使用比较器接口可以在运行时动态地指定比较方式，从而更加灵活。 实现 Comparable 接口的示例代码：\npublic class Person implements Comparable\u0026lt;Person\u0026gt; { private String name; private int age; public Person(String name,int age) { this.name = name; this.age = age; } // 实现 compareTo 方法，按照年龄升序排序 @Override public int compareTo(Person o) { return Integer.compare(this.age, o.age); } // 实现 equals 方法和 hashCode 方法 @Override public boolean equals(Object obj) { if (obj == this) { return true; } if (!(obj instanceof Person)) { return false; } Person other = (Person) obj; return Objects.equals(this.name, other.name) \u0026amp;\u0026amp; this.age == other.age; } @Override public int hashCode() { return Objects.hash(this.name, this.age); } } 在上面的示例代码中，Person 类实现了 Comparable 接口，并实现了 compareTo 方法。在该方法中，我们按照对象的年龄升序排序。为了确保 equals 方法和 hashCode 方法的正确性，我们也实现了这两个方法，以确保 Person 对象在使用哈希表等数据结构时能够正常工作。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/26/consider-implementing-comparable/","summary":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：考虑实现 Comparable 接口。\n介绍 与本章讨论的其他方法不同，compareTo 方法不是在 Object 中声明的。相反，它是 Comparable 接口中的唯一方法。它在性质上类似于 Object 的 equals 方法，除了简单的相等比较之外，它还允许顺序比较，而且它是通用的。一个类实现 Comparable，表明实例具有自然顺序。对实现 Comparable 的对象数组进行排序非常简单：\nArrays.sort(a); 类似地，搜索、计算极值和维护 Comparable 对象的自动排序集合也很容易。例如，下面的程序依赖于 String 实现 Comparable 这一事实，将命令行参数列表按字母顺序打印出来，并消除重复：\npublic class WordList { public static void main(String[] args) { Set\u0026lt;String\u0026gt; s = new TreeSet\u0026lt;\u0026gt;(); Collections.addAll(s, args); System.out.println(s); } } 通过让类实现 Comparable，就可与依赖于此接口的所有通用算法和集合实现进行互操作。你只需付出一点点努力就能获得强大的功能。实际上，Java 库中的所有值类以及所有枚举类型都实现了 Comparable。如果编写的值类具有明显的自然顺序，如字母顺序、数字顺序或时间顺序，则应实现 Comparable 接口：\npublic interface Comparable\u0026lt;T\u0026gt; { int compareTo(T t); } compareTo 方法的一般约定类似于 equals 方法：\n将一个对象与指定的对象进行顺序比较。当该对象小于、等于或大于指定对象时，对应返回一个负整数、零或正整数。如果指定对象的类型阻止它与该对象进行比较，则抛出 ClassCastException。\n在下面的描述中，sgn(expression) 表示数学中的符号函数，它被定义为：根据传入表达式的值是负数、零或正数，对应返回 -1、0 或 1。\n实现者必须确保所有 x 和 y 满足 sgn(x.compareTo(y)) == -sgn(y.compareTo(x))（这意味着 x.compareTo(y) 当且仅当 y.compareTo(x) 抛出异常时才抛出异常）。 实现者还必须确保关系是可传递的：(x.compareTo(y) \u0026gt; 0 \u0026amp;\u0026amp; y.compareTo(z) \u0026gt; 0) 意味着 x.compareTo(z) \u0026gt; 0。 最后，实现者必须确保 x.compareTo(y) == 0 时，所有的 z 满足 sgn(x.","title":"《Effective Java 3》笔记14：考虑实现 Comparable 接口"},{"content":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：明智地覆盖 clone 方法。\n介绍 Cloneable 接口的目的是作为 mixin 接口，用于让类来宣称它们允许克隆。不幸的是，它没有达到这个目的。它的主要缺点是缺少 clone 方法，并且 Object 类的 clone 方法是受保护的。如果不求助于反射，就不能仅仅因为对象实现了 Cloneable 接口就能调用 clone 方法。即使反射调用也可能失败，因为不能保证对象具有可访问的 clone 方法。尽管存在多种缺陷，但该机制的使用范围相当广泛，因此理解它是值得的。本条目将告诉你如何实现行为良好的 clone 方法，讨论什么时候应该这样做，并提供替代方案。\n既然 Cloneable 接口不包含任何方法，用它来做什么呢？它决定了 Object 类受保护的 clone 实现的行为：如果一个类实现了 Cloneable 接口，Object 类的 clone 方法则返回该类实例的逐字段拷贝；否则它会抛出 CloneNotSupportedException。这是接口非常不典型的一种使用方式，不应该效仿。通常，类实现接口可以表明类能够为其客户端做些什么。在本例中，它修改了超类上受保护的方法的行为。\n虽然规范没有说明，但是在实践中，实现 Cloneable 接口的类应该提供一个功能正常的公共 clone 方法。为了实现这一点，类及其所有超类必须遵守复杂的、不可强制执行的、文档很少的协议。产生的机制是脆弱的、危险的和非语言的：即它创建对象而不调用构造函数。\nclone 方法的一般约定很薄弱。下面的内容是从 Object 规范复制过来的：\n创建并返回此对象的副本。\u0026ldquo;副本\u0026rdquo; 的确切含义可能取决于对象的类。通常的意图是，对于任何对象 x，表达式\nx.clone() != x 将为 true，并且表达式\nx.clone().getClass() == x.getClass() 将为 true，但这并不是绝对要求。一般来说，对于任何对象 x 和 y，如果它们的 equals 方法返回 true，则表达式\nx.clone().equals(x) 也应返回 true。\nclone 方法创建并返回对象的副本。「副本」的确切含义可能取决于对象的类别。通常，对于任何对象 x，表达式 x.clone() != x、x.clone().getClass() == x.getClass() 以及 x.clone().equals(x) 的值都将为 true，但都不是绝对的。\n按照惯例，此方法返回的对象应通过调用 super.clone() 来获取。如果一个类及其所有父类（除了 Object）都遵循这个惯例，那么就会有以下情况：\nx.clone().getClass() == x.getClass(). 按照约定，clone 方法返回的对象应该通过调用 super.clone() 来获得。如果一个类和它的所有超类（Object 类除外）都遵守这个约定，在这种情况下，表达式 x.clone().getClass() == x.getClass() 则为 true。\n按照约定，返回的对象应该独立于被克隆的对象。为了实现这种独立性，可能需要在 super.clone() 返回前，修改对象的一个或多个字段。\n这种机制有点类似于构造方法链，只是没有强制执行：\n（1）如果一个类的 clone 方法返回的实例不是通过调用 super.clone() 而是通过调用构造函数获得的，编译器不会报错，但是如果这个类的一个子类调用 super.clone()，由此产生的对象类型将是错误的，影响子类 clone 方法正常工作。 （2）如果覆盖 clone 方法的类是 final 修饰的，那么可以安全地忽略这个约定，因为没有子类需要担心。 （3）如果一个 final 修饰的类不调用 super.clone() 的 clone 方法。类没有理由实现 Cloneable 接口，因为它不依赖于 Object 类的 clone 实现的行为。 class Base { @Override protected Object clone() throws CloneNotSupportedException { return new Base(); // ① } } class BasePro extends Base implements Cloneable { @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } public static void main(String[] args) throws Exception { BasePro basePro = new BasePro(); System.out.println(basePro.clone().getClass()); // 输出 class com.example.demo.Base System.out.println(basePro.getClass()); // 输出 class com.example.demo.BasePro } } 可采用两种方式修复\n① 处改用 super.clone() 移除 Base 类整个 clone() 实现 假设您想在一个类中实现 Cloneable 接口，而其超类提供了一个良好的 clone 方法。首先调用 super.clone() 方法。您得到的对象将是原始对象的一个完全功能的副本。在您的类中声明的任何字段都将具有与原始对象相同的值。如果每个字段都包含一个基本类型的值或一个不可变对象的引用，则返回的对象可能正是您所需要的，此时不需要进一步处理。例如，对于 PhoneNumber 类，就是这种情况，但请注意，不可变类不应提供 clone 方法，因为这只会鼓励浪费性的复制。在这个前提下，下面是一个 PhoneNumber 的 clone 方法的实现示例：\n// Clone method for class with no references to mutable state @Override public PhoneNumber clone() { try { return (PhoneNumber) super.clone(); } catch (CloneNotSupportedException e) { throw new AssertionError(); // Can\u0026#39;t happen } } 为了让这个方法工作，必须修改 PhoneNumber 类的声明，使之实现 Cloneable 接口。虽然 Object 的 clone 方法返回 Object 类型，但是这个 clone 方法返回 PhoneNumber 类型。这样做是合法的，也是可取的，因为 Java 的返回值类型支持协变。换句话说，覆盖方法的返回类型可以是被覆盖方法的返回类型的子类。这样就不需要在客户端中进行强制转换。我们必须把源自 Object 类的 super.clone() 方法在返回前将结果转换为 PhoneNumber 类型，这类强制转换肯定会成功。\n将 super.clone() 包含在 try-catch 块中。这是因为 Object 类声明的 clone 方法会抛出 CloneNotSupportedException，这是一种 checked exception。因为 PhoneNumber 类实现了 Cloneable 接口，所以我们知道对 super.clone() 的调用将会成功。这个样板文件的需求表明 CloneNotSupportedException 应该是 unchecked exception。\n如果对象的字段包含可变对象的引用，前面所示 clone 方法的这种简易实现可能引发灾难。例如，考虑 Stack 类：\npublic class Stack { private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { this.elements = new Object[DEFAULT_INITIAL_CAPACITY]; } public void push(Object e) { ensureCapacity(); elements[size++] = e; } public Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; // Eliminate obsolete reference return result; } // Ensure space for at least one more element. private void ensureCapacity() { if (elements.length == size) elements = Arrays.copyOf(elements, 2 * size + 1); } } 假设你想让这个类可克隆。如果 clone 方法只返回 super.clone()，得到的 Stack 实例在其 size 字段中会有正确的值，但其 elements 字段将引用与原始 Stack 实例相同的数组。修改初始值将破坏克隆的不变性，反之亦然。你将很快发现你的程序产生了无意义的结果或抛出 NullPointerException。\n调用 Stack 类中唯一构造函数的情况永远不会发生。实际上，clone 方法将充当构造函数；你必须确保它不会对原始对象造成伤害，并且 clone 方法正确地实现了不变性。为了使 Stack 类上的 clone 方法正常工作，它必须复制 Stack 类实例的内部。最简单的做法是在 elements 字段对应的数组递归调用 clone 方法：\n// Clone method for class with references to mutable state @Override public Stack clone() { try { Stack result = (Stack) super.clone(); result.elements = elements.clone(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } 注意，我们不需要将 elements.clone 的结果强制转换到 Object[]。在数组上调用 clone 方法将返回一个数组，该数组的运行时和编译时类型与被克隆的数组相同。这是复制数组的首选习惯用法。实际上，复制数组是 clone 机制唯一令人信服的使用场景。\n还要注意，如果 elements 字段是 final 修饰的，上述解决方案就无法工作，因为 clone 方法将被禁止为字段分配新值。这是一个基础问题：与序列化一样，可克隆体系结构与使用 final 修饰可变对象引用的常用方式不兼容，除非在对象与其克隆对象之间可以安全地共享可变对象。为了使类可克隆，可能需要从某些字段中删除 final 修饰符。\n仅仅递归调用 clone 方法并不总是足够的。例如，假设你正在为 HashTable 编写一个 clone 方法，HashTable 的内部由一组 bucket 组成，每个 bucket 引用键-值对链表中的第一个条目。为了提高性能，类实现了自己的轻量级单链表，而不是在内部使用 java.util.LinkedList：\npublic class HashTable implements Cloneable { private Entry[] buckets = ...; private static class Entry { final Object key; Object value; Entry next; Entry(Object key, Object value, Entry next) { this.key = key; this.value = value; this.next = next; } } ... // Remainder omitted } 假设你只是像对 Stack 所做的那样，递归克隆 bucket 数组，如下所示：\n// Broken clone method - results in shared mutable state! @Override public HashTable clone() { try { HashTable result = (HashTable) super.clone(); result.buckets = buckets.clone(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } 尽管 clone 方法有自己的 bucket 数组，但该数组引用的链接列表与原始链表相同，这很容易导致克隆和原始的不确定性行为。要解决这个问题，你必须复制包含每个 bucket 的链表。这里有一个常见的方法：\n// Recursive clone method for class with complex mutable state public class HashTable implements Cloneable { private Entry[] buckets = ...; private static class Entry { final Object key; Object value; Entry next; Entry(Object key, Object value, Entry next) { this.key = key; this.value = value; this.next = next; } // Recursively copy the linked list headed by this Entry Entry deepCopy() { return new Entry(key, value,next == null ? null : next.deepCopy()); } } @Override public HashTable clone() { try { HashTable result = (HashTable) super.clone(); result.buckets = new Entry[buckets.length]; for (int i = 0; i \u0026lt; buckets.length; i++) if (buckets[i] != null) result.buckets[i] = buckets[i].deepCopy(); return result; } catch (CloneNotSupportedException e) { throw new AssertionError(); } } ... // Remainder omitted } 私有内部类 HashTable.Entry 已经被增强，它提供了进行「深拷贝」的方法。HashTable 上的 clone 方法分配一个大小合适的新 buckets 数组，并遍历原始 buckets 数组，对每个非空 buckets 元素进行深拷贝。Entry 类的 deepCopy() 方法会被递归调用直至复制完整个链表（该链表以 Entry 类的实例作为头节点）。这种方法虽然很灵活，而且在 buckets 不太长的情况下可以很好地工作，但是克隆链表并不是一个好方法，因为它为链表中的每个元素消耗一个堆栈帧。如果列表很长，很容易导致堆栈溢出。为了防止这种情况的发生，你可以用迭代替换 deepCopy() 方法的递归调用：\n// Iteratively copy the linked list headed by this Entry Entry deepCopy() { Entry result = new Entry(key, value, next); for (Entry p = result; p.next != null; p = p.next) p.next = new Entry(p.next.key, p.next.value, p.next.next); return result; } 克隆复杂可变对象的最后一种方法是调用 super.clone()，将结果对象中的所有字段设置为初始状态，然后调用更高级别的方法重新生成原始对象的状态。在我们的 HashTable 示例中，buckets 字段将初始化为一个新的 bucket 数组，并且对于克隆的 hash 表中的每个键值映射将调用 put(key, value) 方法（未显示）。这种方法通常产生一个简单、相当优雅的 clone 方法，它的运行速度不如直接操作克隆的内部的方法快。虽然这种方法很简洁，但它与整个可克隆体系结构是对立的，因为它盲目地覆盖了构成体系结构基础的逐字段对象副本。\n与构造函数一样，clone 方法绝不能在正在构建的克隆上调用可覆盖方法。如果 clone 调用一个在子类中被重写的方法，这个方法将在子类有机会修复其在克隆中的状态之前执行，很可能导致克隆和原始的破坏。因此，前一段中讨论的 put(key, value) 方法应该是 final 修饰或 private 修饰的方法。（如果它是私有的，那么它可能是没有 final 修饰的公共「助手方法」。)\n对象的 clone 方法被声明为抛出 CloneNotSupportedException，但是重写方法不需要。公共克隆方法应该省略 throw 子句， 作为不抛出受控异常的方法更容易使用。\n用继承方式设计一个类时，你有两种选择，但是无论你选择哪一种，都不应该实现 Cloneable 接口。你可以选择通过实现一个功能正常的受保护克隆方法来模拟 Object 的行为，该方法声明为抛出 CloneNotSupportedException。这给子类实现 Cloneable 或不实现 Cloneable 的自由，就像它们直接扩展对象一样。或者，你可以选择不实现一个有效的克隆方法，并通过提供以下退化的克隆实现来防止子类实现它：\n// clone method for extendable class not supporting Cloneable @Override protected final Object clone() throws CloneNotSupportedException { throw new CloneNotSupportedException(); } 还有一个细节需要注意。如果你编写了一个实现了 Cloneable 接口的线程安全类，请记住它的 clone 方法必须正确同步，就像其他任何方法一样。Object 类的 clone 方法不是同步的，因此即使它的实现在其他方面是令人满意的，你也可能需要编写一个返回 super.clone() 的同步 clone 方法。\n回顾一下，所有实现 Cloneable 接口的类都应该使用一个返回类型为类本身的公共方法覆盖 clone。这个方法应该首先调用 super.clone()，然后「修复」任何需要「修复」的字段。通常，这意味着复制任何包含对象内部「深层结构」的可变对象，并将克隆对象对这些对象的引用替换为对其副本的引用。虽然这些内部副本通常可以通过递归调用 clone 来实现，但这并不总是最好的方法。如果类只包含基本数据类型的字段或对不可变对象的引用，那么很可能不需要修复任何字段。这条规则也有例外。例如，表示序列号或其他唯一 ID 的字段需要修复，即使它是基本数据类型或不可变的。\n搞这么复杂真的有必要吗？答案是否定的。如果你扩展了一个已经实现了 Cloneable 接口的类，那么除了实现行为良好的 clone 方法之外，你别无选择。否则，最好提供对象复制的替代方法。一个更好的对象复制方法是提供一个复制构造函数或复制工厂。复制构造函数是一个简单的构造函数，它接受单个参数，其类型是包含构造函数的类，例如：\n// Copy constructor public Yum(Yum yum) { ... }; 复制工厂与复制构造函数的静态工厂类似：\n// Copy factory public static Yum newInstance(Yum yum) { ... }; 复制构造函数方法及其静态工厂变体与克隆/克隆相比有许多优点：它们不依赖于易发生风险的语言外对象创建机制；他们不要求无法强制执行的约定；它们与最终字段的正确使用不冲突；它们不会抛出不必要的检查异常；而且不需要强制类型转换。\n此外，复制构造函数或工厂可以接受类型为类实现的接口的参数。例如，按照约定，所有通用集合实现都提供一个构造函数，其参数为 collection 或 Map 类型。基于接口的复制构造函数和工厂（更确切地称为转换构造函数和转换工厂）允许客户端选择副本的实现类型，而不是强迫客户端接受原始的实现类型。例如，假设你有一个 HashSet s，并且希望将它复制为 TreeSet。克隆方法不能提供这种功能，但是使用转换构造函数很容易：new TreeSet\u0026lt;\u0026gt;(s)。\n考虑到与 Cloneable 相关的所有问题，新的接口不应该扩展它，新的可扩展类不应该实现它。虽然 final 类实现 Cloneable 接口的危害要小一些，但这应该被视为一种性能优化，仅在极少数情况下是合理的。通常，复制功能最好由构造函数或工厂提供。这个规则的一个明显的例外是数组，最好使用 clone 方法来复制数组。\n总结 建议慎重覆盖 clone() 方法。clone() 方法是一个用于对象复制的方法，它可以创建一个新的对象，并将原始对象的状态复制到新的对象中。但是，在实现 clone() 方法时，需要注意一些问题，否则使用 clone() 方法可能会导致一些潜在的问题。\n以下是在实现 clone() 方法时需要注意的一些问题：\n首先，需要确保类实现了 Cloneable 接口。这个接口是一个标记接口，没有任何方法，但是如果一个类没有实现 Cloneable 接口，调用其 clone() 方法会抛出 CloneNotSupportedException 异常。 在实现 clone() 方法时，需要调用 super.clone() 方法来创建一个新的对象，并将原始对象的状态复制到新的对象中。 如果类的成员变量包含可变对象，那么需要对这些成员变量进行深度复制，以确保新对象与原始对象具有不同的状态。 clone() 方法返回的对象类型是 Object，需要进行类型转换，这可能会导致一些类型安全问题。因此，建议在覆盖 clone() 方法时，将返回类型声明为类本身的类型，并在方法中进行类型转换。 在实现 clone() 方法时，需要注意对异常的处理。如果一个类没有实现 Cloneable 接口，调用其 clone() 方法会抛出 CloneNotSupportedException 异常。在实现 clone() 方法时，需要考虑这个异常，并在方法中进行适当的处理。 总之，在覆盖 clone() 方法时，需要考虑到上述问题，并根据实际情况进行处理。在某些情况下，可能需要采用其他的复制方式，例如序列化和反序列化。因此，在覆盖 clone() 方法之前，需要仔细考虑是否真正需要使用该方法，并根据实际情况选择最合适的复制方式。\n扩展 1、深度拷贝和浅度拷贝 深度拷贝和浅度拷贝是指在进行对象复制时，对于对象中包含的成员变量，如何进行复制的问题。\n浅度拷贝是指只复制对象中的基本数据类型和引用类型的地址，而不是引用类型所指向的对象本身。这就意味着，在进行浅度拷贝时，原始对象和复制对象中的引用类型成员变量将指向同一个对象，这可能会导致一些潜在的问题，例如一个对象的状态的改变会影响到另一个对象。\n深度拷贝是指将对象中的基本数据类型和引用类型所指向的对象都进行复制。这就意味着，在进行深度拷贝时，原始对象和复制对象中的引用类型成员变量将指向不同的对象，这可以避免上述问题。\n例如，考虑一个包含一个引用类型成员变量的类 Person，其中引用类型成员变量是一个 Address 对象。如果进行浅度拷贝，那么复制对象中的 address成员变量将指向原始对象中的 address 成员变量指向的同一个 Address 对象。这就意味着，如果修改复制对象中的 address 成员变量，原始对象中的 address 成员变量也会发生改变。\n如果进行深度拷贝，那么复制对象中的 address 成员变量将指向一个新的 Address 对象，这样就可以避免修改一个对象对另一个对象造成的影响。\n需要注意的是，进行深度拷贝可能会导致性能问题，因为需要递归地复制对象中的所有成员变量和引用类型所指向的对象。因此，在进行对象复制时，需要根据实际情况选择适当的复制方式，以权衡性能和正确性。\n在 Java 中，通过实现 Cloneable 接口和覆盖 clone() 方法，可以实现对象的浅度拷贝。如果需要进行深度拷贝，可以通过序列化和反序列化实现，或者使用第三方库进行对象复制。\n2、请问在 Java 中如何实现深度拷贝？ 在 Java 中，可以通过以下几种方式实现深度拷贝：\n通过实现 Serializable 接口实现深度拷贝：在需要进行深度拷贝的类中实现 Serializable 接口，并通过序列化和反序列化实现深度拷贝。具体来说，可以将对象序列化为字节数组，然后再将字节数组反序列化为一个新的对象。需要注意的是，对象中的所有成员变量都必须是可序列化的，否则将会抛出 NotSerializableException 异常。\n下面是一个通过实现 Serializable 接口实现深度拷贝的示例代码：\nimport java.io.*; public class Person implements Serializable { private String name; private Address address; // 构造方法和 getter/setter 方法省略 public Person deepCopy() throws IOException, ClassNotFoundException { // 将对象序列化为字节数组 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(this); oos.flush(); // 将字节数组反序列化为一个新的对象 ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray()); ObjectInputStream ois = new ObjectInputStream(bis); return (Person) ois.readObject(); } } 在上面的示例代码中，通过实现 Serializable 接口，并在 deepCopy() 方法中将对象序列化为字节数组，然后再将字节数组反序列化为一个新的对象，从而实现了深度拷贝。需要注意的是，对象中的所有成员变量都必须是可序列化的，否则将会抛出 NotSerializableException 异常。\n通过实现自定义深度拷贝方法实现深度拷贝：在需要进行深度拷贝的类中实现自定义的深度拷贝方法，递归地复制对象中的所有成员变量和引用类型所指向的对象。需要注意的是，如果对象中的成员变量包含循环引用，那么需要对循环引用进行特殊处理，以避免无限递归。\n使用第三方库实现深度拷贝：Java 中有许多第三方库可以用于实现深度拷贝，例如 Apache Commons 的 SerializationUtils、Google 的 Gson、Jackson 等。\n下面是一个使用 Jackson 库实现深度拷贝的示例代码：\nimport com.fasterxml.jackson.databind.ObjectMapper; public class Person { private String name; private Address address; // 构造方法和 getter/setter 方法省略 public Person deepCopy() throws IOException { ObjectMapper objectMapper = new ObjectMapper(); String json = objectMapper.writeValueAsString(this); return objectMapper.readValue(json, Person.class); } } 在上面的示例代码中，通过使用 Jackson 库将对象转换为 JSON 字符串，然后再将 JSON 字符串转换为新的对象，从而实现了深度拷贝。需要注意的是，如果对象中的成员变量包含循环引用，那么需要对循环引用进行特殊处理，以避免无限递归。\n使用流式 API：Java 8 引入了流式 API，可以使用流式 API 来实现对象的深度拷贝。具体来说，可以使用 map() 方法将对象流中的每个元素复制为一个新的对象，然后使用 collect() 方法将新对象收集到一个集合中。需要注意的是，如果对象中的成员变量包含循环引用，那么需要对循环引用进行特殊处理，以避免无限递归。\n当使用流式 API 实现深度拷贝时，可以使用 map() 方法将对象流中的每个元素复制为一个新的对象，然后使用 collect() 方法将新对象收集到一个集合中。需要注意的是，如果对象中的成员变量包含循环引用，那么需要对循环引用进行特殊处理，以避免无限递归。\n以下是一个使用流式 API 实现深度拷贝的示例代码：\nimport java.util.List; import java.util.stream.Collectors; public class Person { private String name; private Address address; // 构造方法和 getter/setter 方法省略 public Person deepCopy() { List\u0026lt;Address\u0026gt; addresses = this.addresses.stream() .map(Address::deepCopy) // 使用 map() 方法将每个 Address 对象复制为一个新的对象 .collect(Collectors.toList()); // 使用 collect() 方法将新对象收集到一个集合中 return new Person(this.name, addresses); } } public class Address { private String street; private String city; // 构造方法和 getter/setter 方法省略 public Address deepCopy() { return new Address(this.street, this.city); // 直接复制 Address 对象即可，因为 Address 类中没有引用类型的成员变量 } } 在上面的示例代码中，通过使用流式 API 将 addresses 集合中的每个 Address 对象复制为一个新的对象，并将新对象收集到一个集合中，从而实现了 Person 对象的深度拷贝。需要注意的是，在实现 Address 的 deepCopy() 方法时，因为 Address 类中没有引用类型的成员变量，因此可以直接复制一个新的 Address 对象即可。\n需要注意的是，如果对象中的成员变量包含循环引用，那么需要进行特殊处理，以避免无限递归。例如，在上面的示例代码中，如果 Person 类中包含一个 List\u0026lt;Person\u0026gt; 类型的成员变量，那么在进行深度拷贝时就需要对 List\u0026lt;Person\u0026gt; 进行特殊处理。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/26/override-clone-judiciously/","summary":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：明智地覆盖 clone 方法。\n介绍 Cloneable 接口的目的是作为 mixin 接口，用于让类来宣称它们允许克隆。不幸的是，它没有达到这个目的。它的主要缺点是缺少 clone 方法，并且 Object 类的 clone 方法是受保护的。如果不求助于反射，就不能仅仅因为对象实现了 Cloneable 接口就能调用 clone 方法。即使反射调用也可能失败，因为不能保证对象具有可访问的 clone 方法。尽管存在多种缺陷，但该机制的使用范围相当广泛，因此理解它是值得的。本条目将告诉你如何实现行为良好的 clone 方法，讨论什么时候应该这样做，并提供替代方案。\n既然 Cloneable 接口不包含任何方法，用它来做什么呢？它决定了 Object 类受保护的 clone 实现的行为：如果一个类实现了 Cloneable 接口，Object 类的 clone 方法则返回该类实例的逐字段拷贝；否则它会抛出 CloneNotSupportedException。这是接口非常不典型的一种使用方式，不应该效仿。通常，类实现接口可以表明类能够为其客户端做些什么。在本例中，它修改了超类上受保护的方法的行为。\n虽然规范没有说明，但是在实践中，实现 Cloneable 接口的类应该提供一个功能正常的公共 clone 方法。为了实现这一点，类及其所有超类必须遵守复杂的、不可强制执行的、文档很少的协议。产生的机制是脆弱的、危险的和非语言的：即它创建对象而不调用构造函数。\nclone 方法的一般约定很薄弱。下面的内容是从 Object 规范复制过来的：\n创建并返回此对象的副本。\u0026ldquo;副本\u0026rdquo; 的确切含义可能取决于对象的类。通常的意图是，对于任何对象 x，表达式\nx.clone() != x 将为 true，并且表达式\nx.clone().getClass() == x.getClass() 将为 true，但这并不是绝对要求。一般来说，对于任何对象 x 和 y，如果它们的 equals 方法返回 true，则表达式\nx.clone().equals(x) 也应返回 true。\nclone 方法创建并返回对象的副本。「副本」的确切含义可能取决于对象的类别。通常，对于任何对象 x，表达式 x.clone() != x、x.clone().getClass() == x.getClass() 以及 x.clone().equals(x) 的值都将为 true，但都不是绝对的。\n按照惯例，此方法返回的对象应通过调用 super.clone() 来获取。如果一个类及其所有父类（除了 Object）都遵循这个惯例，那么就会有以下情况：\nx.clone().getClass() == x.getClass(). 按照约定，clone 方法返回的对象应该通过调用 super.clone() 来获得。如果一个类和它的所有超类（Object 类除外）都遵守这个约定，在这种情况下，表达式 x.clone().getClass() == x.getClass() 则为 true。\n按照约定，返回的对象应该独立于被克隆的对象。为了实现这种独立性，可能需要在 super.clone() 返回前，修改对象的一个或多个字段。","title":"《Effective Java 3》笔记13：明智地覆盖 clone 方法"},{"content":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：始终覆盖 toString 方法。\n介绍 虽然 Object 提供 toString 方法的实现，但它返回的字符串通常不是类的用户希望看到的。它由后跟「at」符号（@）的类名和 hash 代码的无符号十六进制表示（例如 PhoneNumber@163b91）组成。toString 的通用约定是这么描述的，返回的字符串应该是「简洁但信息丰富的表示，易于阅读」。虽然有人认为 PhoneNumber@163b91 简洁易懂，但与 707-867-5309 相比，它的信息量并不大。toString 约定接着描述，「建议所有子类覆盖此方法。」好建议，确实！\n虽然它不如遵守 equals 和 hashCode 约定那么重要，但是 提供一个好的 toString 实现（能）使类更易于使用，使用该类的系统（也）更易于调试。 当对象被传递给 println、printf、字符串连接操作符或断言或由调试器打印时，将自动调用 toString 方法。即使你从来没有调用 toString 对象，其他人也可能（使用）。例如，有对象引用的组件可以在日志错误消息中包含对象的字符串表示。如果你未能覆盖 toString，则该消息可能完全无用。\n如果你已经为 PhoneNumber 提供了一个好的 toString 方法，那么生成一个有用的诊断消息就像这样简单：\nSystem.out.println(\u0026#34;Failed to connect to \u0026#34; + phoneNumber); 无论你是否覆盖 toString，程序员都会以这种方式生成诊断消息，但是除非你（覆盖 toString），否则这些消息不会有用。提供好的 toString 方法的好处不仅仅是将类的实例扩展到包含对这些实例的引用的对象，特别是集合。在打印 map 时，你更愿意看到哪个，{Jenny=PhoneNumber@163b91} 还是 {Jenny=707-867-5309}？\n当实际使用时，toString 方法应该返回对象中包含的所有有趣信息， 如电话号码示例所示。如果对象很大，或者包含不利于字符串表示的状态，那么这种方法是不切实际的。在这种情况下，toString 应该返回一个摘要，例如曼哈顿住宅电话目录（1487536 号清单）或 Thread[main,5,main]。理想情况下，字符串应该是不言自明的。（线程示例未能通过此测试。）如果没有在字符串表示中包含所有对象的有趣信息，那么一个特别恼人的惩罚就是测试失败报告，如下所示：\nAssertion failure: expected {abc, 123}, but was {abc, 123}. 在实现 toString 方法时，你必须做的一个重要决定是是否在文档中指定返回值的格式。建议你针对值类（如电话号码或矩阵）这样做。指定格式的优点是，它可以作为对象的标准的、明确的、人类可读的表示。这种表示可以用于输入和输出，也可以用于持久的人类可读数据对象，比如 CSV 文件。如果指定了格式，提供一个匹配的静态工厂或构造函数通常是一个好主意，这样程序员就可以轻松地在对象及其字符串表示之间来回转换。Java 库中的许多值类都采用这种方法，包括 BigInteger、BigDecimal 和大多数包装类。\n指定 toString 返回值的格式的缺点是，一旦指定了它，就会终生使用它，假设你的类被广泛使用。程序员将编写代码来解析表示、生成表示并将其嵌入持久数据中。如果你在将来的版本中更改了表示形式，你将破坏它们的代码和数据，它们将发出大量的消息。通过选择不指定格式，你可以保留在后续版本中添加信息或改进格式的灵活性。\n无论你是否决定指定格式，你都应该清楚地记录你的意图。 如果指定了格式，则应该精确地指定格式。例如，这里有一个 toString 方法用于 PhoneNumber 类：\n/** * Returns the string representation of this phone number. * The string consists of twelve characters whose format is * \u0026#34;XXX-YYY-ZZZZ\u0026#34;, where XXX is the area code, YYY is the * prefix, and ZZZZ is the line number. Each of the capital * letters represents a single decimal digit. ** If any of the three parts of this phone number is too small * to fill up its field, the field is padded with leading zeros. * For example, if the value of the line number is 123, the last * four characters of the string representation will be \u0026#34;0123\u0026#34;. */ @Override public String toString() { return String.format(\u0026#34;%03d-%03d-%04d\u0026#34;, areaCode, prefix, lineNum); } 如果你决定不指定一种格式，文档注释应该如下所示：\n/** * Returns a brief description of this potion. The exact details * of the representation are unspecified and subject to change, * but the following may be regarded as typical: ** \u0026#34;[Potion #9: type=love, smell=turpentine, look=india ink]\u0026#34; */ @Override public String toString() { ... } 在阅读了这篇文档注释之后，当格式被更改时，生成依赖于格式细节的代码或持久数据的程序员将只能怪他们自己。\n无论你是否指定了格式，都要 提供对 toString 返回值中包含的信息的程序性访问。 例如，PhoneNumber 类应该包含区域代码、前缀和行号的访问器。如果做不到这一点，就会迫使需要这些信息的程序员解析字符串。除了降低性能和使程序员不必要的工作之外，这个过程很容易出错，并且会导致脆弱的系统在你更改格式时崩溃。由于没有提供访问器，你可以将字符串格式转换为事实上的 API，即使你已经指定了它可能会发生更改。\n在静态实用程序类中编写 toString 方法是没有意义的，在大多数 enum 类型中也不应该编写 toString 方法，因为 Java 为你提供了一个非常好的方法。但是，你应该在任何抽象类中编写 toString 方法，该类的子类共享公共的字符串表示形式。例如，大多数集合实现上的 toString 方法都继承自抽象集合类。\n谷歌的开放源码自动值工具将为你生成 toString 方法，大多数 IDE 也是如此。这些方法可以很好地告诉你每个字段的内容，但并不专门针对类的含义。因此，例如，对于 PhoneNumber 类使用自动生成的 toString 方法是不合适的（因为电话号码具有标准的字符串表示形式），但是对于 Potion 类来说它是完全可以接受的。也就是说，一个自动生成的 toString 方法要比从对象继承的方法好得多，对象继承的方法不会告诉你对象的值。\n回顾一下，在你编写的每个实例化类中覆盖对象的 toString 实现，除非超类已经这样做了。它使类更易于使用，并有助于调试。toString 方法应该以美观的格式返回对象的简明、有用的描述。\n总结 建议始终覆盖 toString() 方法。这是因为 toString() 方法是 Java 中最常用的方法之一，它可以将一个对象转换成一个字符串，方便输出和日志记录等操作。\n默认情况下，如果一个类没有覆盖 toString() 方法，那么它将继承自 Object 类的实现，该实现返回一个包含对象类名和散列码的字符串。这个默认的实现可能对于调试和开发过程中的一些操作是有用的，但通常不会提供有关对象的有用信息。\n因此，建议在每个类中都覆盖 toString() 方法，以便在需要时提供有用的信息。在实现 toString() 方法时，可以返回一个包含有关对象状态的字符串，这样就可以在调试和其他操作中使用该字符串。例如，如果一个类表示一个人，那么它的 toString() 方法可以返回该人的姓名和年龄，以便在需要时更好地理解该对象。\n另外，在重写 toString() 方法时，也应该遵循一些约定，以确保该方法的实现正确、高效和易于使用。其中一些约定包括：\n返回的字符串应该以对象的类名作为开头，后面跟着对象的状态信息。例如：Person{name='John', age=30}。 返回的字符串应该是可读的，并且应该包含有关对象状态的所有信息，以便在需要时更好地理解该对象。 返回的字符串应该是不可变的，即不能在返回字符串后更改对象状态以更改返回值。 返回的字符串应该是符合语言习惯的，并且应该适合于国际化和本地化。 总之，覆盖 toString() 方法可以提高代码的可读性和可维护性，因为它提供了有关对象状态的有用信息，同时也符合 Java 语言的习惯和规范。\nJava 中有很多可以自动生成 toString() 方法的开源框架。以下是一些常用的框架：\nApache Commons Lang - ToStringBuilder: Apache Commons Lang 是一个常用的开源 Java 工具库，其中的 ToStringBuilder 类可以帮助开发者自动生成 toString() 方法。使用该类需要在需要自动生成 toString() 方法的类中添加对应的成员变量，并调用 ToStringBuilder 的 reflectionToString() 方法。 Guava - MoreObjects.toStringHelper(): Guava 是 Google 开源的一个 Java 工具库，其中的 MoreObjects 类可以帮助开发者自动生成 toString() 方法。使用该类需要在需要自动生成 toString() 方法的类中添加对应的成员变量，并调用 MoreObjects 的 toStringHelper() 方法。 Lombok - @ToString: Lombok 是一个 Java 库，它可以通过注解来简化 Java 代码。其中的 @ToString 注解可以帮助开发者自动生成 toString() 方法。使用该注解只需要在需要自动生成 toString() 方法的类上添加 @ToString 注解即可，Lombok 会自动为该类生成对应的 toString() 方法 4. Eclipse Collections - ToString: Eclipse Collections 是一个基于 Java 的集合框架，其中的 ToString 类可以帮助开发者自动生成 toString() 方法。使用该类需要在需要自动生成 toString() 方法的类中添加对应的成员变量，并调用 ToString 的 includeFields() 方法。 Apache Commons BeanUtils - ReflectionToStringBuilder: Apache Commons BeanUtils 是一个常用的 Java Bean 操作工具库，其中的 ReflectionToStringBuilder 类可以帮助开发者自动生成 toString() 方法。使用该类需要在需要自动生成 toString() 方法的类中添加对应的成员变量，并调用 ReflectionToStringBuilder 的 toString() 方法。 ","permalink":"https://blog.chensoul.cc/posts/2023/05/26/always-override-tostring/","summary":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：始终覆盖 toString 方法。\n介绍 虽然 Object 提供 toString 方法的实现，但它返回的字符串通常不是类的用户希望看到的。它由后跟「at」符号（@）的类名和 hash 代码的无符号十六进制表示（例如 PhoneNumber@163b91）组成。toString 的通用约定是这么描述的，返回的字符串应该是「简洁但信息丰富的表示，易于阅读」。虽然有人认为 PhoneNumber@163b91 简洁易懂，但与 707-867-5309 相比，它的信息量并不大。toString 约定接着描述，「建议所有子类覆盖此方法。」好建议，确实！\n虽然它不如遵守 equals 和 hashCode 约定那么重要，但是 提供一个好的 toString 实现（能）使类更易于使用，使用该类的系统（也）更易于调试。 当对象被传递给 println、printf、字符串连接操作符或断言或由调试器打印时，将自动调用 toString 方法。即使你从来没有调用 toString 对象，其他人也可能（使用）。例如，有对象引用的组件可以在日志错误消息中包含对象的字符串表示。如果你未能覆盖 toString，则该消息可能完全无用。\n如果你已经为 PhoneNumber 提供了一个好的 toString 方法，那么生成一个有用的诊断消息就像这样简单：\nSystem.out.println(\u0026#34;Failed to connect to \u0026#34; + phoneNumber); 无论你是否覆盖 toString，程序员都会以这种方式生成诊断消息，但是除非你（覆盖 toString），否则这些消息不会有用。提供好的 toString 方法的好处不仅仅是将类的实例扩展到包含对这些实例的引用的对象，特别是集合。在打印 map 时，你更愿意看到哪个，{Jenny=PhoneNumber@163b91} 还是 {Jenny=707-867-5309}？\n当实际使用时，toString 方法应该返回对象中包含的所有有趣信息， 如电话号码示例所示。如果对象很大，或者包含不利于字符串表示的状态，那么这种方法是不切实际的。在这种情况下，toString 应该返回一个摘要，例如曼哈顿住宅电话目录（1487536 号清单）或 Thread[main,5,main]。理想情况下，字符串应该是不言自明的。（线程示例未能通过此测试。）如果没有在字符串表示中包含所有对象的有趣信息，那么一个特别恼人的惩罚就是测试失败报告，如下所示：\nAssertion failure: expected {abc, 123}, but was {abc, 123}. 在实现 toString 方法时，你必须做的一个重要决定是是否在文档中指定返回值的格式。建议你针对值类（如电话号码或矩阵）这样做。指定格式的优点是，它可以作为对象的标准的、明确的、人类可读的表示。这种表示可以用于输入和输出，也可以用于持久的人类可读数据对象，比如 CSV 文件。如果指定了格式，提供一个匹配的静态工厂或构造函数通常是一个好主意，这样程序员就可以轻松地在对象及其字符串表示之间来回转换。Java 库中的许多值类都采用这种方法，包括 BigInteger、BigDecimal 和大多数包装类。\n指定 toString 返回值的格式的缺点是，一旦指定了它，就会终生使用它，假设你的类被广泛使用。程序员将编写代码来解析表示、生成表示并将其嵌入持久数据中。如果你在将来的版本中更改了表示形式，你将破坏它们的代码和数据，它们将发出大量的消息。通过选择不指定格式，你可以保留在后续版本中添加信息或改进格式的灵活性。\n无论你是否决定指定格式，你都应该清楚地记录你的意图。 如果指定了格式，则应该精确地指定格式。例如，这里有一个 toString 方法用于 PhoneNumber 类：\n/** * Returns the string representation of this phone number. * The string consists of twelve characters whose format is * \u0026#34;XXX-YYY-ZZZZ\u0026#34;, where XXX is the area code, YYY is the * prefix, and ZZZZ is the line number.","title":"《Effective Java 3》笔记12：当覆盖 equals 方法时，总要覆盖 hashCode 方法"},{"content":"前言 乐农湖畔生态园 本篇是对 2023-05-15 到 2023-05-21 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n不知不觉，这已经是第 20 篇周报了。这周依旧是健身、理财、学习和写博客。\n自动生成每日早报 最近在朋友圈看到这样一个早报，就在想能否通过代码自动抓取新闻并生成这样一个早报图片？\n于是，在网上找到一篇文章：前后端均基于 vercel 的每日早报项目\n参考源代码，做了一些修改，代码见：fetch_news.py。修改后的逻辑是将抓取的新闻发送到 memos，例如：https://memos.chensoul.cc/m/349 。可以在 github action 设置每天早上 7 点自动发送到 memos，然后再通过 n8n 同步到 『ChenSoul Share』Telegram 频道。\n在 memos 中导出的图片如下：\n如果能够通过 python 自动生成图片，那就更好了。记录一下，待以后实现。\n团建 公司团建选择在周六，而且还是 520 这一天，真是会挑日子。很多人请假，最后只有 13 人参加团建，其中有 8 人是我们开发组的 🤣。挑两张照片发到这里～\n理财 这周总计支出 1861 元，明细如下：\n5 月 15 日：1027 元，武功山旅游，加油 327 5 月 16 日：42 元 5 月 17 日：12 元 5 月 18 日：16 元 5 月 19 日：25 元 5 月 20 日：562 元，看望六舅 5 月 21 日：177 元 健身 本周跑步 36 公里，最长跑步距离为 10 公里。明细数据如下：\n我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在跑步主页。\n工作 博客 本周完成五篇博客：\nJava 设计模式：Abstract Document\nJava 设计模式：Abstract Factory\n《Effective Java 3》笔记 11：当覆盖 equals 方法时，总要覆盖 hashCode 方法\n[译]Build Robust Continuous Integration With Docker and Friends\nPython 学习 1：注释、变量和常量\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n2023-05-19 陈皓（左耳朵耗子）前年做过一次直播访谈，谈到了技术、行业、创业的各个方面。本文是访谈内容的文字整理，以此纪念他。 https://mp.weixin.qq.com/s/bOnW8gDJ-dXp4KbAjhDw9A #memos #skill #tool 2023-05-17 用 Material for MkDocs 来生成专业的技术文档 https://vra.github.io/2023/05/17/mkdocs-material-tutorial/ #memos #tool 2023-05-17 基于 Popsy 创建自己的个人主页 https://popsy.co/ #memos #tool 2023-05-17 Hellonext 是一种反馈管理平台，它可以帮助组织、企业和开发团队更好地管理用户反馈和需求。它提供了一个用户友好的界面，使用户可以轻松地提交反馈和建议，而管理人员可以使用该平台来跟踪和组织这些反馈，并确定哪些反馈应该优先考虑实现。Hellonext 还提供了数据分析和报告功能，帮助管理人员了解用户反馈的趋势和优先级，以便更好地满足用户需求。 https://hellonext.co/ #memos #tool 2023-05-17 Dify 是一个简单且能力丰富的自然语言编程工具。你可以用它搭建商用级应用，个人助理。如果你想自己开发应用，Dify 也能为你省下接入 OpenAI 的后端工作，但使用我们逐步提供高的可视化运营能力，你可以持续的改进和训练你的 GPT 模型。 https://docs.dify.ai/v/zh-hans/getting-started/intro-to-dify #tool #memos 2023-05-17 用 200 行 python 代码实现 dns 服务器的教程 https://implement-dns.wizardzines.com/ #memos #tool 2023-05-17 postman 推出了 postbot，使用人工智能帮助您调试和理解 API、更快地编写测试 https://blog.postman.com/introducing-postbot-postmans-new-ai-assistant/ #tool #memos 2023-05-17 https://imgg.gg/ 是一个可以将任意 sms 内容转换成为图片的工具，不用担心在 APP 上截图会泄漏隐私。生成的图片的样式很像 https://poet.so/ ，不过 Poet.so 只能生成推特、linkedin、shopify 的分享图。 #tool #memos 2023-05-17 都知道 ffmpeg 是媒体文件处理的瑞士军刀，但命令行的操作对大部分人来说确实会面临迷茫和繁琐。FFmpeg.guide 就是一个图形化生成 ffmpeg 命令的工具。 网站地址：https://ffmpeg.guide/ #tool #memos 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/25/weekly_review_20/","summary":"前言 乐农湖畔生态园 本篇是对 2023-05-15 到 2023-05-21 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n不知不觉，这已经是第 20 篇周报了。这周依旧是健身、理财、学习和写博客。\n自动生成每日早报 最近在朋友圈看到这样一个早报，就在想能否通过代码自动抓取新闻并生成这样一个早报图片？\n于是，在网上找到一篇文章：前后端均基于 vercel 的每日早报项目\n参考源代码，做了一些修改，代码见：fetch_news.py。修改后的逻辑是将抓取的新闻发送到 memos，例如：https://memos.chensoul.cc/m/349 。可以在 github action 设置每天早上 7 点自动发送到 memos，然后再通过 n8n 同步到 『ChenSoul Share』Telegram 频道。\n在 memos 中导出的图片如下：\n如果能够通过 python 自动生成图片，那就更好了。记录一下，待以后实现。\n团建 公司团建选择在周六，而且还是 520 这一天，真是会挑日子。很多人请假，最后只有 13 人参加团建，其中有 8 人是我们开发组的 🤣。挑两张照片发到这里～\n理财 这周总计支出 1861 元，明细如下：\n5 月 15 日：1027 元，武功山旅游，加油 327 5 月 16 日：42 元 5 月 17 日：12 元 5 月 18 日：16 元 5 月 19 日：25 元 5 月 20 日：562 元，看望六舅 5 月 21 日：177 元 健身 本周跑步 36 公里，最长跑步距离为 10 公里。明细数据如下：\n我跑过了一些地方，希望随着时间推移，地图点亮的地方越来越多。2 年里我跑过 2 个省份 2 个城市。更多跑步数据在跑步主页。\n工作 博客 本周完成五篇博客：","title":"周报-20｜自动生成每日早报、周末团建"},{"content":"Python 注释、变量和常量是编写 Python 代码时非常重要的概念，下面分别介绍它们的基本用法和语法。\nHello World 创建一个 00_helloworld.py 文件，打印 hello world：\nprint(\u0026#34;Hello，World!\u0026#34;) 执行该文件，会输出结果：\n$ python 00_helloworld.py Hello，World! 一般在 python 文件的开头第一行，我们都会看到下面的代码行：\n# python2 #!/usr/bin/env python # 或者 #!/usr/bin/python # python3 #!/usr/bin/env python3 # 或者 #!/usr/bin/python3 这行代码用来指定本脚本用什么解释器来执行。\n#!/usr/bin/python 是告诉操作系统执行这个脚本的时候，调用 /usr/bin 下的 python 解释器。\n#!/usr/bin/env python 这种用法是为了防止操作系统用户没有将 python 装在默认的 /usr/bin 路径里。当系统看到这一行的时候，首先会到 env 设置里查找 python 的安装路径，再调用对应路径下的解释器程序完成操作。为了增强代码的可移植性，推荐这种写法。\n在 00_helloworld.py 添加这行代码：\n#!/usr/bin/env python print(\u0026#34;Hello，World!\u0026#34;) 然后，修改该文件为可执行属性：\nchmod +x 00_helloworld.py 就可以这样执行：\n. 00_helloworld.py 编码格式 Python3 默认的编码格式是 UTF-8（Unicode Transformation Format - 8 bit）。这是一种通用的字符编码，支持几乎所有的字符集，包括 ASCII、Latin、中文、日文、韩文等。\n在 Python 3.x 中，所有的字符串都是以 Unicode 编码存储的。当你在 Python 中创建一个字符串时，你可以使用任何 Unicode 字符，而不必担心编码问题。\n当你打开一个文本文件时，Python 会自动尝试使用 UTF-8 编码来解析文件内容。如果文件使用其他编码格式，你需要使用相应的编码格式来打开文件，或者在读取文件内容后将其解码为 Unicode。\n在 Python 中，你可以使用编码声明（coding declaration）来指定文件的编码格式。编码声明是一个特殊的注释，出现在 Python 文件的第一行或第二行（如果文件的第一行是 shebang，则编码声明必须出现在第二行），格式如下：\n# -*- coding: encoding -*- # 或者 # coding=utf-8 其中，encoding 是文件的编码格式，可以是 UTF-8、ISO-8859-1 或其他编码格式的名称。编码声明告诉 Python 解释器应该使用指定的编码格式来解析该文件中的文本内容。如果没有编码声明，Python3 默认使用 UTF-8 编码来解析文件内容。\nPython 2.x 的默认编码格式是 ASCII，这是一种 7-bit 的字符编码，只能表示最基本的 ASCII 字符集，无法支持多语言和 Unicode 字符。\n在 Python 2.x 中，如果你需要使用 Unicode 字符，你需要在字符串前面添加一个 u 字符，以表示该字符串是一个 Unicode 字符串。例如：\n# -*- coding: utf-8 -*- s = u\u0026#39;你好，世界！\u0026#39; print s 在 Python 2.x 中，如果你需要打开一个非 ASCII 编码的文本文件，你需要在打开文件时指定文件的编码格式。例如：\nf = open(\u0026#39;filename.txt\u0026#39;, \u0026#39;r\u0026#39;) s = f.read().decode(\u0026#39;gbk\u0026#39;) # 读取并解码文件内容 f.close() 在 Python 2.x 中，你可以使用编码声明来指定文件的编码格式：\n# -*- coding: encoding -*- 其中，encoding 是文件的编码格式，可以是 UTF-8、GBK、ISO-8859-1 或其他编码格式的名称。编码声明告诉 Python 解释器应该使用指定的编码格式来解析该文件中的文本内容。如果没有编码声明，Python 2.x 默认使用 ASCII 编码来解析文件内容。\n在终端输入如下命令，查看编码格式：\n$ python Python 3.11.3 (main, Apr 7 2023, 20:13:31) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import sys \u0026gt;\u0026gt;\u0026gt; sys.getdefaultencoding() \u0026#39;utf-8\u0026#39; 注释 在 Python 中，注释用于在代码中添加注释、解释或说明。注释通常用于提高代码的可读性，帮助其他人理解你的代码。\nPython 支持两种类型的注释：单行注释和多行注释。\n单行注释 在 Python 中，单行注释以井号(#)开头，用于在代码行的末尾或者独立一行中添加注释。任何紧随井号后的文本都将被解释器忽略。\n例如：\n# 这是一个单行注释 print(\u0026#34;Hello, World!\u0026#34;) # 这也是一个单行注释 text = \u0026#34;# This is not a comment because it\u0026#39;s inside quotes.\u0026#34; 在这个例子中，第一行是一个独立的单行注释，第二行则是在代码行的末尾添加的单行注释。这些注释不会影响程序的执行，但是可以帮助其他人理解你的代码。\n多行注释 Python 中使用以三个单引号或者三个双引号括起来的注释被视为多行注释。多行注释通常用于注释函数、类、模块等。例如：\n\u0026#39;\u0026#39;\u0026#39; 这是一个多行注释， 它可以用于描述函数、类或模块的功能和使用方法。 \u0026#39;\u0026#39;\u0026#39; def add_numbers(a, b): \u0026#34;\u0026#34;\u0026#34; 这是一个用于计算两个数字之和的函数。 参数： a -- 第一个数字 b -- 第二个数字 返回值： 两个数字的和 \u0026#34;\u0026#34;\u0026#34; return a + b 注意：\nPython 的多行注释实际上是一个字符串字面值，因此如果不被赋值给任何变量，它们将不会对程序产生任何影响。\n变量 在 Python 中，变量是用来存储数据的标识符。它们是程序中的一种基本元素，用于操作数据并在程序中引用它们。\nPython 中的变量可以存储各种数据类型，包括数字、字符串、列表、元组、字典等。变量的值可以随时更改，因此它们是动态的。\n变量的命名规则如下：\n变量名必须以字母或下划线开头。 变量名可以包含字母、数字和下划线。 变量名区分大小写。 变量名不能与 Python 的关键字相同。 以下是 Python 3.x 版本中的所有关键字：\nFalse class finally is return None continue for lambda try True def from nonlocal while and del global not with as elif if or yield assert else import pass break except in raise 在 Python 2.x 中，还有两个额外的关键字 exec 和 print，但它们在 Python 3.x 中已经被移除。\n如果你不确定某个标识符是否是关键字，你可以使用 Python 的 keyword 模块来检查：\nimport keyword print(keyword.kwlist) 变量定义和使用 在 Python 中，可以使用赋值语句来创建变量。赋值语句使用等号(=)将变量名和要存储在变量中的值分开。\nPython 是动态类型的语言，无须声明变量类型，直接对变量赋值即可使用。\n示例：\n# 创建一个整型变量 x x = 5 # 创建一个字符串变量 name name = \u0026#34;John\u0026#34; # 创建一个列表变量 my_list my_list = [1, 2, 3] # 引用变量 x 的值 print(x) # 输出 5 # 引用变量 name 的值 print(\u0026#34;My name is\u0026#34;, name) # 输出 My name is John # 引用变量 my_list 的值 print(my_list) # 输出 [1, 2, 3] 在 Python 中，变量是动态类型的。这意味着变量的类型可以随时更改。例如，一个变量可以在一个时刻存储一个整数，而在下一个时刻存储一个字符串。\n# 动态类型示例 x = 5 # x 是一个整数 print(x) # 输出 5 x = \u0026#34;Hello, world!\u0026#34; # x 是一个字符串 print(x) # 输出 Hello, world! 在 Python 中，变量是对象的引用。当一个变量被赋值为一个对象时，它实际上是将这个对象的引用存储到变量中。Python 的内存管理器会自动跟踪和回收不再使用的对象。\n一行定义多个变量 在 Python 中可以一行定义多个变量。可以使用逗号将多个变量名分开，并使用等号将它们与相应的值分开。\n# 在 Python 中可以一行定义多个变量。可以使用逗号将多个变量名分开，并使用等号将它们与相应的值分开。 x, y, z = 5, \u0026#34;John\u0026#34;, [1, 2, 3] # 输出变量值 print(x) # 输出 5 print(y) # 输出 John print(z) # 输出 [1, 2, 3] # 一行定义多个变量，使用相同的值 a = b = c = 0 # 输出变量值 print(a) # 输出 0 print(b) # 输出 0 print(c) # 输出 0 变量的作用域 在 Python 中，变量的作用域是指变量在程序中可见和可访问的范围。Python 中有四种作用域：\n局部作用域：变量在函数内部定义，只能在函数内部访问。 嵌套作用域：变量在嵌套函数内部定义，可以在嵌套函数内部和外部函数内部访问。 全局作用域：变量在模块内部定义，可以在模块内的任何函数或类中访问。 内置作用域：变量是 Python 内置的函数和对象，可以在任何地方访问。 如果在函数内部访问全局变量，你需要使用 global 关键字来指示变量的作用域。例如：\nx = 10 # 全局变量 def my_func(): global x # 使用 global 关键字指示变量的作用域 x = 20 # 将全局变量 x 的值修改为 20 my_func() print(x) # 输出 20 变量解包 在 Python 中，可以使用变量解包（unpacking）语法将一个序列或元组中的值分配给多个变量。变量解包语法使用等号(=)将变量名与序列或元组中的值分开，并使用逗号将变量名分开。\n对元组解包\n# 定义一个元组 my_tuple = (1, 2, 3) # 注意：左侧变量的个数必须和待展开的列表长度相等，否则会报错 # 变量解包，将元组中的值分配给多个变量 x, y, z = my_tuple # 输出变量值 print(x) # 输出 1 print(y) # 输出 2 print(z) # 输出 3 可以将变量解包语法与其他 Python 的语言特性结合使用，例如函数返回值和列表推导式。\n# 定义一个函数，返回两个值 def get_name_and_age(): return \u0026#34;John\u0026#34;, 30 # 变量解包，将函数返回的值分配给多个变量 name, age = get_name_and_age() # 输出变量值 print(name) # 输出 John print(age) # 输出 30 # 使用列表推导式创建一个列表，然后进行变量解包 my_list = [1, 2, 3] a, b, c = [x * 2 for x in my_list] # 输出变量值 print(a) # 输出 2 print(b) # 输出 4 print(c) # 输出 6 变量解包语法可以用于嵌套的序列或元组：\n# 定义一个嵌套元组 my_tuple = (1, 2, (3, 4)) # 变量解包，将元组中的值分配给多个变量 x, y, (z, w) = my_tuple # 输出变量值 print(x) # 输出 1 print(y) # 输出 2 print(z) # 输出 3 print(w) # 输出 4 # 定义一个嵌套列表 my_list = [1, 2, [3, 4]] # 变量解包，将列表中的值分配给多个变量 x, y, [z, w] = my_list # 输出变量值 print(x) # 输出 1 print(y) # 输出 2 print(z) # 输出 3 print(w) # 输出 4 使用变量解包语法进行动态解包。动态解包是指在运行时确定要解包的序列或元组，并将其分配给多个变量。\n这通常涉及到使用函数或方法返回的序列或元组，以及不确定序列或元组的长度的情况。\n使用一个星号(*)作为变量名称的前缀可以指定一个变量来接收除了已分配变量之外的所有值。这个变量将是一个列表。\n# 定义一个元组 my_tuple = (1, 2, 3, 4, 5) # 使用动态解包，将元组前两个值分配给变量 x 和 y，后两个值分配给变量 a 和 b，其他值分配给变量 rest x, y, *rest, a, b = my_tuple # 输出变量值 print(x) # 输出 1 print(y) # 输出 2 print(rest) # 输出 [3, 4] print(a) # 输出 5 print(b) # 输出 6 单下划线变量名 在 Python 中，以单个下划线(_)开头的变量名通常表示一个私有变量或占位符变量。\n私有变量：在 Python 中，没有真正的私有变量，但是以单个下划线开头的变量名通常被视为私有变量。这意味着这些变量不应该在模块或类的外部使用，因为它们可能会发生变化或不再存在。但是，它们仍然可以在模块或类的内部使用。\n占位符变量：有时候，在编写代码时，需要使用一个变量来占据一个位置，但是不需要引用变量的值。在这种情况下，可以使用以单个下划线开头的变量名来表示一个占位符变量。\n# 忽略展开时的第二个变量 x, _ = [1, 2] print(x, _) # 输出 1 2 # 使用占位符变量 for _ in range(10): print(_) 可变和不可变对象 在 Python 中，有些对象是可变的，有些对象是不可变的。可变对象是可以修改的，而不可变对象是不能修改的。例如，数字、字符串和元组是不可变的，而列表和字典是可变的。\n# 可变对象示例 my_list = [1, 2, 3] my_list.append(4) print(my_list) # 输出 [1, 2, 3, 4] # 不可变对象示例 my_string = \u0026#34;Hello\u0026#34; my_string += \u0026#34;, world!\u0026#34; print(my_string) # 输出 Hello, world! 常量 在 Python 中，常量是指在程序中定义的不可变的值。常量通常用大写字母表示，以便与变量区分开来。Python 中没有内置的常量类型，但是你可以使用以下方式定义常量：\n使用普通变量表示常量。例如： PI = 3.14159265358979323846 在程序中使用 PI 来表示圆周率，这个值不会被修改。\n使用枚举类（Enum）表示常量。枚举类是 Python 中的一种特殊类型，用于定义一组有限的常量。例如： from enum import Enum class Color(Enum): RED = 1 GREEN = 2 BLUE = 3 在程序中使用 Color.RED、Color.GREEN 和 Color.BLUE 来表示三种颜色，这些值不会被修改。\n常量是编写可读性好、易于理解和维护的代码的重要组成部分。在编写代码时，应该将常量定义为不可变的值，并尽可能使用常量来表示不变的数据。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/23/python-comment-and-variable/","summary":"Python 注释、变量和常量是编写 Python 代码时非常重要的概念，下面分别介绍它们的基本用法和语法。\nHello World 创建一个 00_helloworld.py 文件，打印 hello world：\nprint(\u0026#34;Hello，World!\u0026#34;) 执行该文件，会输出结果：\n$ python 00_helloworld.py Hello，World! 一般在 python 文件的开头第一行，我们都会看到下面的代码行：\n# python2 #!/usr/bin/env python # 或者 #!/usr/bin/python # python3 #!/usr/bin/env python3 # 或者 #!/usr/bin/python3 这行代码用来指定本脚本用什么解释器来执行。\n#!/usr/bin/python 是告诉操作系统执行这个脚本的时候，调用 /usr/bin 下的 python 解释器。\n#!/usr/bin/env python 这种用法是为了防止操作系统用户没有将 python 装在默认的 /usr/bin 路径里。当系统看到这一行的时候，首先会到 env 设置里查找 python 的安装路径，再调用对应路径下的解释器程序完成操作。为了增强代码的可移植性，推荐这种写法。\n在 00_helloworld.py 添加这行代码：\n#!/usr/bin/env python print(\u0026#34;Hello，World!\u0026#34;) 然后，修改该文件为可执行属性：\nchmod +x 00_helloworld.py 就可以这样执行：\n. 00_helloworld.py 编码格式 Python3 默认的编码格式是 UTF-8（Unicode Transformation Format - 8 bit）。这是一种通用的字符编码，支持几乎所有的字符集，包括 ASCII、Latin、中文、日文、韩文等。\n在 Python 3.x 中，所有的字符串都是以 Unicode 编码存储的。当你在 Python 中创建一个字符串时，你可以使用任何 Unicode 字符，而不必担心编码问题。\n当你打开一个文本文件时，Python 会自动尝试使用 UTF-8 编码来解析文件内容。如果文件使用其他编码格式，你需要使用相应的编码格式来打开文件，或者在读取文件内容后将其解码为 Unicode。\n在 Python 中，你可以使用编码声明（coding declaration）来指定文件的编码格式。编码声明是一个特殊的注释，出现在 Python 文件的第一行或第二行（如果文件的第一行是 shebang，则编码声明必须出现在第二行），格式如下：\n# -*- coding: encoding -*- # 或者 # coding=utf-8 其中，encoding 是文件的编码格式，可以是 UTF-8、ISO-8859-1 或其他编码格式的名称。编码声明告诉 Python 解释器应该使用指定的编码格式来解析该文件中的文本内容。如果没有编码声明，Python3 默认使用 UTF-8 编码来解析文件内容。","title":"Python学习1：注释、变量和常量"},{"content":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：当覆盖 equals 方法时，总要覆盖 hashCode 方法。\n介绍 在覆盖了 equals 方法的类中，必须覆盖 hashCode 方法。 如果你没有这样做，该类将违反 hashCode 方法的一般约定，这将阻止该类在 HashMap 和 HashSet 等集合中正常运行。以下是根据 Object 规范修改的约定：\n应用程序执行期间对对象重复调用 hashCode 方法时，它必须一致地返回相同的值，前提是不对 equals 方法中用于比较的信息进行修改。这个值不需要在应用程序的不同执行之间保持一致。 如果根据 equals(Object) 方法判断出两个对象是相等的，那么在两个对象上调用 hashCode 方法必须产生相同的整数结果。 如果根据 equals(Object) 方法判断出两个对象不相等，则不需要在每个对象上调用 hashCode 方法时必须产生不同的结果。但是，程序员应该知道，为不相等的对象生成不同的结果可能会提高散列表的性能。\n当你无法覆盖 hashCode 方法时，将违反第二个关键条款：相等的对象必须具有相等的散列码。 根据类的 equals 方法，两个不同的实例在逻辑上可能是相等的，但是对于对象的 hashCode 方法来说，它们只是两个没有共同之处的对象。因此，Object 的 hashCode 方法返回两个看似随机的数字，而不是约定要求的两个相等的数字。例如：\nMap\u0026lt;PhoneNumber, String\u0026gt; m = new HashMap\u0026lt;\u0026gt;(); m.put(new PhoneNumber(707, 867, 5309), \u0026#34;Jenny\u0026#34;); 此时，你可能期望 m.get(new PhoneNumber(707, 867,5309)) 返回「Jenny」，但是它返回 null。注意，这里涉及到两个 PhoneNumber 实例：一个用于插入到 HashMap 中，另一个相等的实例（被试图）用于检索。由于 PhoneNumber 类未能覆盖 hashCode 方法，导致两个相等的实例具有不相等的散列码，这违反了 hashCode 方法约定。因此，get 方法查找电话号码的散列桶可能会与 put 方法存储电话号码的散列桶不同。即使这两个实例碰巧分配在同一个散列桶上，get 方法几乎肯定会返回 null，因为 HashMap 有一个优化，它缓存每个条目相关联的散列码，如果散列码不匹配，就不会检查对象是否相等。\n解决这个问题就像为 PhoneNumber 编写一个正确的 hashCode 方法一样简单。那么 hashCode 方法应该是什么样的呢？写一个反面例子很容易。例如，以下方法是合法的，但是不应该被使用：\n// The worst possible legal hashCode implementation - never use! @Override public int hashCode() { return 42; } 它是合法的，因为它确保了相等的对象具有相同的散列码。同时它也很糟糕，因为它使每个对象都有相同的散列码。因此，每个对象都分配到同一个桶中，散列表退化为链表。这样，原本应该在线性阶 O(n) 运行的程序将在平方阶 O(n^2) 运行。对于大型散列表，这是工作和不工作的区别。\n一个好的散列算法倾向于为不相等的实例生成不相等的散列码。这正是 hashCode 方法约定第三部分的含义。理想情况下，一个散列算法应该在所有 int 值上均匀合理分布所有不相等实例集合。实现这个理想是很困难的。幸运的是，实现一个类似的并不太难。这里有一个简单的方式：\n1、声明一个名为 result 的 int 变量，并将其初始化为对象中第一个重要字段的散列码 c，如步骤 2.a 中计算的那样。（回想一下 Item-10 中的重要字段会对比较产生影响）\n2、对象中剩余的重要字段 f，执行以下操作：\n为字段计算一个整数散列码 c：\n如果字段是基本数据类型，计算 Type.hashCode(f)，其中 type 是与 f 类型对应的包装类。 如果字段是对象引用，并且该类的 equals 方法通过递归调用 equals 方法来比较字段，则递归调用字段上的 hashCode 方法。如果需要更复杂的比较，则为该字段计算一个「canonical representation」，并在 canonical representation 上调用 hashCode 方法。如果字段的值为空，则使用 0（或其他常数，但 0 是惯用的）。 如果字段是一个数组，则将其每个重要元素都视为一个单独的字段。也就是说，通过递归地应用这些规则计算每个重要元素的散列码，并将每个步骤 2.b 的值组合起来。如果数组中没有重要元素，则使用常量，最好不是 0。如果所有元素都很重要，那么使用 Arrays.hashCode。 将步骤 2.a 中计算的散列码 c 合并到 result 变量，如下所示：\nresult = 31 * result + c; 3、返回 result 变量。\n当你完成了 hashCode 方法的编写之后，问问自己现在相同的实例是否具有相同的散列码。编写单元测试来验证你的直觉（除非你使用 AutoValue 生成你的 equals 方法和 hashCode 方法，在这种情况下你可以安全地省略这些测试）。如果相同的实例有不相等的散列码，找出原因并修复问题。\n可以从散列码计算中排除派生字段。换句话说，你可以忽略任何可以从包含的字段计算其值的字段。你必须排除不用 equals 比较的任何字段，否则你可能会违反 hashCode 方法约定的第二个条款。\n在步骤 2.b 中使用的乘法将使结果取决于字段的顺序，如果类有多个相似的字段，则会产生一个更好的散列算法。例如，如果字符串散列算法中省略了乘法，那么所有的字母顺序都有相同的散列码。选择 31 是因为它是奇素数。如果是偶数，乘法运算就会溢出，信息就会丢失，因为乘法运算等同于移位。使用素数的好处不太明显，但它是传统用法。31 有一个很好的特性，可以用移位和减法来代替乘法，从而在某些体系结构上获得更好的性能：31 * i == (i \u0026lt;\u0026lt;5) – i。现代虚拟机自动进行这种优化。\n让我们将前面的方法应用到 PhoneNumber 类：\n// Typical hashCode method @Override public int hashCode() { int result = Short.hashCode(areaCode); result = 31 * result + Short.hashCode(prefix); result = 31 * result + Short.hashCode(lineNum); return result; } 因为这个方法返回一个简单的确定的计算结果，它的唯一输入是 PhoneNumber 实例中的三个重要字段，所以很明显，相等的 PhoneNumber 实例具有相等的散列码。实际上，这个方法是 PhoneNumber 的一个非常好的 hashCode 方法实现，与 Java 库中的 hashCode 方法实现相当。它很简单，速度也相当快，并且合理地将不相等的电话号码分散到不同的散列桶中。\n虽然本条目中的方法产生了相当不错的散列算法，但它们并不是最先进的。它们的质量可与 Java 库的值类型中的散列算法相媲美，对于大多数用途来说都是足够的。如果你确实需要不太可能产生冲突的散列算法，请参阅 Guava 的 com.google.common.hash.Hashing [Guava]。\nObjects 类有一个静态方法，它接受任意数量的对象并返回它们的散列码。这个名为 hash 的方法允许你编写只有一行代码的 hashCode 方法，这些方法的质量可以与本条目中提供的编写方法媲美。不幸的是，它们运行得更慢，因为它们需要创建数组来传递可变数量的参数，如果任何参数是原始类型的，则需要进行装箱和拆箱。推荐只在性能不重要的情况下使用这种散列算法。下面是使用这种技术编写的 PhoneNumber 的散列算法：\n// One-line hashCode method - mediocre performance @Override public int hashCode() { return Objects.hash(lineNum, prefix, areaCode); } 如果一个类是不可变的，并且计算散列码的成本非常高，那么你可以考虑在对象中缓存散列码，而不是在每次请求时重新计算它。如果你认为这种类型的大多数对象都将用作散列键，那么你应该在创建实例时计算散列码。否则，你可以选择在第一次调用 hashCode 方法时延迟初始化散列码。在一个延迟初始化的字段的情况下，需要注意以确保该类仍然是线程安全的。我们的 PhoneNumber 类不值得进行这种处理，但只是为了向你展示它是如何实现的，如下所示。注意，散列字段的初始值（在本例中为 0）不应该是通常创建的实例的散列码：\n// hashCode method with lazily initialized cached hash code private int hashCode; // Automatically initialized to 0 @Override public int hashCode() { int result = hashCode; if (result == 0) { result = Short.hashCode(areaCode); result = 31 * result + Short.hashCode(prefix); result = 31 * result + Short.hashCode(lineNum); hashCode = result; } return result; } 不要试图从散列码计算中排除重要字段，以提高性能。 虽然得到的散列算法可能运行得更快，但其糟糕的质量可能会将散列表的性能降低到无法使用的程度。特别是，散列算法可能会遇到大量实例，这些实例在你选择忽略的不同区域。如果发生这种情况，散列算法将把所有这些实例映射很少一部分散列码，使得原本应该在线性阶 O(n) 运行的程序将在平方阶 O(n^2) 运行。\n这不仅仅是一个理论问题。在 Java 2 之前，字符串散列算法在字符串中，以第一个字符开始，最多使用 16 个字符。对于大量且分层次的集合（如 url），该函数完全展示了前面描述的病态行为。\n不要为 hashCode 返回的值提供详细的规范，这样客户端就不能理所应当的依赖它。这（也）给了你更改它的余地。 Java 库中的许多类，例如 String 和 Integer，都将 hashCode 方法返回的确切值指定为实例值的函数。这不是一个好主意，而是一个我们不得不面对的错误：它阻碍了在未来版本中提高散列算法的能力。如果你保留了未指定的细节，并且在散列算法中发现了缺陷，或者发现了更好的散列算法，那么你可以在后续版本中更改它。\n总之，每次覆盖 equals 方法时都必须覆盖 hashCode 方法，否则程序将无法正确运行。你的 hashCode 方法必须遵守 Object 中指定的通用约定，并且必须合理地将不相等的散列码分配给不相等的实例。这很容易实现，如果有点枯燥，可使用第 51 页的方法。AutoValue 框架提供了一种能很好的替代手动编写 equals 方法和 hashCode 方法的功能，IDE 也提供了这种功能。\n总结 在《Effective Java 3》第三章《对象的通用方法》中，确实提到了一个重要的原则，即在覆盖 equals 方法时，总要覆盖 hashCode 方法。\n这是因为，如果两个对象在 equals 方法中被认为是相等的，那么它们的 hashCode 方法也必须返回相同的值。这是因为在 Java 中，如果两个对象的 hashCode 不同，则它们将被认为是不同的对象，即使它们在 equals 方法中被认为是相等的。\n因此，如果不覆盖 hashCode 方法，那么可能会导致在使用哈希表、哈希集合或哈希映射等数据结构时出现问题。这些数据结构通常使用 hashCode 方法来确定对象在数据结构中的位置，如果 hashCode 方法没有正确实现，那么可能会导致对象无法正确添加、删除或查找。\n因此，当覆盖 equals 方法时，总要覆盖 hashCode 方法，并确保 hashCode 方法的实现与 equals 方法的实现一致。在实现 hashCode 方法时，通常需要考虑对象的所有属性，并根据属性的值计算一个哈希码，以保证不同的对象具有不同的哈希码，相同的对象具有相同的哈希码。\n在 Java 中，可以使用 Objects 类的 hash 方法来计算对象的哈希码，例如：\n@Override public int hashCode() { return Objects.hash(property1, property2, ...); } 其中，property1、property2 等为对象的属性，可以根据实际情况进行调整。\n总之，在覆盖 equals 方法时，总要覆盖 hashCode 方法，并确保 hashCode 方法的实现与 equals 方法的实现一致。这是 Java 编程中一个重要的原则，应该在实际编程中加以注意。\n以下是一些在 Java 中实现 hashCode 时需要避免的常见错误：\n不考虑所有相关字段：在实现 hashCode 时，需要考虑所有相关字段，这些字段对于对象的标识至关重要。如果省略了一个字段，那么可能会导致相等的对象具有不同的哈希码，这可能会在使用哈希表或哈希集合等数据结构时出现问题。 使用可变字段：如果对象具有可变字段，则不应将它们包含在 hashCode 计算中。这是因为对象的哈希码应该在其生命周期内保持不变，包含可变字段可能会导致哈希码发生变化，即使对象的标识保持不变。 分布不均匀：良好的 hashCode 实现应该生成在哈希表中均匀分布的哈希码。如果哈希码不均匀分布，可能会导致哈希表性能下降或冲突。 不使用质数：在计算 hashCode 时，常常使用质数来避免冲突。如果不使用质数，可能会导致更多的冲突和较差的性能。 使用默认实现：如果不重写 hashCode，将使用 Object 类提供的默认实现，该实现只返回对象的内存地址。这可能对某些情况足够，但不能保证生成唯一的哈希码，可能会在使用哈希表或哈希集合等数据结构时出现问题。 与 equals 不一致：hashCode 实现应该与 equals 实现保持一致，这意味着如果根据 equals 实现，两个对象相等，则它们应该具有相同的 hashCode。如果未确保一致性，可能会在使用哈希表或哈希集合等数据结构时出现问题。 不缓存哈希码：计算对象的哈希码可能是一个昂贵的操作，因此通常需要在计算出哈希码后缓存它。如果不缓存哈希码，可能会导致性能问题，特别是在使用哈希表或哈希集合等数据结构时。 要确保 hashCode 分布均匀，可以采用以下方法：\n使用所有相关字段：在计算 hashCode 时，需要使用所有相关字段，以确保所有字段都对生成的哈希码有贡献。如果省略字段，则可能会导致相等的对象具有不同的哈希码，从而影响哈希表或哈希集合等数据结构的性能。 选择适当的哈希函数：选择适当的哈希函数可以确保生成的哈希码分布均匀。例如，Java 中的 Objects 类提供了一些哈希函数，例如 hash、hashCombine 等，可以根据需要选择适当的哈希函数。 使用质数：使用质数可以避免哈希冲突。在计算 hashCode 时，可以使用质数来计算不同字段的哈希码，然后将它们组合起来以生成最终的哈希码。 压缩哈希码：在生成哈希码后，可以将其压缩到哈希表的合法范围内，以确保哈希码分布均匀。例如，如果哈希表大小为 2 的 n 次方，可以通过将哈希码与 2 的 n 次方-1 进行按位与运算来压缩哈希码，以确保哈希码在 0 到 2 的 n 次方-1 之间均匀分布。 使用哈希码随机化：在生成哈希码后，可以对其进行随机化，以避免敌手攻击和哈希冲突。例如，可以使用一个随机数，将其与哈希码混合，以生成最终的哈希码。 哈希冲突是指不同的键（key）在哈希表中映射到相同的位置（索引）的情况。为了处理哈希冲突，可以采用以下几种方法：\n开放地址法：开放地址法是一种常用的处理哈希冲突的方法，它的思想是在哈希表中寻找一个空槽，将冲突的键放入该槽中。常用的开放地址法包括线性探测、二次探测和双重散列等。 链地址法：链地址法是另一种常用的处理哈希冲突的方法，它的思想是将哈希表中同一个位置的所有键放在一个链表中。当发生哈希冲突时，只需要将冲突的键添加到链表的末尾即可。链地址法适用于存储大量数据的哈希表。 再哈希法：再哈希法是一种处理哈希冲突的方法，它的思想是使用另一个哈希函数来计算冲突键的哈希值。当发生哈希冲突时，使用另一个哈希函数重新计算哈希值，直到找到一个空槽插入键为止。 建立公共溢出区：建立公共溢出区是一种处理哈希冲突的方法，它的思想是在哈希表中保留一些位置，用于存储哈希冲突的键。当发生哈希冲突时，将冲突的键放入公共溢出区中，而不是在哈希表的其他位置中。 无论采用哪种方法，处理哈希冲突时需要考虑以下几个方面：\n效率：处理哈希冲突的方法应该具有高效性，能够在不影响性能的情况下解决哈希冲突。 冲突解决度：处理哈希冲突的方法应该具有良好的冲突解决度，能够尽可能地减少哈希冲突的发生。 实现复杂度：处理哈希冲突的方法应该易于实现和维护。 ","permalink":"https://blog.chensoul.cc/posts/2023/05/23/always-override-hashcode-when-you-override-equals/","summary":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：当覆盖 equals 方法时，总要覆盖 hashCode 方法。\n介绍 在覆盖了 equals 方法的类中，必须覆盖 hashCode 方法。 如果你没有这样做，该类将违反 hashCode 方法的一般约定，这将阻止该类在 HashMap 和 HashSet 等集合中正常运行。以下是根据 Object 规范修改的约定：\n应用程序执行期间对对象重复调用 hashCode 方法时，它必须一致地返回相同的值，前提是不对 equals 方法中用于比较的信息进行修改。这个值不需要在应用程序的不同执行之间保持一致。 如果根据 equals(Object) 方法判断出两个对象是相等的，那么在两个对象上调用 hashCode 方法必须产生相同的整数结果。 如果根据 equals(Object) 方法判断出两个对象不相等，则不需要在每个对象上调用 hashCode 方法时必须产生不同的结果。但是，程序员应该知道，为不相等的对象生成不同的结果可能会提高散列表的性能。\n当你无法覆盖 hashCode 方法时，将违反第二个关键条款：相等的对象必须具有相等的散列码。 根据类的 equals 方法，两个不同的实例在逻辑上可能是相等的，但是对于对象的 hashCode 方法来说，它们只是两个没有共同之处的对象。因此，Object 的 hashCode 方法返回两个看似随机的数字，而不是约定要求的两个相等的数字。例如：\nMap\u0026lt;PhoneNumber, String\u0026gt; m = new HashMap\u0026lt;\u0026gt;(); m.put(new PhoneNumber(707, 867, 5309), \u0026#34;Jenny\u0026#34;); 此时，你可能期望 m.get(new PhoneNumber(707, 867,5309)) 返回「Jenny」，但是它返回 null。注意，这里涉及到两个 PhoneNumber 实例：一个用于插入到 HashMap 中，另一个相等的实例（被试图）用于检索。由于 PhoneNumber 类未能覆盖 hashCode 方法，导致两个相等的实例具有不相等的散列码，这违反了 hashCode 方法约定。因此，get 方法查找电话号码的散列桶可能会与 put 方法存储电话号码的散列桶不同。即使这两个实例碰巧分配在同一个散列桶上，get 方法几乎肯定会返回 null，因为 HashMap 有一个优化，它缓存每个条目相关联的散列码，如果散列码不匹配，就不会检查对象是否相等。\n解决这个问题就像为 PhoneNumber 编写一个正确的 hashCode 方法一样简单。那么 hashCode 方法应该是什么样的呢？写一个反面例子很容易。例如，以下方法是合法的，但是不应该被使用：\n// The worst possible legal hashCode implementation - never use! @Override public int hashCode() { return 42; } 它是合法的，因为它确保了相等的对象具有相同的散列码。同时它也很糟糕，因为它使每个对象都有相同的散列码。因此，每个对象都分配到同一个桶中，散列表退化为链表。这样，原本应该在线性阶 O(n) 运行的程序将在平方阶 O(n^2) 运行。对于大型散列表，这是工作和不工作的区别。","title":"《Effective Java 3》笔记11：当覆盖 equals 方法时，总要覆盖 hashCode 方法"},{"content":" 持续集成 (CI) 已成为软件开发的关键，它允许团队频繁合并代码更改并及早发现错误。\nDocker 容器通过提供一致的环境帮助促进持续集成过程，您可以在其中测试和发送每次提交的代码。\n在本教程中，您将学习如何使用 Docker 为 Flask Web 应用程序创建强大的持续集成管道。\n您将完成在本地开发和测试应用程序、将其容器化、使用 Docker Compose 编排容器以及使用 GitHub Actions 定义 CI 管道的步骤。\n在本教程结束时，您将能够为您的 Web 应用程序创建一个完全自动化的 CI 管道。\n在本教程中，您将：\n在 Docker 容器中本地运行 Redis 服务器 用 Docker 编排 Flask 编写的 Python Web 应用程序 构建 Docker 镜像并将它们推送到 Docker Hub 仓库 使用 Docker Compose 编排多容器应用程序 在任何地方复制类似生产的基础设施 使用 GitHub Actions 定义持续集成工作流 理想情况下，您应该具有使用 Python 进行 Web 开发、测试自动化、将 Redis 与 Python 结合使用以及使用 Git 和 GitHub 进行源代码版本控制的经验。以前接触过 Docker 会更好，但不是必需的。您还应该拥有一个 Git 客户端和一个 GitHub 帐户，以便跟随并复制本教程的步骤。\n注意：本教程大致基于名为 Docker in Action - Fitter, Happier, More Productive 的旧教程，该教程由 Michael Herman 编写，他于 2015 年 2 月 8 日在 PyTennessee 展示了他的 CI 工作流程。如果你有兴趣，您可以查看展示的相应幻灯片在会议上。\n不幸的是，原始教程中描述的许多工具不再受支持或免费提供。在此更新的教程中，您将使用最新的工具和技术，例如 GitHub Actions。\n如果您想跳过在计算机上设置 Docker 和构建示例 Web 应用程序的初始步骤，那么直接跳到定义持续集成管道。无论哪种方式，您都需要下载支持材料，它们与完成的 Flask Web 应用程序和相关资源一起提供，它们将帮助您学习本教程：\n免费下载：单击此处下载您的 Flask 应用程序和相关资源，以便您可以使用 Docker 定义持续集成管道。\n项目架构概览 在本教程结束时，您将拥有一个 Flask Web 应用程序，用于跟踪持久存储在 Redis 数据存储中的页面视图。\n它将是一个由 Docker Compose 编排的多容器应用程序，您将能够在本地和云端构建和测试，为持续集成铺平道路：\n该应用程序由两个 Docker 容器组成。第一个容器将在 Gunicorn 之上运行一个 Flask 应用程序，响应 HTTP 请求并更新页面浏览量。\n第二个容器将运行一个 Redis 实例，用于将页面视图数据持久存储在主机上的本地卷中。\nDocker 是运行此应用程序所需的全部，您现在将对其进行设置。\n在您的计算机上设置 Docker Docker 是一个总称，根据上下文，它对不同的人有不同的含义。例如，当有人提到 docker 时，他们可能指以下之一：\nDocker, Inc.：平台和相关工具背后的公司 Docker：开源容器平台 Docker CLI： docker 客户端命令行程序 dockerd : 管理容器的 Docker 守护进程 还有一些与 Docker 平台相关的工具和项目，例如：\nDocker Compose Docker Desktop Docker Engine Docker Hub Docker Swarm Mode Docker 集群模式 在本教程中，您将使用上面列表中除最后一个之外的所有内容。顺便说一句，不要将遗留的 Docker Classic Swarm 与 1.12 版以来内置于 Docker 引擎中的 Docker Swarm Mode 混淆，后者是一个外部工具。\n注意：您可能听说过 Docker Machine 和 Docker Toolbox。这些是不再维护的旧工具。\nDocker 解决的主要问题是能够在几乎没有或没有配置的情况下在一致且可重现的环境中的任何地方运行应用程序。它可以将您的应用程序代码、二进制文件和依赖项（例如语言运行时和库）打包到一个工件中。您将在开发期间和持续集成服务器上使用 Docker 在本地计算机上模拟假设的生产环境。\n安装 Docker 有两种选择：\nDocker Engine Docker Desktop 如果您熟悉终端并喜欢额外的控制级别，那么开源 Docker 引擎就是您的最佳选择，它提供核心运行时和用于管理容器的命令行界面。另一方面，如果您更喜欢具有直观图形用户界面的一站式解决方案，那么您应该考虑使用 Docker Desktop。\n注意：开箱即用的桌面应用程序附带 Docker Compose，稍后在编排容器以进行持续集成时将需要它。\n当您浏览 Docker 官方文档时，您可能会觉得 Docker Desktop 占据了聚光灯下。这是一个非常棒的工具，但您必须记住，Docker Desktop 仍然免费供个人使用。自 2021 年 8 月起，您需要付费订阅才能在商业项目中使用它。\n虽然在技术上可以并排安装这两种工具，但您通常应该避免同时使用它们，以尽量减少虚拟网络或端口绑定之间任何潜在干扰的风险。您可以通过停止其中之一并在 Docker Engine 和 Docker Desktop 之间切换上下文来实现。\n注意：Docker Desktop 过去只能在 Windows 和 macOS 上使用，但现在情况发生了变化，您现在也可以在某些 Linux 发行版上安装它，包括 Ubuntu、Debian 和 Fedora。但是，Linux 版本的 Docker Desktop 运行在虚拟机之上，以模仿在其他操作系统上使用它的用户体验。\n要验证您是否已在系统上成功安装 Docker（作为 Docker Engine 或 Docker Desktop 包装器应用程序），请打开终端并键入以下命令：\n$ docker --version Docker version 23.0.4, build f480fb1 您应该会看到您的 Docker 版本以及内部版本号。如果您使用的是 Linux，那么您可能希望按照安装后的步骤使用 docker 命令，而无需在其前面加上 sudo 以获得管理权限。\n在开始使用 Docker 来帮助进行持续集成之前，您需要创建一个基本的 Web 应用程序。\n在 Flask 中开发页面视图跟踪器 在接下来的几节中，您将使用 Flask 框架实现一个基本的 Web 应用程序。您的应用程序将跟踪页面浏览总数，并在每次请求时向用户显示该数字：\n应用程序的当前状态将保存在 Redis 数据存储中，该存储通常用于缓存和其他类型的数据持久化。这样，停止您的网络服务器不会重置观看次数。您可以将 Redis 视为一种数据库。\n如果您对从头开始构建此应用程序不感兴趣，请随时通过单击下面的链接下载其完整源代码，然后跳到对您的 Flask Web 应用程序进行 docker 化：\n即使您打算自己编写代码，下载完成的项目并将其用作参考与您的实现进行比较仍然是个好主意，以防您遇到困难。\n免费下载：单击此处下载您的 Flask 应用程序和相关资源，以便您可以使用 Docker 定义持续集成管道。\n在开始开发应用程序之前，您需要设置工作环境。\n准备环境 与每个 Python 项目一样，您在开始时应该遵循大致相同的步骤，包括创建一个新目录，然后为您的项目创建并激活一个隔离的虚拟环境。您可以直接从您最喜欢的代码编辑器（如 Visual Studio Code）或功能齐全的 IDE（如 PyCharm）执行此操作，或者您可以在终端中键入一些命令：\nWindows：\nPS\u0026gt; mkdir page-tracker PS\u0026gt; cd page-tracker PS\u0026gt; python -m venv venv --prompt page-tracker PS\u0026gt; venv\\Scripts\\activate (page-tracker) PS\u0026gt; python -m pip install --upgrade pip Linux + MacOS：\n$ mkdir page-tracker/ $ cd page-tracker/ $ python3 -m venv venv/ --prompt page-tracker $ source venv/bin/activate (page-tracker) $ python -m pip install --upgrade pip 首先，创建一个名为 page-tracker/ 的新目录，然后在其中创建一个名为 venv/ 的 Python 虚拟环境。为虚拟环境提供描述性提示，使其易于识别。最后，激活新建的虚拟环境后，将 pip 升级到最新版本，以免以后安装Python 包时出现问题。\n注意：在 Windows 上，您可能需要先以管理员身份运行 Windows Terminal 并在创建虚拟环境之前放宽脚本执行策略。\n在本教程中，您将使用现代方式通过 pyproject.toml 配置文件和 setuptools 指定项目的依赖项和元数据作为构建后端。此外，您将遵循 src 布局，将应用程序的源代码放在单独的 src/ 子目录中，以更好地组织项目中的文件。这将使您可以直接打包代码，而无需稍后添加的自动化测试。\n继续使用以下命令构建您的 Python 项目占位符：\nWindows：\n(page-tracker) PS\u0026gt; mkdir src\\page_tracker (page-tracker) PS\u0026gt; ni src\\page_tracker\\__init__.py (page-tracker) PS\u0026gt; ni src\\page_tracker\\app.py (page-tracker) PS\u0026gt; ni constraints.txt (page-tracker) PS\u0026gt; ni pyproject.toml Linux + MacOS：\n(page-tracker) $ mkdir -p src/page_tracker (page-tracker) $ touch src/page_tracker/__init__.py (page-tracker) $ touch src/page_tracker/app.py (page-tracker) $ touch constraints.txt (page-tracker) $ touch pyproject.toml 完成后，您应该具有以下目录结构：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── venv/ │ ├── constraints.txt └── pyproject.toml 如您所见，您将只有一个 Python 模块， app ，定义在一个名为 page_tracker 的包中，位于 src/ 目录中。 constraints.txt 文件将指定项目依赖项的固定版本，以实现可重复安装。\n该项目将依赖于两个外部库， Flask 和 Redis ，您可以在 pyproject.toml 文件中声明它们：\n# pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;redis\u0026#34;, ] 请注意，您通常不会在此处指定依赖项版本。相反，您可以将它们与需求或约束文件中的任何传递依赖项一起冻结。第一个告诉 pip 要安装什么包，后者强制执行传递依赖项的特定包版本，类似于 Pipenv 或 Poetry 锁定文件。\n要生成约束文件，您必须首先将您的 page-tracker 项目安装到活动的虚拟环境中，这将从 Python 包索引 (PyPI) 中获取所需的外部库。确保您已经创建了所需的文件夹结构，然后发出以下命令：\n(page-tracker) $ python -m pip install --editable . (page-tracker) $ python -m pip freeze --exclude-editable \u0026gt; constraints.txt 即使您还没有输入一行代码，Python 也会识别并安装您的包占位符。因为您的包遵循 src 布局，所以在开发期间以可编辑模式安装它很方便。这将允许您更改源代码并立即将它们反映在虚拟环境中，而无需重新安装。但是，您想从约束文件中排除可编辑包。\n注意：如果您打算共享您的项目，生成的约束文件非常有价值。这意味着其他人可以在他们的终端中运行以下命令来重现与您相同的环境：\n(page-tracker) $ python -m pip install -c constraints.txt . 因为您通过 -c 选项提供了一个约束文件， pip 安装了固定的依赖项而不是最新的可用依赖项。这意味着您有可重复的安装。稍后您将使用类似的命令来构建 Docker 镜像。\n好的。您几乎已经准备好开始编写您的 Flask Web 应用程序了。在执行此操作之前，您将切换一下方式并准备一个本地 Redis 服务器以通过网络连接。\n通过 Docker 运行 Redis 服务器 Redis 这个名字是单词远程字典服务器的合成词，它非常准确地表达了它作为远程内存数据结构存储的目的。作为一个键值存储，Redis 就像一个远程 Python 字典，您可以从任何地方连接到它。它也被认为是在许多不同环境中使用的最流行的 NoSQL 数据库之一。通常，它用于关系数据库之上的缓存。\n注意：虽然 Redis 将其所有数据保存在易失性内存中，这使其速度极快，但该服务器具有多种持久性选项。在断电或重启的情况下，它们可以确保不同级别的数据持久性。然而，正确配置 Redis 通常很困难，这就是为什么许多团队决定使用外包给云提供商的托管服务的原因。\n在您的计算机上安装 Redis 非常简单，但假设您之前已经安装和配置了 Docker，通过 Docker 运行它会更加简单和优雅。当您在 Docker 容器中运行诸如 Redis 之类的服务时，它会与系统的其余部分保持隔离，而不会造成混乱或占用有限的网络端口号等系统资源。\n要在不将 Redis 安装在主机上的情况下运行 Redis，您可以通过调用以下命令从官方 Redis 镜像运行新的 Docker 容器：\n$ docker run -d --name redis-server redis Unable to find image \u0026#39;redis:latest\u0026#39; locally latest: Pulling from library/redis 26c5c85e47da: Pull complete 39f79586dcf2: Pull complete 79c71d0520e5: Pull complete 60e988668ca1: Pull complete 873c3fc9fdc6: Pull complete 50ce7f9bf183: Pull complete Digest: sha256:f50031a49f41e493087fb95f96fdb3523bb25dcf6a3f0b07c588ad3cdb... Status: Downloaded newer image for redis:latest 09b9842463c78a2e9135add810aba6c4573fb9e2155652a15310009632c40ea8 这将基于最新版本的 redis 镜像创建一个新的 Docker 容器，自定义名称为 redis-server ，稍后您将引用它。容器以分离模式 ( -d ) 在后台运行。当您第一次运行此命令时，Docker 会从 Docker Hub 中拉取相应的 Docker 镜像，这是 Docker 镜像的官方存储库，类似于 PyPI。\n只要一切按计划进行，您的 Redis 服务器就应该启动并运行。因为您以分离模式 ( -d ) 启动了容器，所以它将在后台保持活动状态。要验证这一点，您可以使用 docker container ls 命令或等效的 docker ps 别名列出您的 Docker 容器：\n$ docker ps CONTAINER ID IMAGE ... STATUS PORTS NAMES 09b9842463c7 redis ... Up About a minute 6379/tcp redis-server 在这里，您可以看到一个 ID 前缀与您在运行 docker run 命令时获得的 ID 前缀匹配的容器从大约一分钟前开始启动。该容器基于 redis 镜像，已命名为 redis-server ，并使用 TCP 端口号 6379 ，这是 Redis 的默认端口。\n接下来，您将尝试以各种方式连接到该 Redis 服务器。\n测试与 Redis 的连接 在 Docker Hub 上官方 Redis 镜像的概述页面上，您将找到有关如何连接到在 Docker 容器中运行的 Redis 服务器的说明。具体而言，此页面讨论了如何使用 Docker 镜像附带的专用交互式命令行界面 Redis CLI 。\n您可以从同一个 redis 镜像启动另一个 Docker 容器，但这一次，将容器的入口点设置为 redis-cli 命令而不是默认的 Redis 服务器二进制文件。当您设置多个容器一起工作时，您应该使用 Docker 网络，这需要一些额外的配置步骤。\n首先，新建一个以你的项目命名的自定义桥接网络，例如：\n$ docker network create page-tracker-network c942131265bf097da294edbd2ac375cd5410d6f0d87e250041827c68a3197684 通过定义这样的虚拟网络，您可以连接任意数量的 Docker 容器，并让它们通过描述性名称相互发现。您可以通过运行以下命令列出您创建的网络：\n$ docker network ls NETWORK ID NAME DRIVER SCOPE 1bf8d998500e bridge bridge local d5cffd6ea76f host host local a85d88fc3abe none null local c942131265bf page-tracker-network bridge local 接下来，将现有的 redis-server 容器连接到这个新的虚拟网络，并在启动相应容器时为 Redis CLI 指定相同的网络：\n$ docker network connect page-tracker-network redis-server $ docker run --rm -it \\ --name redis-client \\ --network page-tracker-network \\ redis redis-cli -h redis-server --rm 标志告诉 Docker 在您终止它后立即删除创建的容器，因为这是一个您不需要再次启动的临时或临时容器。 -i 和 -t 标志，缩写为 -it ，以交互方式运行容器，让您通过连接到终端的标准流来键入命令。使用 --name 选项，您可以为新容器指定一个描述性名称。\n--network 选项将你的新 redis-client 容器连接到之前创建的虚拟网络，允许它与 redis-server 容器通信。这样，两个容器都将收到与 --name 选项给定的名称相对应的主机名。请注意，通过使用 -h 参数，您告诉 Redis CLI 连接到由其容器名称标识的 Redis 服务器。\n注意：有一种更快的方法可以通过虚拟网络连接两个容器，而无需显式创建容器。您可以在运行新容器时指定 --link 选项：\n$ docker run --rm -it \\ --name redis-client \\ --link redis-server:redis-client \\ redis redis-cli -h redis-server 但是，此选项已被弃用，并且可能会在某个时候从 Docker 中删除。\n当您的新 Docker 容器启动时，您将进入一个交互式 Redis CLI，它类似于带有以下提示的 Python REPL：\nredis-server:6379\u0026gt; SET pi 3.14 OK redis-server:6379\u0026gt; GET pi \u0026#34;3.14\u0026#34; redis-server:6379\u0026gt; DEL pi (integer) 1 redis-server:6379\u0026gt; KEYS * (empty array) 在那里，您可以测试一些 Redis 命令，例如，设置键值对、获取相应键的值、删除该键值对或检索当前存储在服务器中的所有键的列表。要退出交互式 Redis CLI，请按键盘上的 Ctrl+C。\n如果您安装了 Docker Desktop，那么在大多数情况下，它不会将流量从您的主机路由到容器。你的本地网络和默认的 Docker 网络之间没有连接：\nDocker Desktop for Mac 无法将流量路由到容器。\n适用于 Windows 的 Docker Desktop 无法将流量路由到 Linux 容器。但是，您可以对 Windows 容器执行 ping 操作。\nLinux 上的 Docker Desktop 也是如此。另一方面，如果您使用 Docker 引擎或在 Windows 主机上运行 Windows 容器，那么您将能够通过它们的 IP 地址访问这些容器。\n因此，有时您可以直接从主机与 Redis 服务器通信。首先，找出对应的 Docker 容器的 IP 地址：\n$ docker inspect redis-server \\ -f \u0026#39;{{range .NetworkSettings.Networks}}{{.IPAddress}}{{println}}{{end}}\u0026#39; 172.17.0.2 172.18.0.2 如果您看到多个 IP 地址，则表示您的容器连接到多个网络。当您启动容器时，容器会自动连接到默认的 Docker 网络。\n记下其中一个地址，您可能会有所不同。现在，您可以将此 IP 地址用作 -h 参数的值，而不是 redis-cli 中的链接容器名称。您还可以使用此 IP 地址通过 netcat 或 Telnet 客户端连接到 Redis，例如 PuTTY 或 telnet 命令：\n$ telnet 172.17.0.2 6379 Trying 172.17.0.2... Connected to 172.17.0.2. Escape character is \u0026#39;^]\u0026#39;. SET pi 3.14 +OK GET pi $4 3.14 DEL pi :1 KEYS * *0 ^] telnet\u0026gt; Connection closed. 请记住提供默认为 6379 的端口号，Redis 会在该端口上侦听传入连接。您可以在此处以明文形式键入 Redis 命令，因为服务器使用未加密的协议，除非您在配置中明确启用 TLS 支持。\n最后，您可以利用端口映射使 Redis 在 Docker 容器之外可用。在开发过程中，您将希望直接连接到 Redis，而不是通过来自另一个容器的虚拟网络，因此您不必将它连接到任何网络。\n要使用端口映射，请停止并删除现有的 redis-server ，然后使用定义如下的 -p 选项运行一个新容器：\n$ docker stop redis-server $ docker rm redis-server $ docker run -d --name redis-server -p 6379:6379 redis 冒号左边的数字（ : ）代表主机或你电脑上的端口号，而右边的数字代表即将运行的 Docker 容器内的映射端口。\n在两侧使用相同的端口号可以有效地转发它，这样您就可以连接到 Redis，就像它在您的计算机上本地运行一样：\n$ telnet localhost 6379 Trying 127.0.0.1... Connected to localhost. Escape character is \u0026#39;^]\u0026#39;. INCR page_views :1 INCR page_views :2 INCR page_views :3 ^] telnet\u0026gt; Connection closed. 连接到现在在本地主机和默认端口上可见的 Redis 后，您可以使用 INCR 命令增加页面浏览量。如果底层键尚不存在，则 Redis 将使用值 1 对其进行初始化。\n注意：如果您在本地安装了 Redis，或者某些系统进程也在您的主机上使用端口 6379 ，那么您需要使用未占用的端口以不同方式映射您的端口号。例如，您可以执行以下操作：\n$ docker run -d --name redis-server -p 9736:6379 redis 这将允许您连接到端口 9736 上的本地主机（如果该端口尚未被其他服务占用）。只要可用，使用哪个端口并不重要。\n现在您已经知道如何从命令行连接到 Redis，您可以继续看看如何通过 Python 程序执行相同的操作。\n从 Python 连接到 Redis 此时，您有一个在 Docker 容器中运行的 Redis 服务器，您可以使用 Redis 的默认端口号在本地主机上访问它。\n如果您想了解有关您的容器或任何其他 Docker 资源的更多信息，那么您始终可以通过检查手头的对象来检索有价值的信息：\n$ docker inspect redis-server [ { \u0026#34;Id\u0026#34;: \u0026#34;09b9842463c78a2e9135add810aba6...2a15310009632c40ea8\u0026#34;, ⋮ \u0026#34;NetworkSettings\u0026#34;: { ⋮ \u0026#34;Ports\u0026#34;: { \u0026#34;6379/tcp\u0026#34;: null }, ⋮ \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.2\u0026#34;, ⋮ } } ] 在这种情况下，您要询问有关 redis-server 容器的信息，其中包括大量详细信息，例如容器的网络配置。 docker inspect 命令默认返回 JSON 格式的数据，您可以使用 Go 模板进一步过滤。\n接下来，打开终端，激活项目的虚拟环境，并启动一个新的 Python REPL：\nWindows：\nPS\u0026gt; venv\\Scripts\\activate (page-tracker) PS\u0026gt; python Linux + MacOS：\n$ source venv/bin/activate (page-tracker) $ python 假设您之前在此虚拟环境中安装了 redis 包，您应该能够导入 Python 的 Redis 客户端并调用其中一种方法：\n\u0026gt;\u0026gt;\u0026gt; from redis import Redis \u0026gt;\u0026gt;\u0026gt; redis = Redis() \u0026gt;\u0026gt;\u0026gt; redis.incr(\u0026#34;page_views\u0026#34;) 4 \u0026gt;\u0026gt;\u0026gt; redis.incr(\u0026#34;page_views\u0026#34;) 5 当您在不指定任何参数的情况下创建新的 Redis 实例时，它将尝试连接到在本地主机和默认端口 6379 上运行的 Redis 服务器。在这种情况下，调用 .incr() 确认您已成功与位于 Docker 容器中的 Redis 建立连接，因为它记住了 page_views 键的最后一个值。\n如果您需要连接到位于远程计算机上的 Redis，请提供自定义主机和端口号作为参数：\n\u0026gt;\u0026gt;\u0026gt; from redis import Redis \u0026gt;\u0026gt;\u0026gt; redis = Redis(host=\u0026#34;127.0.0.1\u0026#34;, port=6379) \u0026gt;\u0026gt;\u0026gt; redis.incr(\u0026#34;page_views\u0026#34;) 6 请注意，您应该将端口号作为整数传递，但如果您传递一个字符串，库也不会抱怨。\n连接到 Redis 的另一种方法是使用特殊格式的字符串，它代表一个 URL：\n\u0026gt;\u0026gt;\u0026gt; from redis import Redis \u0026gt;\u0026gt;\u0026gt; redis = Redis.from_url(\u0026#34;redis://localhost:6379/\u0026#34;) \u0026gt;\u0026gt;\u0026gt; redis.incr(\u0026#34;page_views\u0026#34;) 7 如果您想将 Redis 配置存储在文件或环境变量中，这会特别方便。\n好极了！您可以获取这些代码片段之一并将其与您的 Flask Web 应用程序集成。在下一节中，您将看到如何做到这一点。\n在本地实现并运行 Flask 应用程序 返回代码编辑器，打开 page-tracker 项目中的 app 模块，并编写以下几行 Python 代码：\n# src/page_tracker/app.py from flask import Flask from redis import Redis app = Flask(__name__) redis = Redis() @app.get(\u0026#34;/\u0026#34;) def index(): page_views = redis.incr(\u0026#34;page_views\u0026#34;) return f\u0026#34;This page has been seen {page_views} times.\u0026#34; 您首先从项目各自列为依赖项的第三方库中导入 Flask 和 Redis 。接下来，您使用默认参数实例化 Flask 应用程序和 Redis 客户端，这意味着客户端将尝试连接到本地 Redis 服务器。\n最后，您定义一个控制器函数来处理到达 Web 服务器根地址 ( / ) 的 HTTP GET 请求。\n您的端点会增加 Redis 中的页面浏览量，并在客户端的 Web 浏览器中显示合适的消息。就是这样！您拥有一个完整的 Web 应用程序，它可以使用不到十行的代码处理 HTTP 流量并将状态持久保存在远程数据存储中。\n要验证您的 Flask 应用程序是否按预期工作，请在终端中发出以下命令：\n(page-tracker) $ flask --app page_tracker.app run * Serving Flask app \u0026#39;page_tracker.app\u0026#39; * Debug mode: off WARNING: This is a development server. Do not use it in a production ⮑ deployment. Use a production WSGI server instead. * Running on http://127.0.0.1:5000 Press CTRL+C to quit 你可以在你的文件系统的任何地方运行这个命令，只要你已经激活了正确的虚拟环境并安装了你的 page-tracker 包。这应该在禁用调试模式的情况下在本地主机和端口 5000 上运行 Flask 开发服务器。\n如果你想从同一网络上的另一台计算机访问你的服务器，那么你必须使用特殊地址 0.0.0.0 而不是默认的 localhost 将它绑定到所有网络接口，它代表环回接口：\n(page-tracker) $ flask --app page_tracker.app run --host=0.0.0.0 \\ --port=8080 \\ --debug * Serving Flask app \u0026#39;page_tracker.app\u0026#39; * Debug mode: on WARNING: This is a development server. Do not use it in a production ⮑ deployment. Use a production WSGI server instead. * Running on all addresses (0.0.0.0) * Running on http://127.0.0.1:8080 * Running on http://192.168.0.115:8080 Press CTRL+C to quit * Restarting with stat * Debugger is active! * Debugger PIN: 123-167-546 如果需要，您还可以使用适当的命令行选项或标志更改端口号并启用调试模式。\n启动服务器后，您可以点击终端中显示的链接，并在您的网络浏览器中查看包含浏览量的页面。每次刷新此页面时，计数器应加一：\n做得很好！您已经成功创建了一个基本的 Flask 应用程序，它使用 Redis 跟踪页面浏览量。接下来，您将学习如何测试和保护您的 Web 应用程序。\n测试和保护您的 Web 应用程序 在将任何项目打包并部署到生产环境之前，您应该彻底测试、检查和保护底层源代码。在本教程的这一部分，您将练习单元测试、集成测试和端到端测试。您还将执行静态代码分析和安全扫描，以在修复成本仍然低廉的情况下识别潜在的问题和漏洞。\n用单元测试覆盖源代码 单元测试涉及测试程序的各个单元或组件，以确保它们按预期工作。如今，它已成为软件开发的必要组成部分。许多工程师甚至更进一步，严格遵循测试驱动开发方法，首先编写单元测试来驱动代码设计。\n在编写单元测试时，Python 社区中的人们选择 pytest 而不是标准库的 unittest 模块是很常见的。由于 pytest 相对简单，这个测试框架上手很快。继续并将 pytest 添加为项目的可选依赖项：\n# pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;redis\u0026#34;, ] [project.optional-dependencies] dev = [ \u0026#34;pytest\u0026#34;, ] 您可以将以某种方式相关的可选依赖项分组在一个通用名称下。例如，在这里，您创建了一个名为 dev 的组来收集您将在开发过程中使用的工具和库。通过将 pytest 与主要依赖项分开，您将能够仅在需要时按需安装它。毕竟，将您的测试或相关的测试框架与构建的分发包捆绑在一起是没有意义的。\n不要忘记重新安装带有可选依赖项的 Python 包，以使 pytest 进入项目的虚拟环境：\n(page-tracker) $ python -m pip install --editable \u0026#34;.[dev]\u0026#34; 您可以使用方括号列出在您的 pyproject.toml 文件中定义的可选依赖组的名称。在这种情况下，您要求安装用于开发目的的依赖项，包括测试框架。请注意，建议在方括号周围使用引号 ( \u0026quot;\u0026quot; ) 以防止 shell 中潜在的文件名扩展。\n因为您在项目中遵循了 src 布局，所以您不必将测试模块保存在与被测代码相同的文件夹或相同的命名空间包中。您可以为测试创建一个单独的目录分支，如下所示：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── test/ │ └── unit/ │ └── test_app.py │ ├── venv/ │ ├── constraints.txt └── pyproject.toml 您已将测试模块放在 test/unit/ 文件夹中以保持井井有条。 pytest 框架将在您为测试添加前缀 test 时发现您的测试。虽然您可以更改它，但通常在使用相应的测试模块镜像每个 Python 模块时保持默认约定。例如，您将在 test/unit/ 文件夹中用 test_app 覆盖 app 模块。\n您将从测试 Web 应用程序的成功路径开始，这通常意味着向服务器发送请求。每个 Flask 应用程序都带有一个方便的测试客户端，您可以使用它来发出模拟的 HTTP 请求。因为测试客户端不需要运行实时服务器，所以你的单元测试执行得更快并且会变得更加孤立。\n您可以获得测试客户端并将其方便地包装在测试装置中，以使其可用于您的测试功能：\n# test/unit/test_app.py import pytest from page_tracker.app import app @pytest.fixture def http_client(): return app.test_client() 首先，您导入 pytest 包以针对您的自定义函数利用其 @fixture 装饰器。仔细选择您的函数名称，因为它也会成为您可以作为参数传递给各个测试函数的夹具的名称。您还可以从 page_tracker 包中导入 Flask 应用程序以获取相应的测试客户端实例。\n当您打算编写单元测试时，您必须始终通过消除代码单元可能具有的任何依赖关系来隔离它。这意味着您应该模拟或存根您的代码所依赖的任何外部服务、数据库或库。在您的情况下，Redis 服务器就是这样的依赖项。\n不幸的是，您的代码目前使用硬编码的 Redis 客户端，这会阻止模拟。这是从一开始就遵循测试驱动开发的一个很好的论据，但这并不意味着您必须返回并重新开始。相反，您将通过实施依赖注入设计模式来重构您的代码：\n# src/page_tracker/app.py +from functools import cache from flask import Flask from redis import Redis app = Flask(__name__) -redis = Redis() @app.get(\u0026#34;/\u0026#34;) def index(): - page_views = redis.incr(\u0026#34;page_views\u0026#34;) + page_views = redis().incr(\u0026#34;page_views\u0026#34;) return f\u0026#34;This page has been seen {page_views} times.\u0026#34; +@cache +def redis(): + return Redis() 本质上，您将 Redis 客户端创建代码从全局范围移动到一个新的 redis() 函数，您的控制器函数会在运行时针对每个传入请求调用该函数。这将允许您的测试用例在正确的时间用模拟对应物替换返回的 Redis 实例。但是，为了确保内存中只有一个客户端实例，有效地使其成为一个单例，您还缓存了新函数的结果。\n现在回到您的测试模块并实施以下单元测试：\n# test/unit/test_app.py import unittest.mock import pytest from page_tracker.app import app @pytest.fixture def http_client(): return app.test_client() @unittest.mock.patch(\u0026#34;page_tracker.app.redis\u0026#34;) def test_should_call_redis_incr(mock_redis, http_client): # Given mock_redis.return_value.incr.return_value = 5 # When response = http_client.get(\u0026#34;/\u0026#34;) # Then assert response.status_code == 200 assert response.text == \u0026#34;This page has been seen 5 times.\u0026#34; mock_redis.return_value.incr.assert_called_once_with(\u0026#34;page_views\u0026#34;) 您使用 Python 的 @patch 装饰器包装您的测试函数，以将模拟的 Redis 客户端作为参数注入其中。您还告诉 pytest 将您的 HTTP 测试客户端装置作为另一个参数注入。测试函数有一个描述性名称，以动词 should 开头并遵循 Given-When-Then 模式。这两个常用于行为驱动开发的约定，使您的测试被解读为行为规范。\n在您的测试用例中，您首先将模拟 Redis 客户端设置为在其 .incr() 方法被调用时始终返回 5 。然后，您向根端点 ( / ) 发出伪造的 HTTP 请求并检查服务器的响应状态和正文。因为模拟可以帮助您测试单元的行为，所以您只需验证服务器是否使用预期参数调用了正确的方法，并相信 Redis 客户端库可以正常工作。\n要执行单元测试，您可以使用代码编辑器中集成的测试运行器，也可以在终端中键入以下命令：\n(page-tracker) $ python -m pytest -v test/unit/ 您从虚拟环境中将 pytest 作为 Python 模块运行，指示它扫描 test/unit/ 目录以便在那里查找测试模块。 -v 开关增加了测试报告的详细程度，以便您可以看到有关各个测试用例的更多详细信息。\n在所有单元测试都通过后盯着绿色报告会感到满足。它使您对代码有一定程度的信心，但不足以做出任何形式的保证。许多模因说明了即使在单元测试通过后运行集成测试的重要性。\n例如，其中一个经典模因显示有两个抽屉，但一次只能打开一个。虽然每个单独的抽屉或单元都经过测试并独立工作，但当您尝试将它们集成到一件家具中时，就会出现问题。接下来，您将向您的项目添加一个基本的集成测试。\n通过集成测试检查组件交互 集成测试应该是运行单元测试后的下一个阶段。集成测试的目标是检查您的组件作为更大系统的一部分如何相互交互。\n例如，您的页面跟踪器 Web 应用程序可能具有集成测试，用于检查与真正的 Redis 服务器而不是模拟服务器的通信。\n您可以重复使用 pytest 来实施和运行集成测试。但是，您将安装一个额外的 pytest-timeout 插件，以允许您强制运行时间过长的测试用例失败：\n# pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;redis\u0026#34;, ] [project.optional-dependencies] dev = [ \u0026#34;pytest\u0026#34;, \u0026#34;pytest-timeout\u0026#34;, ] 理想情况下，您不必担心单元测试超时，因为它们应该针对速度进行优化。另一方面，集成测试将需要更长的时间来运行，并且可能会在停滞的网络连接上无限挂起，从而阻止您的测试套件完成。因此，在这种情况下有办法中止它们很重要。\n请记住再次重新安装带有可选依赖项的包，以使 pytest-timeout 插件可用：\n(page-tracker) $ python -m pip install --editable \u0026#34;.[dev]\u0026#34; 在继续之前，为您的集成测试添加另一个子文件夹，并在您的 test/ 文件夹中定义一个 conftest.py 文件：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── test/ │ ├── integration/ │ │ └── test_app_redis.py │ │ │ ├── unit/ │ │ └── test_app.py │ │ │ └── conftest.py │ ├── venv/ │ ├── constraints.txt └── pyproject.toml 您将在 conftest.py 中放置公共装置，不同类型的测试将共享这些装置。\n虽然您的 Web 应用程序只有一个组件，但您可以将 Redis 视为 Flask 需要使用的另一个组件。因此，集成测试可能看起来与您的单元测试类似，只是不再模拟 Redis 客户端：\n# test/integration/test_app_redis.py import pytest @pytest.mark.timeout(1.5) def test_should_update_redis(redis_client, http_client): # Given redis_client.set(\u0026#34;page_views\u0026#34;, 4) # When response = http_client.get(\u0026#34;/\u0026#34;) # Then assert response.status_code == 200 assert response.text == \u0026#34;This page has been seen 5 times.\u0026#34; assert redis_client.get(\u0026#34;page_views\u0026#34;) == b\u0026#34;5\u0026#34; 从概念上讲，您的新测试用例包含与以前相同的步骤，但它与真正的 Redis 服务器交互。这就是为什么你给测试最多 1.5 秒来完成使用 @pytest.mark.timeout 装饰器。测试函数将两个夹具作为参数：\n连接到本地数据存储的 Redis 客户端 Flask 的测试客户端连接到您的 Web 应用程序 为了使第二个在您的集成测试中也可用，您必须将 http_client() 夹具从 test_app 模块移动到 conftest.py 文件：\n# test/conftest.py import pytest import redis from page_tracker.app import app @pytest.fixture def http_client(): return app.test_client() @pytest.fixture(scope=\u0026#34;module\u0026#34;) def redis_client(): return redis.Redis() 由于此文件位于文件夹层次结构的上一层， pytest 将选取其中定义的所有灯具，并使它们在整个嵌套文件夹中可见。除了您从另一个 Python 模块移动的熟悉的 http_client() 夹具之外，您还定义了一个返回默认 Redis 客户端的新夹具。请注意，您为它指定了 module 范围，以便为测试模块中的所有函数重用相同的 Redis 客户端实例。\n要执行集成测试，您必须仔细检查 Redis 服务器是否在本地默认端口 6379 上运行，然后像以前一样启动 pytest ，但将其指向包含集成测试的文件夹：\n(page-tracker) $ python -m pytest -v test/integration/ 因为您的集成测试连接到实际的 Redis 服务器，所以它会覆盖您之前可能存储在 page_views 键下的值。但是，如果在执行集成测试时 Redis 服务器未运行，或者如果 Redis 在其他地方运行，那么您的测试将失败。这种失败可能是出于错误的原因，使结果成为假阴性错误，因为您的代码实际上可能按预期工作。\n要观察此问题，请立即停止 Redis 并重新运行集成测试：\n(page-tracker) $ docker stop redis-server redis-server (page-tracker) $ python -m pytest -v test/integration/ ⋮ ========================= short test summary info ========================== FAILED test/integration/test_app_redis.py::test_should_update_redis - ⮑redis.exceptions.ConnectionError: Error 111 connecting to localhost:6379. ⮑Connection refused ============================ 1 failed in 0.19s ============================= 这揭示了您的代码中的一个问题，该问题目前无法妥善处理 Redis 连接错误。本着测试驱动开发的精神，您可以首先编写一个重现该问题的测试用例，然后修复它。切换一下，使用模拟的 Redis 客户端在 test_app 模块中添加以下单元测试：\n# test/unit/test_app.py import unittest.mock from redis import ConnectionError # ... @unittest.mock.patch(\u0026#34;page_tracker.app.redis\u0026#34;) def test_should_handle_redis_connection_error(mock_redis, http_client): # Given mock_redis.return_value.incr.side_effect = ConnectionError # When response = http_client.get(\u0026#34;/\u0026#34;) # Then assert response.status_code == 500 assert response.text == \u0026#34;Sorry, something went wrong \\N{pensive face}\u0026#34; 您设置模拟的 .incr() 方法的副作用，以便调用该方法将引发 redis.ConnectionError 异常，这是您在集成测试失败时观察到的。您的新单元测试是负面测试的一个示例，它期望 Flask 以 HTTP 状态代码 500 和描述性消息进行响应。以下是满足该单元测试的方法：\n# src/page_tracker/app.py from functools import cache from flask import Flask from redis import Redis, RedisError app = Flask(__name__) @app.get(\u0026#34;/\u0026#34;) def index(): try: page_views = redis().incr(\u0026#34;page_views\u0026#34;) except RedisError: app.logger.exception(\u0026#34;Redis error\u0026#34;) return \u0026#34;Sorry, something went wrong \\N{pensive face}\u0026#34;, 500 else: return f\u0026#34;This page has been seen {page_views} times.\u0026#34; @cache def redis(): return Redis() 您拦截顶级异常类 redis.RedisError ，它是 Redis 客户端引发的所有异常类型的祖先。如果出现任何问题，您将返回预期的 HTTP 状态代码和一条消息。为方便起见，您还使用 Flask 内置的记录器记录异常。\n注意：虽然父类是子类直接扩展的直接基类，但祖先类可以位于继承层次结构中更上层的任何位置。\n好极了！由于测试，您修改了单元测试，实施了集成测试，并在发现代码中的缺陷后修复了它。\n尽管如此，当您将应用程序部署到远程环境时，您如何知道所有部分都组合在一起并且一切都按预期工作？\n在下一节中，您将通过对实际 Flask 服务器而不是测试客户端执行端到端测试来模拟真实场景。\n测试真实场景端到端 端到端测试，也称为广泛堆栈测试，包含多种测试，可以帮助您验证整个系统。他们通过模拟实际用户通过应用程序的流程来测试完整的软件堆栈。因此，端到端测试需要一个尽可能模拟生产环境的部署环境。通常还需要专门的测试工程师团队。\n注意：由于端到端测试的维护成本很高，而且往往需要花费大量时间来设置和运行，因此它们位于 Google 测试金字塔的顶端。换句话说，您的目标应该是进行更多的集成测试，甚至在您的项目中进行更多的单元测试。\n由于您最终希望为您的 Docker 应用程序构建一个成熟的持续集成管道，因此进行一些端到端测试将变得至关重要。首先为您的 E2E 测试添加另一个子文件夹：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── test/ │ ├── e2e/ │ │ └── test_app_redis_http.py │ │ │ ├── integration/ │ │ └── test_app_redis.py │ │ │ ├── unit/ │ │ └── test_app.py │ │ │ └── conftest.py │ ├── venv/ │ ├── constraints.txt └── pyproject.toml 您将要实施的测试场景将类似于您的集成测试。不过，主要区别在于您将通过网络将实际的 HTTP 请求发送到实时 Web 服务器，而不是依赖 Flask 的测试客户端。\n为此，您将使用第三方 requests 库，您必须首先在 pyproject.toml 文件中将其指定为另一个可选依赖项：\n# pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;redis\u0026#34;, ] [project.optional-dependencies] dev = [ \u0026#34;pytest\u0026#34;, \u0026#34;pytest-timeout\u0026#34;, \u0026#34;requests\u0026#34;, ] 您不会使用 requests 在生产环境中运行服务器，因此无需将其作为常规依赖项。同样，使用可编辑模式重新安装带有可选依赖项的 Python 包：\n(page-tracker) $ python -m pip install --editable \u0026#34;.[dev]\u0026#34; 您现在可以在端到端测试中使用已安装的 requests 库：\n# test/e2e/test_app_redis_http.py import pytest import requests @pytest.mark.timeout(1.5) def test_should_update_redis(redis_client, flask_url): # Given redis_client.set(\u0026#34;page_views\u0026#34;, 4) # When response = requests.get(flask_url) # Then assert response.status_code == 200 assert response.text == \u0026#34;This page has been seen 5 times.\u0026#34; assert redis_client.get(\u0026#34;page_views\u0026#34;) == b\u0026#34;5\u0026#34; 除了负责发送 HTTP GET 请求的第 12 行之外，此代码与您的集成测试几乎相同。之前，您将该请求发送到测试客户端的根地址，用斜杠字符 ( / ) 表示。现在，您不知道可能在远程主机上运行的 Flask 服务器的确切域或 IP 地址。因此，您的函数接收一个 Flask URL 作为参数， pytest 将其作为固定装置注入。\n您可以通过命令行提供特定的网络服务器地址。同样，您的 Redis 服务器可能在不同的主机上运行，因此您也需要提供其地址作为命令行参数。可是等等！您的 Flask 应用程序当前期望 Redis 始终在本地主机上运行。继续并更新您的代码以使其可配置：\n# src/page_tracker/app.py import os from functools import cache from flask import Flask from redis import Redis, RedisError app = Flask(__name__) @app.get(\u0026#34;/\u0026#34;) def index(): try: page_views = redis().incr(\u0026#34;page_views\u0026#34;) except RedisError: app.logger.exception(\u0026#34;Redis error\u0026#34;) return \u0026#34;Sorry, something went wrong \\N{pensive face}\u0026#34;, 500 else: return f\u0026#34;This page has been seen {page_views} times.\u0026#34; @cache def redis(): return Redis.from_url(os.getenv(\u0026#34;REDIS_URL\u0026#34;, \u0026#34;redis://localhost:6379\u0026#34;)) 通常使用环境变量来设置敏感数据，例如数据库 URL，因为它提供了额外级别的安全性和灵活性。在这种情况下，您的程序需要一个自定义的 REDIS_URL 变量。如果在给定环境中未指定该变量，则您将回退到默认主机和端口。\n要使用自定义命令行参数扩展 pytest ，您必须编辑 conftest.py 并按以下方式连接到框架的参数解析器：\n# test/conftest.py import pytest import redis from page_tracker.app import app def pytest_addoption(parser): parser.addoption(\u0026#34;--flask-url\u0026#34;) parser.addoption(\u0026#34;--redis-url\u0026#34;) @pytest.fixture(scope=\u0026#34;session\u0026#34;) def flask_url(request): return request.config.getoption(\u0026#34;--flask-url\u0026#34;) @pytest.fixture(scope=\u0026#34;session\u0026#34;) def redis_url(request): return request.config.getoption(\u0026#34;--redis-url\u0026#34;) @pytest.fixture def http_client(): return app.test_client() @pytest.fixture(scope=\u0026#34;module\u0026#34;) def redis_client(redis_url): if redis_url: return redis.Redis.from_url(redis_url) return redis.Redis() 您使用类似于 Python 的 argparse 模块的语法定义两个可选参数， --flask-url 和 --redis-url 。然后，您将这些参数包装在会话范围的固定装置中，您将能够将其注入到您的测试函数和其他固定装置中。具体来说，您现有的 redis_client() fixture 现在可以利用可选的 Redis URL。\n注意：因为您的端到端测试和集成测试依赖于相同的 redis_client() fixture，所以您可以通过在两种类型的测试中指定 --redis-url 选项来连接到远程 Redis 服务器。\n这是通过指定 Flask Web 服务器和相应的 Redis 服务器的 URL 来使用 pytest 运行端到端测试的方法：\n(page-tracker) $ python -m pytest -v test/e2e/ \\ --flask-url http://127.0.0.1:5000 \\ --redis-url redis://127.0.0.1:6379 在这种情况下，您可以通过本地主机 ( 127.0.0.1 ) 访问 Flask 和 Redis，但您的应用程序可能会部署到由多台远程计算机组成的地理分布式环境中。当你在本地执行此命令时，确保 Redis 正在运行并首先单独启动你的 Flask 服务器：\n(page-tracker) $ docker start redis-server (page-tracker) $ flask --app page_tracker.app run 为了提高代码质量，如果您有能力，可以不断向您的应用程序添加更多类型的测试。不过，这通常需要一个全职软件质量保证工程师团队。另一方面，执行代码审查或其他类型的静态代码分析是相当容易实现的，可以发现许多令人惊讶的问题。您现在将查看此过程。\n执行静态代码分析和安全扫描 现在您的应用程序已按预期运行，是时候在不执行底层代码的情况下执行静态代码分析了。这是软件开发行业的一种常见做法，可帮助开发人员识别其代码中的潜在软件缺陷和安全风险。\n虽然静态分析的某些步骤可以自动完成，但其他步骤通常需要手动完成，例如同行评审。\n您将使用以下自动化工具，因此请将它们作为可选依赖项添加到您的 pyproject.toml 文件中：\n# pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;redis\u0026#34;, ] [project.optional-dependencies] dev = [ \u0026#34;bandit\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;flake8\u0026#34;, \u0026#34;isort\u0026#34;, \u0026#34;pylint\u0026#34;, \u0026#34;pytest\u0026#34;, \u0026#34;pytest-timeout\u0026#34;, \u0026#34;requests\u0026#34;, ] 之后不要忘记重新安装并固定您的依赖项：\n(page-tracker) $ python -m pip install --editable \u0026#34;.[dev]\u0026#34; (page-tracker) $ python -m pip freeze --exclude-editable \u0026gt; constraints.txt 这会将一些命令行实用工具带入您的虚拟环境。首先，您应该通过一致地格式化代码、对 import 语句进行排序并检查 PEP 8 合规性来清理代码：\n(page-tracker) $ python -m black src/ --check would reformat /home/realpython/page-tracker/src/page_tracker/app.py Oh no! 💥 💔 💥 1 file would be reformatted, 1 file would be left unchanged. (page-tracker) $ python -m isort src/ --check ERROR: /home/.../app.py Imports are incorrectly sorted and/or formatted. (page-tracker) $ python -m flake8 src/ src/page_tracker/app.py:23:1: E302 expected 2 blank lines, found 1 您使用 black 标记代码中的任何格式不一致，使用 isort 确保您的 import 语句根据官方建议保持组织，使用 flake8 检查任何其他 PEP 8 样式违规。\n如果您在运行这些工具后没有看到任何输出，则意味着没有什么可以修复的。另一方面，如果出现警告或错误，那么您可以手动更正任何报告的问题，或者让这些工具在您删除 --check 标志时自动执行：\n(page-tracker) $ python -m black src/ reformatted /home/realpython/page-tracker/src/page_tracker/app.py All done! ✨ 🍰 ✨ 1 file reformatted, 1 file left unchanged. (page-tracker) $ python -m isort src/ Fixing /home/realpython/page-tracker/src/page_tracker/app.py (page-tracker) $ python -m flake8 src/ 如果没有 --check 标志， black 和 isort 都会继续并在不询问的情况下重新格式化受影响的文件。运行这两个命令还解决了 PEP 8 合规性问题，因为 flake8 不再返回任何样式违规。\n注意：遵循整个团队的通用代码风格约定有助于保持代码整洁。这样，当一个人更新源文件时，团队成员就不必对不相关代码部分（例如空格）的更改进行分类。\n一旦一切都干净了，您就可以对代码进行 lint 以查找潜在的代码异味或改进它的方法：\n(page-tracker) $ python -m pylint src/ 当您针对 Web 应用程序的源代码运行 pylint 时，它可能会开始抱怨或多或少有用的东西。它通常发出属于几个类别的消息，包括：\nE: Errors W: Warnings C: 违反公约 R: 重构建议 每条评论都有一个唯一的标识符，例如 C0116 ，如果您觉得它没有帮助，您可以将其隐藏。您可以在全局配置文件中包含抑制的标识符以获得永久效果，或者使用命令行开关忽略给定运行中的某些错误。\n您还可以在给定行上添加特殊格式的 Python 注释以说明特殊情况：\n# src/page_tracker/app.py import os from functools import cache from flask import Flask from redis import Redis, RedisError app = Flask(__name__) @app.get(\u0026#34;/\u0026#34;) def index(): try: page_views = redis().incr(\u0026#34;page_views\u0026#34;) except RedisError: app.logger.exception(\u0026#34;Redis error\u0026#34;) # pylint: disable=E1101 return \u0026#34;Sorry, something went wrong \\N{pensive face}\u0026#34;, 500 else: return f\u0026#34;This page has been seen {page_views} times.\u0026#34; @cache def redis(): return Redis.from_url(os.getenv(\u0026#34;REDIS_URL\u0026#34;, \u0026#34;redis://localhost:6379\u0026#34;)) 在这种情况下，您告诉 pylint 忽略错误 E1101 的特定实例，而不是完全抑制它。这是一个误报，因为 .logger 是 Flask 在运行时生成的动态属性，在静态分析过程中不可用。\n注意：如果您打算使用 pylint 作为自动化持续集成管道的一部分，那么您可能需要指定它何时应该退出并显示错误代码，这通常会停止管道的后续步骤。例如，您可以将其配置为始终返回中性退出代码零：\n(page-tracker) $ python -m pylint src/ --exit-zero 这永远不会停止管道运行，即使 pylint 在代码中发现一些问题。或者，使用 --fail-under ，您可以指定任意分数阈值， pylint 将在该阈值时退出并显示错误代码。\n您会注意到 pylint 为您的代码打分并对其进行跟踪。当您以某种方式解决问题并再次运行该工具时，它会报告一个新分数并告诉您它改善或恶化了多少。使用您的最佳判断来决定 pylint 报告的问题是否值得修复。\n最后，无意中通过源代码泄露敏感数据或暴露其他安全漏洞的情况非常普遍。它甚至发生在最好的软件工程师身上。最近，GitHub 在一个公共存储库中暴露了它的私钥，这可能让攻击者冒充这个巨头。为了降低此类事件的风险，您应该在将源代码部署到任何地方之前对其进行安全或漏洞扫描。\n要扫描您的代码，您可以使用 bandit ，它是您之前作为可选依赖项安装的：\n(page-tracker) $ python -m bandit -r src/ 当您指定文件夹路径而不是文件路径时，还必须包含 -r 标志以递归扫描它。此时， bandit 应该不会在您的代码中发现任何问题。但是，如果您在 Flask 应用程序底部添加以下两行后再次运行它，那么该工具将报告不同严重级别的问题：\n# src/page_tracker/app.py # ... if __name__ == \u0026#34;__main__\u0026#34;: app.run(host=\u0026#34;0.0.0.0\u0026#34;, port=5000, debug=True) 这种 name-main 惯用语是许多 Flask 应用程序中常见的模式，因为它使开发更方便，让您直接运行 Python 模块。另一方面，它暴露了 Flask 的调试器，允许执行任意代码，并通过地址 0.0.0.0 绑定到所有网络接口，为公共流量打开您的服务。\n因此，为了确保您的 Flask 应用程序是安全的，您应该始终在将代码部署到生产环境之前运行 bandit 或类似工具。\n好的。您的 Web 应用程序包含单元、集成和端到端测试。这意味着许多自动化工具已经静态分析和修改了它的源代码。\n接下来，您将继续通过将应用程序包装在 Docker 容器中来实现持续集成，这样您就可以将整个项目部署到远程环境或忠实地将其复制到本地计算机上。\n将您的 Flask Web 应用程序 Docker 化 在本节中，您将以 Docker 容器的形式运行您的页面跟踪器 Web 应用程序，该容器可以与在另一个容器中运行的 Redis 通信。这样的设置对于开发和测试以及将应用程序部署到远程环境很有用。\n即使您的计算机上没有安装 Python 或 Redis，您仍然可以通过 Docker 运行您的项目。\n理解 Docker 术语 对应用程序进行 Docker 化涉及创建 Dockerfile，它是对环境所需状态的声明性描述。它为运行时环境、配置以及运行应用程序所需的所有依赖项和库提供模板。\n要为您的应用程序注入活力，您必须根据该描述构建一个 Docker 镜像。您可以将 Docker 镜像视为操作系统在给定时间的快照。当您与世界或公司内部共享您的 Docker 镜像时，其他人可以重现与您完全相同的环境并运行相同的应用程序。\n这回避了经典，但它适用于我的机器问题。\nDocker 镜像是 Docker 容器的蓝图。每个 Docker 容器都是 Docker 镜像的一个实例。一个容器有独立的状态和资源，包括它自己的文件系统、环境变量和网络接口。单个 Docker 容器通常运行单个进程，使其成为托管特定微服务的理想选择。\n通过添加更多容器，您可以临时扩展一个或多个微服务以处理流量高峰，例如，这在假期期间可能很常见。但是，您的微服务必须架构良好并保持无状态才能使其有效。\n注意：Docker 容器类似于 Vagrant 或 VirtualBox 等虚拟机，但更轻巧且启动速度更快。因此，您可以同时在主机上运行比虚拟机更多的容器。\n这样做的原因是容器的开销较小，因为它们共享操作系统的内核，而虚拟机运行在模拟完整硬件堆栈的管理程序上。另一方面，容器不那么安全，它们也不提供与虚拟机相同级别的隔离。\n典型的应用程序包括在隔离的 Docker 容器中运行的多个服务，这些容器可以相互通信。您的页面跟踪器应用程序有以下两个：\nWeb service Redis service 您已经知道如何通过 Docker 运行 Redis。现在，是时候将您的 Flask Web 应用程序沙盒化到 Docker 容器中，以简化这两种服务的开发和部署过程。\n了解 Dockerfile 的剖析 首先，您将定义一个适用于开发阶段的相对较短的 Dockerfile。在项目根文件夹中创建一个名为 Dockerfile 的文件，该文件与文件层次结构中的 src/ 子文件夹和 pyproject.toml 配置文件处于同一级别：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── test/ │ ├── venv/ │ ├── constraints.txt ├── Dockerfile └── pyproject.toml 您可以随意命名此文件，但坚持默认命名约定将使您不必在每次构建镜像时都指定文件名。 Docker 期望的默认文件名是 Dockerfile ，没有文件扩展名。请注意，它以大写字母 D 开头。\nDockerfile 是一个纯文本文档，其中列出了组装镜像所需的步骤。它遵循特定格式，定义了一套固定的说明供您使用。\n注意：您必须将 Dockerfile 中的每条指令放在单独的一行中，但看到非常长的行被行连续字符 ( \\ ) 多次打断的情况并不少见。事实上，通常需要在一行中塞入多个操作，以利用您现在将要了解的缓存机制。\n当您从 Dockerfile 构建镜像时，您依赖于一系列层。每条指令都会在前一层之上创建一个只读层，封装对镜像底层文件系统的一些修改。图层具有全局唯一标识符，这允许 Docker 将图层存储在缓存中。这有两个主要优点：\n速度：Docker 可以跳过自上次构建以来未更改的层，而是从缓存中加载它们，从而显着加快镜像构建速度。 大小：多个镜像可以共享公共图层，从而减小它们各自的大小。除此之外，层数越少，镜像尺寸越小。 现在您已经了解了 Dockerfile 的这种分层结构，您可以开始向其中添加指令，同时了解创建高效 Docker 镜像的最佳实践。\n选择基础 Docker 镜像 每个 Dockerfile 中的第一条指令 FROM 必须始终定义用于构建新镜像的基础镜像。这意味着您不必从头开始，而是可以选择一个已经构建的合适镜像。例如，您可以使用 Python 解释器附带的镜像：\n# Dockerfile FROM python:3.11.2-slim-bullseye 在这里，您使用名为 python 的官方 Python 镜像，它托管在 Docker Hub 上。官方镜像由相应语言或技术的官方维护者构建和维护。它们不属于 Docker Hub 上的任何特定用户或团队，但在全局命名空间中可用，隐式称为 library/ ，而不是更专业的变体，如 circleci/python 。\n您还可以在冒号 ( : ) 后指定一个可选的标签或标签名称，以缩小基本镜像的特定版本。您可以通过单击相应 Docker Hub 页面上的“标签”选项卡来浏览给定 Docker 镜像的所有可用标签。\n注意：标签不是强制性的，但将它们包含在 FROM 指令中被认为是最佳实践。您应该尽可能具体，以避免不必要的意外。如果您省略该标记，那么 Docker 将拉取一个标记为 latest 的镜像，其中可能包含不合适的操作系统或影响您的应用程序的运行时意外更改。\n标签 3.11.2-slim-bullseye 表示您的基础镜像将是 Debian Bullseye 的精简变体，仅包含基本要素，让您稍后可以根据需要安装任何其他软件包。这减小了镜像的大小并加快了下载时间。此镜像的常规变体和超薄变体之间的大小差异高达八百兆字节！\n该标记还表明您的基础镜像将随已安装的 Python 3.11.2 一起提供，因此您可以立即开始使用它。\n在拉取基础镜像后，您可能想要立即执行的下一个任务是使用最新的安全更新和错误修复对其进行修补，这些更新和错误修复可能是自镜像在 Docker Hub 上发布以来发布的：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes 在 Debian 中，您可以使用 apt-get 命令获取最新的软件包列表并升级任何有可用更新的软件包。请注意，这两个命令都作为一个 RUN 指令的一部分执行，以最大限度地减少文件系统中的层数，从而避免占用过多的磁盘空间。\n注意：Dockerfile 中指令的顺序很重要，因为它会影响构建镜像所需的时间。\n特别是，您应该将其层经常更改的指令放在 Dockerfile 的底部，因为它们最有可能使缓存中的所有后续层无效。\n好的。您已经选择了基本镜像并安装了最新的安全更新。您几乎已经准备好设置您的 Flask 应用程序，但还有几个步骤。\n隔离你的 Docker 镜像 使用 Dockerfiles 时的另一个好习惯是，一旦不再需要它们，就创建并切换到没有管理权限的普通用户。默认情况下，Docker 以超级用户身份运行您的命令，恶意攻击者可以利用它来不受限制地访问您的主机系统。是的，Docker 提供了对容器和主机的根级访问权限！\n以下是避免这种潜在安全风险的方法：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython 您创建一个名为 realpython 的新用户，并告诉 Docker 从现在起在 Dockerfile 中使用该用户。您还将当前工作目录设置为此用户的主目录，这样您就不必在后面的命令中明确指定完整的文件路径。\n即使您的 Docker 容器将运行单个 Flask 应用程序，也请考虑在容器本身内部设置一个专用的虚拟环境。虽然您无需担心将多个 Python 项目彼此隔离，并且 Docker 为您的主机提供了一个合理的隔离层，但您仍然存在干扰容器自身系统工具的风险。\n不幸的是，许多 Linux 发行版都依赖于全局 Python 安装才能顺利运行。如果您开始将包直接安装到全局 Python 环境中，那么您就为潜在的版本冲突打开了大门。这甚至可能导致破坏您的系统。\n注意：如果您仍然不相信在 Docker 容器内创建虚拟环境，那么这条警告消息可能会改变您的想法：\nWARNING: Running pip as the \u0026#39;root\u0026#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is ⮑recommended to use a virtual environment instead: ⮑https://pip.pypa.io/warnings/venv 在 Debian 或 Ubuntu 等衍生发行版上尝试使用系统的全局 pip 命令安装 Python 包后，您可能会看到这一点。\n在 Docker 镜像中创建和激活虚拟环境的最可靠方法是直接修改其 PATH 环境变量：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; 首先，定义一个辅助变量 VIRTUALENV ，其中包含项目虚拟环境的路径，然后使用 Python 的 venv 模块在那里创建该环境。但是，不是使用 shell 脚本激活新环境，而是通过覆盖 python 可执行文件的路径来更新 PATH 变量。\n为什么？这是必要的，因为以通常的方式激活您的环境只是暂时的，不会影响从您的镜像派生的 Docker 容器。此外，如果您使用 Dockerfile 的 RUN 指令激活虚拟环境，那么它只会持续到 Dockerfile 中的下一条指令，因为每条指令都会启动一个新的 shell 会话。\n一旦你有了项目的虚拟环境，你就可以安装必要的依赖项。\n缓存你的项目依赖 与在主机本地工作相比，在 Dockerfile 中安装依赖项看起来略有不同。通常，您会安装依赖项，然后立即安装 Python 包。\n相比之下，当您构建 Docker 镜像时，值得将该过程分为两个步骤以利用层缓存，从而减少构建镜像所需的总时间。\n首先， COPY 将带有项目元数据的两个文件从您的主机导入到 Docker 镜像中：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --chown=realpython pyproject.toml constraints.txt ./ 您只需将包含有关项目依赖项信息的 pyproject.toml 和 constraints.txt 文件复制到 Docker 镜像中 realpython 用户的主目录中。默认情况下，文件归超级用户所有，因此您可能希望使用 --chown 将其所有者更改为您之前创建的普通用户。 --chown 选项类似于 chown 命令，它代表更改所有者。\n您可以在网上找到的许多 Dockerfile 示例会一次性复制所有内容，但那很浪费！\n可能有大量额外文件，例如包含项目整个历史的本地 Git 存储库、代码编辑器设置或项目根文件夹中的其他临时文件。\n它们不仅会使生成的镜像膨胀，而且还会增加过早使 Docker 层缓存失效的可能性。\n注意：您应该只复制您目前需要的单个文件到您的 Dockerfile 中。否则，即使是不相关文件中的最细微变化也会导致剩余图层重建。或者，您可以定义一个 .dockerignore 文件，其工作方式与 .gitignore 副本类似，但明确说明要复制的内容更安全。\n另一个容易遗漏的难题是当您在尝试安装项目依赖项之前忘记升级 pip 本身。在极少数情况下， pip 的旧版本实际上可以阻止安装其他软件包的最新版本！在您的情况下，还值得升级 setuptools ，您将其用作构建后端，以获取最新的安全补丁。\n您可以将以下两个命令组合在一条 RUN 指令中以安装您的依赖项：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --chown=realpython pyproject.toml constraints.txt ./ RUN python -m pip install --upgrade pip setuptools \u0026amp;\u0026amp; \\ python -m pip install --no-cache-dir -c constraints.txt \u0026#34;.[dev]\u0026#34; 您将 pip 和 setuptools 升级到最新版本。然后，安装项目所需的第三方库，包括用于开发的可选依赖项。您限制它们的版本以确保一致的环境，并告诉 pip 使用 --no-cache-dir 禁用缓存。您在虚拟环境之外不需要这些包，因此无需缓存它们。这样，您就可以使 Docker 镜像更小。\n注意：因为您安装了依赖项而没有在 Docker 镜像中安装 page-tracker 包，所以它们将保留在缓存层中。因此，对源代码的任何更改都不需要重新安装这些依赖项。\n您的 Dockerfile 正在增长并变得越来越复杂，但请不要担心。只需要完成几个步骤，就快完成了。\n作为构建过程的一部分运行测试 最后，是时候将您的源代码复制到 Docker 镜像中，并与 linters 和其他静态分析工具一起运行您的测试了：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --chown=realpython pyproject.toml constraints.txt ./ RUN python -m pip install --upgrade pip setuptools \u0026amp;\u0026amp; \\ python -m pip install --no-cache-dir -c constraints.txt \u0026#34;.[dev]\u0026#34; COPY --chown=realpython src/ src/ COPY --chown=realpython test/ test/ RUN python -m pip install . -c constraints.txt \u0026amp;\u0026amp; \\ python -m pytest test/unit/ \u0026amp;\u0026amp; \\ python -m flake8 src/ \u0026amp;\u0026amp; \\ python -m isort src/ --check \u0026amp;\u0026amp; \\ python -m black src/ --check --quiet \u0026amp;\u0026amp; \\ python -m pylint src/ --disable=C0114,C0116,R1705 \u0026amp;\u0026amp; \\ python -m bandit -r src/ --quiet 从主机复制 src/ 和 test/ 文件夹后，将 page-tracker 包安装到虚拟环境中。通过将自动化测试工具融入构建过程，您可以确保如果其中任何一个工具返回非零退出状态代码，则构建您的 Docker 镜像将失败。这正是您在实施持续集成管道时想要的。\n请注意，您必须禁用严重性低的 pylint 问题 C0114 、 C0116 和 R1705 ，它们现在并不重要。否则，它们会阻止您的 Docker 镜像成功构建。\n将各个命令组合在一个 RUN 指令中的原因是为了减少要缓存的层数。请记住，您拥有的层越多，生成的 Docker 镜像就越大。\n注意：此时，您无法执行需要 Redis 的集成或端到端测试，因为您的 Docker 镜像只涉及 Flask 应用程序。在将应用程序部署到某个环境后，您将能够执行它们。\n当所有测试都通过并且没有任何静态分析工具报告任何问题时，您的 Docker 镜像就差不多完成了。但是，当您从镜像创建新容器时，您仍然需要告诉 Docker 要运行什么命令。\n指定要在 Docker 容器中运行的命令 最后一步是指定要在从 Docker 镜像派生的每个新 Docker 容器中执行的命令。在此阶段，您可以在 Flask 的内置开发服务器上启动您的 Web 应用程序：\n# Dockerfile FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --chown=realpython pyproject.toml constraints.txt ./ RUN python -m pip install --upgrade pip setuptools \u0026amp;\u0026amp; \\ python -m pip install --no-cache-dir -c constraints.txt \u0026#34;.[dev]\u0026#34; COPY --chown=realpython src/ src/ COPY --chown=realpython test/ test/ RUN python -m pip install . -c constraints.txt \u0026amp;\u0026amp; \\ python -m pytest test/unit/ \u0026amp;\u0026amp; \\ python -m flake8 src/ \u0026amp;\u0026amp; \\ python -m isort src/ --check \u0026amp;\u0026amp; \\ python -m black src/ --check --quiet \u0026amp;\u0026amp; \\ python -m pylint src/ --disable=C0114,C0116,R1705 \u0026amp;\u0026amp; \\ python -m bandit -r src/ --quiet CMD [\u0026#34;flask\u0026#34;, \u0026#34;--app\u0026#34;, \u0026#34;page_tracker.app\u0026#34;, \u0026#34;run\u0026#34;, \\ \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;5000\u0026#34;] 在这里，您使用 CMD 指令的三种形式之一，它类似于 Python 的 subprocess.run() 函数的语法。请注意，您必须将主机绑定到 0.0.0.0 地址，以便从 Docker 容器外部访问您的应用程序。\n您现在可以基于现有的 Dockerfile 构建 Docker 镜像，并开始运行从中派生的 Docker 容器。以下命令会将您的 Dockerfile 转换为名为 page-tracker 的 Docker 镜像：\n$ docker build -t page-tracker . 它将在当前工作目录中查找 Dockerfile，用点 ( . ) 表示，并使用默认标签 latest 标记生成的镜像。因此，完整的镜像名称将是 page-tracker:latest 。\n不幸的是，您的镜像目前包含很多杂物，例如您在生产中永远不需要的源代码、测试和 linter。\n它们会增加镜像的大小，使下载和部署速度变慢，如果您没有正确维护它们，它们还会导致安全漏洞。此外，这些额外的组件可能会在排除错误时引起问题。\n幸运的是，有一种更好的方法来组织您的 Dockerfile，允许您分多个阶段构建一个镜像，您现在将探索它。\n为多阶段构建重新组织 Dockerfile 到目前为止，您创建的 Dockerfile 相当简单，应该适合开发。保留它，因为稍后您将需要它来使用 Docker Compose 运行端到端测试。您现在可以复制此文件并为其指定一个不同的名称。例如，您可以将 .dev 后缀附加到两个副本之一：\npage-tracker/ │ ├── src/ │ └── page_tracker/ │ ├── __init__.py │ └── app.py │ ├── test/ │ ├── venv/ │ ├── constraints.txt ├── Dockerfile ├── Dockerfile.dev └── pyproject.toml 现在，编辑名为 Dockerfile 的文件并在将构建过程分解为多个阶段时保持打开状态。\n注意：要在构建镜像时指定自定义文件名而不是默认的 Dockerfile ，请使用 -f 或 --file 选项：\n$ docker build -f Dockerfile.dev -t page-tracker . 这个文件名可以是任何你想要的。只需确保在 docker build 命令中正确引用它即可。\n多阶段构建背后的想法是将 Dockerfile 划分为多个阶段，每个阶段都可以基于完全不同的镜像。当您的应用程序的开发环境和运行时环境不同时，这尤其有用。\n例如，您可以在仅用于构建和测试应用程序的临时镜像中安装必要的构建工具，然后将生成的可执行文件复制到最终镜像中。\n多阶段构建可以使您的镜像更小、更高效。这是使用当前 Dockerfile 构建的同一镜像与您将要编写的镜像的比较：\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE page-tracker prod 9cb2e3233522 5 minutes ago 204MB page-tracker dev f9918cb213dc 5 minutes ago 244MB (...) 在这种情况下，大小差异并不显着，但当您有多个镜像要管理和移动时，它会迅速增加。\nDockerfile 中的每个阶段都以其自己的 FROM 指令开始，因此您将有两个。第一个阶段看起来与您当前的 Dockerfile 几乎完全相同，除了您将为这个阶段命名 builder ，您可以稍后参考：\n# Dockerfile -FROM python:3.11.2-slim-bullseye +FROM python:3.11.2-slim-bullseye AS builder RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --chown=realpython pyproject.toml constraints.txt ./ RUN python -m pip install --upgrade pip setuptools \u0026amp;\u0026amp; \\ python -m pip install --no-cache-dir -c constraints.txt \u0026#34;.[dev]\u0026#34; COPY --chown=realpython src/ src/ COPY --chown=realpython test/ test/ RUN python -m pip install . -c constraints.txt \u0026amp;\u0026amp; \\ python -m pytest test/unit/ \u0026amp;\u0026amp; \\ python -m flake8 src/ \u0026amp;\u0026amp; \\ python -m isort src/ --check \u0026amp;\u0026amp; \\ python -m black src/ --check --quiet \u0026amp;\u0026amp; \\ python -m pylint src/ --disable=C0114,C0116,R1705 \u0026amp;\u0026amp; \\ - python -m bandit -r src/ --quiet + python -m bandit -r src/ --quiet \u0026amp;\u0026amp; \\ + python -m pip wheel --wheel-dir dist/ . -c constraints.txt -CMD [\u0026#34;flask\u0026#34;, \u0026#34;--app\u0026#34;, \u0026#34;page_tracker.app\u0026#34;, \u0026#34;run\u0026#34;, \\ - \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;5000\u0026#34;] 因为您要将打包的页面跟踪器应用程序从一个镜像传输到另一个镜像，所以您必须添加使用 Python wheel 格式构建分发包的额外步骤。 pip wheel 命令将在 dist/ 子文件夹中创建一个名为 page_tracker-1.0.0-py3-none-any.whl 的文件。您还可以从此阶段删除 CMD 指令，因为它将成为下一阶段的一部分。\n第二个也是最后一个阶段，隐式命名为 stage-1 ，看起来有点重复，因为它基于相同的镜像：\n# Dockerfile FROM python:3.11.2-slim-bullseye AS builder # ... FROM python:3.11.2-slim-bullseye RUN apt-get update \u0026amp;\u0026amp; \\ apt-get upgrade --yes RUN useradd --create-home realpython USER realpython WORKDIR /home/realpython ENV VIRTUALENV=/home/realpython/venv RUN python3 -m venv $VIRTUALENV ENV PATH=\u0026#34;$VIRTUALENV/bin:$PATH\u0026#34; COPY --from=builder /home/realpython/dist/page_tracker*.whl /home/realpython RUN python -m pip install --upgrade pip setuptools \u0026amp;\u0026amp; \\ python -m pip install --no-cache-dir page_tracker*.whl CMD [\u0026#34;flask\u0026#34;, \u0026#34;--app\u0026#34;, \u0026#34;page_tracker.app\u0026#34;, \u0026#34;run\u0026#34;, \\ \u0026#34;--host\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, \u0026#34;--port\u0026#34;, \u0026#34;5000\u0026#34;] 您首先按照熟悉的步骤升级系统包、创建用户和创建虚拟环境。然后，突出显示的行负责从 builder 阶段复制 wheel 文件。你像以前一样用 pip 安装它。最后，您添加 CMD 指令以使用 Flask 启动您的 Web 应用程序。\n当您使用这样的多阶段 Dockerfile 构建镜像时，您会注意到第一阶段需要更长的时间才能完成，因为它必须安装所有依赖项、运行测试并创建 wheel 文件。\n但是，构建第二阶段会快很多，因为它只需要复制并安装完成的 wheel 文件。另外请注意， builder 阶段是临时的，因此之后不会在您的 Docker 镜像中留下任何痕迹。\n好的。你终于准备好构建你的多阶段 Docker 镜像了！\n构建和版本控制你的 Docker 镜像 在构建镜像之前，强烈建议您为 Docker 镜像选择一个版本控制方案，并始终使用唯一标签对其进行标记。这样，您就会知道在任何给定环境中部署了什么，并能够在需要时回滚到之前的稳定版本。\n对 Docker 镜像进行版本控制有几种不同的策略。例如，一些流行的包括：\n语义版本控制使用以点分隔的三个数字来指示主要版本、次要版本和补丁版本。 Git 提交哈希使用绑定到镜像中源代码的 Git 提交的 SHA-1 哈希。 时间戳使用时间信息（例如 Unix 时间）来指示镜像的构建时间。 没有什么能阻止您结合其中的一些策略来创建一个有效的版本控制系统，该系统将帮助您跟踪镜像中的更改。\n在本教程中，您将坚持使用 Git 提交哈希方法，因为它可以确保您的 Docker 镜像的标签是唯一且不可变的。花点时间在您的 page-tracker/ 文件夹中初始化一个本地 Git 存储库，并使用与您的工作环境相关的文件模式定义一个 .gitignore 。您可以通过使用 pwd 命令打印您的工作目录来仔细检查您是否在正确的文件夹中：\n$ pwd /home/realpython/page-tracker $ git init Initialized empty Git repository in /home/realpython/page-tracker/.git/ $ curl -sL https://www.gitignore.io/api/python,pycharm+all \u0026gt; .gitignore 在这里，您使用 curl 从 gitignore.io 下载内容，请求 Git 从跟踪中排除 Python 和 PyCharm 相关的文件模式。 -L 标志是跟随重定向所必需的，因为该网站最近移动到具有更长域的不同地址。或者，您可以从 GitHub 的 gitignore 存储库中获取其中一个模板，某些代码编辑器会使用该模板。\n初始化本地 Git 存储库后，您可以进行第一次提交并获取相应的哈希值，例如，使用 git rev-parse 命令：\n$ git add . $ git commit -m \u0026#34;Initial commit\u0026#34; [master (root-commit) dde1dc9] Initial commit 11 files changed, 535 insertions(+) create mode 100644 .gitignore create mode 100644 Dockerfile create mode 100644 Dockerfile.dev create mode 100644 constraints.txt create mode 100644 pyproject.toml create mode 100644 src/page_tracker/__init__.py create mode 100644 src/page_tracker/app.py create mode 100644 test/conftest.py create mode 100644 test/e2e/test_app_redis_http.py create mode 100644 test/integration/test_app_redis.py create mode 100644 test/unit/test_app.py $ git rev-parse HEAD dde1dc9303a2a9f414d470d501572bdac29e4075 如果你不喜欢长输出，那么你可以在命令中添加 --short 标志，这将为你提供相同提交哈希的缩写版本：\n$ git rev-parse --short HEAD dde1dc9 默认情况下，它将返回可以唯一标识该特定提交而不会产生歧义的最短前缀。\n现在您已经有了 Git 提交哈希，您可以将它用作 Docker 镜像的标签。要构建镜像，请在指定 -t 或 --tag 选项的同时运行 docker build 命令，以便为新镜像添加标签。尾随点表示您当前的工作目录是查找 Dockerfile 的位置：\n$ docker build -t page-tracker:$(git rev-parse --short HEAD) . 冒号之前的第一部分 page-tracker 是您的 Docker 镜像的助记名称。请注意，在现实生活中，您可能会附加某种后缀来传达此服务的角色。例如，因为这是一个 Flask 网络应用程序，您可以将镜像命名为 page-tracker-web 或类似的名称。冒号后面的是实际标记，在本例中，它是当前提交的 Git 提交哈希。\n如果您之前构建 Docker 镜像时没有给它明确的标签，或者如果您以其他方式标记它，那么您可能会注意到现在构建它只需要几分之一秒！\n那是因为 Docker 缓存了每个文件系统层，只要项目中的重要文件没有更改，就不需要重建这些层。\n另一点值得注意的是，在表面之下，Docker 仅存储您的镜像的一个副本。它有一个唯一的标识符，例如 9cb2e3233522 ，多个标签可以引用：\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE page-tracker dde1dc9 9cb2e3233522 1 hour ago 204MB page-tracker prod 9cb2e3233522 1 hour ago 204MB page-tracker dev f9918cb213dc 1 hour ago 244MB (...) 这就是标记 Docker 镜像的力量。它允许您使用不同的标签引用同一镜像，例如 page-tracker:prod 或 page-tracker:dde1dc9 ，同时保留唯一标识。每个标签都包含存储库名称（您将在下一节中了解）和一个特定的标签名称。\n您现在可以使用您从 Dockerfile 构建的闪亮的新 Docker 镜像来启动一个成熟的 Docker 容器。具体来说，您可以在笔记本电脑或支持 Docker 的远程基于云的服务器上本地运行容器。\n这可能是您进行端到端测试的唯一方法。\n但是如何将容器放到远程环境中呢？你会在下一节中找到答案。\n将镜像推送到 Docker Registry 当您与他人协作处理一段代码时，您通常会使用 Git 等版本控制来跟踪所有相关人员所做的所有更改。虽然 Git 本身是一个分布式版本控制系统，允许您集成任何两个人之间的贡献，但它缺乏集中托管服务来促进多方之间的同时协作。这就是为什么大多数人选择 GitHub 或竞争对手的原因。\nGitHub 是您通常上传源代码的地方，而 Docker Registry 是存储构建的 Docker 镜像的常用位置。从事商业产品的公司将希望在私有云或本地建立自己的 Docker Registry，以获得额外级别的控制和安全性。许多流行的云提供商以托管服务的形式提供高度安全的 Docker 注册表。\n您也可以使用私有注册表，例如，通过 Docker 运行开源分发容器。\n或者，如果这太麻烦，那么您会很高兴得知 Docker Hub 提供了一个安全的托管注册表，您可以开始免费使用它。虽然免费层为您提供了无限数量的公共存储库，但您将只有一个私有存储库，并且对外界不可见。考虑到您不必支付一分钱，这对于个人或业余爱好项目来说是一笔不错的交易。\n注意：您的 Docker Hub 帐户上的存储库是用户可以上传或下载的 Docker 镜像的集合。每个存储库可以包含同一镜像的多个标记版本。\n在这方面，Docker Hub 存储库类似于 GitHub 存储库，但专门用于 Docker 镜像而不是代码。私有存储库允许您仅允许授权用户访问，而公共存储库可供所有人使用。\n为什么要使用 Docker Registry？\n好吧，您不必这样做，但它有助于在整个组织内共享 Docker 镜像或设置持续集成管道。例如，将提交推送到 GitHub 或其他源代码修订系统可以通过自动构建功能启动构建过程。反过来，注册中心会宣布新的 Docker 镜像已成功构建或使用 webhook 开始部署到远程环境以进行进一步测试。\n如果还没有，请立即在 Docker Hub 上注册一个帐户。请注意，除了电子邮件地址和密码外，您还需要提供唯一的用户名，就像在 GitHub 上一样：\n选择一个好记的用户名至关重要，因为它将成为您在 Docker Hub 上的独特句柄。为了避免不同用户拥有的镜像之间的名称冲突，Docker Hub 通过用户名和存储库名称的组合来识别每个存储库。\n例如，如果您的用户名是 realpython ，那么您的一个存储库可以由字符串 realpython/page-tracker 标识，它类似于 GitHub 上存储库的名称。\n在 Web 浏览器中注册并登录到您的新 Docker Hub 帐户后，您应该做的第一件事是为您的镜像创建一个存储库。单击“创建存储库”磁贴或转到顶部导航栏中的“存储库”选项卡，然后单击“创建存储库”按钮。然后，将您的存储库命名为 page-tracker ，如果需要，请为其提供有意义的描述，然后选择 Private 选项以使其仅对您可见：\n之后，您将看到带有终端命令的说明，这些命令将允许您将 Docker 镜像推送到您的存储库。但首先，您必须从命令行登录 Docker Hub，提供您的用户名和密码：\n$ docker login -u realpython Password: 即使您打算仅使用公共存储库，也需要使用 docker login 进行身份验证。\n注意：如果您在 Docker Hub 帐户的安全设置中启用了双因素身份验证，那么您将需要生成一个具有适当权限的访问令牌，以便在命令行中使用 docker 登录。当它要求您输入密码时，只需提供您的令牌即可。\n否则，如果您没有配置双因素身份验证，那么您将能够使用您的 Docker Hub 密码登录。尽管如此，如文档所述，仍然值得生成一个令牌以获得更好的安全性。\n当你使用 Git 将代码推送到远程存储库时，你必须首先从某个地方克隆它或手动设置默认源，它配置本地存储库的元数据。\n相比之下，使用 Docker Hub 或任何其他 Docker 注册表，将本地镜像映射到远程镜像的过程有点不同——您使用标记。具体来说，您使用 Docker Hub 的用户名和存储库名称作为前缀来标记构建的镜像。\n首先，您必须提供要发布的本地 Docker 镜像的源标签，例如 page-tracker:dde1dc9 。要找到您刚刚构建的 page-tracker 镜像的确切标签，请检查您当前的 Git 提交哈希或列出您现有的 docker images 。\n一旦知道如何标记镜像，就可以使用相同的提交哈希来构建目标标签，该标签将在 Docker 注册表中标识您的存储库。请记住在创建新标签之前将 realpython 替换为您自己的 Docker Hub 用户名：\n$ docker tag page-tracker:dde1dc9 realpython/page-tracker:dde1dc9 这会将新标签 realpython/page-tracker:dde1dc9 添加到标记为 page-tracker:dde1dc9 的本地镜像。目标标签的完整形式如下所示：\nregistry/username/repository:tag 当你想推送到默认的 Docker Hub 时，可以省略注册表部分。否则，它可以是域地址，例如 docker.io ，或带有私有注册表实例的可选端口号的 IP 地址。用户名和存储库必须与您在 Docker Hub 或您使用的任何注册表上创建的用户名和存储库相对应。如果您不提供标签，那么 Docker 将隐式应用标签 latest ，这可能是未定义的。\n您可以使用多个标签来标记同一镜像：\n$ docker tag page-tracker:dde1dc9 realpython/page-tracker:latest 正确标记镜像后，您可以使用 docker push 将它们发送到所需的注册表：\n$ docker push realpython/page-tracker:dde1dc9 $ docker push realpython/page-tracker:latest 不要担心发送相同的镜像两次。 Docker 足够聪明，可以知道您之前何时推送过镜像，如果它在注册表中检测到该镜像，则只会传输必要的元数据。\n当您在 Docker Hub 上刷新您的配置文件时，它应该反映您刚刚推送到存储库中的两个标签：\n现在，当您将协作者添加到您的私有存储库时，他们将能够推送或拉取镜像。请记住，这需要在 Docker Hub 上升级订阅计划。\n另一种方法是生成一个对所有存储库具有只读权限的访问令牌，或者创建一个公共存储库。\n好的。终于到了通过在 Docker 容器中运行您的 dockerized Flask web 应用程序的机会了。\n运行一个 Docker 容器 如果你从一个干净的 Docker 环境开始，也许在另一台计算机上，那么你可以通过从 Docker Hub 拉取它来下载你的镜像，只要你有读取该存储库的权限：\n$ docker pull realpython/page-tracker Using default tag: latest latest: Pulling from realpython/page-tracker f1f26f570256: Pull complete 2d2b01660885: Pull complete e4e8e4c0b0e1: Pull complete 1ba60f086308: Pull complete 3c2fccf90be1: Pull complete 15e9066b1610: Pull complete e8271c9a01cc: Pull complete 4f4fb700ef54: Pull complete bb211d339643: Pull complete 8690f9a37c37: Pull complete 7404f1e120d1: Pull complete Digest: sha256:cc6fe40a1ac73e6378d0660bf386a1599880a30e422dc061680769bc4d501164 Status: Downloaded newer image for realpython/page-tracker:latest docker.io/realpython/page-tracker:latest 由于您没有为镜像指定任何标签，因此 Docker 会拉取标记为 latest 的标签。请注意，输出还包括镜像各个层的标识符，对应于用于构建该镜像的原始 Dockerfile 中的 11 条指令。\n不过，您不必手动拉取镜像，因为 Docker 会在您第一次尝试运行它们时为您完成。如果指定的镜像已经在缓存中，那么一个新的容器将立即启动，而不会等到下载完成。\n下面是基于新镜像运行新 Docker 容器的命令：\n$ docker run -p 80:5000 --name web-service realpython/page-tracker * Serving Flask app \u0026#39;page_tracker.app\u0026#39; * Debug mode: off WARNING: This is a development server. Do not use it in a production ⮑ deployment. Use a production WSGI server instead. * Running on all addresses (0.0.0.0) * Running on http://127.0.0.1:5000 * Running on http://172.17.0.3:5000 Press CTRL+C to quit 当您在本地开发项目时，使用端口转发通过主机的 localhost 访问 Web 服务器通常很方便。在这种情况下， -p 选项可让您导航到地址 http://localhost:80 或只是 http://localhost ，而无需知道正在运行的 Docker 容器的确切 IP 地址。端口 80 是 HTTP 协议的默认端口，这意味着您可以在 Web 浏览器中键入地址时省略它。\n此外，此端口映射将确保在 http://localhost:5000 处没有网络端口冲突，以防您没有停止本地 Flask 实例。请记住，您之前启动了一个来执行端到端测试。如果进程仍在后台某处运行，它将占用 Flask 的默认端口 5000 。\n注意：为您的 Docker 容器提供一个描述性名称也很有用，例如 web-service ，这样您就可以通过名称重新启动或删除它，而无需查找相应的容器标识符。如果你不这样做，那么 Docker 会给你的容器一个愚蠢的名字，比如随机选择的 admiring_jang 或 frosty_almeida 。\n如果您不想手动操作，请考虑添加 --rm 标志以在容器停止时自动删除它。\n正如您在上面的输出中看到的，Flask 服务器正在其容器内的所有网络接口 ( 0.0.0.0 ) 上运行，正如您在 Dockerfile 的 CMD 层中指示的那样。\n继续并在您的 Web 浏览器中访问地址 http://localhost 或使用 curl 之类的命令行工具来访问 dockerized 页面跟踪器：\n$ curl http://localhost Sorry, something went wrong 😔 由于 Redis 连接失败，您将看到预期的错误消息，但至少您可以访问在 Docker 容器中运行的 Flask 应用程序。要修复错误，您需要通过传递给 web-service 容器的环境变量指定正确的 Redis URL。\n现在通过按键盘上的 Ctrl+C 或 Cmd+C 停止该容器。然后，找到容器的标识符并删除关联的容器：\n$ docker ps -a CONTAINER ID IMAGE COMMAND CREATED dd446a1b72a7 realpython/page-tracker \u0026#34;flask --app page_tr…\u0026#34; 1 minute ago $ docker rm dd446a1b72a7 -a 标志确保显示所有容器，包括已停止的容器。否则，你不会看到你的。\n通过 Docker 将 Flask Web 应用程序连接到 Redis 的正确方法是创建专用虚拟网络。首先，列出可用网络以检查您是否已经创建了 page-tracker-network ：\n$ docker network ls NETWORK ID NAME DRIVER SCOPE 46e9ff2ec568 bridge bridge local 4795b850cb58 host host local f8f99d305c5e none null local 84b134794660 page-tracker-network bridge local 如果它不存在，那么您现在可以通过发出以下命令来创建一个：\n$ docker network create page-tracker-network 以类似的方式，您可以为 Redis 服务器创建一个卷，以将其数据持久存储在您的主机上。这样，您可以重新启动甚至删除并从头开始创建一个新容器，Redis 将可以访问其之前的状态。这是使用 Docker 创建命名卷的方法：\n$ docker volume create redis-volume 接下来，停止并移除任何可能挂起的 Redis 容器，然后启动一个新容器。这一次，您将容器连接到 page-tracker-network 并将其 /data 文件夹绑定到您刚刚创建的名为 redis-volume 的卷：\n$ docker run -d \\ -v redis-volume:/data \\ --network page-tracker-network \\ --name redis-service \\ redis:7.0.10-bullseye 当您在 GitHub 上查看 Redis 的官方 Docker 镜像时，您会看到一个在 /data 文件夹中定义挂载点的层。 Redis 会不时地将其状态转储到该文件夹中。通过将目录从您的主机挂载到此挂载点，即使容器重新启动，您也可以保持状态。\n通过给你的容器一个描述性的名称， redis-service ，你将能够从同一网络上的另一个容器连接到它。就是这样：\n$ docker run -d \\ -p 80:5000 \\ -e REDIS_URL=redis://redis-service:6379 \\ --network page-tracker-network \\ --name web-service \\ realpython/page-tracker 您启动一个从 page-tracker 镜像派生的新容器，其中包含相当多的参数。以下是上述 docker run 命令中各个标志和选项的快速细分：\n-d ：在后台运行容器，与终端分离。这意味着您将看不到 Flask 服务器的任何输出，并且您将无法再使用 Ctrl+C 或 Cmd+C 停止容器。 -p 80:5000 ：将容器的端口 5000 暴露在主机的端口 80 上，这样你就可以通过本地主机访问你的 web 应用程序。 -e REDIS_URL=... : 将容器的环境变量设置为在同一网络上的另一个容器中运行的 Redis 服务器的地址。 --network page-tracker-network : 指定容器使用的虚拟网络。这将允许同一网络上的其他容器通过抽象名称而不是 IP 地址与该容器通信。 --name web-service : 为容器分配一个有意义的名称，这样更容易从 Docker 命令中引用容器。 现在，当您在 Web 浏览器或终端中访问 Flask Web 应用程序时，您应该观察到正确的行为：\n$ curl http://localhost This page has been seen 1 times. $ curl http://localhost This page has been seen 2 times. $ curl http://localhost This page has been seen 3 times. 每次发送请求时，服务器都会以不同数量的页面浏览量进行响应。请注意，您正在通过本地主机访问服务器。如果您在 web-service 之前启动了 redis-service ，那么容器的 IP 地址可能已更改。\n哇！光是启动和运行两项服务就需要做大量工作。如您所见，手动管理 Docker 镜像、容器、卷、网络、端口和环境变量会让人感到不知所措。而这只是表面现象！\n想象一下，管理一个包含数十种服务的复杂应用程序需要付出多少努力，其中包括生产就绪监控、负载平衡、自动缩放等。\n幸运的是，有更好的方法可以达到同样的效果。在下一节中，您将研究 Docker 之上的一个方便的抽象层，让您在定义持续集成管道之前使用单个命令编排这两种服务。\n使用 Docker Compose 编排容器 大多数现实世界的应用程序由多个组件组成，这些组件自然会转化为 Docker 容器。例如，一个涉及更多的 Web 应用程序可能具有以下内容：\nBack end: Django, FastAPI, Flask Front end: Angular, React, Vue Cache: Couchbase, Memcached, Redis Queue: ActiveMQ, Kafka, RabbitMQ Database: MySQL, PostgreSQL, SQLite 更大的应用程序可能会选择将其后端或前端组件细分为更多的微服务，负责身份验证、用户管理、订单处理、支付或消息传递等。\n为了帮助管理并在某种程度上编排此类应用程序的多个 Docker 容器，您可以使用 Docker Compose。它是一种在 Docker 之上运行的工具，可简化运行多容器 Docker 应用程序。 Docker Compose 允许您根据相互依赖的服务及其配置和要求来定义您的应用程序。然后它将协调它们并将它们作为一个连贯的应用程序运行。\n注意：容器编排自动化分布式应用程序的部署、扩展和配置管理。虽然 Docker Compose 可以帮助进行基本形式的编排，但您最好在更复杂的大型系统中使用 Kubernetes 等工具。\n您将使用 Docker Compose 以声明方式描述您的多容器页面跟踪器应用程序，以及它的服务、网络和卷，使用单个配置文件。通过这样做，您将能够跟踪更改并将您的应用程序部署到任何环境。\n不过，在深入研究之前，请确保您的计算机上安装了 Docker Compose。\n在您的计算机上设置 Docker Compose 如果您按照有关设置 Docker Desktop 的说明进行操作，那么您应该已经安装了 Docker Compose。在您的终端中运行以下命令以确认这一点：\n$ docker compose version Docker Compose version v2.17.2 使用捆绑了 Docker Compose 和一些其他组件的 Docker Desktop，目前是在 macOS 和 Windows 上获取 Docker Compose 的推荐方式。如果您使用的是 Linux，那么您可以尝试通过手动安装 Compose 插件或从您的发行版的软件包存储库安装替代路径。不幸的是，此方法可能不适用于最新和推荐的 Docker Compose 版本。\n注意：在过去，Docker Compose 是一个独立于 Docker 单独维护的项目。它最初是作为 Python 脚本实现的，最终被重写为 Go。\n要使用 Docker Compose，您必须在命令行中调用 docker-compose （带连字符）可执行文件。但是，它现在已集成到 Docker 平台中，因此您可以将 Docker Compose 作为 docker compose 插件调用。这两个命令的工作原理应该相同，因为该插件是一种直接替代品。\n一旦您确认 Docker Compose 在您的终端中可用，您就可以开始了！\n定义多容器 Docker 应用程序 由于您将定义一个多容器 Docker 应用程序，该应用程序可能会在未来增长以包含更多服务，因此有必要重新安排项目中的文件夹结构。在项目根文件夹中创建一个名为 web/ 的新子文件夹，您将在其中存储与 Flask Web 服务相关的所有文件。\n您的虚拟环境也属于这个新的子文件夹，因为其他服务可能是用完全外国的编程语言（如 C++ 或 Java）实现的。不幸的是，移动 venv/ 文件夹可能会破坏相应激活脚本中硬编码的绝对路径。因此，移除旧的虚拟环境并在 web/ 子文件夹中创建一个新的虚拟环境以确保安全：\nWindows：\n(page-tracker) PS\u0026gt; deactivate PS\u0026gt; cd page-tracker\\ PS\u0026gt; rmdir venv\\ /s PS\u0026gt; python -m venv web\\venv\\ --prompt page-tracker PS\u0026gt; web\\venv\\Scripts\\activate (page-tracker) PS\u0026gt; python -m pip install --upgrade pip Linux + MacOS：\n(page-tracker) $ deactivate $ cd page-tracker/ $ rm -rf venv/ $ python3 -m venv web/venv/ --prompt page-tracker $ source web/venv/bin/activate (page-tracker) $ python -m pip install --upgrade pip 然后，将 Flask 应用程序移动到新的 web/ 子文件夹，只留下 .git/ 文件夹、 .gitignore 和任何其他与编辑器相关的配置文件。您可以将它们保存在项目根文件夹中，因为它们对项目中所有可能的服务都是通用的。之后，您的项目结构应如下所示：\npage-tracker/ │ ├── web/ │ │ │ ├── src/ │ │ └── page_tracker/ │ │ ├── __init__.py │ │ └── app.py │ │ │ ├── test/ │ │ ├── e2e/ │ │ │ └── test_app_redis_http.py │ │ │ │ │ ├── integration/ │ │ │ └── test_app_redis.py │ │ │ │ │ ├── unit/ │ │ │ └── test_app.py │ │ │ │ │ └── conftest.py │ │ │ ├── venv/ │ │ │ ├── constraints.txt │ ├── Dockerfile │ ├── Dockerfile.dev │ └── pyproject.toml │ ├── .git/ │ ├── .gitignore └── docker-compose.yml 上面文件树的一个新添加是位于顶层的 docker-compose.yml 文件，您现在将编写该文件。\nDocker Compose 使用 YAML 格式以声明方式描述应用程序的服务，这些服务将成为 Docker 容器、它们的网络、卷、端口映射、环境变量等。\n以前，您必须手动定义应用程序架构的每一部分，但使用 Docker Compose，您可以在一个文件中定义所有内容。该工具甚至可以为您拉取或构建镜像！\n注意：如果您以前从未使用过 YAML，但熟悉 JSON，那么它的语法应该很熟悉，因为 YAML 是 JSON 的超集。查看 YAML：Python 中丢失的电池了解更多详细信息。\nDocker Compose 文件是您定义服务、网络和卷的地方。这是完整的 docker-compose.yml 文件，它反映了您在前面部分中为页面跟踪器应用程序手动定义的所有内容：\n# docker-compose.yml services: redis-service: image: \u0026#34;redis:7.0.10-bullseye\u0026#34; networks: - backend-network volumes: - \u0026#34;redis-volume:/data\u0026#34; web-service: build: ./web ports: - \u0026#34;80:5000\u0026#34; environment: REDIS_URL: \u0026#34;redis://redis-service:6379\u0026#34; networks: - backend-network depends_on: - redis-service networks: backend-network: volumes: redis-volume: 你现在要逐行剖析它：\n第 3 行标志着两个服务 redis-service 和 web-service 声明的开始，它们包含一个多容器 Docker 应用程序。请注意，您可以扩展每个服务，因此 Docker 容器的实际数量可能大于此处声明的服务数量。 第 4 行到第 9 行定义了 redis-service 的配置，包括要运行的 Docker 镜像、要连接的网络以及要挂载的卷。 第 10 到 19 行通过指定包含要构建的 Dockerfile 的文件夹、要公开的端口、要设置的环境变量以及要连接的网络来配置 web-service 。 depends_on 语句要求 redis-service 在 web-service 开始之前可用。 第 21 和 22 行为您的两个服务定义了一个虚拟网络。此声明并非绝对必要，因为 Docker Compose 会自动创建容器并将其连接到新网络。但是，如果需要，显式网络声明可以让您更好地控制其设置和地址范围。 第 24 和 25 行为您的 Redis 服务器定义了一个持久卷。 上面配置文件中的一些值被引用，而另一些则没有。这是针对旧 YAML 格式规范中已知怪癖的预防措施，该规范将某些字符视为特殊字符，如果它们出现在未加引号的字符串中。例如，冒号 ( : ) 可以使一些 YAML 解析器将文字解释为六十进制数字而不是字符串。\n注意：此文件符合最新和推荐的 Compose 规范，该规范不再需要顶级 version 字段，而早期的模式版本需要。阅读官方文档中的 Compose 文件版本控制以了解更多信息。\n停止任何可能仍在运行的与您的项目相关的 Docker 容器，并立即删除它们的关联资源：\n$ docker stop -t 0 web-service redis-service $ docker container rm web-service redis-service $ docker network rm page-tracker-network $ docker volume rm redis-volume 这将删除您之前创建的两个容器、一个网络和一个卷。请注意，您可以将 docker container rm 命令缩写为更短的 docker rm 别名。\n要优雅地删除容器，您应该首先停止它。默认情况下， docker stop 命令将在终止容器之前等待十秒钟，使其有足够的时间在退出之前执行任何必要的清理操作。因为您的 Flask 应用程序在停止运行后不需要做任何事情，您可以使用 -t 选项将此超时设置为零秒，这将立即终止列出的容器。\n要删除所有关联的 Docker 镜像标签，您必须首先找到它们的公共标识符：\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE page-tracker dde1dc9 9cb2e3233522 1 hour ago 204MB page-tracker latest 9cb2e3233522 1 hour ago 204MB realpython/page-tracker dde1dc9 9cb2e3233522 1 hour ago 204MB realpython/page-tracker latest 9cb2e3233522 1 hour ago 204MB (...) 在这种情况下， page-tracker 镜像的所有标签共有的短 ID 等于 9cb2e3233522 ，您可以使用它来取消标记和删除底层 Docker 镜像：\n$ docker rmi -f 9cb2e3233522 Untagged: page-tracker:dde1dc9 Untagged: page-tracker:latest Untagged: realpython/page-tracker:dde1dc9 Untagged: realpython/page-tracker:latest Deleted: sha256:9cb2e3233522e020c366880867980232d747c4c99a1f60a61b9bece40... docker rmi 命令是 docker image rm 和 docker image remove 的别名。\n注意：如果你想从头开始使用全新的 Docker 环境，并且不介意丢失数据，那么你可以使用以下命令修剪所有系统资源：\n$ docker system prune --all --volumes 警告！这将删除您到目前为止使用 Docker 创建的所有内容，包括可能在本教程之外创建的资源，因此请谨慎操作。\n确认删除 Docker 资源后，您可以通过一条指令立即恢复您的页面跟踪器应用程序。在与 docker-comopse.yml 文件相同的文件夹中发出以下命令以避免指定其路径：\n$ docker compose up -d (...) [+] Running 4/4 ⠿ Network page-tracker_backend-network Created 0.1s ⠿ Volume \u0026#34;page-tracker_redis-volume\u0026#34; Created 0.0s ⠿ Container page-tracker-redis-service-1 Started 1.0s ⠿ Container page-tracker-web-service-1 Started 1.3s 第一次运行此命令时，可能需要更长的时间，因为 Docker Compose 必须从 Docker Hub 下载 Redis 镜像并再次从 Dockerfile 构建另一个镜像。但在那之后，它应该感觉几乎是瞬间的。\n您可以在上面的输出中看到 Docker Compose 创建了请求的网络、卷和两个容器。请注意，它始终在此类资源名称前加上您的 Docker Compose 项目名称前缀，该名称默认为包含您的 docker-compose.yml 文件的文件夹名称。在这种情况下，项目名称是 page-tracker 。此功能有助于防止不同 Docker Compose 项目的资源名称发生冲突。\n此外，如果您想启动同一服务的多个副本，Docker Compose 会将连续的数字附加到您的容器名称中。\nDocker Compose 插件提供了几个有用的命令来管理您的多容器应用程序。这里只是其中的几个：\n$ docker compose ps NAME COMMAND SERVICE ... page-tracker-redis-service-1 \u0026#34;docker-entrypoint.s…\u0026#34; redis-service ... page-tracker-web-service-1 \u0026#34;flask --app page_tr…\u0026#34; web-service ... $ docker compose logs --follow (...) page-tracker-web-service-1 | * Running on all addresses (0.0.0.0) page-tracker-web-service-1 | * Running on http://127.0.0.1:5000 page-tracker-web-service-1 | * Running on http://172.20.0.3:5000 page-tracker-web-service-1 | Press CTRL+C to quit $ docker compose stop [+] Running 2/2 ⠿ Container page-tracker-web-service-1 Stopped 10.3s ⠿ Container page-tracker-redis-service-1 Stopped 0.4s $ docker compose restart [+] Running 2/2 ⠿ Container page-tracker-redis-service-1 Started 0.4s ⠿ Container page-tracker-web-service-1 Started 0.5s $ docker compose down --volumes [+] Running 4/4 ⠿ Container page-tracker-web-service-1 Removed 6.0s ⠿ Container page-tracker-redis-service-1 Removed 0.4s ⠿ Volume page-tracker_redis-volume Removed 0.0s ⠿ Network page-tracker_backend-network Removed 0.1s 例如，您可以列出 Docker Compose 项目中的容器而不显示任何其他容器。使用相关命令，您可以查看它们的实时输出、停止、启动和重新启动它们。\n完成项目后，您可以将其拆除，Docker Compose 将删除关联的容器和网络。但是，它不会触及持久数据存储，除非您使用 --volumes 标志明确请求。\n您可能已经在日志中注意到一件事，Flask 已经抱怨了很长时间，那就是使用其不安全、低效且不稳定的开发 Web 服务器来运行您的应用程序。您现在将使用 Docker Compose 来解决这个问题。\n将 Flask 的开发 Web 服务器替换为 Gunicorn Docker 允许您在运行新容器时覆盖 Dockerfile 中列出的默认命令或入口点。例如， redis 镜像中的默认命令启动 Redis 服务器。但是，您之前使用相同的镜像在另一个容器中启动 redis-cli 。同样，您可以在 docker-compose.yml 文件中为您的 Docker 镜像指定自定义命令。您将使用此功能通过生产级 Web 服务器运行 Flask。\n注意：有时，您想要调查现有容器。要在正在运行的容器中运行命令而不是启动新容器，可以使用 docker exec 命令：\n$ docker exec -it -u root page-tracker-web-service-1 /bin/bash root@6e23f154a5b9:/home/realpython# 通过运行 Bash 可执行文件 /bin/bash 并使用 -u 选项指定用户，您可以有效地访问容器，就像通过 SSH 登录远程服务器一样。 -it 标志是运行交互式终端会话所必需的。否则，该命令将立即退出。\n有几个选项可以替换 Flask 的内置开发 Web 服务器，官方文档在部署到生产时推荐使用这些选项。最受欢迎的选择之一是 Gunicorn (Green Unicorn)，它是 Web 服务器网关接口 (WSGI) 协议的纯 Python 实现。要开始使用它，您必须将 gunicorn 包添加为项目中的另一个依赖项：\n# web/pyproject.toml [build-system] requires = [\u0026#34;setuptools\u0026gt;=67.0.0\u0026#34;, \u0026#34;wheel\u0026#34;] build-backend = \u0026#34;setuptools.build_meta\u0026#34; [project] name = \u0026#34;page-tracker\u0026#34; version = \u0026#34;1.0.0\u0026#34; dependencies = [ \u0026#34;Flask\u0026#34;, \u0026#34;gunicorn\u0026#34;, \u0026#34;redis\u0026#34;, ] [project.optional-dependencies] dev = [ \u0026#34;bandit\u0026#34;, \u0026#34;black\u0026#34;, \u0026#34;flake8\u0026#34;, \u0026#34;isort\u0026#34;, \u0026#34;pylint\u0026#34;, \u0026#34;pytest\u0026#34;, \u0026#34;pytest-timeout\u0026#34;, \u0026#34;requests\u0026#34;, ] 请注意，您将 gunicorn 添加到常规依赖项列表中，因为它将成为您应用程序不可或缺的一部分。您希望在构建最终 Docker 镜像后它可用。\n像往常一样，在本地重新安装您的 page-tracker 包并将其依赖项固定在约束文件中。请记住，您可能需要先激活您的虚拟环境，因为您之前在 web/ 子文件夹中重新创建了它：\n(page-tracker) $ python -m pip install --editable \u0026#34;web/[dev]\u0026#34; (page-tracker) $ python -m pip freeze --exclude-editable \u0026gt; web/constraints.txt 请注意，当您从项目的根文件夹中执行这些命令时，它们看起来会略有不同。在这种情况下，您必须将指示当前工作目录的点 ( . ) 替换为您的 web/ 子文件夹的路径。\n现在您已经安装了 Gunicorn，您可以开始使用它了。通过在 web-service 键下添加新的 command 属性来修改 docker-compose.yml ：\n# docker-compose.yml services: redis-service: image: \u0026#34;redis:7.0.10-bullseye\u0026#34; networks: - backend-network volumes: - \u0026#34;redis-volume:/data\u0026#34; web-service: build: ./web ports: - \u0026#34;80:8000\u0026#34; environment: REDIS_URL: \u0026#34;redis://redis-service:6379\u0026#34; networks: - backend-network depends_on: - redis-service command: \u0026#34;gunicorn page_tracker.app:app --bind 0.0.0.0:8000\u0026#34; networks: backend-network: volumes: redis-volume: 此命令将优先于 Dockerfile 的默认命令，后者依赖于 Flask 的开发服务器。从现在开始，Docker Compose 将改为使用 Gunicorn 运行您的 Web 应用程序。为了显示差异，您将在端口 8000 而不是 5000 上运行服务器，因此您还更改了端口映射。\n通过在主机上公开端口 80 ，您仍然可以在不指定端口号的情况下访问 http://localhost 上的应用程序。\n不要忘记提交更改以将您的工作保存在本地 Git 存储库中：\n$ git add . $ git commit -m \u0026#34;Refactor folders and add Docker Compose\u0026#34; 进行小而频繁的提交总是一个好主意，这样您就可以随着时间的推移跟踪增量更改并更好地了解您的工作历史。如果您不确定如何描述您的提交，请尝试解释为什么您进行了特定更改，因为 Git 已经跟踪更改的内容。\n好的。如果您现在尝试重新启动 Docker Compose 应用程序，那么它将失败，因为 Docker 在容器启动期间找不到请求的 gunicorn 可执行文件。您已经添加了您之前构建的 Docker 镜像中缺少的额外依赖项。因此，你必须告诉 Docker Compose 重建你的镜像。您可以使用以下任一命令执行此操作：\ndocker compose build docker compose up \u0026ndash;build 在第一种情况下，您会明确告诉 Docker 预先构建镜像。每当您更改项目依赖项或 Dockerfile 时，您都必须再次运行 docker compose build 以应用这些更改。\n在第二种情况下， docker compose up --build 将指示 Docker 在每次启动容器时即时构建镜像。如果您试图快速迭代对源代码或 Dockerfile 的更改，这将特别有用。\n无论哪种方式，这两个命令都应该在启动相应容器之前在任何受影响的 Docker 镜像中成功构建修改后的层。然后，您可以放心，当您的 Docker Compose 应用程序再次启动时，所有依赖项都将可用。\n继续并立即运行这些命令之一。\n因为您了解如何使用 Docker Compose 来管理应用程序的服务，所以您现在可以了解如何在接近生产的环境中运行端到端测试。\n针对服务运行端到端测试 在第一次尝试中，您将从主机本地执行端到端测试。请注意，必须可以从您的本地网络访问所有必要的服务才能使其正常工作。\n虽然这并不理想，因为您不想向公众公开任何敏感服务（如数据库），但稍后您将了解更好的方法。同时，您可以更新您的 docker-compose.yml 配置以转发 Redis 端口：\n# docker-compose.yml services: redis-service: image: \u0026#34;redis:7.0.10-bullseye\u0026#34; ports: - \u0026#34;6379:6379\u0026#34; networks: - backend-network volumes: - \u0026#34;redis-volume:/data\u0026#34; web-service: build: ./web ports: - \u0026#34;80:8000\u0026#34; environment: REDIS_URL: \u0026#34;redis://redis-service:6379\u0026#34; networks: - backend-network depends_on: - redis-service command: \u0026#34;gunicorn page_tracker.app:app --bind 0.0.0.0:8000\u0026#34; networks: backend-network: volumes: redis-volume: 如果您有一个用于 redis-service 的现有 Docker 容器，那么您需要先删除该容器，即使它当前已停止，以反映新的端口转发规则。幸运的是，Docker Compose 会自动检测 docker-compose.yml 文件中的更改，并在您发出 docker compose up 命令时根据需要重新创建容器：\n$ docker compose up -d [+] Running 2/2 ⠿ Container page-tracker-redis-service-1 Started 1.0s ⠿ Container page-tracker-web-service-1 Started 1.2s $ docker compose ps NAME ... PORTS page-tracker-redis-service-1 ... 0.0.0.0:6379-\u0026gt;6379/tcp page-tracker-web-service-1 ... 0.0.0.0:80-\u0026gt;8000/tcp 列出新容器后，您应该会看到 Redis 容器上的端口 6379 被转发到主机。有了这个，您现在可以使用安装在开发机器上的虚拟环境中的 pytest 运行端到端测试：\n(page-tracker) $ python -m pytest web/test/e2e/ \\ --flask-url http://localhost \\ --redis-url redis://localhost:6379 由于端口映射，您可以使用 localhost 连接到容器，而无需知道它们各自的 IP 地址。\n注意：如果您的测试成功，那么它将覆盖 Redis 中的页面浏览量。根据经验，您永远不应该在带有客户数据的实时环境中运行测试，以避免破坏它。通常建议使用带有虚假或匿名数据的暂存或认证环境来安全地执行全面的端到端测试。\n要模拟故障，您可以在测试执行期间暂时暂停容器：\n$ docker compose pause [+] Running 2/0 ⠿ Container page-tracker-web-service-1 Paused 0.0s ⠿ Container page-tracker-redis-service-1 Paused 0.0s 这将使 Redis 和您的 Flask 应用程序无法再访问。与停止容器不同，暂停它不会终止底层进程，因此暂停会保持容器的状态并导致更快的恢复。\n之后不要忘记取消暂停容器以避免以后出现错误：\n$ docker compose unpause [+] Running 2/0 ⠿ Container page-tracker-web-service-1 Unpaused 0.0s ⠿ Container page-tracker-redis-service-1 Unpaused 0.0s 或者，您可以从同一网络上的另一个容器运行它，而不是在本地针对公开服务运行端到端测试。您可以手动制作这样的容器。\n然而，最近版本的 Docker Compose 提供了一个更优雅的解决方案，它允许您有条件地运行服务的子集。为此，您可以将所需的服务分配给可按需激活的自定义配置文件。\n首先，打开你的 docker-compose.yml 文件并从 Redis 中删除端口转发，因为你不想再将它暴露给外界。然后，基于您的旧 Dockerfile.dev 添加一个新服务，它捆绑了测试框架、测试装置和您的测试代码。您将使用相应的 Docker 镜像来执行端到端测试：\n# docker-compose.yml services: redis-service: image: \u0026#34;redis:7.0.10-bullseye\u0026#34; networks: - backend-network volumes: - \u0026#34;redis-volume:/data\u0026#34; web-service: build: ./web ports: - \u0026#34;80:8000\u0026#34; environment: REDIS_URL: \u0026#34;redis://redis-service:6379\u0026#34; networks: - backend-network depends_on: - redis-service command: \u0026#34;gunicorn page_tracker.app:app --bind 0.0.0.0:8000\u0026#34; test-service: profiles: - testing build: context: ./web dockerfile: Dockerfile.dev environment: REDIS_URL: \u0026#34;redis://redis-service:6379\u0026#34; FLASK_URL: \u0026#34;http://web-service:8000\u0026#34; networks: - backend-network depends_on: - redis-service - web-service command: \u0026gt; sh -c \u0026#39;python -m pytest test/e2e/ -vv --redis-url $$REDIS_URL --flask-url $$FLASK_URL\u0026#39; networks: backend-network: volumes: redis-volume: docker-compose.yml 文件的大部分内容保持不变，因此您可以将注意力集中在突出显示的行上：\n第 22 行定义了您的新服务将属于的配置文件列表。只有一个配置文件，称为 testing ，您将启用它来运行测试。\n第 24 到 26 行指定包含要构建的 Dockerfile 的目录的路径。由于该文件有一个非标准名称，您需要明确提供它。\n第 27 到 29 行定义了两个环境变量，您的测试将使用它们连接到在 Gunicorn 服务器后面运行的 Redis 和 Flask。请注意，您使用 Docker Compose 服务名称作为主机名。\n第 30 和 31 行将服务连接到与其他两个服务相同的网络。\n第 32 到 34 行确保 Redis 和 Flask 在端到端测试之前启动。\n第 35 到 38 行定义了在服务启动时运行的命令。请注意，您使用 YAML 的多行文字折叠 ( \u0026gt; ) 以更具可读性的方式格式化长 shell 命令。\n因为 Docker Compose 可以访问您主机的 shell，所以它会尝试插入对环境变量的任何引用，例如 $REDIS_URL 或 $FLASK_URL ，一旦文件被解析，就会出现在您的 docker-compose.yml 中。不幸的是，这些变量很可能尚未定义。您通过服务的 environment 部分指定它们，这意味着您的容器稍后将获取这些变量。\n要禁用 Docker Compose 过早替换环境变量，您可以使用两个美元符号 ( $$ ) 转义美元符号。这反过来会在将在生成的容器中执行的命令中生成文字字符串 $REDIS_URL 和 $FLASK_URL 。要在容器启动时插入这些变量，您必须将整个命令用单引号 ( ' ) 括起来，并将其传递给 shell ( sh )。\n当您使用 Docker Compose 启动多容器应用程序时，只有不属于任何配置文件的核心服务会启动。如果您还希望启动分配给一个或多个配置文件的服务，则必须使用 --profile 选项列出这些配置文件：\n$ docker compose --profile testing up -d [+] Running 3/3 ⠿ Container page-tracker-redis-service-1 Running 0.0s ⠿ Container page-tracker-web-service-1 Running 0.0s ⠿ Container page-tracker-test-service-1 Started 0.6s $ docker compose ps -a NAME ... SERVICE STATUS ... page-tracker-redis-service-1 ... redis-service running ... page-tracker-test-service-1 ... test-service exited (0) ... page-tracker-web-service-1 ... web-service running ... 请注意，这是 docker compose 命令的一个选项，而不是它的 up 子命令，因此请注意参数顺序。输出显示启动了一个额外的服务，但是当您调查它时，您会注意到 test-service 以成功状态零快速退出。\n要显示有关此服务的更多信息，您可以查看其日志：\n$ docker compose logs test-service ============================= test session starts ========================== platform linux -- Python 3.11.2, pytest-7.2.2, pluggy-1.0.0 -- /home/realp.. cachedir: .pytest_cache rootdir: /home/realpython plugins: timeout-2.1.0 collecting ... collected 1 item test/e2e/test_app_redis_http.py::test_should_update_redis ... PASSED [100%] ============================== 1 passed in 0.10s =========================== 这将向您显示有关该服务的详细信息，包括 pytest 报告形式的测试结果，以及可能发生的任何错误。在这种情况下，测试成功通过。请注意，为简洁起见，对上面的输出进行了编辑。\n到目前为止，您已经使用 Git 对源代码进行了版本控制。您自动化了各种级别的测试并使用 Docker 构建了您的应用程序。最后，您使用 Docker Compose 编排了多个容器。\n此时，您已准备好继续下一步，即使用 Docker 构建持续集成管道。\n定义一个基于 Docker 的持续集成管道 持续集成 (CI) 的目标是通过尽可能频繁地集成团队中多个开发人员的代码更改来实现更快、更可预测的软件发布。\n在过去，集成是一项重大任务，通常需要数周甚至数月才能完成，有时还需要专门的集成工程师团队。\n这种方法的问题是团队中的每个人都在自己的项目副本上工作。集成阶段延迟的时间越长，项目的不同版本就越有可能出现分歧，从而难以将它们结合起来。\n在某些情况下，集成可能比项目的实际开发花费更多的时间！\n连续这个词意味着集成应该经常进行，以最小化更改的范围并降低将缺陷引入代码库的风险。团队每天至少整合一次开发人员的工作，最好是一天多次，这已成为标准做法。\n为了使这成为可能，持续集成需要构建和测试自动化以及具有相对较小功能的短期代码分支来实现。功能切换可以帮助实现需要更长时间开发的更大功能。此外，在尝试集成更改失败后修复失败的构建应该是团队的优先事项，以保持流程真正连续。\n要在您的项目中引入持续集成，您需要以下元素：\n版本控制系统 分支策略 自动构建 自动化测试 持续集成服务器 频繁集成 像 Git 这样的版本控制系统允许多人同时处理同一段代码。根据您的团队结构、经验和其他因素，您可以选择不同的源代码控制分支模型，也称为工作流。一些最受欢迎的包括：\nTrunk-Based Development GitHub Flow Forking Workflow Release Branching Git Flow 各有利弊，适用于不同的场景。例如，分叉策略在开源项目中运作良好，因为它允许任何人在没有特别许可的情况下做出贡献。在本教程中，您将使用称为 GitHub Flow 的流行功能分支工作流程。它只有一个长期存在的主线或主干，传统上称为 master 分支，您可以从中分支出几个短期存在的功能分支。\n注意：尽管使用术语 master 来指代主分支的传统由来已久，但 GitHub 最近宣布将其默认分支名称更改为 main 以更好地反映其目的并避免冒犯性语言。\n同时，当您初始化一个新的存储库时，Git 会继续使用 master ，这在您尝试同步本地和远程存储库时偶尔会出现问题。因此，您将坚持在本教程中使用 master 来保持简单，但如果您想更改默认分支名称，请随时采取额外的步骤。您可以在 GitHub 存储库设置中调整默认分支名称。\n虽然您会发现几种不同的方法来实现与 GitHub Flow 的持续集成，但这些是您将针对 Docker 应用程序遵循的步骤：\n将最新版本的主线获取到您的计算机。 从主线创建一个功能分支。 打开拉取请求以从其他人那里获得早期反馈。 继续在你的功能分支上工作。 经常获取主线，将其合并到您的功能分支并在本地解决任何潜在的冲突。 在本地分支上构建、lint 和测试代码。 只要本地构建和测试成功，就推送您的更改。 每次推送时，检查针对您的功能分支在 CI 服务器上运行的自动化测试。 在再次推送代码之前，在本地重现并修复任何已识别的问题。 完成并通过所有测试后，请求一名或多名同事审查您的更改。 应用他们的反馈，直到审阅者批准您的更新并且所有测试在推送您的最新更改后通过 CI 服务器。 通过将功能分支合并到主线来关闭拉取请求。 对照主线检查 CI 服务器上运行的自动化测试，并集成功能分支的更改。 调查并修复可能发现的任何问题，例如，由于在您上次推送和合并之间其他人向主线引入了新更新。 此列表非常全面，但没有适合所有人的单一持续集成流程。您甚至可以比这更彻底，例如，使用 Terraform 或 GitHub Codespaces 提供专用的暂存环境，并将您的功能分支部署到云中，以便在关闭拉取请求之前进行额外的手动测试。但是，为每个拉取请求启动一个新环境可能不符合成本效益。\n注意：软件工程团队通常将持续集成与持续交付结合起来，形成一个称为 CI/CD 的流程。持续交付是持续集成的扩展，它增加了额外的步骤来将经过验证和集成的构建部署到生产环境。\n虽然持续交付提供了将构建自动部署到生产环境的技术手段，但它仍然需要业务决策和手动触发。\n不要混淆持续交付和持续部署，后者是一个完全自动化的过程，无需人工干预即可将应用程序部署到生产环境。在持续部署中，一旦你推送代码，它就会被测试并集成到主线中，然后最终进入生产环境。\n但是，要成功做到这一点，您需要广泛的测试范围和对自动化过程的信任。\n值得强调的重要一点是涉及的测试量。您应该在本地和持续集成服务器上测试您的功能分支，然后针对集成主线再次运行测试。\n这是为了确保您的功能正常工作并且不会破坏主线。\n您有许多选项可以为您的 Docker 应用程序设置持续集成服务器，包括在线和自托管。流行的选择包括 CircleCI、Jenkins 和 Travis。在本教程中，您将使用 GitHub Actions，这是 GitHub 提供的免费 CI 解决方案。\n将代码推送到 GitHub 存储库 要利用 GitHub Actions，您必须首先在 GitHub 上创建一个存储库。如果您还没有帐户，请注册，然后登录并创建一个名为 page-tracker 的新存储库。\n公共存储库可以无限制地使用 GitHub Actions，而私有存储库每月可在免费层获得 2000 分钟和 500 兆字节的存储空间。\n但是，在 Windows 上运行的作业将消耗比在 Linux 上多一倍的分钟数，而在 macOS 上运行的作业将消耗十倍的分钟数！您可以在官方文档中找到有关 GitHub Actions 计费的更多详细信息。\n稍后，您将启用分支保护规则，该规则目前仅适用于免费层的公共存储库，因此最好现在就创建一个公共存储库。\n保留建议的默认值而不使用 GitHub 的占位符文件初始化新存储库，因为您将推送现有项目。接下来，转到终端并将工作目录更改为您的 page-tracker 项目所在的位置。它应该已经初始化了一个本地 Git 存储库，稍后您将连接到 GitHub。但首先，将所有未决更改提交到本地存储库：\n$ git status On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: docker-compose.yml no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) $ git commit -am \u0026#34;Add a test-service to Docker Compose\u0026#34; 在提交任何更改之前检查存储库的状态始终是个好主意。您现在可以使用以下两个命令将本地存储库连接到 GitHub：\n$ git remote add origin git@github.com:realpython/page-tracker.git $ git push -u origin master 确保将 realpython 替换为您的 GitHub 用户名。第一个命令会将您刚刚创建的 GitHub 上的远程存储库添加到您在 origin 别名下的本地副本。第二个命令会将本地存储库的内容推送到 GitHub。\n之后您可以使用您的 GitHub 存储库刷新网页以确认您的文件已成功发送。当您这样做时，您将准备好使用 GitHub Actions 为您的 Docker 应用程序构建持续集成工作流程！\n学习 GitHub Actions 首先，熟悉一些新术语会有所帮助。 GitHub Actions 允许您指定一个或多个由特定事件触发的工作流程，例如将代码推送到分支或打开新的拉取请求。每个工作流都可以定义许多由步骤组成的作业，这些作业将在运行器上执行。有两种类型的跑步者：\nGitHub 托管的运行器：Ubuntu Linux、Windows、macOS 自托管运行器：您拥有和维护的本地服务器 在本教程中，您将只使用 GitHub 提供的最新 Ubuntu Linux 运行器。请注意，可以在多个运行器上执行相同的作业，例如检查跨平台兼容性。\n除非您另有说明，否则一个工作流程中的作业将在不同的运行器上并行运行，这对于加快构建速度很有用。同时，您可以使一项工作依赖于其他工作。\n使用 GitHub Actions 减少构建时间的另一种方法是启用工作流依赖缓存。\n作业的每个步骤都由一个动作实现，该动作可以是：\n自定义 shell 命令或脚本 在另一个 GitHub 存储库中定义的 GitHub 操作 有许多预定义的 GitHub 操作，您可以在 GitHub Marketplace 上浏览和查找。社区提供并维护它们。例如，有一个用于在 GitHub 上构建和推送 Docker 组织拥有的 Docker 镜像。由于有许多相互竞争的插件，有时有不止一种方法可以使用 GitHub Actions 达到预期的结果。\n与如今与 DevOps 相关的许多工具一样，GitHub 使用 YAML 格式来配置工作流。它会在您的存储库的根文件夹中寻找一个特殊的 .github/workflows/ 文件夹，您可以在其中放置多个 YAML 文件，每个文件对应一个不同的工作流程。此外，您可以在其中包含其他文件，例如要在运行器上执行的配置文件或自定义脚本。\n您只会为持续集成定义一个工作流程，因此请继续创建必要的文件夹结构，其中包含一个名为 ci.yml 的文件：\npage-tracker/ │ ├── web/ │ ├── .git/ │ ├── .github/ │ └── workflows/ │ └── ci.yml │ ├── .gitignore └── docker-compose.yml 尽管您可以使用任何您喜欢的代码编辑器为 GitHub Actions 编写工作流文件，但在这种情况下请考虑使用 GitHub 的基于 Web 的编辑器。它不仅提供通用的 YAML 语法突出显示，还提供架构验证和对可用 GitHub Actions 属性的智能建议。因此，您可以先将代码推送到 GitHub，然后使用内置编辑器直接在那里编辑您的 ci.yml 文件。\n要打开 GitHub 内置的编辑器，请将 Web 浏览器导航到 ci.yml 文件，然后按 E 或单击铅笔图标。您现在可以开始编写 GitHub Actions 工作流文件。\n使用 GitHub Actions 创建工作流 在编辑 ci.yml 文件时，为新工作流指定一个描述性名称并定义应触发它的事件：\n# .github/workflows/ci.yml name: Continuous Integration on: pull_request: branches: - master push: branches: - master 将触发此工作流的两个事件是：\n打开或更改针对 master 分支的拉取请求 推送代码或将分支合并到 master 分支 除了分支名称之外，您还可以为每个事件添加更多属性以缩小触发条件。例如，您可以提供充当正过滤器的文件路径模式，该模式仅在某些文件发生更改时才运行工作流。\n毕竟，您可能不想在编辑 README 文件或更新文档后运行整个持续集成工作流程。不管怎样，你现在会让事情保持简单。\n您的持续集成工作流程的工作是构建 Docker 镜像，使用 Docker Compose 运行端到端测试，如果一切顺利，将构建的镜像推送到 Docker Hub。\n感谢您全面的 Dockerfile，将单元测试、各种静态代码分析工具和安全扫描集成到一个命令中。因此，您无需为 CI 工作流程编写大量 YAML。\nGitHub Action 工作流中的几乎每项工作都是从从 GitHub 存储库中检出代码开始的：\n# .github/workflows/ci.yml name: Continuous Integration on: pull_request: branches: - master push: branches: - master jobs: build: name: Build Docker image and run end-to-end tests runs-on: ubuntu-latest steps: - name: Checkout code from GitHub uses: actions/checkout@v3 您指定一个标识为 build 的作业，它将在 GitHub 提供的最新 Ubuntu 运行器上运行。它的第一步是使用 actions/checkout GitHub 操作检查触发工作流的单个提交。因为 GitHub Actions 实际上是伪装的 GitHub 存储库，所以您可以在 at 符号 ( @ ) 后提供 Git 标记或提交哈希以选择特定版本的操作。\n作为持续集成管道的下一步，您希望在通过 Docker Compose 执行端到端测试之前为您的 Web 和测试服务构建 Docker 镜像。这次您将在运行器上运行一个 shell 命令，而不是使用现有的操作：\n# .github/workflows/ci.yml name: Continuous Integration on: pull_request: branches: - master push: branches: - master jobs: build: name: Build Docker image and run end-to-end tests runs-on: ubuntu-latest steps: - name: Checkout code from GitHub uses: actions/checkout@v3 - name: Run end-to-end tests run: \u0026gt; docker compose --profile testing up --build --exit-code-from test-service 这两个步骤将始终运行以响应文件顶部列出的事件，即打开拉取请求或将功能分支合并到主线中。\n此外，在成功将分支合并到主线后，当所有测试都通过时，您需要将新的 Docker 镜像推送到 Docker Hub。因此，只有当 push 事件触发您的工作流程时，您才会有条件地运行后续步骤。\n但是，如何使用 GitHub Actions 安全访问 Docker Hub 而不会泄露您的秘密？你现在就会知道了。\n通过 GitHub Actions Secrets 访问 Docker Hub 早些时候，当您将其中一个 Docker 镜像从终端推送到 Docker Registry 时，您必须通过调用 docker login 并提供您的用户名和密码来登录 Docker Hub。此外，如果启用双因素身份验证，则必须生成具有足够权限的个人访问令牌并提供它而不是密码。\n从自动化工作流程推送镜像的步骤相似，因此您必须先进行身份验证。您可以使用 shell 命令或预定义的 GitHub 操作来执行此操作，例如 docker/login-action ：\n# .github/workflows/ci.yml name: Continuous Integration on: pull_request: branches: - master push: branches: - master jobs: build: name: Build Docker image and run end-to-end tests runs-on: ubuntu-latest steps: - name: Checkout code from GitHub uses: actions/checkout@v3 - name: Run end-to-end tests run: \u0026gt; docker compose --profile testing up --build --exit-code-from test-service - name: Login to Docker Hub uses: docker/login-action@v2 if: ${{ github.event_name == \u0026#39;push\u0026#39; }} with: username: ${{ secrets.DOCKERHUB_USERNAME }} password: ${{ secrets.DOCKERHUB_TOKEN }} 您有条件地运行此步骤，方法是使用包含在美元符号和双大括号中的 JavaScript 表达式从 github 上下文获取事件类型。然后，您通过另一个预定义的 secrets 上下文和您现在将要定义的两个自定义常量提供您的秘密 Docker Hub 凭据。\n通过单击顶部工具栏中带有齿轮图标的选项卡打开 GitHub 存储库的设置，找到并展开安全部分下的秘密和变量，然后单击操作。这将带您进入一个面板，您可以在该面板中为 GitHub Actions 运行器定义环境变量和加密机密。现在，指定您的 DOCKERHUB_USERNAME 和 DOCKERHUB_TOKEN 机密：\n请注意，这些秘密是加密的，GitHub 不会再次向您显示它们，因此请确保将它们保存在安全的地方。但是，如果您足够努力，那么您将能够恢复它们——例如，通过您工作流程中的 shell 命令。\n当您将功能分支合并到主线时，此操作也会有条件地运行。在 with 部分，您指定 Dockerfile 的路径，请求推送镜像的操作，并列出镜像的标签。请注意，您再次使用 github 上下文来获取当前提交的哈希值，尽管是长格式。\n注意：GitHub Packages 是集成到 GitHub 中的另一项服务。它可以作为 Docker Hub 的替代品。它支持各种包类型，包括 Docker 镜像，让您可以将源代码和二进制包存储在一个地方。 docker/build-push-action 可以利用您的 GitHub 令牌推送到 GitHub Packages。\n此时，您的持续集成工作流已配置完毕并准备就绪。如果您还没有使用 GitHub 内置的代码编辑器，那么请记住提交并推送您的本地存储库以使更改生效：\n$ git status On branch master Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) .github/ nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) $ git add .github/ $ git commit -m \u0026#34;Add a continuous integration workflow\u0026#34; $ git push 在下一节中，您将启用一些分支保护规则以防止任何人将他们的代码直接推送到 master 分支。因此，工作流中的 push 事件将仅适用于通过拉取请求将功能分支合并到主线中。\n启用分支保护规则 再次转到存储库的设置，单击代码和自动化部分下的分支，然后单击标记为添加分支保护规则的按钮。然后，在 Branch name pattern 字段中输入您的主线名称。如果您遵循本教程中使用的命名约定，则应在输入字段中键入 master ：\n接下来，启用其正下方的一个选项，该选项显示 Require a pull request before merging。这将自动需要至少一位审阅者的批准。如果您在 GitHub 上没有其他帐户，您可以暂时取消选中此选项。否则，如果没有其他人批准，您将无法合并您的拉取请求： 向下滚动一点后，您会看到一个选项，上面写着 Require status checks to pass before merging。选择它以显示更多选项。当你这样做时，检查另一个选项 Require branches to be update before merging，这将防止在你的 master 分支有新提交时关闭拉取请求。最后，在下面的搜索框中输入您的工作名称 build ：\n现在，每个拉取请求都需要在允许合并之前通过端到端测试。\n要在不允许管理员和其他具有提升权限的用户绕过这些规则的情况下强制执行这些规则，您可以在底部选择一个标记为不允许绕过上述设置的选项：\n好的。一切就绪！如何使用您的 Docker 应用程序来测试您的持续集成工作流程？\n集成来自功能分支的更改 遵循本教程前面概述的基于 Docker 的持续集成管道。首先创建一个单独的功能分支，以破坏测试的方式修改代码，提交更改并将它们推送到 GitHub：\nWindows：\nPS\u0026gt; git checkout -b feature/replace-emoji-face Switched to a new branch \u0026#39;feature/replace-emoji-face\u0026#39; PS\u0026gt; cd web\\src\\page_tracker PS\u0026gt; (Get-Content app.py).replace(\u0026#39;pensive\u0026#39;, \u0026#39;thinking\u0026#39;) | Set-Content app.py PS\u0026gt; git commit -am \u0026#34;Replace the emoji in an error message\u0026#34; [feature/replace-emoji-face 9225d18] Replace the emoji in an error message 1 file changed, 1 insertion(+), 1 deletion(-) PS\u0026gt; git push --set-upstream origin feature/replace-emoji-face ⋮ remote: Create a pull request for \u0026#39;feature/replace-emoji-face\u0026#39; on GitHub... remote: https://github.com/realpython/page-tracker/pull/new/feature... Linx + MacOS：\n$ git checkout -b feature/replace-emoji-face Switched to a new branch \u0026#39;feature/replace-emoji-face\u0026#39; $ sed -i \u0026#39;s/pensive/thinking/g\u0026#39; web/src/page_tracker/app.py $ git commit -am \u0026#34;Replace the emoji in an error message\u0026#34; [feature/replace-emoji-face 9225d18] Replace the emoji in an error message 1 file changed, 1 insertion(+), 1 deletion(-) $ git push --set-upstream origin feature/replace-emoji-face ⋮ remote: Create a pull request for \u0026#39;feature/replace-emoji-face\u0026#39; on GitHub... remote: https://github.com/realpython/page-tracker/pull/new/feature... ⋮ 您创建并切换到一个名为 feature/replace-emoji-face 的新本地分支，然后将错误消息中的表情符号从沉思脸更改为思考脸，而不更新相应的单元测试。将分支提交并推送到 GitHub 后，您可以通过突出显示行中的链接从您的功能分支打开一个新的拉取请求到 master 。只要您这样做，您的持续集成工作流程就会启动。\n当 GitHub Actions 运行器完成其工作时，由于检查失败，您将无法合并您的分支：\n在这种情况下，您只有一个检查对应于工作流中的 build 作业，您在上一节中将其配置为分支保护规则之一。您可以单击右侧的 Details 链接来调查失败检查的日志，并且您可以选择以调试模式重新运行相应的作业以收集更多数据。\n此外，上面的屏幕截图描述了您的功能分支和目标主线之间的假设冲突。这表明其他人修改了与您相同的文件，并且他们在您修改表情符号时成功地将他们的更改与 master 分支集成。\n没有自动解决此类冲突的方法，因为它涉及理解代码的逻辑并做出关于保留哪些更改以及丢弃哪些更改的主观决定。\n解决此冲突的唯一方法是将更新后的主线合并到您本地的功能分支中，并手动整合冲突的更改。\n即使没有任何冲突，如果主线在您的功能分支之前有几个提交，那么无论测试结果如何，您仍然必须将 master 中的最新更改合并到您的分支中。这是因为您之前制定的另一个分支保护规则：\n合并拉取请求按钮将保持灰色和禁用状态，直到您采取措施解决所有这些问题。\n在现实生活中，您现在应该获取最新的 master 并将其合并到您的功能分支，必要时解决任何冲突。然后，您将更新代码以使所有测试再次通过。返回代码编辑器并使用预期的表情符号修复失败的单元测试：\n# web/test/unit/test_app.py # ... @unittest.mock.patch(\u0026#34;page_tracker.app.redis\u0026#34;) def test_should_handle_redis_connection_error(mock_redis, http_client): # Given mock_redis.return_value.incr.side_effect = ConnectionError # When response = http_client.get(\u0026#34;/\u0026#34;) # Then assert response.status_code == 500 - assert response.text == \u0026#34;Sorry, something went wrong \\N{pensive face}\u0026#34; + assert response.text == \u0026#34;Sorry, something went wrong \\N{thinking face}\u0026#34; 在本地运行测试并对代码的正确性获得信心后，在同一分支上再次提交并将其推送到 GitHub。在这样做之前，值得仔细检查当前分支：\n$ git branch * feature/replace-emoji-face master $ git add web/test/unit/test_app.py $ git commit -m \u0026#34;Fix the failing unit test\u0026#34; $ git push 拉取请求应该接受您的更改并开始另一个 CI 构建。一旦满足所有保护规则，您最终可以通过单击绿色按钮将您的功能分支合并到受保护的主线中：\n请注意，合并将触发针对 master 分支的另一个 CI 构建，以测试您的更改是否与代码库的其余部分很好地集成。事情总是有可能出错。另一方面，如果 CI 构建成功，则工作流将标记并将镜像推送到您的 Docker Hub 存储库：\n每次 CI 工作流成功时，推送的 Docker 镜像都会被标记为当前 Git 提交哈希和标签 latest 。\n恭喜！关于使用 Docker 和朋友构建持续集成管道的整个教程到此结束。给自己当之无愧的表扬，因为这绝非易事！\n后续步骤 您总是可以做很多事情来改进和微调现有的持续集成流程。尽管这是关于构建强大的 CI 管道的详尽且实用的教程，但您只是触及了皮毛！\n以下是一些供您考虑的想法：\n自动部署到云以实现持续交付。\n通过全流程自动化转向持续部署。\n引入负载均衡器和服务副本以获得更好的可扩展性。\n使用身份验证令牌保护敏感数据存储。\n配置服务的持久日志记录和监控。\n实施蓝绿部署以实现零停机。\n添加功能切换以试验金丝雀发布和 A/B 测试。\n通过本教程，您已经为入门打下了良好的基础。您当然可以从这里开始构建一个充分自动化和生产就绪的持续集成系统，利用 Docker 和朋友的力量。\n总结 您现在对如何在容器化环境中构建、部署和管理多容器 Web 应用程序有了深入的了解。您介绍了挂接到 Redis 服务器的 Flask Web 应用程序的开发、测试、保护、码头化和编排。\n您还了解了如何使用 Docker、GitHub Actions 和各种其他工具定义持续集成管道。\n在本教程中，您已经：\n在 Docker 容器中本地运行 Redis 服务器 Docker 编排 一个用 Flask 编写的 Python Web 应用程序 构建 Docker 镜像并将它们推送到 Docker Hub 注册表 使用 Docker Compose 编排多容器应用程序 在任何地方复制类似生产的基础设施 使用 GitHub Actions 定义持续集成工作流程 您准备好构建自己的持续集成管道了吗？在评论中让大家知道！\n免费下载：单击此处下载您的 Flask 应用程序和相关资源，以便您可以使用 Docker 定义持续集成管道。\n原文链接：Build Robust Continuous Integration With Docker and Friends ","permalink":"https://blog.chensoul.cc/posts/2023/05/22/docker-continuous-integration/","summary":"持续集成 (CI) 已成为软件开发的关键，它允许团队频繁合并代码更改并及早发现错误。\nDocker 容器通过提供一致的环境帮助促进持续集成过程，您可以在其中测试和发送每次提交的代码。\n在本教程中，您将学习如何使用 Docker 为 Flask Web 应用程序创建强大的持续集成管道。\n您将完成在本地开发和测试应用程序、将其容器化、使用 Docker Compose 编排容器以及使用 GitHub Actions 定义 CI 管道的步骤。\n在本教程结束时，您将能够为您的 Web 应用程序创建一个完全自动化的 CI 管道。\n在本教程中，您将：\n在 Docker 容器中本地运行 Redis 服务器 用 Docker 编排 Flask 编写的 Python Web 应用程序 构建 Docker 镜像并将它们推送到 Docker Hub 仓库 使用 Docker Compose 编排多容器应用程序 在任何地方复制类似生产的基础设施 使用 GitHub Actions 定义持续集成工作流 理想情况下，您应该具有使用 Python 进行 Web 开发、测试自动化、将 Redis 与 Python 结合使用以及使用 Git 和 GitHub 进行源代码版本控制的经验。以前接触过 Docker 会更好，但不是必需的。您还应该拥有一个 Git 客户端和一个 GitHub 帐户，以便跟随并复制本教程的步骤。\n注意：本教程大致基于名为 Docker in Action - Fitter, Happier, More Productive 的旧教程，该教程由 Michael Herman 编写，他于 2015 年 2 月 8 日在 PyTennessee 展示了他的 CI 工作流程。如果你有兴趣，您可以查看展示的相应幻灯片在会议上。\n不幸的是，原始教程中描述的许多工具不再受支持或免费提供。在此更新的教程中，您将使用最新的工具和技术，例如 GitHub Actions。","title":"[译]Build Robust Continuous Integration With Docker and Friends"},{"content":"本文主要介绍 Abstract Document 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 使用动态属性，并在保持类型安全的同时实现非类型化语言的灵活性。\n抽象文档模式中的属性对象可以动态添加和删除属性，并且属性类型是在运行时确定的，这使得抽象文档模式具有一定的灵活性和可扩展性。\n在抽象文档模式中，属性对象通常使用 Map 或者 List 等数据结构来实现。动态属性的添加和删除可以通过 Map 的 put 和 remove 方法实现，而属性的类型可以通过泛型来确定。\n解释 抽象文档模式使您能够处理其他非静态属性。 此模式使用特征的概念来实现类型安全，并将不同类的属性分离为一组接口。\n真实世界例子\n考虑由多个部分组成的汽车。 但是，我们不知道特定汽车是否真的拥有所有零件，或者仅仅是零件中的一部分。 我们的汽车是动态而且非常灵活的。\n通俗的说\n抽象文档模式允许在对象不知道的情况下将属性附加到对象。\n维基百科说\n面向对象的结构设计模式，用于组织松散类型的键值存储中的对象并使用类型化的视图公开数据。 该模式的目的是在强类型语言中实现组件之间的高度灵活性，在这种语言中，可以在不丢失类型安全支持的情况下，将新属性动态地添加到对象树中。 该模式利用特征将类的不同属性分成不同的接口。\n程序示例\n让我们首先定义基类Document和AbstractDocument。 它们基本上使对象拥有属性映射和任意数量的子对象。\n以下代码在 java 8 中编译正常。\nDocument 接口：\npublic interface Document { Void put(String key, Object value); Object get(String key); \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; children(String key, Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, T\u0026gt; constructor); } 以下接口不使用 Java 8 的 Stream API：\npublic interface Document { Object get(String key); void put(String key, Object value); List\u0026lt;Document\u0026gt; children(String key); } AbstractDocument 抽象类：\npublic abstract class AbstractDocument implements Document { private final Map\u0026lt;String, Object\u0026gt; properties; protected AbstractDocument(Map\u0026lt;String, Object\u0026gt; properties) { Objects.requireNonNull(properties, \u0026#34;properties map is required\u0026#34;); this.properties = properties; } @Override public Void put(String key, Object value) { properties.put(key, value); return null; } @Override public Object get(String key) { return properties.get(key); } @Override public \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; children(String key, Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, T\u0026gt; constructor) { // java 9 //\treturn Stream.ofNullable(get(key)) //\t.filter(Objects::nonNull) //\t.map(el -\u0026gt; (List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;) el) //\t.findAny() //\t.stream() //\t.flatMap(Collection::stream) //\t.map(constructor); // java 8 return Optional.ofNullable(get(key)) .filter(el -\u0026gt; el instanceof List\u0026lt;?\u0026gt;) .map(el -\u0026gt; (List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;) el) .map(List::stream) .orElseGet(Stream::empty) .map(constructor); } @Override public String toString() { return properties.toString(); } } 接下来，我们定义一个枚举“属性”和一组类型，价格，模型和零件的接口。 这使我们能够为 Car 类创建静态外观的界面。\npublic enum Property { PARTS, TYPE, PRICE, MODEL } public interface HasType extends Document { default Optional\u0026lt;String\u0026gt; getType() { return Optional.ofNullable((String) get(Property.TYPE.toString())); } } public interface HasPrice extends Document { default Optional\u0026lt;Number\u0026gt; getPrice() { return Optional.ofNullable((Number) get(Property.PRICE.toString())); } } public interface HasModel extends Document { default Optional\u0026lt;String\u0026gt; getModel() { return Optional.ofNullable((String) get(Property.MODEL.toString())); } } public interface HasParts extends Document { default Stream\u0026lt;Part\u0026gt; getParts() { return children(Property.PARTS.toString(), Part::new); } } public class Part extends AbstractDocument implements HasType, HasModel, HasPrice { public Part(Map\u0026lt;String, Object\u0026gt; properties) { super(properties); } } 现在我们准备介绍 Car。\npublic class Car extends AbstractDocument implements HasModel, HasPrice, HasParts { public Car(Map\u0026lt;String, Object\u0026gt; properties) { super(properties); } } 最后是完整示例中的Car构造和使用方式。\n@Slf4j public class App { /** * Program entry point. * * @param args command line args */ public static void main(String[] args) { log.info(\u0026#34;Constructing parts and car\u0026#34;); Map\u0026lt;String, Object\u0026gt; wheelProperties = ImmutableMap.of( Property.TYPE.toString(), \u0026#34;wheel\u0026#34;, Property.MODEL.toString(), \u0026#34;15C\u0026#34;, Property.PRICE.toString(), 100L); Map\u0026lt;String, Object\u0026gt; doorProperties = ImmutableMap.of( Property.TYPE.toString(), \u0026#34;door\u0026#34;, Property.MODEL.toString(), \u0026#34;Lambo\u0026#34;, Property.PRICE.toString(), 300L); Map\u0026lt;String, Object\u0026gt; carProperties = ImmutableMap.of( Property.MODEL.toString(), \u0026#34;300SL\u0026#34;, Property.PRICE.toString(), 10000L, Property.PARTS.toString(), ImmutableList.of(wheelProperties, doorProperties)); Car car = new Car(carProperties); log.info(\u0026#34;Here is our car:\u0026#34;); log.info(\u0026#34;-\u0026gt; model: {}\u0026#34;, car.getModel().orElse(null)); log.info(\u0026#34;-\u0026gt; price: {}\u0026#34;, car.getPrice().orElse(null)); log.info(\u0026#34;-\u0026gt; parts: \u0026#34;); car.getParts().forEach(p -\u0026gt; log.info(\u0026#34;\\t{}/{}/{}\u0026#34;, p.getType().orElse(null), p.getModel().orElse(null), p.getPrice().orElse(null)) ); } } 再来一个示例代码：\npublic class Person extends AbstractDocument{ public Person() { super(Map.of( \u0026#34;name\u0026#34;, \u0026#34;John Doe\u0026#34;, \u0026#34;age\u0026#34;, 30, \u0026#34;hobbies\u0026#34;, List.of(\u0026#34;Sports\u0026#34;, \u0026#34;Music\u0026#34;)); } } @Slf4j public class PersonApp { public static void main(String[] args) { Person person = new Person(); log.info(\u0026#34;name: {}\u0026#34;, person.get(\u0026#34;name\u0026#34;)); log.info(\u0026#34;age: {}\u0026#34;, person.get(\u0026#34;age\u0026#34;)); log.info(\u0026#34;hobbies: {}\u0026#34;, person.get(\u0026#34;hobbies\u0026#34;)); } } 类图 适用性 使用抽象文档模式，当\n需要即时添加新属性 你想要一种灵活的方式来以树状结构组织域 你想要更宽松的耦合系统 下面是抽象文档模式的一些实际应用：\n1、XML 和 JSON 解析 抽象文档模式可以用于解析 XML 和 JSON 数据。由于 XML 和 JSON 数据通常包含动态属性，因此抽象文档模式可以提供一种灵活的方式来处理这些数据。通过将 XML 或 JSON 数据映射到文档和属性对象，可以轻松地访问和修改这些数据。\nXML 解析 假设我们有一个简单的 XML 文件，内容如下：\n\u0026lt;bookstore\u0026gt; \u0026lt;book category=\u0026#34;cooking\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Everyday Italian\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;Giada De Laurentiis\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2005\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;30.00\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;book category=\u0026#34;children\u0026#34;\u0026gt; \u0026lt;title lang=\u0026#34;en\u0026#34;\u0026gt;Harry Potter\u0026lt;/title\u0026gt; \u0026lt;author\u0026gt;J.K. Rowling\u0026lt;/author\u0026gt; \u0026lt;year\u0026gt;2003\u0026lt;/year\u0026gt; \u0026lt;price\u0026gt;29.99\u0026lt;/price\u0026gt; \u0026lt;/book\u0026gt; \u0026lt;/bookstore\u0026gt; 我们可以使用抽象文档模式来解析这个 XML 文件，首先定义一个Document接口，如下所示：\npublic interface Document { Object get(String key); void put(String key, Object value); List\u0026lt;Document\u0026gt; children(String key); } 然后定义一个具体的 XML 文档类，如下所示：\npublic class XmlDocument implements Document { private final Element element; public XmlDocument(Element element) { this.element = element} @Override public Object get(String key) { return element.getAttribute(key); } @Override public void put(String key, Object value) { element.setAttribute(key, value.toString()); } @Override public List\u0026lt;Document\u0026gt; children(String key) { NodeList nodes = element.getElementsByTagName(key); List\u0026lt;Document\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; nodes.getLength(); i++) { children.add(new XmlDocument((Element) nodes.item(i))); } return children; } } 在这个具体的 XML 文档类中，我们实现了Document接口的三个方法，其中children方法使用了 DOM API 来获取子元素列表，并将每个子元素包装成一个新的XmlDocument对象。\n现在，我们可以使用这个具体的 XML 文档类来解析 XML 文件，如下所示：\nDocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder dBuilder = dbFactory.newDocumentBuilder(); Document doc = new XmlDocument(dBuilder.parse(new File(\u0026#34;books.xml\u0026#34;)).getDocumentElement()); // 获取根元素的属性值 String bookstoreCategory = (String) doc.get(\u0026#34;category\u0026#34;); // 获取所有书的信息 List\u0026lt;Document\u0026gt; books = doc.children(\u0026#34;book\u0026#34;); for (Document book : books) { String category = (String)doc.get(\u0026#34;category\u0026#34;); String title = (String) book.children(\u0026#34;title\u0026#34;).get(0).get(\u0026#34;\u0026#34;); String author = (String) book.children(\u0026#34;author\u0026#34;).get(0).get(\u0026#34;\u0026#34;); int year = (int) book.children(\u0026#34;year\u0026#34;).get(0).get(\u0026#34;\u0026#34;); double price = (double) book.children(\u0026#34;price\u0026#34;).get(0).get(\u0026#34;\u0026#34;); System.out.println(\u0026#34;Category: \u0026#34; + category + \u0026#34;, Title: \u0026#34; + title + \u0026#34;, Author: \u0026#34; + author + \u0026#34;, Year: \u0026#34; + year + \u0026#34;, Price: \u0026#34; + price); } JSON 解析 假设我们有一个简单的 JSON 文件，以下是example.json文件的内容：：\n{ \u0026#34;name\u0026#34;: \u0026#34;John Smith\u0026#34;, \u0026#34;age\u0026#34;: 35, \u0026#34;address\u0026#34;: { \u0026#34;street\u0026#34;: \u0026#34;123 Main St\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Anytown\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;CA\u0026#34;, \u0026#34;zip\u0026#34;: \u0026#34;12345\u0026#34; }, \u0026#34;phone\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;home\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;555-1234\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;work\u0026#34;, \u0026#34;number\u0026#34;: \u0026#34;555-5678\u0026#34; } ] } 我们可以使用抽象文档模式来解析这个 JSON 文件，首先定义一个Document接口，如下所示：\npublic interface Document { Object get(String key); void put(String key, Object value); List\u0026lt;Document\u0026gt; children(String key); } 然后定义一个具体的 JSON 文档类，如下所示：\nimport com.google.gson.*; import java.util.ArrayList; import java.util.List; public class JsonDocument implements Document { private final JsonObject object; public JsonDocument(JsonObject object) { this.object = object; } @Override public Object get(String key) { JsonElement element = object.get(key); if (element == null) { return null; } if (element.isJsonPrimitive()) { JsonPrimitive primitive = element.getAsJsonPrimitive(); if (primitive.isNumber()) { return primitive.getAsNumber(); } else if (primitive.isBoolean()) { return primitive.getAsBoolean(); } else { return primitive.getAsString(); } } else if (element.isJsonObject()) { return new JsonDocument(element.getAsJsonObject()); } else if (element.isJsonArray()) { JsonArray array = element.getAsJsonArray(); List\u0026lt;Document\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); for (JsonElement child : array) { children.add(new JsonDocument(child.getAsJsonObject())); } return children; } else { return null; } } @Override public void put(String key, Object value) { if (value instanceof String) { object.addProperty(key, (String) value); } else if (value instanceof Number) { object.addProperty(key, (Number) value); } else if (value instanceof Boolean) { object.addProperty(key, (Boolean) value); } else if (value instanceof Document) { JsonDocument jsonDocument = (JsonDocument) value; object.add(key, jsonDocument.object); } else if (value instanceof List) { List\u0026lt;Document\u0026gt; children = (List\u0026lt;Document\u0026gt;) value; JsonArray array = new JsonArray(); for (Document child : children) { JsonDocument jsonChild = (JsonDocument) child; array.add(jsonChild.object); } object.add(key, array); } } @Override public List\u0026lt;Document\u0026gt; children(String key) { JsonElement element = object.get(key); List\u0026lt;Document\u0026gt; children = new ArrayList\u0026lt;\u0026gt;(); if (element != null \u0026amp;\u0026amp; element.isJsonArray()) { JsonArray array = element.getAsJsonArray(); for (JsonElement child : array) { children.add(new JsonDocument(child.getAsJsonObject())); } } return children; } } 现在，我们可以使用这个具体的 JSON 文档类来解析 JSON 文件，如下所示：\npublic class JsonParsingExample { public static void main(String[] args) { try { // 读取JSON文件并解析 Gson gson = new Gson(); JsonElement jsonElement = gson.fromJson(new FileReader(\u0026#34;example.json\u0026#34;), JsonElement.class); JsonDocument doc = new JsonDocument(jsonElement.getAsJsonObject()); // 获取根元素的属性值 String name = (String) doc.get(\u0026#34;name\u0026#34;); int age = (int) doc.get(\u0026#34;age\u0026#34;); // 获取地址 JsonDocument address = (JsonDocument) doc.get(\u0026#34;address\u0026#34;); String street = (String) address.get(\u0026#34;street\u0026#34;); String city = (String) address.get(\u0026#34;city\u0026#34;); String state = (String) address.get(\u0026#34;state\u0026#34;); String zip = (String) address.get(\u0026#34;zip\u0026#34;); // 获取电话号码 List\u0026lt;Document\u0026gt; phoneList = doc.children(\u0026#34;phone\u0026#34;); for (Document phone : phoneList) { String type = (String) phone.get(\u0026#34;type\u0026#34;); String number = (String) phone.get(\u0026#34;number\u0026#34;); System.out.println(type + \u0026#34;: \u0026#34; + number); } } catch (Exception e) { e.printStackTrace(); } } } 2、动态配置 抽象文档模式可以用于动态配置。通过将配置数据映射到文档和属性对象，可以轻松地访问和修改配置数据。此外，由于抽象文档模式支持动态属性，因此可以在运行时添加或删除属性，从而使配置更加灵活。\n假设有一个学生信息管理系统，需要存储和检索学生信息。学生信息包括学生姓名、学生年龄、学生性别、学生家庭地址等属性。由于学生属性可能会随时变化，因此需要使用一种灵活的方式来处理这些属性，并且需要轻松地访问和修改这些属性。\n为了实现这个功能，可以使用抽象文档模式。定义一个学生文档类（StudentDocument），该类包含学生属性的访问器和修改器方法，并且支持动态属性。然后，定义一个学生属性类（Property），该类包含属性名称、属性类型和属性值等属性，并且支持动态属性。最后，使用一个构建器（Builder）类来创建具体的学生文档对象，并将学生属性添加到文档中。\n示例代码如下：\nimport java.util.ArrayList; import java.util.List; public class Property { private String name; private Object value; public Property(String name, Object value) { this.name = name; this.value = value; } public String getName() { return name; } public Object getValue() { return value; } public void setValue(Object value) { this.value = value; } } public abstract class Document { private List\u0026lt;Property\u0026gt; properties = new ArrayList\u0026lt;\u0026gt;(); public Object getProperty(String name) { for (Property property : properties) { if (property.getName().equals(name)) { return property.getValue(); } } return null; } public void setProperty(String name, Object value) { for (Property property : properties) { if (property.getName().equals(name)) { property.setValue(value); return; } } properties.add(new Property(name, value)); } } public class StudentDocument extends Document { public String getName() { return (String) getProperty(\u0026#34;name\u0026#34;); } public void setName(String name) { setProperty(\u0026#34;name\u0026#34;, name); } public int getAge() { return (int) getProperty(\u0026#34;age\u0026#34;); } public void setAge(int age) { setProperty(\u0026#34;age\u0026#34;, age); } public String getGender() { return (String) getProperty(\u0026#34;gender\u0026#34;); } public void setGender(String gender) { setProperty(\u0026#34;gender\u0026#34;, gender); } public String getAddress() { return (String) getProperty(\u0026#34;address\u0026#34;); } public void setAddress(Stringaddress) { setProperty(\u0026#34;address\u0026#34;, address); } } public class StudentBuilder { private StudentDocument student = new StudentDocument(); public void setName(String name) { student.setName(name); } public void setAge(int age) { student.setAge(age); } public void setGender(String gender) { student.setGender(gender); } public void setAddress(String address) { student.setAddress(address); } public StudentDocument build() { return student; } } 使用抽象文档模式，可以轻松地访问和修改学生属性，如下所示：\nStudentBuilder builder = new StudentBuilder(); builder.setName(\u0026#34;Tom\u0026#34;); builder.setAge(18); builder.setGender(\u0026#34;Male\u0026#34;); builder.setAddress(\u0026#34;Beijing\u0026#34;); StudentDocument student = builder.build(); System.out.println(student.getName()); // 输出：Tom student.setAddress(\u0026#34;Shanghai\u0026#34;); System.out.println(student.getAddress()); // 输出：Shanghai student.setProperty(\u0026#34;phoneNumber\u0026#34;, \u0026#34;1234567890\u0026#34;); System.out.println(student.getProperty(\u0026#34;phoneNumber\u0026#34;)); // 输出：1234567890 3、业务规则引擎 抽象文档模式可以用于实现业务规则引擎。通过将规则数据映射到文档和属性对象，可以轻松地访问和修改规则数据。此外，由于抽象文档模式支持动态属性，因此可以在运行时添加或删除规则，从而使规则引擎更加灵活。\n假设我们有一个简单的业务规则，用于确定用户是否有资格获得某项奖励。这个规则可能涉及到多个条件，例如用户的年龄、所在地区以及购物金额等。\n我们可以将这个规则表示为一个文档，例如一个 JSON 文档，其中每个属性对应一个规则条件。例如：\n{ \u0026#34;age\u0026#34;: { \u0026#34;operator\u0026#34;: \u0026#34;\u0026gt;=\u0026#34;, \u0026#34;value\u0026#34;: 18 }, \u0026#34;region\u0026#34;: { \u0026#34;operator\u0026#34;: \u0026#34;in\u0026#34;, \u0026#34;value\u0026#34;: [\u0026#34;east\u0026#34;, \u0026#34;south\u0026#34;] }, \u0026#34;amount\u0026#34;: { \u0026#34;operator\u0026#34;: \u0026#34;\u0026gt;=\u0026#34;, \u0026#34;value\u0026#34;: 1000 } } 然后，我们可以使用抽象文档模式来解析这个文档，并将其转换为一个规则对象。例如，我们可以创建一个名为Rule的类，它包含三个属性：\npublic class Rule { private final String key; private final String operator; private final Object value; private final Object secondValue; public Rule(String key, String operator, Object value) { this(key, operator, value, null); } public Rule(String key, String operator, Object value, Object secondValue) { this.key = key; this.operator = operator; this.value = value; this.secondValue = secondValue; } public boolean evaluate(Document document) { Object documentValue = document.get(key); if (documentValue == null) { return false; } switch (operator) { case \u0026#34;\u0026gt;=\u0026#34;: return compare(documentValue, value) \u0026gt;= 0; case \u0026#34;\u0026lt;=\u0026#34;: return compare(documentValue, value) \u0026lt;= 0; case \u0026#34;\u0026gt;\u0026#34;: return compare(documentValue, value) \u0026gt; 0; case \u0026#34;\u0026lt;\u0026#34;: return compare(documentValue, value) \u0026lt; 0; case \u0026#34;==\u0026#34;: return compare(documentValue,value) == 0; case \u0026#34;!=\u0026#34;: return compare(documentValue, value) != 0; case \u0026#34;in\u0026#34;: if (value instanceof List) { List\u0026lt;?\u0026gt; listValue = (List\u0026lt;?\u0026gt;) value; for (Object item : listValue) { if (compare(documentValue, item) == 0) { return true; } } } return false; case \u0026#34;not in\u0026#34;: boolean found=false; if (value instanceof List) { List\u0026lt;?\u0026gt; listValue = (List\u0026lt;?\u0026gt;) value; for (Object item : listValue) { if (compare(documentValue, item) == 0) { found=true; break; } } } return !found; case \u0026#34;between\u0026#34;: if (secondValue == null) { return false; } int cmp1 = compare(documentValue, value); int cmp2 = compare(documentValue, secondValue); return cmp1 \u0026gt;= 0 \u0026amp;\u0026amp; cmp2 \u0026lt;= 0; case \u0026#34;not between\u0026#34;: if (secondValue == null) { return false; } int cmp1 = compare(documentValue, value); int cmp2 = compare(documentValue, secondValue); return cmp1 \u0026lt; 0 || cmp2 \u0026gt; 0; case \u0026#34;regex\u0026#34;: if (documentValue instanceof String \u0026amp;\u0026amp; value instanceof String) { String strValue = (String) value; String strDocumentValue = (String) documentValue; return strDocumentValue.matches(strValue); } return false; case \u0026#34;startswith\u0026#34;: if(documentValue instanceof String \u0026amp;\u0026amp; value instanceof String) { String strValue = (String) value; String strDocumentValue = (String) documentValue; return strDocumentValue.startsWith(strValue); } return false; case \u0026#34;endswith\u0026#34;: if (documentValue instanceof String \u0026amp;\u0026amp; value instanceof String) { String strValue = (String) value; String strDocumentValue = (String) documentValue; return strDocumentValue.endsWith(strValue); } return false; case \u0026#34;like\u0026#34;: if (documentValue instanceof String \u0026amp;\u0026amp; value instanceof String) { String strValue = (String) value; String strDocumentValue = (String) documentValue; return strDocumentValue.contains(strValue); } return false; case \u0026#34;not like\u0026#34;: if (documentValue instanceof String \u0026amp;\u0026amp; value instanceof String) { String strValue = (String) value; String strDocumentValue = (String) documentValue; return !strDocumentValue.contains(strValue); } return false; default: return false; } } private int compare(Object a, Object b) { if (a instanceof Number \u0026amp;\u0026amp; b instanceof Number) { return Double.compare(((Number) a).doubleValue(), ((Number) b).doubleValue()); } else if (a instanceof String \u0026amp;\u0026amp; b instanceof String) { return ((String) a).compareTo((String) b); } else { return a.toString().compareTo(b.toString()); } } } Rule类有一个evaluate方法，它接受一个Document对象，并根据规则条件对文档进行评估。例如，对于上面的规则文档，我们可以创建三个Rule对象：\nRule ageRule = new Rule(\u0026#34;age\u0026#34;, \u0026#34;between\u0026#34;, 18, 30); Rule regionRule = new Rule(\u0026#34;region\u0026#34;, \u0026#34;in\u0026#34;, Arrays.asList(\u0026#34;east\u0026#34;, \u0026#34;south\u0026#34;)); Rule amountRule = new Rule(\u0026#34;amount\u0026#34;, \u0026#34;\u0026gt;=\u0026#34;, 1000); 然后，我们可以将这些规则应用于用户数据，例如一个存储在数据库中的用户记录。我们可以将用户数据表示为一个文档，例如一个 XML 文档：\n\u0026lt;user\u0026gt; \u0026lt;name\u0026gt;John Doe\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;25\u0026lt;/age\u0026gt; \u0026lt;region\u0026gt;east\u0026lt;/region\u0026gt; \u0026lt;amount\u0026gt;1200\u0026lt;/amount\u0026gt; \u0026lt;/user\u0026gt; 我们可以使用抽象文档模式解析该文档并将其转换为Document对象。然后，我们可以使用Rule对象和Document对象来评估用户是否有资格获得奖励。例如：\nDocument userDocument = ... // 解析用户数据为一个Document对象 boolean isEligible = ageRule.evaluate(userDocument) \u0026amp;\u0026amp; regionRule.evaluate(userDocument) \u0026amp;\u0026amp; amountRule.evaluate(userDocument); 4、数据库映射 抽象文档模式可以用于将数据库数据映射到文档和属性对象上。通过将数据库表映射到文档对象，将表的列映射到属性对象，可以轻松地访问和修改数据库数据。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/22/java-design-patterns-abstract-document/","summary":"本文主要介绍 Abstract Document 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 使用动态属性，并在保持类型安全的同时实现非类型化语言的灵活性。\n抽象文档模式中的属性对象可以动态添加和删除属性，并且属性类型是在运行时确定的，这使得抽象文档模式具有一定的灵活性和可扩展性。\n在抽象文档模式中，属性对象通常使用 Map 或者 List 等数据结构来实现。动态属性的添加和删除可以通过 Map 的 put 和 remove 方法实现，而属性的类型可以通过泛型来确定。\n解释 抽象文档模式使您能够处理其他非静态属性。 此模式使用特征的概念来实现类型安全，并将不同类的属性分离为一组接口。\n真实世界例子\n考虑由多个部分组成的汽车。 但是，我们不知道特定汽车是否真的拥有所有零件，或者仅仅是零件中的一部分。 我们的汽车是动态而且非常灵活的。\n通俗的说\n抽象文档模式允许在对象不知道的情况下将属性附加到对象。\n维基百科说\n面向对象的结构设计模式，用于组织松散类型的键值存储中的对象并使用类型化的视图公开数据。 该模式的目的是在强类型语言中实现组件之间的高度灵活性，在这种语言中，可以在不丢失类型安全支持的情况下，将新属性动态地添加到对象树中。 该模式利用特征将类的不同属性分成不同的接口。\n程序示例\n让我们首先定义基类Document和AbstractDocument。 它们基本上使对象拥有属性映射和任意数量的子对象。\n以下代码在 java 8 中编译正常。\nDocument 接口：\npublic interface Document { Void put(String key, Object value); Object get(String key); \u0026lt;T\u0026gt; Stream\u0026lt;T\u0026gt; children(String key, Function\u0026lt;Map\u0026lt;String, Object\u0026gt;, T\u0026gt; constructor); } 以下接口不使用 Java 8 的 Stream API：\npublic interface Document { Object get(String key); void put(String key, Object value); List\u0026lt;Document\u0026gt; children(String key); } AbstractDocument 抽象类：","title":"Java设计模式：Abstract Document"},{"content":"本文主要介绍 Abstract Factory 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 抽象工厂（Abstract Factory）是一种创建型设计模式，它提供了一种方式来创建一系列相关或依赖对象的家族，而无需指定它们具体的类。\n抽象工厂模式使用一个抽象工厂接口来定义一组相关的工厂方法，每个工厂方法都能够创建一组相关的产品。具体的工厂实现了这个接口，并能够创建具体的产品。客户端代码只需要使用抽象工厂接口来创建产品，而不需要关心具体的产品实现。\n解释 真实世界例子\n要创建一个王国，我们需要具有共同主题的对象。精灵王国需要精灵国王、精灵城堡和精灵军队，而兽人王国需要兽人国王、兽人城堡和兽人军队。王国中的对象之间存在依赖关系。\n通俗的说\n工厂的工厂； 一个将单个但相关/从属的工厂分组在一起而没有指定其具体类别的工厂。\n维基百科上说\n抽象工厂模式提供了一种封装一组具有共同主题的单个工厂而无需指定其具体类的方法\n程序示例\n翻译上面的王国示例。 首先，我们为王国中的对象提供了一些接口和实现。\npublic interface Castle { String getDescription(); } public interface King { String getDescription(); } public interface Army { String getDescription(); } // Elven implementations -\u0026gt; public class ElfCastle implements Castle { static final String DESCRIPTION = \u0026#34;This is the Elven castle!\u0026#34;; @Override public String getDescription() { return DESCRIPTION; } } public class ElfKing implements King { static final String DESCRIPTION = \u0026#34;This is the Elven king!\u0026#34;; @Override public String getDescription() { return DESCRIPTION; } } public class ElfArmy implements Army { static final String DESCRIPTION = \u0026#34;This is the Elven Army!\u0026#34;; @Override public String getDescription() { return DESCRIPTION; } } // Orcish implementations similarly -\u0026gt; ... 然后我们有了王国工厂的抽象和实现\npublic interface KingdomFactory { Castle createCastle(); King createKing(); Army createArmy(); } public class ElfKingdomFactory implements KingdomFactory { public Castle createCastle() { return new ElfCastle(); } public King createKing() { return new ElfKing(); } public Army createArmy() { return new ElfArmy(); } } public class OrcKingdomFactory implements KingdomFactory { public Castle createCastle() { return new OrcCastle(); } public King createKing() { return new OrcKing(); } public Army createArmy() { return new OrcArmy(); } } 现在我们有了抽象工厂，使我们可以制作相关对象的系列，即精灵王国工厂创建了精灵城堡，国王和军队等。\nKingdomFactory factory = new ElfKingdomFactory(); Castle castle = factory.createCastle(); King king = factory.createKing(); Army army = factory.createArmy(); castle.getDescription(); king.getDescription(); army.getDescription(); 程序输出:\nThis is the Elven castle! This is the Elven king! This is the Elven Army! 现在，我们可以为不同的王国工厂设计工厂。 在此示例中，我们创建了 FactoryMaker，负责返回 ElfKingdomFactory 或 OrcKingdomFactory 的实例。 客户可以使用 FactoryMaker 来创建所需的具体工厂，该工厂随后将生产不同的具体对象（军队，国王，城堡）。 在此示例中，我们还使用了一个枚举来参数化客户要求的王国工厂类型。\npublic static class FactoryMaker { public enum KingdomType { ELF, ORC } public static KingdomFactory makeFactory(KingdomType type) { return switch (type) { case ELF -\u0026gt; new ElfKingdomFactory(); case ORC -\u0026gt; new OrcKingdomFactory(); default -\u0026gt; throw new IllegalArgumentException(\u0026#34;KingdomType not supported.\u0026#34;); }; } } @Slf4j public class App{ private final Kingdom kingdom = new Kingdom(); public Kingdom getKingdom() { return kingdom; } public static void main(String[] args) { App app = new App(); LOGGER.info(\u0026#34;elf kingdom\u0026#34;); createKingdom(KingdomType.ELF); LOGGER.info(kingdom.getArmy().getDescription()); LOGGER.info(kingdom.getCastle().getDescription()); LOGGER.info(kingdom.getKing().getDescription()); LOGGER.info(\u0026#34;orc kingdom\u0026#34;); createKingdom(KingdomType.ORC); LOGGER.info(kingdom.getArmy().getDescription()); LOGGER.info(kingdom.getCastle().getDescription()); LOGGER.info(kingdom.getKing().getDescription()); } } 类图 优缺点 优点包括：\n抽象工厂模式能够帮助我们创建具有高内聚性的对象家族，这些对象家族之间相互协作，从而构成一个完整的系统。 抽象工厂模式能够保证客户端代码与具体产品实现之间的解耦，从而让系统更加灵活和可扩展。 抽象工厂模式能够隐藏产品的具体实现细节，从而提高系统的安全性和稳定性。 而缺点则包括：\n抽象工厂模式比较复杂，需要定义许多接口和抽象类，这会增加系统的复杂性和开发成本。 如果需要添加新的产品族，那么就需要修改抽象工厂接口以及所有的具体工厂实现，这会带来一定的风险和不便。 抽象工厂模式可能会导致系统的扩展性受限，因为一旦定义了抽象工厂接口，就不能够轻易地修改它。 在《Effective Java》中，作者还提到了一个关于抽象工厂模式的建议：在设计抽象工厂接口时，要考虑到未来可能的变化。例如，如果我们预计将来可能会添加新的产品族，那么就应该尽量设计一个灵活的抽象工厂接口，以便在不修改现有代码的情况下添加新的产品族。\n举例：Abstract Factory Design Pattern in Java\nComputer.java：\npublic abstract class Computer { public abstract String getRAM(); public abstract String getHDD(); public abstract String getCPU(); @Override public String toString(){ return \u0026#34;RAM= \u0026#34;+this.getRAM()+\u0026#34;, HDD=\u0026#34;+this.getHDD()+\u0026#34;, CPU=\u0026#34;+this.getCPU(); } } PC.java：\npublic class PC extends Computer { private String ram; private String hdd; private String cpu; public PC(String ram, String hdd, String cpu){ this.ram=ram; this.hdd=hdd; this.cpu=cpu; } @Override public String getRAM() { return this.ram; } @Override public String getHDD() { return this.hdd; } @Override public String getCPU() { return this.cpu; } } Server.java：\npublic class Server extends Computer { private String ram; private String hdd; private String cpu; public Server(String ram, String hdd, String cpu){ this.ram=ram; this.hdd=hdd; this.cpu=cpu; } @Override public String getRAM() { return this.ram; } @Override public String getHDD() { return this.hdd; } @Override public String getCPU() { return this.cpu; } } 抽象工厂方法：\npublic interface ComputerAbstractFactory { public Computer createComputer(); } public class PCFactory implements ComputerAbstractFactory { private String ram; private String hdd; private String cpu; public PCFactory(String ram, String hdd, String cpu){ this.ram=ram; this.hdd=hdd; this.cpu=cpu; } @Override public Computer createComputer() { return new PC(ram,hdd,cpu); } } public class ServerFactory implements ComputerAbstractFactory { private String ram; private String hdd; private String cpu; public ServerFactory(String ram, String hdd, String cpu){ this.ram=ram; this.hdd=hdd; this.cpu=cpu; } @Override public Computer createComputer() { return new Server(ram,hdd,cpu); } } 工厂类：\npublic class ComputerFactory { public static Computer getComputer(ComputerAbstractFactory factory){ return factory.createComputer(); } } 测试：\npublic class TestDesignPatterns { public static void main(String[] args) { testAbstractFactory(); } private static void testAbstractFactory() { Computer pc = ComputerFactory.getComputer(new PCFactory(\u0026#34;2 GB\u0026#34;,\u0026#34;500 GB\u0026#34;,\u0026#34;2.4 GHz\u0026#34;)); Computer server = ComputerFactory.getComputer(new ServerFactory(\u0026#34;16 GB\u0026#34;,\u0026#34;1 TB\u0026#34;,\u0026#34;2.9 GHz\u0026#34;)); System.out.println(\u0026#34;AbstractFactory PC Config::\u0026#34;+pc); System.out.println(\u0026#34;AbstractFactory Server Config::\u0026#34;+server); } } 输出结果：\nAbstractFactory PC Config::RAM= 2 GB, HDD=500 GB, CPU=2.4 GHz AbstractFactory Server Config::RAM= 16 GB, HDD=1 TB, CPU=2.9 GHz 适用性 在以下情况下使用抽象工厂模式\n该系统应独立于其产品的创建，组成和表示方式 系统应配置有多个产品系列之一 相关产品对象系列旨在一起使用，你需要强制执行此约束 你想提供产品的类库，并且只想暴露它们的接口，而不是它们的实现。 从概念上讲，依赖项的生存期比使用者的生存期短。 你需要一个运行时值来构建特定的依赖关系 你想决定在运行时从系列中调用哪种产品。 你需要提供一个或更多仅在运行时才知道的参数，然后才能解决依赖关系。 当你需要产品之间的一致性时 在向程序添加新产品或产品系列时，您不想更改现有代码。 相关模式 Factory Method Factory Kit 使用 jdk 中以下类使用了抽象工厂模式：\njavax.xml.parsers.DocumentBuilderFactoryopen javax.xml.transform.TransformerFactoryopen javax.xml.xpath.XPathFactoryopen 以下是一些常见的开源框架和库：\nSpring Framework：Spring Framework 是一个流行的 Java 应用程序框架，它使用了抽象工厂模式来创建不同类型的对象，例如数据源、事务管理器和消息队列等。 Hibernate ORM：Hibernate ORM 是一个用于管理对象关系映射（ORM）的框架，它使用了抽象工厂模式来创建数据库连接、事务管理器和查询语句等对象。 Apache Commons：Apache Commons 是一个开源的 Java 工具库，它包含了许多常用的工具类和函数。其中，一些模块（例如 Commons Codec 和 Commons Pool）使用了抽象工厂模式来创建不同类型的对象。 Apache Struts：Apache Struts 是一个基于 MVC（模型-视图-控制器）模式的 Web 应用程序框架，它使用了抽象工厂模式来创建不同类型的 Action 类和结果类型。 Apache CXF：Apache CXF 是一个用于构建 Web 服务的框架，它使用了抽象工厂模式来创建不同类型的 Web 服务端点和客户端。 Apache Axis：Apache Axis 是一个用于构建 Web 服务的框架，它使用了抽象工厂模式来创建不同类型的 Web 服务端点和客户端。 Apache Log4j：Apache Log4j 是一个流行的 Java 日志框架，它使用了抽象工厂模式来创建不同类型的日志记录器和 Appender（日志输出器）。 Apache Commons Configuration：Apache Commons Configuration 是一个用于读取和写入配置文件的库，它使用了抽象工厂模式来创建不同类型的配置对象，例如 XMLConfiguration 和 PropertiesConfiguration 等。 除此之外，许多其他的开源框架和库也使用了抽象工厂模式，例如 Hibernate、MyBatis、JDBC、JPA、JUnit 等。这些框架和库使用抽象工厂模式的原因是它能够帮助创建具有高内聚性的对象家族，并且能够保证客户端代码与具体产品实现之间的解耦。同时，抽象工厂模式也能够隐藏产品的具体实现细节，从而提高系统的安全性和稳定性。这些优点让抽象工厂模式成为了这些框架和库中常用的设计模式之一。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/22/java-design-patterns-abstract-factory/","summary":"本文主要介绍 Abstract Factory 模式，在 Java Design Patterns 网站上有对该模式进行介绍。这里主要是做个笔记，并添加一些扩展，以加深对该设计模式的理解。\nJava Design Patterns 提供了各种 Java 设计模式的介绍、示例代码和用例说明。该网站旨在帮助 Java 开发人员了解和应用各种常见的设计模式，以提高代码的可读性、可维护性和可扩展性。\nJava Design Patterns 网站提供了多种设计模式分类方式，包括创建型模式（Creational Patterns）、结构型模式（Structural Patterns）和行为型模式（Behavioral Patterns），以及其他一些常见的模式。\n对于每个设计模式，该网站提供了详细的介绍、示例代码和用例说明，并且提供了一些常见的使用场景和注意事项。开发人员可以根据自己的需求选择适合自己的设计模式，并且可以参考示例代码和用例说明来理解和应用该模式。\n此外，Java Design Patterns 网站还提供了一些其他资源，如设计模式的 UML 图、设计模式的优缺点、设计模式的比较等。这些资源可以帮助开发人员更好地理解和应用设计模式。\n中文网站：https://java-design-patterns.com/zh/\nGithub 上源码仓库（非官方）：https://github.com/iluwatar/java-design-patterns\n目的 抽象工厂（Abstract Factory）是一种创建型设计模式，它提供了一种方式来创建一系列相关或依赖对象的家族，而无需指定它们具体的类。\n抽象工厂模式使用一个抽象工厂接口来定义一组相关的工厂方法，每个工厂方法都能够创建一组相关的产品。具体的工厂实现了这个接口，并能够创建具体的产品。客户端代码只需要使用抽象工厂接口来创建产品，而不需要关心具体的产品实现。\n解释 真实世界例子\n要创建一个王国，我们需要具有共同主题的对象。精灵王国需要精灵国王、精灵城堡和精灵军队，而兽人王国需要兽人国王、兽人城堡和兽人军队。王国中的对象之间存在依赖关系。\n通俗的说\n工厂的工厂； 一个将单个但相关/从属的工厂分组在一起而没有指定其具体类别的工厂。\n维基百科上说\n抽象工厂模式提供了一种封装一组具有共同主题的单个工厂而无需指定其具体类的方法\n程序示例\n翻译上面的王国示例。 首先，我们为王国中的对象提供了一些接口和实现。\npublic interface Castle { String getDescription(); } public interface King { String getDescription(); } public interface Army { String getDescription(); } // Elven implementations -\u0026gt; public class ElfCastle implements Castle { static final String DESCRIPTION = \u0026#34;This is the Elven castle!\u0026#34;; @Override public String getDescription() { return DESCRIPTION; } } public class ElfKing implements King { static final String DESCRIPTION = \u0026#34;This is the Elven king!","title":"Java设计模式：Abstract Factory"},{"content":"前言 本篇是对 2023-05-08 到 2023-05-14 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周继续学习 python，发现一个质量非常高的 python 学习网站 Real Python，该网站有学习 python 的一些教程，是收费的，部分章节是可以免费观看的。\n另外，周五晚上老婆临时起意想去武功山看日出，于是立即规划行程并购买火车票。因为一年半之前，我去过一次，所以规划起来还是很轻松的。上一次去是国庆节碰到下雨，没有看到日出。幸运的是，这次是晴天，不仅看到了日落还看到了日出。这一次没有选择住帐篷，而是住在了云中雾客栈，没想到这个客栈离金顶需要 40 分钟左右的路程，而且有段路程是坑坑洼洼。\n去武功山之前，先去了长沙，再次游了橘子洲头，并第一次在长沙跑步打卡。本想在萍乡也跑步打卡，奈何没有得逞。\n这次去了长沙和武功山，下次基本上是再也不会去爬武功山了。长沙还会去，因为从武功山回来路上，就和老婆规划着什么时候去张家界。\n武功山看日出 理财 这周总计支出 1784 元，明细如下：\n5 月 8 日：12 元 5 月 9 日：18 元 5 月 10 日：200 元 5 月 11 日：12 元 5 月 12 日：445 元 5 月 13 日：662 元 5 月 14 日：435 元 因为周末出去旅游，所以本周支出有所增多。\n健身 本周跑步 56 公里，最长跑步距离为 13 公里。\n明细数据如下：\n周末出去旅游，路过长沙，在长沙跑了两天，累计跑了 6 公里。这样，我的跑步数据 从 2 年里我跑过 1 个省份 1 个城市 变成了 2 年里我跑过 2 个省份 2 个城市。\n工作 Java 博客 本周完成两篇博客\n《Effective Java 3》笔记 10：覆盖 equals 方法时应遵守的约定 JSR 166 规范 Python Python 初学建议 1、新手如何学习 python？\n推荐几篇文章：\ncPython - 给大学生的入门教程\n如何学 Python？\n2、学习 python 编程的 11 个建议\n原文：11 Beginner Tips for Learning Python Programming，总结出以下 11 条新手编程建议：\n提示 #1：每天编写代码\n提示#2：写出来\n提示#3：互动\n提示#4：休息\n提示#5：成为漏洞赏金猎人\n提示#6：与正在学习的其他人在一起\n技巧#7：教导\n技巧#8：结对编程\n提示#9：提出“好的”问题\n技巧#10：构建一些东西\n技巧#11：为开源做贡献\n3、Pyhton 播客： Ep 01. 新人到底需要什么\n播客中提到的内容：\nTech lead starlette Python’s super() considered super! huey apscheduler Python 3: ten years later - PyCon 2018 David Beazley - Python Concurrency From the Ground Up: LIVE! - PyCon 2015 pyflame 提问的智慧 XY 问题 Python Logger pdb PyCharm Jupyter notebook Let me google that, let me google that for you 学习操作系统的知识，看哪本书好？ PHP 黑系列之二：PHP 为什么函数命名是如此不一致？ Scheme The Little Schemer SICP CS 61A: Structure and Interpretation of Computer Programs Python Tips 本周订阅了 Real Python 的 Python Tricks，收到两封邮件，分享如下：\n1、如何一行代码合并两个字典\n# How to merge two dictionaries # in Python 3.5+ \u0026gt;\u0026gt;\u0026gt; x = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} \u0026gt;\u0026gt;\u0026gt; y = {\u0026#39;b\u0026#39;: 3, \u0026#39;c\u0026#39;: 4} \u0026gt;\u0026gt;\u0026gt; z = {**x, **y} \u0026gt;\u0026gt;\u0026gt; z {\u0026#39;c\u0026#39;: 4, \u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 3} # In Python 2.x you could # use this: \u0026gt;\u0026gt;\u0026gt; z = dict(x, **y) \u0026gt;\u0026gt;\u0026gt; z {\u0026#39;a\u0026#39;: 1, \u0026#39;c\u0026#39;: 4, \u0026#39;b\u0026#39;: 3} # In these examples, Python merges dictionary keys # in the order listed in the expression, overwriting # duplicates from left to right. # # See: https://www.youtube.com/watch?v=Duexw08KaC8 说明：\n这段代码用于将两个字典 x 和 y 合并成一个新字典 z，其中 ** 是 Python 中的解包运算符，可以将一个字典拆分成多个键值对，然后将这些键值对作为参数传递给一个函数或用于创建一个新的字典。\n在这个例子中，{**x, **y} 表示将字典 x 和 y 拆分成多个键值对，然后将这些键值对合并成一个新字典。由于字典 y 中的键 b 与字典 x 中的键 b 相同，因此在合并后的字典中，键 b 对应的值将被更新为字典 y 中的值（即 3）。\n除了上面的方法之外，还可以使用 update() 方法\nx = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} y = {\u0026#39;b\u0026#39;: 3, \u0026#39;c\u0026#39;: 4} z = x.copy() z.update(y) 在上面的代码中，首先将字典 x 复制一份到 z 中，然后使用 update() 方法将字典 y 合并到 z 中。如果字典 y 中的键在字典 x 中已经存在，则会使用字典 y 中的值来更新字典 z 中的值。最终得到一个新字典 z，它包含了字典 x 和 y 中的所有键值对。\n2、在 Python 中一次测试多个标志的不同方法\n# Different ways to test multiple # flags at once in Python x, y, z = 0, 1, 0 if x == 1 or y == 1 or z == 1: print(\u0026#39;passed\u0026#39;) if 1 in (x, y, z): print(\u0026#39;passed\u0026#39;) # These only test for truthiness: if x or y or z: print(\u0026#39;passed\u0026#39;) if any((x, y, z)): print(\u0026#39;passed\u0026#39;) 除了前面提到的四种方法外，还有其他几种方式来测试多个变量是否至少有一个等于某个值：\n使用列表解析式 x, y, z = 0, 1, 0 if any([i == 1 for i in (x, y, z)]): print(\u0026#39;passed\u0026#39;) 在上面的代码中，使用列表解析式生成一个新列表，其中包含变量 x、y、z 中每个变量是否等于 1 的布尔值。然后，使用 any() 函数来测试新列表中是否存在至少一个为真的元素，如果存在，则条件为真，执行 print() 语句。\n使用 sum() 函数 x, y, z = 0, 1, 0 if sum((i == 1 for i in (x, y, z))): print(\u0026#39;passed\u0026#39;) 在上面的代码中，使用生成器表达式生成一个新的迭代器对象，其中包含变量 x、y、z 中每个变量是否等于 1 的布尔值。然后，将迭代器对象传递给 sum() 函数，它会将所有为真的元素加起来并返回一个整数。如果返回的整数大于 0，则条件为真，执行 print() 语句。\n使用 map() 函数和 any() 函数 x, y, z = 0, 1, 0 if any(map(lambda i: i == 1, (x, y, z))): print(\u0026#39;passed\u0026#39;) 在上面的代码中，使用 map() 函数将一个匿名函数 lambda i: i == 1 应用于变量 x、y、z 中的每个元素，它会将每个元素与 1 进行比较并返回一个布尔值。然后，使用 any() 函数来测试返回的布尔值序列中是否存在至少一个为真的元素，如果存在，则条件为真，执行 print() 语句。\n使用 reduce() 方法 from functools import reduce x, y, z = 0, 1, 0 if reduce(lambda a, b: a or b, (i == 1 for i in (x, y, z))): print(\u0026#39;passed\u0026#39;) 在上面的代码中，使用生成器表达式生成一个新的迭代器对象，其中包含变量 x、y、z 中每个变量是否等于 1 的布尔值。然后，使用 reduce() 函数将一个匿名函数 lambda a, b: a or b 应用于迭代器对象中的所有元素，它会将所有元素按照布尔逻辑 or 进行聚合，并返回一个布尔值。如果返回的布尔值为真，则条件为真，执行 print() 语句。\n本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n2023-05-10 一些非常有趣的 python 爬虫例子,对新手比较友好,主要爬取淘宝、天猫、微信、微信读书、豆瓣、QQ 等网站。查看链接 #memos #python #tool 2023-05-08 这个网站整理了开发者的学习成长路线图，有比较详细的技能树，推荐学习内容等等，偏向开发者。 查看链接 #memos #tool 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/18/weekly_review_19/","summary":"前言 本篇是对 2023-05-08 到 2023-05-14 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周继续学习 python，发现一个质量非常高的 python 学习网站 Real Python，该网站有学习 python 的一些教程，是收费的，部分章节是可以免费观看的。\n另外，周五晚上老婆临时起意想去武功山看日出，于是立即规划行程并购买火车票。因为一年半之前，我去过一次，所以规划起来还是很轻松的。上一次去是国庆节碰到下雨，没有看到日出。幸运的是，这次是晴天，不仅看到了日落还看到了日出。这一次没有选择住帐篷，而是住在了云中雾客栈，没想到这个客栈离金顶需要 40 分钟左右的路程，而且有段路程是坑坑洼洼。\n去武功山之前，先去了长沙，再次游了橘子洲头，并第一次在长沙跑步打卡。本想在萍乡也跑步打卡，奈何没有得逞。\n这次去了长沙和武功山，下次基本上是再也不会去爬武功山了。长沙还会去，因为从武功山回来路上，就和老婆规划着什么时候去张家界。\n武功山看日出 理财 这周总计支出 1784 元，明细如下：\n5 月 8 日：12 元 5 月 9 日：18 元 5 月 10 日：200 元 5 月 11 日：12 元 5 月 12 日：445 元 5 月 13 日：662 元 5 月 14 日：435 元 因为周末出去旅游，所以本周支出有所增多。\n健身 本周跑步 56 公里，最长跑步距离为 13 公里。\n明细数据如下：\n周末出去旅游，路过长沙，在长沙跑了两天，累计跑了 6 公里。这样，我的跑步数据 从 2 年里我跑过 1 个省份 1 个城市 变成了 2 年里我跑过 2 个省份 2 个城市。\n工作 Java 博客 本周完成两篇博客\n《Effective Java 3》笔记 10：覆盖 equals 方法时应遵守的约定 JSR 166 规范 Python Python 初学建议 1、新手如何学习 python？","title":"周报-19｜武功山看日出、Python初学建议"},{"content":"JSR 介绍 JSR，全称 Java Specification Requests， 即 Java 规范提案， 主要是用于向 JCP(Java Community Process) 提出新增标准化技术规范的正式请求。每次 JAVA 版本更新都会有对应的 JSR 更新，比如在 Java 8 版本中，其新特性 Lambda 表达式对应的是 JSR 335，新的日期和时间 API 对应的是 JSR 310。\nJSR 166 是 Doug Lea 提出的一个关于 Java 并发编程的规范提案。JDK1.5 之前，我们控制程序并发访问同步代码只能使用 synchronized，那个时候 synchronized 的性能还没优化好，性能并不好，控制线程也只能使用 Object 的 wait 和 notify 方法。这个时候 Doug Lea 给 JCP 提交了 JSR-166 的提案，在提交 JSR-166 之前，Doug Lea 已经使用了类似 J.U.C 包功能的代码已经三年多了，这些代码就是 J.U.C 的原型。\nJ.U.C，即 java.util.concurrent 的缩写，该包参考自 EDU.oswego.cs.dl.util.concurrent，是 JSR 166 标准规范的一个实现。\nDoug Lea 主页：Doug Lea\u0026rsquo;s Home Page JSR-166：Concurrency JSR-166 Interest Site JSR 166 Slider：JSR-166: Concurrency Utilities java.util.concurrent JavaDoc: JDK 1.5 、 JDK 7 、 JDK 8 、 JDK 9 JSR-166 包括多个规范，每个规范都引入了一些新的接口和类，以下是详细描述：\nJSR-166（Java SE 5）：定义了 Java 并发包的核心接口和类，包括 Executors 框架、Queues、Timing、Synchronizers、Concurrent Collections、Memory Consistency Properties、Atomic、Locks 等。这些接口和类提供了一种方便、高效、可扩展的方式来处理异步任务和并发编程。 JSR-166x（Java SE 7）：定义了 Java 并发包中的一些新特性，包括 Phaser、TransferQueue、Exchanger、LinkedTransferQueue 等接口和类。其中 Phaser 支持分阶段执行任务，TransferQueue 和 LinkedTransferQueue 实现了高效的生产者-消费者模式，Exchanger 支持两个线程之间交换数据。 JSR-166y（Java SE 8）：定义了 Java 并发包中的一些新特性，包括 StampedLock、CompletableFuture、LongAdder 等接口和类。其中 StampedLock 是一种乐观锁，支持读写分离，CompletableFuture 支持异步任务执行和结果处理，LongAdder 是一种高效的计数器。 JSR-166z（Java SE 9）：定义了 Java 并发包中的一些新特性，包括 VarHandle、Fences 等接口和类。其中 VarHandle 提供了一种更加灵活的原子操作方式，Fences 提供了一些方法用于控制内存屏障。 JUC java.util.concurrent 包下的类以及引入版本（没有标注版本号的为 1.5 ）：\njava.util.concurrent java.util.concurrent.locks AbstractOwnableSynchronizer 1.6 AbstractQueuedLongSynchronizer 1.6 AbstractQueuedSynchronizer Condition Lock LockSupport ReadWriteLock ReentrantLock ReentrantReadWriteLock StampedLock 1.8 java.util.concurrent.atomic AtomicBoolean AtomicInteger AtomicIntegerArray AtomicIntegerFieldUpdater AtomicLong AtomicLongArray AtomicLongFieldUpdater AtomicMarkableReference AtomicReference AtomicReferenceArray AtomicReferenceFieldUpdater AtomicStampedReference DoubleAccumulator 1.8 DoubleAdder 1.8 LongAccumulator 1.8 LongAdder 1.8 AbstractExecutorService ArrayBlockingQueue BlockingDeque 1.6 BlockingQueue BrokenBarrierException Callable CancellationException CompletableFuture 1.8 CompletionException 1.8 CompletionService CompletionStage 1.8 ConcurrentHashMap ConcurrentLinkedDeque 1.7 ConcurrentLinkedQueue ConcurrentMap ConcurrentNavigableMap 1.6 ConcurrentSkipListMap 1.6 ConcurrentSkipListSet 1.6 CopyOnWriteArrayList CopyOnWriteArraySet CountDownLatch CountedCompleter 1.8 CyclicBarrier Delayed DelayQueue Exchanger ExecutionException Executor ExecutorCompletionService Executors ExecutorService Flow 1.9 ForkJoinPool 1.7 ForkJoinTask 1.7 ForkJoinWorkerThread 1.7 Future FutureTask LinkedBlockingDeque 1.6 LinkedBlockingQueue LinkedTransferQueue 1.7 Phaser 1.7 PriorityBlockingQueue RecursiveAction 1.7 RecursiveTask 1.7 RejectedExecutionException RejectedExecutionHandler RunnableFuture RunnableScheduledFuture ScheduledExecutorService ScheduledFuture ScheduledThreadPoolExecutor Semaphore SubmissionPublisher 1.9 SynchronousQueue ThreadFactory ThreadLocalRandom 1.7 ThreadPoolExecutor TimeoutException TimeUnit TransferQueue 1.7 大致可以分为以下几类：\n原子更新 锁和条件 线程池 并发容器 同步器 在学习 JUC 之前我们需要了解 CAS，AQS 和 Unsafe。\nCAS： AQS： Unsafe： CAS CAS（Compare and Swap）是一种基于原子性操作的并发编程技术，常用于实现线程安全的数据结构和算法。CAS 操作由三个参数组成：内存位置 V、期望值 A、新值 B。当且仅当 V 的值等于 A 时，CAS 操作才会将 V 的值设置为 B，否则不做任何操作。它的实现原理可以简单概括为以下几个步骤：\n读取内存位置 V 的值，同时记录下该值的版本号或标记位。 检查内存位置 V 的值是否等于期望值 A。如果相等，则执行第 3 步；否则，操作失败。 将新值 B 写入内存位置 V，并更新其版本号或标记位。 返回操作结果。 CAS 操作是一种乐观锁机制，它不需要锁定整个共享资源，而是只针对需要修改的值进行原子性操作，从而避免了锁的竞争和开销。在执行 CAS 操作时，线程会对内存位置进行读取和写入，但同时也会检查内存位置的版本号或标记位，以保证操作的原子性和一致性。\n需要注意的是，如果多个线程同时执行 CAS 操作，可能会出现 ABA 问题。例如，线程 A 读取内存位置 V 的值为 A，然后线程 B 将 V 的值修改为 B，最后线程 B 又将 V 的值修改为 A。此时，线程 A 执行 CAS 操作时，会发现内存位置 V 的值还是 A，虽然这个 A 的版本号或标记位与之前不同，但线程 A 并不知道 V 的值曾经被修改过，因此会将新值写入内存位置 V，从而导致数据不一致。为了解决 ABA 问题，可以使用带有版本号或标记位的 CAS 操作，或者使用其他的并发编程技术，例如锁或读写锁。\nJava 中的AtomicXXX类实现了 CAS 操作，例如 AtomicInteger、AtomicLong 等。这些类提供了一组原子性操作方法，例如 get()、set()、addAndGet()、compareAndSet()等，它们可以被多个线程安全地使用。\nCAS 操作虽然免去了锁的开销，但也存在一些问题。首先，CAS 操作需要进行多次尝试，直到成功为止。如果并发程度较高，多个线程同时进行 CAS 操作，可能会导致大量的 CAS 操作失败，从而降低性能。其次，CAS 操作只能保证单个变量的原子性操作，无法保证多个变量之间的操作的原子性，因此需要额外的措施来保证多个变量之间的一致性。\n下面是一个使用 AtomicInteger 实现简单计数器的例子：\nimport java.util.concurrent.atomic.AtomicInteger; public class Counter { private AtomicInteger value = new AtomicInteger(0); public void increment() { int oldValue, newValue; do { oldValue = value.get(); newValue = oldValue + 1; } while (!value.compareAndSet(oldValue, newValue)); } public int getValue() { return value.get(); } } 在上面的示例中，increment() 方法使用 do-while 循环和compareAndSet()方法执行 CAS 操作来增加计数器的值。该方法重复使用get()方法读取计数器的当前值，计算新值，然后尝试使用compareAndSet()方法更新计数器。循环将继续，直到 CAS 操作成功并且计数器成功更新。\ngetValue() 方法使用get()方法简单地返回计数器的当前值。\n需要注意的是，在使用 CAS 操作时，需要小心处理潜在的 ABA 问题，其中共享变量的值可能在初始读取和更新尝试之间多次更改。一种处理方法是在共享变量中使用版本号或时间戳，以确保更新仅在值未更改的情况下成功。\nABA 问题是在使用 CAS（Compare-and-Swap）操作进行并发编程时经常遇到的一个问题。它发生在一个线程从共享内存位置读取一个值，然后另一个线程将该值更改为另一个值，最后又将其更改回原始值，从而使第一个线程的操作意外成功。\n为了处理 ABA 问题，常用的方法是在共享内存位置中添加一个版本号或时间戳。版本号或时间戳可以在每次修改内存位置时进行递增或更新。这可以确保 CAS 操作不仅检查值，还检查内存位置的版本号或时间戳。\n以下是使用版本号处理 ABA 问题的示例：\nimport java.util.concurrent.atomic.AtomicStampedReference; public class ConcurrentStack\u0026lt;T\u0026gt; { private AtomicStampedReference\u0026lt;Node\u0026lt;T\u0026gt;\u0026gt; top = new AtomicStampedReference\u0026lt;\u0026gt;(null, 0); public void push(T value) { Node\u0026lt;T\u0026gt; newHead = new Node\u0026lt;\u0026gt;(value); int[] stampHolder = new int[1]; Node\u0026lt;T\u0026gt; oldHead; do { oldHead = top.get(stampHolder); newHead.next = oldHead; stampHolder[0]++; } while (!top.compareAndSet(oldHead, newHead, stampHolder[0] - 1, stampHolder[0])); } public T pop() { Node\u0026lt;T\u0026gt; oldHead; int[] stampHolder = new int[1]; do { oldHead = top.get(stampHolder); if (oldHead == null) { return null; } } while (!top.compareAndSet(oldHead, oldHead.next, stampHolder[0], stampHolder[0] + 1)); return oldHead.value; } private static class Node\u0026lt;T\u0026gt; { private final T value; private Node\u0026lt;T\u0026gt; next; private Node(T value) { this.value = value; } } } 在上面的示例中，ConcurrentStack 类使用 AtomicStampedReference 存储栈顶节点。AtomicStampedReference 类存储值的引用和版本号，版本号在引用更改时进行更新。\npush() 方法使用新值创建一个新的 Node，然后尝试使用 CAS 操作将其推入栈中。循环将继续，直到 CAS 操作成功，节点成功推入栈中。\npop() 方法尝试使用 CAS 操作从栈中弹出顶部节点。循环将继续，直到顶部节点成功弹出或栈为空为止。\n通过使用具有版本号的 AtomicStampedReference，ConcurrentStack 类可以处理在并发操作中可能发生的 ABA 问题。\nAQS AQS（AbstractQueuedSynchronizer）是 Java 中用于实现同步器（如锁，信号量等）的框架，它提供了一些基本的同步操作，例如获取锁、释放锁、等待条件、唤醒线程等。\nAQS 的实现原理基于一个双向链表，用于维护等待线程的队列。当一个线程需要获取同步器时，它会首先尝试使用 CAS 操作来获取同步器，如果获取成功，则继续执行；如果获取失败，则将线程加入等待队列中，并将其挂起。当同步器释放时，它会唤醒等待队列中的一个或多个线程，并将它们从等待队列中移除，使它们可以继续执行。\nAQS 的等待队列是通过一个双向链表来实现的，每个节点代表一个等待线程，节点中包含了线程的状态以及等待条件等信息。等待队列中的节点是按照等待时间的先后顺序排列的，先等待的线程排在前面，后等待的线程排在后面。当一个线程被唤醒时，它会重新尝试获取同步器，如果获取成功，则继续执行；如果获取失败，则它会再次加入等待队列中，并将自己挂起。\nAQS 的具体实现是通过重写其内部的一些方法来实现的。例如，tryAcquire() 方法用于实现获取同步器的逻辑，它会首先尝试使用 CAS 操作来获取同步器，如果获取成功，则返回 true；否则返回 false。tryRelease() 方法用于实现释放同步器的逻辑，它会释放同步器，并唤醒等待队列中的一个或多个线程。tryAcquireShared() 和 tryReleaseShared() 方法则用于实现共享式同步器的逻辑，它们类似于 tryAcquire() 和 tryRelease() 方法，但是可以支持多个线程同时获取或释放同步器。\nUnsafe Unsafe 类是 Java 中一个非常特殊且强大的类，它提供了一些不安全的操作，例如直接操作内存、线程挂起和恢复等。Unsafe 类是 Java 中少数几个不被公开支持的类之一，它主要被用于 Java 核心库和其他一些高级框架中，如 Netty、Hadoop 和 Kafka 等。\n由于 Unsafe 类提供了一些不安全的操作，因此它的使用需要非常小心。如果不正确地使用 Unsafe 类，可能会导致程序崩溃或安全漏洞。因此，Java 官方并不建议开发人员使用 Unsafe 类，而是建议开发人员使用更加安全和标准的 Java API。\nUnsafe 类中一些常用的方法包括：\nallocateMemory(long size)：分配一段指定大小的内存空间。 freeMemory(long address)：释放指定地址的内存空间。 putXXX(Object target, long offset, XXX value)：将指定类型的值写入目标对象的指定偏移量处。 getXXX(Object target, long offset)：从目标对象的指定偏移量处读取指定类型的值。 park(boolean isAbsolute, long time)：挂起当前线程，直到被其他线程唤醒或指定的时间到期。 unpark(Thread thread)：恢复指定线程的运行。 需要注意的是，Unsafe 类中的大部分方法都是 native 方法，实现方式依赖于底层操作系统和硬件平台。这意味着 Unsafe 类中的方法在不同的平台上可能会有不同的行为，因此需要针对不同的平台进行测试和验证。\nJava 9 中官方提出了移除 Sun.misc.Unsafe 类，并在该版本中将该类标记为不推荐使用。然而，由于 Unsafe 类在 Java 语言生态中的应用非常广泛，许多框架和库都依赖于 Unsafe 类来实现高性能和低层次的操作。因此，在 Java 9 中，官方引入了 jdk.internal.misc.Unsafe 类来替代 Sun.misc.Unsafe 类的功能，以保持对 Java 生态中使用 Unsafe 类的支持。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/18/jsr-166/","summary":"JSR 介绍 JSR，全称 Java Specification Requests， 即 Java 规范提案， 主要是用于向 JCP(Java Community Process) 提出新增标准化技术规范的正式请求。每次 JAVA 版本更新都会有对应的 JSR 更新，比如在 Java 8 版本中，其新特性 Lambda 表达式对应的是 JSR 335，新的日期和时间 API 对应的是 JSR 310。\nJSR 166 是 Doug Lea 提出的一个关于 Java 并发编程的规范提案。JDK1.5 之前，我们控制程序并发访问同步代码只能使用 synchronized，那个时候 synchronized 的性能还没优化好，性能并不好，控制线程也只能使用 Object 的 wait 和 notify 方法。这个时候 Doug Lea 给 JCP 提交了 JSR-166 的提案，在提交 JSR-166 之前，Doug Lea 已经使用了类似 J.U.C 包功能的代码已经三年多了，这些代码就是 J.U.C 的原型。\nJ.U.C，即 java.util.concurrent 的缩写，该包参考自 EDU.oswego.cs.dl.util.concurrent，是 JSR 166 标准规范的一个实现。\nDoug Lea 主页：Doug Lea\u0026rsquo;s Home Page JSR-166：Concurrency JSR-166 Interest Site JSR 166 Slider：JSR-166: Concurrency Utilities java.util.concurrent JavaDoc: JDK 1.5 、 JDK 7 、 JDK 8 、 JDK 9 JSR-166 包括多个规范，每个规范都引入了一些新的接口和类，以下是详细描述：\nJSR-166（Java SE 5）：定义了 Java 并发包的核心接口和类，包括 Executors 框架、Queues、Timing、Synchronizers、Concurrent Collections、Memory Consistency Properties、Atomic、Locks 等。这些接口和类提供了一种方便、高效、可扩展的方式来处理异步任务和并发编程。 JSR-166x（Java SE 7）：定义了 Java 并发包中的一些新特性，包括 Phaser、TransferQueue、Exchanger、LinkedTransferQueue 等接口和类。其中 Phaser 支持分阶段执行任务，TransferQueue 和 LinkedTransferQueue 实现了高效的生产者-消费者模式，Exchanger 支持两个线程之间交换数据。 JSR-166y（Java SE 8）：定义了 Java 并发包中的一些新特性，包括 StampedLock、CompletableFuture、LongAdder 等接口和类。其中 StampedLock 是一种乐观锁，支持读写分离，CompletableFuture 支持异步任务执行和结果处理，LongAdder 是一种高效的计数器。 JSR-166z（Java SE 9）：定义了 Java 并发包中的一些新特性，包括 VarHandle、Fences 等接口和类。其中 VarHandle 提供了一种更加灵活的原子操作方式，Fences 提供了一些方法用于控制内存屏障。 JUC java.","title":"JSR 166规范"},{"content":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：覆盖 equals 方法时应遵守的约定。\n介绍 覆盖 equals 方法似乎很简单，但是有很多覆盖的方式会导致出错，而且后果可能非常严重。避免问题的最简单方法是不覆盖 equals 方法，在这种情况下，类的每个实例都只等于它自己。如果符合下列任何条件，就是正确的做法：\n类的每个实例本质上都是唯一的。 对于像 Thread 这样表示活动实体类而不是值类来说也是如此。Object 提供的 equals 实现对于这些类具有完全正确的行为。\n该类不需要提供「逻辑相等」测试。 例如，java.util.regex.Pattern 可以覆盖 equals 来检查两个 Pattern 实例是否表示完全相同的正则表达式，但设计人员认为客户端不需要或不需要这个功能。在这种情况下，从 Object 继承的 equals 实现是理想的。\n超类已经覆盖了 equals，超类行为适合于这个类。 例如，大多数 Set 的实现从 AbstractSet 继承其对等实现，List 从 AbstractList 继承实现，Map 从 AbstractMap 继承实现。\n类是私有的或包私有的，并且你确信它的 equals 方法永远不会被调用。 如果你非常厌恶风险，你可以覆盖 equals 方法，以确保它不会意外调用：\n@Override public boolean equals(Object o) { throw new AssertionError(); // Method is never called } 什么时候覆盖 equals 方法是合适的？当一个类有一个逻辑相等的概念，而这个概念不同于仅判断对象的同一性（相同对象的引用），并且超类还没有覆盖 equals。对于值类通常是这样。值类只是表示值的类，例如 Integer 或 String。使用 equals 方法比较引用和值对象的程序员希望发现它们在逻辑上是否等价，而不是它们是否引用相同的对象。覆盖 equals 方法不仅是为了满足程序员的期望，它还使实例能够作为 Map 的键或 Set 元素时，具有可预测的、理想的行为。\n有一个表示状态的内部类。没有覆盖 equals 方法时，equals 的结果与 s1==s2 相同，为 false，即两者并不是相同对象的引用。\npublic static void main(String[] args) { class Status { public String status; } Status s1 = new Status(); Status s2 = new Status(); System.out.println(s1==s2); // false System.out.println(s1.equals(s2)); // false } 覆盖 equals 方法后，以业务逻辑来判断是否相同，具备相同 status 字段即为相同。在使用去重功能时，也以此作为判断依据。\npublic static void main(String[] args) { class Status { public String status; @Override public boolean equals(Object o) { return Objects.equals(status, ((Status) o).status); } } Status s1 = new Status(); Status s2 = new Status(); System.out.println(s1==s2); // false System.out.println(s1.equals(s2)); // true } 不需要覆盖 equals 方法的一种值类是使用实例控件来确保每个值最多只存在一个对象的类。枚举类型属于这一类。对于这些类，逻辑相等与对象标识相同，因此对象的 equals 方法函数与逻辑 equals 方法相同。\n当你覆盖 equals 方法时，你必须遵守它的通用约定。以下是具体内容，来自 Object 规范：equals 方法实现了等价关系。它应有这些属性：\n反射性：对于任何非空的参考值 x，x.equals(x) 必须返回 true。 对称性：对于任何非空参考值 x 和 y，x.equals(y) 必须在且仅当 y.equals(x) 返回 true 时返回 true。 传递性：对于任何非空的引用值 x, y, z，如果 x.equals(y) 返回 true，y.equals(z) 返回 true，那么 x.equals(z) 必须返回 true。 一致性：对于任何非空的引用值 x 和 y, x.equals(y) 的多次调用必须一致地返回 true 或一致地返回 false，前提是不修改 equals 中使用的信息。 对于任何非空引用值 x，x.equals(null) 必须返回 false。 除非你有数学方面的倾向，否则这些起来有点可怕，但不要忽略它！如果你违反了它，你的程序很可能会出现行为异常或崩溃，并且很难确定失败的根源。用 John Donne 的话来说，没有一个类是孤立的。一个类的实例经常被传递给另一个类。许多类（包括所有集合类）依赖于传递给它们的对象遵守 equals 约定。\n既然你已经意识到了违反 equals 约定的危险，让我们详细讨论一下。好消息是，尽管表面上看起来很复杂，但其实并不复杂。一旦你明白了，就不难坚持下去了。\n什么是等价关系？简单地说，它是一个操作符，它将一组元素划分为子集，子集的元素被认为是彼此相等的。这些子集被称为等价类。为了使 equals 方法有用，从用户的角度来看，每个等价类中的所有元素都必须是可互换的。现在让我们依次检查以下五个需求：\n反射性 ，第一个要求仅仅是说一个对象必须等于它自己。很难想象会无意中违反了这条规则。如果你违反了它，然后将类的一个实例添加到集合中，contains 方法很可能会说该集合不包含你刚才添加的实例。\n对称性 ，第二个要求是任何两个对象必须在是否相等的问题上达成一致。与第一个要求不同，无意中违反了这个要求的情况不难想象。例如，考虑下面的类，它实现了不区分大小写的字符串。字符串的情况是保留的 toString，但忽略在 equals 的比较：\n// Broken - violates symmetry! public final class CaseInsensitiveString { private final String s; public CaseInsensitiveString(String s) { this.s = Objects.requireNonNull(s); } // Broken - violates symmetry! @Override public boolean equals(Object o) { if (o instanceof CaseInsensitiveString) return s.equalsIgnoreCase(((CaseInsensitiveString) o).s); if (o instanceof String) // One-way interoperability! return s.equalsIgnoreCase((String) o); return false; } ... // Remainder omitted } 这个类中的 equals 方法天真地尝试与普通字符串进行互操作。假设我们有一个不区分大小写的字符串和一个普通字符串：\nCaseInsensitiveString cis = new CaseInsensitiveString(\u0026#34;Polish\u0026#34;); String s = \u0026#34;polish\u0026#34;; 正如预期的那样，cis.equals(s) 返回 true。问题是，虽然 CaseInsensitiveString 中的 equals 方法知道普通字符串，但是 String 中的 equals 方法对不区分大小写的字符串不知情。因此，s.equals(cis) 返回 false，这明显违反了对称性。假设你将不区分大小写的字符串放入集合中：\nList\u0026lt;CaseInsensitiveString\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); list.add(cis); 此时 list.contains(s) 返回什么？谁知道呢？在当前的 OpenJDK 实现中，它碰巧返回 false，但这只是一个实现案例。在另一个实现中，它可以很容易地返回 true 或抛出运行时异常。一旦你违反了 equals 约定，就不知道当其他对象面对你的对象时，会如何表现。\ncontains 方法在 ArrayList 中的实现源码如下\n// ArrayList 的大小 private int size; // 保存 ArrayList 元素的容器，一个 Object 数组 transient Object[] elementData; // non-private to simplify nested class access public boolean contains(Object o) { return indexOf(o) \u0026gt;= 0; } public int indexOf(Object o) { return indexOfRange(o, 0, size); } int indexOfRange(Object o, int start, int end) { Object[] es = elementData; if (o == null) { for (int i = start; i \u0026lt; end; i++) { if (es[i] == null) { return i; } } } else { for (int i = start; i \u0026lt; end; i++) { if (o.equals(es[i])) { return i; } } } return -1; } ​ 为了消除这个问题，只需从 equals 方法中删除与 String 互操作的错误尝试。一旦你这样做了，你可以重构方法为一个单一的返回语句：\n@Override public boolean equals(Object o) { return o instanceof CaseInsensitiveString \u0026amp;\u0026amp; ((CaseInsensitiveString) o).s.equalsIgnoreCase(s); } 传递性 ，equals 约定的第三个要求是，如果一个对象等于第二个对象，而第二个对象等于第三个对象，那么第一个对象必须等于第三个对象。同样，无意中违反了这个要求的情况不难想象。考虑向超类添加新的值组件时，子类的情况。换句话说，子类添加了一条影响 equals 比较的信息。让我们从一个简单的不可变二维整数点类开始：\npublic class Point { private final int x; private final int y; public Point(int x, int y) { this.x = x; this.y = y; } @Override public boolean equals(Object o) { if (!(o instanceof Point)) return false; Point p = (Point)o; return p.x == x \u0026amp;\u0026amp; p.y == y; } ... // Remainder omitted } 假设你想继承这个类，对一个点添加颜色的概念：\npublic class ColorPoint extends Point { private final Color color; public ColorPoint(int x, int y, Color color) { super(x, y); this.color = color; } ... // Remainder omitted } equals 方法应该是什么样子？如果你完全忽略它，则实现将从 Point 类继承而来，在 equals 比较中颜色信息将被忽略。虽然这并不违反 equals 约定，但显然是不可接受的。假设你写了一个 equals 方法，该方法只有当它的参数是另一个颜色点，且位置和颜色相同时才返回 true：\n// Broken - violates symmetry! @Override public boolean equals(Object o) { if (!(o instanceof ColorPoint)) return false; return super.equals(o) \u0026amp;\u0026amp; ((ColorPoint) o).color == color; } 这种方法的问题是，当你比较一个点和一个颜色点时，你可能会得到不同的结果，反之亦然。前者比较忽略颜色，而后者比较总是返回 false，因为参数的类型是不正确的。为了使问题更具体，让我们创建一个点和一个颜色点：\nPoint p = new Point(1, 2); ColorPoint cp = new ColorPoint(1, 2, Color.RED); 然后，p.equals(cp) 返回 true，而 cp.equals(p) 返回 false。当你做「混合比较」的时候，你可以通过让 ColorPoint.equals 忽略颜色来解决这个问题：\n// Broken - violates transitivity! @Override public boolean equals(Object o) { if (!(o instanceof Point)) return false; // If o is a normal Point, do a color-blind comparison if (!(o instanceof ColorPoint)) return o.equals(this); // o is a ColorPoint; do a full comparison return super.equals(o) \u0026amp;\u0026amp; ((ColorPoint) o).color == color; } 这种方法确实提供了对称性，但牺牲了传递性：\nColorPoint p1 = new ColorPoint(1, 2, Color.RED); Point p2 = new Point(1, 2); ColorPoint p3 = new ColorPoint(1, 2, Color.BLUE); 现在，p1.equals(p2) 和 p2.equals(p3) 返回 true，而 p1.equals(p3) 返回 false，这明显违反了传递性。前两个比较是「色盲」，而第三个比较考虑了颜色。\n同样，这种方法会导致无限的递归：假设有两个点的子类，比如 ColorPoint 和 SmellPoint，每个都使用这种 equals 方法。然后调用 myColorPoint.equals(mySmellPoint) 会抛出 StackOverflowError。\n那么解决方案是什么？这是面向对象语言中等价关系的一个基本问题。除非你愿意放弃面向对象的抽象优点，否则无法继承一个可实例化的类并添加一个值组件，同时保留 equals 约定。\n你可能会听到它说你可以继承一个实例化的类并添加一个值组件，同时通过在 equals 方法中使用 getClass 测试来代替 instanceof 测试来保持 equals 约定：\n// Broken - violates Liskov substitution principle (page 43) @Override public boolean equals(Object o) { if (o == null || o.getClass() != getClass()) return false; Point p = (Point) o; return p.x == x \u0026amp;\u0026amp; p.y == y; } 只有当对象具有相同的实现类时，才会产生相等的效果。这可能看起来不是很糟糕，但其后果是不可接受的：Point 的子类的实例仍然是一个 Point，并且它仍然需要作为一个函数来工作，但是如果采用这种方法，它就不会这样做！假设我们要写一个方法来判断一个点是否在单位圆上。我们可以这样做：\n// Initialize unitCircle to contain all Points on the unit circle private static final Set\u0026lt;Point\u0026gt; unitCircle = Set.of( new Point( 1, 0), new Point( 0, 1), new Point(-1, 0), new Point( 0, -1) ); public static boolean onUnitCircle(Point p) { return unitCircle.contains(p); } 虽然这可能不是实现功能的最快方法，但它工作得很好。假设你以一种不添加值组件的简单方式继承 Point，例如，让它的构造函数跟踪创建了多少实例：\npublic class CounterPoint extends Point { private static final AtomicInteger counter = new AtomicInteger(); public CounterPoint(int x, int y) { super(x, y); counter.incrementAndGet(); } public static int numberCreated() { return counter.get(); } } Liskov 替换原则指出，类型的任何重要属性都应该适用于所有子类型，因此为类型编写的任何方法都应该在其子类型上同样有效。这是我们先前做的正式声明，即点的子类（如 CounterPoint）仍然是一个 Point，并且必须作为一个 Point。但假设我们传递了一个 CounterPoint 给 onUnitCircle 方法。如果 Point 类使用基于 getclass 的 equals 方法，那么不管 CounterPoint 实例的 x 和 y 坐标如何，onUnitCircle 方法都会返回 false。这是因为大多数集合，包括 onUnitCircle 方法使用的 HashSet，都使用 equals 方法来测试包含性，没有一个 CounterPoint 实例等于任何一个点。但是，如果你在 Point 上使用了正确的基于实例的 equals 方法，那么在提供对位实例时，相同的 onUnitCircle 方法就可以很好地工作。\n里氏替换原则（Liskov Substitution Principle，LSP）面向对象设计的基本原则之一。里氏替换原则指出：任何父类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当衍生类可以替换掉父类，软件单位的功能不受到影响时，父类才能真正被复用，而衍生类也能够在父类的基础上增加新的行为。\n虽然没有令人满意的方法来继承一个可实例化的类并添加一个值组件，但是有一个很好的解决方案：遵循的建议，「Favor composition over inheritance.」。给 ColorPoint 一个私有的 Point 字段和一个 public 视图方法，而不是让 ColorPoint 继承 Point，该方法返回与这个颜色点相同位置的点：\n// Adds a value component without violating the equals contract public class ColorPoint { private final Point point; private final Color color; public ColorPoint(int x, int y, Color color) { point = new Point(x, y); this.color = Objects.requireNonNull(color); } /** * Returns the point-view of this color point. */ public Point asPoint() { return point; } @Override public boolean equals(Object o) { if (!(o instanceof ColorPoint)) return false; ColorPoint cp = (ColorPoint) o; return cp.point.equals(point) \u0026amp;\u0026amp; cp.color.equals(color); } ... // Remainder omitted } Java 库中有一些类确实继承了一个可实例化的类并添加了一个值组件。例如，java.sql.Timestamp 继承 java.util.Date 并添加了纳秒字段。如果在同一个集合中使用时间戳和日期对象，或者以其他方式混合使用时间戳和日期对象，那么时间戳的 equals 实现确实违反了对称性，并且可能导致不稳定的行为。Timestamp 类有一个免责声明，警告程序员不要混合使用日期和时间戳。虽然只要将它们分开，就不会遇到麻烦，但是没有什么可以阻止你将它们混合在一起，因此产生的错误可能很难调试。时间戳类的这种行为是错误的，不应该效仿。\n注意，你可以向抽象类的子类添加一个值组件，而不违反 equals 约定。这对于遵循中的建议而得到的类层次结构很重要，「Prefer class hierarchies to tagged classes.」。例如，可以有一个没有值组件的抽象类形状、一个添加半径字段的子类圆和一个添加长度和宽度字段的子类矩形。只要不可能直接创建超类实例，前面显示的那种问题就不会发生。\n非无效性 ，最后的要求没有一个正式的名称，所以我冒昧地称之为「非无效性」。它说所有对象都不等于 null。虽然很难想象在响应调用 o.equals(null) 时意外地返回 true，但不难想象意外地抛出 NullPointerException。一般约定中禁止这样做。许多类都有相等的方法，通过显式的 null 测试来防止它：\n@Override public boolean equals(Object o) { if (o == null) return false; ... } 这个测试是不必要的。要测试其参数是否相等，equals 方法必须首先将其参数转换为适当的类型，以便能够调用其访问器或访问其字段。在执行转换之前，方法必须使用 instanceof 运算符来检查其参数的类型是否正确：\n如果缺少这个类型检查，并且 equals 方法传递了一个错误类型的参数，equals 方法将抛出 ClassCastException，这违反了 equals 约定。但是，如果 instanceof 操作符的第一个操作数为空，则指定该操作符返回 false，而不管第二个操作数中出现的是什么类型。因此，如果传入 null，类型检查将返回 false，因此不需要显式的 null 检查。\n综上所述，这里有一个高质量构建 equals 方法的秘诀：\n1、使用 == 运算符检查参数是否是对该对象的引用。 如果是，返回 true。这只是一种性能优化，但如果比较的代价可能很高，那么这种优化是值得的。\n2、使用 instanceof 运算符检查参数是否具有正确的类型。 如果不是，返回 false。通常，正确的类型是方法发生的类。有时候，它是由这个类实现的某个接口。如果类实现了一个接口，该接口对 equals 约定进行了改进，以允许跨实现该接口的类进行比较，则使用该接口。集合接口，如 Set、List、Map 和 Map.Entry 具有此属性。\n3、将参数转换为正确的类型。 因为在这个强制类型转换之前有一个实例测试，所以它肯定会成功。\n4、对于类中的每个「重要」字段，检查参数的字段是否与该对象的相应字段匹配。 如果所有这些测试都成功，返回 true；否则返回 false。如果第 2 步中的类型是接口，则必须通过接口方法访问参数的字段；如果是类，你可以根据字段的可访问性直接访问它们。\n对于类型不是 float 或 double 的基本类型字段，使用 == 运算符进行比较；对于对象引用字段，递归调用 equals 方法；对于 float 字段，使用 static Float.compare(float,float) 方法；对于 double 字段，使用 Double.compare(double, double)。float 和 double 字段的特殊处理是由于 Float.NaN、-0.0f 和类似的双重值的存在而必须的；请参阅 Float.equals文档。虽然你可以将 float 和 double 字段与静态方法 Float.equals 和 Double.equals 进行比较，这将需要在每个比较上进行自动装箱，这将有较差的性能。对于数组字段，将这些指导原则应用于每个元素。如果数组字段中的每个元素都很重要，那么使用Arrays.equals` 方法之一。\n一些对象引用字段可能合法地包含 null。为了避免可能出现 NullPointerException，请使用静态方法 Objects.equals(Object, Object) 检查这些字段是否相等。\n对于某些类，例如上面的 CaseInsensitiveString，字段比较比简单的 equal 测试更复杂。如果是这样，你可能希望存储字段的规范形式，以便 equals 方法可以对规范形式进行廉价的精确比较，而不是更昂贵的非标准比较。这种技术最适合于不可变类；如果对象可以更改，则必须使规范形式保持最新。\nequals 方法的性能可能会受到字段比较顺序的影响。为了获得最佳性能，你应该首先比较那些更可能不同、比较成本更低的字段，或者理想情况下两者都比较。不能比较不属于对象逻辑状态的字段，例如用于同步操作的锁字段。你不需要比较派生字段（可以从「重要字段」计算），但是这样做可能会提高 equals 方法的性能。如果派生字段相当于整个对象的摘要描述，那么如果比较失败，比较该字段将节省比较实际数据的开销。例如，假设你有一个多边形类，你缓存这个区域。如果两个多边形的面积不相等，你不需要比较它们的边和顶点。\n写完 equals 方法后，问自己三个问题：它具备对称性吗？具备传递性吗？具备一致性吗？ 不要只问自己，要编写单元测试来检查，除非使用 AutoValue（第 49 页）来生成 equals 方法，在这种情况下，你可以安全地省略测试。如果属性不能保持，请找出原因，并相应地修改 equals 方法。当然，equals 方法还必须满足其他两个属性（反射性和非无效性），但这两个通常会自己处理。\n在这个简单的 PhoneNumber 类中，根据前面的方法构造了一个 equals 方法：\n// Class with a typical equals method public final class PhoneNumber { private final short areaCode, prefix, lineNum; public PhoneNumber(int areaCode, int prefix, int lineNum) { this.areaCode = rangeCheck(areaCode, 999, \u0026#34;area code\u0026#34;); this.prefix = rangeCheck(prefix, 999, \u0026#34;prefix\u0026#34;); this.lineNum = rangeCheck(lineNum, 9999, \u0026#34;line num\u0026#34;); } private static short rangeCheck(int val, int max, String arg) { if (val \u0026lt; 0 || val \u0026gt; max) throw new IllegalArgumentException(arg + \u0026#34;: \u0026#34; + val); return (short) val; } @Override public boolean equals(Object o) { if (o == this) return true; if (!(o instanceof PhoneNumber)) return false; PhoneNumber pn = (PhoneNumber)o; return pn.lineNum == lineNum \u0026amp;\u0026amp; pn.prefix == prefix \u0026amp;\u0026amp; pn.areaCode == areaCode; } ... // Remainder omitted } 以下是一些最后的警告：\n当你覆盖 equals 时，也覆盖 hashCode。\n不要自作聪明。 如果你只是为了判断相等性而测试字段，那么遵循 equals 约定并不困难。如果你在寻求对等方面过于激进，很容易陷入麻烦。一般来说，考虑到任何形式的混叠都不是一个好主意。例如，File 类不应该尝试将引用同一文件的符号链接等同起来。值得庆幸的是，它不是。\n不要用另一种类型替换 equals 声明中的对象。 对于程序员来说，编写一个类似于这样的 equals 方法，然后花上几个小时思考为什么它不能正常工作是很常见的：\n// Broken - parameter type must be Object! public boolean equals(MyClass o) { ... } 这里的问题是，这个方法没有覆盖其参数类型为 Object 的 Object.equals，而是重载了它。即使是普通的方法，提供这样一个「强类型的」equals 方法是不可接受的，因为它会导致子类中的重写注释产生误报并提供错误的安全性。\n如本条目所示，一致使用 Override 注释将防止你犯此错误。这个 equals 方法不会编译，错误消息会告诉你什么是错误的：\n// Still broken, but won’t compile @Override public boolean equals(MyClass o) { ... } 编写和测试 equals （和 hashCode）方法很乏味，生成的代码也很单调。手动编写和测试这些方法的一个很好的替代方法是使用谷歌的开源 AutoValue 框架，它会自动为你生成这些方法，由类上的一个注释触发。在大多数情况下，AutoValue 生成的方法与你自己编写的方法基本相同。\nIDE 也有生成 equals 和 hashCode 方法的功能，但是生成的源代码比使用 AutoValue 的代码更冗长，可读性更差，不会自动跟踪类中的变化，因此需要进行测试。也就是说，让 IDE 生成 equals（和 hashCode）方法通常比手动实现更可取，因为 IDE 不会出现粗心的错误，而人会。\n总之，除非必须，否则不要覆盖 equals 方法：在许多情况下，从 Object 继承而来的实现正是你想要的。如果你确实覆盖了 equals，那么一定要比较类的所有重要字段，并以保留 equals 约定的所有 5 项规定的方式进行比较。\n总结 《Effective Java》第三版的第 10 条内容讲解了在重写 Java 中的equals方法时，遵循通用协定的重要性。equals方法用于确定两个对象是否相等。\n通用协定定义了equals方法必须具有以下特性：\n反射性：对于任何非空的x，x.equals(x)必须返回true。 对称性：对于任何非空引用x和y，如果x.equals(y)返回true，则y.equals(x)必须返回true。 传递性：对于任何非空引用x、y和z，如果x.equals(y)返回true并且y.equals(z)返回true，则x.equals(z)必须返回true。 一致性：对于任何非空引用x和y，多次调用x.equals(y)必须始终返回true或始终返回false，前提是在 equals 比较中使用的信息未被修改。 可空性：对于任何非空引用x，x.equals(null)必须返回false。 在重写equals方法时，重要的是要确保满足这些特性。此外，建议遵循一些最佳实践，例如：\n比较前检查引用是否相同：如果两个对象引用相同，即它们指向同一个对象，那么它们一定相等。在比较两个对象之前，首先使用==运算符检查它们的引用是否相同，以提高效率。\n比较对象类型：在比较两个对象之前，首先使用instanceof运算符检查它们是否属于同一个类。如果不是，那么它们不可能相等。这样可以避免在继承层次结构中出现问题。\n比较每个重要字段：在比较两个对象时，需要比较它们的每个重要字段。对于基本类型字段，使用==运算符进行比较；对于对象引用字段，递归调用Objects.equals()方法比较；对于float和double类型的字段，使用Float.compare和Double.compare方法进行比较；对于数组字段，使用Arrays.equals方法进行比较。\n覆盖hashCode方法：根据通用协定，如果两个对象相等，它们的hashCode值也必须相等。因此，在重写equals方法时，通常也需要重写hashCode方法，以确保对象的相等性被正确地判断，并且避免散列表中出现哈希冲突。\n考虑使用@Override注释指示您正在覆盖equals方法。\n不将equals方法定义为只接受特定类型的参数：equals方法的参数类型应该是Object类型，而不是具体的类或接口类型。这样可以确保equals方法可以比较任何类型的对象，而不仅仅是特定类型的对象。\n不使用getClass方法比较对象类型：在比较两个对象的类型时，不应该使用getClass方法，而应该使用instanceof运算符。这是因为getClass方法可能会被子类重写，并返回不同的结果，从而导致比较结果出现问题。\n不将equals方法与==运算符混淆：equals方法用于比较对象的内容，而==运算符用于比较对象的引用。在比较两个对象时，应该使用equals方法而不是==运算符。\n不将equals方法与compareTo方法混淆：equals方法用于比较对象的内容，而compareTo方法用于比较对象的顺序。在比较两个对象时，应该使用适当的方法，避免混淆它们的作用。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/17/obey-the-general-contract-when-overriding-equals/","summary":"本文是 《Effective Java 3》第三章《对象的通用方法》的学习笔记：覆盖 equals 方法时应遵守的约定。\n介绍 覆盖 equals 方法似乎很简单，但是有很多覆盖的方式会导致出错，而且后果可能非常严重。避免问题的最简单方法是不覆盖 equals 方法，在这种情况下，类的每个实例都只等于它自己。如果符合下列任何条件，就是正确的做法：\n类的每个实例本质上都是唯一的。 对于像 Thread 这样表示活动实体类而不是值类来说也是如此。Object 提供的 equals 实现对于这些类具有完全正确的行为。\n该类不需要提供「逻辑相等」测试。 例如，java.util.regex.Pattern 可以覆盖 equals 来检查两个 Pattern 实例是否表示完全相同的正则表达式，但设计人员认为客户端不需要或不需要这个功能。在这种情况下，从 Object 继承的 equals 实现是理想的。\n超类已经覆盖了 equals，超类行为适合于这个类。 例如，大多数 Set 的实现从 AbstractSet 继承其对等实现，List 从 AbstractList 继承实现，Map 从 AbstractMap 继承实现。\n类是私有的或包私有的，并且你确信它的 equals 方法永远不会被调用。 如果你非常厌恶风险，你可以覆盖 equals 方法，以确保它不会意外调用：\n@Override public boolean equals(Object o) { throw new AssertionError(); // Method is never called } 什么时候覆盖 equals 方法是合适的？当一个类有一个逻辑相等的概念，而这个概念不同于仅判断对象的同一性（相同对象的引用），并且超类还没有覆盖 equals。对于值类通常是这样。值类只是表示值的类，例如 Integer 或 String。使用 equals 方法比较引用和值对象的程序员希望发现它们在逻辑上是否等价，而不是它们是否引用相同的对象。覆盖 equals 方法不仅是为了满足程序员的期望，它还使实例能够作为 Map 的键或 Set 元素时，具有可预测的、理想的行为。\n有一个表示状态的内部类。没有覆盖 equals 方法时，equals 的结果与 s1==s2 相同，为 false，即两者并不是相同对象的引用。\npublic static void main(String[] args) { class Status { public String status; } Status s1 = new Status(); Status s2 = new Status(); System.","title":"《Effective Java 3》笔记10：覆盖equals方法时应遵守的约定"},{"content":"介绍 Git Flow 是由 Vincent Driessen 在 2010 年提出的一种 Git 工作流。在这之前，Git 没有一个明确的标准工作流，导致团队在使用 Git 时往往会遇到一些问题，如分支管理、版本控制等。为了解决这些问题，Vincent Driessen 提出了 Git Flow 分支模型，成为了 Git 在实际应用中的一种标准工作流。\n随着时间的推移，Git Flow 也在不断发展和完善。在 2011 年，Atlassian 发布了 SourceTree，这是一款图形化的 Git 客户端，支持 Git Flow 分支模型。在 2013 年，Git Flow 的一些开发者发布了 Git Flow AVH Edition，这是 Git Flow 的一个增强版本，提供了更多的功能和选项。此外，Git Flow 还得到了其他开源工具和平台的支持，如 GitHub、GitLab 等。\nGit Flow 分支模型 Git Flow 分支模型定义了一种标准的 Git 分支模型，它将代码分为两个长期分支（master 和 develop）和三个短期分支（feature、release 和 hotfix），使得团队可以更好地管理代码的版本和发布。\n以下是 Git Flow 分支模型的详细介绍：\nmaster 分支 master 分支是代码库的主分支，它包含了所有已发布的代码和版本。所有代码都应该在该分支上进行测试和验证，以确保代码的质量和稳定性。master分支只能通过合并release或hotfix分支来更新。 develop 分支 develop 分支是代码库的开发分支，它包含了所有开发中的代码和功能。所有新的代码都应该在该分支上进行开发和测试，以确保代码的可靠性和稳定性。develop分支只能通过合并feature分支来更新。 feature 分支 feature 分支是为开发新的功能或修复 bug 而创建的临时分支。每个feature分支都是从develop分支分离出来的，开发完成后会合并回develop分支。feature 分支的命名应该清晰明确，以反映该分支所涉及的功能或问题。 release 分支 release 分支是为发布新版本而创建的临时分支。每个release分支都是从develop分支分离出来的，发布完成后会合并回develop分支和master分支。在 release 分支上可以进行一些小的修复和调整，以确保发布的代码的质量和稳定性。 hotfix 分支 hotfix 分支是为快速修复生产环境中的问题而创建的临时分支。每个 hotfix 分支都是从 master 分支分离出来的，修复完成后会合并回 develop 分支和 master 分支。hotfix分支的优先级比其他分支更高，因为它们需要尽快修复生产环境中的问题。 根据上面的理论，我们来实际操作一遍。首先，是 develop 分支创建一个 feature 分支。\n$ git checkout -b feature-test develop Switched to a new branch \u0026#34;feature-test\u0026#34; 将 feature 分支的修改合并到 develop 分支，然后删除 feature 分支：\n$ git checkout develop Switched to branch \u0026#39;develop\u0026#39; $ git merge --no-ff feature-test Updating ea1b82a..05e9557 (Summary of changes) $ git branch -d feature-test Deleted branch feature-test (was 05e9557). $ git push origin develop 合并分支时，添加--no-ff 参数和不添加的区别：\n从 develop 分支创建一个 release 分支，并将版本号改为 1.2 ：\n$ git checkout -b release-1.2 develop Switched to a new branch \u0026#34;release-1.2\u0026#34; $ ./bump-version.sh 1.2 Files modified successfully, version bumped to 1.2. $ git commit -a -m \u0026#34;Bumped version number to 1.2\u0026#34; [release-1.2 74d9424] Bumped version number to 1.2 1 files changed, 1 insertions(+), 1 deletions(-) release 分支完成开发之后，将 release 分支合并到 master 分支，并创建一个标签：\n$ git checkout master Switched to branch \u0026#39;master\u0026#39; $ git merge --no-ff release-1.2 Merge made by recursive. (Summary of changes) $ git tag -a 1.2 将 release 分支合并到 develop 分支：\n$ git checkout develop Switched to branch \u0026#39;develop\u0026#39; $ git merge --no-ff release-1.2 Merge made by recursive. (Summary of changes) 最后删除 release 分支：\n$ git branch -d release-1.2 Deleted branch release-1.2 (was ff452fe). 对于 hoftfix 分支，操作步骤和 release 分支类似，故不在赘述。\ngit-flow 工具 git-flow 工具可以简化上面的操作步骤，关于 git-flow 的介绍可以参考文章：Using git-flow to automate your git branching workflow。\nmacos 上安装 git-flow：\nbrew install git-flow git-flow 首先需要初始化，如果不存在 develop 分支，则会新建一个 develop 分支：\ngit flow init No branches exist yet. Base branches must be created now. Branch name for production releases: [master] Branch name for \u0026#34;next release\u0026#34; development: [develop] How to name your supporting branch prefixes? Feature branches? [feature-] Release branches? [release-] Hotfix branches? [hotfix/] Support branches? [support/] Version tag prefix? [] feature 分支 开发一个新功能，创建一个新分支 foo\n$ git flow feature start foo 等价于\n#切换到develop分支,确保新的 feature 分支是基于最新的 develop 分支创建的。 $ git checkout -b feature-foo develop 取消正在进行中的功能分支，并且会将分支删除\n$ git flow feature delete foo 等价于\n$ git branch -D feature-foo foo 功能自测通过后，合并到 develop\n$ git flow feature finish foo 等价于\n//切换到 develop 分支 $ git checkout develop //将 feature-foo 分支中的更改合并到 develop 分支。 --no-ff 参数将保留 foo 分支的commit记录。 $ git merge --no-ff feature-foo //删除已完成的分支 $ git branch -d feature-foo release 分支 当所有新的功能和必要的修复已经被彻底的测试过了，那就开始生成一个新的 release , 在此之后不能添加新功能，只有错误修复、文档生成和其他面向发布的任务应该在该分支中进行。\n# 1.0.0 是版本号 $ git flow release start 1.0.0 等价于\n# 从 develop 分支 创建release分支 $ git checkout -b release-1.0.0 develop 取消正在进行中的发布分支，并且会将分支删除。\n$ git flow release delete 1.0.0 等价于\ngit branch -D release-1.0.0 添加完发布文档之后，完成 release\n$ git flow release finish 1.0.0 等价于\n#切换到 develop 分支。 $ git checkout develop #将 release-1.0.0 分支合并到 develop 分支，--no-ff 选项以保留 feature 分支的 commit 记录 $ git merge --no-ff release-1.0.0 #创建一个名为 1.0.0 的标签 $ git tag -a 1.0.0 -m \u0026#34;Release 1.0.0\u0026#34; #切换到 master 分支。 $ git checkout master #将 release-1.0.0 分支合并到 master 分支，--no-ff 选项以保留 feature 分支的 commit 记录 $ git merge --no-ff release-1.0.0 #删除 release-1.0.0 分支。 $ git branch -d release-1.0.0 Hotfixes 分支 线上发生问题的时候，先回滚到之前的稳定版本，稳定局势 然后创建热修复分支开始改 BUG\n$ git flow hotfix start 1.0.1 等价于\n#从master分支 创建一个hotfix/1.0.1分支 $ git checkout -b hotfix/1.0.1 foo master 紧急修复完毕\n$ git flow hotfix finish 1.0.1 等价于\n#切换 master 分支 $ git checkout master #合并热修复分支到master,--no-ff 选项以保留 feature 分支的 commit 记录 $ git merge --no-ff hotfix/ohno #创建一个名为 1.0.1 的标签 $ git tag 1.0.1 #切换到 develop 分支 $ git checkout develop #合并热修复分支到 develop ,--no-ff 选项以保留 feature 分支的 commit 记录 $ git merge --no-ff hotfix/1.0.1 #删除热修复分支 $ git branch -d hotfix/1.0.1 git-flow (AVH Edition) Git-flow (AVH Edition)是 Git Flow 的一个增强版本，由一些 Git Flow 的开发者开发和维护。Git-flow (AVH Edition)在保留 Git Flow 基本思想的前提下，增加了一些新的功能和选项，使得 Git Flow 更加灵活和适用于不同的团队和项目。\nGit-flow (AVH Edition)的主要增强功能包括：\n支持 git-flow init 命令，可以在一个新的 Git 仓库中快速初始化 Git Flow。 支持 git flow feature pull 命令，可以拉取其他团队成员的 feature 分支。 支持 git flow feature publish 命令，可以将 feature 分支发布到远程仓库。 支持 git flow hotfix finish 命令，可以在修复生产环境问题时自动合并到 develop 分支和 master 分支并发布新版本。 支持 git flow support 分支，可以为旧版本提供长期支持。 允许使用 Hooks and Filters 来扩展和自定义 Git Flow 的行为。 除了以上功能之外，Git-flow (AVH Edition)还提供了更多的选项和配置，使得团队可以根据不同的需求和情况来自定义 Git Flow 的分支模型和工作流程。\n初始化 使用下面命令初始化 git fow，-d 是可选参数，表示使用默认参数：\ngit flow init [-d] 创建 feature/release/hotfix/support 分支 查看、开始、完成、删除 feature 分支：\ngit flow feature # \u0026lt;base\u0026gt; 参数必须是分支名称，缺失时，默认为 develop 分支 git flow feature start \u0026lt;name\u0026gt; [\u0026lt;base\u0026gt;] git flow feature finish \u0026lt;name\u0026gt; git flow feature delete \u0026lt;name\u0026gt; 发布或者跟踪 feature 分支：\n#如果当前在 feature/name 分支，则可以省略 \u0026lt;name\u0026gt; 参数 git flow feature publish \u0026lt;name\u0026gt; git flow feature track \u0026lt;name\u0026gt; 当 feature 分支发布之后，其他人可以拉取该分支：\ngit pull git checkout feature/\u0026lt;name\u0026gt; 类似地，查看、开始、完成、删除 release 分支：\ngit flow release git flow release start \u0026lt;name\u0026gt; [\u0026lt;base\u0026gt;] git flow release finish \u0026lt;name\u0026gt; git flow release delete \u0026lt;name\u0026gt; 类似地，查看、开始、完成、删除 hotfix 分支：\ngit flow hotfix git flow hotfix start \u0026lt;name\u0026gt; [\u0026lt;base\u0026gt;] git flow hotfix finish \u0026lt;name\u0026gt; git flow hotfix delete \u0026lt;name\u0026gt; 查看、开始 support 分支：\ngit flow support git flow support start \u0026lt;name\u0026gt; \u0026lt;base\u0026gt; Hooks 和 Filters Git-flow (AVH Edition)允许使用 Hooks and Filters 来扩展和自定义 Git Flow 的行为。Hooks 和 Filters 是 Git Flow 中的两个关键概念，它们可以在 Git Flow 的不同阶段执行自定义脚本或命令，从而实现 Git Flow 的高度定制化。\nHooks 是一些脚本或命令，它们会在 Git Flow 的不同阶段被调用。Git Flow (AVH Edition)支持以下 Hooks：\ngit-flow-init: 该 Hook 会在 git-flow init 命令执行时被调用。 git-flow-feature-start: 该 Hook 会在创建新的 feature 分支时被调用。 git-flow-feature-finish: 该 Hook 会在完成 feature 分支时被调用。 git-flow-release-start: 该 Hook 会在创建新的 release 分支时被调用。 git-flow-release-finish: 该 Hook 会在完成 release 分支时被调用。 git-flow-hotfix-start: 该 Hook 会在创建新的 hotfix 分支时被调用。 git-flow-hotfix-finish: 该 Hook 会在完成 hotfix 分支时被调用。 Filters 是一些命令或参数，它们会在 Git Flow 的不同阶段被过滤或修改。Git Flow (AVH Edition)支持以下 Filters：\ngit-flow-feature-start-message: 可以用于修改 feature 分支创建时的提交信息。 git-flow-feature-finish-message: 可以用于修改 feature 分支完成时的提交信息。 git-flow-release-start-message: 可以用于修改 release 分支创建时的提交信息。 git-flow-release-finish-message: 可以用于修改 release 分支完成时的提交信息。 git-flow-hotfix-start-message: 可以用于修改 hotfix 分支创建时的提交信息。 git-flow-hotfix-finish-message: 可以用于修改 hotfix 分支完成时的提交信息。 下面是一些使用 Hooks 和 Filters 的例子：\n使用 git-flow-init Hook 如果需要在执行 git-flow init 命令时执行一些自定义脚本，可以使用 git-flow-init Hook。假设我们想在 git-flow init 命令执行时输出一些信息，可以在.git/hooks/git-flow-init文件中添加以下内容：\n#!/bin/bash echo \u0026#34;Executing git-flow-init Hook\u0026#34; 使用 git-flow-feature-start Hook 如果需要在创建新的 feature 分支时执行一些自定义脚本，可以使用 git-flow-feature-start Hook。假设我们想在创建新的 feature 分支时自动为该分支设置一些默认值，可以在.git/hooks/git-flow-feature-start文件中添加以下内容：\n#!/bin/bash # Set default values for feature branch git config branch.$GIT_BRANCH_NAME.some_config_value \u0026#34;default_value\u0026#34; 使用 git-flow-feature-finish-message Filter 如果需要修改 feature 分支完成时的提交信息，可以使用 git-flow-feature-finish-message Filter。假设我们想在 feature 分支完成时强制要求填写提交信息，可以在.git/config文件中添加以下内容：\n[gitflow \u0026#34;feature\u0026#34;] finishmessage = Please provide a meaningful commit message for the feature branch 使用 git-flow-hotfix-start Hook 如果需要在创建新的 hotfix 分支时执行一些自定义脚本，可以使用 git-flow-hotfix-start Hook。假设我们想在创建新的 hotfix 分支时自动为该分支设置一些默认值，可以在.git/hooks/git-flow-hotfix-start文件中添加以下内容：\n#!/bin/bash # Set default values for hotfix branch git config branch.$GIT_BRANCH_NAME.some_config_value \u0026#34;default_value\u0026#34; 使用 git-flow-hotfix-finish Hook 在.git/hooks/git-flow-hotfix-finish文件中添加以下内容：\n#!/bin/bash # Update version number in package.json VERSION=$(cat package.json | jq -r \u0026#39;.version\u0026#39;) NEW_VERSION=$(echo $VERSION | awk -F. \u0026#39;{$NF++;print}\u0026#39; | sed \u0026#39;s/ /./g\u0026#39;) sed -i \u0026#39;\u0026#39; \u0026#34;s/\\\u0026#34;version\\\u0026#34;: \\\u0026#34;$VERSION\\\u0026#34;/\\\u0026#34;version\\\u0026#34;: \\\u0026#34;$NEW_VERSION\\\u0026#34;/g\u0026#34; package.json 该脚本用于修改前端项目中的版本号。\nGitHub Flow 模型 GitHub Flow 是一种基于 GitHub 的分支模型和代码开发工作流程，它是一个简单而灵活的模型，在敏捷开发和持续交付方面具有很高的效率。相比于 Git Flow，GitHub Flow 更加适合团队和开发者进行快速迭代和快速上线。\nGitHub Flow 的分支模型非常简单：只有一个主分支（通常是 master 分支）和多个特性分支。主分支始终处于稳定状态并用于生产环境。每个特性分支用于开发新功能或修复 bug，并在开发人员完成相应的开发和测试工作后合并到主分支中。\nGitHub Flow 遵循以下 6 条原则：\nmaster 分支永远是随时可部署发布的 需求新增基于 master 分支，并创建一个语义化分支 定期推送本地分支到远端 合并到 master 需要提 PR PR 一旦经过 code review 无误后即可合并到 master master 一旦接收到合并请求，即可立即部署发布 GitHub Flow 的代码开发工作流程如下：\n创建特性分支：从主分支中创建一个新的特性分支，用于开发新功能或修复 bug。 开发和测试：在特性分支上进行开发和测试，确保代码符合质量标准，并通过自动化测试。 发起合并请求：将特性分支合并到主分支中，发起一个合并请求（pull request），并邀请其他开发者进行代码审查和讨论。 代码审查：其他开发者对代码进行审查和讨论，提出意见和建议，并确保代码符合质量标准和最佳实践。 合并代码：在经过审查和讨论后，将特性分支合并到主分支中，并将代码部署到生产环境。 部署代码：在合并到主分支后，使用自动化部署工具将代码部署到生产环境。 Gitlab flow 模型 GitLab Flow 是一个基于 GitLab 的分支模型和开发工作流程，旨在支持敏捷开发和持续交付。\nGitLab 在 2014 年提出 11 条最佳实践，更多请点击这里，其相对 GitHub 增加了环境分支，且代码必须由上游（master）向下游（staging）发展，并且针对持续发布和版本发布都提出了相应的准则，下面是其大致流程图：\nGitLab Flow 的主要特点包括：\n简单的分支模型：GitLab Flow 使用一个简单的分支模型，包括一个主分支（通常命名为“master”或“production”）和一个开发分支（通常命名为“develop”或“staging”）。特性分支从开发分支创建，并在特性或错误修复完成并通过测试后合并回开发分支中。 持续集成和交付：GitLab Flow 强调持续集成和交付（CI/CD），这意味着每次对代码的更改都会自动构建、测试和部署到测试环境或生产环境（如果测试通过）。 代码审查：GitLab Flow 鼓励进行代码审查，这意味着每次对代码的更改都会由至少一个其他开发人员进行审查，以确保其符合质量标准并不会引入任何安全漏洞。 合并请求：GitLab Flow 使用合并请求来管理将代码更改合并到主分支的过程。合并请求允许开发人员在将更改合并到主分支之前对其进行审查和讨论。 环境管理：GitLab Flow 提供高级的环境管理功能，允许团队创建和管理不同的开发、测试、暂存和生产环境。 GitLab Flow 提供了高级的环境管理功能，可以帮助团队更好地管理不同的开发、测试、暂存和生产环境。以下是使用 GitLab Flow 进行环境管理的一些方法：\n创建不同的环境分支：在 GitLab Flow 中，可以为不同的环境创建分支。例如，可以创建一个名为“develop”的开发分支，一个名为“staging”的暂存分支，和一个名为“production”的生产分支。这些分支可以帮助团队更好地管理不同环境的代码，确保每个环境都有自己的代码版本。 配置环境变量：在 GitLab 中，可以为每个环境设置不同的环境变量。这些环境变量可以用于配置不同环境中的应用程序和服务，例如数据库连接字符串、API 密钥等。通过设置正确的环境变量，可以确保应用程序在不同环境中正确运行。 自动化部署和测试：GitLab Flow 支持自动化部署和测试，可以帮助团队更快地部署代码到不同环境中。可以使用 GitLab 的 CI/CD 管道来自动化测试和部署过程，并将代码推送到正确的环境分支中。 环境监控和报告：GitLab Flow 还支持环境监控和报告功能，可以帮助团队更好地了解不同环境的运行状况和性能。可以使用 GitLab 的监控和报告工具来监视不同环境的性能指标、错误率等，并及时发现和解决问题。 GitLab Flow 的分支模型如下：\n主分支：主分支始终处于稳定状态，并用于生产环境。在 GitLab Flow 中，主分支通常是 master 分支或 production 分支。 特性分支：特性分支用于开发新功能或修复 bug，并从主分支中创建。在 GitLab Flow 中，特性分支通常以 feature/或 fix/为前缀。 集成分支：集成分支用于将特性分支集成到主分支中，并进行测试和部署。在 GitLab Flow 中，集成分支通常是 develop 分支或 staging 分支。 发布分支：发布分支用于将特性分支和集成分支的代码发布到生产环境中。在 GitLab Flow 中，发布分支通常是 release/为前缀的分支。 GitLab Flow 的开发工作流程如下：\n创建特性分支：从主分支中创建一个新的特性分支，用于开发新功能或修复 bug。 开发和测试：在特性分支上进行开发和测试，确保代码符合质量标准，并通过自动化测试。 合并到集成分支：将特性分支合并到集成分支中，并进行集成测试和自动化部署。 发布到生产环境：将集成分支的代码发布到生产环境中，并进行最终测试和部署。 合并到主分支：在发布到生产环境后，将集成分支合并到主分支中，并将代码部署到生产环境。 GitLab Flow 强调 CI/CD 集成和测试自动化，以确保代码质量和快速迭代。它还支持自动化部署和环境管理，以帮助开发人员更轻松地管理不同环境和部署代码。GitLab Flow 是一个灵活和强大的开发工作流程，适用于各种类型的项目和团队。\nGitLab Flow、Git Flow 和 GitHub Flow GitLab Flow、Git Flow 和 GitHub Flow 都是三种常见的基于 Git 的工作流程。下面是 GitLab Flow 与其他工作流程的主要区别：\nGitLab Flow 与 Git Flow 的比较： GitLab Flow 比 Git Flow 更简单和更灵活。Git Flow 有一个更复杂的分支模型，包含多个长期存在的分支，而 GitLab Flow 只使用几个主要分支和特性分支。\nGitLab Flow 强调持续集成和持续部署（CI/CD），鼓励频繁合并到主要分支。Git Flow 更注重版本控制和发布管理。\nGitLab Flow 与 GitLab 内置的 CI/CD 管道更紧密地集成在一起，更容易自动化开发工作流程。\nGitLab Flow 与 GitHub Flow 的比较： GitLab Flow 和 GitHub Flow 有许多相似之处，例如它们都以 GitHub 或 GitLab 作为中央仓库，使用特性分支进行开发。 GitLab Flow 强调 CI/CD 集成和测试自动化，而 GitHub Flow 更注重代码审查和协作。 GitLab Flow 还提供更高级的环境管理、部署和监控功能，更适合于大型、复杂的项目。 总体而言，GitLab Flow 比 Git Flow 更简单和更灵活，强调 CI/CD 集成和自动化。与 GitHub Flow 相比，GitLab Flow 提供更高级的环境管理和部署功能，更适合于大型、复杂的项目。选择哪种工作流程最终取决于项目和开发团队的具体需求和要求。\n其他 flow TrunkBased OneFlow AoneFlow 总结 目前公司代码部署在自建的 gitlab 上面，对于公司的项目，个人倾向于使用 git-flow 分支模型，并且使用 git-flow (AVH Edition) 来简化操作。\n目前，我参与的大多数项目都是 java 项目并且使用 maven 进行构建。\n在 Maven 项目中，可以使用 Maven 版本控制器来区分 release 版本和 snapshot 版本。\nRelease 版本\n对于 Git Flow 中的 release 分支，通常用于为生产环境准备代码。\n在 Maven 项目中，可以使用 Maven Release 插件来自动化创建和发布 release 版本。\nmvn release:prepare mvn release:perform 使用这些命令，Maven Release 插件会自动更新项目版本号、创建 tag、构建 release 版本，并发布到 Maven 仓库中。发布的版本号不包含 -SNAPSHOT 后缀。\n或者，使用 mvn versions：\nmvn versions:set -DnewVersion=1.0.0-SNAPSHOT mvn versions:commit Snapshot 版本\n对于 Git Flow 中的 feature 和 develop 分支，通常用于开发和测试新功能或 bug 修复，这些分支使用 snapshot 版本。在 Maven 中，snapshot 版本的版本号包含 -SNAPSHOT 后缀，表示当前版本是正在开发的版本。\n对于这些项目，git-flow 操作步骤如下：\n1、初始化\ngit flow init -d 2、开始 feature 分支\ngit flow feature start test 设置 maven 项目中版本为 snapshot 版本。\nmvn versions:set -DnewVersion=1.0.0-SNAPSHOT mvn versions:commit 对于 maven 多模块项目，如果使用 revision 来统一定义版本号，则使用下面命令：\nmvn versions:set-property -Dproperty=revision -DnewVersion=1.0.0-SNAPSHOT mvn versions:commit 3、本地在 feature 分支上完成一些开发之后，完成 feature 分支\ngit flow feature finish test 4、开始 release 分支\ngit flow release start 1.0.0 5、本地在 release 分支上完成一些开发之后，完成 feature 分支\n设置 maven 项目中版本为 release 版本。\nmvn versions:set -DnewVersion=1.0.0 mvn versions:commit 对于 maven 多模块项目，如果使用 revision 来统一定义版本号，则使用下面命令：\nmvn versions:set-property -Dproperty=revision -DnewVersion=1.0.0 mvn versions:commit 另外，对于多模块项目，需要在每个模块执行下面命令将 jar 推送到 maven 中央仓库：\nmvn deploy -DskipTests 然后完成分支：\ngit flow release finish 1.0.0 6、推送主分支和开发分支\ngit push origin develop git checkout main git push origin main 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/11/git-flow-model-and-usage/","summary":"介绍 Git Flow 是由 Vincent Driessen 在 2010 年提出的一种 Git 工作流。在这之前，Git 没有一个明确的标准工作流，导致团队在使用 Git 时往往会遇到一些问题，如分支管理、版本控制等。为了解决这些问题，Vincent Driessen 提出了 Git Flow 分支模型，成为了 Git 在实际应用中的一种标准工作流。\n随着时间的推移，Git Flow 也在不断发展和完善。在 2011 年，Atlassian 发布了 SourceTree，这是一款图形化的 Git 客户端，支持 Git Flow 分支模型。在 2013 年，Git Flow 的一些开发者发布了 Git Flow AVH Edition，这是 Git Flow 的一个增强版本，提供了更多的功能和选项。此外，Git Flow 还得到了其他开源工具和平台的支持，如 GitHub、GitLab 等。\nGit Flow 分支模型 Git Flow 分支模型定义了一种标准的 Git 分支模型，它将代码分为两个长期分支（master 和 develop）和三个短期分支（feature、release 和 hotfix），使得团队可以更好地管理代码的版本和发布。\n以下是 Git Flow 分支模型的详细介绍：\nmaster 分支 master 分支是代码库的主分支，它包含了所有已发布的代码和版本。所有代码都应该在该分支上进行测试和验证，以确保代码的质量和稳定性。master分支只能通过合并release或hotfix分支来更新。 develop 分支 develop 分支是代码库的开发分支，它包含了所有开发中的代码和功能。所有新的代码都应该在该分支上进行开发和测试，以确保代码的可靠性和稳定性。develop分支只能通过合并feature分支来更新。 feature 分支 feature 分支是为开发新的功能或修复 bug 而创建的临时分支。每个feature分支都是从develop分支分离出来的，开发完成后会合并回develop分支。feature 分支的命名应该清晰明确，以反映该分支所涉及的功能或问题。 release 分支 release 分支是为发布新版本而创建的临时分支。每个release分支都是从develop分支分离出来的，发布完成后会合并回develop分支和master分支。在 release 分支上可以进行一些小的修复和调整，以确保发布的代码的质量和稳定性。 hotfix 分支 hotfix 分支是为快速修复生产环境中的问题而创建的临时分支。每个 hotfix 分支都是从 master 分支分离出来的，修复完成后会合并回 develop 分支和 master 分支。hotfix分支的优先级比其他分支更高，因为它们需要尽快修复生产环境中的问题。 根据上面的理论，我们来实际操作一遍。首先，是 develop 分支创建一个 feature 分支。","title":"Git Flow分支模型和使用"},{"content":"前言 本篇是对 2023-05-01 到 2023-05-07 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n继上周实现导出苹果接口数据之后，这周又实现了自动导出豆瓣数据。此外，还萌生了导出每天阅读的数据的想法。奈何现在阅读 app 都需要收费，只能暂且搁置这个想法。\n最近在学习 Python，于是将学习中做的笔记发布到了博客，这周发布了两篇文章，希望通过输出来倒逼输入，以此来快速掌握 python 编程并能开发一些项目。另外，计划在学完之后，继续学习 Rust 和 Go，甚至开始学习前端开发。\n最近又一次更换了博客主题，主要出发点是想找一个简洁的主题，减少不必要的信息干扰，也不想花时间在修改主题上面。减少了菜单链接。\n导出豆瓣数据 最近阅读了一篇文章 很认真的在考虑不再使用豆瓣这件事 ，于是使用 lizheming/doumark-action 导出豆瓣数据。\n在我的 github 主页 https://github.com/chensoul/chensoul 创建一个 workflow douban.yml ，每隔一个小时同步一次豆瓣数据（读书、电影、音乐）到 csv 文件。拿到这些文件之后，就可以通过 html + css 渲染出来，类似这个页面 书影音。等豆瓣数据增多之后，再考虑实现这个。\n除此之外，之前还实现了通过 n8n 实时同步豆瓣数据到 memos 和 telegram：\n通过 python 脚本 获取最近 10 条记录，显示到 我的 github 主页。\n理财 这周总计支出 816 元，明细如下：\n5 月 1 日：55 元 5 月 2 日：79 元 5 月 3 日：370 元，其中 270 元加油 5 月 4 日：136 元，其中捐款 50 元 5 月 5 日：12 元 5 月 6 日：100 元，手机话费充值 5 月 7 日：64 元 最近一直想统计一下工作和生活中的固定支出费用，于是今天花了点时间做了统计。没想到每年工作和生活中固定支出费用竟然达到了 1529+6180=7709 元。其中大块头是手机话费和停车位费用，手机话费是因为办理一个电信套餐送宽带和一部手机；停车位费用是因为今年买了车。\n年费，总计：1529 元\nTypora：89 元 百度硬盘：178 元，2024-01-28 到期 快连 VPN：374 元，2024-01-16 到期 搬瓦工 VPS：640 元，2024-01-14 到期 1Password：248 元，2023-08-17 到期 月费，总计：515*12=6180 元\n手机话费：189 元\n停车位：320 元\niCloud：6 元\n健身 本周 跑步 记录如下，总计跑步 34.37 公里，其中周六第一次跑了 12 公里，比之前有所进步。遗憾的是，有两天没有跑步，导致连续跑步天数有中断。\n从 3 月份开始跑步到 5 月，目前总共跑步距离达到了 230 公里。\n工作 Effective Java 3 笔记 本周写了两篇《Effective Java 3》的学习笔记，分别是：\n《Effective Java 3》笔记 8：避免使用终结器和清除器 《Effective Java 3》笔记 9：使用 try-with-resources 优于 try-finally 至此，《Effective Java 3》第二章学习完了，现在总结如下：\n1、静态工厂方法代替构造函数\n静态工厂方法是一种创建对象的方式，它们与构造器不同，具有明确的名称，并且可以返回任意类型的对象。静态工厂方法的优点包括：\n名称可以描述对象的含义，使得代码更加清晰易读；\n静态工厂方法可以控制创建对象的方式，提高灵活性；\n静态工厂方法可以缓存已创建的对象，避免创建重复对象，提高性能；\n静态工厂方法可以返回任意类型的对象，而不仅仅是该类或者其子类的实例。\n2、使用构造器代替构造方法\n当一个类需要多个参数时，可以使用构建器，将参数逐个设置，最后调用 build 方法构建对象。构建器的优点包括：\n可以避免长参数列表，使得代码更加清晰易读；\n构建器可以强制要求必需的参数，提高代码的安全性；\n构建器可以返回不可变对象，提高代码的线程安全性。\n3、使用私有构造函数或枚举类型创建单例\n通过私有构造器或者枚举类型来实现 Singleton，它们的优点包括：\n可以确保只有一个实例存在，提高代码的安全性；\n可以缩小类的可访问性，提高代码的封装性；\n可以让代码更加自然，避免使用静态方法和静态变量的限制。\n4、用私有构造函数使类不可实例化\n使用私有构造函数强制实现不可实例化的主要原因是防止类被意外地实例化，以使代码更加健壮和可靠。在某些情况下，我们只需要使用类中的静态方法和静态字段，而不需要创建该类的实例。\n5、依赖注入优于硬编码资源\n使用依赖注入比硬编码资源的优点：\n可测试性：使用依赖注入，很容易创建和注入模拟对象进行测试。这样，我们可以将正在测试的组件隔离开来，并专注于测试其行为，而不必担心其依赖项的行为。 灵活性：使用依赖注入，我们可以轻松地用不同实现替换依赖项。这在需要更改组件的行为而不更改其代码时非常有用。 解耦：依赖注入有助于将组件与其依赖项解耦，使代码更加模块化并易于维护。 关注点分离：依赖注入将依赖项的创建和管理与组件本身分离，允许更清晰地分离关注点。 6、避免创建不必要的对象\n7、排除过时的对象引用\n在代码中及时清理不再使用的对象引用，以避免内存泄漏和性能问题。当一个对象不再需要时，应该尽快将其引用设置为 null，这样 JVM 可以及时回收它所占用的内存。\n8、避免使用终结器和清除器\n终结方法和清除方法是一种释放资源的方式，但是它们并不可靠，不应该依赖于它们来释放资源。应该使用 try-with-resources 结构或者显式的调用 close 方法来释放资源。\n9、使用 try-with-resources 优于 try-finally\ntry-with-resources 语句是 Java 7 中引入的一种新语法，主要目的是为了简化资源管理的代码，并确保资源被正确地关闭，避免了资源泄漏和异常处理的问题。\nPython Python 安装、构建、发布、下载和运行 Python 包和环境管理 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n2023-05-06 git flow 模型的提出：查看链接 gitflow-avh 是一个增强工具：查看链接 #git #tool #memos 2023-05-06 又有哪家阅读管理网站可取代豆瓣读书 查看链接 #douban #memos 2023-05-05 分享一些阅人经验： 1. 嘴巴太快的人，往往没什么城府。嘴巴太甜的人，不可以深交。 2. 话少的人往往是两个极端，要么真的简单，要么深不可测。 3. 性格写在脸上的人，人品不会太差。能够控制情绪的人，往往不是一般人。 4. 开口就说“我有一个朋友怎样怎样”的人，往往单纯没啥真本事。 5. 不喜欢麻烦别人的人，通常也不喜欢被别人麻烦。一个不懂拒绝的人，也是一个不懂应酬的人。 6. 如果一个人可以做到潇洒而不合群，这人多半是个老江湖。如果一个人因不合群特别不自在，这人多半是社会小白。 7. 看地位高的大佬推荐什么人、用什么人，那这个大佬就是什么样的人。 8. 越是做事小心翼翼的人，越容易得罪人。反而霸气点的人，往往都会有三分薄面。 9. 善于巴结讨好别人的人，最好不要与之深交，否则必受其累。 10. 看起来一本正经、不苟言笑、斯斯文文的人，往往都比较闷骚。 11. 能在一定位置上的人，无论你多么讨厌他，一定有他某些过人之处。 12. 能够在一段感情失败后，很快走出来的人，要么没有真心付出，要么理性得可怕。 13. 想知道一个人品行如何，可以观察一下他培养出来的孩子。 14. 高度自律的人，往往对别人的要求也很高。 15. 年少得志，太容易获得成功的人，往往容易栽跟头。如果能扛过去并吸取教训，将来的成就会更大，否则容易掉入深渊。 16. 面对恭维或羞辱都不动声色的人，肯定是城府极深的狠角色。这种人千万别乱得罪，否则受到的反击会很突然很猛烈，下场会很惨。 #摘录 #memos 2023-05-05 WoodpeckerCI 是一个由社区维护的 DroneCI 分支，使用 Apache License 2.0 许可证发布。社区版进一步扩展了 pipeline 的功能特性、支持对文件路径设置 pipeline 执行条件，并且可以与 Gitea 实现紧密集成。不同的是，DroneCI 的配置文件是 .drone.yml，WoodpeckerCI 重命名为了 .woodpecker.yml。好在 WoodpeckerCI 也兼容 DroneCI 的配置文件，迁移起来并不会太麻烦。 查看链接 #memos #tool 2023-05-04 git-flow[实战系列] 查看链接 #memos #git #tool 2023-05-04 在 Node.js 生态系统中查找积极维护和流行的库 查看链接 #web #nodejs #memos 2023-05-04 可以用来取代 UUID, 效率更高, 支持自定义字符集 查看链接 #memos #tool 2023-05-04 unDraw: 一个可以免费使用的插图库, 优势: 可免费商用/支持直接改色 查看链接 #memos #tool 2023-05-04 临时文件上传服务 文件传输工具，上传的文件只保留 48 小时，过期自动删除 查看链接 Pixeldrain 免费文件分享，免费每个文件最大 20 GB per file，无广告。 查看链接 TEMPORARY FILE HOSTING All uploaded files are automatically deleted after 60 minutes. 查看链接 Super simple file sharing! Upload as many files as you like up to 2 GB and get a link to share.（一次下载后，链接即过期） 查看链接 Upload And Share (MP4, WEBM) Temporary Videos 查看链接 #memos #tool 2023-05-04 适合编程时听的音乐 查看链接 查看链接 #memos #music 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/10/weekly_review_18/","summary":"前言 本篇是对 2023-05-01 到 2023-05-07 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n继上周实现导出苹果接口数据之后，这周又实现了自动导出豆瓣数据。此外，还萌生了导出每天阅读的数据的想法。奈何现在阅读 app 都需要收费，只能暂且搁置这个想法。\n最近在学习 Python，于是将学习中做的笔记发布到了博客，这周发布了两篇文章，希望通过输出来倒逼输入，以此来快速掌握 python 编程并能开发一些项目。另外，计划在学完之后，继续学习 Rust 和 Go，甚至开始学习前端开发。\n最近又一次更换了博客主题，主要出发点是想找一个简洁的主题，减少不必要的信息干扰，也不想花时间在修改主题上面。减少了菜单链接。\n导出豆瓣数据 最近阅读了一篇文章 很认真的在考虑不再使用豆瓣这件事 ，于是使用 lizheming/doumark-action 导出豆瓣数据。\n在我的 github 主页 https://github.com/chensoul/chensoul 创建一个 workflow douban.yml ，每隔一个小时同步一次豆瓣数据（读书、电影、音乐）到 csv 文件。拿到这些文件之后，就可以通过 html + css 渲染出来，类似这个页面 书影音。等豆瓣数据增多之后，再考虑实现这个。\n除此之外，之前还实现了通过 n8n 实时同步豆瓣数据到 memos 和 telegram：\n通过 python 脚本 获取最近 10 条记录，显示到 我的 github 主页。\n理财 这周总计支出 816 元，明细如下：\n5 月 1 日：55 元 5 月 2 日：79 元 5 月 3 日：370 元，其中 270 元加油 5 月 4 日：136 元，其中捐款 50 元 5 月 5 日：12 元 5 月 6 日：100 元，手机话费充值 5 月 7 日：64 元 最近一直想统计一下工作和生活中的固定支出费用，于是今天花了点时间做了统计。没想到每年工作和生活中固定支出费用竟然达到了 1529+6180=7709 元。其中大块头是手机话费和停车位费用，手机话费是因为办理一个电信套餐送宽带和一部手机；停车位费用是因为今年买了车。","title":"周报-18｜导出豆瓣数据、Effective Java 3第二章总结"},{"content":"发展历史 Python 包管理工具是 Python 生态系统中的一个重要组成部分，它们为 Python 开发者提供了方便、快捷的包管理方式。以下是 Python 包管理工具的发展历史概述：\n1991 年：Python 语言首次发布，Python 包管理工具还未出现。 1998 年：Python Distutils 工具发布，它是 Python 的第一个包管理工具，可以用于打包、安装和分发 Python 包。 2004 年：easy_install 工具发布，它是一种用于安装、升级和卸载 Python 包的工具，可以自动解析依赖关系并安装所需的其他包。 2007 年：pip 工具发布，它是 easy_install 的一个替代品，提供了更好的依赖项解析、升级和卸载功能，以及更好的用户体验。 2012 年：Python 软件基金会宣布，pip 将成为 Python 包管理生态系统中的标准工具，取代 easy_install。 2013 年：Wheel 格式发布，它是一种用于打包和分发 Python 包的格式，可以包含 C 扩展模块，并且支持多平台安装。 2018 年：PEP 517 和 518 发布，它们提供了一种新的 Python 包构建和分发标准，可以使包构建和分发变得更加简单和可靠。 2018 年：flit 工具发布，它是一种简单的 Python 包构建和分发工具，可以通过 pyproject.toml 文件来配置包的元数据和依赖项。 2019 年：poetry 工具发布，它是一种专注于依赖管理和项目构建的 Python 包管理工具，可以自动解析依赖关系、构建项目、生成 lock 文件等。 2020 年：PEP 621 发布，它是一种新的 Python 包元数据标准，可以用于定义 Python 包的元数据信息，如名称、版本、作者、许可证等。 2020 年：PEP 636 发布，它是一种新的 CPython 扩展模块元数据标准，可以用于定义 CPython 扩展模块的元数据信息，如名称、版本、作者、许可证等。 2021 年：flit 3 发布，它增加了对 PEP 621 和 PEP 636 的支持，可以使用 pyproject.toml 文件来定义 Python 包和 CPython 扩展模块的元数据信息。 PyPA 是 Python Packaging Authority 的缩写，即 Python 包管理权威组织。PyPA 的目标是为 Python 社区提供一个标准的、易于使用的包管理工具和相关工具的生态系统，并提供相关的文档和规范。\nPyPA 组织成立于 2013 年，由一些 Python 包管理工具的核心开发者组成。目前，PyPA 组织维护了一些 Python 包管理工具和相关工具的项目，包括：\npip: Python 包管理工具，用于安装和管理 Python 包。 setuptools: Python 包构建和分发工具，用于打包和分发 Python 包。 wheel: Python 包二进制分发格式，用于加快 Python 包的安装速度。 twine: Python 包上传工具，用于将 Python 包上传到 PyPI 或其他包仓库。 virtualenv: Python 虚拟环境工具，用于创建和管理 Python 虚拟环境。 此外，PyPA 还制定了一些包管理的标准和规范，如：\nPEP 517 和 PEP 518: 定义了 Python 包的构建规范和构建工具的接口规范。 PEP 440: 定义了 Python 包版本号的语义化规范。 PEP 503: 定义了 Python 包仓库的 URL 命名规范。 PEP 621: 定义了 Python 包元数据的标准格式。 PyPA 的工作对 Python 社区的包管理生态系统产生了重要的影响，使得 Python 包的构建、分发、安装和管理更加统一和规范。在使用 Python 包时，可以参考 PyPA 的相关工具和规范，以便更好地管理和使用 Python 包。\nDistutils 发展历史 Distutils 是 Python 生态系统中的第一个包管理工具，它为 Python 开发者提供了一种方便、快捷的包管理方式。以下是 Distutils 的发展历史概述：\n1998 年：Python 1.5.2 版本发布，它成为第一个具备模块打包功能的 Python 版本，但打包功能还比较简单。 1999 年：Distutils 工具发布，它是 Python 1.6 版本中的一个标准库，可以用于打包、安装和分发 Python 包。 2000 年：Distutils 0.9.1 版本发布，它增加了对 Windows 平台的支持，以及对 Python 2.0 版本的支持。 2002 年：Distutils 1.0 版本发布，它增加了对 Python 2.2 版本的支持，以及一些新特性和改进，如支持 C 扩展模块、支持自定义命令、支持打包多个模块等。 2007 年：setuptools 工具发布，它是 Distutils 的一个扩展，提供了更好的依赖项解析、升级和卸载功能，以及更好的插件机制和扩展性。 2013 年：Distutils 项目停止维护，它的代码被合并到 Python 标准库中，成为 Python 打包和分发的标准工具。 总的来说，Distutils 是 Python 生态系统中第一个包管理工具，它为 Python 包的构建、打包、安装和分发提供了很多方便和支持。在其发展历史中，Distutils 不断更新迭代，增加了许多新特性和功能，以适应 Python 生态系统的变化和需求。尽管现在 Distutils 不再主动维护，但它的代码被集成到 Python 标准库中，仍然为 Python 包管理提供基础支持。\neasy_install 发展历史 easy_install 是 Python 包管理工具之一，它的发展历史可以追溯到 2004 年，以下是 easy_install 的发展历史概述：\n2004 年：easy_install 首次发布，它是一种用于安装、升级和卸载 Python 包的工具，可以自动解析依赖关系并安装所需的其他包。 2005 年：easy_install 被纳入到 setuptools 中，成为 setuptools 的一部分。此时，easy_install 已经成为 Python 包管理生态系统中的一个核心工具。 2007 年：easy_install 0.6b1 发布，它引入了一些新的功能和改进，如对源码分发的支持、对 egg 格式的支持等。 2008 年：pip 工具发布，它是 easy_install 的一个替代品，提供了更好的依赖项解析、升级和卸载功能，以及更好的用户体验。 2012 年：Python 软件基金会宣布，pip 将成为 Python 包管理生态系统中的标准工具，取代 easy_install。 总的来说，easy_install 是 Python 包管理生态系统中的一个重要工具，它为 Python 开发者提供了一种简单、方便的包管理方式。尽管 easy_install 的功能和性能在某些方面已经被 pip 和其他工具取代，但它仍然是 Python 包管理历史上的一个重要里程碑，对 Python 包管理工具的发展产生了积极的影响。\nSetuptools 发展历史 setuptools 是由 Phillip J. Eby 开发的，它是 Python 的一个包管理工具，用于构建、分发和安装 Python 包。\nPhillip J. Eby 是一位知名的 Python 社区成员和开源软件贡献者，他也是 Python Packaging Authority 的成员之一。在 2004 年，他开始开发 setuptools，这个项目的目标是为 Python 开发者提供一个更好、更方便的包管理工具，以替代原有的 distutils 工具。\nsetuptools 和 distutils 的主要区别在于 setuptools 提供了一些额外的功能，如自动发现依赖关系、支持命令扩展、支持 egg 包等。这些功能使得 Python 包的构建、分发和安装变得更加灵活和高效。\nsetuptools 从一开始就受到了 Python 社区的欢迎和支持，它的代码托管在 GitHub 上，并逐渐发展成为 Python 生态系统中使用最广泛的包管理工具之一。setuptools 也是许多其他 Python 工具和框架的基础，如 Flask、Django、numpy 等。\n以下是 Setuptools 的发展历史概述：\n1994 年：Python 1.0 版本中没有 setup.py，安装 Python 包需要手动复制文件。随着 Python 的发展，用户需要更方便的方法来安装和管理包，因此开始出现了一些简单的自动化安装工具。 2000 年：Distutils 是 Python1.6 官方的包管理工具，它提供了一组用于打包、构建和分发 Python 包的工具和命令。其中，setup.py 是 Distutils 的核心组件，用于定义和配置包的元数据、依赖项和入口点等信息。 2004 年：Setuptools 首次发布，它是 Distutils 的一个扩展，提供了一些额外的功能和扩展，如对 egg 格式的支持、对依赖项的管理、对命令扩展的支持等。 2008 年：Setuptools 0.6 发布，它引入了一些新的功能和改进，如对 Python 2.6 和 3.0 的支持、对 namespace packages 的支持等。 2010 年：Distribute 发布，它是 Setuptools 的一个分支，旨在提供更好的兼容性和易用性。Distribute 移除了一些过时的功能和选项，并添加了一些新的功能和扩展。 2013 年：Setuptools 0.7 发布，它借鉴了 Distribute 的一些设计和功能，并移除了一些过时的功能和选项。Setuptools 0.7 的语法与 Distribute 的语法相同。 2018 年：Setuptools 40.0 发布，它引入了一些新的功能和改进，并移除了一些过时的功能和选项。Setuptools 40.0 的语法与 Setuptools 0.7 相同。 2020 年：Setuptools 49.0 发布，它增加了对 Python 3.9 的支持，并引入了一些新的功能和改进，如对 GitLab 的支持、对环境变量的支持等。 setup.cfg 发展历史 setup.cfg 文件是 Python 项目的元数据和构建选项的配置文件，它可以替代 setup.py 脚本来定义 Python 项目的元数据和构建选项。以下是 setup.cfg 的主要发展历史：\nPython 2.5：setuptools 扩展模块发布，引入了 setup.cfg 文件来定义项目的元数据和构建选项。 Python 3.1：distutils2 项目发布，旨在改进 distutils 模块的设计和实现，引入了 setup.cfg 文件作为定义项目元数据和构建选项的首选方式。 Python 3.4：setuptools 扩展模块被添加到 Python 标准库中，成为 distutils 的一部分，setup.cfg 文件成为标准的配置文件格式。 随着 Python 的发展，setup.cfg 文件逐渐成为 Python 项目的标准配置文件格式。它提供了比 setup.py 脚本更简洁、更易于阅读和维护的配置方式，同时也更容易与其他工具集成。需要注意的是，setup.cfg 文件并不是必需的，如果没有指定该文件，则 setuptools 将默认使用 setup.py 脚本来定义项目的元数据和构建选项\npyproject.toml 发展历史 pyproject.toml 是一个 TOML 格式的文件，用于定义 Python 项目的元数据和构建选项。它是 Python 中的一个新的标准文件，用于替代 setup.py 脚本和 setup.cfg 文件来定义和构建 Python 项目。以下是 pyproject.toml 的主要发展历史：\nPEP 517：该 PEP 提出了一个新的构建系统接口，用于替代 setup.py 和 setup.cfg，并引入了 pyproject.toml 文件作为定义 Python 项目的元数据和构建选项的标准文件格式。 PEP 518：该 PEP 提出了一种新的方式来定义项目的依赖关系，并引入了 pyproject.toml 文件作为标准的项目元数据文件格式。 随着 PEP 517 和 PEP 518 的发布，pyproject.toml 文件逐渐成为 Python 项目的标准元数据文件格式。它提供了比 setup.py 脚本和 setup.cfg 文件更灵活、更易于配置和扩展的方式，同时也更容易与构建工具和依赖管理器集成。需要注意的是，pyproject.toml 文件只在使用 PEP 517 和 PEP 518 规范的构建工具中才会被识别和使用。\n总之，pyproject.toml 文件是 Python 项目的标准元数据和构建选项的配置文件，它提供了比 setup.py 脚本和 setup.cfg 文件更灵活、更易于配置和扩展的方式，成为了 Python 项目的标准元数据文件格式。\nPip 发展历史 在 Python 中，pip 和 setuptools 是两个常用的包管理工具，它们在安装和管理 Python 包方面发挥着重要作用。\npip 是由 Ian Bicking 和其他 Python 社区成员开发的，它是 Python 的包管理器之一，用于在 Python 程序中安装和管理软件包。\nIan Bicking 是一位 Python 程序员和开源软件贡献者，他还是 Pylons 和 Paste 等框架的创始人之一。在 2008 年，他开始开发 pip，这个项目的目标是为 Python 社区提供一个更好、更易用的包管理器，以替代原有的 easy_install 工具。\npip 从一开始就受到了 Python 社区的欢迎和支持，它的代码托管在 GitHub 上，并逐渐发展成为 Python 生态系统中使用最广泛的包管理器之一。pip 支持从 PyPI（Python Package Index）等源中下载和安装 Python 包，并自动处理包之间的依赖关系，使得 Python 包的管理变得更加简单和高效。\n目前，pip 已经成为了 Python 官方推荐的包管理器，并且已经集成到 Python 2.7.9 和 Python 3.4 以及更高版本中，可以直接使用，无需额外安装。\npip 与 setuptools 有密切的关系，因为它使用 setuptools 来构建和安装 Python 包。\nsetuptools 是一个 Python 包的构建和分发工具，它提供了一组 API 来定义、构建和打包 Python 包。setuptools 可以自动生成 setup.py 文件，这个文件描述了 Python 包的元数据和依赖关系，以便 pip 和其他工具可以使用它来安装和管理包。\n在安装和管理 Python 包时，pip 会使用 setuptools 来解决依赖关系、构建和安装包。pip 会在下载包之前检查包的依赖关系，并使用 setuptools 来安装这些依赖项。如果包需要进行构建，pip 也会使用 setuptools 来构建它们\n以下是 pip 的发展历史概述：\n2008 年：pip 首次发布，它是 easy_install 的一个替代品，提供了更好的依赖项解析、升级和卸载功能，以及更好的用户体验。 2011 年：pip 正式成为 Python 包管理的标准工具之一，并被纳入到 Python 2.7 和 Python 3.2 中。 2013 年：pip 1.4 发布，它引入了一些新的功能和改进，如对 wheel 格式的支持、对安装源的优化等。 2016 年：pip 8.0 发布，它引入了一些新的功能和改进，如对 hash 校验的支持、对源索引的优化等。 2018 年：pip 18.0 发布，它引入了一些新的功能和改进，如对 Python 3.7 的支持、对源索引的改进等。 2020 年：pip 20.0 发布，它引入了一些新的功能和改进，如对 Python 3.8 的支持、对源索引的优化等。 Wheel 发展历史 Wheel 是 Python 包分发的一种格式，它的发展历史可以追溯到 2012 年，以下是 Wheel 的发展历史概述：\n2012 年：Wheel 首次提出，它的目标是提供一种更快、更可靠、更简单的 Python 包分发格式，以取代旧的 egg 格式。\n2013 年：Wheel 1.0 发布，它引入了一些新的功能和改进，如对 namespace packages 的支持、对多平台支持的改进等。\n2014 年：Wheel 0.24 发布，它引入了一些新的功能和改进，如对 Python 3.4 的支持、对源码分发的改进等。\n2016 年：Wheel 0.29 发布，它引入了一些新的功能和改进，如对 Python 3.6 的支持、对源码分发的改进等。\n2018 年：Wheel 0.31 发布，它引入了一些新的功能和改进，如对 Python 3.7 的支持、对源码分发的改进等。\n2020 年：Wheel 0.35 发布，它引入了一些新的功能和改进，如对 Python 3.9 的支持、对源码分发的改进等。\nEgg 是 Python 包分发格式之一，它的全称是 Easy Install Package，是由 setuptools 提供的一种打包和安装 Python 包的格式。Egg 格式早期是作为 Python 包管理工具 easy_install 的默认格式而出现的，但现在已逐渐被 Wheel 格式取代。\nEgg 格式的文件扩展名为 .egg，它是一个压缩文件，可以包含 Python 模块、资源文件、文档等。与其他 Python 包分发格式相比，Egg 格式具有以下特点：\nEgg 格式的文件可以被 easy_install 直接安装，无需解包。 Egg 格式支持 Python 2.x 和 Python 3.x 的跨版本安装。 Egg 格式支持多版本安装，可以在同一台机器上同时安装多个版本的同一 Python 包。 虽然 Egg 格式曾经是 Python 包分发生态系统中的一个重要组成部分，但是随着 setuptools 的发展和 Wheel 格式的出现，Egg 格式已经逐渐被取代。现在大部分 Python 包都已经使用 Wheel 格式进行分发，因为它比 Egg 格式更快、更可靠、更灵活，并且能够支持更多的 Python 版本和平台。\nWheel 是 Python 包分发格式之一，它的全称是 Python Wheel Package，是由 Python 社区提供的一种打包和安装 Python 包的格式。与其他 Python 包分发格式相比，Wheel 格式具有以下特点：\nWheel 格式的文件扩展名为 .whl，它是一个压缩文件，可以包含 Python 模块、资源文件、文档等。 Wheel 格式支持 Python 2.x 和 Python 3.x 的跨版本安装。 Wheel 格式可以包含 C 扩展模块，因此可以在安装时直接编译和安装 C 扩展模块，而不需要使用其他工具。 Wheel 格式支持多平台安装，即可以在 Windows、Linux、macOS 等不同的操作系统上安装同一个 Wheel 包。 Wheel 格式的安装速度比 Egg 格式快，因为它使用了更简单、更快速的算法。 Wheel 格式可以通过 pip 工具直接安装，无需使用其他 Python 包管理工具。 Twine 发展历史 Twine 是 Python 生态系统中的一个包管理工具，它主要用于将打包好的 Python 包上传到 PyPI（Python Package Index）等包仓库中。以下是 Twine 的发展历史概述：\n2015 年：Twine 工具发布，它是一个用于上传 Python 包到 PyPI 的命令行工具，支持 GPG 签名和 HTTPS 传输。 2016 年：Twine 1.4 版本发布，它增加了对 Wheel 包格式的支持，以及一些新特性和改进，如支持多个 PyPI 仓库、支持检查包重复上传等。 2017 年：Twine 1.8 版本发布，它增加了对 PEP 517 和 PEP 518 的支持，以及一些新特性和改进，如支持源码安装、支持上传多个包文件等。 2018 年：Twine 1.12 版本发布，它增加了对 Python 3.7 和 PyPI 的新特性的支持，以及一些新特性和改进，如支持使用环境变量配置 PyPI 仓库、支持使用 .pypirc 文件配置认证信息等。 2020 年：Twine 3.2 版本发布，它移除了 Python 2 的支持，增加了对 Python 3.9 的支持，以及一些新特性和改进，如支持使用 twine check 命令检查包是否符合 PyPI 标准、支持使用 twine register 命令在 PyPI 中注册项目等。 virtualenv 发展历史 Virtualenv 是 Python 生态系统中的一个重要工具，它提供了一种在单个系统中运行多个独立 Python 环境的方式。\nVirtualenv 是由 Ian Bicking 开发的，它是一个 Python 虚拟环境管理工具。Ian Bicking 是一位 Python 程序员和开源软件贡献者，他还是 Pylons 和 Paste 等框架的创始人之一。\nVirtualenv 的第一个版本于 2007 年发布，它的主要目的是为了解决 Python 包依赖性的问题。在 Python 中，不同的项目可能需要不同的 Python 版本和依赖包，而这些依赖包可能会相互冲突。Virtualenv 可以创建一个隔离的 Python 环境，使得每个项目都可以独立地安装和使用其所需的 Python 版本和依赖包，从而避免了冲突问题。\n在 Virtualenv 发布之后，它很快成为了 Python 开发社区中的一个重要工具，受到了广泛的关注和使用。Virtualenv 后来也被集成到了 Python 官方的文档中，并且有许多其他的虚拟环境管理工具，如 Pyenv 和 Conda，也是基于 Virtualenv 的思想和实现方式开发的。\n以下是 Virtualenv 的发展历史概述：\n2007 年：Virtualenv 工具发布，它是一个用于创建独立 Python 环境的工具，可以避免不同项目之间的依赖冲突。 2009 年：Virtualenvwrapper 工具发布，它是 Virtualenv 的一个扩展，提供了更好的虚拟环境管理方式，如创建、切换、删除虚拟环境等。 2010 年：Virtualenv 1.5 版本发布，它增加了对 Python 3 的支持，以及一些新特性和改进，如支持使用 requirements.txt 文件安装依赖、支持使用 pip 安装包等。 2011 年：Virtualenv 1.6 版本发布，它增加了对 Python 3.2 的支持，以及一些新特性和改进，如支持使用 -p 选项指定 Python 解释器、支持使用 \u0026ndash;system-site-packages 选项共享系统 Python 包等。 2013 年：Virtualenv 1.10 版本发布，它增加了对 Python 3.3 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;always-copy 选项复制依赖包、支持使用 \u0026ndash;clear 选项清空虚拟环境等。 2017 年：Virtualenv 16.0 版本发布，它增加了对 Python 3.6 和 pip 10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;upgrade 选项更新包、支持使用 \u0026ndash;prompt 选项设置虚拟环境提示符等。 2018 年：Virtualenv 16.1 版本发布，它增加了对 Python 3.7 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;creator 选项指定创建虚拟环境的方式、支持使用 \u0026ndash;verbose 选项显示详细信息等。 2019 年：Virtualenv 16.7.0 版本发布，它增加了对 Python 3.8 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;system-site-packages 选项共享系统 Python 包、支持使用 \u0026ndash;copies 选项复制依赖包等。 2020 年：Virtualenv 20.0.0 版本发布，它增加了对 Python 3.9 和 pip 20 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;prompt-cmd 选项设置虚拟环境提示符、支持使用 \u0026ndash;no-pip 选项创建不包含 pip 的虚拟环境等。 2021 年：Virtualenv 20.8.1 版本发布，它增加了对 Python 3.10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;download 选项从指定 URL 下载 Python 解释器、支持使用 \u0026ndash;clear 选项清空虚拟环境等。 总的来说，Virtualenv 是 Python 生态系统中一个非常重要的工具，它提供了一种方便、快捷的虚拟环境管理方式，为 Python 开发者提供了很多便利。在其发展历史中，Virtualenv 不断更新迭代，增加了许多新特性和功能，以适应 Python 生态系统的变化和需求。虽然现在 Virtualenv 已经不再主动维护，但它的代码被集成到其他工具中，如 venv 和 pipenv，仍然为 Python 开发者提供基础支持。\nvenv 发展历史 venv 是由 Python 官方开发团队开发的，它是 Python 3.3 版本引入的标准库模块，用于创建 Python 虚拟环境。\nPython 的官方文档中对 venv 的介绍如下：\n\u0026ldquo;venv 模块提供了 Python 3 中的虚拟环境支持。虚拟环境是 Python 环境的隔离副本，包括 Python 解释器和一个独立的库副本。虚拟环境通常用于为不同的项目创建独立的环境，以避免项目之间的依赖冲突。\u0026rdquo;\n与 Virtualenv 和其他虚拟环境管理工具不同，venv 是 Python 官方提供的标准库模块，因此它的功能和用法都与 Python 解释器密切相关，并且在 Python 安装时已经预装了 venv 模块，因此不需要额外安装。\n在使用 venv 创建虚拟环境时，可以选择使用系统中已经安装的 Python 解释器，也可以使用 venv 模块自动安装一个新的 Python 解释器。创建的虚拟环境和它所依赖的 Python 包都是独立的，不会与系统中的 Python 环境和其他虚拟环境产生冲突。\n以下是 venv 的发展历史概述：\n2012 年：Python 3.3 版本发布，它引入了 venv 标准库，用于创建独立的 Python 环境，取代了 Python 2 中的 virtualenv 工具。\n2013 年：venv 1.1 版本发布，它增加了对 Python 3.4 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;system-site-packages 选项共享系统 Python 包、支持使用 \u0026ndash;copies 选项复制依赖包等。\n2014 年：venv 1.2 版本发布，它增加了对 Python 3.5 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;clear 选项清空虚拟环境、支持使用 \u0026ndash;upgrade 选项更新包等。\n2015 年：venv 1.3 版本发布，它增加了对 Python 3.6 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;prompt 选项设置虚拟环境提示符、支持使用 \u0026ndash;without-pip 选项创建不包含 pip 的虚拟环境等。\n2017 年：venv 3.6.0 版本发布，它增加了对 Python 3.6 的支持，以及一些新特性和改进，如支持使用 activate.csh 和 activate.fish 脚本、支持使用 bin/python3 命令启动 Python 解释器等。\n2018 年：venv 3.7.0 版本发布，它增加了对 Python 3.7 的支持，以及一些新特性和改进，如支持使用 venv 模块创建虚拟环境、支持使用 ensurepip 模块安装 pip 等。\n2019 年：venv 3.8.0 版本发布，它增加了对 Python 3.8 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;symlinks 选项创建符号链接而非复制文件、支持使用 \u0026ndash;upgrade-deps 选项更新依赖包等。\n2020 年：venv 3.9.0 版本发布，它增加了对 Python 3.9 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;list 选项列出虚拟环境中已安装的包、支持使用 \u0026ndash;upgrade 选项更新 pip 等。\n2021 年：venv 3.10.0 版本发布，它增加了对 Python 3.10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;symlink-to 选项指定符号链接目录、支持使用 \u0026ndash;prompt-cmd 选项设置虚拟环境提示符等。\nPyenv 发展历史 Pyenv 是一个 Python 版本管理工具，可以用于在同一系统中管理多个 Python 版本。以下是 Pyenv 的发展历史概述：\n2011 年：Pyenv 0.1.0 版本发布，最初由 Yasuhiro Matsumoto 开发。这个版本只支持在 Bash shell 中使用。 2012 年：Pyenv 0.2.0 版本发布，支持在其他 shell 中使用，如 Zsh 和 Fish。 2013 年：Pyenv 0.4.0 版本发布，增加了对 Python 3 的支持。 2014 年：Pyenv 0.4.1 版本发布，增加了对 Jython 和 Stackless Python 的支持。 2015 年：Pyenv 1.0.0 版本发布，它增加了对 Python 的解释器和标准库的支持，以及一些新特性和改进，如增加了 pyenv virtualenv 命令来管理虚拟环境、增加了 pyenv whence 命令来查找可执行文件的位置等。 2018 年：Pyenv 1.2.0 版本发布，增加了对 PyPy3 的支持，并修复了一些 bug。 2020 年：Pyenv 1.2.21 版本发布，增加了对 Python 3.9.0 的支持，并修复了一些 bug。 Pyenv 的发展历史显示出它的长期稳定性和不断改进的趋势，以适应不断变化的 Python 生态系统和开发者需求。Pyenv 的主要特点是可以在同一系统中管理多个 Python 版本，可以很方便地切换版本，也支持使用虚拟环境来隔离不同项目的依赖。Pyenv 在 Python 开发者社区中广受欢迎，是一个不可或缺的工具之一。\nPipenv 发展历史 Pipenv 是在 2017 年由 Kenneth Reitz 开发的 Python 项目依赖管理工具。以下是 Pipenv 的发展历史概述：\n2017 年：Pipenv 1.0.0 版本发布，它是第一个稳定版本。Pipenv 结合了 pip 和 virtualenv 的功能，提供了一个更简单的方式来管理 Python 项目依赖。它自动为每个项目创建虚拟环境，并使用 Pipfile 和 Pipfile.lock 文件来管理项目依赖。 2018 年：Pipenv 2018.5.18 版本发布，它增加了许多新特性和改进，如支持使用 \u0026ndash;skip-lock 选项跳过生成 Pipfile.lock 文件、支持使用 \u0026ndash;deploy 选项安装 Pipfile.lock 文件中的依赖、支持使用 \u0026ndash;update 选项更新依赖等。 2019 年：Pipenv 2019.6.3 版本发布，它增加了对 Python 3.8 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;use-feature 选项安装依赖、支持使用 \u0026ndash;outdated 选项显示过期的依赖等。 2020 年：Pipenv 2020.6.2 版本发布，它增加了支持使用 \u0026ndash;python 选项指定 Python 解释器版本、支持使用 \u0026ndash;pre 选项安装预览版依赖、支持使用 \u0026ndash;keep-outdated 选项保留过期的依赖等。 2021 年：Pipenv 2021.5.29 版本发布，它增加了对 Python 3.10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;platform 选项指定安装依赖的平台、支持使用 \u0026ndash;bundle 选项生成依赖包压缩文件等。 Poetry 发展历史 Poetry 是一个较新的 Python 项目依赖管理工具，在 2018 年由 Sébastien Eustace 开发。以下是 Poetry 的发展历史概述：\n2018 年：Poetry 0.1.0 版本发布，它是第一个公开发布的版本。Poetry 通过 pyproject.toml 文件来管理项目依赖，并使用虚拟环境来隔离项目依赖。 2019 年：Poetry 0.12.0 版本发布，它增加了对 Python 3.8 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;lock 选项生成锁文件、支持使用 \u0026ndash;develop 选项安装开发依赖等。 2020 年：Poetry 1.0.0 版本发布，它增加了对 Python 3.9 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;experimental 选项启用实验性功能、支持使用 \u0026ndash;remove-untracked 选项删除未跟踪的依赖等。 2021 年：Poetry 1.2.0 版本发布，它增加了对 Python 3.10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;workspace 选项管理多个相关项目、支持使用 \u0026ndash;source 选项指定依赖源等。 Poetry 的发展历史显示出它的快速发展和不断改进的趋势，以适应不断变化的 Python 生态系统和开发者需求。Poetry 相较于 pipenv 和 virtualenv 等工具，它有着更加简洁的配置文件和更加易于使用的命令行接口，因此在 Python 开发者中越来越受欢迎。\nPdm 发展历史 PDM 是一个比较新的 Python 项目依赖管理工具，由李辉开发，它于 2020 年首次发布。以下是 PDM 的发展历史概述：\n2020 年：PDM 0.1.0 版本发布，它是第一个公开发布的版本。PDM 使用 pyproject.toml 文件来管理项目依赖，并使用虚拟环境来隔离项目依赖。与其他依赖管理工具不同，PDM 可以使用多个依赖源，以便从不同的源安装依赖。 2021 年：PDM 1.0.0 版本发布，它增加了对 Python 3.10 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;edit 选项编辑依赖文件、支持使用 \u0026ndash;update-prereleases 选项更新预览版依赖等。 2022 年：PDM 2.0.0 版本发布，它增加了对 Python 3.11 的支持，以及一些新特性和改进，如支持使用 \u0026ndash;lockfile 选项指定锁定文件、支持使用 \u0026ndash;find-links 选项指定依赖的本地路径或 URL 等。 PDM 的发展历史显示出它的快速发展和不断改进的趋势，以适应不断变化的 Python 生态系统和开发者需求。PDM 具有类似 Poetry 的简洁配置文件和易于使用的命令行接口，但 PDM 的多源支持和依赖快照功能则是它的独特特点，这些功能使得 PDM 在一些特定场景下更加适用。\nPyflow 发展历史 Pyflow 是另一个 Python 项目依赖管理工具，于 2016 年首次发布。以下是 Pyflow 的发展历史概述：\n2016 年：Pyflow 0.1.0 版本发布，它是第一个公开发布的版本。Pyflow 使用 requirements.txt 文件来管理项目依赖，并使用虚拟环境来隔离项目依赖。与其他依赖管理工具不同，Pyflow 支持自动化的依赖解决方案，以便更轻松地安装和更新依赖。 2017 年：Pyflow 0.3.0 版本发布，它增加了许多新特性和改进，如支持使用 \u0026ndash;editable 选项安装可编辑依赖、支持使用 \u0026ndash;pre 选项安装预览版依赖等。 2018 年：Pyflow 2.0.0 版本发布，它增加了对 Python 3 的支持，以及一些新特性和改进，如支持使用 Pipfile.lock 文件管理依赖、支持在 Pipfile 中使用多个依赖源等。 尽管 Pyflow 的开发已经停止，但是它的一些思想和特性被其他依赖管理工具所采纳，例如 Pipenv 和 Poetry。Pyflow 在其时代内曾经是一个有影响力的依赖管理工具，它的自动化依赖解决方案、虚拟环境功能和多个依赖源等特性为后来的依赖管理工具提供了启示。\nConda 发展历史 Conda 是一个开源的包管理系统和环境管理系统，用于管理 Python 包和其他科学计算相关的软件包。以下是 Conda 的发展历史：\n2012 年，Continuum Analytics 公司发布了第一个版本的 Conda，用于管理 Python 环境和软件包。\n2015 年，Conda 发布了 4.0 版本，引入了虚拟环境和交叉平台支持，支持 Python、R 和其他语言的包管理。\n2016 年，Conda 发布了 4.2 版本，引入了 Conda Forge，一个社区驱动的软件包仓库，提供了更丰富的软件包和更快的更新周期。\n2018 年，Conda 发布了 4.5 版本，引入了命令行界面的改进和新功能，如环境快速复制和包依赖关系的可视化。\n2019 年，Conda 发布了 4.6 版本，引入了环境锁定和自动环境激活功能，提高了环境管理的效率和可靠性。\n2020 年，Anaconda Inc. 收购了 Quansight 公司，并将其旗下的 Mamba 包管理器与 Conda 进行整合，提高了包管理的速度和稳定性。\n2021 年，Conda 发布了 4.10 版本，引入了 Conda 市场，一个用户界面友好的软件包搜索和安装工具，提供了更好的用户体验和社区支持。\n总结 项目依赖管理工具（虚拟环境）：\n官方的： venv 三方的： virtualenv pyenv pipenv pyflow poetry pdm Conda 包管理工具：\nsetuptools：包构建 twine：包上传和发布 pip：包安装工具 pypa/build：包构建，用于替代 setuptools 下面是 pdm、poetry、pipenv、venv、virtualenv、conda 的简要对比：\n1、pdm：\n优点：\n支持 Pipfile.lock 管理依赖项，可以保证依赖项的版本和环境的一致性。 自动创建和管理虚拟环境，可以避免环境冲突和版本问题。 自动安装缺失的系统依赖项，可以避免出现缺少系统库导致的问题。 自动审查安全漏洞，可以避免使用有安全漏洞的依赖项。 缺点：\n还比较新，生态不够完善。 没有像 poetry 和 pipenv 那样支持发布包到 PyPI。 2、poetry：\n优点：\n支持 pyproject.toml 管理依赖项，可以保证依赖项的版本和环境的一致性。 自动创建和管理虚拟环境，可以避免环境冲突和版本问题。 自动安装缺失的系统依赖项，可以避免出现缺少系统库导致的问题。 自动审查安全漏洞，可以避免使用有安全漏洞的依赖项。 支持发布包到 PyPI。 缺点：\n有些人觉得配置比较复杂，学习曲线比较陡峭。 3、pipenv：\n优点：\n支持 Pipfile 和 Pipfile.lock 管理依赖项，可以保证依赖项的版本和环境的一致性。 自动创建和管理虚拟环境，可以避免环境冲突和版本问题。 自动安装缺失的系统依赖项，可以避免出现缺少系统库导致的问题。 自动审查安全漏洞，可以避免使用有安全漏洞的依赖项。 支持发布包到 PyPI。 缺点：\n有些人觉得速度比较慢。 有些人觉得配置比较复杂，学习曲线比较陡峭。 4、venv：\n优点：\n自带 Python，无需安装额外的依赖。 简单易用，命令行操作方便。 Python 3.3+ 后自带，不需要安装额外的库。 缺点：\n只支持 Python 3.3+。 需要手动安装依赖项。 5、virtualenv：\n优点：\n支持 Python 2 和 Python 3。 可以在同一台机器上创建多个虚拟环境，可以避免环境冲突和版本问题。 可以在不同的 Python 版本之间切换。 缺点：\n需要手动安装依赖项。 6、conda：\n优点：\n支持多个操作系统和多个 Python 版本。 可以管理 Python 环境和非 Python 环境。 可以管理依赖项和安装包。 可以创建和管理虚拟环境。 支持发布包到 Anaconda Cloud。 缺点：\n安装包可能比较大。 有些人觉得配置比较复杂，学习曲线比较陡峭。 总的来说，这些工具都有各自的优缺点，可以根据自己的需求和使用习惯选择最适合自己的工具。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/09/python-package-and-env-management/","summary":"发展历史 Python 包管理工具是 Python 生态系统中的一个重要组成部分，它们为 Python 开发者提供了方便、快捷的包管理方式。以下是 Python 包管理工具的发展历史概述：\n1991 年：Python 语言首次发布，Python 包管理工具还未出现。 1998 年：Python Distutils 工具发布，它是 Python 的第一个包管理工具，可以用于打包、安装和分发 Python 包。 2004 年：easy_install 工具发布，它是一种用于安装、升级和卸载 Python 包的工具，可以自动解析依赖关系并安装所需的其他包。 2007 年：pip 工具发布，它是 easy_install 的一个替代品，提供了更好的依赖项解析、升级和卸载功能，以及更好的用户体验。 2012 年：Python 软件基金会宣布，pip 将成为 Python 包管理生态系统中的标准工具，取代 easy_install。 2013 年：Wheel 格式发布，它是一种用于打包和分发 Python 包的格式，可以包含 C 扩展模块，并且支持多平台安装。 2018 年：PEP 517 和 518 发布，它们提供了一种新的 Python 包构建和分发标准，可以使包构建和分发变得更加简单和可靠。 2018 年：flit 工具发布，它是一种简单的 Python 包构建和分发工具，可以通过 pyproject.toml 文件来配置包的元数据和依赖项。 2019 年：poetry 工具发布，它是一种专注于依赖管理和项目构建的 Python 包管理工具，可以自动解析依赖关系、构建项目、生成 lock 文件等。 2020 年：PEP 621 发布，它是一种新的 Python 包元数据标准，可以用于定义 Python 包的元数据信息，如名称、版本、作者、许可证等。 2020 年：PEP 636 发布，它是一种新的 CPython 扩展模块元数据标准，可以用于定义 CPython 扩展模块的元数据信息，如名称、版本、作者、许可证等。 2021 年：flit 3 发布，它增加了对 PEP 621 和 PEP 636 的支持，可以使用 pyproject.toml 文件来定义 Python 包和 CPython 扩展模块的元数据信息。 PyPA 是 Python Packaging Authority 的缩写，即 Python 包管理权威组织。PyPA 的目标是为 Python 社区提供一个标准的、易于使用的包管理工具和相关工具的生态系统，并提供相关的文档和规范。","title":"Python包和环境管理"},{"content":"最近开始学习 python，这篇文章记录如何安装 python、搭建 python 开发环境，以及如何构建、发布 python 包。我使用的是 macos 系统，所以本篇文章中的一些命令是基于 macos ，特此说明。\n1、安装 MacOS 上通过 brew 安装 Python3：\nbrew install python3 查看 python3 安装路径：\n$ which python3 /opt/homebrew/bin/python3 $ type python3 python3 is /opt/homebrew/bin/python3 查看版本：\npython --version 设置环境变量，我使用的是 zsh，所以需要修改 ~/.zshrc，添加下面代码：\nexport PYTHON_HOME=/opt/homebrew/opt/python@3.11 export PATH=$PYTHON_HOME/bin:$PATH alias python=python3 alias pip=pip3 使配置生效：\nsource ~/.zshrc 2、创建项目 创建一个目录 chensoul_hello：\nmkdir chensoul_hello cd chensoul_hello 创建一个 main.py ，打印 helloworld：\nprint(\u0026#34;hello world\u0026#34;) 试试运行 main.py：\npython main.py 3、创建虚拟环境 使用 python venv 模块创建虚拟环境 .venv：\npython -m venv .venv 使用 . 开头的目录或者文件为隐藏文件。如果使用 git 管理项目，则需要将 .venv 添加到 .gitignore。\n激活虚拟环境：\nsource .venv/bin/activate 4、使用 setuptools 管理项目 setuptools 是 Python 的一个包管理工具，它可以帮助开发人员更方便地打包和发布 Python 代码。setuptools 提供了一些命令行工具，例如 easy_install 和 setup.py。\nsetup.py 文件是 setuptools 用于构建、打包和发布 Python 包的核心文件之一。通过 setup.py 文件，开发人员可以指定包的元数据、依赖关系、安装脚本等信息，从而实现包的安装、升级和卸载等操作。\n具体来说，setup.py 文件通常包含以下内容：\n包的元数据，例如包的名称、版本号、作者、许可证等信息。 包的依赖关系，例如需要依赖哪些其他 Python 包。 包的安装脚本，例如需要安装哪些文件、脚本等。 其他自定义的构建和发布选项，例如文档生成、命令行工具的生成等。 通过运行 python setup.py 命令，可以执行一系列操作，例如将包构建为源代码或二进制分发包、将其上传到 PyPI 或其他包仓库、安装包到本地系统等。同时，setuptools 还提供了一些功能，例如自动化依赖关系管理、版本控制、命令行工具的生成和文档的生成等，可以帮助开发人员更加高效地进行 Python 开发。\n1、安装 setuptools\npip install setuptools 2、创建 setup.py 文件\n在使用 setuptools 时，通常需要创建一个 setup.py 文件，用来描述包的信息、依赖关系和安装方式等。setup.py 文件通常包含一个 setup() 函数，用来定义包的元数据和依赖关系等信息。例如：\nfrom setuptools import setup, find_packages setup( name=\u0026#39;chensoul_hello\u0026#39;, version=\u0026#39;1.0.0\u0026#39;, author=\u0026#39;chensoul\u0026#39;, author_email=\u0026#39;chensoul@chensoul.cc\u0026#39;, description=\u0026#39;A simple Python package\u0026#39;, packages=find_packages(), install_requires=[ \u0026#39;numpy\u0026gt;=1.16.0\u0026#39;, \u0026#39;pandas\u0026gt;=0.23.4\u0026#39;, ], entry_points={ \u0026#39;console_scripts\u0026#39;: [ \u0026#39;hello_command=chensoul_hello.cli:main\u0026#39;, ], }, ) 这个 setup.py 文件定义了一个名为 chensoul_hello 的 Python 包，指定了包的元数据、依赖关系等信息。\nname：包的名称。 version：包的版本号。 author：包的作者。 author_email：作者的电子邮件地址。 description：包的简要描述。 packages：包含需要打包的 Python 包的列表，使用 find_packages() 函数可以自动查找所有包。 install_requires：包依赖的其他 Python 包。 console_scripts： 是一个可选参数，用于定义包中的命令行工具。它是一个字典，键是命令的名称，值是命令对应的入口点（entry point）。入口点是一个字符串，通常是模块名和函数名的组合，例如 \u0026ldquo;chensoul_hello.cli:main\u0026rdquo;，表示调用 chensoul_hello 包中的 cli 模块的 main 函数。当使用 setuptools 安装包时，console_scripts 会自动创建一个可执行文件，并将入口点指向该文件。这个文件通常被放在 Python 的 bin 目录下，例如 /usr/local/bin。 对于上面的例子，如果想要在命令行中使用 hello_command 命令，需要创建名为 \u0026ldquo;chensoul_hello\u0026rdquo; 的 Python 包：\n创建一个名为 \u0026ldquo;chensoul_hello\u0026rdquo; 的文件夹，并进入该文件夹。\n在 \u0026ldquo;chensoul_hello\u0026rdquo; 文件夹中创建一个名为 __init__.py 的空文件。这个文件用于指示 Python 解释器该文件夹是一个 Python 包。\nmkdir chensoul_hello cd chensoul_hello touch __init__.py 在 \u0026ldquo;chensoul_hello\u0026rdquo; 文件夹中创建一个名为 cli.py 的文件。这个文件用于定义命令行脚本的入口函数。在 cli.py 文件中添加以下代码：\ndef main(): print(\u0026#34;Hello, world!\u0026#34;) 5、使用 setuptools 构建包 在项目的根目录，使用以下命令来构建源码分发包：\npython setup.py sdist 或者使用以下命令来构建二进制 wheel 包：\npython setup.py bdist_wheel 在执行上面两个命令之前，需要确保已经安装了 setuptools 和 wheel。如果没有安装，可以使用以下命令安装：\npip install setuptools wheel 也可以一起执行：\npython setup.py sdist bdist_wheel 执行完成后，会在当前目录下生成 dist 目录，并在其中生成两个包文件：一个源代码包和一个二进制包。这两个包文件可以通过 pip 安装，也可以直接将它们拷贝到其他机器上使用。\n6、使用 twine 发布包 twine 是一个 Python 包，用于将 Python 包上传到 PyPI 或其他类似的包仓库。它可以帮助你将打包好的 Python 包上传到 PyPI 服务器或其他类似的服务器。\n安装 twine 在终端或命令行中运行以下命令安装 twine：\npip install twine 打包 Python 包 如果你已经使用 setuptools 构建了源码分发包或二进制 wheel 包，可以使用 wheel 工具来将其转换为 wheel 包或上传到 PyPI 或其他支持的包仓库。例如，使用以下命令将源码分发包转换为 wheel 包：\npip wheel dist/chensoul_hello-1.0.0.tar.gz 注册账号 在上传包之前，你需要注册一个 PyPI 账号。如果你还没有注册，请访问 PyPI 网站（https://pypi.org/account/register/）进行注册。\n在使用 twine 工具上传包时，需要先在 PyPI 网站上注册账号并获取上传凭证（例如 API 密钥或用户名密码），然后将凭证保存在本地的 $HOME/.pypirc 文件中。\n[pypi] username = __token__ password = pypi-XXXXXX 上传 Python 包 twine 工具支持上传到以下包仓库：\nPyPI（Python Package Index）：PyPI 是 Python 社区的官方包仓库，提供了大量的 Python 包供用户下载和使用。PyPI 使用 https://pypi.org/ 作为官方网站，可以使用 twine 工具将包上传到 PyPI。\nTest PyPI：Test PyPI 是 PyPI 的一个测试环境，用于测试和验证包的上传和分发过程。Test PyPI 使用 https://test.pypi.org/ 作为官方网站，可以使用 twine 工具将包上传到 Test PyPI。\n任何支持 twine 格式的包仓库：twine 工具支持将包上传到任何支持 twine 格式的包仓库，只需要指定包仓库的 URL 和凭证即可。例如，可以使用 twine 工具将包上传到自己的私有包仓库或第三方包仓库。\n例如，使用以下命令将一个 wheel 包上传到 PyPI：\n$ twine upload dist/chensoul_hello-1.0.0-py3-none-any.whl Enter your username: __token__ Enter your password: 或者使用以下命令将一个源码分发包上传到 PyPI：\ntwine upload dist/chensoul_hello-1.0.0.tar.gz 同时上传 wheel 包和源码：\ntwine upload dist/* 这个命令将会上传 dist 目录下的所有包到 Test PyPI。需要注意的是，上传到不同的包仓库可能需要不同的命令和参数，具体可以参考包仓库的文档或帮助信息。\ntwine upload --repository-url https://test.pypi.org/legacy/ dist/* 如果上传时提示错误：\nUploading distributions to https://upload.pypi.org/legacy/ Uploading chensoul_hello-1.0.0-py3-none-any.whl 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 kB • 00:00 • ? WARNING Error during upload. Retry with the --verbose option for more details. ERROR HTTPError: 403 Forbidden from https://upload.pypi.org/legacy/ The user \u0026#39;chensoul\u0026#39; isn\u0026#39;t allowed to upload to project \u0026#39;my-package\u0026#39;. See https://pypi.org/help/#project-name for more information. 原因是项目名称 my-package 不合法或者已存在，需要修改包名称。\n如果项目已经存在，则可以添加参数覆盖已经存在的项目：\ntwine upload dist/* --skip-existing 7、使用 pip 安装包 如果你想安装、升级或删除 Python 包，可以使用 pip 工具来进行操作。\n使用以下命令来安装本地的包：\npip install dist/chensoul_hello-1.0.0.tar.gz 或者安装本地的 wheel 包：\npip install dist/chensoul_hello-1.0.0-py3-none-any.whl 也可以使用以下命令来从仓库中安装一个包及其依赖项：\npip install chensoul_hello 查看本地下载的安装包：\n$ pip list|grep chensoul-hello chensoul-hello 1.0.0 在使用 setuptools 构建 Python 包时，包名应该符合 Python 包命名规范。具体来说，包名应该只包含小写字母、数字和短横线 -，不能包含其他字符，包名应该以字母开头，并且不能超过 32 个字符。\n另外，如果你在包名中使用了短横线 -，在引用包时需要将其替换成下划线 _。例如，如果你的包名为 chensoul-hello，在引用包时应该使用 import chensoul_hello。\n总之，在使用 setuptools 构建 Python 包时，包名应该符合 Python 包命名规范，并且如果包名中包含短横线 -，在引用包时应该使用下划线 _。\n可以使用以下命令导出当前环境中的所有依赖项列表到 requirements.txt 文件中：\npip freeze \u0026gt; requirements.txt 可以使用以下命令根据 requirements.txt 文件中的依赖项列表安装包：\npip install -r requirements.txt 8、运行命令 $ hello_command Hello, world! 9、使用 pypa/build 构建包 执行下面命令时：\npython setup.py bdist_wheel 出现一个警告：\n******************************************************************************** Please avoid running ``setup.py`` directly. Instead, use pypa/build, pypa/installer, pypa/build or other standards-based tools. See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details. ******************************************************************************** pypa/build 和 pypa/installer 是 Python Packaging Authority（PyPA）维护的两个工具，分别用于构建和安装 Python 包。pypa/build 就是 build 模块，而 pypa/installer 就是 pip。\n下面是它们的使用方法：\n安装 pypa/build 工具：\npip install build 运行以下命令构建包：\npython -m build python -m build 是一个用于构建 Python 包的命令行工具，它是 Python 3.10 中新增的标准库模块 build 的入口点。使用 python -m build 可以方便地构建源代码发行包和二进制发行包，支持多种格式，包括 sdist、wheel、zip、tar 等。\n在使用 python -m build 构建 Python 包之前，需要确保你的项目符合 Python 包的标准。具体来说，你需要在项目根目录下创建一个 setup.cfg 文件和一个 setup.py 文件，其中 setup.cfg 文件包含项目元数据和构建选项，setup.py 文件包含构建和打包的具体实现。\n如果需要发布包到 PyPI 或其他包仓库，可以使用以下命令：\ntwine upload dist/* 10、附录 pypa/build 和 setuptools 对比 python -m build 和 python setup.py sdist bdist_wheel 都是用于构建 Python 包的命令行工具，但它们有一些区别。\npython -m build 是 Python 3.10 中新增的标准库模块 build 的入口点，支持多种构建格式，包括 sdist、wheel、zip、tar 等。它可以自动构建源代码发行包和二进制发行包，并支持多种平台和 Python 版本。python -m build 的使用方式比较简单，需要在项目根目录下创建一个 setup.py 文件或者 pyproject.toml 文件，然后在项目根目录下执行 python -m build 命令即可。 python setup.py sdist bdist_wheel 是传统的 Python 包构建方式，需要在项目根目录下创建一个 setup.py 文件，其中包含构建和打包的具体实现。它支持的构建格式比较有限，只包括 sdist 和 bdist_wheel 两种格式。python setup.py sdist bdist_wheel 的使用方式相对较为繁琐，需要执行多个命令，并指定相应的参数和选项。 总之，python -m build 是 Python 3.10 中新增的标准库模块 build 的入口点，支持多种构建格式，使用起来比较简单。而 python setup.py sdist bdist_wheel 是传统的 Python 包构建方式，使用起来相对较为繁琐，但仍然是一种常见的构建方式。需要根据自己的实际情况选择适合的构建工具。\n相对于使用 python setup.py sdist bdist_wheel 命令，使用 python -m build 命令有以下几个优点：\n更简单的命令：python -m build 命令比 python setup.py sdist bdist_wheel 命令更加简单易用，因为它不需要你编写 setup.py 文件。你可以使用 pyproject.toml 文件来代替，这样会更简单和现代化。 更好的配置：build 模块使用 pyproject.toml 文件来配置包的构建，这是一种更现代和标准化的配置方式。该文件可以指定构建依赖项、包含在软件包中的其他文件以及其他元数据。 更多的输出格式：python -m build 支持比 python setup.py sdist bdist_wheel 更多的输出格式，包括 wheel、sdist、zip、tar 等等。 更好的性能：相对于 python setup.py sdist bdist_wheel 命令，python -m build 命令通常更快，特别是对于具有许多依赖项的大型项目而言。这是因为 build 可以并行处理某些任务，例如构建二进制软件包。 更好的兼容性：python -m build 设计为与多个 Python 版本和平台兼容，而 python setup.py sdist bdist_wheel 命令通常特定于特定版本或平台。 综上所述，相对于 python setup.py sdist bdist_wheel 命令，python -m build 提供了一种更简单、更现代、更灵活的构建 Python 包的方式，具有更好的性能和兼容性。不过，python setup.py sdist bdist_wheel 命令仍然是构建软件包的常用和得到广泛支持的方法，特别是对于较老的项目或具有更复杂要求的项目而言。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/09/python-install-build-publish-run/","summary":"最近开始学习 python，这篇文章记录如何安装 python、搭建 python 开发环境，以及如何构建、发布 python 包。我使用的是 macos 系统，所以本篇文章中的一些命令是基于 macos ，特此说明。\n1、安装 MacOS 上通过 brew 安装 Python3：\nbrew install python3 查看 python3 安装路径：\n$ which python3 /opt/homebrew/bin/python3 $ type python3 python3 is /opt/homebrew/bin/python3 查看版本：\npython --version 设置环境变量，我使用的是 zsh，所以需要修改 ~/.zshrc，添加下面代码：\nexport PYTHON_HOME=/opt/homebrew/opt/python@3.11 export PATH=$PYTHON_HOME/bin:$PATH alias python=python3 alias pip=pip3 使配置生效：\nsource ~/.zshrc 2、创建项目 创建一个目录 chensoul_hello：\nmkdir chensoul_hello cd chensoul_hello 创建一个 main.py ，打印 helloworld：\nprint(\u0026#34;hello world\u0026#34;) 试试运行 main.py：\npython main.py 3、创建虚拟环境 使用 python venv 模块创建虚拟环境 .venv：\npython -m venv .venv 使用 . 开头的目录或者文件为隐藏文件。如果使用 git 管理项目，则需要将 .venv 添加到 .gitignore。\n激活虚拟环境：\nsource .venv/bin/activate 4、使用 setuptools 管理项目 setuptools 是 Python 的一个包管理工具，它可以帮助开发人员更方便地打包和发布 Python 代码。setuptools 提供了一些命令行工具，例如 easy_install 和 setup.","title":"Python安装、构建、发布、下载和运行"},{"content":"本文是 《Effective Java 3》第二章的学习笔记：使用 try-with-resources 优于 try-finally。\n介绍 Java 库包含许多必须通过调用 close 方法手动关闭的资源。常见的有 InputStream、OutputStream 和 java.sql.Connection。关闭资源常常会被客户端忽略，这会导致可怕的性能后果。虽然这些资源中的许多都使用终结器作为安全网，但终结器并不能很好地工作。\n从历史上看，try-finally 语句是确保正确关闭资源的最佳方法，即使在出现异常或返回时也是如此：\n// try-finally - No longer the best way to close resources! static String firstLineOfFile(String path) throws IOException { BufferedReader br = new BufferedReader(new FileReader(path)); try { return br.readLine(); } finally { br.close(); } } 这可能看起来不坏，但添加第二个资源时，情况会变得更糟：\n// try-finally is ugly when used with more than one resource! static void copy(String src, String dst) throws IOException { InputStream in = new FileInputStream(src); try { OutputStream out = new FileOutputStream(dst); try { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) \u0026gt;= 0) out.write(buf, 0, n); } finally { out.close(); } } finally { in.close(); } } 使用 try-finally 语句关闭资源的正确代码（如前两个代码示例所示）也有一个细微的缺陷。try 块和 finally 块中的代码都能够抛出异常。例如，在 firstLineOfFile 方法中，由于底层物理设备发生故障，对 readLine 的调用可能会抛出异常，而关闭的调用也可能出于同样的原因而失败。在这种情况下，第二个异常将完全覆盖第一个异常。异常堆栈跟踪中没有第一个异常的记录，这可能会使实际系统中的调试变得非常复杂（而这可能是希望出现的第一个异常，以便诊断问题）。虽然可以通过编写代码来抑制第二个异常而支持第一个异常，但实际上没有人这样做，因为它太过冗长。\n当 Java 7 引入 try-with-resources 语句时，所有这些问题都一次性解决了。要使用这个结构，资源必须实现 AutoCloseable 接口，它由一个单独的 void-return close 方法组成。Java 库和第三方库中的许多类和接口现在都实现或扩展了 AutoCloseable。如果你编写的类存在必须关闭的资源，那么也应该实现 AutoCloseable。\n下面是使用 try-with-resources 的第一个示例：\n// try-with-resources - the the best way to close resources! static String firstLineOfFile(String path) throws IOException { try (BufferedReader br = new BufferedReader(new FileReader(path))) { return br.readLine(); } } 下面是使用 try-with-resources 的第二个示例：\n// try-with-resources on multiple resources - short and sweet static void copy(String src, String dst) throws IOException { try (InputStream in = new FileInputStream(src);OutputStream out = new FileOutputStream(dst)) { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) \u0026gt;= 0) out.write(buf, 0, n); } } 和使用 try-finally 的原版代码相比，try-with-resources 为开发者提供了更好的诊断方式。考虑 firstLineOfFile 方法。如果异常是由 readLine 调用和不可见的 close 抛出的，则后一个异常将被抑制，以支持前一个异常。实际上，还可能会抑制多个异常，以保留实际希望看到的异常。这些被抑制的异常不会仅仅被抛弃；它们会被打印在堆栈跟踪中，并标记它们被抑制。可以通过编程方式使用 getSuppressed 方法访问到它们，该方法是在 Java 7 中添加到 Throwable 中的。\n可以在带有资源的 try-with-resources 语句中放置 catch 子句，就像在常规的 try-finally 语句上一样。这允许处理异常时不必用另一层嵌套来影响代码。作为一个特指的示例，下面是我们的 firstLineOfFile 方法的一个版本，它不抛出异常，但如果无法打开文件或从中读取文件，则返回一个默认值：\n// try-with-resources with a catch clause static String firstLineOfFile(String path, String defaultVal) { try (BufferedReader br = new BufferedReader(new FileReader(path))) { return br.readLine(); } catch (IOException e) { return defaultVal; } } 扩展 try-with-resources 语句是 Java 7 中引入的一种新语法，主要目的是为了简化资源管理的代码，并确保资源被正确地关闭，避免了资源泄漏和异常处理的问题。\n在 Java 中，当使用一些需要手动释放资源的类时，例如 I/O 流、数据库连接等，我们需要在代码中显式地调用 close() 方法来释放资源。这种方式可能会出现一些问题，例如：\n忘记关闭资源：如果开发人员忘记关闭资源，可能会导致资源泄漏，占用系统资源，降低系统性能。 异常处理问题：如果在关闭资源之前发生异常，可能会导致资源未能正确关闭，进一步导致资源泄漏和其他问题。 为了解决这些问题，Java 7 引入了 try-with-resources 语句。它提供了一种更简洁、更安全、更易读的方式来管理资源的关闭，避免了开发人员手动释放资源的问题，并且可以确保资源被正确地关闭。\n使用 try-with-resources 语句，我们可以将资源的创建和初始化放在 try 语句的括号内，它们在 try 块执行结束后，会自动关闭资源。如果在关闭资源时发生异常，try-with-resources 语句会自动处理异常，确保所有资源都被正确地关闭。\ntry-with-resources 语句使用以下语法：\ntry (Resource1 r1 = new Resource1(); Resource2 r2 = new Resource2()) { // use r1 and r2 } catch (Exception e) { // handle the exception } 在这个例子中，Resource1 和 Resource2 是需要在使用后关闭的资源，它们将在 try 块结束后自动关闭。如果发生异常，catch 块将处理它。\nResource1 和 Resource2 必须实现 AutoCloseable 接口，该接口定义了 close() 方法，用于关闭资源。当 try 块结束时，close() 方法将自动被调用，以便关闭资源。\n需要注意的是，try-with-resources 语句可以同时管理多个资源，资源的创建和初始化应该在 try 语句的括号内完成。\ntry-with-resources 语句有以下优点：\n简洁性：try-with-resources 语句可以让代码更简洁，不需要显式地调用 close() 方法。 安全性：try-with-resources 语句可以确保资源被正确地关闭，避免了资源泄漏和异常处理的问题。 可读性：try-with-resources 语句可以让代码更易读，更容易理解资源的使用和管理。 需要注意的是，try-with-resources 语句只能用于管理实现了 AutoCloseable 接口的资源，并且只有在 Java 7 及以上版本才支持该语法。\n除了 I/O 流和数据库连接之外，还有一些类需要手动释放资源，例如：\n图形界面组件：在使用图形界面组件时，例如窗口、对话框、面板等，需要手动释放资源，例如关闭窗口、释放图形资源等。 线程：在使用线程时，需要手动停止线程，释放线程占用的系统资源。 Socket 和 ServerSocket：在使用 Socket 和 ServerSocket 时，需要手动关闭它们，以便释放网络资源。 文件句柄：在使用文件系统时，需要手动关闭文件句柄，以便释放系统资源。 JDBC Statement 和 ResultSet：在使用 JDBC 时，需要手动关闭 Statement 和 ResultSet 对象，以便释放数据库资源。 JNI 资源：在使用 JNI 调用本地方法时，需要手动释放 JNI 资源，例如 C/C++ 中的内存和文件句柄等。 ","permalink":"https://blog.chensoul.cc/posts/2023/05/08/prefer-try-with-resources-to-try-finally/","summary":"本文是 《Effective Java 3》第二章的学习笔记：使用 try-with-resources 优于 try-finally。\n介绍 Java 库包含许多必须通过调用 close 方法手动关闭的资源。常见的有 InputStream、OutputStream 和 java.sql.Connection。关闭资源常常会被客户端忽略，这会导致可怕的性能后果。虽然这些资源中的许多都使用终结器作为安全网，但终结器并不能很好地工作。\n从历史上看，try-finally 语句是确保正确关闭资源的最佳方法，即使在出现异常或返回时也是如此：\n// try-finally - No longer the best way to close resources! static String firstLineOfFile(String path) throws IOException { BufferedReader br = new BufferedReader(new FileReader(path)); try { return br.readLine(); } finally { br.close(); } } 这可能看起来不坏，但添加第二个资源时，情况会变得更糟：\n// try-finally is ugly when used with more than one resource! static void copy(String src, String dst) throws IOException { InputStream in = new FileInputStream(src); try { OutputStream out = new FileOutputStream(dst); try { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) \u0026gt;= 0) out.write(buf, 0, n); } finally { out.","title":"《Effective Java 3》笔记9：使用 try-with-resources 优于 try-finally"},{"content":"本文是 《Effective Java 3》第二章的学习笔记：避免使用终结器和清除器。\n介绍 终结器是不可预测的、常常是危险的，通常也是不必要的。 它们的使用可能导致不稳定的行为、低效率和可移植性问题。终结器有一些有效的用途，我们稍后会介绍，但通常情况下应该避免使用它们。从 Java 9 开始，终结器已经被弃用，但它们仍然被 Java 库使用。Java 9 中终结器的替代品是清除器。 清除器的危险比终结器小，但仍然不可预测、缓慢，而且通常是不必要的。\n终结器是通过在对象上实现 finalize() 方法来实现的，而清除器是通过使用 Cleaner 类来实现的。它们的工作方式有所不同：\n终结器是由垃圾回收器自动执行的，无法预测何时执行，也无法保证一定会执行。当垃圾回收器决定将对象回收时，它会调用对象的 finalize() 方法，以便对象在被销毁之前执行一些清理操作。\n清除器是由 Java 9 虚拟机通过引用队列和 Cleaner 对象执行的，可以在对象被回收之前或之后执行。在对象被垃圾回收之前，Java 虚拟机会将该对象的引用添加到一个引用队列中，然后在某些时刻，Java 虚拟机会创建一个 Cleaner 对象，并将该引用队列与 Cleaner 对象关联起来。当该对象被垃圾回收时，它的引用将被添加到与 Cleaner 对象关联的引用队列中，Cleaner 对象会在某些时刻自动执行，以便对象在被销毁之前或之后执行一些清理操作。\n在 Java 9 中，引入了 java.lang.ref.Cleaner 类，作为终结器的替代品，用于执行对象清理操作。相比终结器，Cleaner 具有以下优点：\n显式管理：Cleaner 使用明确的代码路径来管理清理操作，而不是使用隐式的终结器机制。 可控性：Cleaner 允许开发人员控制何时执行清理操作，而不是完全依赖于垃圾回收器的行为。 安全性：Cleaner 执行清理操作时，会确保类加载器已准备好，因此可以安全地执行本地清理操作。 Cleaner 通过注册一个任务来执行清理操作。该任务可以是 Runnable 或者继承自 PhantomReference 类的子类对象。当对象被垃圾回收器回收时，Cleaner 将自动执行注册的任务。\n终结器和清除器的使用场景非常有限，因为它们的执行时间不可预测，可能会导致一些问题，例如性能问题、不稳定的行为、低效率和可移植性问题。\n终结器和清除器的主要问题是：\n它们无法可靠地及时执行，甚至可能根本不会执行。当对象变得不可访问，终结器或清除器对它进行操作的时间是不确定的。这意味着永远不应该在终结器或清除器中执行任何对时间要求很严格的操作。例如，依赖终结器或清除器关闭文件就是一个严重错误，因为打开的文件描述符是有限的资源。如果由于系统在运行终结器或清除器的延迟导致许多文件处于打开状态，程序可能会运行失败，因为它不能再打开其他文件。\n终结器的另一个问题是，在终结期间抛出的未捕获异常被忽略，该对象的终结终止。未捕获的异常可能会使其他对象处于损坏状态。如果另一个线程试图使用这样一个损坏的对象，可能会导致任意的不确定性行为。正常情况下，未捕获的异常将终止线程并打印堆栈跟踪，但如果在终结器中出现，则不会打印警告。清除器没有这个问题，因为使用清除器的库可以控制它的线程。\n它们可能会导致性能问题。终结器由垃圾回收器执行，这可能会导致垃圾回收过程中的延迟。另一方面，清除器使用单独的线程执行，这可能会导致额外的开销和同步问题。\n《Effective Java》第三版建议使用显式终止方法，例如 close()，释放系统资源。当应用程序完成对资源的使用时，可以显式调用这些方法，而不依赖于垃圾回收器来执行它们。\n如果必须使用终结器或清除器， 《Effective Java》第三版建议使用防御性编程实现它们，即使用 try-finally 块确保执行关键的清理操作，并避免引用其他可能已被垃圾回收的对象或资源。\n扩展 System.gc() System.gc() 方法是 Java 中的一种垃圾回收机制，它可以在请求垃圾回收器运行时强制进行一次垃圾回收。\nSystem.gc() 方法不是强制垃圾回收的方法，因为 Java 虚拟机可以忽略它。Java 编程语言规范要求 System.gc() 方法只是一个建议，不能保证它一定会导致垃圾回收器运行。因此，它不应该被频繁地调用，因为这可能会导致性能问题。\nSystem.gc() 方法的使用场景非常有限。通常情况下，应该让垃圾回收器自行管理内存，而不是使用 System.gc() 方法来强制进行垃圾回收。如果需要确保某些对象在垃圾回收之前被释放，可以使用弱引用或软引用来管理这些对象，或使用显式终止方法来释放系统资源。\n需要注意的是，System.gc() 方法可能会耗费较长时间，因为它可能会强制回收所有未使用的对象。因此，在实际使用中，应该谨慎使用 System.gc() 方法，并仅在必要时使用它。\nSystem.runFinalization() System.runFinalization() 方法是在 Java 1.2 版本中引入的。在 Java 1.2 中，引入了垃圾回收器的改进，包括使用引用类型、终结器和垃圾回收器性能的提升。System.runFinalization() 方法作为终结器机制的一部分，用于确保所有对象的finalize() 方法被执行。在垃圾回收器将对象从内存中释放之前，如果该对象具有终结器，则垃圾回收器会调用对象的 finalize() 方法，以便在对象被销毁之前执行一些清理操作。System.runFinalization() 方法可以确保所有对象的 finalize() 方法被执行。\nSystem.runFinalization() 方法不是强制终结器执行的方法，因为 Java 虚拟机可以忽略它。Java 编程语言规范要求 System.runFinalization() 方法只是一个建议，不能保证它一定会导致终结器执行。因此，它不应该被频繁地调用，因为这可能会导致性能问题。\nSystem.runFinalization() 方法的使用场景非常有限。通常情况下，应该避免使用终结器来执行清理操作，因为终结器的执行时间不可预测，可能会导致一些问题，例如性能问题、不稳定的行为、低效率和可移植性问题。相反，应该使用显式终止方法来释放系统资源。\n需要注意的是，System.runFinalization() 方法可能会耗费较长时间，因为它可能会执行所有对象的终结器。因此，在实际使用中，应该谨慎使用 System.runFinalization() 方法，并仅在必要时使用它\n清除器和终结器使用场景 使用清除器和终结器的例子并不常见，因为它们的使用场景非常有限。以下是一些可能需要使用清除器和终结器的场景：\n在 Java 8 及之前的版本中，java.sql.Connection 类中的 finalize() 方法被用于关闭数据库连接。在 Java 9 中，这个方法被弃用，因为终结器的使用不可靠和危险。相反，Connection 接口中添加了一个 close() 方法，应该使用这个方法来释放数据库连接。 在 Java 9 中，java.lang.ref.Cleaner 类被引入作为终结器的替代品，可以用于执行对象清理操作。例如，如果需要在对象被垃圾回收之前执行一些清理操作（例如释放本地内存或关闭文件句柄），可以使用 Cleaner 类来实现。以下是一个使用 Cleaner 类的简单示例： public class Resource implements AutoCloseable { private final Cleaner cleaner = Cleaner.create(); private final File file; public Resource(File file) { this.file = file; cleaner.register(this, new CleanupTask(file)); } @Override public void close() throws Exception { // release any resources held by this object } private static class CleanupTask implements Runnable { private final File file; public CleanupTask(File file) { this.file = file; } @Override public void run() { // clean up the resource associated with the given file } } } 在这个例子中，Resource 类持有一个 File 对象，并在创建对象时使用 Cleaner 类注册了一个 CleanupTask 对象。当 Resource 对象被垃圾回收时，Cleaner 对象将自动调用 CleanupTask 对象的 run() 方法，以便执行 File 对象的清理操作（例如关闭文件句柄）。\n需要注意的是，这仅是一个简单的示例，实际使用中需要谨慎使用和考虑清除器和终结器的局限性。通常情况下，我们应该避免使用它们，使用显式终止方法来释放系统资源。\n以下是一些使用显式终止方法的例子：\nJava I/O 类。Java I/O 类通常需要使用显式终止方法来释放系统资源，例如关闭文件句柄或网络连接。例如，java.io.FileInputStream 类中的 close() 方法用于关闭打开的文件。 try (FileInputStream fis = new FileInputStream(\u0026#34;example.txt\u0026#34;)) { // read from the file } catch (IOException e) { // handle the exception } 在这个例子中，使用 try-with-resources 语句来创建 FileInputStream 对象，这将自动调用 close() 方法，以便释放文件句柄。\n数据库连接。数据库连接通常需要使用显式终止方法来释放连接。例如，java.sql.Connection 接口中的 close() 方法用于关闭数据库连接。 try (Connection conn = DriverManager.getConnection(url, user, password)) { // use the database connection } catch (SQLException e) { // handle the exception } 在这个例子中，使用 try-with-resources 语句来创建 Connection 对象，这将自动调用 close() 方法，以便释放数据库连接。\n线程池。线程池通常需要使用显式终止方法来关闭线程池，以便释放线程资源。例如，java.util.concurrent.ExecutorService 接口中的 shutdown() 方法用于关闭线程池。 ExecutorService executor = Executors.newFixedThreadPool(10); try { // submit tasks to the executor } finally { executor.shutdown(); } 在这个例子中，使用 finally 块来确保在执行完任务后关闭线程池，以便释放线程资源。\n如何避免资源泄漏？ 资源泄漏是指在使用资源（如文件句柄、网络连接、数据库连接、线程等）时，没有正确地释放或关闭它们，导致资源长时间占用，最终可能导致程序崩溃或系统性能下降。\n以下是一些避免资源泄漏的方法：\n使用 try-with-resources 语句。try-with-resources 语句是一种自动关闭资源的机制，可以确保在使用完资源后自动关闭它们。例如： try (FileInputStream fis = new FileInputStream(\u0026#34;example.txt\u0026#34;)) { // read from the file } catch (IOException e) { // handle the exception } 在这个例子中，FileInputStream 对象将在 try 块结束后自动关闭。\n显式关闭资源。如果不能使用 try-with-resources 语句，应该使用显式关闭资源的方法来释放资源。例如，在使用完数据库连接后，应该调用 Connection 接口中的 close() 方法来释放连接。\n使用防御性编程。在使用资源时，应该使用防御性编程，确保在任何情况下都能正确地释放资源。例如，在使用文件句柄时，应该确保在读取或写入文件时，使用 try-finally 块来确保在发生异常时关闭文件句柄。\nFileInputStream fis = null; try { fis = new FileInputStream(\u0026#34;example.txt\u0026#34;); // read from the file } catch (IOException e) { // handle the exception } finally { if (fis != null) { try { fis.close(); } catch (IOException e) { // handle the exception } } } 在这个例子中，使用 try-finally 块来确保在发生异常时关闭文件句柄。\n使用资源管理框架。一些资源管理框架，例如 Apache Commons IO 和 Google Guava，提供了一些实用工具类和方法，可以帮助避免资源泄漏。 总结 终结器和清除器都是 Java 中用于对象清理的机制，它们各有优缺点。\n终结器的优点：\n无需显式调用：终结器是一种自动的机制，无需显式调用，可以在对象被垃圾回收时自动执行。 灵活性：终结器允许开发人员编写任意的清理代码，无需考虑清理操作的执行时间或顺序。 终结器的缺点：\n不可控性：终结器的执行时间和顺序是不可预测的，可能会导致一些问题，例如性能问题、不稳定的行为、低效率和可移植性问题。 安全性问题：终结器可能会引起一些安全性问题，例如在 finalize() 方法中重新启动线程或打开文件等。 清除器的优点：\n明确的代码路径：清除器使用明确的代码路径来执行清理操作，相比终结器，它更加可控和安全。 可控性：清除器允许开发人员控制何时执行清理操作，而不是完全依赖于垃圾回收器的行为。 安全性：清除器执行清理操作时，会确保类加载器已准备好，因此可以安全地执行本地清理操作。 清除器的缺点：\n显式调用：清除器需要显式调用，开发人员需要为每个需要清理的对象注册一个清理器，这可能会增加代码的复杂性。 限制性：清除器只能用于执行一些清理操作，不能用于执行其他类型的操作。 综上所述，终结器和清除器各有优缺点，应该根据实际需求和场景选择适当的机制来管理对象清理。一般来说，应该优先使用显式终止方法来释放系统资源，只有在必要时才考虑使用终结器或清除器。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/08/avoid-finalizers-and-cleaners/","summary":"本文是 《Effective Java 3》第二章的学习笔记：避免使用终结器和清除器。\n介绍 终结器是不可预测的、常常是危险的，通常也是不必要的。 它们的使用可能导致不稳定的行为、低效率和可移植性问题。终结器有一些有效的用途，我们稍后会介绍，但通常情况下应该避免使用它们。从 Java 9 开始，终结器已经被弃用，但它们仍然被 Java 库使用。Java 9 中终结器的替代品是清除器。 清除器的危险比终结器小，但仍然不可预测、缓慢，而且通常是不必要的。\n终结器是通过在对象上实现 finalize() 方法来实现的，而清除器是通过使用 Cleaner 类来实现的。它们的工作方式有所不同：\n终结器是由垃圾回收器自动执行的，无法预测何时执行，也无法保证一定会执行。当垃圾回收器决定将对象回收时，它会调用对象的 finalize() 方法，以便对象在被销毁之前执行一些清理操作。\n清除器是由 Java 9 虚拟机通过引用队列和 Cleaner 对象执行的，可以在对象被回收之前或之后执行。在对象被垃圾回收之前，Java 虚拟机会将该对象的引用添加到一个引用队列中，然后在某些时刻，Java 虚拟机会创建一个 Cleaner 对象，并将该引用队列与 Cleaner 对象关联起来。当该对象被垃圾回收时，它的引用将被添加到与 Cleaner 对象关联的引用队列中，Cleaner 对象会在某些时刻自动执行，以便对象在被销毁之前或之后执行一些清理操作。\n在 Java 9 中，引入了 java.lang.ref.Cleaner 类，作为终结器的替代品，用于执行对象清理操作。相比终结器，Cleaner 具有以下优点：\n显式管理：Cleaner 使用明确的代码路径来管理清理操作，而不是使用隐式的终结器机制。 可控性：Cleaner 允许开发人员控制何时执行清理操作，而不是完全依赖于垃圾回收器的行为。 安全性：Cleaner 执行清理操作时，会确保类加载器已准备好，因此可以安全地执行本地清理操作。 Cleaner 通过注册一个任务来执行清理操作。该任务可以是 Runnable 或者继承自 PhantomReference 类的子类对象。当对象被垃圾回收器回收时，Cleaner 将自动执行注册的任务。\n终结器和清除器的使用场景非常有限，因为它们的执行时间不可预测，可能会导致一些问题，例如性能问题、不稳定的行为、低效率和可移植性问题。\n终结器和清除器的主要问题是：\n它们无法可靠地及时执行，甚至可能根本不会执行。当对象变得不可访问，终结器或清除器对它进行操作的时间是不确定的。这意味着永远不应该在终结器或清除器中执行任何对时间要求很严格的操作。例如，依赖终结器或清除器关闭文件就是一个严重错误，因为打开的文件描述符是有限的资源。如果由于系统在运行终结器或清除器的延迟导致许多文件处于打开状态，程序可能会运行失败，因为它不能再打开其他文件。\n终结器的另一个问题是，在终结期间抛出的未捕获异常被忽略，该对象的终结终止。未捕获的异常可能会使其他对象处于损坏状态。如果另一个线程试图使用这样一个损坏的对象，可能会导致任意的不确定性行为。正常情况下，未捕获的异常将终止线程并打印堆栈跟踪，但如果在终结器中出现，则不会打印警告。清除器没有这个问题，因为使用清除器的库可以控制它的线程。\n它们可能会导致性能问题。终结器由垃圾回收器执行，这可能会导致垃圾回收过程中的延迟。另一方面，清除器使用单独的线程执行，这可能会导致额外的开销和同步问题。\n《Effective Java》第三版建议使用显式终止方法，例如 close()，释放系统资源。当应用程序完成对资源的使用时，可以显式调用这些方法，而不依赖于垃圾回收器来执行它们。\n如果必须使用终结器或清除器， 《Effective Java》第三版建议使用防御性编程实现它们，即使用 try-finally 块确保执行关键的清理操作，并避免引用其他可能已被垃圾回收的对象或资源。\n扩展 System.gc() System.gc() 方法是 Java 中的一种垃圾回收机制，它可以在请求垃圾回收器运行时强制进行一次垃圾回收。\nSystem.gc() 方法不是强制垃圾回收的方法，因为 Java 虚拟机可以忽略它。Java 编程语言规范要求 System.gc() 方法只是一个建议，不能保证它一定会导致垃圾回收器运行。因此，它不应该被频繁地调用，因为这可能会导致性能问题。\nSystem.gc() 方法的使用场景非常有限。通常情况下，应该让垃圾回收器自行管理内存，而不是使用 System.gc() 方法来强制进行垃圾回收。如果需要确保某些对象在垃圾回收之前被释放，可以使用弱引用或软引用来管理这些对象，或使用显式终止方法来释放系统资源。\n需要注意的是，System.gc() 方法可能会耗费较长时间，因为它可能会强制回收所有未使用的对象。因此，在实际使用中，应该谨慎使用 System.gc() 方法，并仅在必要时使用它。\nSystem.runFinalization() System.runFinalization() 方法是在 Java 1.2 版本中引入的。在 Java 1.2 中，引入了垃圾回收器的改进，包括使用引用类型、终结器和垃圾回收器性能的提升。System.","title":"《Effective Java 3》笔记8：避免使用终结器和清除器"},{"content":"前言 本篇是对 2023-04-24 到 2023-04-30 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周二早上跑步右小腿抽筋，跑步暂停了两天，所以有两天走路没有到一万步。在小腿恢复之后，继续跑步，查看 strava 上的统计，这周总共跑了 27 公里，比上周 41 公里少了 14 公里。\n这周空闲时间就在想，能不能每天自动收集个人的一些数据，比如，目前我能想到的数据包括跑步、走路、体重、编码、早起等等。\n目前是使用 strava app 记录跑步数据，通过 running_page 可以实时收集我的每天 跑步数据。\n走路、体重数据可以从苹果健康数据获取：\n编码数据可以从 wakatime 获取：\n早起的数据，我目前是通过 ios workflow 自动化来实现的。当早起闹钟响起时，往 memos 写入一条记录。\n如果可以获取到苹果屏幕使用时间数据，则可以从苹果手机获取每日第一次拿起手机的时间作为早起时间（待研究）。\n导出苹果健康数据 如何导出苹果健康数据？可以参考这篇文章 想要分析或备份 iPhone 「健康」应用数据？教你 3 种方法将其导出 。这篇文章提到的 Health Export 工具和 python 脚本我都试过，QS Access 在手机上没有找到。\n1. Health Export 在线解析 Health Export 是国外一名独立开发者写的在线解析工具，它专门用于将健康应用导出的 XML 文件转换为 CSV 文件。\nHealth Export 提供了一个 web 网站 可以解析传苹果手机导出的健康数据。\n如何从 IPhone 手机导出苹果健康数据呢？您可以通过以下步骤导出这些数据：\n打开“健康”应用程序。 点击屏幕右上角的“个人资料”图标。 滚动到页面底部，找到“导出健康数据”选项，并点击它。 在弹出窗口中选择要导出的数据类型，例如步数、心率等。 点击“下一步”按钮。 在下一个页面中，您可以选择要导出的时间范围。您可以选择“全部数据”或指定日期范围。 点击“请求导出”按钮。 您将被要求输入一个密码以保护您的数据。输入密码后，点击“下一步”按钮。 在弹出窗口中，您可以选择将数据发送到您的电子邮件地址或其他应用程序。 点击“导出”按钮。 完成这些步骤后，您的健康数据将被导出为一个可下载的 zip 文件。您可以将其保存到您的设备上或发送到其他应用程序或云存储服务。\n将导出的文件 export.xml 上传到 web 网站 ，稍等片刻可以导出结果。导出的健康数据是一个指标一个 csv 文件，如果想合并数据，需要做进一步处理。\n另外，Health Export 也提供了 IOS APP，功能好用，支持选择指定指标数据按日期聚合导出为一个 csv，还有定时导出的功能，遗憾的是需要收费。\n2、使用 python 脚本 这里使用了 @Radcliffe 提供的开源代码。目前，Github 可以在国内自由访问，所以直接通过此链接下载名称为 applehealthdata.py 的脚本文件。\n然后，将之前下载好的 导出.xml 与该脚本文件放置在同一目录下方。为了防止报错，这里需要将 导出.xml 更名为 export.xml。\n接下来，在该文件夹下打开终端（macOS \u0026amp; Linux）或者命令行工具（Windows），使用 Python 2 执行该脚本：\npython applehealthdata.py export.xml 稍等片刻，XML 文件就会被解析为数个 CSV 文件了。\n这里，我对 applehealthdata.py 这个文件做了一点修改，只导出指定的指标的指定列的数据，修改后的脚本在 applehealthdata.py。目前，我只关注以下 6 个指标：\nRECORDS=[ \u0026#39;BodyFatPercentage\u0026#39;, \u0026#39;BodyMass\u0026#39;, \u0026#39;BodyMassIndex\u0026#39;, \u0026#39;DistanceWalkingRunning\u0026#39;, \u0026#39;LeanBodyMass\u0026#39;, \u0026#39;StepCount\u0026#39; ] 这 6 个指标中文含义分别是：\nBodyFatPercentage：脂肪率 BodyMass：体重 BodyMassIndex：BMI 指数 LeanBodyMass：净体重 DistanceWalkingRunning：走路跑步距离 StepCount：走路步数 导出的列只需要 type、startDate、value 这 3 个：\nRECORD_FIELDS = OrderedDict(( # (\u0026#39;sourceName\u0026#39;, \u0026#39;s\u0026#39;), # (\u0026#39;sourceVersion\u0026#39;, \u0026#39;s\u0026#39;), # (\u0026#39;device\u0026#39;, \u0026#39;s\u0026#39;), (\u0026#39;type\u0026#39;, \u0026#39;s\u0026#39;), # (\u0026#39;unit\u0026#39;, \u0026#39;s\u0026#39;), # (\u0026#39;creationDate\u0026#39;, \u0026#39;d\u0026#39;), (\u0026#39;startDate\u0026#39;, \u0026#39;d\u0026#39;), # (\u0026#39;endDate\u0026#39;, \u0026#39;d\u0026#39;), (\u0026#39;value\u0026#39;, \u0026#39;n\u0026#39;), )) 这样导出了这 6 个 csv 文件：\nBodyMass.csv DistanceWalkingRunning.csv StepCount.csv BodyFatPercentage.csv BodyMassIndex.csv LeanBodyMass.csv 接下来，把这 6 个文件导入数据库，并进行合并处理。数据库我选择的是 postgres，以上 6 个文件对于 6 个建表语句：\nCREATE SEQUENCE IF NOT EXISTS health_id_seq; CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;BodyFatPercentage\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;BodyMass\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;BodyMassIndex\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;DistanceWalkingRunning\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;LeanBodyMass\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); CREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;StepCount\u0026#34; ( \u0026#34;id\u0026#34; int4 NOT NULL DEFAULT nextval(\u0026#39;health_id_seq\u0026#39;::regclass), \u0026#34;type\u0026#34; varchar, \u0026#34;start_date\u0026#34; timestamp, \u0026#34;value\u0026#34; float8, PRIMARY KEY (\u0026#34;id\u0026#34;) ); 我想把这 6 个文件按照日期合并到一个表中，于是创建 health 表：\nCREATE TABLE \u0026#34;public\u0026#34;.\u0026#34;health\u0026#34; ( \u0026#34;day\u0026#34; text NOT NULL, \u0026#34;fat_pct\u0026#34; float8, \u0026#34;bmi\u0026#34; float8, \u0026#34;lean_weight\u0026#34; float8, \u0026#34;step_count\u0026#34; float8, \u0026#34;step_distance\u0026#34; numeric, \u0026#34;weight\u0026#34; float8, PRIMARY KEY (\u0026#34;day\u0026#34;) ); 接下来，通过 sql 合并数据插入到 health 表：\ninsert into health select f.day,t.fat_pct,t.bmi,t.lean_weight,f.step_count,g.step_distance,t.weight from ( select to_char(start_date, \u0026#39;YYYY-MM-DD\u0026#39;) as day,sum(\u0026#34;value\u0026#34;) step_count from \u0026#34;StepCount\u0026#34; group by to_char(start_date, \u0026#39;YYYY-MM-DD\u0026#39;) ) f left outer join ( select to_char(start_date, \u0026#39;YYYY-MM-DD\u0026#39;) as day,round(cast(sum(\u0026#34;value\u0026#34;) as numeric) ,2) as step_distance from \u0026#34;DistanceWalkingRunning\u0026#34; group by to_char(start_date, \u0026#39;YYYY-MM-DD\u0026#39;) ) g on f.day=g.day left outer join ( select a.day,a.weight,e.\u0026#34;value\u0026#34; \u0026#34;lean_weight\u0026#34;,cast(c.\u0026#34;value\u0026#34;*100 as numeric) as \u0026#34;fat_pct\u0026#34;,d.\u0026#34;value\u0026#34; \u0026#34;bmi\u0026#34; from ( select to_char(start_date, \u0026#39;YYYY-MM-DD\u0026#39;) as day,min(start_date) as min_start_date,min(value) as weight from \u0026#34;BodyMass\u0026#34; group by day ) a left outer join \u0026#34;BodyFatPercentage\u0026#34; c on a.min_start_date=c.start_date left outer join \u0026#34;BodyMassIndex\u0026#34; d on a.min_start_date=d.start_date left outer join \u0026#34;LeanBodyMass\u0026#34; e on a.min_start_date=e.start_date order by a.day ) t on t.day=f.day order by f.day asc 最后的数据如下：\n完整的 csv 文件保存在 health.csv 。有些记录中体重相关的数据为空，这是因为体重相关数据是通过其他和电子秤关联的 app 写进去的。要想每天都有体重相关的数据，则需要每天使用电子称测量体重。\n得到这份数据之后，就可以进行统计了，比如统计体重的变化、每天走路的步数等等。\n理财 这周总计支出 732 元，明细如下：\n4 月 25 日：117 元，100 元加油 4 月 26 日：59 元，买药 4 月 28 日：419 元，加油 360 元 4 月 29 日：21 元 4 月 30 日：116 元 4 月累计支出共 3048 元，比 3 月支出 3520 元少了 472 元。主要支出来自这几个：\n交通：1177 元，其中 300 元是缴纳 ETC 押金 餐饮：827 元 购物：751 元 娱乐：216 元，看电影 健身 四月跑步记录如下，总计跑了 16 小时、125 公里。更详细数据，可以参考我的 跑步主页。\n工作 Effective Java 3 笔记 请参考 《Effective Java 3》笔记 4：用私有构造函数使类不可实例化 和 《Effective Java 3》笔记 7：排除过时的对象引用。\nFlexyPool FlexyPool 是一个用于监控数据库连接池的开源工具。它支持监控和报告连接池的使用情况、性能和瓶颈，以及自动调整连接池的大小和行为。FlexyPool 支持多种流行的 Java 数据库连接池，例如 HikariCP、Tomcat JDBC Pool、C3P0、BoneCP 等等。\nFlexyPool 主要提供以下功能：\n监控连接池的使用情况，包括连接数、请求数、等待时间、执行时间等等。 报告连接池的性能和瓶颈，例如最慢的查询、最频繁的错误、最短的连接时间等等。 自动调整连接池的大小和行为，以提高性能和减少资源消耗。 集成到常见的监控工具中，例如 Prometheus、Grafana、InfluxDB 等等。 FlexyPool 的使用相对简单，只需要将其添加到应用程序的依赖中，然后配置连接池和 FlexyPool 的参数即可。例如，如果你正在使用 HikariCP 连接池，可以按照以下步骤配置 FlexyPool：\n1、添加 FlexyPool 的依赖到应用程序的 pom.xml 文件中：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.vladmihalcea.flexypool\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;flexy-pool-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2、在应用程序的配置文件中，配置连接池和 FlexyPool 的参数：\n# HikariCP 数据库连接池配置 hikari.dataSourceClassName=com.mysql.jdbc.jdbc2.optional.MysqlDataSource hikari.dataSource.url=jdbc:mysql://localhost:3306/mydb hikari.dataSource.user=root hikari.dataSource.password=secret hikari.minimumIdle=10 hikari.maximumPoolSize=20 hikari.idleTimeout=30000 hikari.poolName=hikariPool # FlexyPool 配置 flexyPool.metricsFactory=histogram flexyPool.metric.log.enabled=true flexyPool.metric.log.level=info flexyPool.metric.log.interval=10 flexyPool.metric.prometheus.enabled=true flexyPool.metric.prometheus.port=9090 在这个配置中，我们首先配置了 HikariCP 连接池的参数，然后配置了 FlexyPool 的参数。这些参数包括度量工厂、日志和度量记录的级别、度量记录的间隔、是否启用 Prometheus 集成等等。\n3、在应用程序启动时，将 FlexyPool 的代理对象添加到连接池中：\nDataSource dataSource = ...; // 获取连接池对象 FlexyPoolDataSource flexyPoolDataSource = new FlexyPoolDataSource\u0026lt;\u0026gt;(dataSource); 在这个代码中，我们首先获取 HikariCP 连接池对象，然后将其包装成 FlexyPool 的代理对象。这样，所有的数据库操作都将通过 FlexyPool 进行代理和监控。\nBaeldung 网站上有一篇介绍 Spring Boot 中如何使用 FlexyPool 连接池监控工具的教程，名为 A Guide to FlexyPool in Spring Boot。\n这篇文章首先介绍了 FlexyPool 工具的作用，以及如何将其集成到 Spring Boot 应用程序中。FlexyPool 可以监控和报告连接池的使用情况、性能和瓶颈，以及自动调整连接池的大小和行为，以提高性能和减少资源消耗。\n然后，文章介绍了如何在 Spring Boot 应用程序中使用 FlexyPool。具体步骤包括：\n添加 FlexyPool 的依赖到应用程序的 pom.xml 文件中。 配置连接池和 FlexyPool 的参数，例如 HikariCP 连接池的参数、FlexyPool 的度量工厂、日志和度量记录的级别、度量记录的间隔、是否启用 Prometheus 集成等等。 创建 FlexyPoolDataSource 对象，作为连接池的代理对象。该对象将自动创建和管理连接池，并使用 FlexyPool 工具进行监控和调整。 在应用程序中使用连接池，例如获取连接、执行 SQL 语句、关闭连接等等。 最后，文章总结了一些连接池监控和优化的最佳实践，例如：\n使用 FlexyPool 工具监控连接池的使用情况和性能瓶颈，以及调整连接池的大小和行为，以提高性能和减少资源消耗。 配置连接池和 FlexyPool 的参数，以适应应用程序的负载和性能要求。 避免连接池泄漏和死锁等问题，例如及时关闭连接、设置合理的超时时间等等。 本周分享 大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中。我写了一个 python 脚本从 memos 读取最近一周的 memos 记录。\n2023-04-28 09:01:43 4 个文生图 AI 工具 查看链接 #memos 2023-04-27 13:29:50 这是 Jony Ive 的 LoveFrom 团队出品的一本关于乔布斯的书，书中几乎全部引用乔布斯自己的话，没有解读，更加「原汁原味」，同时也收录了一些珍贵的照片。 查看链接 查看链接 #memos 2023-04-27 09:52:58 Alpine, Tailwind, Deno, SQLite 我的本地服务四件套 查看链接 Update: 用 Remix 替代了 Alpine 和 Deno，确实方便。 #web #memos 2023-04-27 08:32:37 FlexyPool 是一个用于监控数据库连接池的开源工具。它支持监控和报告连接池的使用情况、性能和瓶颈，以及自动调整连接池的大小和行为。FlexyPool 支持多种流行的 Java 数据库连接池，例如 HikariCP、Tomcat JDBC Pool、C3P0、BoneCP 等等。 FlexyPool 主要提供以下功能： 监控连接池的使用情况，包括连接数、请求数、等待时间、执行时间等等。 报告连接池的性能和瓶颈，例如最慢的查询、最频繁的错误、最短的连接时间等等。 自动调整连接池的大小和行为，以提高性能和减少资源消耗。 集成到常见的监控工具中，例如 Prometheus、Grafana、InfluxDB 等等。 查看链接 #java #memos 2023-04-27 07:24:03 人一生中最重要的两天就是出生那天和发现人生目标的那天。 \u0026mdash;\u0026mdash;马克吐温 #摘录 2023-04-25 20:07:58 受 查看链接 启发，在 iPhone 上，创建了一个自动化捷径。当早起闹铃响起时，往 memos 发送一条早起记录，内容如下： 早起时间：2023 年 4 月 25 日 20:02 今日语录： 有些事情本身我们无法控制，只好控制自己。 起床啦，喝杯咖啡，去跑步，每天进步一点点。 #memos 2023-04-25 08:57:03 【怎样种时间的种子？】 时间不够用，如何种时间的种子？ 1.走电梯时耐心等候自动关门，让更多的人进来，节约了他们的时间。（这还是一颗空间、房子的种子） 2.帮父母完成她的心愿或者事务性工作。 3.教会家里的小孩子如何节约父母的时间，这个就非常高级了。 4.路上随手捡走垃圾、不乱扔垃圾，让清洁工人有更多的时间。 5.帮助老师或者有更多能量的平台做事情。 6.经常性的做义工。 7.打电话长话短说，简洁明了节约对方的时间。 8.微信尽可能用打字，让对方快速简单地知道事情。 9.开会提前到，至少准时到，千万不能迟到，会议迟到，那种下的都是巨大的种子。 10.开车让人，腾出时间给别人。 11.开心收拾家务，让家人更加容易找到东西。 12.主动收拾公共办公区域，让同事快速有效工作。 13.不闲聊八卦浪费别人时间（这颗闲聊八卦的坏种子，还会让你在工作中没有人听从你的好意见，缺乏领导力） 14.参加任何会议提前准备，积极回应。 15.与别人分享时间的管理工具，分享获得富裕时间的好种子，这可也是法布施的好种子。 16.提醒、帮助或者关注拖延症的朋友。 17.不爽约父母安排的聚餐吃饭，不回家吃饭提前说。（恩田的大种子） 18.鼓励别人的梦想，真诚由心地赞美别人。 #金刚智慧 2023-04-24 19:21:02 有一个想法，可以写一段脚本从 telegram 或者 memos 读取上周的分享记录，然后，转换为 markdown 格式发布在周报中。这样，周报就可以变成半自动化了。 于是，写了一个 python 脚本实现了从 memos 读取记录。😁 #skill 2023-04-24 17:26:52 晚唐李商隐的《锦瑟》 锦瑟无端五十弦，一弦一柱思华年。 庄生晓梦迷蝴蝶，望帝春心托杜鹃。 沧海月明珠有泪，蓝田日暖玉生烟。 此情可待成追忆，只是当时已惘然。 #诗词 2023-04-24 14:07:04 使用一行代码为网站的输入框增加上 AI 能力。 查看链接 #skill 2023-04-24 14:04:23 平常是糊里糊涂的，现在变得出人意外的小心谨慎，这正是由于报复的欲望，而这种欲望多么能够锻炼人！ —— 大仲马 #摘录 2023-04-24 14:03:59 使人疲乏的不是远方的深谷，而是鞋子里的一粒沙子。 —— 伏尔泰 #摘录 2023-04-24 11:00:30 📝 《Effective Java 3》笔记：避免创建不必要的对象 #blog 查看链接 2023-04-24 08:20:31 使用 Python 实现 RSS 转 Newsletter. 查看链接 #python 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/06/weekly_review_17/","summary":"前言 本篇是对 2023-04-24 到 2023-04-30 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周二早上跑步右小腿抽筋，跑步暂停了两天，所以有两天走路没有到一万步。在小腿恢复之后，继续跑步，查看 strava 上的统计，这周总共跑了 27 公里，比上周 41 公里少了 14 公里。\n这周空闲时间就在想，能不能每天自动收集个人的一些数据，比如，目前我能想到的数据包括跑步、走路、体重、编码、早起等等。\n目前是使用 strava app 记录跑步数据，通过 running_page 可以实时收集我的每天 跑步数据。\n走路、体重数据可以从苹果健康数据获取：\n编码数据可以从 wakatime 获取：\n早起的数据，我目前是通过 ios workflow 自动化来实现的。当早起闹钟响起时，往 memos 写入一条记录。\n如果可以获取到苹果屏幕使用时间数据，则可以从苹果手机获取每日第一次拿起手机的时间作为早起时间（待研究）。\n导出苹果健康数据 如何导出苹果健康数据？可以参考这篇文章 想要分析或备份 iPhone 「健康」应用数据？教你 3 种方法将其导出 。这篇文章提到的 Health Export 工具和 python 脚本我都试过，QS Access 在手机上没有找到。\n1. Health Export 在线解析 Health Export 是国外一名独立开发者写的在线解析工具，它专门用于将健康应用导出的 XML 文件转换为 CSV 文件。\nHealth Export 提供了一个 web 网站 可以解析传苹果手机导出的健康数据。\n如何从 IPhone 手机导出苹果健康数据呢？您可以通过以下步骤导出这些数据：\n打开“健康”应用程序。 点击屏幕右上角的“个人资料”图标。 滚动到页面底部，找到“导出健康数据”选项，并点击它。 在弹出窗口中选择要导出的数据类型，例如步数、心率等。 点击“下一步”按钮。 在下一个页面中，您可以选择要导出的时间范围。您可以选择“全部数据”或指定日期范围。 点击“请求导出”按钮。 您将被要求输入一个密码以保护您的数据。输入密码后，点击“下一步”按钮。 在弹出窗口中，您可以选择将数据发送到您的电子邮件地址或其他应用程序。 点击“导出”按钮。 完成这些步骤后，您的健康数据将被导出为一个可下载的 zip 文件。您可以将其保存到您的设备上或发送到其他应用程序或云存储服务。\n将导出的文件 export.xml 上传到 web 网站 ，稍等片刻可以导出结果。导出的健康数据是一个指标一个 csv 文件，如果想合并数据，需要做进一步处理。\n另外，Health Export 也提供了 IOS APP，功能好用，支持选择指定指标数据按日期聚合导出为一个 csv，还有定时导出的功能，遗憾的是需要收费。\n2、使用 python 脚本 这里使用了 @Radcliffe 提供的开源代码。目前，Github 可以在国内自由访问，所以直接通过此链接下载名称为 applehealthdata.","title":"周报-17｜导出苹果健康数据、自动化收集个人数据、FlexyPool动态连接池"},{"content":"本文是 《Effective Java 3》第二章的学习笔记：排除过时的对象引用。\n介绍 \u0026ldquo;Eliminate obsolete object references\u0026rdquo; 是一条 Java 编程最佳实践的原则，指的是在代码中及时清理不再使用的对象引用，以避免内存泄漏和性能问题。当一个对象不再需要时，应该尽快将其引用设置为 null，这样 JVM 可以及时回收它所占用的内存。\n考虑以下简单的堆栈实现：\nimport java.util.Arrays; import java.util.EmptyStackException; // Can you spot the \u0026#34;memory leak\u0026#34;? public class Stack { private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { elements = new Object[DEFAULT_INITIAL_CAPACITY]; } public void push(Object e) { ensureCapacity(); elements[size++] = e; } public Object pop() { if (size == 0) throw new EmptyStackException(); return elements[--size]; } /** * Ensure space for at least one more element, roughly * doubling the capacity each time the array needs to grow. */ private void ensureCapacity() { if (elements.length == size) elements = Arrays.copyOf(elements, 2 * size + 1); } } 这个程序没有明显的错误。你可以对它进行详尽的测试，它会以优异的成绩通过所有的测试，但是有一个潜在的问题。简单地说，该程序有一个「内存泄漏」问题，由于垃圾收集器活动的增加或内存占用的增加，它可以悄无声息地表现为性能的降低。在极端情况下，这种内存泄漏可能导致磁盘分页，甚至出现 OutOfMemoryError 程序故障，但这种故障相对少见。\n那么内存泄漏在哪里呢？如果堆栈增长，然后收缩，那么从堆栈中弹出的对象将不会被垃圾收集，即使使用堆栈的程序不再引用它们。这是因为栈保留了这些对象的旧引用。一个过时的引用，是指永远不会被取消的引用。在本例中，元素数组的「活动部分」之外的任何引用都已过时。活动部分由索引小于大小的元素组成。\n垃圾收集语言中的内存泄漏（更确切地说是无意的对象保留）是暗藏的风险。如果无意中保留了对象引用，那么对象不仅被排除在垃圾收集之外，该对象引用的任何对象也被排除在外，依此类推。即使只是无意中保留了一些对象引用，许多许多的对象也可能被阻止被垃圾收集，从而对性能产生潜在的巨大影响。\n解决这类问题的方法很简单：一旦引用过时，就将置空。在我们的 Stack 类中，对某个项的引用一旦从堆栈中弹出就会过时。pop 方法的正确版本如下：\npublic Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; // Eliminate obsolete reference return result; } 用 null 处理过时引用的另一个好处是，如果它们随后被错误地关联引用，程序将立即失败，出现 NullPointerException，而不是悄悄地做错误的事情。尽可能快地检测编程错误总是有益的。\n那么，什么时候应该取消引用呢？Stack 类的哪些方面容易导致内存泄漏？简单地说，它管理自己的内存。存储池包含元素数组的元素（对象引用单元，而不是对象本身）数组的活动部分（如前面所定义的）中的元素被分配，而数组其余部分中的元素是空闲的。垃圾收集器没有办法知道这一点；对于垃圾收集器，元素数组中的所有对象引用都同样有效。只有程序员知道数组的非活动部分不重要。只要数组元素成为非活动部分的一部分，程序员就可以通过手动清空数组元素，有效地将这个事实传递给垃圾收集器。\n一般来说，一个类管理它自己的内存时，程序员应该警惕内存泄漏。当释放一个元素时，该元素中包含的任何对象引用都应该被置为 null。\n另一个常见的内存泄漏源是缓存。 一旦将对象引用放入缓存中，就很容易忘记它就在那里，并且在它变得无关紧要之后很久仍将它留在缓存中。有几个解决这个问题的办法。如果你非常幸运地实现了一个缓存，只要缓存外有对其键的引用，那么就将缓存表示为 WeakHashMap；当条目过时后，条目将被自动删除。记住，WeakHashMap 只有在缓存条目的预期生存期由键的外部引用（而不是值）决定时才有用。\n更常见的情况是，缓存条目的有效生存期定义不太好，随着时间的推移，条目的价值会越来越低。在这种情况下，缓存偶尔应该清理那些已经停用的条目。这可以通过后台线程（可能是 ScheduledThreadPoolExecutor）或向缓存添加新条目时顺便完成。LinkedHashMap 类通过其 removeEldestEntry 方法简化了后一种方法。对于更复杂的缓存，你可能需要直接使用 java.lang.ref。\n内存泄漏的第三个常见来源是侦听器和其他回调。 如果你实现了一个 API，其中客户端注册回调，但不显式取消它们，除非你采取一些行动，否则它们将累积。确保回调被及时地垃圾收集的一种方法是仅存储对它们的弱引用，例如，将它们作为键存储在 WeakHashMap 中。\n如何排除过时对象引用 以下是一些示例，展示了如何使用 Java 语言中的一些技术来排除过时的对象引用。\n在循环中使用局部变量 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; list.size(); i++) { String str = list.get(i); // do something with str } 在这个示例中，我们使用局部变量str来引用列表中的元素，而不是重复地使用list.get(i)。这样，当循环结束时，str的引用将被自动清除，避免了过时的对象引用。\n在使用完对象后及时清除引用 SomeObject obj = new SomeObject(); // do something with obj obj = null; // clear the reference to obj 在这个示例中，我们在使用完对象后立即将其引用设置为 null，以便 JVM 可以及时回收它所占用的内存。如果不清除引用，对象将一直存在于内存中，直到 JVM 进行垃圾回收。\n使用弱引用 WeakReference\u0026lt;SomeObject\u0026gt; ref = new WeakReference\u0026lt;\u0026gt;(new SomeObject()); SomeObject obj = ref.get(); // do something with obj obj = null; // clear the reference to obj 在这个示例中，我们使用了一个弱引用来引用对象，以便在对象不再被强引用时可以被及时回收。当我们需要使用对象时，可以通过弱引用获取对象的引用，使用完后及时将其引用设置为 null。\n使用 try-with-resources 语句 try (InputStream in = new FileInputStream(\u0026#34;file.txt\u0026#34;)) { // do something with in } 在这个示例中，我们使用了 try-with-resources 语句来打开一个文件流，并在使用完后自动关闭它。这样可以确保在不再需要文件流时，它的引用将被清除，避免了过时的对象引用。\n使用软引用 SoftReference\u0026lt;SomeObject\u0026gt; ref = new SoftReference\u0026lt;\u0026gt;(new SomeObject()); SomeObject obj = ref.get(); // do something with obj obj = null; // clear the reference to obj 在这个示例中，我们使用了一个软引用来引用对象，以便在 JVM 需要回收内存时可以回收对象。软引用在内存不足时通常会被回收，但在内存充足时可以保留对象，避免了过时的对象引用。\n使用虚引用 ReferenceQueue\u0026lt;SomeObject\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); PhantomReference\u0026lt;SomeObject\u0026gt; ref = new PhantomReference\u0026lt;\u0026gt;(new SomeObject(), queue); // do something ref.clear(); // clear the reference to obj 在这个示例中，我们使用了一个虚引用来引用对象，以便在 JVM 回收对象之前可以进行一些必要的清理工作。虚引用在 JVM 回收对象时会被添加到一个引用队列中，因此我们可以在对象被回收之前执行必要的清理工作。\n使用对象池 class ObjectPool\u0026lt;T\u0026gt; { private final Set\u0026lt;T\u0026gt; objects = new HashSet\u0026lt;\u0026gt;(); public synchronized T getObject() { T obj; if (objects.isEmpty()) { obj = createObject(); } else { obj = objects.iterator().next(); objects.remove(obj); } return obj; } public synchronized void returnObject(T obj) { objects.add(obj); } private T createObject() { // create a new object } } 在这个示例中，我们使用了一个对象池来管理对象的生命周期。当需要一个对象时，我们从对象池中获取一个对象，而不是每次都创建一个新的对象。当不再需要对象时，我们将其返回到对象池中，以便其他对象可以重复使用。对象池可以避免过时的对象引用，并提高代码的性能和可伸缩性。\n使用弱散列映射 Map\u0026lt;SomeObject, Object\u0026gt; map = new WeakHashMap\u0026lt;\u0026gt;(); SomeObject key = new SomeObject(); Object value = new Object(); map.put(key, value); // do something key = null; // clear the reference to key // do something // the entry in the map may be removed if key is not strongly referenced elsewhere 在这个示例中，我们使用了一个弱散列映射来存储对象引用和相应的值。当对象不再被强引用时，它的引用可能被从映射中删除，从而避免了过时的对象引用。弱散列映射通常用于缓存和事件处理等场景。\n使用缓存 class SomeObjectCache { private static final int MAX_SIZE = 100; private static final Map\u0026lt;String, SomeObject\u0026gt; cache = new LinkedHashMap\u0026lt;String, SomeObject\u0026gt;(MAX_SIZE, 0.75f, true) { protected boolean removeEldestEntry(Map.Entry\u0026lt;String, SomeObject\u0026gt; eldest) { return size() \u0026gt; MAX_SIZE; } }; public synchronized static SomeObject get(String key) { return cache.get(key); } public synchronized static void put(String key, SomeObject value) { cache.put(key, value); } } 在这个示例中，我们使用了一个缓存来存储对象引用和相应的值。当缓存达到最大大小时，最旧的条目将被自动删除，从而避免了过时的对象引用。缓存通常用于频繁访问的数据和计算结果，可以提高代码的性能和可伸缩性。\n使用对象池框架 对象池框架是一种用于管理对象生命周期的通用框架，可以避免过时的对象引用和提高代码的性能和可伸缩性。一些流行的对象池框架包括 Apache Commons Pool 和 Google Guava Cache。\n扩展 弱引用、软引用和虚引用区别 弱引用、软引用和虚引用是 Java 中三种不同类型的引用，它们之间的区别如下：\n弱引用（WeakReference） 弱引用是一种较弱的引用类型，当一个对象只被弱引用所引用时，它在下一次垃圾回收时会被回收。\n弱引用通常用于需要缓存大量对象的应用场景，例如缓存和高速缓存等。在这些场景中，使用弱引用可以避免占用过多的内存，同时又可以快速访问缓存中的对象。\n应该使用弱引用的情况包括：\n需要缓存大量对象：使用弱引用可以避免占用过多的内存空间，从而可以缓存更多的对象。\n不需要快速访问缓存中的对象：由于弱引用只有在下一次垃圾回收时才会被回收，因此可能会导致较长的访问延迟。如果应用程序可以容忍这种情况，可以考虑使用弱引用。\n需要频繁的垃圾回收：由于弱引用只有在下一次垃圾回收时才会被回收，因此可能会导致频繁的垃圾回收。如果应用程序可以容忍这种情况，可以考虑使用弱引用。\n例如，我们可以使用弱引用来实现一个缓存，当内存不足时，JVM 会自动回收弱引用所引用的对象，从而避免内存泄漏和 OOM 错误。\nMap\u0026lt;String, WeakReference\u0026lt;SomeObject\u0026gt;\u0026gt; cache = new HashMap\u0026lt;\u0026gt;(); public SomeObject getObject(String key) { SomeObject obj = null; WeakReference\u0026lt;SomeObject\u0026gt; reference = cache.get(key); if (reference != null) { obj = reference.get(); } if (obj == null) { obj = createObject(); if (obj != null) { cache.put(key, new WeakReference\u0026lt;\u0026gt;(obj)); } } return obj; } 在这个示例中，我们使用弱引用来缓存对象，当内存不足时，JVM 会自动回收弱引用所引用的对象。这样可以避免占用过多的内存，同时又可以快速访问缓存中的对象。\n软引用（SoftReference） 软引用是一种较强的引用类型，当一个对象只被软引用所引用时，只有在内存不足时才会被回收。\n软引用通常用于需要缓存大量对象的应用场景，例如图片缓存、数据缓存等。在这些场景中，使用软引用可以避免占用过多的内存，同时又可以快速访问缓存中的对象。\n应该使用软引用的情况包括：\n需要缓存大量对象：使用软引用可以避免占用过多的内存空间，从而可以缓存更多的对象。\n需要快速访问缓存中的对象：使用软引用可以快速访问缓存中的对象，避免频繁地加载和计算。\n可以容忍偶尔的垃圾回收：由于软引用只有在内存不足时才会被回收，因此可能会导致偶尔的垃圾回收。如果应用程序可以容忍这种情况，可以考虑使用软引用。\n例如，我们可以使用软引用来实现一个图片缓存，当内存不足时，JVM 会自动回收软引用所引用的对象，从而避免内存泄漏和 OOM 错误。\nMap\u0026lt;String, SoftReference\u0026lt;Bitmap\u0026gt;\u0026gt; imageCache = new HashMap\u0026lt;\u0026gt;(); public Bitmap loadImage(String url) { Bitmap bitmap = null; SoftReference\u0026lt;Bitmap\u0026gt; reference = imageCache.get(url); if (reference != null) { bitmap = reference.get(); } if (bitmap == null) { bitmap = downloadImage(url); if (bitmap != null) { imageCache.put(url, new SoftReference\u0026lt;\u0026gt;(bitmap)); } } return bitmap; } 在这个示例中，我们使用软引用来缓存图片，当内存不足时，JVM 会自动回收软引用所引用的对象。这样可以避免占用过多的内存，同时又可以快速访问缓存中的图片。\n虚引用（PhantomReference） 虚引用是 Java 中四种引用类型中最弱的一种，它主要用于跟踪对象被垃圾回收的状态。虚引用本身并不会对对象的生命周期产生影响，但可以在对象被垃圾回收时收到一个通知，从而进行一些清理或其他操作。\n虚引用的使用场景比较少，一般用于以下几个方面：\n对象的 finalize()方法： 虚引用可以用于实现对象的 finalize()方法，当对象被垃圾回收时，虚引用会收到一个通知，从而触发对象的 finalize()方法。 NIO DirectByteBuffer 对象的释放： 在使用 NIO 编程时，可能会创建大量的 DirectByteBuffer 对象，这些对象可能会占用大量的内存空间。当这些对象不再使用时，需要手动调用 System.gc()方法触发一次垃圾回收，才能释放这些对象的内存。使用虚引用可以避免手动调用 System.gc()方法，当这些对象被垃圾回收时，虚引用会收到一个通知，从而释放这些对象的内存。 对象池的管理： 在一些需要频繁创建和销毁对象的应用场景中，可以使用对象池来提高性能。当对象不再使用时，可以将对象放入虚引用中，当对象被垃圾回收时，虚引用会收到一个通知，从而将对象从对象池中移除。 需要注意的是，虚引用不适用于缓存或其他需要快速访问对象的应用场景，因为虚引用本身并不保证对象的可用性和可访问性。\n因此，软引用和弱引用的主要区别在于它们的强度和垃圾回收的时机。软引用比弱引用更强，只有在内存不足时才会被回收，而弱引用则更弱，只有在下一次垃圾回收时才会被回收。同时，使用软引用可能会导致更少的垃圾回收，但可能会占用更多的内存空间，而使用弱引用可能会导致更频繁的垃圾回收，但可以更快地释放内存空间。\n弱引用是否会影响程序的性能？ 弱引用可能会影响程序的性能，因为它们可能会导致频繁的垃圾回收。由于弱引用只有在下一次垃圾回收时才会被回收，因此当使用大量的弱引用时，可能会导致更频繁的垃圾回收，从而降低程序的性能。\n当一个对象只被弱引用所引用时，在下一次垃圾回收时它会被回收。如果应用程序中存在大量的弱引用对象，每次垃圾回收都需要扫描这些对象，从而增加了垃圾回收的时间和开销。\n因此，在使用弱引用时需要注意以下几点：\n不要过度使用弱引用：如果应用程序中存在大量的弱引用对象，可能会导致频繁的垃圾回收，从而影响程序的性能。因此，应该避免过度使用弱引用，尽可能减少弱引用对象的数量。 注意垃圾回收的时机：弱引用只在下一次垃圾回收时才会被回收，因此可能会导致较长的访问延迟。在使用弱引用时需要注意垃圾回收的时机，如果应用程序需要快速访问缓存中的对象，可能需要使用其他类型的引用。 检查弱引用是否被回收：当一个对象只被弱引用所引用时，它在下一次垃圾回收时会被回收。在使用弱引用时需要注意检查弱引用对象是否被回收，避免引用无效的对象。 如何检查弱引用对象是否被回收？ 在 Java 中，可以通过获取弱引用对象的 get()方法返回的对象来检查引用对象是否被回收。当一个弱引用所引用的对象被回收后，get()方法返回的对象将为 null。\n例如，以下示例代码演示了如何使用弱引用检查对象是否被回收：\nObject obj = new Object(); WeakReference\u0026lt;Object\u0026gt; weakRef = new WeakReference\u0026lt;\u0026gt;(obj); // 检查对象是否被回收 if (weakRef.get() != null) { // 对象未被回收 System.out.println(\u0026#34;Object is alive\u0026#34;); } else { // 对象已被回收 System.out.println(\u0026#34;Object has been collected\u0026#34;); } 在这个示例中，我们创建了一个对象，并使用弱引用来引用它。然后，我们通过检查弱引用对象的 get()方法返回的对象来判断对象是否被回收。\n当对象未被回收时，get()方法返回的对象不为 null，表示对象仍然存活。当对象被回收时，get()方法返回的对象为 null，表示对象已经被回收。\n需要注意的是，由于弱引用只在下一次垃圾回收时才会被回收，因此在使用弱引用检查对象是否被回收时，需要注意垃圾回收的时机。如果应用程序需要立即检查对象是否被回收，可以手动触发一次垃圾回收，例如通过System.gc()方法来触发。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/05/eliminate-obsolete-object-references/","summary":"本文是 《Effective Java 3》第二章的学习笔记：排除过时的对象引用。\n介绍 \u0026ldquo;Eliminate obsolete object references\u0026rdquo; 是一条 Java 编程最佳实践的原则，指的是在代码中及时清理不再使用的对象引用，以避免内存泄漏和性能问题。当一个对象不再需要时，应该尽快将其引用设置为 null，这样 JVM 可以及时回收它所占用的内存。\n考虑以下简单的堆栈实现：\nimport java.util.Arrays; import java.util.EmptyStackException; // Can you spot the \u0026#34;memory leak\u0026#34;? public class Stack { private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { elements = new Object[DEFAULT_INITIAL_CAPACITY]; } public void push(Object e) { ensureCapacity(); elements[size++] = e; } public Object pop() { if (size == 0) throw new EmptyStackException(); return elements[--size]; } /** * Ensure space for at least one more element, roughly * doubling the capacity each time the array needs to grow. */ private void ensureCapacity() { if (elements.","title":"《Effective Java 3》笔记7：排除过时的对象引用"},{"content":"本文是 《Effective Java 3》第二章的学习笔记：用私有构造函数使类不可实例化。\n介绍 使用私有构造函数强制实现不可实例化的主要原因是防止类被意外地实例化，以使代码更加健壮和可靠。在某些情况下，我们只需要使用类中的静态方法和静态字段，而不需要创建该类的实例。如果类中没有显式地定义私有构造函数，Java 编译器将会自动为该类生成一个默认的公共构造函数，这意味着该类可以在其他类中被实例化。如果这不是我们想要的，为了防止其他人意外地实例化我们的类，我们可以将构造函数设置为私有。\n此外，使用私有构造函数强制实现不可实例化还有以下优点：\n明确表明该类不可被实例化，提高了代码的可读性和可维护性。 防止类被子类化，从而避免了继承所带来的副作用和不必要的复杂性。 提高了代码的安全性，防止其他类在不合适的情况下实例化该类。 这是一个实现了私有构造函数强制实现不可实例化的类的示例：\npublic class UtilityClass { // 禁止默认构造函数防止实例化 private UtilityClass() { throw new AssertionError(); } // 其他静态方法和字段 // ... } 这个类中的私有构造函数会在被调用时抛出AssertionError。这样做可以确保构造函数永远不会从类内部或外部调用。\n通过将构造函数设置为私有，这个类就不能从外部被实例化。这个习惯用法也防止了类被子类化。如果一个类的构造函数是私有的，那么它不能被子类调用，因为子类必须调用父类的构造函数来完成初始化。因此，如果一个类的构造函数是私有的，它就不能被子类化，因为子类不能调用父类的构造函数来完成初始化。\n以下是一个示例，展示了如何使用私有构造函数防止类被子类化：\npublic final class FinalClass { private FinalClass() { // private constructor } public static void doSomething() { // do something } } 在这个示例中，FinalClass被声明为final，因此不能被子类化。此外，它的构造函数是私有的，因此不能从子类中被调用。由于该类不能被子类化，因此它的行为不会受到子类的影响，从而避免了继承所带来的副作用和不必要的复杂性。\n在某些情况下，将类设置为不能被实例化，但可以被子类化是有用的。这通常是因为我们希望子类化的类能够继承父类的行为和属性，同时又不希望外部能够实例化该类。以下是一个例子：\npublic abstract class Animal { private String name; protected Animal(String name) { this.name = name; } public String getName() { return name; } public abstract void makeSound(); } public class Dog extends Animal { public Dog(String name) { super(name); } @Override public void makeSound() { System.out.println(\u0026#34;Woof!\u0026#34;); } } 在这个例子中，Animal类被设置为抽象类，它的构造函数被设置为protected，这意味着该类不能被实例化，但可以被子类化。Dog类继承了Animal类，并实现了makeSound()方法。由于Animal类的构造函数被设置为protected，所以Dog类可以调用父类的构造函数来进行初始化。\n在这个例子中，我们希望Animal类能够提供一些通用的行为和属性，同时又不希望外部能够实例化该类，因为Animal类本身并不是一种具体的动物。而Dog类作为Animal类的子类，可以继承Animal类的行为和属性，并实现自己的特定行为，以实现具体的功能。\n用途 私有构造函数还有其他一些用途，以下是一些常见的用途：\n防止实例化：私有构造函数可以防止类被实例化，这对于只包含静态方法和静态字段的实用工具类非常有用。这些类可以通过将构造函数设置为私有来防止它们被实例化，从而避免不必要的对象创建和资源浪费。\n强制实现单例：单例模式是一种常见的设计模式，它要求一个类有且仅有一个实例，并提供一个全局访问点。私有构造函数可以强制实现单例模式，因为它可以防止类被实例化，除非类的内部定义了一个静态实例并提供了一个公共的静态访问方法。\npublic class Singleton { private static Singleton instance; private Singleton() { // private constructor } public static Singleton getInstance() { if (instance == null) { instance = new Singleton(); } return instance; } } 在这个示例中，Singleton类的构造函数是私有的，因此它不能被其他类实例化。getInstance()方法提供了一个全局访问点，并在需要时创建了一个静态实例。由于构造函数是私有的，因此只有Singleton类的内部才能创建实例，从而实现了单例模式。\n防止子类化：私有构造函数可以防止类被子类化，从而避免了继承所带来的副作用和不必要的复杂性。\npublic final class FinalClass { private FinalClass() { // private constructor } public static void doSomething() { // do something } } 在这个示例中，FinalClass类被声明为final，它的构造函数是私有的，因此它不能被子类化。该类提供了一些静态方法，可以在其他类中调用，但是不能被子类化。\n限制继承：如果一个类的构造函数是私有的，那么它不能被继承，这可以用来限制类的继承。\n实现工厂方法：工厂方法是一种常见的设计模式，它提供了一个创建对象的接口，但是将具体的对象创建过程留给了子类或具体的实现类。私有构造函数可以与工厂方法一起使用，以确保只有工厂方法能够创建对象，从而使对象创建过程更加可控和安全。\npublic class Shape { private Shape() { // private constructor } public static Shape createRectangle() { return new Rectangle(); } public static Shape createCircle() { return new Circle(); } } class Rectangle extends Shape { public Rectangle() { // constructor } } class Circle extends Shape { public Circle() { // constructor } } 在这个示例中，Shape类的构造函数是私有的，因此它不能被实例化。Shape类提供了两个静态工厂方法，createRectangle()和createCircle()，用于创建不同的形状。Rectangle和Circle类继承自Shape类，并实现了自己的构造函数。\n","permalink":"https://blog.chensoul.cc/posts/2023/05/05/enforce-noninstantiability-with-a-private-constructor/","summary":"本文是 《Effective Java 3》第二章的学习笔记：用私有构造函数使类不可实例化。\n介绍 使用私有构造函数强制实现不可实例化的主要原因是防止类被意外地实例化，以使代码更加健壮和可靠。在某些情况下，我们只需要使用类中的静态方法和静态字段，而不需要创建该类的实例。如果类中没有显式地定义私有构造函数，Java 编译器将会自动为该类生成一个默认的公共构造函数，这意味着该类可以在其他类中被实例化。如果这不是我们想要的，为了防止其他人意外地实例化我们的类，我们可以将构造函数设置为私有。\n此外，使用私有构造函数强制实现不可实例化还有以下优点：\n明确表明该类不可被实例化，提高了代码的可读性和可维护性。 防止类被子类化，从而避免了继承所带来的副作用和不必要的复杂性。 提高了代码的安全性，防止其他类在不合适的情况下实例化该类。 这是一个实现了私有构造函数强制实现不可实例化的类的示例：\npublic class UtilityClass { // 禁止默认构造函数防止实例化 private UtilityClass() { throw new AssertionError(); } // 其他静态方法和字段 // ... } 这个类中的私有构造函数会在被调用时抛出AssertionError。这样做可以确保构造函数永远不会从类内部或外部调用。\n通过将构造函数设置为私有，这个类就不能从外部被实例化。这个习惯用法也防止了类被子类化。如果一个类的构造函数是私有的，那么它不能被子类调用，因为子类必须调用父类的构造函数来完成初始化。因此，如果一个类的构造函数是私有的，它就不能被子类化，因为子类不能调用父类的构造函数来完成初始化。\n以下是一个示例，展示了如何使用私有构造函数防止类被子类化：\npublic final class FinalClass { private FinalClass() { // private constructor } public static void doSomething() { // do something } } 在这个示例中，FinalClass被声明为final，因此不能被子类化。此外，它的构造函数是私有的，因此不能从子类中被调用。由于该类不能被子类化，因此它的行为不会受到子类的影响，从而避免了继承所带来的副作用和不必要的复杂性。\n在某些情况下，将类设置为不能被实例化，但可以被子类化是有用的。这通常是因为我们希望子类化的类能够继承父类的行为和属性，同时又不希望外部能够实例化该类。以下是一个例子：\npublic abstract class Animal { private String name; protected Animal(String name) { this.name = name; } public String getName() { return name; } public abstract void makeSound(); } public class Dog extends Animal { public Dog(String name) { super(name); } @Override public void makeSound() { System.","title":"《Effective Java 3》笔记4：用私有构造函数使类不可实例化"},{"content":"前言 本篇是对 2023-04-17 到 2023-04-23 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作，手上累积了三个迭代版本，因为临近五一及其他原因，短期内无法发布上线。开发过程中，想着这些版本都会一个个上线，所以三个版本之间合并了代码，存在了依赖关系。以后，还是需要小版本迭代、上一个版本发布之后再从 main 分支合并代码。\n这周先后看了《灌篮高手》电影、《春山如笑》话剧，体验了两种艺术表现形式，都让人失望。\n利用空余时间，将 n8n 进行了调整，只将我在豆瓣、github、spotify、blog、strava 上的活动同步到 telegram，而直接不同步到 memos，单独创建一个 workflow 将 telegram 同步到 memos。这样 telegram 是一个对外分享的频道，而 memos 可以分享一些个人的心情或者说说。另外，为了减少对大家的干扰，不再将 rss 订阅内容同步到我的 telegram 频道。\n灌篮高手 4 月 20 日，灌篮高手国内上映，抽时间下班和老婆去看了这场电影。看完之后发了一个朋友圈：\n两个小时的电影，一场篮球比赛，尽是回忆，留下的是半亩良田半亩差评\n这就是我对这个电影的评价。因为情怀而去看了这部电影，却被情怀出卖了，这年头情怀不值钱了么？整部电影以宫城良田为视角，不停的回忆，四十分钟的比赛节奏不停的中断。很多片段都是动画里的内容，没有多少新内容。流川枫的刻画太少、樱木花道还是那样勇猛、晴子就没出现几次。。。\n看话剧 周六去中南剧场看了一个话剧《春山如笑》，这是第一次看话剧，第一次接触话剧这个艺术表现形式。相比较于电影，我还是更喜欢看电影。\n理财 这周总计支出 292.5 元，明细如下：\n4 月 21 日：59 元，和同事一起吃饭 4 月 22 日：232 元，周末买菜做饭，买水果 4 月 24 日：1.5 元，跑步小腿抽筋，骑共享单车回公司 四月累计支出共 2417 元，其中餐饮和购物占了一半。\n健身 每天走一万步，这周完成了目标。以后每天跑步的话，这个目标就很容易达成了，甚至这个目标会换成每天跑步。\n从 strava 的训练日志，可以看到本周运动记录如下：\n从 strava 的训练日历，可以看到截至 24 日，本月运动了 20 天，23 次，一共跑步了 100 公里。\n工作 Effective Java 3 笔记 请参考《《Effective Java 3》笔记：避免创建不必要的对象》。\n上面这个图是使用 Shots 制作的，它是免费的，可以制作好看的图片，强烈推荐使用。\n本周分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 使用 Python 实现 RSS 转 Newsletter 5 种微服务注册中心该如何选型？ 5 Years of Indie Hacking 一个技术精致的网站：接口设计和图片加载 抛弃又贵又难用的录屏软件，3 分钟入门 FFmpeg 开始学习和使用 Rust 一些工具 EnhanceAI 使用一行代码为网站的输入框增加上 AI 能力。\nAvatar Maker 一款在线 2D 动漫头像生成器，效果比较偏美漫风格。针对于半身头像的一些特征，提供了丰富的选项。\nMarkflow 网页元素快速拷贝的工具，支持复制粘贴到 Figma，React，Html 里。这个网页中可以试用，Inspector 的效果还是很不错的。就是 Free Plan 每个月只能拷贝 5 个 elements 有点过于没诚意。\nShots 一款在线 Mockup 工具，能非常快速的做出套壳的效果图，内置的模版很多，样式调整的颗粒度也很细。适合独立开发快速出图。\n本周嘀咕 其实，大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道或者我的 memos 中，如果有一个脚本可以读取 Telegram 或者 memos 接口获取上周的分享记录，则可以自动化生成分享内容了。于是，花了一点时间写了一个 python 脚本 fetch_memos.py 来读取 memos 接口。\n获取到的内容如下：\n2023-04-21 08:31:23 📺 看过灌篮高手 #douban #watched 查看链接 2023-04-18 20:33:47 📺 看过龙马精神 #douban #watched 查看链接 2023-04-18 20:33:47 📖 最近在读 Rust 权威指南 #douban #reading 查看链接 2023-04-18 20:33:47 📖 最近在读 Python 编程 #douban #reading 查看链接 2023-04-18 20:33:47 📖 最近在读 Python 工匠 #douban #reading 查看链接 2023-04-18 18:40:50 📝 周报-15 ｜ Umami 升级到 2.0、汉街蜡像馆、使用 Strava 跑步 #blog 查看链接 2023-04-17 17:48:43 🌟 chensoul starred chensoul/chensoul.github.io #github #star 查看链接 2023-04-17 17:10:45 📝 《Effective Java 3》笔记：使用私有构造函数或枚举类型创建单例 #blog 查看链接 后续的想法：对上面内容进行分类，比如，将带有豆瓣、Github、Strava、Spotfy、Blog 标签的内容，归纳为我最近的活动；将带有 tool、skill 等标签其他内容归纳为我的分享（技术相关）；将其他内容归纳为我发表的说说。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/25/weekly_review_16/","summary":"前言 本篇是对 2023-04-17 到 2023-04-23 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作，手上累积了三个迭代版本，因为临近五一及其他原因，短期内无法发布上线。开发过程中，想着这些版本都会一个个上线，所以三个版本之间合并了代码，存在了依赖关系。以后，还是需要小版本迭代、上一个版本发布之后再从 main 分支合并代码。\n这周先后看了《灌篮高手》电影、《春山如笑》话剧，体验了两种艺术表现形式，都让人失望。\n利用空余时间，将 n8n 进行了调整，只将我在豆瓣、github、spotify、blog、strava 上的活动同步到 telegram，而直接不同步到 memos，单独创建一个 workflow 将 telegram 同步到 memos。这样 telegram 是一个对外分享的频道，而 memos 可以分享一些个人的心情或者说说。另外，为了减少对大家的干扰，不再将 rss 订阅内容同步到我的 telegram 频道。\n灌篮高手 4 月 20 日，灌篮高手国内上映，抽时间下班和老婆去看了这场电影。看完之后发了一个朋友圈：\n两个小时的电影，一场篮球比赛，尽是回忆，留下的是半亩良田半亩差评\n这就是我对这个电影的评价。因为情怀而去看了这部电影，却被情怀出卖了，这年头情怀不值钱了么？整部电影以宫城良田为视角，不停的回忆，四十分钟的比赛节奏不停的中断。很多片段都是动画里的内容，没有多少新内容。流川枫的刻画太少、樱木花道还是那样勇猛、晴子就没出现几次。。。\n看话剧 周六去中南剧场看了一个话剧《春山如笑》，这是第一次看话剧，第一次接触话剧这个艺术表现形式。相比较于电影，我还是更喜欢看电影。\n理财 这周总计支出 292.5 元，明细如下：\n4 月 21 日：59 元，和同事一起吃饭 4 月 22 日：232 元，周末买菜做饭，买水果 4 月 24 日：1.5 元，跑步小腿抽筋，骑共享单车回公司 四月累计支出共 2417 元，其中餐饮和购物占了一半。\n健身 每天走一万步，这周完成了目标。以后每天跑步的话，这个目标就很容易达成了，甚至这个目标会换成每天跑步。\n从 strava 的训练日志，可以看到本周运动记录如下：\n从 strava 的训练日历，可以看到截至 24 日，本月运动了 20 天，23 次，一共跑步了 100 公里。\n工作 Effective Java 3 笔记 请参考《《Effective Java 3》笔记：避免创建不必要的对象》。\n上面这个图是使用 Shots 制作的，它是免费的，可以制作好看的图片，强烈推荐使用。\n本周分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 使用 Python 实现 RSS 转 Newsletter 5 种微服务注册中心该如何选型？ 5 Years of Indie Hacking 一个技术精致的网站：接口设计和图片加载 抛弃又贵又难用的录屏软件，3 分钟入门 FFmpeg 开始学习和使用 Rust 一些工具 EnhanceAI 使用一行代码为网站的输入框增加上 AI 能力。","title":"周报-16｜《灌篮高手》电影、《春山如笑》话剧"},{"content":"本文是 《Effective Java 3》第二章的学习笔记：避免创建不必要的对象。\n介绍 创建对象时，经常会复用对象。如果对象是不可变的，那么它总是可以被复用的。\n下面一个例子：\nString s = new String(\u0026#34;bikini\u0026#34;); // DON\u0026#39;T DO THIS! 该语句每次执行时都会创建一个新的 String 实例，而这些对象创建都不是必需的。String 构造函数的参数 (\u0026quot;bikini\u0026quot;) 本身就是一个 String 实例，在功能上与构造函数创建的所有对象相同。如果这种用法发生在循环或频繁调用的方法中，创建大量 String 实例是不必要的。\n改进后的版本如下：\nString s = \u0026#34;bikini\u0026#34;; 这个版本使用单个 String 实例，而不是每次执行时都创建一个新的实例。此外，可以保证在同一虚拟机中运行的其他代码都可以复用该对象，只要恰好包含相同的字符串字面量。\n通常可以通过使用静态工厂方法来避免创建不必要的对象，而不是在提供这两种方法的不可变类上使用构造函数。例如，工厂方法 Boolean.valueOf(String) 比构造函数 Boolean(String) 更可取，后者在 Java 9 中被弃用了。构造函数每次调用时都必须创建一个新对象，而工厂方法从来不需要这样做，在实际应用中也不会这样做。除了复用不可变对象之外，如果知道可变对象不会被修改，也可以复用它们。\n有些对象的创建的代价相比而言要昂贵得多。如果你需要重复地使用这样一个「昂贵的对象」，那么最好将其缓存以供复用。\n下面是使用正则表达式最简单的方法：\n// Performance can be greatly improved! static boolean isRomanNumeral(String s) { return s.matches(\u0026#34;^(?=.)M*(C[MD]|D?C{0,3})\u0026#34; + \u0026#34;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\u0026#34;); } 这个实现的问题是它依赖于 String.matches 方法。虽然 String.matches 是检查字符串是否与正则表达式匹配的最简单方法，但它不适合在性能关键的情况下重复使用。 问题在于，它在内部为正则表达式创建了一个 Pattern 实例，并且只使用一次，之后就进行垃圾收集了。创建一个 Pattern 实例是很昂贵的，因为它需要将正则表达式编译成有限的状态机。\n为了提高性能，将正则表达式显式编译为 Pattern 实例（它是不可变的），作为类初始化的一部分，缓存它，并在每次调用 isRomanNumeral 方法时复用同一个实例：\n// Reusing expensive object for improved performance public class RomanNumerals { private static final Pattern ROMAN = Pattern.compile(\u0026#34;^(?=.)M*(C[MD]|D?C{0,3})\u0026#34; + \u0026#34;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\u0026#34;); static boolean isRomanNumeral(String s) { return ROMAN.matcher(s).matches(); } } 如果频繁调用 isRomanNumeral，改进版本将提供显著的性能提升。不仅性能得到了改善，清晰度也得到了提高。为不可见的 Pattern 实例创建一个静态终态字段允许我们为它命名，这比正则表达式本身更容易阅读。\n如果加载包含改进版 isRomanNumeral 方法的类时，该方法从未被调用过，那么初始化字段 ROMAN 是不必要的。因此，可以用延迟初始化字段的方式在第一次调用 isRomanNumeral 方法时才初始化字段，而不是在类加载时初始化，但不建议这样做。通常情况下，延迟初始化会使实现复杂化，而没有明显的性能改善。\n当一个对象是不可变的，很明显，它可以安全地复用，但在其他情况下，它远不那么明显，甚至违反直觉。考虑适配器的情况，也称为视图。适配器是委托给支持对象的对象，提供了一个替代接口。因为适配器的状态不超过其支持对象的状态，所以不需要为给定对象创建一个给定适配器的多个实例。\n例如，Map 接口的 keySet 方法返回 Map 对象的 Set 视图，其中包含 Map 中的所有键。事实上，返回的 Set 实例通常是可变的，但所有返回的对象在功能上都是相同的，因为它们都由相同的 Map 实例支持。因此，对给定 Map 对象上的 keySet 的每次调用都可能返回相同的 Set 实例。\n由于返回的 Set 实例在功能上是相同的，因此创建 keySet 视图对象的多个实例是不必要的，也没有好处。因此，在使用 keySet 视图的时候，我们应该尽可能地重用同一个 Set 实例，而不是每次调用 keySet 方法都创建一个新的 Set 实例。\n以下是一个示例，展示了如何重用 keySet 视图的 Set 实例：\nimport java.util.HashMap; import java.util.Map; import java.util.Set; public class TestKeySetReuse { private static final Map\u0026lt;Integer, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); public static void main(String[] args) { map.put(1, \u0026#34;one\u0026#34;); map.put(2, \u0026#34;two\u0026#34;); map.put(3, \u0026#34;three\u0026#34;); Set\u0026lt;Integer\u0026gt; keySet1 = map.keySet(); Set\u0026lt;Integer\u0026gt; keySet2 = map.keySet(); System.out.println(keySet1 == keySet2); // true，说明是同一个实例 keySet1.remove(1); System.out.println(map); // {2=two, 3=three} System.out.println(keySet2); // [2, 3] } } 在这个示例中，我们首先创建了一个 HashMap 对象，并向其中添加了一些键值对。然后，我们两次调用 keySet 方法，分别将返回的 Set 实例保存到 keySet1 和 keySet2 变量中。\n由于 keySet1 和 keySet2 是由相同的 Map 实例支持的，因此它们是相等的，即 keySet1 == keySet2 返回 true。我们可以看到，实际上它们是同一个 Set 实例。\n然后，我们从 keySet1 中删除一个键，并打印出 Map 和 keySet2 的内容。我们可以看到，当我们修改了 keySet1 中的内容时，keySet2 也被修改了，因为它们是同一个 Set 实例。\n因此，在使用 Map 的 keySet 方法时，应该尽可能地重用同一个 Set 实例，以避免不必要的对象创建和不必要的行为。\n另一种创建不必要对象的方法是自动装箱，它允许程序员混合基本类型和包装类型，根据需要自动装箱和拆箱。自动装箱模糊了基本类型和包装类型之间的区别， 两者有细微的语义差别和不明显的性能差别。\n// Hideously slow! Can you spot the object creation? private static long sum() { Long sum = 0L; for (long i = 0; i \u0026lt;= Integer.MAX_VALUE; i++) sum += i; return sum; } 这个程序得到了正确的答案，但是由于一个字符的印刷错误，它的速度比实际要慢得多。变量 sum 被声明为 Long 而不是 long，这意味着程序将构造大约 231 个不必要的 Long 实例（大约每次将 Long i 添加到 Long sum 时都有一个实例）。将 sum 的声明从 Long 更改为 long，机器上的运行时间将从 6.3 秒减少到 0.59 秒。教训很清楚：基本类型优于包装类，还应提防意外的自动装箱。\n本条目不应该被曲解为是在暗示创建对象是成本昂贵的，应该避免。相反，创建和回收这些小对象的构造函数成本是很低廉的，尤其是在现代 JVM 实现上。创建额外的对象来增强程序的清晰性、简单性或功能通常是件好事。\n相反，通过维护自己的对象池来避免创建对象不是一个好主意，除非池中的对象非常重量级。证明对象池是合理的对象的典型例子是数据库连接。建立连接的成本非常高，因此复用这些对象是有意义的。然而，一般来说，维护自己的对象池会使代码混乱，增加内存占用，并损害性能。现代 JVM 实现具有高度优化的垃圾收集器，在轻量级对象上很容易胜过这样的对象池。\n总结 避免创建不必要的对象可以提高性能和减少内存占用。\n// 不推荐的写法，会创建不必要的对象 Integer sum = 0; for (int i = 0; i \u0026lt; 1000000; i++) { sum += i; } // 推荐的写法，使用基本类型 int sum = 0; for (int i = 0; i \u0026lt; 1000000; i++) { sum += i; } 如果一个对象是不可变的，可以将其缓存起来并重复使用，而不是每次需要时都创建一个新对象。\n以下是一些常见的不可变对象和它们的缓存实现：\n字符串常量池 Java 语言中的字符串是不可变的，因此字符串常量可以被缓存起来并重复使用。Java 虚拟机维护了一个字符串常量池，它缓存了所有的字符串常量，并确保相同的字符串只被创建一次。\nString s1 = \u0026#34;Hello\u0026#34;; // 从字符串常量池中获取 String s2 = \u0026#34;Hello\u0026#34;; // 从字符串常量池中获取 String s3 = new String(\u0026#34;Hello\u0026#34;); // 创建新的字符串对象 System.out.println(s1 == s2); // true System.out.println(s1 == s3); // false 数字常量池 Java 语言中的整数、浮点数和字符等基本数据类型的值也可以被缓存起来并重复使用。Java 虚拟机维护了一个数字常量池，它缓存了一定范围内的整数、浮点数和字符等基本数据类型的值，并确保相同的值只被创建一次。\nInteger i1 = 100; // 从数字常量池中获取 Integer i2 = 100; // 从数字常量池中获取 Integer i3 = new Integer(100); // 创建新的 Integer 对象 System.out.println(i1 == i2); // true System.out.println(i1 == i3); // false 注意：数字常量池的范围可以通过 JVM 参数 -XX:AutoBoxCacheMax=\u0026lt;size\u0026gt; 来调整，其中 \u0026lt;size\u0026gt; 是常量池的大小。\n枚举常量 Java 语言中的枚举常量是不可变的，它们在枚举类型被加载时就被创建并缓存起来，而不是每次需要时都创建一个新对象。\nenum Color { RED, GREEN, BLUE }; Color c1 = Color.RED; // 获取枚举常量 RED Color c2 = Color.GREEN; // 获取枚举常量 GREEN Color c3 = new Color(\u0026#34;YELLOW\u0026#34;); // 创建新的枚举常量 System.out.println(c1 == c2); // false System.out.println(c1 == Color.RED); // true LocalDate、LocalTime、LocalDateTime Java 8 引入的日期时间 API 中的 LocalDate、LocalTime、LocalDateTime 类型都是不可变的。这些类型的对象可以被缓存起来并重复使用，以提高程序的性能。\nLocalDate today = LocalDate.now(); // 获取当前日期 LocalDate tomorrow = today.plusDays(1); // 计算明天的日期 LocalDate yesterday = today.minusDays(1); // 计算昨天的日期 可以使用线程安全的 ConcurrentHashMap 来实现 LocalDate 的缓存：\nConcurrentHashMap\u0026lt;String, LocalDate\u0026gt; cache = new ConcurrentHashMap\u0026lt;\u0026gt;(); LocalDate date = cache.computeIfAbsent(\u0026#34;2023-04-24\u0026#34;, LocalDate::parse); BigDecimal Java 中的 BigDecimal 类型也是不可变的，它们的值在创建后不会改变。因此，可以将 BigDecimal 对象缓存起来并重复使用，以避免不必要的对象创建。\nBigDecimal zero = BigDecimal.ZERO; // 缓存 0 BigDecimal one = BigDecimal.ONE; // 缓存 1 BigDecimal ten = BigDecimal.TEN; // 缓存 10 可以使用静态 final 常量来实现 BigDecimal 的缓存：\npublic class Constants { public static final BigDecimal ZERO = BigDecimal.ZERO; public static final BigDecimal ONE = BigDecimal.ONE; public static final BigDecimal TEN = BigDecimal.TEN; } Immutable Collections Guava 和 Java 9+ 中都提供了不可变集合类，如 ImmutableList、ImmutableSet、ImmutableMap 等。这些不可变集合类的对象是不可变的，因此可以被缓存起来并重复使用。\nImmutableList\u0026lt;String\u0026gt; list = ImmutableList.of(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); // 创建不可变列表 ImmutableSet\u0026lt;Integer\u0026gt; set = ImmutableSet.of(1, 2, 3); // 创建不可变集合 ImmutableMap\u0026lt;String, Integer\u0026gt; map = ImmutableMap.of(\u0026#34;a\u0026#34;, 1, \u0026#34;b\u0026#34;, 2, \u0026#34;c\u0026#34;, 3); // 创建不可变映射 可以使用静态 final 常量来实现不可变集合的缓存：\npublic class Constants { public static final ImmutableList\u0026lt;String\u0026gt; LIST = ImmutableList.of(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); public static final ImmutableSet\u0026lt;Integer\u0026gt; SET = ImmutableSet.of(1, 2, 3); public static final ImmutableMap\u0026lt;String, Integer\u0026gt; MAP = ImmutableMap.of(\u0026#34;a\u0026#34;, 1, \u0026#34;b\u0026#34;, 2, \u0026#34;c\u0026#34;, 3); } 避免使用装箱类型，如 Integer、Boolean 等，因为它们在自动装箱和拆箱时会创建不必要的对象。可以使用基本类型和对象包装类型之间的相互转换方法来避免这种情况。\n对于大量的短字符串，可以考虑使用字符串池或者使用 String.intern() 方法，以避免创建大量的 String 对象。\n// 不推荐的写法，会创建大量的 String 对象 String str = \u0026#34;\u0026#34;; for (int i = 0; i \u0026lt; 1000000; i++) { str += \u0026#34;a\u0026#34;; } // 推荐的写法，使用 StringBuilder 和字符串池 StringBuilder sb = new StringBuilder(); for (int i = 0; i \u0026lt; 1000000; i++) { sb.append(\u0026#34;a\u0026#34;); } String str = sb.toString().intern(); String.intern() 方法\nString.intern() 方法是一个 native 方法，它的作用是返回字符串对象的规范化表示形式，即返回字符串常量池中与该字符串相等的对象的引用（如果常量池中已经存在该字符串，则直接返回常量池中的对象；否则，将该字符串添加到常量池中，并返回该字符串的引用）。\n例如，假设我们有如下代码：\nString s1 = \u0026#34;hello\u0026#34;; String s2 = new String(\u0026#34;hello\u0026#34;); String s3 = s2.intern(); 在这个代码中，我们首先创建了一个字符串对象 s1，它是字符串常量池中的一个对象。然后，我们通过 new 关键字创建了一个新的字符串对象 s2，它与 s1 的内容相同，但是它在堆内存中创建。接下来，我们调用 s2 的 intern() 方法，将 s2 放入字符串常量池中，并返回常量池中的对象引用。因此，s3 指向的是字符串常量池中的对象。\n需要注意的是，由于字符串常量池中的字符串对象是唯一的，因此使用 intern() 方法可以节省内存空间。但是，由于字符串常量池的空间是有限的，如果程序中大量使用 intern() 方法，可能会导致常量池溢出的问题。因此，如果不是必须使用 intern() 方法，最好不要使用它。\n另外，由于 intern() 方法是一个 native 方法，它的性能可能会比较低。在实际开发中，应该根据具体情况进行选择，避免滥用 intern() 方法。\n尽量使用静态工厂方法而不是构造方法创建对象，因为静态工厂方法可以重复使用已经创建的对象，从而避免创建不必要的对象。\n// 不推荐的写法，每次都创建一个新的对象 Date now = new Date(); // 推荐的写法，使用静态工厂方法 Date now = Date.from(Instant.now()); 避免创建不必要的数组，可以使用 List、Set、Map 等集合类型来代替数组。\n// 不推荐的写法，会创建不必要的数组对象 String[] arr = new String[]{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}; // 推荐的写法，使用 List List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); 如果必须创建不可变的数组，可以使用静态工厂方法 Arrays.asList() 来创建 List，从而避免创建额外的数组对象。\n// 不推荐的写法，会创建不必要的数组对象 String[] arr = new String[]{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;}; List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(arr)); // 推荐的写法，使用 Arrays.asList() List\u0026lt;String\u0026gt; list = Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;); 避免创建过多的临时对象，如在循环中创建的对象。可以重复使用已经创建的对象，或者使用可重用的对象池来减少对象的创建和垃圾回收。\n// 不推荐的写法，会创建不必要的对象 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10000; i++) { list.add(String.valueOf(i)); } // 推荐的写法，使用可重用的对象池 List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); StringBuffer sb = new StringBuffer(); for (int i = 0; i \u0026lt; 10000; i++) { sb.setLength(0); sb.append(i); list.add(sb.toString()); } 避免在类的构造方法中创建大量的对象。如果在构造方法中创建大量的对象，会导致内存占用过大，从而影响程序的性能。可以将对象的创建放在需要使用的方法中，或者使用懒加载的方式来延迟对象的创建。\n// 不推荐的写法，会在构造方法中创建大量的对象 public class MyClass { private List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); public MyClass() { for (int i = 0; i \u0026lt; 10000; i++) { list.add(String.valueOf(i)); } } } // 推荐的写法，将对象的创建放在需要使用的方法中 public class MyClass { private List\u0026lt;String\u0026gt; list; public MyClass() {} public List\u0026lt;String\u0026gt; getList() { if (list == null) { list = new ArrayList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 10000; i++) { list.add(String.valueOf(i)); } } return list; } } 避免在递归方法中创建不必要的对象。如果在递归方法中创建不必要的对象，会导致内存占用过大，从而导致栈溢出等问题。可以使用可重用的对象池来减少对象的创建和垃圾回收。\n// 不推荐的写法，会在递归方法中创建不必要的对象 public static int fibonacci(int n) { if (n \u0026lt;= 1) { return n; } return fibonacci(n - 1) + fibonacci(n - 2); } // 推荐的写法，使用可重用的对象池 public static int fibonacci(int n, Map\u0026lt;Integer, Integer\u0026gt; cache) { if (n \u0026lt;= 1) { return n; } if (cache.containsKey(n)) { return cache.get(n); } int result = fibonacci(n - 1, cache) + fibonacci(n - 2, cache); cache.put(n, result); return result; } 适配器模式 适配器模式是一种常见的设计模式，它可以帮助我们将一个对象的接口适配成另一个对象的接口。适配器模式通常用于以下情况：\n当我们需要使用一个已有的类，但是它的接口与我们期望的不兼容时，我们可以使用适配器模式来将其接口适配成我们需要的接口。 当我们需要使用多个不兼容的类时，我们可以使用适配器模式来将它们的接口适配成一个统一的接口。 在适配器模式中，适配器对象通常是不可变的，因为它们的状态不超过支持对象的状态。因此，可以安全地复用适配器对象。\n例如，考虑一个支持英国插头的设备，但我们需要将其插入到一个美国插座上。我们可以使用一个适配器来适配英国插头到美国插座。适配器的状态不超过英国插头的状态，因此可以安全地复用适配器对象，而不必为每个设备创建一个新的适配器对象。\n以下是一个简单的适配器示例：\n// 支持英国插头的设备 public class BritishDevice { public void plugIn() { System.out.println(\u0026#34;Plugged in British device\u0026#34;); } } // 美国插座接口 public interface USPlug { void plug(); } // 英国到美国的适配器 public class BritishToUSAdapter implements USPlug { private final BritishDevice device; public BritishToUSAdapter(BritishDevice device) { this.device = device; } @Override public void plug() { device.plugIn(); } } // 美国插座 public class USOutlet { public void plugIn(USPlug plug) { plug.plug(); } } // 测试适配器 public class TestAdapter { public static void main(String[] args) { BritishDevice device = new BritishDevice(); BritishToUSAdapter adapter = new BritishToUSAdapter(device); USOutlet outlet = new USOutlet(); outlet.plugIn(adapter); } } 在这个示例中，我们定义了一个 BritishDevice 类来模拟一个支持英国插头的设备。我们还定义了一个 USPlug 接口来表示一个美国插头，以及一个 USOutlet 类来表示一个美国插座。\n我们使用一个适配器类 BritishToUSAdapter 来适配 BritishDevice 到 USPlug 接口。适配器类的构造函数接收一个 BritishDevice 对象，并将其保存在一个成员变量中。适配器实现了 USPlug 接口，并将 plug 方法委托给 BritishDevice 对象的 plugIn 方法。\n在测试适配器时，我们创建了一个 BritishDevice 对象和一个适配器对象，并将适配器对象传递给 USOutlet 的 plugIn 方法。USOutlet 对象使用适配器对象来将 BritishDevice 对象适配到 USPlug 接口，从而将其插入到美国插座中。\n在这个示例中，适配器对象是不可变的，因为它的状态不超过支持对象的状态。因此，我们可以安全地复用适配器对象，而不必为每个设备创建一个新的适配器对象。\n扩展 Java 8 的 Stream API 避免创建不必要对象 下面这段代码：\nlong sum = categoryStatistics.getData().stream().mapToLong(t -\u0026gt; t.getValue()).sum(); 在使用 list.stream().mapToLong(t -\u0026gt; t.getValue()).sum() 对集合中的元素进行求和时，确实可以通过这种方式来避免创建不必要的对象。\n具体来说，mapToLong() 方法会将集合中的元素映射为一个 LongStream 对象，而 LongStream 对象是一个原始类型流，它在内存中的占用空间比较小。因此，使用 mapToLong() 方法可以避免创建不必要的对象，从而提高程序的性能。\n另外，sum() 方法是一个终端操作，它会对流中的所有元素进行求和，并返回最终的结果。由于 sum() 方法是一个终端操作，它会直接对流中的元素进行求和，而不会创建新的对象。因此，使用 sum() 方法可以进一步避免创建不必要的对象，从而提高程序的性能。\n在大多数情况下，list.stream().mapToLong(t -\u0026gt; t.getValue()).sum() 的性能会比 list.stream().mapToLong(t -\u0026gt; t.getValue()).reduce(0L, (a, b) -\u0026gt; a + b) 更好。\n原因是，sum() 方法是一个终端操作，它会对流中的所有元素进行求和，并返回最终的结果。sum() 方法底层使用了一些优化技术，例如使用循环展开、使用 SIMD 指令等，从而充分利用 CPU 的性能优势，提高计算速度。\n相比之下，reduce() 方法是一个归约操作，它将对流中的元素进行累计计算，并返回最终的结果。由于 reduce() 方法需要对元素进行二元操作，因此它比 sum() 方法更加复杂，可能会带来一些额外的开销。此外，reduce() 方法还需要指定一个初始值，如果初始值不当，可能会导致结果错误或者性能下降。\n不过，对于某些特殊情况，reduce() 方法可能会比 sum() 方法更加适用。例如，如果我们需要对流中的元素进行自定义的累计计算，就需要使用 reduce() 方法。此外，reduce()方法还支持并行计算，可以充分利用多核处理器的性能优势，提高计算速度。\n综上所述，我们应该根据具体情况选择使用 sum() 方法还是 reduce() 方法。对于大多数情况下的求和操作，sum() 方法是一个更好的选择，因为它比 reduce() 方法更加高效。但是，在某些特殊情况下，reduce() 方法可能会更加适用。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/24/avoid-creating-unnecessary-objects/","summary":"本文是 《Effective Java 3》第二章的学习笔记：避免创建不必要的对象。\n介绍 创建对象时，经常会复用对象。如果对象是不可变的，那么它总是可以被复用的。\n下面一个例子：\nString s = new String(\u0026#34;bikini\u0026#34;); // DON\u0026#39;T DO THIS! 该语句每次执行时都会创建一个新的 String 实例，而这些对象创建都不是必需的。String 构造函数的参数 (\u0026quot;bikini\u0026quot;) 本身就是一个 String 实例，在功能上与构造函数创建的所有对象相同。如果这种用法发生在循环或频繁调用的方法中，创建大量 String 实例是不必要的。\n改进后的版本如下：\nString s = \u0026#34;bikini\u0026#34;; 这个版本使用单个 String 实例，而不是每次执行时都创建一个新的实例。此外，可以保证在同一虚拟机中运行的其他代码都可以复用该对象，只要恰好包含相同的字符串字面量。\n通常可以通过使用静态工厂方法来避免创建不必要的对象，而不是在提供这两种方法的不可变类上使用构造函数。例如，工厂方法 Boolean.valueOf(String) 比构造函数 Boolean(String) 更可取，后者在 Java 9 中被弃用了。构造函数每次调用时都必须创建一个新对象，而工厂方法从来不需要这样做，在实际应用中也不会这样做。除了复用不可变对象之外，如果知道可变对象不会被修改，也可以复用它们。\n有些对象的创建的代价相比而言要昂贵得多。如果你需要重复地使用这样一个「昂贵的对象」，那么最好将其缓存以供复用。\n下面是使用正则表达式最简单的方法：\n// Performance can be greatly improved! static boolean isRomanNumeral(String s) { return s.matches(\u0026#34;^(?=.)M*(C[MD]|D?C{0,3})\u0026#34; + \u0026#34;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\u0026#34;); } 这个实现的问题是它依赖于 String.matches 方法。虽然 String.matches 是检查字符串是否与正则表达式匹配的最简单方法，但它不适合在性能关键的情况下重复使用。 问题在于，它在内部为正则表达式创建了一个 Pattern 实例，并且只使用一次，之后就进行垃圾收集了。创建一个 Pattern 实例是很昂贵的，因为它需要将正则表达式编译成有限的状态机。\n为了提高性能，将正则表达式显式编译为 Pattern 实例（它是不可变的），作为类初始化的一部分，缓存它，并在每次调用 isRomanNumeral 方法时复用同一个实例：\n// Reusing expensive object for improved performance public class RomanNumerals { private static final Pattern ROMAN = Pattern.compile(\u0026#34;^(?=.)M*(C[MD]|D?C{0,3})\u0026#34; + \u0026#34;(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\u0026#34;); static boolean isRomanNumeral(String s) { return ROMAN.","title":"《Effective Java 3》笔记6：避免创建不必要的对象"},{"content":"前言 题图：楚河汉街蜡像馆\n本篇是对 2023-04-10 到 2023-04-16 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作不算忙碌，继续学习《Effective Java 3》这本书，并花了一些时间学习 Rust、Python 的基础语法。\n这个月已经过了一半，减肥也进行了两周，体重从 72 公斤减到了现在的 68.4 公斤。在之前每天走路 1 万步的基础上，打算开始每天跑步，比记录跑步数据。\n这周总计支出 916 元，明细如下：\n4 月 12 日：329 元，开通 ETC 预存 300 元 4 月 15 日：116 元，周末买菜做饭 4 月 16 日：471 元，老婆过生，吃饭和看电影 四月累计支出共 2025 元，其中餐饮和购物占了一半。\n健身 这周每天走路步数如下，其中有一天因为加班而没有完成一万步的目标。\n受 @Conge 博客影响，开始记录每天的跑步数据。首先是注册了 strava 账号，然后参考 running_page 部署了一个我的跑步主页 run.chensoul.cc。\n因为我之前是使用悦跑圈 APP 记录跑步，所以又参考这篇文章导出 gpx 数据，然后同步到 Strava。最后，可以把悦跑圈 APP 卸载了。\n上周跑步数据如下，总计 28.64 公里，比上周的 19.05 公里多了 9.6 公里。\n上面搞定了之后，就可以使用 Strava 来跑步了。为了增加社交乐趣性，我在 n8n 里面创建了一个 workflow，将 Strava 活动发送到我的『ChenSoul Share』Telegram 频道，效果如下。\nUmami 升级到 2.0 1、首先备份数据库\n2、升级数据库\ngit clone https://github.com/umami-software/migrate-v1-v2.git cd migrate-v1-v2 yarn install yarn build 创建 .env 文件：\n#修改为你的数据库地址 DATABASE_URL=postgresql://umami:xxxxx@postgres.chensoul.cc:5432/umami 运行：\nyarn start 3、重新部署静态页面\n日志提示报错：\n解决办法是修改 scripts/check-db.js：\n4、修改跟踪脚本，把站点中所有追踪脚本名字umami.js改为script.js。\n5、最后查看实时仪表盘。我的 umami 实时 访问地址\n工作 Effective Java 3 笔记 请参考《Effective Java 3 笔记：依赖注入优于硬编码资源》。\n汉街蜡像馆 周末趁武汉旅游大年卡还没过期，跑到楚河汉街蜡像馆去溜达了一圈。因为有年卡，省去了 150 元的门票。\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 1、Java 编程教程\n这个网站是新加坡南洋理工大学的一位老师的教案（英文），主要内容为新生的 Java 编程\n2、offsec.tools\n这个网站收集各种安全相关的软件工具，目前共有 600 多个。\n3、我的习惯养成计划：五分钟规则+打卡\n4、我编程 20 年的指导原则\n5、用 zmv 批量重命名文件\n一些工具 WebPerformance Report 这个网站可以用邮箱订阅你的网站性能的个性化报告。它会监控指定网站的性能，每周会发送一封报告邮件给你。 ","permalink":"https://blog.chensoul.cc/posts/2023/04/18/weekly_review_15/","summary":"前言 题图：楚河汉街蜡像馆\n本篇是对 2023-04-10 到 2023-04-16 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作不算忙碌，继续学习《Effective Java 3》这本书，并花了一些时间学习 Rust、Python 的基础语法。\n这个月已经过了一半，减肥也进行了两周，体重从 72 公斤减到了现在的 68.4 公斤。在之前每天走路 1 万步的基础上，打算开始每天跑步，比记录跑步数据。\n这周总计支出 916 元，明细如下：\n4 月 12 日：329 元，开通 ETC 预存 300 元 4 月 15 日：116 元，周末买菜做饭 4 月 16 日：471 元，老婆过生，吃饭和看电影 四月累计支出共 2025 元，其中餐饮和购物占了一半。\n健身 这周每天走路步数如下，其中有一天因为加班而没有完成一万步的目标。\n受 @Conge 博客影响，开始记录每天的跑步数据。首先是注册了 strava 账号，然后参考 running_page 部署了一个我的跑步主页 run.chensoul.cc。\n因为我之前是使用悦跑圈 APP 记录跑步，所以又参考这篇文章导出 gpx 数据，然后同步到 Strava。最后，可以把悦跑圈 APP 卸载了。\n上周跑步数据如下，总计 28.64 公里，比上周的 19.05 公里多了 9.6 公里。\n上面搞定了之后，就可以使用 Strava 来跑步了。为了增加社交乐趣性，我在 n8n 里面创建了一个 workflow，将 Strava 活动发送到我的『ChenSoul Share』Telegram 频道，效果如下。\nUmami 升级到 2.0 1、首先备份数据库\n2、升级数据库\ngit clone https://github.com/umami-software/migrate-v1-v2.git cd migrate-v1-v2 yarn install yarn build 创建 .env 文件：\n#修改为你的数据库地址 DATABASE_URL=postgresql://umami:xxxxx@postgres.chensoul.cc:5432/umami 运行：","title":"周报-15｜Umami升级到2.0、汉街蜡像馆、使用Strava跑步"},{"content":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 依赖注入是软件工程中使用的一种设计模式，用于将组件和依赖项相互解耦。而不是在组件内部创建和管理依赖项，我们从外部传递它们。这种方法可以帮助创建更模块化和灵活的代码。\n相比之下，硬编码资源涉及在组件内部直接创建和管理依赖项。这种方法可能会使代码不太灵活，难以维护。\n举例 许多类依赖于一个或多个底层资源。例如，拼写检查程序依赖于字典。常见做法是，将这种类实现为静态实用工具类：\n// Inappropriate use of static utility - inflexible \u0026amp; untestable! public class SpellChecker { private static final Lexicon dictionary = ...; private SpellChecker() {} // Noninstantiable public static boolean isValid(String word) { ... } public static List\u0026lt;String\u0026gt; suggestions(String typo) { ... } } 类似地，我们也经常看到它们的单例实现：\n// Inappropriate use of singleton - inflexible \u0026amp; untestable! public class SpellChecker { public static INSTANCE = new SpellChecker(...); private final Lexicon dictionary = ...; private SpellChecker(...) {} public boolean isValid(String word) { ... } public List\u0026lt;String\u0026gt; suggestions(String typo) { ... } } 这两种方法都不令人满意，因为它们假设只使用一个字典。在实际应用中，每种语言都有自己的字典，特殊的字典用于特殊的词汇表。另外，最好使用一个特殊的字典进行测试。\n你可以尝试让 SpellChecker 支持多个字典：首先取消 dictionary 字段的 final 修饰，并在现有的拼写检查器中添加更改 dictionary 的方法。但是在并发环境中这种做法是笨拙的、容易出错的和不可行的。静态实用工具类和单例不适用于由底层资源参数化的类。\n所需要的是支持类的多个实例的能力（在我们的示例中是 SpellChecker），每个实例都使用客户端需要的资源（在我们的示例中是 dictionary）。满足此要求的一个简单模式是在创建新实例时将资源传递给构造函数。 这是依赖注入的一种形式：字典是拼写检查器的依赖项，在创建它时被注入到拼写检查器中。\n// Dependency injection provides flexibility and testability public class SpellChecker { private final Lexicon dictionary; public SpellChecker(Lexicon dictionary) { this.dictionary = Objects.requireNonNull(dictionary); } public boolean isValid(String word) { ... } public List\u0026lt;String\u0026gt; suggestions(String typo) { ... } } 依赖注入模式非常简单，许多程序员在不知道其名称的情况下使用了多年。虽然拼写检查器示例只有一个资源（字典），但是依赖注入可以处理任意数量的资源和任意依赖路径。它保持了不可变性，因此多个客户端可以共享依赖对象（假设客户端需要相同的底层资源）。依赖注入同样适用于构造函数、静态工厂和构建器。\n以下是这些情况的示例：\n构造函数 在构造函数中使用依赖注入是最常见的方式。例如，假设我们有一个名为UserService的类，它需要一个能够验证用户的UserValidator接口作为依赖项。我们可以像这样在构造函数中注入UserValidator：\npublic class UserService { private UserValidator userValidator; public UserService(UserValidator userValidator) { this.userValidator = userValidator; } // ... } 静态工厂 静态工厂是一种创建对象的方式，它将创建对象的逻辑封装在一个静态方法中。例如，假设我们有一个名为UserServiceFactory的类，它负责创建UserService实例。我们可以像这样在静态工厂方法中注入UserValidator：\npublic class UserServiceFactory { public static UserService createUserService(UserValidator userValidator) { return new UserService(userValidator); } } 构建器 构建器是一种创建对象的方式，它将创建对象的逻辑封装在一个构建器类中。例如，假设我们有一个名为UserServiceBuilder的类，它负责创建UserService实例。我们可以像这样在构建器类中注入UserValidator：\npublic class UserServiceBuilder { private UserValidator userValidator; public UserServiceBuilder withUserValidator(UserValidator userValidator) { this.userValidator = userValidator; return this; } public UserService build() { return new UserService(userValidator); } } 这样，我们可以使用构建器来创建UserService实例，并在构建器中注入UserValidator。例如：\nUserValidator userValidator = new CustomUserValidator(); UserService userService = new UserServiceBuilder().withUserValidator(userValidator).build(); 这种模式的一个有用变体是将资源工厂传递给构造函数。资源工厂是一种创建和提供对象的方式，它可以在需要时动态地创建和返回资源。在将资源工厂传递给构造函数时，我们可以将对象的创建和配置逻辑从类中移除，从而实现更好的可测试性和可维护性。\n以下是一个使用资源工厂传递给构造函数的示例：\npublic class UserService { private UserValidator userValidator; private DataSource dataSource; public UserService(ResourceFactory resourceFactory) { this.userValidator = resourceFactory.createUserValidator(); this.dataSource = resourceFactory.createDataSource(); } public boolean authenticate(String username, String password) { // perform authentication using userValidator and dataSource ... } } 在上面的示例中，UserService类需要一个能够验证用户的UserValidator实例和一个DataSource实例。这两个依赖项都是通过资源工厂来创建的。通过将资源工厂传递给构造函数，我们可以将对象的创建和配置逻辑从类中移除，并使其更加灵活和可维护。\n例如，假设我们有一个名为MySqlResourceFactory的类，它实现了ResourceFactory接口，并用于创建UserValidator和DataSource实例。我们可以像这样使用它来创建UserService实例：\nResourceFactory resourceFactory = new MySqlResourceFactory(); UserService userService = new UserService(resourceFactory); 使用这种方法，我们将UserService类与具体的资源实现解耦，并使其更加灵活和可维护。同时，我们可以轻松地模拟和测试UserService类，因为我们可以在测试中传递不同的资源工厂实现，而不需要依赖于外部资源。\n函数式接口 在 Java 8 中，Supplier\u0026lt;T\u0026gt;是一个函数式接口，用于表示一个无参数函数，该函数返回类型为T。由于其函数式特性，Supplier\u0026lt;T\u0026gt;非常适合表示工厂，因为它可以提供一种通用的方式来创建对象。\n以下是一个使用Supplier\u0026lt;T\u0026gt;表示工厂的示例：\npublic class UserService { private UserValidator userValidator; public UserService(Supplier\u0026lt;UserValidator\u0026gt; userValidatorFactory) { this.userValidator = userValidatorFactory.get(); } public boolean authenticate(String username, String password) { // perform authentication using userValidator ... } } 在上面的示例中，UserService类的构造函数接受一个Supplier\u0026lt;UserValidator\u0026gt;作为参数。这个Supplier可以在需要时动态地创建UserValidator实例。在UserService类中，我们可以通过调用userValidatorFactory.get()来获取UserValidator实例。\n例如，假设我们有一个名为CustomUserValidator的类，它实现了UserValidator接口，并用于验证用户。我们可以像这样使用UserService类和Supplier\u0026lt;T\u0026gt;来创建UserService实例：\nSupplier\u0026lt;UserValidator\u0026gt; userValidatorFactory = CustomUserValidator::new; UserService userService = new UserService(userValidatorFactory); 在上面的示例中，userValidatorFactory是一个Supplier\u0026lt;UserValidator\u0026gt;实例，它使用CustomUserValidator::new构造函数引用来创建UserValidator实例。通过将这个Supplier传递给UserService类的构造函数，我们可以创建UserService实例，而无需显式地创建UserValidator实例。\n使用Supplier\u0026lt;T\u0026gt;表示工厂可以使我们的代码更加简洁和灵活。它可以使对象的创建更加通用，并允许我们在需要时动态地创建对象。同时，由于Supplier\u0026lt;T\u0026gt;是一个函数式接口，我们可以使用 lambda 表达式和方法引用来创建工厂，使代码更加简洁和易于理解。\n优点 以下是使用依赖注入比硬编码资源的优点：\n可测试性：使用依赖注入，很容易创建和注入模拟对象进行测试。这样，我们可以将正在测试的组件隔离开来，并专注于测试其行为，而不必担心其依赖项的行为。 灵活性：使用依赖注入，我们可以轻松地用不同实现替换依赖项。这在需要更改组件的行为而不更改其代码时非常有用。 解耦：依赖注入有助于将组件与其依赖项解耦，使代码更加模块化并易于维护。 关注点分离：依赖注入将依赖项的创建和管理与组件本身分离，允许更清晰地分离关注点。 运用 依赖注入是一种常见的设计模式，被广泛应用于许多开源框架中。以下是一些常见的开源框架和库，它们使用依赖注入来管理对象之间的依赖关系：\nSpring Framework：Spring 是一个非常流行的 Java 框架，它使用依赖注入来管理应用程序中的对象之间的依赖关系。Spring 通过@Autowired注解和 XML 配置文件来实现依赖注入。 Google Guice：Guice 是一个轻量级的依赖注入框架，它使用 Java 注解来实现依赖注入。Guice 提供了一个Binder接口，使用户可以配置注入规则。 Dagger：Dagger 是一个基于 Java 和 Android 平台的依赖注入框架，它使用 Java 注解和代码生成技术来实现依赖注入。Dagger 提供了一个Component接口，用于表示应用程序对象之间的依赖关系。 CDI：CDI 是 Java EE 6 中引入的一种依赖注入框架，它使用 Java 注解和 XML 配置文件来实现依赖注入。CDI 提供了一个BeanManager接口，使用户可以配置和管理应用程序对象之间的依赖关系。 Micronaut：Micronaut 是一个轻量级的依赖注入框架，它使用 Java 注解和字节码生成技术来实现依赖注入。Micronaut 提供了一个@Inject注解，用于标记需要注入的依赖项。 Weld：Weld 是一个 Java SE 和 Java EE 的依赖注入框架，它使用 Java 注解和 XML 配置文件来实现依赖注入。Weld 提供了一个BeanManager接口，用于配置和管理应用程序对象之间的依赖关系。 PicoContainer：PicoContainer 是一个轻量级的依赖注入框架，它使用 Java 注解和代码生成技术来实现依赖注入。PicoContainer 提供了一个Container接口，用于表示应用程序对象之间的依赖关系。 HK2：HK2 是 Java EE 8 和 Jakarta EE 9 的依赖注入框架，它使用 Java 注解和 XML 配置文件来实现依赖注入。HK2 提供了一个ServiceLocator接口，用于配置和管理应用程序对象之间的依赖关系。 Micrometer：Micrometer 是一个用于度量应用程序性能的库，它使用依赖注入来管理度量记录器之间的依赖关系。Micrometer 支持多种依赖注入框架，包括 Spring 和 Guice。 Google Dagger Hilt：Dagger Hilt 是一个基于 Dagger 2 的依赖注入库，它使用注解来管理对象之间的依赖关系。它提供了一些附加功能，例如使用@ViewModelInject注解来注入 ViewModel 依赖项。 Quarkus：Quarkus 是一个用于构建可扩展的 Java 应用程序的框架，它使用依赖注入来管理应用程序对象之间的依赖关系。它支持多种依赖注入框架，包括 CDI、Spring 和 Guice。 Micronaut Data：Micronaut Data 是一个用于管理数据库访问的库，它使用依赖注入来管理数据访问对象之间的依赖关系。它支持多种 ORM 框架，包括 Hibernate 和 JDBC。 Akka：Akka 是一个用于构建事件驱动应用程序的库，它使用依赖注入来管理 Actor 之间的依赖关系。它提供了一个@Inject注解，用于标记需要注入的依赖项。 JHipster：JHipster 是一个用于生成现代 Web 应用程序的框架，它使用依赖注入来管理应用程序对象之间的依赖关系。它支持多种依赖注入框架，包括 Spring 和 Guice。 Vert.x：Vert.x 是一个基于事件驱动的应用程序框架，它使用依赖注入来管理应用程序对象之间的依赖关系。它支持多种依赖注入框架，包括 CDI 和 Guice。 Quarkus Reactive：Quarkus Reactive 是一个用于构建反应式应用程序的框架，它使用依赖注入来管理应用程序对象之间的依赖关系。它支持多种依赖注入框架，包括 CDI 和 Spring。 Micronaut Security：Micronaut Security 是一个用于管理 Web 应用程序安全的库，它使用依赖注入来管理安全服务之间的依赖关系。它支持多种安全框架，包括 Spring Security 和 Apache Shiro。 Eclipse MicroProfile：Eclipse MicroProfile 是一个用于构建微服务的框架，它使用依赖注入来管理微服务之间的依赖关系。它支持多种依赖注入框架，包括 CDI 和 Guice。 Kotlin Koin：Koin 是一个用于 Kotlin 应用程序的依赖注入库，它使用 DSL 语法来管理应用程序对象之间的依赖关系。它支持单例、工厂和懒加载等不同的注入模式。 Spring Cloud：Spring Cloud 是一个用于构建分布式系统的框架，它使用依赖注入来管理分布式系统之间的依赖关系。它支持多种依赖注入框架，包括 Spring 和 Guice。 Micronaut HTTP Client：Micronaut HTTP Client 是一个用于管理 HTTP 客户端的库，它使用依赖注入来管理 HTTP 客户端之间的依赖关系。它支持多种 HTTP 客户端实现，包括 Apache HttpClient 和 Netty。 Quarkus Security：Quarkus Security 是一个用于管理 Web 应用程序安全的库，它使用依赖注入来管理安全服务之间的依赖关系。它支持多种安全框架，包括 Spring Security 和 Apache Shiro。 这些框架和库都使用依赖注入来管理对象之间的依赖关系，使代码更加灵活、可维护和可测试。它们提供了一些不同的注入技术和 API，以适应不同的应用场景和需求。\nSpring 依赖注入 在 Spring 框架中，依赖注入是核心特性之一。Spring 使用依赖注入来管理应用程序对象之间的依赖关系，以实现松耦合、可测试和可扩展的代码。以下是 Spring 中使用依赖注入的方法：\n注解：Spring 使用注解将依赖项注入到对象中。常用的注解包括@Autowired、@Qualifier和@Value。其中，@Autowired注解用于自动装配依赖项，@Qualifier注解用于指定依赖项的名称或限定符，@Value注解用于从属性文件或环境变量中注入值。 XML 配置文件：Spring 也支持使用 XML 配置文件来定义对象之间的依赖关系。在 XML 配置文件中，可以使用\u0026lt;bean\u0026gt;元素定义对象，并使用\u0026lt;property\u0026gt;元素设置对象的属性和依赖项。 Java 配置类：Spring 还支持使用 Java 配置类来定义对象之间的依赖关系。在 Java 配置类中，可以使用@Configuration注解定义配置类，并使用@Bean注解定义对象，并使用@Autowired注解注入依赖项。 以下是一些在 Spring 中使用依赖注入的例子：\n1、自动装配示例：\n@Component public class MyService { private final MyRepository myRepository; @Autowired public MyService(MyRepository myRepository) { this.myRepository = myRepository; } // ... } 在这个例子中，MyService类通过构造函数注入了MyRepository依赖。在MyService对象创建时，Spring 框架自动装配并注入了MyRepository对象。\n2、XML 配置示例：\n\u0026lt;bean id=\u0026#34;myService\u0026#34; class=\u0026#34;com.example.MyService\u0026#34;\u0026gt; \u0026lt;constructor-arg ref=\u0026#34;myRepository\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;myRepository\u0026#34; class=\u0026#34;com.example.MyRepository\u0026#34;/\u0026gt; 在这个例子中，MyService类和MyRepository类被定义为 Spring 的 bean，并在 XML 配置文件中指定它们之间的依赖关系。在MyService对象创建时，Spring 框架自动创建并注入了MyRepository对象。\n3、Java 配置示例：\n@Configuration public class AppConfig { @Bean public MyService myService(MyRepository myRepository) { return new MyService(myRepository); } @Bean public MyRepository myRepository() { return new MyRepository(); } } 在这个例子中，AppConfig类通过@Bean注解定义了MyService对象和MyRepository对象，并通过方法参数的方式注入了MyRepository依赖。在应用程序启动时，Spring 框架会自动创建并注入这些对象。\nSpring 依赖注入意事项 在使用 Spring 中的依赖注入时，有一些注意事项需要注意，以确保代码的正确性和可维护性。\n依赖项注入的顺序：如果一个类依赖于多个其他类，那么这些依赖项的注入顺序可能会影响到代码的正确性。为了避免这种情况，可以使用@DependsOn注解指定依赖项之间的顺序。 循环依赖：如果两个或多个类之间出现循环依赖，那么会导致对象无法正确创建。为了避免这种情况，可以使用构造函数注入或 setter 注入来解决循环依赖问题。 作用域：Spring 提供了多种作用域，包括单例、原型和请求作用域等。在使用依赖注入时，需要了解每种作用域的区别和适用场景，并选择合适的作用域。 配置文件管理：在使用 XML 配置文件或 Java 配置类时，需要注意配置文件或类的管理和维护。可以使用 Spring 的 Profile 功能来管理不同的配置文件或类，并根据不同的环境或需求来选择合适的配置。 依赖注入类型选择：Spring 支持多种依赖注入类型，包括构造函数注入、setter 注入和字段注入等。需要根据情况选择合适的依赖注入类型，并考虑到代码的可测试性和可维护性。 如何避免循环依赖问题 循环依赖是指两个或多个类之间相互依赖而导致无法正确创建对象的情况。在 Spring 中，可以通过以下几种方式来避免循环依赖问题：\n使用构造函数注入：构造函数注入是指依赖项通过构造函数的方式进行注入。这种方式可以避免循环依赖问题，因为对象的创建顺序是确定的，每个对象都必须先创建其依赖项，然后才能创建自身。 使用 setter 注入：setter 注入是指依赖项通过 setter 方法进行注入。这种方式可以避免循环依赖问题，因为对象的创建顺序是不确定的，每个对象都可以先创建自身，然后再通过 setter 方法注入其依赖项。 使用@Lazy注解：@Lazy注解可以延迟依赖项的注入，直到对象第一次使用该依赖项时才进行注入。这种方式可以避免循环依赖问题，因为对象的创建顺序是不确定的，每个对象都可以先创建自身，然后再等待其依赖项被注入。 优化依赖关系：如果出现循环依赖问题，可以通过优化依赖关系来解决。例如，将依赖项抽象成接口或抽象类，然后通过不同的实现类来解决循环依赖问题。 Spring 多种依赖注入类的优缺点 Spring 支持多种依赖注入类型，包括构造函数注入、setter 注入和字段注入等。各种依赖注入类型的优缺点如下：\n1、构造函数注入\n优点：\n对象创建时依赖项已经确定，可以保证依赖项的完整性和正确性。 依赖项是只读的，可以保证对象的不变性。 缺点：\n构造函数注入比较繁琐，需要在每个类中添加构造函数和依赖项参数。 2、setter 注入\n优点：\nsetter 注入比较灵活，可以随时注入或更改依赖项。 可以使用默认构造函数创建对象，简化代码。 缺点：\n对象创建时依赖项可能还未注入，需要进行 null 检查。 setter 方法是公共的，可能会影响对象的不变性。 3、字段注入\n优点：\n简单方便，不需要手动编写构造函数或 setter 方法。 可以使用默认构造函数创建对象，简化代码。 缺点：\n依赖项是公共的，可能会影响对象的不变性。 对象创建时依赖项可能还未注入，需要进行 null 检查。 总的来说，**构造函数注入是最推荐的依赖注入方式，因为它可以保证对象的完整性和正确性。**setter 注入和字段注入则比较灵活，但需要注意依赖项的注入时机和可能对对象不变性的影响。根据具体的情况和需求，可以选择合适的依赖注入方式。\n总结 总之，不要使用单例或静态实用工具类来实现依赖于一个或多个底层资源的类，这些资源的行为会影响类的行为，也不要让类直接创建这些资源。相反，将创建它们的资源或工厂传递给构造函数（或静态工厂或构建器）。这种操作称为依赖注入，它将大大增强类的灵活性、可复用性和可测试性。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/17/prefer-dependency-injection-to-hardwiring-resources/","summary":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 依赖注入是软件工程中使用的一种设计模式，用于将组件和依赖项相互解耦。而不是在组件内部创建和管理依赖项，我们从外部传递它们。这种方法可以帮助创建更模块化和灵活的代码。\n相比之下，硬编码资源涉及在组件内部直接创建和管理依赖项。这种方法可能会使代码不太灵活，难以维护。\n举例 许多类依赖于一个或多个底层资源。例如，拼写检查程序依赖于字典。常见做法是，将这种类实现为静态实用工具类：\n// Inappropriate use of static utility - inflexible \u0026amp; untestable! public class SpellChecker { private static final Lexicon dictionary = ...; private SpellChecker() {} // Noninstantiable public static boolean isValid(String word) { ... } public static List\u0026lt;String\u0026gt; suggestions(String typo) { ... } } 类似地，我们也经常看到它们的单例实现：\n// Inappropriate use of singleton - inflexible \u0026amp; untestable! public class SpellChecker { public static INSTANCE = new SpellChecker(...); private final Lexicon dictionary = ...; private SpellChecker(...) {} public boolean isValid(String word) { ... } public List\u0026lt;String\u0026gt; suggestions(String typo) { ... } } 这两种方法都不令人满意，因为它们假设只使用一个字典。在实际应用中，每种语言都有自己的字典，特殊的字典用于特殊的词汇表。另外，最好使用一个特殊的字典进行测试。\n你可以尝试让 SpellChecker 支持多个字典：首先取消 dictionary 字段的 final 修饰，并在现有的拼写检查器中添加更改 dictionary 的方法。但是在并发环境中这种做法是笨拙的、容易出错的和不可行的。静态实用工具类和单例不适用于由底层资源参数化的类。","title":"《Effective Java 3》笔记5：依赖注入优于硬编码资源"},{"content":"前言 本篇是对 2023-04-03 到 2023-04-09 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周还是和以前一样每天运动，并开始施行断食。因为是刚开始断食，有时候忍不住饥饿感而吃了一些东西。\n本周工作主要是发布了一个版本，其余时间用来学习 Rust 和 Python，初学这两种语言，他们语法上有很多相似之处。如何学习一门编程语言？整理了一些步骤。尝试了一下用多种语言编写猜数游戏，这些语言包括 Rust、Ptyhon、Go、NodeJs、JavaScript、Kotlin、Bash，除了 Java。这是一个很有意思的事情，如果能够把这些语言都熟练掌握，那就更好了。\n关于健身 完成了每天一万步的计划，并且共跑步 5 次，一共 18.6 公里，平均配速 7 分钟 4 9 秒，每天跳绳 500+。\n关于记账 本周继续使用微信记账本记录每天支出。累计消费 835 元，明细如下：\n4 月 3 日，周一：支出 59 元，餐饮\n4 月 4 日，周二：支出 0 元，\n4 月 5 日，周三：支出 228 元，超市购物\n4 月 6 日，周四：支出 15 元，停车费\n4 月 7 日，周五：支出 12 元\n4 月 8 日，周六：支出 415 元，加油+餐饮\n4 月 8 日，周日：支出 106 元，餐饮\n如何学习一门编程语言 学习一门编程语言的基础语法对于初学者来说非常重要，以下是一些详细的步骤：\n了解编程语言的基础概念：在学习编程语言之前，了解编程的基础概念是非常重要的。例如，变量、数据类型、条件语句、循环、函数等等。 寻找学习资源：学习编程语言的基础语法可以通过各种学习资源来实现，如书籍、教程、在线视频和交互式学习平台等。选择适合自己的学习资源是非常重要的。 学习变量和数据类型：在学习编程语言之前，学习变量和数据类型是必须的。了解如何定义变量、赋值和使用不同的数据类型，例如字符串、整数、浮点数、布尔值等等。 学习条件语句：条件语句是编程语言中的重要概念之一。例如，学习如何使用 if 语句和 else 语句，使程序在特定条件下执行不同的代码块。 学习循环：循环是编程语言中的另一个重要概念。例如，学习如何使用 while 循环和 for 循环，使程序在特定条件下重复执行代码块。 学习函数：函数是编程语言中的重要概念之一。学习如何定义和使用函数，以将代码结构化并重用。 练习编写代码：练习编写代码是学习编程语言基础语法的重要方式。编写小程序或项目，例如打印\u0026quot;Hello World\u0026quot;、计算器或猜数字游戏等。 学习调试和错误处理：学习如何调试代码和处理常见错误，例如语法错误、逻辑错误和运行时错误等。 总结一下，学习一门编程语言的步骤：\n安装\nHello World\n注释 格式化输出 变量和常量\n数据类型\n基本类型 运算 类型转换 复杂类型 表达式和语句\n条件 循环 断言 函数\n类和对象\n包和模块\n异常处理\n标准库\nIO 网络 多线程 单元测试\n接下来，打算按照上面的步骤来学习 Rust、Python、Go，也许还会有 NodeJs 和 Kotlin，并整理相关笔记。\n工作 Effective Java 3 笔记 请参考 《Effective Java 3》笔记：使用私有构造函数或枚举类型创建单例\nRust 因为对 Tauri 这个 GUI 框架挺感兴趣，所以我开始学习 Rust 了，目前在参考 https://rustwiki.org/ 上的 通过例子学 Rust 和 《Rust 权威指南》 学习 Rust。\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 Where to find the EPUB file in iBooks for Mac under OS X 10.9 Mavericks 使用 CDN 加速 Umami 静态资源 实用 Web API 规范 一次本地免费过滤 RSS 的尝试：NetNewsWire 不想当作家的程序员写不出 Redis Kotlin 语法一站式手册 一些工具 Listmonk 一款自主托管的电子邮件列表管理工具。它允许您将邮件列表导入到自己的服务器中，并使用它来管理您的邮件列表和发送电子邮件。Listmonk 具有良好的可扩展性和自定义性，可通过 REST API 进行操作，并支持高级功能，例如自定义字段、模板和自动化工作流程，从而使其成为一个非常有用和灵活的电子邮件列表管理工具。与其他在线邮件列表服务相比，Listmonk 的优势之一是您完全掌控自己的数据和服务器，因此您不必担心第三方公司的数据隐私问题。 SiteSucker SiteSucker 是一款 MacOS 平台上的免费工具，它可以帮助用户将整个网站下载到本地电脑中。使用 SiteSucker，用户只需要输入目标网站的 URL，它就会自动下载该网站的所有页面、图像、视频和其他资源，并将它们保存在本地硬盘上，以便用户离线浏览或备份。SiteSucker 支持多线程下载和断点续传，可以在不中断下载的情况下暂停和恢复下载任务。此外，它还可以过滤 URL，以便用户只下载特定类型的文件，例如 HTML、图像或视频文件。总之，SiteSucker 是一款非常实用的工具，适用于需要离线浏览网站、备份网站或进行网站抓取的用户。 Montaigne 用苹果笔记来创建网站、博客或作品集 WechatExporter 聊天记录导出 RapidAPI 一款 MacOS 平台上的 API 开发工具，它旨在帮助开发人员更轻松地设计、测试和调试 API。Paw 提供了一个直观的用户界面，可以让用户轻松地构建和调试 API 请求，并查看服务器响应。Paw 支持多种 API 协议和格式，例如 REST、SOAP、GraphQL、JSON 和 XML 等，可以与多种服务器端点和身份验证方式进行集成。此外，Paw 还具有强大的自动化和脚本化功能，允许用户使用 JavaScript 或 Python 编写自定义脚本，以自动化 API 测试和集成工作流程。 卸载 MacOS 微信键盘 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/13/weekly_review_14/","summary":"前言 本篇是对 2023-04-03 到 2023-04-09 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周还是和以前一样每天运动，并开始施行断食。因为是刚开始断食，有时候忍不住饥饿感而吃了一些东西。\n本周工作主要是发布了一个版本，其余时间用来学习 Rust 和 Python，初学这两种语言，他们语法上有很多相似之处。如何学习一门编程语言？整理了一些步骤。尝试了一下用多种语言编写猜数游戏，这些语言包括 Rust、Ptyhon、Go、NodeJs、JavaScript、Kotlin、Bash，除了 Java。这是一个很有意思的事情，如果能够把这些语言都熟练掌握，那就更好了。\n关于健身 完成了每天一万步的计划，并且共跑步 5 次，一共 18.6 公里，平均配速 7 分钟 4 9 秒，每天跳绳 500+。\n关于记账 本周继续使用微信记账本记录每天支出。累计消费 835 元，明细如下：\n4 月 3 日，周一：支出 59 元，餐饮\n4 月 4 日，周二：支出 0 元，\n4 月 5 日，周三：支出 228 元，超市购物\n4 月 6 日，周四：支出 15 元，停车费\n4 月 7 日，周五：支出 12 元\n4 月 8 日，周六：支出 415 元，加油+餐饮\n4 月 8 日，周日：支出 106 元，餐饮\n如何学习一门编程语言 学习一门编程语言的基础语法对于初学者来说非常重要，以下是一些详细的步骤：\n了解编程语言的基础概念：在学习编程语言之前，了解编程的基础概念是非常重要的。例如，变量、数据类型、条件语句、循环、函数等等。 寻找学习资源：学习编程语言的基础语法可以通过各种学习资源来实现，如书籍、教程、在线视频和交互式学习平台等。选择适合自己的学习资源是非常重要的。 学习变量和数据类型：在学习编程语言之前，学习变量和数据类型是必须的。了解如何定义变量、赋值和使用不同的数据类型，例如字符串、整数、浮点数、布尔值等等。 学习条件语句：条件语句是编程语言中的重要概念之一。例如，学习如何使用 if 语句和 else 语句，使程序在特定条件下执行不同的代码块。 学习循环：循环是编程语言中的另一个重要概念。例如，学习如何使用 while 循环和 for 循环，使程序在特定条件下重复执行代码块。 学习函数：函数是编程语言中的重要概念之一。学习如何定义和使用函数，以将代码结构化并重用。 练习编写代码：练习编写代码是学习编程语言基础语法的重要方式。编写小程序或项目，例如打印\u0026quot;Hello World\u0026quot;、计算器或猜数字游戏等。 学习调试和错误处理：学习如何调试代码和处理常见错误，例如语法错误、逻辑错误和运行时错误等。 总结一下，学习一门编程语言的步骤：\n安装\nHello World\n注释 格式化输出 变量和常量\n数据类型\n基本类型 运算 类型转换 复杂类型 表达式和语句","title":"周报-14｜如何学习一门编程语言"},{"content":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 单例是一个只实例化一次的类。单例通常表示无状态对象，比如函数或系统组件，它们在本质上是唯一的。将一个类设计为单例会使它的客户端测试时变得困难， 除非它实现了作为其类型的接口，否则无法用模拟实现来代替单例。\n实现 实现单例有两种常见的方法。两者都基于保持构造函数私有和导出公共静态成员以提供对唯一实例的访问。\n在第一种方法中，成员是一个 final 字段：\n// Singleton with public final field public class Elvis { public static final Elvis INSTANCE = new Elvis(); private Elvis() { ... } public void leaveTheBuilding() { ... } } 私有构造函数只调用一次，用于初始化 public static final 修饰的 Elvis 类型字段 INSTANCE。不使用 public 或 protected 的构造函数保证了「独一无二」的空间：一旦初始化了 Elvis 类，就只会存在一个 Elvis 实例，不多也不少。客户端所做的任何事情都不能改变这一点，但有一点需要注意：拥有特殊权限的客户端可以借助 AccessibleObject.setAccessible 方法利用反射调用私有构造函数。\nConstructor\u0026lt;?\u0026gt;[] constructors = Elvis.class.getDeclaredConstructors(); AccessibleObject.setAccessible(constructors, true); Arrays.stream(constructors).forEach(name -\u0026gt; { if (name.toString().contains(\u0026#34;Elvis\u0026#34;)) { Elvis instance = (Elvis) name.newInstance(); instance.leaveTheBuilding(); } }); 如果需要防范这种攻击，请修改构造函数，使其在请求创建第二个实例时抛出异常。\n在实现单例的第二种方法中，公共成员是一种静态工厂方法：\n// Singleton with static factory public class Elvis { private static final Elvis INSTANCE = new Elvis(); private Elvis() { ... } public static Elvis getInstance() { return INSTANCE; } public void leaveTheBuilding() { ... } } 所有对 getInstance() 方法的调用都返回相同的对象引用，并且不会创建其他 Elvis 实例。\n公共字段方法的主要优点是 API 明确了类是单例的：public static 修饰的字段是 final 的，因此它总是包含相同的对象引用。第二个优点是更简单。\n静态工厂方法的一个优点是，它可以在不更改 API 的情况下决定类是否是单例。工厂方法返回唯一的实例，但是可以对其进行修改，为调用它的每个线程返回一个单独的实例。第二个优点是，如果应用程序需要的话，可以编写泛型的单例工厂。使用静态工厂的最后一个优点是方法引用能够作为一个提供者，例如 Elvis::getInstance 是 Supplier\u0026lt;Elvis\u0026gt; 的提供者。\nSupplier\u0026lt;Elvis\u0026gt; sup = Elvis::getInstance; Elvis obj = sup.get(); obj.leaveTheBuilding(); 除非能够与这些优点沾边，否则使用 public 字段的方式更可取。\n要使单例类使用这两种方法中的任何一种实现可序列化，仅仅在其声明中添加实现 serializable 是不够的。要维护单例保证，应声明所有实例字段为 transient，并提供 readResolve 方法。否则，每次反序列化实例时，都会创建一个新实例，在我们的示例中，这会导致出现虚假的 Elvis。\n// readResolve method to preserve singleton property private Object readResolve() { // Return the one true Elvis and let the garbage collector // take care of the Elvis impersonator. return INSTANCE; } 实现单例的第三种方法是声明一个单元素枚举：\n// Enum singleton - the preferred approach public enum Elvis { INSTANCE; public void leaveTheBuilding() { ... } } 这种方法类似于 public 字段方法，但是它更简洁，默认提供了序列化机制，提供了对多个实例化的严格保证，即使面对复杂的序列化或反射攻击也是如此。这种方法可能有点不自然，但是单元素枚举类型通常是实现单例的最佳方法。 注意，如果你的单例必须扩展一个超类而不是 Enum（尽管你可以声明一个 Enum 来实现接口），你就不能使用这种方法。\n扩展 单例模式是一种创建型设计模式，它确保一个类只有一个实例，并提供一个全局访问点来访问该实例。在 Java 语言中，单例模式一般有以下几种实现方式：\n饿汉式单例模式 在类加载时就创建单例实例，因此也称为静态初始化单例。\npublic class EagerSingleton { private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() {} public static EagerSingleton getInstance() { return instance; } } 懒汉式单例模式 在第一次调用getInstance()方法时才创建单例实例，也称为延迟初始化单例。\npublic class LazySingleton { private static LazySingleton instance; private LazySingleton() {} public static synchronized LazySingleton getInstance() { if (instance == null) { instance = new LazySingleton(); } return instance; } } 在这个示例代码中，我们使用了synchronized关键字来保证线程安全。但是这种方式会影响性能，因为每次调用getInstance()方法都会进行同步。因此，我们可以使用双重检查锁定来提高性能。\n双重检查锁定单例模式 在懒汉式单例模式的基础上，使用双重检查锁定来保证线程安全和性能。\npublic class LazySingleton { private static volatile LazySingleton instance; private LazySingleton() {} public static LazySingleton getInstance() { if (instance == null) { synchronized (LazySingleton.class) { if (instance == null) { instance = new LazySingleton(); } } } return instance; } } 在上述实现中，instance 字段使用 volatile 关键字修饰，可以确保多个线程都能够正确地处理该变量。\n在 getInstance() 方法中，首先检查实例是否已经存在，如果存在则直接返回实例引用。否则，获取类对象的锁，再次检查实例是否存在。如果实例仍然不存在，则创建实例。由于 synchronized 关键字可以确保同一时刻只有一个线程可以进入临界区，因此可以避免多个线程同时创建实例的情况。\n需要注意的是，在使用双重锁检测时，需要使用 volatile 关键字来保证多个线程都能够正确地处理共享变量。同时，为了保证所有线程都看到同一个实例，需要使用静态字段来存储单例实例。\n关于 volatile 关键字修饰\n在 Java 中，当一个变量被多个线程共享时，如果没有采取特殊的措施，可能会出现一个线程修改了变量值，但其他线程并没有看到该变量的变化的情况。这是因为每个线程都有自己的 CPU 缓存，该变量的值可能存在于某个线程的 CPU 缓存中，但其他线程并没有及时更新缓存中的值。\nvolatile 是一种 Java 关键字，它可以确保多个线程都能够正确地处理该变量。当一个变量被声明为 volatile 时，它会具有以下特性：\n可见性：当一个线程修改了 volatile 变量的值时，其他线程可以立即看到该变化。 禁止指令重排：编译器和 CPU 会对指令进行重排以提高执行效率，但有时这种重排可能会导致多线程程序出现问题。volatile 变量的写操作会在读操作之前，确保变量的修改对其他线程立即可见，从而禁止指令重排。 在上述单例模式实现中，instance 字段被声明为 volatile，这是为了确保多个线程都能够正确地处理该变量。如果没有使用 volatile，可能会出现某个线程创建了实例，但其他线程并没有看到该变化的情况。使用 volatile 可以确保多个线程都能够正确地处理 instance 变量，从而避免出现多个实例的情况。\n枚举单例模式 使用枚举类型来定义单例，它保证了线程安全和序列化安全。\npublic enum EnumSingleton { INSTANCE; public void doSomething() { // do something } } 关于枚举\n在 Java 中，枚举是一种特殊的类，它可以用于定义一组常量。枚举常量是在枚举类被加载时创建的，且只会被创建一次。因此，枚举天然具有单例模式的特性。\n在 Java 中，单例模式是一种常用的设计模式，它可以确保某个类只有一个实例，并提供全局访问点。单例模式的实现方式有多种，包括懒汉式、饿汉式、双重检查锁等。但是，这些实现方式都需要考虑线程安全和序列化等问题，而枚举天然具有线程安全和序列化的特性。\n枚举类是在 Java 1.5 版本中引入的，它是一个特殊的类，可以用于定义一组常量。枚举常量是在枚举类被加载时创建的，且只会被创建一次。因此，枚举天然具有单例模式的特性，而且枚举类的实现方式非常简单，无需考虑线程安全和序列化等问题。因此，使用枚举实现单例模式是一种简单、安全、高效的方式。\n一个实际中使用的例子：\n@AllArgsConstructor @Getter public enum ChannelType implements CodeAware { VMS(2, \u0026#34;语音电话\u0026#34;) { @Override public AbstractNotificationStrategy strategy(Properties properties, NotificationTemplate notificationTemplate, Collection\u0026lt;NotificationUser\u0026gt; users) { return new VmsNotificationStrategy(new VmsNotificationChannel(properties), notificationTemplate, users); } @Override public NotificationTemplate template(String title, String template, Set\u0026lt;String\u0026gt; imageUrls) { return new VmsNotificationTemplate(title, template, imageUrls); } }, FEISHU(3, \u0026#34;飞书\u0026#34;) { @Override public AbstractNotificationStrategy strategy(Properties properties, NotificationTemplate notificationTemplate, Collection\u0026lt;NotificationUser\u0026gt; users) { return new FeishuNotificationStrategy(new FeishuNotificationChannel(properties), notificationTemplate, users); } @Override public NotificationTemplate template(String title, String template, Set\u0026lt;String\u0026gt; imageUrls) { return new FeishuNotificationTemplate(title, template, imageUrls); } }; private Integer code; private String name; public abstract AbstractNotificationStrategy strategy(Properties properties, NotificationTemplate notificationTemplate, Collection\u0026lt;NotificationUser\u0026gt; users); public abstract NotificationTemplate template(String title, String template, Set\u0026lt;String\u0026gt; imageUrls); } 静态内部类单例模式 静态内部类单例模式是一种常用的实现单例模式的方式，它可以保证线程安全且实现简单。在该模式中，单例实例是通过静态内部类来实现的。\n在 Java 中，静态内部类是一种特殊的类，它是在另一个类内部定义的静态类。静态内部类可以访问外部类的静态字段和方法，但不能访问外部类的非静态字段和方法。\n使用静态内部类实现单例模式的方式如下：\npublic class StaticInnerClassSingleton { private StaticInnerClassSingleton() {} private static class SingletonHolder { private static final StaticInnerClassSingleton INSTANCE = new StaticInnerClassSingleton(); } public static StaticInnerClassSingleton getInstance() { return SingletonHolder.INSTANCE; } } 在上述代码中，SingletonHolder 是静态内部类，它包含一个静态常量 INSTANCE，该常量是在静态内部类被加载时创建的，且只会被创建一次。由于静态内部类的加载是在需要时才进行的，因此可以实现懒加载的效果。在 getInstance 方法中，直接返回 SingletonHolder.INSTANCE 即可获取单例实例。\n在静态内部类单例模式中，由于静态内部类的加载是在需要时才进行的，且只会被加载一次，因此可以保证单例实例的线程安全。在多线程环境下，多个线程同时调用 getInstance 方法时，由于静态内部类的加载是线程安全的，因此可以保证只有一个单例实例被创建。\n此外，静态内部类单例模式的实现方式简单且易于理解，而且不需要考虑线程安全和序列化等问题，因此是一种常用的实现单例模式的方式。\n注册式单例模式 使用容器来存储单例实例，通过唯一的标识符来访问单例实例。\n总的来说，每种实现方式都有其适用的场景和优缺点，开发者需要根据具体的需求来选择合适的实现方式。\npublic class SingletonRegistry { private static Map\u0026lt;String, Object\u0026gt; registry = new HashMap\u0026lt;\u0026gt;(); private SingletonRegistry() {} public static synchronized void register(String name, Object obj) { registry.put(name, obj); } public static synchronized Object getSingleton(String name) { return registry.get(name); } } 在这个示例代码中，我们在register()方法和getSingleton()方法上都加了synchronized关键字，确保了多线程情况下的线程安全。但是这种方式会影响性能，因为每次调用getSingleton()方法都会进行同步。\n以下是使用并发容器实现线程安全的示例代码：\npublic class SingletonRegistry { private static ConcurrentMap\u0026lt;String, Object\u0026gt; registry = new ConcurrentHashMap\u0026lt;\u0026gt;(); private SingletonRegistry() {} public static void register(String name, Object obj) { registry.put(name, obj); } public static Object getSingleton(String name) { return registry.get(name); } } 使用ConcurrentMap的computeIfAbsent方法可以更加简洁地实现线程安全的注册式单例模式，它可以确保多线程情况下的线程安全，并且避免了使用synchronized关键字带来的性能问题。\n以下是使用ConcurrentMap的computeIfAbsent方法实现线程安全的示例代码：\npublic class SingletonRegistry { private static ConcurrentMap\u0026lt;String, Object\u0026gt; registry = new ConcurrentHashMap\u0026lt;\u0026gt;(); private SingletonRegistry() {} public static void register(String name, Object obj) { registry.putIfAbsent(name, obj); } public static Object getSingleton(String name) { return registry.computeIfAbsent(name, key -\u0026gt; createSingleton(key)); } private static Object createSingleton(String name) { // create singleton object return new Object(); } } 在这个示例代码中，我们使用ConcurrentHashMap来存储注册信息，并且使用了putIfAbsent方法来避免重复添加元素。在getSingleton方法中，我们使用了computeIfAbsent方法来获取单例实例，如果实例不存在，则调用createSingleton方法创建实例。由于ConcurrentHashMap的并发操作是线程安全的，因此使用computeIfAbsent方法可以确保多线程情况下的线程安全。\n运用 以下，整理了常见的开源框架中单例模式运用。\nLog4j Log4j 是一个用于记录日志的开源框架，它使用单例模式来管理 Logger 的实例。Logger 是一个线程安全的类，用于记录应用程序的日志信息。\n以下是 Log4j 的单例模式实现代码：\npublic class Logger { private static final Map\u0026lt;String, Logger\u0026gt; instances = new ConcurrentHashMap\u0026lt;\u0026gt;(); private Logger() { // private constructor } public static Logger getLogger(String name) { Logger instance = instances.get(name); if (instance == null) { synchronized (instances) { instance = instances.get(name); if (instance == null) { instance = new Logger(); instances.put(name, instance); } } } return instance; } // other methods } 在这个示例中，Logger 使用一个 Map 来缓存所有的 Logger 实例，并在需要获取 Logger 实例时使用双重检查锁定机制来确保只有一个线程可以创建实例。\nJedis Jedis 是一个用于连接 Redis 数据库的开源框架，它使用单例模式来管理 JedisPool 的实例。JedisPool 是一个线程安全的类，用于管理可重用的 Jedis 实例。\n以下是 Jedis 的单例模式实现代码：\npublic class JedisPool { private static final Map\u0026lt;String, JedisPool\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private JedisPool() { // private constructor } public static synchronized JedisPool getInstance(String host, int port) { String key = host + \u0026#34;:\u0026#34; + port; JedisPool instance = INSTANCES.get(key); if (instance == null) { instance = new JedisPool(host, port); INSTANCES.put(key, instance); } return instance; } // other methods } 在这个示例中，Jedis 使用一个 ConcurrentHashMap 来缓存所有的 JedisPool 实例，并在需要获取 JedisPool 实例时使用 synchronized 方法来确保只有一个线程可以创建实例。\nRetrofit Retrofit 是一个用于简化 HTTP 请求的开源框架，它使用单例模式来管理 Retrofit 的实例。Retrofit 是一个线程安全的类，用于创建 HTTP 请求。\n以下是 Retrofit 的单例模式实现代码：\npublic class Retrofit { private static final Retrofit INSTANCE = new Retrofit(); private Retrofit() { // private constructor } public static Retrofit getInstance() { return INSTANCE; } public \u0026lt;T\u0026gt; T create(Class\u0026lt;T\u0026gt; service) { // create HTTP request using service interface } // other methods } 在这个示例中，Retrofit 使用静态变量和静态方法来获取单例实例，并在整个应用程序中共享使用。\nGson Gson 是一个用于将 JSON 字符串转换为 Java 对象的开源框架，它使用单例模式来管理 Gson 的实例。Gson 是一个线程安全的类，用于处理 JSON 数据。\n以下是 Gson 的单例模式实现代码：\npublic class Gson { private static final Gson INSTANCE = new Gson(); private Gson() { // private constructor } public static Gson getInstance() { return INSTANCE; } public \u0026lt;T\u0026gt; T fromJson(String json, Class\u0026lt;T\u0026gt; classOfT) { // convert JSON string to Java object } // other methods } 在这个示例中，Gson 使用静态变量和静态方法来获取单例实例，并在整个应用程序中共享使用。\nSpring Framework Spring Framework 是一个用于构建企业级 Java 应用程序的开源框架，它使用单例模式来管理 Bean 的实例。Bean 是一个线程安全的类，用于实现应用程序的业务逻辑。\n以下是 Spring Framework 的单例模式实现代码：\npublic class DefaultListableBeanFactory implements BeanFactory { private final Map\u0026lt;String, Object\u0026gt; singletonObjects = new ConcurrentHashMap\u0026lt;\u0026gt;(256); public Object getBean(String name) throws BeansException { Object bean = this.singletonObjects.get(name); if (bean == null) { synchronized (this.singletonObjects) { bean = this.singletonObjects.get(name); if (bean == null) { bean = createBean(name); this.singletonObjects.put(name, bean); } } } return bean; } private Object createBean(String name) { // create Bean instance } // other methods } 在这个示例中，Spring Framework 使用一个 ConcurrentHashMap 来缓存所有的 Bean 实例，并在需要获取 Bean 实例时使用双重检查锁定机制来确保只有一个线程可以创建实例。\nHibernate Hibernate 是一个用于处理关系数据库的开源框架，它使用单例模式来管理 SessionFactory 的实例。SessionFactory 是一个线程安全的类，用于创建和管理 Session 对象。\n以下是 Hibernate 的单例模式实现代码：\npublic class SessionFactory { private static final SessionFactory INSTANCE = new SessionFactory(); private SessionFactory() { // private constructor } public static SessionFactory getInstance() { return INSTANCE; } public Session openSession() { // create and return new Session object } // other methods } 在这个示例中，Hibernate 使用静态变量和静态方法来获取单例实例，并在整个应用程序中共享使用。\nJUnit JUnit 是一个用于编写单元测试的开源框架，它使用单例模式来管理 TestSuite 的实例。TestSuite 是一个线程安全的类，用于管理测试用例的集合。\n以下是 JUnit 的单例模式实现代码：\npublic class TestSuite { private static final TestSuite INSTANCE = new TestSuite(); private final List\u0026lt;TestCase\u0026gt; testCases = new ArrayList\u0026lt;\u0026gt;(); private TestSuite() { // private constructor } public static TestSuite getInstance() { return INSTANCE; } public void addTestCase(TestCase testCase) { testCases.add(testCase); } public void run(TestResult result) { for (TestCase testCase : testCases) { testCase.run(result); } } // other methods } 在这个示例中，JUnit 使用静态变量和静态方法来获取 TestSuite 的单例实例，并在整个测试应用程序中共享使用。\nApache Commons Lang Apache Commons Lang 是一个用于提供常用 Java 工具类的开源库，它使用单例模式来管理 CharSet 的实例。CharSet 是一个线程安全的类，用于管理字符集编码。\n以下是 Apache Commons Lang 的单例模式实现代码：\npublic class CharSet { private static final Map\u0026lt;String, CharSet\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private CharSet() { // private constructor } public static CharSet getInstance(String name) { CharSet instance = INSTANCES.get(name); if (instance == null) { synchronized (CharSet.class) { instance = INSTANCES.get(name); if (instance == null) { instance = new CharSet(); INSTANCES.put(name, instance); } } } return instance; } // other methods } 在这个示例中，Apache Commons Lang 使用一个 ConcurrentHashMap 来缓存所有的 CharSet 实例，并在需要获取 CharSet 实例时使用双重检查锁定机制来确保只有一个线程可以创建实例。\nApache Commons Pool Apache Commons Pool 是一个用于管理对象池的开源库，它使用单例模式来管理 ObjectPool 的实例。ObjectPool 是一个线程安全的类，用于管理可重用对象的池。\n以下是 Apache Commons Pool 的单例模式实现代码：\npublic class GenericObjectPool\u0026lt;T\u0026gt; implements ObjectPool\u0026lt;T\u0026gt; { private static final Map\u0026lt;String, ObjectPool\u0026lt;?\u0026gt;\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private GenericObjectPool() { // private constructor } public static synchronized \u0026lt;T\u0026gt; ObjectPool\u0026lt;T\u0026gt; getInstance(String name, PooledObjectFactory\u0026lt;T\u0026gt; factory) { ObjectPool\u0026lt;?\u0026gt; instance = INSTANCES.get(name); if (instance == null) { instance = new GenericObjectPool\u0026lt;\u0026gt;(factory); INSTANCES.put(name, instance); } return (ObjectPool\u0026lt;T\u0026gt;) instance; } // other methods } 在这个示例中，Apache Commons Pool 使用一个 ConcurrentHashMap 来缓存所有的 ObjectPool 实例，并在需要获取 ObjectPool 实例时使用 synchronized 方法来确保只有一个线程可以创建实例。\nTomcat Tomcat 是一个用于运行 Java Web 应用程序的开源服务器，它使用单例模式来管理 ServletContext 的实例。ServletContext 是一个线程安全的类，用于管理 Web 应用程序的上下文信息。\n以下是 Tomcat 的单例模式实现代码：\npublic class ApplicationContext extends StandardContext { private static final Map\u0026lt;String, ApplicationContext\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private ApplicationContext() { // private constructor } public static ApplicationContext getInstance(String contextPath) { ApplicationContext instance = INSTANCES.get(contextPath); if (instance == null) { synchronized (ApplicationContext.class) { instance = INSTANCES.get(contextPath); if (instance == null) { instance = new ApplicationContext(); instance.setPath(contextPath); INSTANCES.put(contextPath, instance); } } } return instance; } // other methods } 在这个示例中，Tomcat 使用一个 ConcurrentHashMap 来缓存所有的 ServletContext 实例，并在需要获取 ServletContext 实例时使用双重检查锁定机制来确保只有一个线程可以创建实例。\nOkHttp OkHttp 是一个用于进行网络请求的开源框架，它使用单例模式来管理 OkHttpClient 的实例。OkHttpClient 是一个线程安全的类，用于管理网络请求的配置和执行。\n以下是 OkHttp 的单例模式实现代码：\npublic class OkHttpClient { private static final Map\u0026lt;String, OkHttpClient\u0026gt; INSTANCES = new ConcurrentHashMap\u0026lt;\u0026gt;(); private OkHttpClient() { // private constructor } public static synchronized OkHttpClient getInstance() { String key = \u0026#34;default\u0026#34;; OkHttpClient instance = INSTANCES.get(key); if (instance == null) { instance = new OkHttpClient.Builder() .build(); INSTANCES.put(key, instance); } return instance; } // other methods } 在这个示例中，OkHttp 使用一个 ConcurrentHashMap 来缓存所有的 OkHttpClient 实例，并在需要获取 OkHttpClient 实例时使用 synchronized 方法来确保只有一个线程可以创建实例。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/11/enforce-the-singleton-property-with-a-private-constructor-or-an-enum-type/","summary":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 单例是一个只实例化一次的类。单例通常表示无状态对象，比如函数或系统组件，它们在本质上是唯一的。将一个类设计为单例会使它的客户端测试时变得困难， 除非它实现了作为其类型的接口，否则无法用模拟实现来代替单例。\n实现 实现单例有两种常见的方法。两者都基于保持构造函数私有和导出公共静态成员以提供对唯一实例的访问。\n在第一种方法中，成员是一个 final 字段：\n// Singleton with public final field public class Elvis { public static final Elvis INSTANCE = new Elvis(); private Elvis() { ... } public void leaveTheBuilding() { ... } } 私有构造函数只调用一次，用于初始化 public static final 修饰的 Elvis 类型字段 INSTANCE。不使用 public 或 protected 的构造函数保证了「独一无二」的空间：一旦初始化了 Elvis 类，就只会存在一个 Elvis 实例，不多也不少。客户端所做的任何事情都不能改变这一点，但有一点需要注意：拥有特殊权限的客户端可以借助 AccessibleObject.setAccessible 方法利用反射调用私有构造函数。\nConstructor\u0026lt;?\u0026gt;[] constructors = Elvis.class.getDeclaredConstructors(); AccessibleObject.setAccessible(constructors, true); Arrays.stream(constructors).forEach(name -\u0026gt; { if (name.toString().contains(\u0026#34;Elvis\u0026#34;)) { Elvis instance = (Elvis) name.newInstance(); instance.leaveTheBuilding(); } }); 如果需要防范这种攻击，请修改构造函数，使其在请求创建第二个实例时抛出异常。\n在实现单例的第二种方法中，公共成员是一种静态工厂方法：\n// Singleton with static factory public class Elvis { private static final Elvis INSTANCE = new Elvis(); private Elvis() { .","title":"《Effective Java 3》笔记3：使用私有构造函数或枚举类型创建单例"},{"content":"前言 本篇是对 2023-03-27 到 2023-04-02 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周是三月的最后一周，想到这，就想对随便对三月份做个总结。总结的方面，大概包括工作、生活、学习、健身、财务、娱乐几个方面。万事开头难，不知道能者多少，但是，相信不管写多少，都是有意义的。\n先来说说最近一周做了什么。查看一下 gitlab 上标签提交记录，这周发布了一个版本，其余时间是进行测试，为下周发布做准备。在工作之余，开始学习《Effective Java 3》，并用 chatgpt 作为辅助工作，加深对技术的理解。另外，有了想学习 React、Rust、Go、Pyhon 的想法。想学的东西有点多，只能一步步来。争取每天利用下班之后的一个小时进行碎片化的学习，并且做好相关笔记，如有可能发布在这个博客上面。加油！\n这周完成了每天一万步的计划，其中周末走了 3 万多步，并且还开始了跑步。\n关于健身 完成了每天一万步的计划，并且共跑步 8 次，一共 26 公里，最高平均配速 7 分钟，还跳绳一次（550 下）。\n跑步的目的不是快，而是乐此不疲。每天跑步 5 公里，每次消耗 300 卡路里的热量，大概需要 10 周才能瘦 10 斤。\n光靠走路和跑步，想在 4 月完成瘦 10 斤的目标，应该是不可能的，打算辅助间歇性断食，看下效果。\n跑步是一种有氧运动，可以促进身体代谢，消耗体内的脂肪和热量，达到减肥的效果。但是减肥的效果受到很多因素的影响，如个人的体重、身高、年龄、性别、饮食习惯、跑步强度、频率和时长等。\n通常来说，减肥的基本原理是消耗更多的热量，从而达到体重减轻的效果。每天跑步 5 公里的运动量相对较小，一般在一个小时左右可以完成。如果每天坚持跑步，同时注意饮食控制，增加其他有氧运动和合理的休息，可能会在几个月内看到一定的减肥效果。\n根据一般的减肥经验，每消耗 3500 卡路里的热量就可以减少一斤体重。假设每次跑步消耗 300 卡路里的热量，那么每天跑步 5 公里约消耗 300 ~ 400 卡路里的热量。如果每天坚持跑步，并且保持每天消耗 300 ~ 400 卡路里的热量，那么大约需要 10 周时间才能减少 10 斤体重。\n关于记账 上周开始，在寻找一个记账的 APP，想开始记录每天的收入与支出。当然，更多的应该是支出了。现在，大环境不行，公司裁员不停，必须要开源节流，手上储备足够的现金。\n找来找去，发现微信里没有有个『微信记账本』小程序就可以在微信里自动记账，也支持手动记账。于是，这周试了一下这个小程序，并有意的控制自己每天的输出。因为每天都有带饭，这样中饭就不用花钱了；早餐呢，是泡之前买的黑芝麻糊喝，省去了早餐费用。结果是，这周的支出只有 4.5 元。一次是早上买了一本豆浆，一次是早上跑步怕迟到就骑了一次动感单车。\n正好三月结束了，查看了一下三月的支出报表。总的来说，三月支出的有点多，超乎了我的想象。如果每个月都是支出这么多，那以后的零花钱就不够用了。还是要勒紧裤腰带过日子啊。\n更新 SSL 证书 安装 acme.sh\ncurl https://get.acme.sh | sh -s email=chensoul.eth@gmail.com 我的域名托管在 cloudflare，故需要获取 cloudflare API key，在 API 令牌 页面，点击查看 Global API Key。\n保存 CF_Key 和 CF_Email：\nexport CF_Key=\u0026#34;cloudflare 中查看你的 key\u0026#34; export CF_Email=\u0026#34;chensoul.eth@gmail.com\u0026#34; 生成证书，并重启 nginx：\nacme.sh --issue -d \u0026#34;chensoul.cc\u0026#34; -d \u0026#34;*.chensoul.cc\u0026#34; --dns dns_cf \\ --cert-file /usr/local/nginx/ssl/chensoul.cc.cer \\ --key-file /usr/local/nginx/ssl/chensoul.cc.key \\ --fullchain-file /usr/local/nginx/ssl/fullchain.cer \\ --reloadcmd \u0026#34;nginx -s reload\u0026#34; 移除域名证书自动更新\nacme.sh --remove -d chensoul.cc -d \u0026#34;*.chensoul.cc\u0026#34; 百度站点收录 参考 向百度主动推送网站链接 使用脚本定时推送网站链接到百度站点。对 push_to_baidu.sh 脚本的 parse 方法做了如下修改，以解决 xmllint 解析带有命名空间的 xml 文件报错 的问题。\nfunction parse { local file=$1 echo $file $XMLLINT --format --xpath \u0026#34;//*[local-name()=\u0026#39;loc\u0026#39; and namespace-uri()=\u0026#39;http://www.sitemaps.org/schemas/sitemap/0.9\u0026#39;]/text()\u0026#34; \u0026#34;$file\u0026#34; | sed -e \u0026#39;s/https/\\nhttps/g\u0026#39; \u0026gt; \u0026#34;$URL_TEMP\u0026#34; echo $URL_TEMP } 工作 Effective Java 3 笔记 请参考 《Effective Java 3》笔记：使用构造器代替构造函数\nRust 因为对 Tauri 这个 GUI 框架挺感兴趣，所以我开始学习 Rust 了，目前在参考 https://rustwiki.org/ 上的 通过例子学 Rust 和 Rust 程序设计语言 学习 Rust。\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 Go wasm 使用：Go 代码编译成 WebAssembly 及调用\n失业三个月，我都干了啥？\n介绍一下 gitea 的 action\n作为绝对初学者学习 Web 开发\n一些工具 数据统计分析：https://usefathom.com\nCloudflare 图床：Cloudflare Images\nJava 单元测试插件：Squaretest for IntelliJ IDEA\n基于标记的科学排版系统：Typst。可以协同工作，且界面更友好。旨在成为 LaTeX、Word 和 Google Docs 等的替代品。\n数据可视化资源库：https://vis.zone/lib/。网站提供非常全面的可视化图表类型供参考，还收集了很多实现可视化的代码、工具、课程、书籍。\n一个免费的 chatgpt 在线 web：https://chatbot.theb.ai/#/chat/1002\n一些视频 以下是最近在看的电视、动画片\n-《飚速宅男》第五季。一群高中生骑自行车的热血故事。\n-《潘多拉伪造的乐园》。此剧讲述了一名拥有令人称羡生活的女子在恢复过往的记忆后，为保护自己和家人对随意操纵自己命运的人展开报复的故事\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/04/04/weekly_review_13/","summary":"前言 本篇是对 2023-03-27 到 2023-04-02 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n本周是三月的最后一周，想到这，就想对随便对三月份做个总结。总结的方面，大概包括工作、生活、学习、健身、财务、娱乐几个方面。万事开头难，不知道能者多少，但是，相信不管写多少，都是有意义的。\n先来说说最近一周做了什么。查看一下 gitlab 上标签提交记录，这周发布了一个版本，其余时间是进行测试，为下周发布做准备。在工作之余，开始学习《Effective Java 3》，并用 chatgpt 作为辅助工作，加深对技术的理解。另外，有了想学习 React、Rust、Go、Pyhon 的想法。想学的东西有点多，只能一步步来。争取每天利用下班之后的一个小时进行碎片化的学习，并且做好相关笔记，如有可能发布在这个博客上面。加油！\n这周完成了每天一万步的计划，其中周末走了 3 万多步，并且还开始了跑步。\n关于健身 完成了每天一万步的计划，并且共跑步 8 次，一共 26 公里，最高平均配速 7 分钟，还跳绳一次（550 下）。\n跑步的目的不是快，而是乐此不疲。每天跑步 5 公里，每次消耗 300 卡路里的热量，大概需要 10 周才能瘦 10 斤。\n光靠走路和跑步，想在 4 月完成瘦 10 斤的目标，应该是不可能的，打算辅助间歇性断食，看下效果。\n跑步是一种有氧运动，可以促进身体代谢，消耗体内的脂肪和热量，达到减肥的效果。但是减肥的效果受到很多因素的影响，如个人的体重、身高、年龄、性别、饮食习惯、跑步强度、频率和时长等。\n通常来说，减肥的基本原理是消耗更多的热量，从而达到体重减轻的效果。每天跑步 5 公里的运动量相对较小，一般在一个小时左右可以完成。如果每天坚持跑步，同时注意饮食控制，增加其他有氧运动和合理的休息，可能会在几个月内看到一定的减肥效果。\n根据一般的减肥经验，每消耗 3500 卡路里的热量就可以减少一斤体重。假设每次跑步消耗 300 卡路里的热量，那么每天跑步 5 公里约消耗 300 ~ 400 卡路里的热量。如果每天坚持跑步，并且保持每天消耗 300 ~ 400 卡路里的热量，那么大约需要 10 周时间才能减少 10 斤体重。\n关于记账 上周开始，在寻找一个记账的 APP，想开始记录每天的收入与支出。当然，更多的应该是支出了。现在，大环境不行，公司裁员不停，必须要开源节流，手上储备足够的现金。\n找来找去，发现微信里没有有个『微信记账本』小程序就可以在微信里自动记账，也支持手动记账。于是，这周试了一下这个小程序，并有意的控制自己每天的输出。因为每天都有带饭，这样中饭就不用花钱了；早餐呢，是泡之前买的黑芝麻糊喝，省去了早餐费用。结果是，这周的支出只有 4.5 元。一次是早上买了一本豆浆，一次是早上跑步怕迟到就骑了一次动感单车。\n正好三月结束了，查看了一下三月的支出报表。总的来说，三月支出的有点多，超乎了我的想象。如果每个月都是支出这么多，那以后的零花钱就不够用了。还是要勒紧裤腰带过日子啊。\n更新 SSL 证书 安装 acme.sh\ncurl https://get.acme.sh | sh -s email=chensoul.eth@gmail.com 我的域名托管在 cloudflare，故需要获取 cloudflare API key，在 API 令牌 页面，点击查看 Global API Key。\n保存 CF_Key 和 CF_Email：\nexport CF_Key=\u0026#34;cloudflare 中查看你的 key\u0026#34; export CF_Email=\u0026#34;chensoul.","title":"周报-13｜健身、记账、更新SSL证书、代码提交百度站点收录"},{"content":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 当一个类需要多个构造函数参数时，可以考虑使用构建器模式来创建对象。构建器模式是一种创建对象的设计模式，它可以通过链式调用方法的方式来设置对象的构造参数，并最终返回一个构造完整的对象。\n优点 使用构建器模式的原因有以下几点：\n避免构造函数参数过多的问题：当一个类需要多个构造函数参数时，构造函数的参数列表可能会变得很长，这会导致代码难以理解和维护。使用构建器模式可以将构造函数参数拆分成多个方法，从而使代码更加清晰易懂。 提高代码的可读性和可维护性：使用构建器模式可以使代码更加易懂和易维护，因为可以通过方法名来清晰地表达每个参数的含义。 提供更多的灵活性和可定制性：构建器模式可以提供更多的灵活性和可定制性，因为可以在构造对象时进行更多的逻辑处理和判断。例如，可以在构建器中添加验证逻辑，以确保参数的有效性。 支持多线程环境：构建器模式可以支持多线程环境，因为每个构建器都是独立的，不会受到其他线程的影响。 以下是一个例子：\npublic class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; private NutritionFacts(Builder builder) { this.servingSize = builder.servingSize; this.servings = builder.servings; this.calories = builder.calories; this.fat = builder.fat; this.sodium = builder.sodium; this.carbohydrate = builder.carbohydrate; } //省略 get set public static class Builder { // Required parameters private final int servingSize; private final int servings; // Optional parameters - initialized to default values private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public Builder(int servingSize, int servings) { this.servingSize = servingSize; this.servings = servings; } public Builder calories(int calories) { this.calories = calories; return this; } public Builder fat(int fat) { this.fat = fat; return this; } public Builder sodium(int sodium) { this.sodium = sodium; return this; } public Builder carbohydrate(int carbohydrate) { this.carbohydrate = carbohydrate; return this; } public NutritionFacts build() { return new NutritionFacts(this); } } } 在上述示例中，我们定义了一个名为 NutritionFacts 的类，它包含了一些营养成分的信息，例如每份的大小、总份数、卡路里、脂肪、钠和碳水化合物等成员变量。我们还定义了一个名为 Builder 的静态内部类，用于构建 NutritionFacts 对象。\n在 Builder 类中，我们定义了一个带有两个参数的构造方法，并在其中初始化了必需的成员变量 servingSize 和 servings。我们还定义了一些可选的方法，用于设置 NutritionFacts 对象的卡路里、脂肪、钠和碳水化合物等成员变量。这些方法都支持链式调用，并返回 Builder 对象本身，以便进行多次方法调用。\n在 Builder 类中，我们最终定义了一个 build() 方法，用于创建 NutritionFacts 对象并返回。在 build() 方法中，我们调用 NutritionFacts 的私有构造器并将 Builder 对象作为参数传递进去，从而创建 NutritionFacts 对象并初始化其成员变量。\n现在，我们可以使用 NutritionFacts.Builder 类来创建 NutritionFacts 对象，并使用链式调用来设置 NutritionFacts 对象的成员变量。例如，我们可以使用以下代码来创建一个每份大小为 240ml、总共有 8 份、卡路里为 100、脂肪为 2、钠为 35、碳水化合物为 27 的 NutritionFacts 对象：\nNutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100) .fat(2) .sodium(35) .carbohydrate(27) .build(); 在上述代码中，我们首先创建了一个 NutritionFacts.Builder 对象，并在构造函数中传递了每份大小和总份数等参数。然后，我们使用链式调用来设置卡路里、脂肪、钠和碳水化合物等成员变量，并最终调用 build() 方法来创建 NutritionFacts 对象。\n可以使用 lombok 注解来简化代码，但是，无法在构造器的构造方法里设置必要参数。\nimport lombok.Builder; @Builder public class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; } 缺点 虽然构建器模式可以提高代码的可读性、可维护性以及提供更多的灵活性和可定制性，但它也有一些缺点，包括：\n增加代码复杂度：使用构建器模式会增加代码的复杂度，因为需要创建一个独立的构建器类，并且需要在构建器类中定义多个方法来设置对象的属性。这会增加代码量并且需要更多的时间来编写和维护代码。 增加内存开销：使用构建器模式需要创建一个独立的构建器对象，并且需要在构建器对象中保存对象的属性。这会增加内存开销，并且在创建对象时需要更多的时间和资源。 对于简单对象不适用：构建器模式更适用于构造复杂对象，对于简单对象来说，使用构建器模式可能会增加代码的复杂度和开销。 需要额外的代码：使用构建器模式需要编写额外的代码来创建构建器类和定义方法。如果只需要构造一个简单的对象，使用构建器模式可能会浪费时间和资源。 层次构建器 层次构建器（Hierarchical Builder）是一种构建器模式的扩展，它允许创建层次结构的对象，并支持在父对象中嵌套子对象。它通常由一个抽象的构建器接口，多个具体的构建器实现和一个指导者（Director）组成。\n在层次构建器中，每个构建器都负责创建特定类型的对象，并且可以在其构建方法中调用其他构建器的构建方法来创建嵌套的子对象。指导者负责协调构建器的顺序和调用构建器的方法来构建对象层次结构。\n层次构建器模式的优点包括：\n支持创建复杂的对象层次结构，能够构建包含多个层次和嵌套子对象的对象。 提供了更好的可读性和可维护性，因为每个构建器都只需要关注一个特定类型的对象，而且可以通过方法名来清晰地表达每个参数的含义。 提供了更多的灵活性和可定制性，因为可以在构建器中添加验证逻辑，以确保参数的有效性，并且可以动态地组合构建器来创建不同类型的对象。 层次构建器模式的缺点包括：\n代码量：由于层次构建器模式需要定义多个构建器类，因此代码量会比较大，尤其是在构建复杂对象时。\n嵌套层次：层次构建器模式中的对象层次结构是通过嵌套多个构建器实现的，这会导致代码的嵌套层次较深，可能会影响代码的可读性和可维护性。\n可能会增加内存开销：因为每个构建器都需要创建一个独立的对象，并且需要在构建器对象中保存对象的属性。对于大型对象和多级嵌套结构，开销可能会很大。\n不适合简单对象的构建：层次构建器模式适用于构建复杂对象层次结构，但对于简单的对象构建，使用层次构建器模式可能会显得过于繁琐和不必要。\n使用 举例 1 1、定义抽象的构建器接口，用于创建不同类型的对象和添加子对象：\npublic interface ComputerBuilder { void buildCPU(String model); void buildGPU(String model); void buildMemory(int size); void addStorage(String type, int size); void addPeripheral(String type); Computer getResult(); } 2、创建具体的构建器实现，用于构建不同类型的对象和添加子对象：\npublic class DesktopBuilder implements ComputerBuilder { private Desktop computer = new Desktop(); public void buildCPU(String model) { computer.setCPU(new CPU(model)); } public void buildGPU(String model) { computer.setGPU(new GPU(model)); } public void buildMemory(int size) { computer.setMemory(new Memory(size)); } public void addStorage(String type, int size) { computer.addStorage(new Storage(type, size)); } public void addPeripheral(String type) { computer.addPeripheral(new Peripheral(type)); } public Computer getResult() { return computer; } } public class LaptopBuilder implements ComputerBuilder { private Laptop computer = new Laptop(); public void buildCPU(String model) { computer.setCPU(new CPU(model)); } public void buildGPU(String model) { computer.setGPU(new GPU(model)); } public void buildMemory(int size) { computer.setMemory(new Memory(size)); } public void addStorage(String type, int size) { computer.addStorage(new Storage(type, size)); } public void addPeripheral(String type) { computer.addPeripheral(new Peripheral(type)); } public Computer getResult() { return computer; } } 3、创建指导者类，用于协调构建器的顺序和调用构建器的方法来构建对象层次结构：\npublic class ComputerDirector { private ComputerBuilder builder; public ComputerDirector(ComputerBuilder builder) { this.builder = builder; } public void construct() { builder.buildCPU(\u0026#34;Intel Core i7\u0026#34;); builder.buildGPU(\u0026#34;Nvidia GeForce RTX 3080\u0026#34;); builder.buildMemory(16); builder.addStorage(\u0026#34;SSD\u0026#34;, 512); builder.addPeripheral(\u0026#34;Keyboard\u0026#34;); builder.addPeripheral(\u0026#34;Mouse\u0026#34;); } } 4、使用层次构建器模式创建计算机系统对象：\nComputerBuilder desktopBuilder = new DesktopBuilder(); ComputerBuilder laptopBuilder = new LaptopBuilder(); ComputerDirector director = new ComputerDirector(desktopBuilder); director.construct(); Computer desktop = desktopBuilder.getResult(); director = new ComputerDirector(laptopBuilder); director.construct(); Computer laptop = laptopBuilder.getResult(); // 将两个计算机系统对象组合成一个更大的计算机系统对象 ComputerSystem system = new ComputerSystem(); system.addComputer(desktop); system.addComputer(laptop); 在上面的示例中，DesktopBuilder 和 LaptopBuilder 分别是具体的构建器实现，用于创建桌面计算机和笔记本电脑对象。ComputerDirector 是指导者类，用于协调构建器的顺序和调用构建器的方法来构建对象层次结构。使用 ComputerDirector 构建计算机系统对象时，可以先使用 DesktopBuilder 构建桌面计算机对象，再使用 LaptopBuilder 构建笔记本电脑对象，最后将两个计算机系统对象组合成一个更大的计算机系统对象。\n下面是另一个使用层次构建器模式创建层次结构对象的例子，假设需要创建一个组织结构的层次结构对象，其中包含多个部门和嵌套子部门：\n1、定义抽象的构建器接口，用于创建不同类型的对象和添加子对象：\npublic interface DepartmentBuilder { void buildName(String name); void buildManager(String manager); void addSubDepartment(Department subDepartment); Department getResult(); } public abstract class DepartmentImpl implements Department { protected String name; protected String manager; protected List\u0026lt;Department\u0026gt; subDepartments = new ArrayList\u0026lt;\u0026gt;(); public void setName(String name) { this.name = name; } public void setManager(String manager) { this.manager = manager; } public void addSubDepartment(Department subDepartment) { subDepartments.add(subDepartment); } public void removeSubDepartment(Department subDepartment) { subDepartments.remove(subDepartment); } public List\u0026lt;Department\u0026gt; getSubDepartments() { return subDepartments; } public String getName() { return name; } public String getManager() { return manager; } } public class DevelopmentDepartment extends DepartmentImpl { // 添加特定于开发部门的属性和方法 } public class SalesDepartment extends DepartmentImpl { // 添加特定于销售部门的属性和方法 } 2、创建具体的构建器实现，用于构建不同类型的对象和添加子对象：\npublic class SalesDepartmentBuilder implements DepartmentBuilder { private SalesDepartment department = new SalesDepartment(); public void buildName(String name) { department.setName(name); } public void buildManager(String manager) { department.setManager(manager); } public void addSubDepartment(Department subDepartment) { department.addSubDepartment(subDepartment); } public Department getResult() { return department; } } public class DevelopmentDepartmentBuilder implements DepartmentBuilder { private DevelopmentDepartment department = new DevelopmentDepartment(); public void buildName(String name) { department.setName(name); } public void buildManager(String manager) { department.setManager(manager); } public void addSubDepartment(Department subDepartment) { department.addSubDepartment(subDepartment); } public Department getResult() { return department; } } 3、创建指导者类，用于协调构建器的顺序和调用构建器的方法来构建对象层次结构：\npublic class OrganizationDirector { private DepartmentBuilder builder; public OrganizationDirector(DepartmentBuilder builder) { this.builder = builder; } public void construct() { builder.buildName(\u0026#34;Organization\u0026#34;); builder.buildManager(\u0026#34;CEO\u0026#34;); Department salesDept = new SalesDepartment(); salesDept.setName(\u0026#34;Sales Department\u0026#34;); salesDept.setManager(\u0026#34;Sales Manager\u0026#34;); builder.addSubDepartment(salesDept); Department devDept = new DevelopmentDepartment(); devDept.setName(\u0026#34;Development Department\u0026#34;); devDept.setManager(\u0026#34;Development Manager\u0026#34;); Department frontendDevDept = new DevelopmentDepartment(); frontendDevDept.setName(\u0026#34;Front-end Development Department\u0026#34;); frontendDevDept.setManager(\u0026#34;Front-end Development Manager\u0026#34;); devDept.addSubDepartment(frontendDevDept); Department backendDevDept = new DevelopmentDepartment(); backendDevDept.setName(\u0026#34;Back-end Development Department\u0026#34;); backendDevDept.setManager(\u0026#34;Back-end Development Manager\u0026#34;); devDept.addSubDepartment(backendDevDept); builder.addSubDepartment(devDept); } } 4、使用层次构建器模式创建组织结构对象：\nDepartmentBuilder salesDeptBuilder = new SalesDepartmentBuilder(); DepartmentBuilder devDeptBuilder = new DevelopmentDepartmentBuilder(); OrganizationDirector director = new OrganizationDirector(salesDeptBuilder); director.construct(); Department salesDept = salesDeptBuilder.getResult(); director = new OrganizationDirector(devDeptBuilder); director.construct(); Department devDept = devDeptBuilder.getResult(); // 将两个部门对象组合成一个更大的组织结构对象 Organization organization = new Organization(); organization.addDepartment(salesDept); organization.addDepartment(devDept); 在上面的示例中，SalesDepartmentBuilder 和 DevelopmentDepartmentBuilder 分别是具体的构建器实现，用于创建销售部门和开发部门对象。OrganizationDirector 是指导者类，用于协调构建器的顺序和调用构建器的方法来构建对象层次结构。使用 OrganizationDirector 构建组织结构对象时，可以先使用 SalesDepartmentBuilder 构建销售部门对象，再使用 DevelopmentDepartmentBuilder 构建开发部门对象，最后将两个部门对象组合成一个更大的组织结构对象。\n举例 2 public abstract class ComputerComponent { private final String manufacturer; private final String model; // ... protected ComputerComponent(Builder\u0026lt;?\u0026gt; builder) { manufacturer = builder.manufacturer; model = builder.model; // ... } public String getManufacturer() { return manufacturer; } public String getModel() { return model; } public static abstract class Builder\u0026lt;T extends Builder\u0026lt;T\u0026gt;\u0026gt; { private String manufacturer; private String model; // ... public T setManufacturer(String manufacturer) { this.manufacturer = manufacturer; return self(); } public T setModel(String model) { this.model = model; return self(); } protected abstract T self(); public abstract ComputerComponent build(); } } public class Motherboard extends ComputerComponent { private final String socketType; // ... protected Motherboard(Builder builder) { super(builder); socketType = builder.socketType; // ... } public String getSocketType() { return socketType; } public static class Builder extends ComputerComponent.Builder\u0026lt;Builder\u0026gt; { private String socketType; // ... public Builder setSocketType(String socketType) { this.socketType = socketType; return this; } @Override protected Builder self() { return this; } @Override public Motherboard build() { return new Motherboard(this); } } } public class CPU extends ComputerComponent { private final int coreCount; // ... protected CPU(Builder builder) { super(builder); coreCount = builder.coreCount; // ... } public int getCoreCount() { return coreCount; } public static class Builder extends ComputerComponent.Builder\u0026lt;Builder\u0026gt; { private int coreCount; // ... public Builder setCoreCount(int coreCount) { this.coreCount = coreCount; return this; } @Override protected Builder self() { return this; } @Override public CPU build() { return new CPU(this); } } } public class Computer { private final Motherboard motherboard; private final CPU cpu; // ... protected Computer(Builder builder) { motherboard = builder.motherboard; cpu = builder.cpu; // ... } public Motherboard getMotherboard() { return motherboard; } public CPU getCpu() { return cpu; } public static class Builder { private Motherboard motherboard; private CPU cpu; // ... public Builder setMotherboard(Motherboard motherboard) { this.motherboard = motherboard; return this; } public Builder setCpu(CPU cpu) { this.cpu = cpu; return this; } public Computer build() { return new Computer(this); } } } 使用示例：\nMotherboard.Builder motherboardBuilder = new Motherboard.Builder() .setManufacturer(\u0026#34;ASUS\u0026#34;) .setModel(\u0026#34;ROG Strix Z590-E Gaming\u0026#34;) .setSocketType(\u0026#34;LGA 1200\u0026#34;) // ... CPU.Builder cpuBuilder = new CPU.Builder() .setManufacturer(\u0026#34;Intel\u0026#34;) .setModel(\u0026#34;Core i9-11900K\u0026#34;) .setCoreCount(8) // ... Computer.Builder computerBuilder = new Computer.Builder() .setMotherboard(motherboardBuilder.build()) .setCpu(cpuBuilder.build()) // ... Computer computer = computerBuilder.build(); 在这个示例中，ComputerComponent 类是一个抽象基类，定义了计算机组件的基本属性和方法。它还定义了一个抽象的构建器类，用于构建它的子类的实例。\n每个 ComputerComponent 的具体子类都有自己的具体构建器类，该类扩展了抽象构建器类。具体构建器提供了设置相应组件属性的方法，例如主板的制造商、型号和插座类型，处理器的时钟速度和内存的容量。\nComputer 类代表一个完整的计算机系统，并具有用于构建 Computer 类的实例的构建器类。Computer.Builder 类提供了设置每个组件属性的方法，使用 Consumer 函数接口来接受配置相应构建器的 lambda 表达式。\n使用 以下是几个常见开源框架中使用建造者模式的例子：\nRetrofit Retrofit 是一个 Android 和 Java 平台上的 RESTful API 库，它使用建造者模式来创建 RestAdapter 对象。RestAdapter.Builder 类是一个建造者类，它包含了一系列的方法，用于设置 Retrofit 的配置选项，如设置 API 的 base URL、设置 HTTP Client、设置 Converter 等。\n示例代码：\nRestAdapter restAdapter = new RestAdapter.Builder() .setEndpoint(\u0026#34;https://api.github.com\u0026#34;) .setClient(new OkClient()) .setLogLevel(RestAdapter.LogLevel.FULL) .build(); Gson Gson 是一个用于在 Java 对象和 JSON 数据之间进行序列化和反序列化的库。它使用建造者模式来创建 Gson 对象。GsonBuilder 类是一个建造者类，它包含了一系列的方法，用于配置 Gson 的行为，如设置日期格式、设置字段的命名策略等。\n示例代码：\nGson gson = new GsonBuilder() .setDateFormat(\u0026#34;yyyy-MM-dd\u0026#39;T\u0026#39;HH:mm:ssZ\u0026#34;) .setFieldNamingPolicy(FieldNamingPolicy.LOWER_CASE_WITH_UNDERSCORES) .create(); Apache HttpClient Apache HttpClient 是一个用于创建 HTTP 客户端的库，它使用建造者模式来创建 HttpClient 对象。HttpClientBuilder 类是一个建造者类，它包含了一系列的方法，用于配置 HttpClient 的行为，如设置连接池、设置代理、设置 Cookie 管理器等。\n示例代码：\nHttpClient httpClient = HttpClientBuilder.create() .setMaxConnTotal(100) .setMaxConnPerRoute(10) .setProxy(new HttpHost(\u0026#34;localhost\u0026#34;, 8080)) .setDefaultCookieStore(new BasicCookieStore()) .build(); Apache Kafka Apache Kafka 是一个分布式消息队列系统，它使用建造者模式来创建 Producer 和 Consumer 对象。ProducerConfig 和 ConsumerConfig 类是建造者类，它们包含了一系列的方法，用于配置 Producer 和 Consumer 的行为，如设置 broker 地址、设置序列化器等。\n示例代码：\nProperties producerProps = new Properties(); producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \u0026#34;localhost:9092\u0026#34;); producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); Producer\u0026lt;String, String\u0026gt; producer = new KafkaProducer\u0026lt;\u0026gt;(producerProps); Properties consumerProps = new Properties(); consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, \u0026#34;localhost:9092\u0026#34;); consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, \u0026#34;my-group\u0026#34;); Consumer\u0026lt;String, String\u0026gt; consumer = new KafkaConsumer\u0026lt;\u0026gt;(consumerProps); Apache Commons Configuration Apache Commons Configuration 是一个用于读取和写入各种配置文件的库，它使用建造者模式来创建 Configuration 对象。ConfigurationBuilder 类是一个建造者类，它包含了一系列的方法，用于配置 Configuration 的行为，如设置配置文件类型、设置属性的分隔符等。\n示例代码：\nConfiguration config = new ConfigurationBuilder() .setDelimiterParsingDisabled(true) .setFile(new File(\u0026#34;config.properties\u0026#34;)) .setListDelimiterHandler(new DefaultListDelimiterHandler(\u0026#39;,\u0026#39;)) .build(); Guava Guava 是一个 Google 开发的 Java 库，它包含了许多实用的工具类和数据结构，其中包括使用建造者模式来创建的 ImmutableList、ImmutableMap 和 ImmutableSet 等不可变集合类。\n示例代码：\nImmutableList\u0026lt;String\u0026gt; list = ImmutableList.\u0026lt;String\u0026gt;builder() .add(\u0026#34;foo\u0026#34;) .add(\u0026#34;bar\u0026#34;) .add(\u0026#34;baz\u0026#34;) .build(); ImmutableMap\u0026lt;String, Integer\u0026gt; map = ImmutableMap.\u0026lt;String, Integer\u0026gt;builder() .put(\u0026#34;foo\u0026#34;, 1) .put(\u0026#34;bar\u0026#34;, 2) .put(\u0026#34;baz\u0026#34;, 3) .build(); ImmutableSet\u0026lt;String\u0026gt; set = ImmutableSet.\u0026lt;String\u0026gt;builder() .add(\u0026#34;foo\u0026#34;) .add(\u0026#34;bar\u0026#34;) .add(\u0026#34;baz\u0026#34;) .build(); JPA Java Persistence API（JPA）是 Java EE 平台的一个 ORM 框架，它使用建造者模式来创建 EntityManagerFactory 对象。EntityManagerFactoryBuilder 类是一个建造者类，它包含了一系列的方法，用于配置 EntityManagerFactory 的行为，如设置数据源、设置 JPA 的属性等。\n示例代码：\nEntityManagerFactory entityManagerFactory = new EntityManagerFactoryBuilder() .dataSource(myDataSource) .persistenceUnit(\u0026#34;myPersistenceUnit\u0026#34;) .properties(myProperties) .build(); Spring Framework Spring Framework 是一个 Java 平台上的开源应用程序框架，它使用建造者模式来创建 RestTemplate 和 HttpHeaders 对象。RestTemplateBuilder 和 HttpHeadersBuilder 类是建造者类，它们包含了一系列的方法，用于配置 RestTemplate 和 HttpHeaders 的行为，如设置连接超时、设置请求头等。\n示例代码：\nRestTemplate restTemplate = new RestTemplateBuilder() .setConnectTimeout(Duration.ofSeconds(10)) .setReadTimeout(Duration.ofSeconds(10)) .build(); HttpHeaders headers = new HttpHeadersBuilder() .setContentType(MediaType.APPLICATION_JSON) .build(); 优化 建造者模式的优化主要包括以下几个方面：\n使用静态内部类优化建造者模式 建造者模式通常使用一个 Builder 类来构建复杂对象，为了避免 Builder 类变得过于臃肿，可以将其设计为静态内部类，这样可以使代码更加清晰，同时也能够保证线程安全。\n使用流式接口优化建造者模式 流式接口是一种链式调用的方式，它可以将多个方法调用连接起来，形成一个链式结构，使得代码更加简洁易读。在建造者模式中，可以使用流式接口来优化 Builder 类，使得客户端可以通过链式调用的方式来创建复杂对象，从而简化代码。\n使用默认值优化建造者模式 在建造者模式中，有些属性是必须的，而有些属性是可选的，可以使用默认值来为可选属性设置默认值，从而避免客户端必须为每个可选属性都提供值的情况，同时也能够简化客户端代码。\n使用 Java 8 中的 Optional 类优化建造者模式 Java 8 中引入了 Optional 类，该类可以用于处理可能为 null 的值，可以进一步优化建造者模式中的代码。\n在建造者模式中，我们通常需要设置多个属性，其中有些属性可能是可选的，如果直接使用 null 来表示可选属性的值，可能会导致代码出现空指针异常，而使用 Optional 类可以避免这个问题。\n下面是一个使用 Optional 类优化建造者模式的示例代码：\nimport java.util.Optional; public class Computer { private String cpu; private String memory; private String hardDisk; private Optional\u0026lt;String\u0026gt; graphicsCard; private Computer(ComputerBuilder builder) { this.cpu = builder.cpu; this.memory = builder.memory; this.hardDisk = builder.hardDisk; this.graphicsCard = builder.graphicsCard; } // 省略getter方法 public static class ComputerBuilder { private String cpu; private String memory; private String hardDisk; private Optional\u0026lt;String\u0026gt; graphicsCard = Optional.empty(); public ComputerBuilder setCpu(String cpu) { this.cpu = cpu; return this; } public ComputerBuilder setMemory(String memory) { this.memory = memory; return this; } public ComputerBuilder setHardDisk(String hardDisk) { this.hardDisk = hardDisk; return this; } public ComputerBuilder setGraphicsCard(String graphicsCard) { this.graphicsCard = Optional.ofNullable(graphicsCard); return this; } public Computer build() { return new Computer(this); } } } 在这个示例代码中，我们使用 Optional 类来表示可选属性的值，将 graphicsCard 属性的类型改为Optional\u0026lt;String\u0026gt;。在 ComputerBuilder 类中，我们使用 Optional.ofNullable 方法来将可选属性的值转换为 Optional 对象，并在调用 build 方法时，将 Optional 对象转换为普通的字符串类型。\n使用 Lambda 表达式优化建造者模式 Lambda 表达式是 Java 8 中引入的一种新的语言特性，可以进一步优化建造者模式中的代码，使得代码更加简洁易读。\n在建造者模式中，我们通常需要定义多个属性，并在构造方法中进行初始化。使用 Lambda 表达式可以避免定义多个属性的问题，将属性的赋值操作通过 Lambda 表达式传递给构造方法。\n下面是一个使用 Lambda 表达式优化建造者模式的示例代码：\nimport java.util.Optional; import java.util.function.Consumer; public class Computer { private String cpu; private String memory; private String hardDisk; private Optional\u0026lt;String\u0026gt; graphicsCard; private Computer(Consumer\u0026lt;ComputerBuilder\u0026gt; builder) { ComputerBuilder computerBuilder = new ComputerBuilder(); builder.accept(computerBuilder); this.cpu = computerBuilder.cpu; this.memory = computerBuilder.memory; this.hardDisk = computerBuilder.hardDisk; this.graphicsCard = computerBuilder.graphicsCard; } // 省略getter方法 public static class ComputerBuilder { private String cpu; private String memory; private String hardDisk; private Optional\u0026lt;String\u0026gt; graphicsCard = Optional.empty(); public ComputerBuilder setCpu(String cpu) { this.cpu = cpu; return this; } public ComputerBuilder setMemory(String memory) { this.memory = memory; return this; } public ComputerBuilder setHardDisk(String hardDisk) { this.hardDisk = hardDisk; return this; } public ComputerBuilder setGraphicsCard(String graphicsCard) { this.graphicsCard = Optional.ofNullable(graphicsCard); return this; } } public static void main(String[] args) { Computer computer = new Computer(builder -\u0026gt; builder .setCpu(\u0026#34;Intel i7\u0026#34;) .setMemory(\u0026#34;16GB\u0026#34;) .setHardDisk(\u0026#34;512GB SSD\u0026#34;) .setGraphicsCard(\u0026#34;NVIDIA GTX 1660\u0026#34;)); } } 在这个示例代码中，我们将 Computer 类的构造方法改为接收一个 Consumer\u0026lt;ComputerBuilder\u0026gt; 类型的参数，这个参数表示一个包含属性赋值操作的 Lambda 表达式。在构造方法中，我们先创建一个 ComputerBuilder 对象，然后通过 Lambda 表达式调用 ComputerBuilder 对象的方法来设置属性值，并最终通过 ComputerBuilder 对象创建 Computer 对象。\n使用泛型和反射优化 class EntityCreator\u0026lt;T\u0026gt; { private Class\u0026lt;T\u0026gt; classInstance; private T entityObj; public EntityCreator(Class\u0026lt;T\u0026gt; classInstance, Object... initParams) throws Exception { this.classInstance = classInstance; Class\u0026lt;?\u0026gt;[] paramTypes = new Class\u0026lt;?\u0026gt;[initParams.length]; for (int index = 0, length = initParams.length; index \u0026lt; length; index++) { String checkStr = initParams[index].getClass().getSimpleName(); if (checkStr.contains(\u0026#34;Integer\u0026#34;)) { paramTypes[index] = int.class; } if (checkStr.contains(\u0026#34;Double\u0026#34;)) { paramTypes[index] = double.class; } if (checkStr.contains(\u0026#34;Boolean\u0026#34;)) { paramTypes[index] = boolean.class; } if (checkStr.contains(\u0026#34;String\u0026#34;)) { paramTypes[index] = initParams[index].getClass(); } } Constructor\u0026lt;T\u0026gt; constructor = classInstance.getDeclaredConstructor(paramTypes); constructor.setAccessible(true); this.entityObj = constructor.newInstance(initParams); } public EntityCreator\u0026lt;T\u0026gt; setValue(String paramName, Object paramValue) throws Exception { Field field = classInstance.getDeclaredField(paramName); field.setAccessible(true); field.set(entityObj, paramValue); return this; } public T build() { return entityObj; } } ​ 如此，可移除整个内部 Builder 类，NutritionFacts 类私有构造的参数仅包括两个必填的 servingSize、servings 字段：\npublic class NutritionFacts { // Required parameters private final int servingSize; private final int servings; // Optional parameters - initialized to default values private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; private NutritionFacts(int servingSize, int servings) { this.servingSize = servingSize; this.servings = servings; } } 该案例的客户端代码改为：\nNutritionFacts cocaCola = new EntityCreator\u0026lt;\u0026gt;(NutritionFacts.class, 240, 8) .setValue(\u0026#34;calories\u0026#34;, 100) .setValue(\u0026#34;sodium\u0026#34;, 35) .setValue(\u0026#34;carbohydrate\u0026#34;, 27).build(); ","permalink":"https://blog.chensoul.cc/posts/2023/04/03/builder-instead-of-constructors/","summary":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 当一个类需要多个构造函数参数时，可以考虑使用构建器模式来创建对象。构建器模式是一种创建对象的设计模式，它可以通过链式调用方法的方式来设置对象的构造参数，并最终返回一个构造完整的对象。\n优点 使用构建器模式的原因有以下几点：\n避免构造函数参数过多的问题：当一个类需要多个构造函数参数时，构造函数的参数列表可能会变得很长，这会导致代码难以理解和维护。使用构建器模式可以将构造函数参数拆分成多个方法，从而使代码更加清晰易懂。 提高代码的可读性和可维护性：使用构建器模式可以使代码更加易懂和易维护，因为可以通过方法名来清晰地表达每个参数的含义。 提供更多的灵活性和可定制性：构建器模式可以提供更多的灵活性和可定制性，因为可以在构造对象时进行更多的逻辑处理和判断。例如，可以在构建器中添加验证逻辑，以确保参数的有效性。 支持多线程环境：构建器模式可以支持多线程环境，因为每个构建器都是独立的，不会受到其他线程的影响。 以下是一个例子：\npublic class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; private NutritionFacts(Builder builder) { this.servingSize = builder.servingSize; this.servings = builder.servings; this.calories = builder.calories; this.fat = builder.fat; this.sodium = builder.sodium; this.carbohydrate = builder.carbohydrate; } //省略 get set public static class Builder { // Required parameters private final int servingSize; private final int servings; // Optional parameters - initialized to default values private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public Builder(int servingSize, int servings) { this.","title":"《Effective Java 3》笔记2：使用构造器代替构造方法"},{"content":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 静态工厂方法是指在类中定义一个静态方法，用于创建该类的实例。示例：\npublic static Boolean valueOf(boolean b) { return b ? Boolean.TRUE : Boolean.FALSE; } 与构造函数不同的是，静态工厂方法可以有自己的名称，并且可以根据参数的不同返回不同的对象实例。\n优点 这本书中提到了一些静态工厂方法的优点，包括：\n静态工厂方法可以有意义的名称：与构造函数不同，静态工厂方法可以有自己的名称，这使得代码更具有可读性和可维护性。\n例如，BigInteger 类提供了一个返回素数的静态工厂方法 BigInteger.probablePrime 。\n静态工厂方法可以隐藏实现细节：静态工厂方法可以隐藏对象的创建和初始化过程，使客户端代码更加简洁和易于维护。\n这是服务提供者框架的基础。\n服务提供者框架中有三个基本组件：服务接口，代表要实现的服务；提供者注册 API，提供者使用它来注册实现，以及服务访问 API，客户端使用它来获取服务的实例。服务访问 API 允许客户端指定选择实现的标准。在没有这些条件的情况下，API 返回一个默认实现的实例，或者允许客户端循环使用所有可用的实现。服务访问 API 是灵活的静态工厂，它构成了服务提供者框架的基础。\n服务提供者框架的第四个可选组件是服务提供者接口，它描述了产生服务接口实例的工厂对象。在没有服务提供者接口的情况下，必须以反射的方式实例化实现。\n在 JDBC 中，Connection 扮演服务接口的角色。DriverManager.registerDriver 是提供者注册的 API，DriverManager.getConnection 是服务访问 API，Driver 是服务提供者接口。\n服务提供者框架模式有许多变体。例如，服务访问 API 可以向客户端返回比提供者提供的更丰富的服务接口，这是桥接模式。依赖注入框架可以看作是强大的服务提供者。由于是 Java 6，该平台包括一个通用服务提供者框架 Java.util.ServiceLoader，所以你不需要，通常也不应该自己写。JDBC 不使用 ServiceLoader，因为前者比后者要早。\n静态工厂方法可以返回缓存的对象：静态工厂方法可以返回缓存的对象，这避免了创建新对象的开销，提高了性能。\n这种技术类似于享元模式。如果经常请求相同的对象，特别是在创建对象的代价很高时，它可以极大地提高性能。\n举例 1：使用 ConcurrentHashMap\npublic class ThreadSafeCache { private static final Map\u0026lt;String, ThreadSafeCache\u0026gt; instances = new ConcurrentHashMap\u0026lt;\u0026gt;(); private ThreadSafeCache() {} public static ThreadSafeCache getInstance(String key) { return instances.computeIfAbsent(key, k -\u0026gt; new ThreadSafeCache()); } } 在上面的示例中，computeIfAbsent 方法用于计算缓存对象。如果 key 在 instances 中不存在，则使用 lambda 表达式 k -\u0026gt; new ThreadSafeCache() 创建一个新的 ThreadSafeCache 对象，并将该对象与 key 关联。如果 key 已经存在，则直接返回与之关联的 ThreadSafeCache 对象。\n使用 computeIfAbsent 方法可以更简洁地实现线程安全的缓存类，并且可以确保在多线程环境下的线程安全性。\n举例 2：使用 synchronized 关键字\npublic class ThreadSafeCache { private static final Map\u0026lt;String, ThreadSafeCache\u0026gt; instances = new HashMap\u0026lt;\u0026gt;(); private ThreadSafeCache() {} public static synchronized ThreadSafeCache getInstance(String key) { if (!instances.containsKey(key)) { instances.put(key, new ThreadSafeCache()); } return instances.get(key); } } 静态工厂方法可以返回子类对象：静态工厂方法可以返回实现了某个接口或继承了某个类的子类对象，这提高了代码的灵活性和可扩展性。\n例如，Java 的 Collections 框架有 45 个接口实用工具实现，提供了不可修改的集合、同步集合等。几乎所有这些实现都是通过一个非实例化类（java.util.Collections ）中的静态工厂方法导出的。返回对象的类都是私有的子类。\n举例：\npublic interface Shape { void draw(); } public class Circle implements Shape { @Override public void draw() { System.out.println(\u0026#34;Drawing Circle\u0026#34;); } } public class Square implements Shape { @Override public void draw() { System.out.println(\u0026#34;Drawing Square\u0026#34;); } } public class ShapeFactory { public static Shape getShape(String shapeType) { if (shapeType == null) { return null; } if (shapeType.equalsIgnoreCase(\u0026#34;CIRCLE\u0026#34;)) { return new Circle(); } else if (shapeType.equalsIgnoreCase(\u0026#34;SQUARE\u0026#34;)) { return new Square(); } return null; } } 在上面的示例中，ShapeFactory 类使用静态工厂方法 getShape 来创建 Shape 对象。如果 shapeType 参数为 CIRCLE ，则创建 Circle 对象并返回，如果参数为 SQUARE，则创建 Square 对象并返回。\n静态工厂方法可以返回不可变对象：静态工厂方法可以返回不可变对象，这确保了对象的安全性和线程安全性。\n举例：\npublic final class ThreadSafeImmutableClass { private final int id; private final String name; private ThreadSafeImmutableClass(int id, String name) { this.id = id; this.name = name; } public static ThreadSafeImmutableClass getInstance(int id, String name) { return new ThreadSafeImmutableClass(id, name); } public int getId() { return id; } public String getName() { return name; } } 在上面的示例中，ThreadSafeImmutableClass 类使用静态工厂方法 getInstance 来创建不可变对象。由于该类的属性都是 final 的，因此该对象是不可变的。由于没有任何状态可以修改，因此该对象是线程安全的。\n缺点 使用静态工厂方法也有一些缺点，例如：\n静态工厂方法可能会导致代码的可测试性变差，因为它们往往是静态的，难以进行模拟和替换。 静态工厂方法可能会使代码的扩展性变差，因为它们通常是静态的，难以扩展和修改。 静态工厂方法可能会使代码的可读性变差，因为它们往往是自定义的，难以理解和维护。 仅提供静态工厂方法也存在一些局限：\n不可继承：静态工厂方法是通过类名直接调用的，因此无法通过继承来创建对象的变体或子类对象。 可能难以扩展：如果在实现静态工厂方法时没有考虑到所有可能的用例，那么在需要添加新功能或对象类型时可能会很难扩展。 可能难以测试：如果静态工厂方法中包含复杂的逻辑或依赖外部资源，那么在测试时可能会很难模拟或替换这些依赖项。 可能会引起混淆：如果在同一个类中定义多个静态工厂方法，它们可能具有相似的名称或参数类型，从而可能会导致混淆或误用。 对象创建可能较慢：如果创建对象需要进行复杂的计算或依赖大量的外部资源，那么静态工厂方法可能会导致对象创建的性能问题。 所以，在选择不同的静态工厂方法时，需要考虑以下几个因素：\n目的：考虑每个工厂方法的目的，以及它是否符合您的需求。不同的工厂方法可能有不同的目的，例如创建新对象、返回共享实例或从一种类型转换为另一种类型。 灵活性：考虑每个工厂方法的灵活性。某些工厂方法可能比其他工厂方法更灵活，允许更多的自定义或配置选项。 可读性：考虑工厂方法的可读性。好的工厂方法应该易于阅读和理解，具有清晰的名称和明确的参数。 性能：考虑每个工厂方法的性能影响。根据具体的用例，某些工厂方法可能比其他工厂方法更高效或更快。 兼容性：考虑工厂方法是否与您现有的代码库和第三方库兼容。根据具体的技术和框架，某些工厂方法可能比其他工厂方法更兼容。 维护：考虑每个工厂方法的维护影响。根据实现的复杂性以及文档和支持的可用性，某些工厂方法可能比其他工厂方法更易于维护。 使用 以下是一些常见静态工厂方法的名称：\nfrom，用于从其他类型的对象或数据源中创建一个对象，例如 Date.from 和 Duration.from。\nDate d = Date.from(instant); of，一个聚合方法，它接受多个参数并返回一个包含这些参数的实例，例如：\nSet\u0026lt;Rank\u0026gt; faceCards = EnumSet.of(JACK, QUEEN, KING); valueOf，一种替代 from 和 of 但更冗长的方法，例如：\nBigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE); instance 或 getInstance，返回一个实例，该实例由其参数（如果有的话）描述，但不具有相同的值，例如：\nStackWalker luke = StackWalker.getInstance(options); create 或 newInstance，与 instance 或 getInstance 类似，只是该方法保证每个调用都返回一个新实例，例如：\nObject newArray = Array.newInstance(classObject, arrayLen); getType，类似于 getInstance，但如果工厂方法位于不同的类中，则使用此方法。其类型是工厂方法返回的对象类型，例如：\nFileStore fs = Files.getFileStore(path); Runtime runtime = Runtime.getRuntime(); newType，与 newInstance 类似，但是如果工厂方法在不同的类中使用。类型是工厂方法返回的对象类型，例如：\nBufferedReader br = Files.newBufferedReader(path); type，一个用来替代 getType 和 newType 的比较简单的方式，例如：\nList\u0026lt;Complaint\u0026gt; litany = Collections.list(legacyLitany); parse：用于从字符串或其他格式中解析出一个对象，例如 LocalDate.parse 和 NumberFormat.parse。\nbuild：用于构建一个对象，例如 RequestBuilder.build 和 ResponseBuilder.build。\n还有一些常用的静态工厂方法名称：\nasXxx：用于将该类的对象转换为其他类型的对象，例如 ByteBuffer.asCharBuffer 和 FileChannel.asIntBuffer。 toXxx：用于将该类的对象转换为其他类型的对象，例如 BigInteger.toByteArray 和 String.toCharArray。 getXXX：用于获取某个对象，例如 TimeZone.getDefault。 newXxx：用于创建一个新的对象，例如 File.newFile 和 Thread.newThread。 withXxx：用于创建一个修改了指定属性的对象的副本，例如 LocalDate.withYear 和 HttpHeaders.withAccept。 forXxx：用于创建一个与指定参数相关的对象，例如 Charset.forName 和 ThreadLocalRandom.forWeb。 ","permalink":"https://blog.chensoul.cc/posts/2023/04/03/static-factory-methods-instead-of-constructors/","summary":"本文是 《Effective Java 3》第二章的学习笔记，在整理笔记过程中，通过 chatgpt 的帮助做了一些扩展。\n介绍 静态工厂方法是指在类中定义一个静态方法，用于创建该类的实例。示例：\npublic static Boolean valueOf(boolean b) { return b ? Boolean.TRUE : Boolean.FALSE; } 与构造函数不同的是，静态工厂方法可以有自己的名称，并且可以根据参数的不同返回不同的对象实例。\n优点 这本书中提到了一些静态工厂方法的优点，包括：\n静态工厂方法可以有意义的名称：与构造函数不同，静态工厂方法可以有自己的名称，这使得代码更具有可读性和可维护性。\n例如，BigInteger 类提供了一个返回素数的静态工厂方法 BigInteger.probablePrime 。\n静态工厂方法可以隐藏实现细节：静态工厂方法可以隐藏对象的创建和初始化过程，使客户端代码更加简洁和易于维护。\n这是服务提供者框架的基础。\n服务提供者框架中有三个基本组件：服务接口，代表要实现的服务；提供者注册 API，提供者使用它来注册实现，以及服务访问 API，客户端使用它来获取服务的实例。服务访问 API 允许客户端指定选择实现的标准。在没有这些条件的情况下，API 返回一个默认实现的实例，或者允许客户端循环使用所有可用的实现。服务访问 API 是灵活的静态工厂，它构成了服务提供者框架的基础。\n服务提供者框架的第四个可选组件是服务提供者接口，它描述了产生服务接口实例的工厂对象。在没有服务提供者接口的情况下，必须以反射的方式实例化实现。\n在 JDBC 中，Connection 扮演服务接口的角色。DriverManager.registerDriver 是提供者注册的 API，DriverManager.getConnection 是服务访问 API，Driver 是服务提供者接口。\n服务提供者框架模式有许多变体。例如，服务访问 API 可以向客户端返回比提供者提供的更丰富的服务接口，这是桥接模式。依赖注入框架可以看作是强大的服务提供者。由于是 Java 6，该平台包括一个通用服务提供者框架 Java.util.ServiceLoader，所以你不需要，通常也不应该自己写。JDBC 不使用 ServiceLoader，因为前者比后者要早。\n静态工厂方法可以返回缓存的对象：静态工厂方法可以返回缓存的对象，这避免了创建新对象的开销，提高了性能。\n这种技术类似于享元模式。如果经常请求相同的对象，特别是在创建对象的代价很高时，它可以极大地提高性能。\n举例 1：使用 ConcurrentHashMap\npublic class ThreadSafeCache { private static final Map\u0026lt;String, ThreadSafeCache\u0026gt; instances = new ConcurrentHashMap\u0026lt;\u0026gt;(); private ThreadSafeCache() {} public static ThreadSafeCache getInstance(String key) { return instances.computeIfAbsent(key, k -\u0026gt; new ThreadSafeCache()); } } 在上面的示例中，computeIfAbsent 方法用于计算缓存对象。如果 key 在 instances 中不存在，则使用 lambda 表达式 k -\u0026gt; new ThreadSafeCache() 创建一个新的 ThreadSafeCache 对象，并将该对象与 key 关联。如果 key 已经存在，则直接返回与之关联的 ThreadSafeCache 对象。","title":"《Effective Java 3》笔记1：静态工厂方法代替构造函数"},{"content":"前言 本篇是对 2023-03-20 到 2023-03-26 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n上周去同济医院检查鼾症，检查结果是轻度症状，医生建议多运动减肥。这周每天走路 1 万步的目标已达成。\n工作上发布了一个版本，另外两个迭代正在进行中，预计这周再发布一个版本。从飞书通讯录看到又有三个非技术类同事被裁，这周周会，部门领导说最近又有一个做商务的同事被优化了。\n上周有一天早上，车子停在小区里面，被两个车子挡住了前后道路，联系不上车主，只好坐地铁上班。话说，自从开车上班之后，使用手机的频率明显降低了很多。\n上周末阳光正好，于是回家去给已故的亲人扫墓。周六回老家，周日回老婆家。逝者已逝，活着的人要善待自己，好好吃饭，好好睡觉，好好工作，好好运动。\n工作 Effective Java 3 笔记 请参考 《Effective Java 3》笔记：静态工厂方法代替构造函数。\nMachine-Learning-With-Go B 站视频：「课程」使用 Go 做机器学习\n源代码：Machine-Learning-With-Go\n生活 车辆被堵 早上准备开车上班，发现车子前后道路都被车辆占道了。前面车辆占道，昨天晚上下班回来就发现了，也确认了这个车辆没有留挪车电话。当时就隐隐担忧今天早上会被挡住前后道路。没有想到，真的被挡了。后面的车辆留了挪车电话。六点半开始，我就给后面车的车主打电话发短信，对方一直没接电话，估计手机调静音还在睡觉吧。没有想到的是，截止到现在时间八点，他还没有给我回电话，这哥们睡得那是真香啊。\n在道路被占用之后，我做了什么？除了给留了号码的那个车主打电话之外，我还想到交管 12123 APP 上面有一个一键挪车功能。于是，试了一下这个功能。原以为这个功能可以电话通知到对方挪车。实际情况却只是提交了一个工单而已，真是一个鸡肋的功能。用户使用这个功能，是希望及时联系到车主过来挪车，而不是提交一个工单之后，傻傻的等待。另外，这个功能也不能叫一键挪车，因为点击了这个功能之后，还要输入车牌号、上传照片。更好的体验应该是只用上传占用道路的车辆照片，由系统识别出车牌号，然后后台找到车主的手机号，生成一个临时号码并调用手机的拨号功能。\n在道路被占用之后，我的心态是怎样的？刚开始想生气愤怒，后来想了想，事已至此，没有必要生气，生气只能影响自己一天的心情和好运。并尝试把这种对自己不利的一面转化为对自己有利的一面。原想六点半开车上班，道路被占之后，就可以体验一下七点多甚至八点多开车上班需要多长时间以及是否堵车。\n如果是我把道路占用了，我该怎么做呢？首先，是车上留一个手机号码；其次，是第二天早上保证手机不关机并且没有静音。\n如何避免再次出现这样的情况呢？一是通过电话或者便条的形式提醒车主要在车上留一个挪车电话并保证电话畅通，二是反馈给物业让物业来提醒小区里的车主不要随意占用车道。\n开车总结 学到了新知识：\n学会了如何调节前灯的高度。数字越大，灯光照射的越近。 开车需要改进的地方：\n1、今天在菜场点火的时候，错把油门当刹车 2、准备加速超过左边货车的时候，货车打了右前灯，下意识地把方向盘向右打了一点 3、遇到红绿灯变黄灯时，刹车太急。想冲过去，但犹豫了。这样做太危险，不能存在侥幸心理。下次遇到这种情况，宁可提前刹车，等红灯过了，再向前行驶。 好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 做了 6 年程序员，我学到的 10 条经验\nJetBrains 常用插件\nv2ray + warp-go 非全局使用 Cloudflare WARP 解锁 New Bing 等服务\n如何创建属于自己的私人资料库与私人搜索引擎 _\n如何高效地协作开发：一些 Google 的实践\nJava 高性能缓存库 Caffeine\n一些工具 优设导航官网：设计导航 2013 年上线至今，是优设网旗下最专业好用的设计师导航网站！设计导航为设计师提供 UI 设计、设计教程、素材下载、高清图库、配色方案、App 设计、网页设计等设计网站导航指引。设计导航每周更新，设计风向标就看优设网！\nZeabur 属于国人的免费托管平台\nNeovim 使用体验\nGithub Copilot 免费平替 - Codeium\nChat with documents\nCodeium：一款免费的类 Github Copilot 的 AI 代码辅助产品，可以便捷的和 AI 进行结对编程。初步使用下来和主流的 IDE 的集成很好，感兴趣的朋友可以先到浏览器里在线尝试一番。\n一些视频 飚速宅男第五季 魔女 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/03/28/weekly_review_12/","summary":"前言 本篇是对 2023-03-20 到 2023-03-26 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n上周去同济医院检查鼾症，检查结果是轻度症状，医生建议多运动减肥。这周每天走路 1 万步的目标已达成。\n工作上发布了一个版本，另外两个迭代正在进行中，预计这周再发布一个版本。从飞书通讯录看到又有三个非技术类同事被裁，这周周会，部门领导说最近又有一个做商务的同事被优化了。\n上周有一天早上，车子停在小区里面，被两个车子挡住了前后道路，联系不上车主，只好坐地铁上班。话说，自从开车上班之后，使用手机的频率明显降低了很多。\n上周末阳光正好，于是回家去给已故的亲人扫墓。周六回老家，周日回老婆家。逝者已逝，活着的人要善待自己，好好吃饭，好好睡觉，好好工作，好好运动。\n工作 Effective Java 3 笔记 请参考 《Effective Java 3》笔记：静态工厂方法代替构造函数。\nMachine-Learning-With-Go B 站视频：「课程」使用 Go 做机器学习\n源代码：Machine-Learning-With-Go\n生活 车辆被堵 早上准备开车上班，发现车子前后道路都被车辆占道了。前面车辆占道，昨天晚上下班回来就发现了，也确认了这个车辆没有留挪车电话。当时就隐隐担忧今天早上会被挡住前后道路。没有想到，真的被挡了。后面的车辆留了挪车电话。六点半开始，我就给后面车的车主打电话发短信，对方一直没接电话，估计手机调静音还在睡觉吧。没有想到的是，截止到现在时间八点，他还没有给我回电话，这哥们睡得那是真香啊。\n在道路被占用之后，我做了什么？除了给留了号码的那个车主打电话之外，我还想到交管 12123 APP 上面有一个一键挪车功能。于是，试了一下这个功能。原以为这个功能可以电话通知到对方挪车。实际情况却只是提交了一个工单而已，真是一个鸡肋的功能。用户使用这个功能，是希望及时联系到车主过来挪车，而不是提交一个工单之后，傻傻的等待。另外，这个功能也不能叫一键挪车，因为点击了这个功能之后，还要输入车牌号、上传照片。更好的体验应该是只用上传占用道路的车辆照片，由系统识别出车牌号，然后后台找到车主的手机号，生成一个临时号码并调用手机的拨号功能。\n在道路被占用之后，我的心态是怎样的？刚开始想生气愤怒，后来想了想，事已至此，没有必要生气，生气只能影响自己一天的心情和好运。并尝试把这种对自己不利的一面转化为对自己有利的一面。原想六点半开车上班，道路被占之后，就可以体验一下七点多甚至八点多开车上班需要多长时间以及是否堵车。\n如果是我把道路占用了，我该怎么做呢？首先，是车上留一个手机号码；其次，是第二天早上保证手机不关机并且没有静音。\n如何避免再次出现这样的情况呢？一是通过电话或者便条的形式提醒车主要在车上留一个挪车电话并保证电话畅通，二是反馈给物业让物业来提醒小区里的车主不要随意占用车道。\n开车总结 学到了新知识：\n学会了如何调节前灯的高度。数字越大，灯光照射的越近。 开车需要改进的地方：\n1、今天在菜场点火的时候，错把油门当刹车 2、准备加速超过左边货车的时候，货车打了右前灯，下意识地把方向盘向右打了一点 3、遇到红绿灯变黄灯时，刹车太急。想冲过去，但犹豫了。这样做太危险，不能存在侥幸心理。下次遇到这种情况，宁可提前刹车，等红灯过了，再向前行驶。 好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 做了 6 年程序员，我学到的 10 条经验\nJetBrains 常用插件\nv2ray + warp-go 非全局使用 Cloudflare WARP 解锁 New Bing 等服务\n如何创建属于自己的私人资料库与私人搜索引擎 _\n如何高效地协作开发：一些 Google 的实践\nJava 高性能缓存库 Caffeine\n一些工具 优设导航官网：设计导航 2013 年上线至今，是优设网旗下最专业好用的设计师导航网站！设计导航为设计师提供 UI 设计、设计教程、素材下载、高清图库、配色方案、App 设计、网页设计等设计网站导航指引。设计导航每周更新，设计风向标就看优设网！\nZeabur 属于国人的免费托管平台\nNeovim 使用体验\nGithub Copilot 免费平替 - Codeium\nChat with documents\nCodeium：一款免费的类 Github Copilot 的 AI 代码辅助产品，可以便捷的和 AI 进行结对编程。初步使用下来和主流的 IDE 的集成很好，感兴趣的朋友可以先到浏览器里在线尝试一番。","title":"周报-12｜车辆被堵、开车总结、Effective Java3笔记"},{"content":"前言 图片：涨渡湖湿地水上森林公园\n本篇是对 2023-03-13 到 2023-03-19 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作主要是重构、优化系统，工作节奏比之前轻缓了很多。这周也开始了开车上下班，除去周五去医院做检查，一共开了 4 天车。从汉口到光谷，一共 29 公里，如果早上 6:30 出发，就只需要 50 分钟；如果 6:45 出发，竟然需要两个小时，真是无语了。无奈之下，只能每天早点出门早点到公司，然后，打完卡之后，在公司楼下走路。\n这周开始心里默默定了一个 flag，就是每天走路 10000 步。看了一下微信运动，基本上达成了，除了周五晚上因为加班，而少走了 64 步。\n从语雀迁移到 Obsidian 上周提到开始使用格志 APP 来写日志，使用了一段时间之后，发现了一些缺点：\n部分功能收费 导出的 markdown 不支持图片显示 不支持本地存储 于是，放弃了使用格志 APP，继而在使用了一段时间 Obsidian 之后，改为使用 Obsidian 来写日志和周报。\n为了不给自己太大压力，日报每天复盘内容包括以下几方面：\n今日待办\n学习\n工作\n生活\n健身\n导出语雀文档为 markdown 参考 yuque/yuque-exporter 文档，下载 yuque-exporter 之后进行导出操作，发现以下问题：\n该项目需要使用的 nodejs 版本为 18.0.4 nodejs 使用正确的版本还是导出失败 于是，改为使用源码编译和运行导出。\n1、先下载代码：\ngit clone https://github.com/yuque/yuque-exporter.git 2、修改 main.ts 中需要导出的语雀知识库地址为自己的仓库地址：\n// Determining if an ESM module is main then run the code if (import.meta.url.startsWith(\u0026#34;file:\u0026#34;)) { const modulePath = fileURLToPath(import.meta.url); if (process.argv[1] === modulePath) { const urlPaths = [\u0026#34;chensoul/rose\u0026#34;, \u0026#34;chensoul/growup\u0026#34;, \u0026#34;chensoul/tech\u0026#34;]; await start({ urlPaths }); } } 3、参考 文档 申请语雀 TOKEN。\n4、下载项目依赖：\nnpm i 5、运行项目，开始导出：\nYUQUE_TOKEN=XXXXXX npm start 导出的文件在 storage 目录，接下来可以拷贝到 Obsidian 目录里。\n6、另外，可以对 yuque-exporter 源码做一些修改：\n导出的 markdown 文件不要有 frontmatter，修改 doc.ts 中 buildDoc 方法： export async function buildDoc( doc: TreeNode, mapping: Record\u0026lt;string, TreeNode\u0026gt; ) { const docDetail = await readJSON( path.join(metaDir, doc.namespace, \u0026#34;docs\u0026#34;, `${doc.url}.json`) ); const content = await remark() .data(\u0026#34;settings\u0026#34;, { bullet: \u0026#34;-\u0026#34;, listItemIndent: \u0026#34;one\u0026#34; }) .use([ [replaceHTML], [relativeLink, { doc, mapping }], [downloadAsset, { doc, mapping }], ]) .process(docDetail.body); // doc.content = frontmatter(doc) + content.toString(); doc.content = content.toString(); // FIXME: remark will transform `*` to `\\*` doc.content = doc.content.replaceAll(\u0026#34;\\\\*\u0026#34;, \u0026#34;*\u0026#34;); return doc; } 导出的段落之间增加换行，修改 doc.ts 中 replaceHTML 方法： function replaceHTML() { return (tree) =\u0026gt; { const htmlNodes = selectAll(\u0026#34;html\u0026#34;, tree) as Text[]; for (const node of htmlNodes) { if (node.value === \u0026#34;\u0026lt;br /\u0026gt;\u0026#34; || node.value === \u0026#34;\u0026lt;br/\u0026gt;\u0026#34;) { node.type = \u0026#34;text\u0026#34;; node.value = \u0026#34;\\n\\n\\n\u0026#34;; } } }; } 7、删除导出的 markdown 文件当中的锚点标签（例如：\u0026lt;a name=\u0026quot;xx\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;）\ncd storage # macos 上执行 find . -type f -name \u0026#39;*.md\u0026#39; -exec sed -i \u0026#39;\u0026#39; \u0026#39;s/\u0026lt;a name=\\\u0026#34;[^\\\u0026#34;]*\\\u0026#34;\u0026gt;\u0026lt;\\/a\u0026gt;//g\u0026#39; {} + 在上面的示例代码中，我们使用了 sed 命令来删除 Markdown 文件中所有的类似 \u0026lt;a name=\u0026quot;xx\u0026quot;\u0026gt;\u0026lt;/a\u0026gt; 的锚点标签。其中：\n-i '' 参数表示直接修改源文件，而不是输出到标准输出流。'' 表示在 macOS 系统上备份修改前的文件，如果在 Linux 系统上使用该命令，可以省略该参数。 s/\u0026lt;a name=\\\u0026quot;[^\\\u0026quot;]*\\\u0026quot;\u0026gt;\u0026lt;\\/a\u0026gt;//g 表示用空字符串替换所有符合正则表达式 \u0026lt;a name=\\\u0026quot;[^\\\u0026quot;]*\\\u0026quot;\u0026gt;\u0026lt;\\/a\u0026gt; 的字符串。该正则表达式匹配所有以 \u0026lt;a name= 开头，以 \u0026quot;\u0026gt;\u0026lt;/a\u0026gt; 结尾的标签，且中间的文本不包含双引号。 8、将导出的 markdown 文件中的本地图片批量上传到图床，操作方法：使用 typora 打开 storage 目录，然后依次点击 格式、图像、上传所有本地图片\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 GitHub Actions 成本优化：让你的团队更具竞争力\nNginx 开启 gzip 压缩\nObsidan 日记、记账与自动同步\nDoprax 搭建免费 V2ray 节点\nHi，土区 iCloud\n国区使用土耳其 iCloud 服务，手把手保姆级上车教程\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/03/20/weekly_review_11/","summary":"前言 图片：涨渡湖湿地水上森林公园\n本篇是对 2023-03-13 到 2023-03-19 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的工作主要是重构、优化系统，工作节奏比之前轻缓了很多。这周也开始了开车上下班，除去周五去医院做检查，一共开了 4 天车。从汉口到光谷，一共 29 公里，如果早上 6:30 出发，就只需要 50 分钟；如果 6:45 出发，竟然需要两个小时，真是无语了。无奈之下，只能每天早点出门早点到公司，然后，打完卡之后，在公司楼下走路。\n这周开始心里默默定了一个 flag，就是每天走路 10000 步。看了一下微信运动，基本上达成了，除了周五晚上因为加班，而少走了 64 步。\n从语雀迁移到 Obsidian 上周提到开始使用格志 APP 来写日志，使用了一段时间之后，发现了一些缺点：\n部分功能收费 导出的 markdown 不支持图片显示 不支持本地存储 于是，放弃了使用格志 APP，继而在使用了一段时间 Obsidian 之后，改为使用 Obsidian 来写日志和周报。\n为了不给自己太大压力，日报每天复盘内容包括以下几方面：\n今日待办\n学习\n工作\n生活\n健身\n导出语雀文档为 markdown 参考 yuque/yuque-exporter 文档，下载 yuque-exporter 之后进行导出操作，发现以下问题：\n该项目需要使用的 nodejs 版本为 18.0.4 nodejs 使用正确的版本还是导出失败 于是，改为使用源码编译和运行导出。\n1、先下载代码：\ngit clone https://github.com/yuque/yuque-exporter.git 2、修改 main.ts 中需要导出的语雀知识库地址为自己的仓库地址：\n// Determining if an ESM module is main then run the code if (import.meta.url.startsWith(\u0026#34;file:\u0026#34;)) { const modulePath = fileURLToPath(import.meta.url); if (process.argv[1] === modulePath) { const urlPaths = [\u0026#34;chensoul/rose\u0026#34;, \u0026#34;chensoul/growup\u0026#34;, \u0026#34;chensoul/tech\u0026#34;]; await start({ urlPaths }); } } 3、参考 文档 申请语雀 TOKEN。","title":"周报-11｜从语雀迁移到Obsidian"},{"content":"前言 本篇是对 2023-03-06 到 2023-03-12 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周发现 VPS 上 某些使用 docker 部署的服务（cusdis、umami、uptime、n8n、rsshub、memos）国内用户无法访问了，于是就折腾了一下使用 Cloudflare Tunnel 来代理这些服务。配置成功之后，又发现本地如果开启 VPN，Cloudflare Tunnel 代理的域名还是无法访问，于是放弃了使用 Cloudflare Tunnel，改为将这些国内无法访问的服务部署到免费的 VPS 服务器上，比如：Railway、Vercel。\n这周工作忙完之后，就开始着手通知系统的重构改造服务，想着 chatgpt 这么火，于是就试试让它来写代码。在不断地修改需求的情况下，chatgpt 写出来的代码稍加调整逐渐可以使用了。\n周六从汉口开车去白沙洲湖北财税职业学院，全程 20 公里，回来的时候不小心把路边的面包车擦碰了一下。于是一脸懵的经历了一次保险定损维修。\n周六开始使用 格志 APP 写日志，选择它来记录日志的原因是它支持批量导出 mardkown、pdf、图片等。唯一有个小遗憾的是，这个应用没有图床，导出的 markdown 文件里面图片的链接不是 http 协议。\n周日去新荣龙湖天耀天街售房部看了一下房子。107 平三室两厅两卫，单价 2 万 5 带精装修，公积金贷款 90 万，商业贷款 30 年，每个月房贷 6000。目前来说，买不起这里的房子，但是，作为一个买房目标还是可以的，加油！\n开车总结 最近刷视频，总结的一些开车经验如下：\n提前预判，前面车子刹车，不管是正前方，还是左右前方，这时候也要刹车\n前面有大货车，不要从右边超车\n会车时，看路宽\n不要连续变道，变道时既要看后视镜，又要看窗边\n红灯路口右转时，要看地面或者路边是否有禁止右转标识\n通过 Cloudflare Tunnel 访问服务 以下内容参考 初探 Cloudflare 零信任 - 通过 Cloudflare Tunnel 访问服务。\n1、创建 Cloudflare Tunnel 登录 Cloudflare Zero Trust 控制台，选择左侧导航栏的 Access 菜单，进入 Tunnels 配置，点击 Create a tunnel 创建一个 Tunnel，输入 Tunnel 隧道名称\n选择服务器的操作系统和平台架构：\n可以看到安装命令：\n复制左边命令粘贴到 SSH 会话里安装 Cloudflared（注意保护 Refresh Token 不要泄漏）\nbrew install cloudflare/cloudflare/cloudflared \u0026amp;\u0026amp; sudo cloudflared service install eyJhIjoiMmUxOTgwYTBlZjQzZjU3YjkyMGVhMjhjZGY5ZDM4ZDEiLCJ0IjoiYzU1ZTU3MmUtMTEyMS00OWJkLTgzMTgtNjc3NDIyYWMwMjU0IiwicyI6Ik1qZGtZakkyTldFdE5XVTRNUzAwTXpWaExXRXlNRFl0T0RobE5EbGpObVZpWmpJMSJ9 2、删除 Cloudflare DNS 的 A 记录解析 我的域名托管在 Cloudflare 上，所以需要将原来的域名解析记录删除，主要涉及以下两个需要被国内用户访问的域名（其余域名是我个人使用，所以只需要我开启 VPN 访问即可。）：\ncusdis.chensoul.cc umami.chensoul.cc 3、在 Cloudflare Tunnel 添加 hostname 如果需要对 ssh 服务开启代理，请参考：Connect with SSH through Cloudflare Tunnel。\n关键步骤是：\n为 ssh 通道创建 Hostname\n在本地安装 cloudflared\n配置 ~/.ssh/config，添加下面配置（注意：我使用 Homebrew 安装的 cloudflared）：\nHost ssh.chensoul.cc ProxyCommand /opt/homebrew/bin/cloudflared access ssh --hostname %h 通过 ssh 访问 ssh.chensoul.cc：\nssh root@ssh.chensoul.cc 4、在 vps 上启用防火墙，停止 nginx 服务 将 vps 上 nginx 配置的反向代理删除，并可以禁用这些服务暴露的端口。\n5、测试 经过测试，又发现本地如果开启 VPN，Cloudflare Tunnel 代理的域名还是无法访问，于是放弃了使用 Cloudflare Tunnel，改为将这些国内无法访问的服务部署到免费的 VPS 服务器上，比如：Railway、Vercel。\nVercel 部署 Cusdis、umami 参考 轻量级开源免费博客评论系统解决方案（Cusdis + Railway） 在 Railway 上部署 cusdis，数据库还是可以使用 vps 上部署的 postgresql，只需要配置一个 jdbc 链接即可：\npostgresql://cusdis:xxxxxx@postgres.chensoul.cc:5432/cusdis 部署完之后，发现存在跨域问题，故全部改为使用 Vercel 来部署。\n参考 Cusdis 官方文档 来部署 Cusdis，对于 Cusdis 存在跨域问题，参考 Sometimes form shows on page, sometimes not - CORS issue #135，修改你的 github 的 cusdis 仓库中的 next.config.js 文件：\nasync headers() { return [ { source: \u0026#34;/:path*\u0026#34;, headers: [ { key: \u0026#34;Access-Control-Allow-Origin\u0026#34;, value: \u0026#34;*\u0026#34; }, ], }, ] }, 参考 Umami 官方文档 来部署 Umami，umami 的 postgresql jdbc 链接还是使用 vps 上面部署的 postgresql\npostgresql://umami:xxxxxxpostgres.chensoul.cc:5432/umami Chatgpt 写代码 在 https://poe.com/chatgpt 里面输入下面文字：\n请用 java 实现一个通知系统，给出完整的代码，需求如下：\n1、通知事件，指业务平台触发的事件，通知事件有名称，描述，编码。通知事件可以定义多个属性。属性有名称、描述、编码，类型。类型有整形、字符串、日期、时间、浮点数、列表几种。\n2、通知规则。通知规则有名称、生效时间（一直生效，或者指定时间段生效），通知事件（从创建好的事件选择一个）、描述。通知规则可以创建多个规则项。每个规则项要选择事件下面的某一个属性，并且可以对该事件属性选择一个操作符（大于、小于、等于、在两个指之间）和设置对应的值。如果是大于、小于、等于，则只用选择一个值。如果是在两个指之间，则需要选择两个值。多个执行条件在规则执行时，是按与执行。规则可以指定多个通知用户（姓名、手机号）。\n3、通知策略。一个规则可以定义多个通知策略。通知策略有通知模版、通知渠道。每个通知模版有标题、描述以及模版内容（模板内容支持变量替换）。\n4、通知渠道有类型、配置属性，可以发送消息，支持的通知渠道有飞书、邮件。\n5、通知规则测试。给定一个事件码和事实数据，系统查询出该事件码关联的多个规则。每个规则通过 easy-rule 4.1.0 框架去执行。每个规则项执行前，需要校验事实数据里的值的类型和事件属性定义的类型是否一致。多个规则项的执行结果求交集。当最后结果为 true 时，将通知策略中的模板内容进行变量替换，然后通过渠道发送消息给这些人。\n注意：相同的消息内容，在一分钟内，只通过一个渠道给某一个用户发送一次，不要重复发送。\nchatgpt 回答如下：\n总结：\n让 chatgpt 写代码相对来说，还是很方便的，可以提供一些编程示例或者开阔编程思路，但是也有一些缺陷：\nchatgpt 写的代码不一定准确，或者说没有考虑一些异常情况。需要不断地和 chatgpt 聊天，描述清楚需求，让 chatgpt 来修正代码，这样交互式聊天，相对来说会有点耗时。 提供的 url 链接可能 404。 好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 Java 近期新闻：Gradle 8.0、Maven、Payara 平台、Piranha、Spring Framework、MyFaces 和 Piranha\nRackNerd VPS 推荐\n一些工具 Zed Atom 作者新开发的编辑器 Zed 速度确实非常快，基本的功能也都支持，现在还在内测阶段，暂时不支持安装 extension。\n图片转 webp mac 上安装：\nbrew install webp 使用示例：\ncwebp -q 50 -lossless picture.png -o picture_lossless.webp cwebp -q 70 picture_with_alpha.png -o picture_with_alpha.webp cwebp -sns 70 -f 50 -size 60000 picture.png -o picture.webp 一些影视 冰海陷落，推荐指数：☆☆☆☆。疯狂的芭堤雅将军杜罗夫（米哈伊尔・戈尔沃伊 Mikhail Gorevoy 饰）预谋发动第三次世界大战，他制造了一场巨大的水域爆炸，致使附近的美军潜艇队遇袭。美国海军派出了海底经验丰富但名声寥寥的乔・格拉斯潜水艇船长（杰拉德・巴特勒 Gerard Butler 饰）率领潜艇队前去调查。\n黑暗荣耀第二季，推荐指数：☆☆☆☆。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/03/13/weekly_review_10/","summary":"前言 本篇是对 2023-03-06 到 2023-03-12 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周发现 VPS 上 某些使用 docker 部署的服务（cusdis、umami、uptime、n8n、rsshub、memos）国内用户无法访问了，于是就折腾了一下使用 Cloudflare Tunnel 来代理这些服务。配置成功之后，又发现本地如果开启 VPN，Cloudflare Tunnel 代理的域名还是无法访问，于是放弃了使用 Cloudflare Tunnel，改为将这些国内无法访问的服务部署到免费的 VPS 服务器上，比如：Railway、Vercel。\n这周工作忙完之后，就开始着手通知系统的重构改造服务，想着 chatgpt 这么火，于是就试试让它来写代码。在不断地修改需求的情况下，chatgpt 写出来的代码稍加调整逐渐可以使用了。\n周六从汉口开车去白沙洲湖北财税职业学院，全程 20 公里，回来的时候不小心把路边的面包车擦碰了一下。于是一脸懵的经历了一次保险定损维修。\n周六开始使用 格志 APP 写日志，选择它来记录日志的原因是它支持批量导出 mardkown、pdf、图片等。唯一有个小遗憾的是，这个应用没有图床，导出的 markdown 文件里面图片的链接不是 http 协议。\n周日去新荣龙湖天耀天街售房部看了一下房子。107 平三室两厅两卫，单价 2 万 5 带精装修，公积金贷款 90 万，商业贷款 30 年，每个月房贷 6000。目前来说，买不起这里的房子，但是，作为一个买房目标还是可以的，加油！\n开车总结 最近刷视频，总结的一些开车经验如下：\n提前预判，前面车子刹车，不管是正前方，还是左右前方，这时候也要刹车\n前面有大货车，不要从右边超车\n会车时，看路宽\n不要连续变道，变道时既要看后视镜，又要看窗边\n红灯路口右转时，要看地面或者路边是否有禁止右转标识\n通过 Cloudflare Tunnel 访问服务 以下内容参考 初探 Cloudflare 零信任 - 通过 Cloudflare Tunnel 访问服务。\n1、创建 Cloudflare Tunnel 登录 Cloudflare Zero Trust 控制台，选择左侧导航栏的 Access 菜单，进入 Tunnels 配置，点击 Create a tunnel 创建一个 Tunnel，输入 Tunnel 隧道名称\n选择服务器的操作系统和平台架构：\n可以看到安装命令：\n复制左边命令粘贴到 SSH 会话里安装 Cloudflared（注意保护 Refresh Token 不要泄漏）\nbrew install cloudflare/cloudflare/cloudflared \u0026amp;\u0026amp; sudo cloudflared service install eyJhIjoiMmUxOTgwYTBlZjQzZjU3YjkyMGVhMjhjZGY5ZDM4ZDEiLCJ0IjoiYzU1ZTU3MmUtMTEyMS00OWJkLTgzMTgtNjc3NDIyYWMwMjU0IiwicyI6Ik1qZGtZakkyTldFdE5XVTRNUzAwTXpWaExXRXlNRFl0T0RobE5EbGpObVZpWmpJMSJ9 2、删除 Cloudflare DNS 的 A 记录解析 我的域名托管在 Cloudflare 上，所以需要将原来的域名解析记录删除，主要涉及以下两个需要被国内用户访问的域名（其余域名是我个人使用，所以只需要我开启 VPN 访问即可。）：","title":"周报-10｜通过Cloudflare Tunnel访问服务、Vercel部署Cusdis和Umami"},{"content":"前言 本篇是对 2023-02-27 到 2023-03-05 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的主要工作是版本测试和项目上线，在大家的共同努力下，最后是成功上线。\n由于公司最近在裁员，留下来的都开始卷起来，每天晚上 8 点之后下班，这样平均一天的工作时间才有 11 小时。据说，旁边组的同事平均每天都是 12 个小时工作时间。裁了三位同事之后，我们软件组还有 8 人，算法组有 7 人，产品组有 6 人，终端组有 4 人。距集团公司六月上市还有两个月，裁员估计还会继续，同志们还需努力加班，争取被裁的不是自己。\n这周还是没有开车，每天坐地铁上下班，刷刷 rss 看看 b 站视频，了解一些行业最新动态，同时也看看同样在写博客的那些独立开发者每周都在做什么，也学习一些新技术或者新技能。\n这周接触了 web3 空投，花了几个小时使用自动加手动的方式刷了 120 多个账号。自动的方式，就是用 nodejs 代码在 bsc 网络批量创建账号并保存为 csv 文件；其次，通过 onekey web 上的批量转账功能，给每个账户转了 0.00125bnb。手动操作的部分就是，一个个的将账号私钥导入狐狸钱包，然后，用 lifeform cartoon 连接钱包账户，mint 成功之后，分享链接，再继续连接狐狸的下一个账号，重复上面操作。\n因为太耗时间，所以只刷了 120 个账号。趁工作不忙的时候，用 chatgpt 搜索一下如何将上面的操作全部自动化。\n周末两天，继续练车，从汉口到阳逻，再到新洲，最后去新洲的将军山爬山、去道观河看风景。算下来，最近这三个周末六天时间，我一共开了 800 多公里了。目前，暂时没有收到违规通知，但还是存在很多不足的地方。\n开车总结 这周开车，发现存在以下问题：\n1、停车还是会忘记熄火拔钥匙。 2、红绿灯口，停在大货车后面，并靠得近，前方视线受阻。经过红绿灯时，感觉像是闯了红灯。 3、超车时候，没有加速。 4、在山路行驶，入弯和出弯都会减速。 5、判断车距的经验不足。表现在行驶过程中、侧方停车、倒车入库。 针对以上问题，晚上刷了一些视频，做了一些笔记，希望能够帮助自己改正上面这些问题。\n1、目光看远。入弯提前收油，脚备刹车。如果弯道过急，就带点刹车，如果车速你可以控制，直接收油过弯；出弯加油，眼睛看出弯口。身体跟随方向盘靠。这样，车速不降，可以控制车速。如果以 80 码速度过弯，且这个车还在车道内，这个车的速度你就控制住了。但凡有点越线，说明车速过快，你就要降低速度。\n2、靠右行驶。会车时，主动靠右。转弯时，发现对面有来车，鸣笛示意。\n3、路口远道的原则，跟小车不跟大车。如果跟着大车，留一个车位空间，让大车先走，确认绿灯再走。\n4、红绿灯路口，提前减速，提醒后面车减速，不要急刹车，防止后面车追尾。特别是在绿灯闪的时候，不要没有减速，突然停车。否则后面车会以为你要加速冲过去，他也加速，这样，他就会追尾你。\n博客该写什么 看到一篇博客 What to blog about，里面聊到了博客该写什么。一时兴起，想翻译成中文。于是，分别使用了 chrome 沉浸式翻译插件和 chatgpt 来翻译这篇文章，得到结果如下：\n1、使用 chrome 沉浸式翻译插件 翻译这篇文章：\n总结来说，博客可以写两部分内容：\n今天学到的东西 正在做的项目 2、使用 chatgpt 翻译这篇文章：\n请 chatgpt 翻译这篇文章 https://simonwillison.net/2022/Nov/6/what-to-blog-about/ 为中文，得到的结果如下：\n标题：该写什么博客？\n随着我写了一篇新的博客文章，我想分享一下我最近学到的关于写博客的一些事情。\n一旦你开始写博客，你就必须保持一定的频率和持续的内容更新。这不仅是为了吸引和保持读者，也是为了让自己不断成长和发展。对于我来说，博客是我最有价值的自我表达形式之一，因为它迫使我去思考和组织我的想法，而这些想法可能会被淹没在日常生活的喧嚣中。\n但是，选择博客内容可以很困难，特别是当你有多个感兴趣的话题和项目。以下是一些我最近学到的有关选择博客主题的技巧：\n每周至少写一篇文章 尽管这可能听起来像一个艰巨的任务，但保持每周至少写一篇文章的频率可以帮助你保持写作的习惯和进展。这也有助于避免长时间的空白期，这可能会使你失去写作的动力和读者的兴趣。\n写下你的目标和想法清单 在开始写博客之前，先写下你感兴趣的话题和你想写的内容。这可以帮助你保持焦点并避免浪费时间在想要的内容上。\n关注你的读者 虽然你的博客可能是一个人的项目，但是考虑到你的读者的兴趣和需求是至关重要的。试着想一下你的读者会对哪些话题感兴趣，并尝试写出他们会发现有趣或有用的内容。\n保持开放和灵活 不要把自己局限在一个主题或领域中。保持开放和灵活，尝试不同的话题和领域。这不仅可以让你发现新的兴趣和机会，还可以让你在写作方面更有创意和灵感。\n尝试不同的博客格式 不仅可以通过写作来表达自己，还可以通过不同的博客格式来实现这一点。尝试写一篇教程、一篇演示、一篇评论或一篇问题解答文章。这可以让你更好地探索和展示你的技能和知识。\n总之，写博客可以是一种令人满意的表达方式，可以帮助你探索和发现新的想法和机会。关键是要保持频率和灵活性，并尝试不同的博客格式。\nWeb3 批量空投 最近，参与了 Lifeform Cartoon 的空投，这是我第一次参与 web3。下面是记录一下操作步骤：\n下载狐狸钱包 批量创建账号 批量从一个账号转币到多个账号 批量导入账号到狐狸钱包 访问 Lifeform Cartoon 的邀请链接地址，比如：https://cartoon.lifeform.cc?referral=0x068b021B7d44e4795c6ec07234D66c144644dC37，然后，连接狐狸钱包里的账号，mint 之后，分享链接再使用新的链接重复上面动作 上面的步骤，如果是几百个账号手动执行，则需要花费很长时间。作为一个程序员，有没有办法让程序自动实现呢？\n在网上查找了一些资料，同时使用 chatgpt（备注：https://poe.com/chatgpt）找到了使用 nodejs 实现的相关代码。\n1、批量创建账号 在 BSC 网络上使用 Node.js 编程语言批量创建账户并保存为 CSV 文件的完整代码，不使用 csv-writer 库\n2、批量转账 在 BSC 网络上使用 Node.js 编程语言从一个账号批量转 0.0125bnb 到前面创建的多个账号，输出完整的可以运行的代码\n3、批量导入账号到 metamask 钱包 通过编程实现在 BSC 网络 批量导入账号到浏览器的 metamask 钱包\n下一步，就是测试上面代码，实现全流程代码托管。\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 Service Profiles in Docker | Baeldung ChatGPT 终极指南 谈谈我对 ChatGPT 应用的 prompt 的看法 支持 OpenAI ChatGPT API 的优秀软件 编程新手如何通过 ChatGPT 一天完成一个 MVP 产品 让 OpenAI 生成 git commit message 好代码的五个特质 - Thoughtworks 洞见 我如何搭建自己的博客（英文） 从 Mac 开箱开始 设置一个开发环境 - ZedeX 创始人 CEO 为什么要写作（原创 5000 字长文尝试说透） 从抄书到开源之巅：章亦春的程序人生 一些工具 1、poe.com 美国问答网站 Quora 开发的 ChatBot 产品，整合不同聊天机器，包括 ChatGPT。响应速度非常快，比 chat.openai.com 的免费账户快非常多。有 ios 版，手机也能用了。ios 版有社区，可以分享聊天记录。\n2、FounderBeats Founder Beats 是一家面向初创企业和创业者的音乐制作工作室，专门为他们提供高质量的背景音乐和音效。Founder Beats 的音乐库包含了各种类型的音乐，如流行、摇滚、电子、嘻哈、民谣等，以及各种音效和配乐，可以满足不同用户的需求。Founder Beats 的音乐都是由专业音乐人和制作人制作的，具有高品质和原创性。\n除了音乐制作，Founder Beats 还提供了其他服务，如音频制作、混音和母带处理等，可以帮助客户制作高质量的音频内容。Founder Beats 的团队拥有丰富的音乐制作和音频处理经验，可以为客户提供专业的建议和支持。\nFounder Beats 的客户包括初创企业、广告代理商、视频制作公司、游戏开发商等，他们可以使用 Founder Beats 的音乐和音效来增强他们的品牌形象、视频内容、游戏体验等。Founder Beats 的定价模式灵活，客户可以根据自己的需求选择适合自己的价格和许可证。\n3、Manticore Search Manticore Search 是一款开源的全文搜索引擎，支持高性能的搜索和分析。它是 Sphinx Search 的后继者，使用了类似的架构和 API，并且在功能和性能方面有很多改进。Manticore Search 使用 C++编写，具有高效的索引和查询引擎，可以处理大量的数据和高并发访问。它支持多种数据源和数据格式，包括 MySQL、PostgreSQL、XML、JSON、CSV 等。\nManticore Search 提供了丰富的查询语言和 API，包括 SQL、SPHINQL 和 HTTP API 等，可以满足不同用户的需求。它支持全文搜索、模糊搜索、短语搜索、近义词搜索、地理位置搜索等多种搜索方式，并且支持高级过滤、排序、分组、聚合等功能。Manticore Search 还具有高可用性和可扩展性，支持主从复制、分片、集群等部署方式，可以满足不同规模和负载的应用场景。\nManticore Search 是一款使用广泛的全文搜索引擎，它被广泛应用于电子商务、社交网络、新闻媒体、在线教育等领域，帮助用户快速检索和发现所需信息。Manticore Search 在 GitHub 上开源，拥有活跃的社区和开发者，用户可以通过 GitHub 社区获得支持和贡献代码。\n4、Unsilence unsilence 是一个基于 Python 的命令行工具，用于检测和修复音频文件中的静音区域。它可以帮助用户自动检测和删除音频文件中的静音部分，从而提高音频的质量和可听性。unsilence 支持多种音频格式，如 MP3、WAV、OGG 等，可以在不损失音频质量的情况下删除静音。\n使用 unsilence 非常简单，用户只需在命令行中输入 unsilence 命令和音频文件名，unsilence 就会自动检测和修复音频文件中的静音部分。用户也可以通过设置参数来调整 unsilence 的处理方式，如设置最小静音长度、最小音量阈值等。\n5、CSS Bed 这个网页收集并展示各种无类的极简化 CSS 框架。如果你想选一个简单的 CSS 框架，可以看看它\n6、lightrun lightrun.com 是一款基于云的实时 Java 和 Kotlin 应用程序调试和观察工具。它提供了一种无需修改代码即可实时调试 Java 和 Kotlin 应用程序的方式，减少了开发人员的调试时间，提高了应用程序的稳定性和可靠性。lightrun.com 还提供了实时日志查看和分析，可以帮助开发人员快速定位问题和解决问题，提高了应用程序的可维护性。\nlightrun.com 可以与常见的 Java 开发工具集成，如 Eclipse、IntelliJ IDEA 和 VS Code。它还支持多种操作系统和云平台，如 Windows、Linux、Docker、AWS 和 Azure 等。开发人员可以使用 lightrun.com 来调试和监视本地应用程序，也可以在云端快速诊断生产环境中的问题。\nlightrun.com 采用了安全的云架构，并且使用了端到端加密来保护用户数据的安全性。它还提供了灵活的计费模式，用户可以根据自己的需求选择适合自己的计费方式。\n7、https://github.com/apps/cr-gpt 基于 ChatGPT 的 Github Code Review 机器人\n8、妙记多 Mojidoc 新一代生产协同工具\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/03/07/weekly_review_9/","summary":"前言 本篇是对 2023-02-27 到 2023-03-05 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周的主要工作是版本测试和项目上线，在大家的共同努力下，最后是成功上线。\n由于公司最近在裁员，留下来的都开始卷起来，每天晚上 8 点之后下班，这样平均一天的工作时间才有 11 小时。据说，旁边组的同事平均每天都是 12 个小时工作时间。裁了三位同事之后，我们软件组还有 8 人，算法组有 7 人，产品组有 6 人，终端组有 4 人。距集团公司六月上市还有两个月，裁员估计还会继续，同志们还需努力加班，争取被裁的不是自己。\n这周还是没有开车，每天坐地铁上下班，刷刷 rss 看看 b 站视频，了解一些行业最新动态，同时也看看同样在写博客的那些独立开发者每周都在做什么，也学习一些新技术或者新技能。\n这周接触了 web3 空投，花了几个小时使用自动加手动的方式刷了 120 多个账号。自动的方式，就是用 nodejs 代码在 bsc 网络批量创建账号并保存为 csv 文件；其次，通过 onekey web 上的批量转账功能，给每个账户转了 0.00125bnb。手动操作的部分就是，一个个的将账号私钥导入狐狸钱包，然后，用 lifeform cartoon 连接钱包账户，mint 成功之后，分享链接，再继续连接狐狸的下一个账号，重复上面操作。\n因为太耗时间，所以只刷了 120 个账号。趁工作不忙的时候，用 chatgpt 搜索一下如何将上面的操作全部自动化。\n周末两天，继续练车，从汉口到阳逻，再到新洲，最后去新洲的将军山爬山、去道观河看风景。算下来，最近这三个周末六天时间，我一共开了 800 多公里了。目前，暂时没有收到违规通知，但还是存在很多不足的地方。\n开车总结 这周开车，发现存在以下问题：\n1、停车还是会忘记熄火拔钥匙。 2、红绿灯口，停在大货车后面，并靠得近，前方视线受阻。经过红绿灯时，感觉像是闯了红灯。 3、超车时候，没有加速。 4、在山路行驶，入弯和出弯都会减速。 5、判断车距的经验不足。表现在行驶过程中、侧方停车、倒车入库。 针对以上问题，晚上刷了一些视频，做了一些笔记，希望能够帮助自己改正上面这些问题。\n1、目光看远。入弯提前收油，脚备刹车。如果弯道过急，就带点刹车，如果车速你可以控制，直接收油过弯；出弯加油，眼睛看出弯口。身体跟随方向盘靠。这样，车速不降，可以控制车速。如果以 80 码速度过弯，且这个车还在车道内，这个车的速度你就控制住了。但凡有点越线，说明车速过快，你就要降低速度。\n2、靠右行驶。会车时，主动靠右。转弯时，发现对面有来车，鸣笛示意。\n3、路口远道的原则，跟小车不跟大车。如果跟着大车，留一个车位空间，让大车先走，确认绿灯再走。\n4、红绿灯路口，提前减速，提醒后面车减速，不要急刹车，防止后面车追尾。特别是在绿灯闪的时候，不要没有减速，突然停车。否则后面车会以为你要加速冲过去，他也加速，这样，他就会追尾你。\n博客该写什么 看到一篇博客 What to blog about，里面聊到了博客该写什么。一时兴起，想翻译成中文。于是，分别使用了 chrome 沉浸式翻译插件和 chatgpt 来翻译这篇文章，得到结果如下：\n1、使用 chrome 沉浸式翻译插件 翻译这篇文章：\n总结来说，博客可以写两部分内容：\n今天学到的东西 正在做的项目 2、使用 chatgpt 翻译这篇文章：\n请 chatgpt 翻译这篇文章 https://simonwillison.net/2022/Nov/6/what-to-blog-about/ 为中文，得到的结果如下：\n标题：该写什么博客？\n随着我写了一篇新的博客文章，我想分享一下我最近学到的关于写博客的一些事情。\n一旦你开始写博客，你就必须保持一定的频率和持续的内容更新。这不仅是为了吸引和保持读者，也是为了让自己不断成长和发展。对于我来说，博客是我最有价值的自我表达形式之一，因为它迫使我去思考和组织我的想法，而这些想法可能会被淹没在日常生活的喧嚣中。\n但是，选择博客内容可以很困难，特别是当你有多个感兴趣的话题和项目。以下是一些我最近学到的有关选择博客主题的技巧：\n每周至少写一篇文章 尽管这可能听起来像一个艰巨的任务，但保持每周至少写一篇文章的频率可以帮助你保持写作的习惯和进展。这也有助于避免长时间的空白期，这可能会使你失去写作的动力和读者的兴趣。","title":"周报-9｜开车总结、博客该写什么、Web3批量空投"},{"content":"前言 本篇是对 2023-02-20 到 2023-02-26 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这篇周报又是在地铁上完成编写的。回顾这一周的工作，还是项目测试、修复 bug 和准备上线发布。平静的工作节奏因为突如其来的裁员消息而变得内卷起来，大家下班的时间都纷纷往后移到了 20 点左右。周末的时候，还是练车，从汉口开车到新洲。刚开始有点不敢，后来还是鼓起勇气，平安的到达。\n工作 内存泄漏 这周线上环境，出现了告警，提示 jvm 出现了 full gc。于是赶紧 dump 内存进行分析查找原因。顺便整理了内存相关的知识。\n什么是内存泄漏？\n这个问题直接问 chatgpt：\n内存泄漏（Memory Leak）是指在程序中动态分配的内存由于某些原因程序未能释放或无法释放，导致系统内存的实际可用空间不断减少的现象。内存泄漏的发生会导致程序占用的内存越来越多，最终导致程序崩溃或系统变慢。\n在 Java 中，程序员通常使用 new 运算符在堆上分配内存，这些内存不再使用时必须释放，否则就会出现内存泄漏。下面是一些常见的 Java 内存泄漏的情况：\n对象持有过多的引用 当一个对象持有其他对象的引用时，这些对象就不能被垃圾收集器回收，导致内存泄漏。比如，一个静态集合（如 Map、List）持有了大量对象的引用，但是这些对象已经不再需要了，却因为集合中仍然持有这些对象的引用，导致这些对象无法被回收，造成内存泄漏。\n长时间持有对象锁 在 Java 中，如果一个线程获取了一个对象的锁，但是在释放锁之前发生了异常，那么这个锁就不会被释放，从而导致内存泄漏。这种情况特别容易发生在 synchronized 块中。\n不正确的缓存使用 如果程序员不正确地使用缓存，就会导致内存泄漏。比如，如果使用一个静态 Map 来缓存对象，但是不从 Map 中删除对象，那么这些对象就会一直存在于内存中，造成内存泄漏。\n大量创建临时对象 如果程序频繁地创建临时对象，而这些对象又没有被及时清除，就会导致内存泄漏。比如，在循环中创建大量的字符串对象，但是没有及时清除，就会导致内存泄漏。\n为了避免内存泄漏，Java 程序员可以使用一些技术来优化程序，比如使用缓存池、避免使用不必要的静态变量、使用 finalize()方法释放资源等等。\n如何排查内存泄漏？\n内存分析工具：内存分析工具可以帮助您找到哪些对象占用了大量的内存。一些常用的内存分析工具包括：Eclipse MAT、VisualVM 和 YourKit。这些工具可以帮助您分析内存快照、查找内存泄漏并确定导致内存泄漏的代码位置。\n堆转储文件：堆转储文件是一个包含了 JVM 堆中所有对象的快照。您可以使用以下命令生成一个堆转储文件：jmap -dump:format=b,file=heap.bin ，其中是您的 Java 应用程序的进程 ID。然后，您可以使用内存分析工具来分析该文件。\n代码审查：在编写代码时，您可以使用一些技巧来避免内存泄漏。例如，您应该确保正确地关闭流和数据库连接，避免在循环中创建对象，以及使用软引用或弱引用来存储缓存数据等。通过仔细审查代码并识别可能导致内存泄漏的部分，可以避免这些问题在运行时发生。\n监视工具：JVM 提供了一些监视工具，例如 jstat 和 jconsole，可以用于监视 JVM 的内存使用情况。通过监视这些指标，您可以识别是否存在内存泄漏的迹象。\n代码注入：在您的应用程序中，您可以注入一些代码，例如使用 JMX、AOP 等，以便您可以实时监视内存使用情况，并记录任何内存泄漏迹象。\n参考文章\n一次完整的 JVM 堆外内存泄漏故障排查记录\n深入探索 Java 8 Lambda 表达式\njava lambda 表达式内存泄露_浅谈 Java 内存泄露\n裁员 去年公司就在裁员，陆陆续续裁了几次，每次都是裁两三个，动作都不大，但是很高效。因为部门人数就在五十左右，所以谁没来上班，都能很快察觉。\n公司要在六月份上市，上市之前要使财报好看，就要开源节流、降本增效。节约成本的一个方式就是裁员，据说这次裁员动作比以前都大都迅速，今天提出裁员人数，明天就要给出名单，月底就要走人。\n现在还只是二月份，离六月还有三个月。谁也不知道，后面还会有什么更大的裁员动作。说不定哪天就空出一个工位，说不定哪天领导就换了人，说不定哪天部门就被拆散了。\n互联网公司最大的变化就是变化。之前在阿里工作，公司的价值观里有一条就是拥抱变化。\n拥抱变化的最好方式就是积极面对，主动加班，提高工作效率，增加工作产出。\n生活 练车 这是买车之后的第二周，还是没有开车去上班。一是因为开车不过熟练，胆子小，不敢开得太快；二是公司楼下的停车位还没有办好。\n周六本想叫朋友过来给我当陪练，后来因为要回新洲，就算了，还是自己开车，带着老婆回新洲。\n老婆科目一考过了，后面因为工作原因就没去练车和考试。她坐副驾驶，一边剥豆子一边提醒我注意交通规则。\n在老婆的坐镇之下，顺利的从汉口开车六十公里到达新洲，路上没有违反交通规则。\n周六下午去看了一下潘塘花朝节，有点失望，没有想象中的热闹。可能因为这不是正宗的花朝节，正宗的应该是在旧街。\n逛了一圈，买了两百菜刀、一个砧板、两颗果树、一盆墨兰花。\n周六从新洲开回阳逻，周日又从阳逻开回老家去看父亲。买车后第一次回家，放了鞭炮 🧨。\n中午包饺子，吃完饭就去菜园收割青菜。农村对于城市里上班族来说，一大好处是，每次回家，都可以装满青菜带回城市。\n下午，从老家驱车回阳逻再到汉口。在开车的过程中，发现和总结了一些问题。\n之前开车，总是盯着仪表盘，看车速达到了多少。车速一到 70 多就下意识地松油门和踩刹车。现在开始把眼睛注意力放到前方，不去可以在意车速，只是当导航提示我超速的时候，我白降低一点速度。\n在红绿灯之前，如果不转弯，不要提前换道或者超车，保持中间道路行驶即可。\n好物分享 虽然大部分有意思的内容会分享在 『ChenSoul Share』Telegram 频道，不过还是挑选一部分在这里列举一下，感觉更像一个 newsletter 了。\n一些文章 使用 GitHub Actions 自动申请与部署 SSL 证书\nThe AI search engine for developers\n用 AI 写文章\njava lambda 表达式内存泄露_浅谈 Java 内存泄露\n在家躺着拿工资，是挺过意不去的\n车辆违章和交通事故处理流程\n浅谈 Code Review 之事前准备\n一些工具 1、Raycast Raycast 是一款想要取代 Spotlight 的快捷启动器，通过 Mac 上面的一些组合键来为让你完成在 Mac 上面的快捷启动，提高你日常当中在 Mac 上面的操作效率，如果以 macOS 系统版本风格来比喻的话，Alfred 的 UI 风格应该能匹配几年前的 macOS 吧，而 Raycast 却是能够驾驭 macOS Big Sur 全新的视觉风格。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/02/27/weekly_review_8/","summary":"前言 本篇是对 2023-02-20 到 2023-02-26 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这篇周报又是在地铁上完成编写的。回顾这一周的工作，还是项目测试、修复 bug 和准备上线发布。平静的工作节奏因为突如其来的裁员消息而变得内卷起来，大家下班的时间都纷纷往后移到了 20 点左右。周末的时候，还是练车，从汉口开车到新洲。刚开始有点不敢，后来还是鼓起勇气，平安的到达。\n工作 内存泄漏 这周线上环境，出现了告警，提示 jvm 出现了 full gc。于是赶紧 dump 内存进行分析查找原因。顺便整理了内存相关的知识。\n什么是内存泄漏？\n这个问题直接问 chatgpt：\n内存泄漏（Memory Leak）是指在程序中动态分配的内存由于某些原因程序未能释放或无法释放，导致系统内存的实际可用空间不断减少的现象。内存泄漏的发生会导致程序占用的内存越来越多，最终导致程序崩溃或系统变慢。\n在 Java 中，程序员通常使用 new 运算符在堆上分配内存，这些内存不再使用时必须释放，否则就会出现内存泄漏。下面是一些常见的 Java 内存泄漏的情况：\n对象持有过多的引用 当一个对象持有其他对象的引用时，这些对象就不能被垃圾收集器回收，导致内存泄漏。比如，一个静态集合（如 Map、List）持有了大量对象的引用，但是这些对象已经不再需要了，却因为集合中仍然持有这些对象的引用，导致这些对象无法被回收，造成内存泄漏。\n长时间持有对象锁 在 Java 中，如果一个线程获取了一个对象的锁，但是在释放锁之前发生了异常，那么这个锁就不会被释放，从而导致内存泄漏。这种情况特别容易发生在 synchronized 块中。\n不正确的缓存使用 如果程序员不正确地使用缓存，就会导致内存泄漏。比如，如果使用一个静态 Map 来缓存对象，但是不从 Map 中删除对象，那么这些对象就会一直存在于内存中，造成内存泄漏。\n大量创建临时对象 如果程序频繁地创建临时对象，而这些对象又没有被及时清除，就会导致内存泄漏。比如，在循环中创建大量的字符串对象，但是没有及时清除，就会导致内存泄漏。\n为了避免内存泄漏，Java 程序员可以使用一些技术来优化程序，比如使用缓存池、避免使用不必要的静态变量、使用 finalize()方法释放资源等等。\n如何排查内存泄漏？\n内存分析工具：内存分析工具可以帮助您找到哪些对象占用了大量的内存。一些常用的内存分析工具包括：Eclipse MAT、VisualVM 和 YourKit。这些工具可以帮助您分析内存快照、查找内存泄漏并确定导致内存泄漏的代码位置。\n堆转储文件：堆转储文件是一个包含了 JVM 堆中所有对象的快照。您可以使用以下命令生成一个堆转储文件：jmap -dump:format=b,file=heap.bin ，其中是您的 Java 应用程序的进程 ID。然后，您可以使用内存分析工具来分析该文件。\n代码审查：在编写代码时，您可以使用一些技巧来避免内存泄漏。例如，您应该确保正确地关闭流和数据库连接，避免在循环中创建对象，以及使用软引用或弱引用来存储缓存数据等。通过仔细审查代码并识别可能导致内存泄漏的部分，可以避免这些问题在运行时发生。\n监视工具：JVM 提供了一些监视工具，例如 jstat 和 jconsole，可以用于监视 JVM 的内存使用情况。通过监视这些指标，您可以识别是否存在内存泄漏的迹象。\n代码注入：在您的应用程序中，您可以注入一些代码，例如使用 JMX、AOP 等，以便您可以实时监视内存使用情况，并记录任何内存泄漏迹象。\n参考文章\n一次完整的 JVM 堆外内存泄漏故障排查记录\n深入探索 Java 8 Lambda 表达式\njava lambda 表达式内存泄露_浅谈 Java 内存泄露\n裁员 去年公司就在裁员，陆陆续续裁了几次，每次都是裁两三个，动作都不大，但是很高效。因为部门人数就在五十左右，所以谁没来上班，都能很快察觉。\n公司要在六月份上市，上市之前要使财报好看，就要开源节流、降本增效。节约成本的一个方式就是裁员，据说这次裁员动作比以前都大都迅速，今天提出裁员人数，明天就要给出名单，月底就要走人。\n现在还只是二月份，离六月还有三个月。谁也不知道，后面还会有什么更大的裁员动作。说不定哪天就空出一个工位，说不定哪天领导就换了人，说不定哪天部门就被拆散了。\n互联网公司最大的变化就是变化。之前在阿里工作，公司的价值观里有一条就是拥抱变化。\n拥抱变化的最好方式就是积极面对，主动加班，提高工作效率，增加工作产出。\n生活 练车 这是买车之后的第二周，还是没有开车去上班。一是因为开车不过熟练，胆子小，不敢开得太快；二是公司楼下的停车位还没有办好。","title":"周报-8｜内存泄漏、公司裁员、练车"},{"content":"前言 本篇是对 2023-02-13 到 2023-02-19 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n练车 这周末开始练车，周六是第一次开自己的车，简单试驾了一样；周日则开了一百多公里，具体行程是从阳逻到新洲，从新洲单汉口，从汉口到光谷，从光谷回汉口。\n这途中走了江北快速公路、二环、二七长江大桥、东湖隧道，从白天开到晚上夜行，经历过堵车，路上看到车祸后的事故现场。\n一天下来，总共开车有五个多小时，感觉开车好累。作为新手，开车的过程中要全神贯注，铭记开车最重要的是慢这一原则，速度不敢过快。\n回顾这一天的练车过程，发现自己存在以下问题：\n对汽车不熟悉，不清楚车内每个按钮有什么作用。\n不敢开的太快，油门踩到六十公里之后，就下意识地松油门。整个行驶过程中，平均车速大概在二十多公里每小时。\n对交规不熟悉，第一次用高德地图，不知道什么时候改该变道、什么时候该走中间道路。要变道时候，不够果敢，打了灯光之后，没有快速变道，甚至还降速，等后面车子，而后面车子也在等我。\n对车距不敏感。行驶过程中，和左右车辆相隔距离多近，没有一个直观的感受。观察后视镜，后面车距多远，有时候也判断不准，导致自己变道犹豫不决，险些擦碰。\n变道、转弯，有时候忘记打灯。转弯时候，方向盘动得太早，没有等车过斑马线再打方向盘。左转弯时候，没有转大弯，导致车子有一次擦到了左边的石墩子，幸好不是很严重。\n倒车和侧方停车不够熟练。\n对上班路线不熟悉，不知道怎么进入公司楼下停车场。\n基于以上表现，接下来一周还是坐地铁上班。目前来说还是更喜欢坐地铁上班，可以看视频听音频，可以查看 RSS 订阅文章，可以写周报，可以闭目养神。\n老婆给我买的实习期贴牌到了，后面司机看到这么可爱的牌子，估计以为是个妹子在开车吧，应该会喇叭下留情了吧 😄。\n接下来的周末，还要继续练车，和车子培养感情，从内到外熟悉车子，熟悉上班路线和交通规则，提高行驶速度。加油 💪🏻！\n博客优化 这周重新对博客进行了优化，主要包括以下几个方面：\n1、优化页面加载速度 每次打开博客首页，感觉页面加载有点慢，故想加快博客打开速度，第一个想到的是减少博客加载资源的次数，也就是去掉一些飞必须的 css 和 javascript 引用；其次，是对 css 进行压缩。\n去掉对 font-awesome css 的引用。这个对博客来说可有可无，所以直接去掉。 去掉对 jquery、bootstrap js 的引用。同样也不是必须的，自定义的 javascript 直接使用原生的操作就行。 移除未使用的 css。想参考这篇文章 CleanCSS - 移除未使用的 CSS 代码，对 css 进行瘦身，无奈文章中的服务器出现故障，无法访问服务。故，暂时搁浅。 2、修改网站字体 参考这篇文章 字体漫谈-网站字体最佳实践 引入 open-sans 字体：\n\u0026lt;link rel=\u0026#34;preload\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/woff2\u0026#34; href=\u0026#34;/css/font/open-sans.css\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;/css/font/open-sans.css\u0026#34; media=\u0026#34;print\u0026#34; onload=\u0026#34;this.media=\u0026#39;all\u0026#39;\u0026#34; /\u0026gt; 并修改网站 font-family 如下：\nbody { font-family: Open Sans, system-ui, -apple-system, Arial, sans-serif; word-break: break-word; } 3、修改关于页面内容 参考这篇文章 GitHub Profile README Generator，对 GitHub 首页 进行改造。\n4、dns 解析迁移到 cloudflare 将 dns 解析从 AWS 迁移到 cloudflare，并开启 CDN 缓存。\n5、博客测速 以上优化完成之后，在 PageSpeed Insights 网站上对博客首页加载速度进行了测速。移动端测试结果为 93 分，如下图：\n影响评分的原因在于：\nFirst Contentful Paint (3G) 加载的 bootstrap.min.css 文件过大，包括了一些未使用的 CSS 桌面端测试结果评分为 99 分：\n另外，试了一下使用 chatgpt 来给出网站优化建议，回答如下：\nn8n 调整 新增了 3 个 workflow：\n定时获取 BTC 价格，并发送到 我的电报群组\n定时获取 spotify 喜欢列表，并发送到电报和 memos\n每天早上 7 点，发送天气预报给微信\n修改了以下 workflow：\n将豆瓣最近动态同步到电报群组以及 memos 将 GitHub 最近动态同步到电报群组以及 memos 将 博客 RSS 同步到电报群组以及 memos 此外，在苹果手机上添加了两个捷径：\n捷径一：调用 memos API 创建 memos 捷径二：对网站通过 RSSBud 获取 RSS 订阅地址并发送到电报的 flowerrss 机器人进行订阅 ChatGPT 注册账号 参考 注册 ChatGPT 详细指南 注册账号，我在 sms-activate 网站是购买的巴西的手机号来接验证码。\n解决地区受限问题：在浏览器地址栏里输入 javascript:，然后粘贴下面代码：\nwindow.localStorage.removeItem( Object.keys(window.localStorage).find((i) =\u0026gt; i.startsWith(\u0026#34;@@auth0spajs\u0026#34;)) ); 如果还是无效，则清理浏览器 cookie 和 session，再刷新页面。\n账号创建成功之后，创建了几个 chat：\n『文案小助手』：在今后的会话里，你都将扮演我的文案纠错润色助理，并综合给出优化后的版本。 『专业后端开发老师』：在今后的对话里，你是一个专业的后端语言开发者老师，会回答我所有关于后端开发相关的问题，尤其是 Java、Pyhon、Go 语言，同时也包括 Shell 脚本、Makefile、Docker、K8S 等运维部署相关的疑问，每次都会给出代码示例，不需要我再额外提醒。 『专业前端开发老师』：在今后的对话里，你是一个专业的前端开发者老师，会回答我所有关于前端语言开发相关的问题，尤其是 TypeScript、React、Vuejs、CSS、Html 和 Nextjs，每次都会给出代码示例，不需要我再额外提醒。 『个人搜索引擎』：在今后的会话里，请你扮演我的专业搜索引擎，为我搜索查阅相关问题的答案和信息，每个问题尽量给出链接和出处，不需要我额外再说明。 点击 链接，可以创建应用。给飞书用户准备的 ChatGPT 机器人，参看 ChatGPT-Feishu。\n💻 好物分享 一些文章 技术类：\n我的个人 IT 基础设施（英文）\n打造我的家庭办公环境（英文）\n科技爱好者周刊（第 191 期）：一个程序员的财务独立之路\n入行 14 年，我还是觉得编程很难\n设计服务端软件配置的 4 条建议\n非技术类：\n除了健康，都是小事\n驾考指南\n一些工具 1、亲戚关系计算器\n2、ImageOptim\n开源图片压缩软件：一款 Mac 小工具，可以方便的进行图片压缩，支持多格式、批量处理。值得注意的是，它压缩之后的图片会覆盖之前的图片。使用了这个工具之后，我就把 TinyPNG4Mac 卸载了。\n3、沉浸式双语网页翻译扩展 – immersive-translate 强烈推荐这个网页翻译插件，和其他插件翻译整个页面相比，这个插件的优势是可以同时显示双语，中英文对照非常棒，是一个 开源 的项目，完全免费使用。也支持 PDF，配合任何 epub 在线阅读网站对照翻译阅读书也非常方便。也支持了 Deepl，腾讯翻译等等的翻译服务。开发者 @OwenYoungZh\n4、Input Source Pro Input Source Pro 可以根据应用或是网站自动切换输入法，并且在切换窗口的时候还会贴心的提示当前的输入法是什么，比如设置 VSCode、iTerm、Xcode 默认为英文输入法，而笔记软件和企业微信默认为中文输入法，切换软件时再也不需要按 shift 键了！\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/02/21/weekly_review_7/","summary":"前言 本篇是对 2023-02-13 到 2023-02-19 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n练车 这周末开始练车，周六是第一次开自己的车，简单试驾了一样；周日则开了一百多公里，具体行程是从阳逻到新洲，从新洲单汉口，从汉口到光谷，从光谷回汉口。\n这途中走了江北快速公路、二环、二七长江大桥、东湖隧道，从白天开到晚上夜行，经历过堵车，路上看到车祸后的事故现场。\n一天下来，总共开车有五个多小时，感觉开车好累。作为新手，开车的过程中要全神贯注，铭记开车最重要的是慢这一原则，速度不敢过快。\n回顾这一天的练车过程，发现自己存在以下问题：\n对汽车不熟悉，不清楚车内每个按钮有什么作用。\n不敢开的太快，油门踩到六十公里之后，就下意识地松油门。整个行驶过程中，平均车速大概在二十多公里每小时。\n对交规不熟悉，第一次用高德地图，不知道什么时候改该变道、什么时候该走中间道路。要变道时候，不够果敢，打了灯光之后，没有快速变道，甚至还降速，等后面车子，而后面车子也在等我。\n对车距不敏感。行驶过程中，和左右车辆相隔距离多近，没有一个直观的感受。观察后视镜，后面车距多远，有时候也判断不准，导致自己变道犹豫不决，险些擦碰。\n变道、转弯，有时候忘记打灯。转弯时候，方向盘动得太早，没有等车过斑马线再打方向盘。左转弯时候，没有转大弯，导致车子有一次擦到了左边的石墩子，幸好不是很严重。\n倒车和侧方停车不够熟练。\n对上班路线不熟悉，不知道怎么进入公司楼下停车场。\n基于以上表现，接下来一周还是坐地铁上班。目前来说还是更喜欢坐地铁上班，可以看视频听音频，可以查看 RSS 订阅文章，可以写周报，可以闭目养神。\n老婆给我买的实习期贴牌到了，后面司机看到这么可爱的牌子，估计以为是个妹子在开车吧，应该会喇叭下留情了吧 😄。\n接下来的周末，还要继续练车，和车子培养感情，从内到外熟悉车子，熟悉上班路线和交通规则，提高行驶速度。加油 💪🏻！\n博客优化 这周重新对博客进行了优化，主要包括以下几个方面：\n1、优化页面加载速度 每次打开博客首页，感觉页面加载有点慢，故想加快博客打开速度，第一个想到的是减少博客加载资源的次数，也就是去掉一些飞必须的 css 和 javascript 引用；其次，是对 css 进行压缩。\n去掉对 font-awesome css 的引用。这个对博客来说可有可无，所以直接去掉。 去掉对 jquery、bootstrap js 的引用。同样也不是必须的，自定义的 javascript 直接使用原生的操作就行。 移除未使用的 css。想参考这篇文章 CleanCSS - 移除未使用的 CSS 代码，对 css 进行瘦身，无奈文章中的服务器出现故障，无法访问服务。故，暂时搁浅。 2、修改网站字体 参考这篇文章 字体漫谈-网站字体最佳实践 引入 open-sans 字体：\n\u0026lt;link rel=\u0026#34;preload\u0026#34; as=\u0026#34;font\u0026#34; type=\u0026#34;font/woff2\u0026#34; href=\u0026#34;/css/font/open-sans.css\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;/css/font/open-sans.css\u0026#34; media=\u0026#34;print\u0026#34; onload=\u0026#34;this.media=\u0026#39;all\u0026#39;\u0026#34; /\u0026gt; 并修改网站 font-family 如下：\nbody { font-family: Open Sans, system-ui, -apple-system, Arial, sans-serif; word-break: break-word; } 3、修改关于页面内容 参考这篇文章 GitHub Profile README Generator，对 GitHub 首页 进行改造。\n4、dns 解析迁移到 cloudflare 将 dns 解析从 AWS 迁移到 cloudflare，并开启 CDN 缓存。","title":"周报-7｜练车、博客优化、注册ChatGPT账号"},{"content":"前言 本篇是对 2023-02-06 到 2023-02-12 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这篇周报又是在坐地铁的时候完成编写的，一边坐地铁，一边回顾上一周发生的事情，一边复盘和总结。坐地铁大概有一个半小时，从家到公司的一段通勤路程。现在还没有买车，所以都是坐地铁上下班。\n说到车，周六去二手市场买了一辆 17 年出产的上汽宝来，今天周一去过了户并且选了一个幸运的车牌号，尾号是 8688，寓意着要发发发！\n上个月报名的内观训练营，这周也结业了，训练营运营人员还给我发了一个结业证书。\n这是写周报的第六周，观察了一下博客访问量，从开始统计起到这周不到一个月的时间，访问量突破了 1000。\n工作 这周的工作主要内容是在项目里实现用户可以切换租户和租户数据拆分。\n第一个功能的需求是一个账号（有姓名、手机号、密码等属性）可以访问多个租户，在每个租户里有自己的数据权限和角色。第二个功能，主要是使用 SQL 进行数据加工。\n总体上来说，这周工作处于充实忙碌的情况。而且，上下班的通勤时间，也在 B 站上看视频。这周主要看的是小马哥的 Java 训练营的公开视频。小马哥的 B 站视频，是我最近刷的比较多的一个视频，另外一个是 coder1v5 的视频，他们分享的视频都是关于 Java 的，里面有非常多的干货，而且还提供了源代码。如果你也是一名 Java 开发工程师，推荐你也关注他们。\n生活 买车和选号 去年 11 月 16 日，拿到了驾照，直到现在才买了一辆车。过年前，因为疫情加上工作忙，一直没有抽出时间去了解车子行情。可能是对于车子的需求感没有那么强的原因，才导致考驾照、买车不积极。结婚之前，住在公司旁边，走路五分钟上下班，根本就用不上车。结婚之后，从光谷搬到汉口，每天上下班在路上通勤时间都有三个小时了。每天早上七点就要起来做饭（带饭到公司，中午微波炉热着吃，每天可以省下一餐伙食费），然后去赶地铁。疫情放开之前，地铁上人不多，每次都有位置坐。疫情放开之后，地铁里都是人，不是每次都有位置坐，经常要站着。站着的时候，有时候就内观冥想，想想最近有没有做得不对的地方，想想工作下一步该怎么计划；有时候就看 B 站关于 Java 的视频。也算是充分利用了这段通勤时间。\n为了上下班通勤更方便，才计划买车的，也不知道开车能够缩短多少通勤时间，也希望这节约下来的时间，可以用在读书和健身上。另外一方面，买车了之后，回家看望父母会更方便。这就是买车的原因。\n考虑到刚拿驾照、以后还要买房，这次就只买了一个二手车。原计划只买个三万左右的车，最后还是超出了预算。\n去二手市场买车的时候，是在周六，周末过不了户，所以这周一又过来办理过户和选车牌号。过户的过程还是很快的，全部交给二手市场的人代办。至于，选车牌号，之前了解了一下，车牌号尽量选尾号都是数字的，这样好记；不要带数字 4，不吉利；选号有时间限制，超过了时间未选，会默认选第一个。点击 “选号开始” 按钮之前，心里还有点紧张。当看到第一屏的号码时候，很快地扫描了一遍，发现了一个尾号为 8688 的号码。于是，就跟一同过来买车的姐夫说，这个号码怎么样。姐夫激动地说这个号码好，就选这个。真的没有想到今天运气这么好，选到了这么好的一个号码。激动得想跟朋友圈里的好友分享。之前买车的时候，付完预付款，就有分享买车的喜悦的冲动。这时候，老婆在旁边跟我说，要低调，不要和身边的亲戚说。所以，就一直没有告诉亲人和身边的朋友。没想到，这次选了一个幸运的车牌号，还是没忍住发了一个部分好友不可见的朋友圈。\n这说明自己定力还是不够，分享欲太强，不够谦虚和低调。满招损，谦受益。只是买了一个车和选到一个幸运的车牌号而已，不能高兴太早，后面还要花时间练车上路、开车还要慢和稳，不能出交通事故，铭记 “新手上路，多多指教”。\n学英语，最重要的是练习。开车，最重要的是慢。\n学习 内观冥想 一月份报名内观冥想训练营的初衷是想学习内观冥想的方法，后来因为每天早上要赶地铁以及觉得课程内容和自己期望的有些差距，就没有坚持听课和打卡。\n虽然，没有听完所有课程，但是从开始几节课程，初步体会和感受了一下什么是内观冥想，也认识了一些内观冥想的朋友。也没有想到，最后还收到了一个结业证书。\nPython 最近有个机器学习的项目，用到了 Python，所以需要学习 Python 并掌握相关的业务知识。这一个机会，同时也是一个挑战。\n娱乐 -《粉色理论》。这部泰国双女主的同性电视剧，豆瓣上评分 9.2，在这周完结了。\n分享 HashedWheelTimer：是来自于 Netty 的工具类，在 netty-common 包中。它用于实现延时任务。\nKillbill common queue：一个基于 DB 实现的分布式的队列，它上层还包装了 EventBus 事件总线机制。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/02/13/weekly_review_6/","summary":"前言 本篇是对 2023-02-06 到 2023-02-12 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这篇周报又是在坐地铁的时候完成编写的，一边坐地铁，一边回顾上一周发生的事情，一边复盘和总结。坐地铁大概有一个半小时，从家到公司的一段通勤路程。现在还没有买车，所以都是坐地铁上下班。\n说到车，周六去二手市场买了一辆 17 年出产的上汽宝来，今天周一去过了户并且选了一个幸运的车牌号，尾号是 8688，寓意着要发发发！\n上个月报名的内观训练营，这周也结业了，训练营运营人员还给我发了一个结业证书。\n这是写周报的第六周，观察了一下博客访问量，从开始统计起到这周不到一个月的时间，访问量突破了 1000。\n工作 这周的工作主要内容是在项目里实现用户可以切换租户和租户数据拆分。\n第一个功能的需求是一个账号（有姓名、手机号、密码等属性）可以访问多个租户，在每个租户里有自己的数据权限和角色。第二个功能，主要是使用 SQL 进行数据加工。\n总体上来说，这周工作处于充实忙碌的情况。而且，上下班的通勤时间，也在 B 站上看视频。这周主要看的是小马哥的 Java 训练营的公开视频。小马哥的 B 站视频，是我最近刷的比较多的一个视频，另外一个是 coder1v5 的视频，他们分享的视频都是关于 Java 的，里面有非常多的干货，而且还提供了源代码。如果你也是一名 Java 开发工程师，推荐你也关注他们。\n生活 买车和选号 去年 11 月 16 日，拿到了驾照，直到现在才买了一辆车。过年前，因为疫情加上工作忙，一直没有抽出时间去了解车子行情。可能是对于车子的需求感没有那么强的原因，才导致考驾照、买车不积极。结婚之前，住在公司旁边，走路五分钟上下班，根本就用不上车。结婚之后，从光谷搬到汉口，每天上下班在路上通勤时间都有三个小时了。每天早上七点就要起来做饭（带饭到公司，中午微波炉热着吃，每天可以省下一餐伙食费），然后去赶地铁。疫情放开之前，地铁上人不多，每次都有位置坐。疫情放开之后，地铁里都是人，不是每次都有位置坐，经常要站着。站着的时候，有时候就内观冥想，想想最近有没有做得不对的地方，想想工作下一步该怎么计划；有时候就看 B 站关于 Java 的视频。也算是充分利用了这段通勤时间。\n为了上下班通勤更方便，才计划买车的，也不知道开车能够缩短多少通勤时间，也希望这节约下来的时间，可以用在读书和健身上。另外一方面，买车了之后，回家看望父母会更方便。这就是买车的原因。\n考虑到刚拿驾照、以后还要买房，这次就只买了一个二手车。原计划只买个三万左右的车，最后还是超出了预算。\n去二手市场买车的时候，是在周六，周末过不了户，所以这周一又过来办理过户和选车牌号。过户的过程还是很快的，全部交给二手市场的人代办。至于，选车牌号，之前了解了一下，车牌号尽量选尾号都是数字的，这样好记；不要带数字 4，不吉利；选号有时间限制，超过了时间未选，会默认选第一个。点击 “选号开始” 按钮之前，心里还有点紧张。当看到第一屏的号码时候，很快地扫描了一遍，发现了一个尾号为 8688 的号码。于是，就跟一同过来买车的姐夫说，这个号码怎么样。姐夫激动地说这个号码好，就选这个。真的没有想到今天运气这么好，选到了这么好的一个号码。激动得想跟朋友圈里的好友分享。之前买车的时候，付完预付款，就有分享买车的喜悦的冲动。这时候，老婆在旁边跟我说，要低调，不要和身边的亲戚说。所以，就一直没有告诉亲人和身边的朋友。没想到，这次选了一个幸运的车牌号，还是没忍住发了一个部分好友不可见的朋友圈。\n这说明自己定力还是不够，分享欲太强，不够谦虚和低调。满招损，谦受益。只是买了一个车和选到一个幸运的车牌号而已，不能高兴太早，后面还要花时间练车上路、开车还要慢和稳，不能出交通事故，铭记 “新手上路，多多指教”。\n学英语，最重要的是练习。开车，最重要的是慢。\n学习 内观冥想 一月份报名内观冥想训练营的初衷是想学习内观冥想的方法，后来因为每天早上要赶地铁以及觉得课程内容和自己期望的有些差距，就没有坚持听课和打卡。\n虽然，没有听完所有课程，但是从开始几节课程，初步体会和感受了一下什么是内观冥想，也认识了一些内观冥想的朋友。也没有想到，最后还收到了一个结业证书。\nPython 最近有个机器学习的项目，用到了 Python，所以需要学习 Python 并掌握相关的业务知识。这一个机会，同时也是一个挑战。\n娱乐 -《粉色理论》。这部泰国双女主的同性电视剧，豆瓣上评分 9.2，在这周完结了。\n分享 HashedWheelTimer：是来自于 Netty 的工具类，在 netty-common 包中。它用于实现延时任务。\nKillbill common queue：一个基于 DB 实现的分布式的队列，它上层还包装了 EventBus 事件总线机制。\n以上。","title":"周报-6｜买车和选号、粉色理论"},{"content":"前言 本篇是对 2023-01-30 到 2023-02-05 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周是过年后的第一个工作周，被国家安排了连上七天班，算是体会了一次 “过年七天乐，上班七天累” 的过山车。七天的工作主要是测试并发布项目，每天忙的焦头乱额，生怕项目出了问题。有句话说，怕什么来什么。没想到周六还是报出了一个故障，还在睡觉中的我被一个电话吵醒，接着忙着找问题和解决方法，一天的时间就都花在这上面。万幸的是事故影响不大，发布了一个小版本进行修复。事故原因，还是值得警惕。\n工作总结 项目事故 这周主要是自定义拦截器和 ErrorCoder 来记录 feign 请求的调用次数，包括调用成功的和失败的。另外，如果调用失败，设置了重试两次。这里重试的前提是 http 请求出现 4xx 或者 5xx 状态码错误，如果是状态码为 200 但返回了自定义业务异常，是不会触发重试机制的。这一点没有注意到，而发布前，我想当然的把一个接口的手动重试代码删掉了，导致调用该接口出现业务异常之后没有进行重试，影响了业务方的使用。\n出现该问题的原因，一是没想出重试的前提条件，没有写代码注释；二是没有写单元测试；三是没有交叉代码审核。此外，还有一点，越是项目发布关键时期，越要注意休息，保持大脑足够清晰和敏捷。\nAOP 日志记录 参考 【每天进步一点点（二）-哔哩哔哩】 在项目里添加代码对 controller 方法请求参数、返回结果、执行时间的记录。视频中讲的很清楚，这里就不贴代码了。\n该方法，可以对 controller 的所有方法（不管是 get 还是 post 或其他方法），都记录日志。如果想排除 get 方法（一个项目里查询比修改请求大很多），需要添加代码进行过滤。\n另外，打印请求参数时，实际是记录的请求参数的 toString 方法，如果请求参数里有些对象没有定义 toString 方法，则记录的是对象的引用地址。再者，如果对象里有些敏感字段不想输出到日志里，则需要重写 toString 方法。一个可选的方法是，改为打印请求参数的 json 序列化值，这样做又会带来序列化开销。\n如果 controller 层代码被代理了多次，则请求参数和返回结果会打印多次。\n生活 牙疼 一个月黑风高的晚上，加班回来的程序员偷偷喝了三杯牛奶，结果第二天牙齿开始疼了，特别是吃到冷热酸甜的东西，都会短暂的巨疼。去牙科诊所看了，医生说要做根管治疗，费用 800，可以报销 420，做完以后，牙套价格另算，有一千到几千的价格不等。刚不久还刷到视频说，有两个省要规范治疗牙齿费用。\n忍着疼痛上了一周班，结果不仅牙痛，吃饭没胃口，还影响了上班，真是得不偿失。\n周六晚上，在牙齿疼痛的地方，插了一点老爸给我的药水。睡觉时，先是畏冷，再就是牙疼的地方发炎，肚子发烧，烧到了不知道多少度，反正我是没有拿温度计去测量。烧的我大脑都是糊的，一晚上没睡好，中途还醒了几次。好在第二天，就好了一些，吃东西也没那么疼了。看来，专家顺发烧是体内细菌在和病毒做斗争，应该是对的啰。\n经历了这一晚上，感觉像是体验了一次阳的过程。之前新冠阳了，我是轻症状，没有发烧。这次牙疼发烧，算是把之前新冠没有吃过的苦找补回来，人生也算是多了一种体验。\n娱乐 -《狂飙》。最近很火，也刚好完结了。我没有去看，没有时间去追，就看了前面几集。\n-《粉红理论》。老婆在追的一部泰剧，她是在微博看些别人剪辑的几分钟的片段。叫我也去微博看看，我说我不用微博，我翻墙去找网站观看。老婆眼睛一亮，说那不是可以看到无删减版本，那个兴奋劲哟！很快，我找到了网站，发现已经上线了 11 集，而且每集都有 60 多分钟长（老婆看的都是阉割版～ 😯）。\n学习 最近 Damus 很火，我也去注册了一个账号，为此还重新下载了狐狸 🦊 钱包。随即，干脆也注册了 Mastodon 账号和 Crossbell 账号。\n我的 Damus 账号 npub1dav96pmjv58n60eqz7ctmhvsd7t2yljvzevf6uckmchz6zamx2wq0k7dm5\n我的 Mastodon 账号 @chensoul@mas.to\n我的 crossbell 账号 chensoul@crossbell\n好物分享 Mac 删除原生英文 ABC 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/02/07/weekly_review_5/","summary":"前言 本篇是对 2023-01-30 到 2023-02-05 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这周是过年后的第一个工作周，被国家安排了连上七天班，算是体会了一次 “过年七天乐，上班七天累” 的过山车。七天的工作主要是测试并发布项目，每天忙的焦头乱额，生怕项目出了问题。有句话说，怕什么来什么。没想到周六还是报出了一个故障，还在睡觉中的我被一个电话吵醒，接着忙着找问题和解决方法，一天的时间就都花在这上面。万幸的是事故影响不大，发布了一个小版本进行修复。事故原因，还是值得警惕。\n工作总结 项目事故 这周主要是自定义拦截器和 ErrorCoder 来记录 feign 请求的调用次数，包括调用成功的和失败的。另外，如果调用失败，设置了重试两次。这里重试的前提是 http 请求出现 4xx 或者 5xx 状态码错误，如果是状态码为 200 但返回了自定义业务异常，是不会触发重试机制的。这一点没有注意到，而发布前，我想当然的把一个接口的手动重试代码删掉了，导致调用该接口出现业务异常之后没有进行重试，影响了业务方的使用。\n出现该问题的原因，一是没想出重试的前提条件，没有写代码注释；二是没有写单元测试；三是没有交叉代码审核。此外，还有一点，越是项目发布关键时期，越要注意休息，保持大脑足够清晰和敏捷。\nAOP 日志记录 参考 【每天进步一点点（二）-哔哩哔哩】 在项目里添加代码对 controller 方法请求参数、返回结果、执行时间的记录。视频中讲的很清楚，这里就不贴代码了。\n该方法，可以对 controller 的所有方法（不管是 get 还是 post 或其他方法），都记录日志。如果想排除 get 方法（一个项目里查询比修改请求大很多），需要添加代码进行过滤。\n另外，打印请求参数时，实际是记录的请求参数的 toString 方法，如果请求参数里有些对象没有定义 toString 方法，则记录的是对象的引用地址。再者，如果对象里有些敏感字段不想输出到日志里，则需要重写 toString 方法。一个可选的方法是，改为打印请求参数的 json 序列化值，这样做又会带来序列化开销。\n如果 controller 层代码被代理了多次，则请求参数和返回结果会打印多次。\n生活 牙疼 一个月黑风高的晚上，加班回来的程序员偷偷喝了三杯牛奶，结果第二天牙齿开始疼了，特别是吃到冷热酸甜的东西，都会短暂的巨疼。去牙科诊所看了，医生说要做根管治疗，费用 800，可以报销 420，做完以后，牙套价格另算，有一千到几千的价格不等。刚不久还刷到视频说，有两个省要规范治疗牙齿费用。\n忍着疼痛上了一周班，结果不仅牙痛，吃饭没胃口，还影响了上班，真是得不偿失。\n周六晚上，在牙齿疼痛的地方，插了一点老爸给我的药水。睡觉时，先是畏冷，再就是牙疼的地方发炎，肚子发烧，烧到了不知道多少度，反正我是没有拿温度计去测量。烧的我大脑都是糊的，一晚上没睡好，中途还醒了几次。好在第二天，就好了一些，吃东西也没那么疼了。看来，专家顺发烧是体内细菌在和病毒做斗争，应该是对的啰。\n经历了这一晚上，感觉像是体验了一次阳的过程。之前新冠阳了，我是轻症状，没有发烧。这次牙疼发烧，算是把之前新冠没有吃过的苦找补回来，人生也算是多了一种体验。\n娱乐 -《狂飙》。最近很火，也刚好完结了。我没有去看，没有时间去追，就看了前面几集。\n-《粉红理论》。老婆在追的一部泰剧，她是在微博看些别人剪辑的几分钟的片段。叫我也去微博看看，我说我不用微博，我翻墙去找网站观看。老婆眼睛一亮，说那不是可以看到无删减版本，那个兴奋劲哟！很快，我找到了网站，发现已经上线了 11 集，而且每集都有 60 多分钟长（老婆看的都是阉割版～ 😯）。\n学习 最近 Damus 很火，我也去注册了一个账号，为此还重新下载了狐狸 🦊 钱包。随即，干脆也注册了 Mastodon 账号和 Crossbell 账号。\n我的 Damus 账号 npub1dav96pmjv58n60eqz7ctmhvsd7t2yljvzevf6uckmchz6zamx2wq0k7dm5\n我的 Mastodon 账号 @chensoul@mas.to\n我的 crossbell 账号 chensoul@crossbell\n好物分享 Mac 删除原生英文 ABC 以上。","title":"周报-5｜项目事故、牙疼、Damus"},{"content":"前言 本篇是对 2023-01-23 到 2023-01-29 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n过年 这周处于过年吃喝拜年模式，除了腊月二十九和正月初一，其他时间都是和老婆在路上。因为是结婚第一个新年，需要带着老婆去各个亲戚家拜年。因为是第一次在新房过年，就把老爸从农村接过来一起过年。因为年前没有来得及买车，去哪里都不方便，都要需要滴滴打车。为此，打车花了不少钱，当然，给红包也给了不少钱。趁初一不用拜年的缝隙时间，带老婆和老爸去看了两场电影《无名》和《交换人生》。老爸很少去看电影院看电影，听到要去看电影，像个小孩似的，饭还吃完，就跑去电梯门口等电梯。这两场电影，看的我瞌睡来了，倒是初二晚上看《满江红》睡意全无。\n总结下来，这个年过的不轻松，身体忙碌，心里幸福 🥰。\n向上管理 年前，部门领导找我谈 2022 年绩效结果时候，提到我可以 “向上管理” 他。最近从 杜屹东 的博客 这一年我在阿里学到的 也看到了他在阿里工作一年后悟到对向上管理的理解。\n及时和老板表达想法 让老板知道你在忙什么 主动帮老板做一些脏活累活 前两条是老板知道你的想法，后面一条是帮老板解决问题。此外，还可以帮老板规避风险。\n本周工作 这是年后的第一周，主要是处理年前没有完成的项目迭代。\nFeign 集成 Micometer OpenFeign 官方提供了 feign-micrometer 来支持 feign 集成 micrometer。\nGitHub github = Feign.builder() .addCapability(new MicrometerCapability()) .target(GitHub.class, \u0026#34;https://api.github.com\u0026#34;); 其本质是对 feign 拦截器、client、encoder、decoder 进行封装，测试过程中在没有获取到指标。故，改为使用 z 自定义拦截器和 ErrorCoder 来记录请求次数和失败次数。\n@Bean public GitHub gihhub(MetricsInterceptor metricsInterceptor){ GitHub github = Feign.builder() .requestInterceptor(metricsInterceptor) .errorDecoder(new MetricsErrorDecoder()) .target(GitHub.class, \u0026#34;https://api.github.com\u0026#34;); } MetricsInterceptor 代码如下：\npublic class MetricsInterceptor implements RequestInterceptor, MeterBinder { private static MeterRegistry meterRegistry; public static final String FEIGN_REQUEST = \u0026#34;feign.requests\u0026#34;; public static final String FEIGN_REQUEST_ERROR = \u0026#34;feign.requests.error\u0026#34;; public MetricsInterceptor() { } public void apply(RequestTemplate template) { Micrometers.async(() -\u0026gt; { String methodKey = template.methodMetadata().configKey(); Counter counter = Counter.builder(\u0026#34;feign.requests\u0026#34;).tags(new String[]{\u0026#34;method\u0026#34;, StringUtils.substringBefore(methodKey, \u0026#34;(\u0026#34;)}).register(meterRegistry); counter.increment(); }); } public void bindTo(MeterRegistry registry) { meterRegistry = registry; } } MetricsErrorDecoder 代码如下：\npublic class MetricsErrorDecoder implements ErrorDecoder { private static final Logger log = LoggerFactory.getLogger(MetricsErrorDecoder.class); private static MeterRegistry registry = new SimpleMeterRegistry(); public MetricsErrorDecoder() { } protected void metrics(String methodKey) { Micrometers.async(() -\u0026gt; { Metrics.counter(\u0026#34;feign.requests.error\u0026#34;, new String[]{\u0026#34;method\u0026#34;, StringUtils.substringBefore(methodKey, \u0026#34;(\u0026#34;)}).increment(); }); } public Exception decode(String methodKey, Response response) { this.metrics(methodKey); FeignException exception = FeignException.errorStatus(methodKey, response); return exception; } static { Counter.builder(\u0026#34;feign.requests.error\u0026#34;).register(registry); } } Sentry 集成飞书通知 参考 通过 Webhook 实现 Sentry 错误自动化飞书机器人报警 这篇文章，使用 fastapi 部署一个 http 服务将 sentry 的回调转发到飞书群的机器人。由于，fastapi 需要在服务器上安装 python3，为了不污染我的 vps，我创建一个 docker 镜像 sentry-feishu-hook，修改了 python 脚本中的编译错误，并在 vps 上通过 docker 启动该服务。\n先编译镜像，再运行：\ndocker build -t sentry-feishu-hook . docker run -d --name sentry-feishu-hook -p 3080:3080 sentry-feishu-hook 接下来在 sentry 项目的 WebHooks 里添加 http://ip:3080/hook\n点击 Test Plugin，飞书群组可以收到消息：\n好物分享 https://www.warp.dev/：一个 Rust 编写，使用 GPU 渲染的终端应用。目标是提升开发者的效率。 Restful API Mock 工具：JSONPlaceholder NetNewsWire。Inoreader 最近总是抽风，就改为使用 NetNewsWire 了。使用起来，还是比较顺滑，遗憾的是没有安卓 App。 Cubox。最近看到这个收藏工具，下载了使用起来。 以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/01/30/weekly_review_4/","summary":"前言 本篇是对 2023-01-23 到 2023-01-29 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n过年 这周处于过年吃喝拜年模式，除了腊月二十九和正月初一，其他时间都是和老婆在路上。因为是结婚第一个新年，需要带着老婆去各个亲戚家拜年。因为是第一次在新房过年，就把老爸从农村接过来一起过年。因为年前没有来得及买车，去哪里都不方便，都要需要滴滴打车。为此，打车花了不少钱，当然，给红包也给了不少钱。趁初一不用拜年的缝隙时间，带老婆和老爸去看了两场电影《无名》和《交换人生》。老爸很少去看电影院看电影，听到要去看电影，像个小孩似的，饭还吃完，就跑去电梯门口等电梯。这两场电影，看的我瞌睡来了，倒是初二晚上看《满江红》睡意全无。\n总结下来，这个年过的不轻松，身体忙碌，心里幸福 🥰。\n向上管理 年前，部门领导找我谈 2022 年绩效结果时候，提到我可以 “向上管理” 他。最近从 杜屹东 的博客 这一年我在阿里学到的 也看到了他在阿里工作一年后悟到对向上管理的理解。\n及时和老板表达想法 让老板知道你在忙什么 主动帮老板做一些脏活累活 前两条是老板知道你的想法，后面一条是帮老板解决问题。此外，还可以帮老板规避风险。\n本周工作 这是年后的第一周，主要是处理年前没有完成的项目迭代。\nFeign 集成 Micometer OpenFeign 官方提供了 feign-micrometer 来支持 feign 集成 micrometer。\nGitHub github = Feign.builder() .addCapability(new MicrometerCapability()) .target(GitHub.class, \u0026#34;https://api.github.com\u0026#34;); 其本质是对 feign 拦截器、client、encoder、decoder 进行封装，测试过程中在没有获取到指标。故，改为使用 z 自定义拦截器和 ErrorCoder 来记录请求次数和失败次数。\n@Bean public GitHub gihhub(MetricsInterceptor metricsInterceptor){ GitHub github = Feign.builder() .requestInterceptor(metricsInterceptor) .errorDecoder(new MetricsErrorDecoder()) .target(GitHub.class, \u0026#34;https://api.github.com\u0026#34;); } MetricsInterceptor 代码如下：\npublic class MetricsInterceptor implements RequestInterceptor, MeterBinder { private static MeterRegistry meterRegistry; public static final String FEIGN_REQUEST = \u0026#34;feign.requests\u0026#34;; public static final String FEIGN_REQUEST_ERROR = \u0026#34;feign.requests.error\u0026#34;; public MetricsInterceptor() { } public void apply(RequestTemplate template) { Micrometers.","title":"周报-4｜过年、向上管理、工作周总结"},{"content":"我的 VPS 使用的是 centos 服务器，所以以下操作都是基于 centos 系统。\n服务器设置 更新 yum 源：\nyum update 安装常用软件：\nyum install wget curl git vim -y 设置时区为\n[可选] 设置系统 Swap 交换分区\n因为 vps 服务器的运行内存很小，所以这里先设置下 Swap\n# 1GB RAM with 2GB Swap sudo fallocate -l 2G /swapfile \u0026amp;\u0026amp; \\ sudo dd if=/dev/zero of=/swapfile bs=1024 count=2097152 \u0026amp;\u0026amp; \\ sudo chmod 600 /swapfile \u0026amp;\u0026amp; \\ sudo mkswap /swapfile \u0026amp;\u0026amp; \\ sudo swapon /swapfile \u0026amp;\u0026amp; \\ echo \u0026#34;/swapfile swap swap defaults 0 0\u0026#34; | sudo tee -a /etc/fstab \u0026amp;\u0026amp; \\ sudo swapon --show \u0026amp;\u0026amp; \\ sudo free -h 安装 Nginx 参考 CentOS 7 下 yum 安装和配置 Nginx ，使用 yum 安装：\nrpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm yum install nginx -y systemctl enable nginx 打开防火墙端口\nyum install firewalld -y firewall-cmd --zone=public --permanent --add-service=http firewall-cmd --reload 使用反向代理需要打开网络访问权限\nsetsebool -P httpd_can_network_connect on 安装并生成证书 域名托管在 CloudFlare，可以参考 文章\ncurl https://get.acme.sh | sh -s email=ichensoul@gmail.com export CF_Key=\u0026#34;XXXXXXXXXXXXXXXXXX\u0026#34; export CF_Email=\u0026#34;ichensoul@gmail.com\u0026#34; .acme.sh/acme.sh --issue --server letsencrypt --dns dns_cf -d chensoul.cc -d \u0026#39;*.chensoul.cc\u0026#39; cp .acme.sh/chensoul.cc_ecc/{chensoul.cc.cer,chensoul.cc.key,fullchain.cer,ca.cer} /etc/nginx/ssl/ .acme.sh/acme.sh --installcert -d chensoul.cc -d *.chensoul.cc --cert-file /etc/nginx/ssl/chensoul.cc.cer --key-file /etc/nginx/ssl/chensoul.cc.key --fullchain-file /etc/nginx/ssl/fullchain.cer --ca-file /etc/nginx/ssl/ca.cer --reloadcmd \u0026#34;sudo nginx -s reload\u0026#34; Docker 安装和配置 Docker 安装\ncurl -fsSL https://get.docker.com -o get-docker.sh sh get-docker.sh 启动 docker：\nsystemctl enable docker systemctl start docker 设置 iptables 允许流量转发：\niptables -P FORWARD ACCEPT 安装 Compose\ncurl -L \u0026#34;https://github.com/docker/compose/releases/download/v2.23.3/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 设置执行权限：\nchmod +x /usr/local/bin/docker-compose 参考 Best Practice: Use a Docker network ，创建一个自定义的网络：\ndocker network create custom 查看 docker 网络：\ndocker network ls NETWORK ID NAME DRIVER SCOPE 68f4aeaa57bd bridge bridge local 6a96b9d8617e custom bridge local 4a8679e35f4d host host local ba21bef23b04 none null local 注意：bridge、host、none 是内部预先创建的网络。\n然后，在其他服务的 docker-compose.yml 文件添加：\nnetworks: - custom networks: custom: external: true 服务部署 MySQL 1、使用 docker-compose 安装\nmysql.yaml\nversion: \u0026#34;3\u0026#34; services: mysql: image: mysql:8 container_name: mysql platform: linux/amd64 restart: unless-stopped volumes: - /data/volumes/mysql/:/var/lib/mysql/ environment: - MYSQL_ROOT_HOST=% - MYSQL_ROOT_PASSWORD=admin@mysql! - TZ=Asia/Shanghai ports: - \u0026#34;3306:3306\u0026#34; command: --lower_case_table_names=1 --skip-ssl --character_set_server=utf8mb4 --explicit_defaults_for_timestamp healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;mysql\u0026#34;, \u0026#34;-e\u0026#34;, \u0026#34;SHOW DATABASES;\u0026#34;] interval: 5s timeout: 5s retries: 10 networks: - custom networks: custom: external: true 注意：修改 Docker-MySQL 容器的 默认用户加密规则\n2、启动\ndocker-compose -f mysql.yaml up -d 3、进入容器：\ndocker exec -it mysql bash Rsshub 直接通过 Docker 安装运行：\ndocker run -d --name rsshub -p 1200:1200 diygod/rsshub 配置 nginx ：\nserver { listen 80; listen [::]:80; server_name rsshub.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name rsshub.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:1200; } } Uptime Kuma 参考 kuma，使用 docker compose 部署，创建 uptime.yaml：\nversion: \u0026#34;3.3\u0026#34; services: uptime-kuma: image: louislam/uptime-kuma:1 container_name: uptime-kuma volumes: - ~/.uptime-kuma:/app/data ports: - 3001:3001 # \u0026lt;Host Port\u0026gt;:\u0026lt;Container Port\u0026gt; restart: always 启动：\ndocker-compose -f uptime.yaml up -d 配置 nginx 配置文件 /etc/nginx/conf.d/uptime.conf ：\nserver { listen 80; listen [::]:80; server_name uptime.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name uptime.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:3001; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $host; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; } } 升级\ndocker compose -f uptime.yaml down docker pull louislam/uptime-kuma:1 docker-compose -f uptime.yaml up -d Umami 1、在 mysql 容器创建 umami 数据库和用户：\ndocker exec -it mysql bash mysql -uroot -padmin@mysql! CREATE USER \u0026#39;umami\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;umami@mysql!\u0026#39;; CREATE DATABASE umami; GRANT ALL ON umami.* TO \u0026#39;umami\u0026#39;@\u0026#39;%\u0026#39;; ALTER USER \u0026#39;umami\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;umami@mysql!\u0026#39;; 参考：HCL SafeLinx Server with MySQL 8.0 causes \u0026ldquo;Authentication plugin \u0026lsquo;caching_sha2_password\u0026rsquo; reported error: Authentication requires secure connection.\u0026rdquo;\n2、通过 docker-compose 安装，创建 umami.yaml：\nversion: \u0026#34;3\u0026#34; services: umami: image: ghcr.io/umami-software/umami:mysql-latest container_name: umami ports: - \u0026#34;3000:3000\u0026#34; environment: DATABASE_URL: mysql://umami:umami@mysql!@mysql:3306/umami DATABASE_TYPE: mysql HASH_SALT: vps@2023 TRACKER_SCRIPT_NAME: random-string.js networks: - custom restart: always networks: custom: external: true 参考 https://eallion.com/umami/，Umami 的默认跟踪代码是被大多数的广告插件屏蔽的，被屏蔽了你就统计不到访客信息了。如果需要反屏蔽，需要在 docker-compose.yml 文件中添加环境变量：TRACKER_SCRIPT_NAME，如：\nenvironment: TRACKER_SCRIPT_NAME: random-string.js 然后获取到的跟踪代码的 src 会变成：\nsrcipt.js =\u0026gt; random-string.js 启动：\ndocker-compose -f umami.yaml up -d 3、设置自定义域名\numami.chensoul.cc\n4、配置 nginx 配置文件 /etc/nginx/conf.d/umami.conf\nserver { listen 80; listen [::]:80; server_name umami.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name umami.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:3000; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header REMOTE-HOST $remote_addr; add_header X-Cache $upstream_cache_status; # 缓存 add_header Cache-Control no-cache; expires 12h; } } 5、添加网站\n访问 https://umami.chensoul.cc/，默认用户名和密码为 admin/umami。登陆之后，修改密码，并添加网站。\n6、升级\ndocker compose -f umami.yaml down docker pull ghcr.io/umami-software/umami:mysql-latest docker-compose -f umami.yaml up -d Cusdis VPS IP 可能被墙，所以可以使用三方云服务部署，具体参考轻量级开源免费博客评论系统解决方案 （Cusdis + Railway）\n1、在 mysql 容器创建 cusdis 数据库和用户：\ndocker exec -it mysql bash mysql -uroot -p CREATE USER \u0026#39;cusdis\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;cusdis@mysql!\u0026#39;; CREATE DATABASE cusdis; GRANT ALL ON cusdis.* TO \u0026#39;cusdis\u0026#39;@\u0026#39;%\u0026#39;; ALTER USER \u0026#39;cusdis\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;cusdis@mysql!\u0026#39;; 2、通过 docker-compose 安装，创建 cusdis.yaml：\nversion: \u0026#34;3\u0026#34; services: cusdis: image: djyde/cusdis:latest container_name: cusdis ports: - \u0026#34;3010:3000\u0026#34; environment: - USERNAME=admin - PASSWORD=cusdis - JWT_SECRET=vps@2023 - NEXTAUTH_URL=https://cusdis.chensoul.cc - HOST=https://cusdis.chensoul.cc - DB_TYPE=mysql - DB_URL=mysql://cusdis:cusdis@mysql!@mysql:3306/cusdis networks: - custom restart: always networks: custom: external: true 以下配置为 EMAIL 配置可选，下面是使用 Gmail 进行配置，需要首先开启两阶段验证并创建一个应用密码：\nSMTP_HOST=smtp.gmail.com SMTP_PORT=465 SMTP_SECURE=true SMTP_USER=your gmail email SMTP_PASSWORD=\u0026lt;app password\u0026gt; SMTP_SENDER=your gmail email 3、启动\ndocker-compose -f cusdis.yaml up -d 4、配置 nginx\nserver { listen 80; listen [::]:80; server_name cusdis.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name cusdis.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:3010; proxy_pass_header Authorization; proxy_pass_header WWW-Authenticate; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; if ($uri = \u0026#39;/js/iframe.umd.js\u0026#39;) { add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;*\u0026#39;; #add_header \u0026#39;Access-Control-Allow-Origin\u0026#39; \u0026#39;http://localhost:1313\u0026#39;; } } } 5、部署一个 Telegram 机器人，参考 Official Telegram bot。\n6、升级\ndocker compose -f cusdis.yaml down docker pull djyde/cusdis:latest docker-compose -f cusdis.yaml up -d memos 1、在 mysql 容器创建 n8n 数据库和用户：\ndocker exec -it mysql bash mysql -uroot -p CREATE USER \u0026#39;memos\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;memos@mysql!\u0026#39;; CREATE DATABASE memos; GRANT ALL ON memos.* TO \u0026#39;memos\u0026#39;@\u0026#39;%\u0026#39;; ALTER USER \u0026#39;memos\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;memos@mysql!\u0026#39;; 2、通过 docker-compose 安装，创建 memos.yaml：\nversion: \u0026#34;3.0\u0026#34; services: memos: image: neosmemo/memos:latest container_name: memos environment: - MEMOS_DRIVER=mysql - MEMOS_DSN=memos:memos@mysql!@tcp(mysql)/memos volumes: - ~/.memos/:/var/opt/memos ports: - 5230:5230 networks: - custom networks: custom: external: true 启动\ndocker-compose -f memos.yaml up -d 配置 nginx 配置文件 /etc/nginx/conf.d/memos.conf\nserver { listen 80; listen [::]:80; server_name memos.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name memos.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:5230; } } 升级\ndocker compose -f memos.yaml down docker pull neosmemo/memos:latest docker-compose -f memos.yaml up -d n8n 1、在 mysql 容器创建 n8n 数据库和用户：\ndocker exec -it mysql bash mysql -uroot -p CREATE USER \u0026#39;n8n\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;n8n@mysql!\u0026#39;; CREATE DATABASE n8n; GRANT ALL ON n8n.* TO \u0026#39;n8n\u0026#39;@\u0026#39;%\u0026#39;; ALTER USER \u0026#39;n8n\u0026#39; IDENTIFIED WITH caching_sha2_password BY \u0026#39;n8n@mysql!\u0026#39;; 2、通过 docker-compose 安装，创建 n8n.yaml：\nversion: \u0026#34;3.8\u0026#34; services: n8n: image: n8nio/n8n container_name: n8n restart: always environment: - DB_TYPE=mysqldb - DB_MYSQLDB_HOST=mysql - DB_MYSQLDB_PORT=3306 - DB_MYSQLDB_DATABASE=n8n - DB_MYSQLDB_USER=n8n - DB_MYSQLDB_PASSWORD=n8n@mysql! - TZ=\u0026#34;Asia/Shanghai\u0026#34; - GENERIC_TIMEZONE=\u0026#34;Asia/Shanghai\u0026#34; - WEBHOOK_URL=https://n8n.chensoul.cc/ ports: - 5678:5678 volumes: - ~/.n8n:/home/node/.n8n networks: - custom networks: custom: external: true 3、启动\ndocker-compose -f n8n.yaml up -d 4、配置 nginx 配置文件 /etc/nginx/conf.d/n8n.conf\nserver { listen 80; listen [::]:80; server_name n8n.chensoul.cc; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name n8n.chensoul.cc; ssl_certificate /etc/nginx/ssl/fullchain.cer; ssl_certificate_key /etc/nginx/ssl/chensoul.cc.key; ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://127.0.0.1:5678; chunked_transfer_encoding off; proxy_buffering off; proxy_cache off; access_log /var/log/nginx/n8n.log combined buffer=128k flush=5s; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;Upgrade\u0026#34;; } } 这里面的转发配置不对的话，会导致直接访问 5678 端口正常，但是访问 nginx 的话，workflow 会一直处于执行。\n5、添加 workflow\n参考这篇文章 http://stiles.cc/archives/237/ ，目前我配置了以下 workflows，实现了 github、douban、rss、memos 同步到 Telegram。\nworkflows 参考：\nReorx Pseudoyu raye Zeabur 6、升级\ndocker compose -f n8n.yaml down docker pull n8nio/n8n docker-compose -f n8n.yaml up -d 7、备份\n安装 jq\nyum install epel-release -y yum install jq -y #!/bin/bash DATE=$(date +%Y%m%d_%H%M%S) BACKUP_DIR=\u0026#34;/opt/backup/n8n\u0026#34; mkdir -p $BACKUP_DIR EXPORT_DIR=\u0026#34;workflow-${DATE}\u0026#34; docker exec -u node -it n8n n8n export:workflow --backup --output=./$EXPORT_DIR/ docker cp n8n:/home/node/$EXPORT_DIR ${BACKUP_DIR}/$EXPORT_DIR #docker exec -u node -it n8n n8n export:credentials --all --output=./credentials.json #docker cp n8n:/home/node/credentials.json . cd $BACKUP_DIR/$EXPORT_DIR for file in *; do filename=$(cat \u0026#34;$file\u0026#34; | jq -r \u0026#39;.name\u0026#39;) # 使用-r选项以纯文本形式输出字段值 echo \u0026#34;$filename\u0026#34; mv \u0026#34;$file\u0026#34; \u0026#34;$filename\u0026#34;.json done 数据库备份 #!/bin/bash # 容器名称 CONTAINER_NAME=\u0026#34;mysql\u0026#34; # 备份目录 BACKUP_DIR=\u0026#34;/opt/backup/mysql\u0026#34; # 日期时间 DATE=$(date +%Y%m%d_%H%M%S) # 备份文件名后缀 BACKUP_POSTFIX=\u0026#34;backup_${DATE}\u0026#34; # MySQL连接参数 DB_USER=\u0026#34;root\u0026#34; DB_PASSWORD=\u0026#34;admin@mysql!\u0026#34; # 要备份的数据库列表 DATABASES=(\u0026#34;memos\u0026#34; \u0026#34;n8n\u0026#34; \u0026#34;umami\u0026#34;) # 创建备份目录 mkdir -p $BACKUP_DIR # 遍历数据库列表进行备份 for DB_NAME in \u0026#34;${DATABASES[@]}\u0026#34; do # 备份文件名 BACKUP_FILE=\u0026#34;${DB_NAME}_${BACKUP_POSTFIX}.sql\u0026#34; # 执行备份 docker exec $CONTAINER_NAME mysqldump -u $DB_USER --password=$DB_PASSWORD $DB_NAME \u0026gt; $BACKUP_DIR/$BACKUP_FILE # 检查备份是否成功 if [ $? -eq 0 ]; then echo \u0026#34;数据库 $DB_NAME 备份成功: $BACKUP_FILE\u0026#34; else echo \u0026#34;数据库 $DB_NAME 备份失败\u0026#34; fi done ","permalink":"https://blog.chensoul.cc/posts/2023/01/25/notes-about-deploy-services-in-vps/","summary":"我的 VPS 使用的是 centos 服务器，所以以下操作都是基于 centos 系统。\n服务器设置 更新 yum 源：\nyum update 安装常用软件：\nyum install wget curl git vim -y 设置时区为\n[可选] 设置系统 Swap 交换分区\n因为 vps 服务器的运行内存很小，所以这里先设置下 Swap\n# 1GB RAM with 2GB Swap sudo fallocate -l 2G /swapfile \u0026amp;\u0026amp; \\ sudo dd if=/dev/zero of=/swapfile bs=1024 count=2097152 \u0026amp;\u0026amp; \\ sudo chmod 600 /swapfile \u0026amp;\u0026amp; \\ sudo mkswap /swapfile \u0026amp;\u0026amp; \\ sudo swapon /swapfile \u0026amp;\u0026amp; \\ echo \u0026#34;/swapfile swap swap defaults 0 0\u0026#34; | sudo tee -a /etc/fstab \u0026amp;\u0026amp; \\ sudo swapon --show \u0026amp;\u0026amp; \\ sudo free -h 安装 Nginx 参考 CentOS 7 下 yum 安装和配置 Nginx ，使用 yum 安装：","title":"我的VPS服务部署记录"},{"content":"前言 本篇是对 2023-01-16 到 2023-01-22 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是过年前的最后一周，上了三天班，请了两天假回去准备年货、去亲戚家吃年饭。趁放假之前，继续对博客做了一些定制，也在我的 VPS 上通过 Docker 部署了一些服务。\n定制博客 基于 pseudoyu 的博客和主题定制博客，发现并修复了 bug，还做了一些改进，并在他的 github 提交 issue 和 merge request。\n接着在他博客主页留言，几个来回下来，收获不少。一是解决了我提出的问题，二是给我分享了一个搬瓦工的 the plan 优惠码。这时候去看了下我原来的 vps 刚好还有一天要到期，就立即花了 92 美元（原价是 99 美元）购买了一台 2G 内存托管在香港的服务器。\n缘分就是这么奇妙，如果我不主动和这个博主联系，就不会知道搬瓦工还有这个优惠，就不会帮助我解决了博客定制过程中遇到的疑惑。\n当你想要什的时候，先给出去，你就会收获更。有舍才有得。\n博客个人介绍 我的博客源文件托管在 gihub，在这个仓库可以看到我的一些个人介绍。\nvps 上服务部署 购买了新的 VPS 之后，就将原来的 VPS 导出镜像，然后导入到新的 VPS，最后再安装了以下服务：\nflowerss-bot：一个支持应用内阅读的 Telegram RSS Bot。 n8n：一款开源的自动工作流服务，类似 IFTTT、Zapier，可以互联互通包括 GitHub、Dropbox、Google、NextCLoud、RSS、Slack、Telegram 在内的几十款在线服务。 memos：一个开源且免费的自托管知识库 cusdis：一个界面清爽、注重隐私的轻量级 (~5kb gzip) 评论系统，可以很方便地与 React、Vue 或其他博客系统结合，并且还提供了一个后台来管理所有的评论 umami：一个简单易用、自托管的开源网站访问流量统计分析工具 pgsql uptime-kuma：一个开源免费的监控工具 rsshub：一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源 通过 Docker 部署这些服务非常简单，主要是需要注意的一点是：将这些服务部署到同一个网路，这样各个服务之间可以互相通信。比如：很多服务都需要依赖数据库 postgresql，可以使用 docker-compose 来编排服务。安装部署过程参考：我的 VPS 服务部署记录\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/01/25/weekly_review_3/","summary":"前言 本篇是对 2023-01-16 到 2023-01-22 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是过年前的最后一周，上了三天班，请了两天假回去准备年货、去亲戚家吃年饭。趁放假之前，继续对博客做了一些定制，也在我的 VPS 上通过 Docker 部署了一些服务。\n定制博客 基于 pseudoyu 的博客和主题定制博客，发现并修复了 bug，还做了一些改进，并在他的 github 提交 issue 和 merge request。\n接着在他博客主页留言，几个来回下来，收获不少。一是解决了我提出的问题，二是给我分享了一个搬瓦工的 the plan 优惠码。这时候去看了下我原来的 vps 刚好还有一天要到期，就立即花了 92 美元（原价是 99 美元）购买了一台 2G 内存托管在香港的服务器。\n缘分就是这么奇妙，如果我不主动和这个博主联系，就不会知道搬瓦工还有这个优惠，就不会帮助我解决了博客定制过程中遇到的疑惑。\n当你想要什的时候，先给出去，你就会收获更。有舍才有得。\n博客个人介绍 我的博客源文件托管在 gihub，在这个仓库可以看到我的一些个人介绍。\nvps 上服务部署 购买了新的 VPS 之后，就将原来的 VPS 导出镜像，然后导入到新的 VPS，最后再安装了以下服务：\nflowerss-bot：一个支持应用内阅读的 Telegram RSS Bot。 n8n：一款开源的自动工作流服务，类似 IFTTT、Zapier，可以互联互通包括 GitHub、Dropbox、Google、NextCLoud、RSS、Slack、Telegram 在内的几十款在线服务。 memos：一个开源且免费的自托管知识库 cusdis：一个界面清爽、注重隐私的轻量级 (~5kb gzip) 评论系统，可以很方便地与 React、Vue 或其他博客系统结合，并且还提供了一个后台来管理所有的评论 umami：一个简单易用、自托管的开源网站访问流量统计分析工具 pgsql uptime-kuma：一个开源免费的监控工具 rsshub：一个开源、简单易用、易于扩展的 RSS 生成器，可以给任何奇奇怪怪的内容生成 RSS 订阅源 通过 Docker 部署这些服务非常简单，主要是需要注意的一点是：将这些服务部署到同一个网路，这样各个服务之间可以互相通信。比如：很多服务都需要依赖数据库 postgresql，可以使用 docker-compose 来编排服务。安装部署过程参考：我的 VPS 服务部署记录\n以上。","title":"周报-3｜博客定制、VPS部署服务"},{"content":"前言 本篇是对 2023-01-09 到 2023-01-15 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是年前倒数第二个工作周，工作上主要是完成项目一个版本的测试和发布。这个博客主要是分享一些技术相关笔记和个人的生活记录与思考，所以不会涉及具体的工作内容。\n周三晚上是部门年会，领导提出了 2023 年收入 6.2 亿的目标，比 2022 年收入增长 140%。从公司领导层这乐观的年度规划，看得出来公司的发展属于上升趋势，同时意味着 2023 年又是忙碌和压力巨大的一年。\n工作闲暇之余，看到了一些独立开发者的博客，并受他们博客文章的影响，立即决定重新捣鼓博客。于是，在一腔热情之下，花了三天时间重构了博客，也对博客以后的方向做了一些规划。\n周末是过小年，小年伊始，年味渐浓。周六晚上，堂哥家吃年饭。周日中午，自己家吃年饭。这是新婚后第一次两边的家人一起吃年饭。虽然很早就确定了年饭时间大家都有时间的周末、预定了可以坐下 20 多人的大桌，但还是遗憾人没有到齐。\n博客重构 博客主题 以前的博客主要是纯粹分享技术，很少有自己的思考，基本上就是代码比汉字要多不少。博客没有博主的思考，无法让读者认识、了解博主，并和博主产生深入的链接。这样的博客没有灵魂，就仅仅是一个纯分享的 wiki。\n这次重新开始写博客之后，规划的博客主题是分享技术、记录生活、启发思考。技术上的文章，要有深度；生活的点滴，要有复盘；思考的内容，要有共鸣。\n博客规划 以前博客文章的分类有 java、database、devops、web，在删了一些文章之后，将博客的分类调整为想法（Ideas）、笔记（Notes）两类，后面再根据实际情况添加或者调整分类。\n健康，爱情和使命，按照这个顺序，其它的都不重要\n文章链接 以前的博客链接格式是 posts/:slug，现在调整为 posts/:year/:month/:day/:slug。因为现在博客只有几篇文章，所以暂时不打算做原有链接路径到新路径的重定向工作。\n博客部署 目前有三种方案部署方案：\ngithub pages。国内访问速度受影响。 cloudflare pages。可以使用 cdn 加速。 Self hosted。需要购买云主机和手动运维。 目前，是倾向于使用第二种方案。源码保存到 github 上，github actions 编译和部署静态文件到 cf-pages 分支，通过 cloudflare pages 链接 github 仓库、自动化部署静态文件并设置自定义域名 blog.chensoul.cc。\n发布流程 本地编写 markdown 文件，图片保存到公有云，通过 git 提交到 github 仓库，使用 github actions 通过 n8n 自动发布到多平台，比如：公众号，语雀等。\n待办事项 本周对博客重构，计划完成以下功能：\n在不修改原主题的前提下，通过 git log 记录对主题的改动 添加 Cusdis 评论系统 添加 Umami 统计分析 添加 Kuma 服务监控 添加搜索、回到顶部功能 使用 阿里云对象存储 作为图床 github actions 集成 n8n 域名 dns 解析迁移到 cloudflare 以下是使用 kuma 监控我的 VPS 上的服务。\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/01/15/weekly_review_2/","summary":"前言 本篇是对 2023-01-09 到 2023-01-15 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是年前倒数第二个工作周，工作上主要是完成项目一个版本的测试和发布。这个博客主要是分享一些技术相关笔记和个人的生活记录与思考，所以不会涉及具体的工作内容。\n周三晚上是部门年会，领导提出了 2023 年收入 6.2 亿的目标，比 2022 年收入增长 140%。从公司领导层这乐观的年度规划，看得出来公司的发展属于上升趋势，同时意味着 2023 年又是忙碌和压力巨大的一年。\n工作闲暇之余，看到了一些独立开发者的博客，并受他们博客文章的影响，立即决定重新捣鼓博客。于是，在一腔热情之下，花了三天时间重构了博客，也对博客以后的方向做了一些规划。\n周末是过小年，小年伊始，年味渐浓。周六晚上，堂哥家吃年饭。周日中午，自己家吃年饭。这是新婚后第一次两边的家人一起吃年饭。虽然很早就确定了年饭时间大家都有时间的周末、预定了可以坐下 20 多人的大桌，但还是遗憾人没有到齐。\n博客重构 博客主题 以前的博客主要是纯粹分享技术，很少有自己的思考，基本上就是代码比汉字要多不少。博客没有博主的思考，无法让读者认识、了解博主，并和博主产生深入的链接。这样的博客没有灵魂，就仅仅是一个纯分享的 wiki。\n这次重新开始写博客之后，规划的博客主题是分享技术、记录生活、启发思考。技术上的文章，要有深度；生活的点滴，要有复盘；思考的内容，要有共鸣。\n博客规划 以前博客文章的分类有 java、database、devops、web，在删了一些文章之后，将博客的分类调整为想法（Ideas）、笔记（Notes）两类，后面再根据实际情况添加或者调整分类。\n健康，爱情和使命，按照这个顺序，其它的都不重要\n文章链接 以前的博客链接格式是 posts/:slug，现在调整为 posts/:year/:month/:day/:slug。因为现在博客只有几篇文章，所以暂时不打算做原有链接路径到新路径的重定向工作。\n博客部署 目前有三种方案部署方案：\ngithub pages。国内访问速度受影响。 cloudflare pages。可以使用 cdn 加速。 Self hosted。需要购买云主机和手动运维。 目前，是倾向于使用第二种方案。源码保存到 github 上，github actions 编译和部署静态文件到 cf-pages 分支，通过 cloudflare pages 链接 github 仓库、自动化部署静态文件并设置自定义域名 blog.chensoul.cc。\n发布流程 本地编写 markdown 文件，图片保存到公有云，通过 git 提交到 github 仓库，使用 github actions 通过 n8n 自动发布到多平台，比如：公众号，语雀等。\n待办事项 本周对博客重构，计划完成以下功能：\n在不修改原主题的前提下，通过 git log 记录对主题的改动 添加 Cusdis 评论系统 添加 Umami 统计分析 添加 Kuma 服务监控 添加搜索、回到顶部功能 使用 阿里云对象存储 作为图床 github actions 集成 n8n 域名 dns 解析迁移到 cloudflare 以下是使用 kuma 监控我的 VPS 上的服务。","title":"周报-2｜博客重构"},{"content":"前言 本篇是对 2023-01-02 到 2023-01-08 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是 2023 年的第一周，元旦放了三天假之后，就用投入了工作之中。元旦已过，过年就没多远了，很多公司也开始准备年会了。因为疫情，这个年注定不好过。现在疫情放开，不知道有多少公司能够熬过这个年，进入百废待兴的节奏。\n最近把 rss 阅读器又用起来，每天阅读订阅的未读文章，关注到好几个独立开发者。他们每周都在坚持写博客、分享技术文章。从他们的分享里面，可以看到他们有在做自己的 side projects，也有在开源项目提交代码。看着他们的 github 主页每天都有提交代码，再看看我的 github 主页很久没有提交过代码，顿感惭愧。目前，公司使用的是自建的 gitlab 仓库托管代码，很多代码不方便公开分享，自己夜很少花时间写一些小项目公开分享到 github。干脆就清理一些 github 长期没有维护的仓库，取关了一些好友，更新了 github 主页，最后看了一下粉丝还有 574 人，相对而言也是少的可怜 🥺。\n开始写周报 前段时间，开始尝试在 语雀 上每天写日记，写了几天之后，没有坚持下来。\n总结了一下，没有坚持下来的原因主要是在于每天没有积累足够的分享内容，也就是输入不够；另外，输出之后的反馈不够，这和观众流量有关。作为一个程序员，更喜欢自动化工作的快感和满足感。哟还是更倾向于将博客以 markdown 文件保存到本地或者 git 仓库，然后通过自动化脚本编译部署到多平台。在关注了一些独立开发者的博客之后，更是坚定了这种想法。于是有了这篇写周报的文章，以周为单位记录每一周的所看所思所感。\n关于写博客的流程，电脑上使用 typora 编辑器有着很好的用户体验。如果也能在手机上用 markdown 写文章并提交到 github 上就更完美了。刚开始我使用的是 mweb 这个 app，最近在 ios 上又发现了 metion 这个 app 就可以支持和 git 同步。\n这篇文章就是通过 metion 编写和提交的。图片是本地上传的，图片名称应该是一串随机数，待文章发布之后，需要将图片重命名为有意义的名称，这样方便在图床里查阅和管理。\n关于图片的宽度设置，特别是竖形图，建议将宽度设置为一半。设置方法是：在 md 文件里使用 img 标签引入图片，这样就可以添加一个 sytle=\u0026quot;width: 50%\u0026quot; 来设置宽度。例如，上面图片就是这样设置的。\n\u0026lt;img src=\u0026#34;http://chensoul.oss-cn-hangzhou.aliyuncs.com/images/ios-app-metion.png\u0026#34; alt=\u0026#34;ios-app-metion\u0026#34; style=\u0026#34;width: 50%\u0026#34; /\u0026gt; 内观冥想 这个月参加了一个内观冥想 21 天训练营，每天早上 7 点到 8 点是上课时间，正好也是我上班时间。在听了几天课程并打卡之后，就放弃了。\n21 天课程内容，每天的主题分别是：\n目标 计划 结果 比较 抱怨 后悔 他应该知道自己错了 不可能 目标 今日内观冥想主题是目标\n静静地放空自己，回想自己关注目标的记忆。好像自己曾经设立过很多目标，又好像什么都没有。目标是什么，好像描述不出来，又琢磨不透。\n曾经立下的那些目标算是目标吗？他们可以实现吗？他们实现了吗？为什么没有实现呢？无志之人常立志，有志之人立常志。远的不说，先看看 2022 年实现了哪些目标。读书，是彻底放下了；健身，元旦前减到 130 斤的目标在 “阳康后不要剧烈运动” 的说辞下耽误了；定投，也是终止了；买车，车是消耗品；结婚，实现了。\n算了下，实现了的目标也就是结婚了。少的可怜。为什么会这样呢？大抵是自己不够自律，没有持续的坚持，也没有及时的反思和调整。也就是自我察觉不够吧！或者说没有养成自我察觉的方法和习惯。这也就是为什么要参加 21 天内观训练营的原因吧。\n一个人很难认清自身的局限性，很难扩大自己的认知，多与身边的人交流和学习，通过观他人，再来思自己，应该可以提升自己的察觉意识。\n计划 今日内观冥想主题是计划。\n早上冥想是在地铁，冥想的时候放空自己，感受自己的思绪、情绪和身体的注意力。因为是站着，注意力一会儿在脚上，一会儿在手上，不能完全地放空自己。想必要是完全放松，估计就站不住了吧。\n冥想地过程中，重要的是感受和观察。感受当下的感受，观察自己的观察，任有他们流动和发展。所谓没有绝对的对与错，冥想的过程中，重要的是作为一个旁观者，不要有过多的主观意识。\n结果 今天的内观冥想主题是结果。\n把身体挂在钩子上，静静地观察和感受。一方面感受身体，一方面会思考自己对结果的理解。什么是结果？自己过去一年取得了什么样的结果？为什么没有取得？\n比较 今日内观冥想主题是比较。冥想时，观察自己的感受、情绪、想法，他们可能是任何样子的。不管是怎样的，他们都是正常的，都是他们本来的样子，也就是空性。\n把比较这个念头挂起来，静静地看比较这两个字。然后开始觉察比较这两个字。这个时候，大脑开始在思考比较这个念头是什么。思绪在变化的时候，对对比较这个念头的感受也在变化。无论如何变化，自己都不要干预。当自己有了比较这个念头，自己的感受是失望的。失望自己不如别人，不如过去。失望过后，又不服气，又暗下决心要好好努力。这个过程中，我是我的主人，是我在有着各种各样的感受。如果我能控制自己的情绪，就能控制自己的行为。\n抱怨 今日冥想主题是抱怨。\n生活中有什么抱怨的？抱怨又解决不了问题？问题又不是自己造成的，可能是别人造成的！别人的事情是别人的事情，自己的事情是自己造成。别人的事情，你管不了，你能管理的是你自己的。管好自己的心态情绪和行为，因为抱怨解决不了别人的问题，也解决不了自己的事情。甚至你的抱怨还会给别人带来负能量，给你们带来争吵，给自己带来蛮烦，给自己地能力和情绪带来消耗。与其消耗自己，还不如提升自己。有时候不要局限在自己的思维里，换个角度，提升格局，一切事情都不是事情了。这个世界哪有那么多所谓重要的事情。那些今天你看来很重要的事儿，在十年二十年之后，根本就不值得一提。所以很多时候，要用发展的眼光看问题。一切都会过去，一切都会好起来。当你这样想的时候，在你心里在你眼前，就没有什么烦恼了，也就不会抱怨了。\n好物分享 几个截图软件：\nTinySnap Chrome 截图插件，支持设置背景\nSnipaste 截图\n以上。\n","permalink":"https://blog.chensoul.cc/posts/2023/01/08/weekly_review_1/","summary":"前言 本篇是对 2023-01-02 到 2023-01-08 这周生活的记录与思考。首发在我的个人 博客，你可以移步了解更多或者给我留言。\n这是 2023 年的第一周，元旦放了三天假之后，就用投入了工作之中。元旦已过，过年就没多远了，很多公司也开始准备年会了。因为疫情，这个年注定不好过。现在疫情放开，不知道有多少公司能够熬过这个年，进入百废待兴的节奏。\n最近把 rss 阅读器又用起来，每天阅读订阅的未读文章，关注到好几个独立开发者。他们每周都在坚持写博客、分享技术文章。从他们的分享里面，可以看到他们有在做自己的 side projects，也有在开源项目提交代码。看着他们的 github 主页每天都有提交代码，再看看我的 github 主页很久没有提交过代码，顿感惭愧。目前，公司使用的是自建的 gitlab 仓库托管代码，很多代码不方便公开分享，自己夜很少花时间写一些小项目公开分享到 github。干脆就清理一些 github 长期没有维护的仓库，取关了一些好友，更新了 github 主页，最后看了一下粉丝还有 574 人，相对而言也是少的可怜 🥺。\n开始写周报 前段时间，开始尝试在 语雀 上每天写日记，写了几天之后，没有坚持下来。\n总结了一下，没有坚持下来的原因主要是在于每天没有积累足够的分享内容，也就是输入不够；另外，输出之后的反馈不够，这和观众流量有关。作为一个程序员，更喜欢自动化工作的快感和满足感。哟还是更倾向于将博客以 markdown 文件保存到本地或者 git 仓库，然后通过自动化脚本编译部署到多平台。在关注了一些独立开发者的博客之后，更是坚定了这种想法。于是有了这篇写周报的文章，以周为单位记录每一周的所看所思所感。\n关于写博客的流程，电脑上使用 typora 编辑器有着很好的用户体验。如果也能在手机上用 markdown 写文章并提交到 github 上就更完美了。刚开始我使用的是 mweb 这个 app，最近在 ios 上又发现了 metion 这个 app 就可以支持和 git 同步。\n这篇文章就是通过 metion 编写和提交的。图片是本地上传的，图片名称应该是一串随机数，待文章发布之后，需要将图片重命名为有意义的名称，这样方便在图床里查阅和管理。\n关于图片的宽度设置，特别是竖形图，建议将宽度设置为一半。设置方法是：在 md 文件里使用 img 标签引入图片，这样就可以添加一个 sytle=\u0026quot;width: 50%\u0026quot; 来设置宽度。例如，上面图片就是这样设置的。\n\u0026lt;img src=\u0026#34;http://chensoul.oss-cn-hangzhou.aliyuncs.com/images/ios-app-metion.png\u0026#34; alt=\u0026#34;ios-app-metion\u0026#34; style=\u0026#34;width: 50%\u0026#34; /\u0026gt; 内观冥想 这个月参加了一个内观冥想 21 天训练营，每天早上 7 点到 8 点是上课时间，正好也是我上班时间。在听了几天课程并打卡之后，就放弃了。\n21 天课程内容，每天的主题分别是：\n目标 计划 结果 比较 抱怨 后悔 他应该知道自己错了 不可能 目标 今日内观冥想主题是目标\n静静地放空自己，回想自己关注目标的记忆。好像自己曾经设立过很多目标，又好像什么都没有。目标是什么，好像描述不出来，又琢磨不透。\n曾经立下的那些目标算是目标吗？他们可以实现吗？他们实现了吗？为什么没有实现呢？无志之人常立志，有志之人立常志。远的不说，先看看 2022 年实现了哪些目标。读书，是彻底放下了；健身，元旦前减到 130 斤的目标在 “阳康后不要剧烈运动” 的说辞下耽误了；定投，也是终止了；买车，车是消耗品；结婚，实现了。","title":"周报-1｜开始写周报、冥想"},{"content":"最近编写文档或者写博客，喜欢用 Typora 编辑器通过 Markdown 语法完成编写所有内容。为此，还付费购买了许可证。\n喜欢 Typora 的理由：\n所见即所得的编辑，Markdown 的语法都支持快捷键操作，非常方便\n可以自定义主题的 CSS，包括文章内容就可以粘贴到公众号里\n上传图片，支持图床服务。可以将图片上传到指定的图床，前提是需要先安装一个客户端，这里我使用的是 PicGo。然后，PicGo 支持常见的一些图床服务。\n支持导出\nTypora 图片复制到本地 接下来，聊聊 Typora 的图片上传设置：\n当你插入图片时，你可以分情况对图片进行设置。比如：\n1、对本地位置的图片，可以设置一个上传规则：复制到指定路径或者是当前路径下的一个文件夹、上传图片。\n如果是编写一个文档，我们就设置把图片保存到本地的 assets 文件夹内，这样方便管理。 如果是编写博客，图片一般是集中管理的，我们可以设置复制到一个指定路径 2、类似的，对网络位置的图片也可以使用上面的规则。\n注意，如果将图片保存到本地目录，在文章中引用图片是使用的相对或者绝对路径。如果只是在本地查看，是可以预览图片的。但是，如果将博客上传到服务器，则因为路径问题可能会出现无法预览图片的情况。\n所以，这种情况我们需要做一些修改。通常我会设置图片复制到博客的静态页面目录下面，比如，我现在使用的是 Hugo 构建静态博客，会将图片保存到 static/img 目录下，并且，还需要修改图片的 markdown 引用路径为 /images/image-20220819124422239.png ，以表示绝对路径查找图片，在博客服务器上就是相对根域名目录去 img 路径下查找图片。待 hugo 编译完成上传静态文件到服务器之后，可以通过 https://blog.chensoul.cc/images/ 加上图片名称的方式访问到图片。\n但是，显然，这时候在 Typora 是无法预览图片的，因为在本地查找不到这个绝对路径地址。这时候可以在 Typora 里面设置一个绝对路径，操作方法是，在 显示 -\u0026gt; 图片 -\u0026gt; 图像 -\u0026gt; 设置图片根目录 里进行设置。\n设置完成之后，在当前文件的 md 文件的顶部元数据代码里会多一行代码：\ntitle: \u0026#34;博客中如何使用图床服务\u0026#34; date: 2022-08-19T12:15:54+08:00 slug: using-images-in-blog categories: [日志] tags: [hugo] draft: true typora-root-url: ../../static 这样博客里所有的图片都会保存的博客服务器，如果博客访问量增大，则图片加载时间会变慢。为了解决这个问题，需要将图片进行压缩，并给博客设置 CDN 加速。\nTypora 图片上传到网络 将图片保存到本地，待博客静态页面部署到服务器上之后，可以实现正常预览情况。但是，如果我们想把 md 文件打包上传到一些云笔记，比如：语雀，你会发现上传之后会出现图片无法预览的情况。\n这时候，我们需要将图片上传到网络。首先，我们需要安装 PicGo，然后设置图床服务，这里我使用的是 github 作为图床来保存图片，并使用 jsDelivr 的 CDN 服务进行加速访问。\n如何利用 Github 搭建自己的免费图床？可以参考这篇 文章。这里，记录一下我的操作步骤。\n1、使用博客的托管仓库 的 static/img 目录来保存图片，这样方便图片的管理（比如：压缩、重命名，删除无用图片），如果图床服务不可用了，所有博客图片还有一个备份，只需要修改博客内图片的引用地址。前提是需要将仓库设置为 public。\n2、在 github 设置里面创建一个 Token。以此打开 Settings -\u0026gt; Developer settings -\u0026gt; Personal access tokens，最后点击 generate new token\n3、在 PicGo 里设置 github 图床：\n设定仓库名：chensoul/blog.chensoul.cc\n设定分支：main\n设定 Token：XXXXXXXXXXXXXXXXX\n指定存储路径：static/images/\n设置自定义域名：https://cdn.jsdelivr.net/gh/chensoul/blog.chensoul.cc\n4、需要修改博客文章内引用的图片地址，将 /images/ 替换为 https://cdn.jsdelivr.net/gh/chensoul/blog.chensoul.cc/images/ ，可以使用脚本批量替换：\ngrep -lr --null \u0026#39;](\\/img\\/\u0026#39; | xargs -0 sed -i \u0026#39;\u0026#39; \u0026#39;s/](\\/img\\//](https:\\/\\/cdn.jsdelivr.net\\/gh\\/chensoul\\/blog.chensoul.cc\\/static\\/img\\//g\u0026#39; 参数说明：\ngrep -i, --ignore-case 查找文件时不区分大小写 -l, --files-with-matches 返回文件名 -R, -r, --recursive 递归搜索子目录 sed -i 默认 sed 会打印到标准输出，使用 -i 将直接在文件内编辑替换 s 替换 g 全局替换标志 I 大小写不敏感标志 反过来，查询 https://cdn.jsdelivr.net/gh/chensoul/blog.chensoul.cc/static/images/ 下的图片地址替换 /img\ngrep -lr --null \u0026#39;](https://cdn.jsdelivr.net/gh/chensoul/blog.chensoul.cc/static/images/\u0026#39; | xargs -0 sed -i \u0026#39;\u0026#39; \u0026#39;s/](https:\\/\\/cdn.jsdelivr.net\\/gh\\/chensoul\\/blog.chensoul.cc\\/static\\/img\\//](\\/img\\//g\u0026#39; 另外，在博客编译部署的流程之中，可以定制化一些步骤将博客同步发布到其他系统。当然，在发布之前，也可以先将本地图片的 url 替换成图床地址的 url。等后续实现了，再发布一篇文章。\n如果 github 或者 jsdelivr 服务不稳定，则需要考虑使用其他图床了。\n可以通过这个地址 https://tcp.ping.pe/ 来检测 IP 或者域名是否可以访问\n","permalink":"https://blog.chensoul.cc/posts/2022/08/19/using-images-in-blog/","summary":"最近编写文档或者写博客，喜欢用 Typora 编辑器通过 Markdown 语法完成编写所有内容。为此，还付费购买了许可证。\n喜欢 Typora 的理由：\n所见即所得的编辑，Markdown 的语法都支持快捷键操作，非常方便\n可以自定义主题的 CSS，包括文章内容就可以粘贴到公众号里\n上传图片，支持图床服务。可以将图片上传到指定的图床，前提是需要先安装一个客户端，这里我使用的是 PicGo。然后，PicGo 支持常见的一些图床服务。\n支持导出\nTypora 图片复制到本地 接下来，聊聊 Typora 的图片上传设置：\n当你插入图片时，你可以分情况对图片进行设置。比如：\n1、对本地位置的图片，可以设置一个上传规则：复制到指定路径或者是当前路径下的一个文件夹、上传图片。\n如果是编写一个文档，我们就设置把图片保存到本地的 assets 文件夹内，这样方便管理。 如果是编写博客，图片一般是集中管理的，我们可以设置复制到一个指定路径 2、类似的，对网络位置的图片也可以使用上面的规则。\n注意，如果将图片保存到本地目录，在文章中引用图片是使用的相对或者绝对路径。如果只是在本地查看，是可以预览图片的。但是，如果将博客上传到服务器，则因为路径问题可能会出现无法预览图片的情况。\n所以，这种情况我们需要做一些修改。通常我会设置图片复制到博客的静态页面目录下面，比如，我现在使用的是 Hugo 构建静态博客，会将图片保存到 static/img 目录下，并且，还需要修改图片的 markdown 引用路径为 /images/image-20220819124422239.png ，以表示绝对路径查找图片，在博客服务器上就是相对根域名目录去 img 路径下查找图片。待 hugo 编译完成上传静态文件到服务器之后，可以通过 https://blog.chensoul.cc/images/ 加上图片名称的方式访问到图片。\n但是，显然，这时候在 Typora 是无法预览图片的，因为在本地查找不到这个绝对路径地址。这时候可以在 Typora 里面设置一个绝对路径，操作方法是，在 显示 -\u0026gt; 图片 -\u0026gt; 图像 -\u0026gt; 设置图片根目录 里进行设置。\n设置完成之后，在当前文件的 md 文件的顶部元数据代码里会多一行代码：\ntitle: \u0026#34;博客中如何使用图床服务\u0026#34; date: 2022-08-19T12:15:54+08:00 slug: using-images-in-blog categories: [日志] tags: [hugo] draft: true typora-root-url: ../../static 这样博客里所有的图片都会保存的博客服务器，如果博客访问量增大，则图片加载时间会变慢。为了解决这个问题，需要将图片进行压缩，并给博客设置 CDN 加速。\nTypora 图片上传到网络 将图片保存到本地，待博客静态页面部署到服务器上之后，可以实现正常预览情况。但是，如果我们想把 md 文件打包上传到一些云笔记，比如：语雀，你会发现上传之后会出现图片无法预览的情况。\n这时候，我们需要将图片上传到网络。首先，我们需要安装 PicGo，然后设置图床服务，这里我使用的是 github 作为图床来保存图片，并使用 jsDelivr 的 CDN 服务进行加速访问。\n如何利用 Github 搭建自己的免费图床？可以参考这篇 文章。这里，记录一下我的操作步骤。\n1、使用博客的托管仓库 的 static/img 目录来保存图片，这样方便图片的管理（比如：压缩、重命名，删除无用图片），如果图床服务不可用了，所有博客图片还有一个备份，只需要修改博客内图片的引用地址。前提是需要将仓库设置为 public。\n2、在 github 设置里面创建一个 Token。以此打开 Settings -\u0026gt; Developer settings -\u0026gt; Personal access tokens，最后点击 generate new token","title":"博客中如何使用图床服务"},{"content":"这是我的第一篇文章，作为程序员，首先要做得第一件事情，就是配置好开发环境，因为我使用的是 Mac 开发环境，所以，这篇文章主要是基于 Mac 操作系统，记录开发环境搭建过程。\n系统设置 dotfile 配置 下载 dotfile 文件：\ngit clone git@github.com:chensoul/snippets.git 拷贝到用户目录：\ncd dotfiles sh bootstrap.sh macos 系统设置：\n. .macos 安装软件 安装 brew、nvs sh install.sh 安装 MySQL 安装 MySQL：\n# 搜索可以安装的版本 ➜ brew search mysql # 安装对应的版本 ➜ brew install mysql@5.7 # 写入环境变量 echo \u0026#39;export PATH=\u0026#34;/opt/homebrew/opt/mysql@5.7/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 为了让编译器找到 mysql@5.7 还需要写入 echo \u0026#39;export LDFLAGS=\u0026#34;-L/opt/homebrew/opt/mysql@5.7/lib\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/mysql@5.7/include\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 为了让 pkg-config 找到 mysql@5.7 还需要写入 echo \u0026#39;PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/mysql@5.7/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc MySQL 服务相关：\n# 查看 MySQL 服务状态 ➜ brew services info mysql@5.7 ➜ mysql.server status # 启动 MySQL 服务 ➜ brew services start mysql@5.7 ➜ mysql.server start # 重启 MySQL 服务 ➜ brew services restart mysql@5.7 ➜ mysql.server restart # 停止 MySQL 服务 ➜ brew services stop mysql@5.7 ➜ mysql.server stop 接着初始化 MySQL 设置，主要配置一下 root 密码已经是否远程登录登，根据提示来操作就行了：\nmysql_secure_installation 数据库外连，这是个可选操作 根据自己的实际情况自行决定是否开启（有被攻击的风险）：\nmysql \u0026gt; grant all on *.* to root@\u0026#39;%\u0026#39; identified by \u0026#39;你设置的密码\u0026#39; with grant option; mysql \u0026gt; flush privileges; 安装 Redis # 安装 redis ➜ brew install redis # 查看 redis 服务状态 ➜ brew services info redis # 启动 redis 服务端 ➜ brew services start redis # 启动 redis 客户端 ➜ redis-cli # 编辑默认配置文件 ➜ sudo vim /opt/homebrew/etc/redis.conf 系统备份 1、备份 maven 仓库：\nzip -r m2.zip ~/.m2 2、备份代码空间\nfind ~/workspace -type d -name \u0026#34;target\u0026#34; -exec rm -rf {} + zip -r workspace.zip ~/workspace ","permalink":"https://blog.chensoul.cc/posts/2021/09/09/mac-development-environment-setup/","summary":"这是我的第一篇文章，作为程序员，首先要做得第一件事情，就是配置好开发环境，因为我使用的是 Mac 开发环境，所以，这篇文章主要是基于 Mac 操作系统，记录开发环境搭建过程。\n系统设置 dotfile 配置 下载 dotfile 文件：\ngit clone git@github.com:chensoul/snippets.git 拷贝到用户目录：\ncd dotfiles sh bootstrap.sh macos 系统设置：\n. .macos 安装软件 安装 brew、nvs sh install.sh 安装 MySQL 安装 MySQL：\n# 搜索可以安装的版本 ➜ brew search mysql # 安装对应的版本 ➜ brew install mysql@5.7 # 写入环境变量 echo \u0026#39;export PATH=\u0026#34;/opt/homebrew/opt/mysql@5.7/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 为了让编译器找到 mysql@5.7 还需要写入 echo \u0026#39;export LDFLAGS=\u0026#34;-L/opt/homebrew/opt/mysql@5.7/lib\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc echo \u0026#39;export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/mysql@5.7/include\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc # 为了让 pkg-config 找到 mysql@5.7 还需要写入 echo \u0026#39;PKG_CONFIG_PATH=\u0026#34;/opt/homebrew/opt/mysql@5.7/lib/pkgconfig\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc MySQL 服务相关：\n# 查看 MySQL 服务状态 ➜ brew services info mysql@5.7 ➜ mysql.server status # 启动 MySQL 服务 ➜ brew services start mysql@5.7 ➜ mysql.server start # 重启 MySQL 服务 ➜ brew services restart mysql@5.","title":"Mac开发环境配置"},{"content":"从零开始搭建博客，包括注册域名、购买服务器、部署程序及网站配置和优化。\n域名 搭建一个博客或者网站，需要有一个域名。那什么是域名呢？看看百度百科上的解释：\n域名（英语：Domain Name），又称网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识（有时也指地理位置）。\n由于IP 地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP 地址相互映射，使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP 地址数串。\n简单来说，IP 地址可以标识一台计算机，但是不容易记忆，所以，设计出了域名。而域名就是标识因特网上的一台计算机，由网域名称系统 DNS 来完成域名和 IP 之间的映射。\n如何注册域名？有很多网站提供域名注册服务，比如国内的：\n阿里云 腾讯云 华为云 国外的：\nGoDaddy Namecheap Amazon 注册域名的建议：\n1、建议在正规、出名的网站注册域名，防止网站跑路。我曾经在一个小网站注册了一个域名，使用了几年之后，续期的时候，联系不上对方，导致无法使用该域名，甚至该域名被别人抢注册了。 2、在国内网站注册域名，都需要备案。如果不想备案，请在国外网站注册域名。我的域名 chensoul.cc 就是在亚马逊上注册的。一是不想备案，二是对比了上面几个网站，发现亚马逊上的 com 域名价格相对便宜，所以一次性购买了 5 年。 3、建议优先注册 com 域名，域名尽可能的简短并且方便记忆。 我曾经注册过的域名：\njavachen.com、javachen.space、javachen.xyz huaiu.com 服务器 注册了域名之后，需要一台服务器运行程序。服务器可以是一台物理机，比如你可以使用自己的电脑作为服务器；也可以是一台虚拟的云服务器，比如在云服务提供商购买一台独立的服务器；也可以使用第三方提供的服务器空间，比如 Github 上可以部署静态程序。不管哪种方式，服务器都需要有一个公网 IP，这样才能在因特网上访问你服务器上部署的程序。有了服务器之后，就可以给服务器公网 IP 设置域名解析。\n我的服务器是在搬瓦工购买的，一年 49.99 美元。\n程序 安装 Hugo 在 Mac 下安装 Hugo：\nbrew install hugo 新建站点 hugo new site chensoul.github.io -y yaml 上述命令会生成一个名为 chensoul.github.io 的文件夹，下面对文件夹结构做个说明：\n$ tree chensoul.github.io chensoul.github.io ├── archetypes │ └── default.md ├── config.yaml ├── content ├── data ├── layouts ├── static └── themes 6 directories, 2 files 新建的站点，还没有加入 Git 版本管理，进入到这个目录下，执行一下如下命令，完成 Git Repo 的初始化：\ncd chensoul.github.io git init . 新建站点后，我们开始添加主题。\n添加主题 在 Hugo 的官网上 Hugo Themes 有非常非常多的主题，可以根据自己的喜好选择一个主题。这里，我使用的是 hugo-theme-den 主题。\n使用 git submodule\u0026ndash;helper 下载主题到 theme 目录下：\ngit submodule--helper add https://github.com/shaform/hugo-theme-den themes/den --depth=1 git submodule--helper update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) 以后，当主题有更新时，执行下面命令更新：\ngit submodule update --remote --merge 如果遇到异常，可以参考文章解决。\nfatal: remote error: upload-pack: not our ref fc7223ca00124e8f5b5b354457379071e2fd091b 启动 启动预览：\nhugo server 默认是 1313 端口号，在浏览器中直接访问 http://localhost:1313/ 就可以访问到新建的博客了。\n定制化 站点信息 配置网站的基本信息，将 config.yaml 修改如下：\nbaseURL: https://blog.chensoul.cc/ title: ChenSoul theme: den enableRobotsTXT: true enableEmoji: true hasCJKLanguage: true preserveTaxonomyNames: true rssLimit: 100 page_view_conter: true enableRelated: true # Copyright, appears in the footer # copyright = \u0026#34;\u0026#34; # default: author.name # Pagination # number of entries per page for archives, tags and categories # since we don\u0026#39;t have list view, recommend a large value paginate: 20 paginatePath: \u0026#34;page\u0026#34; # Syntax Hightlight PygmentsCodeFences: true PygmentsUseClasses: true # required for shhighlight shortcode # service plugins disqusShortname: \u0026#34;\u0026#34; # disqus_shortname googleAnalytics: \u0026#34;\u0026#34; # UA-XXXXXXXX-X # language support # en / zh / other... translations present in i18n/ defaultContentLanguage: \u0026#34;zh\u0026#34; # Default language to use defaultContentLanguageInSubdir: true permalinks: posts: /posts/:slug/ categories: /categories/:slug/ tags: /tags/:slug/ pages: /:slug/ author: name: chensoul sitemap: changefreq: weekly priority: 0.5 filename: sitemap.xml params: since: \u0026#34;2020\u0026#34; rssFullContent: true keywords: - devops - programming description: Programming | Devops logoTitle: ChenSoul siteLogoImage: images/fly.png # headerTitle = \u0026#34;chensoul\u0026#34; # default: title headerImage: images/background.webp showAuthorCard: true showMenuLanguages: true autoLoadComments: false paginateOriginalStyle: true # The date format to use; for a list of valid formats, see https://gohugo.io/functions/format/ dateFormatToUse: 2006-01-02 google_verification: \u0026#34;D8XBzUhT4irNUQLKut79HFni0v3Xow4FY-oxUcsUlVk\u0026#34; # Link custom CSS and JS assets # (relative to /static/css and /static/js respectively) customCSS: [] customJS: [] markup: goldmark: renderer: unsafe: true # ------------------------------------- # # ---- Related Articles --------------- # # ------------------------------------- # related: # Only include matches with rank \u0026gt;= threshold. This is a normalized rank between 0 and 100. threshold: 50 # To get stable \u0026#34;See also\u0026#34; sections we, by default, exclude newer related pages. includeNewer: true # Will lower case keywords in both queries and in the indexes. toLower: true indices: - name: categories weight: 200 - name: keywords weight: 150 - name: tags weight: 100 languages: zh: languageCode: zh languageName: 中文 contentDir: content weight: 1 params: description: Devops | Programming menu: main: - name: 思考 weight: 10 identifier: idea url: categories/idea/ social: - name: Telegram weight: 10 identifier: telegram url: https://t.me/chensoul_share - name: Twitter weight: 20 identifier: twitter url: https://twitter.com/chensoul_eth - name: BiliBili weight: 40 identifier: bilibili url: https://space.bilibili.com/699805065/ links: - name: GitHub weight: 10 identifier: github url: https://github.com/chensoul - name: Services weight: 20 identifier: services-status url: https://uptime.chensoul.cc/status/services - name: Analytics weight: 30 identifier: chensoul-analytics url: https://data.chensoul.cc/share/8YKX7FUa/pseudoyu-blog 部署 GitHub Actions 部署 1、首先在 github 里创建一个仓库：chensoul.github.io\n2、将本地文件提交到 github\ncd chensoul.github.io git init . echo \u0026#34;# chensoul.github.io\u0026#34; \u0026gt;\u0026gt; README.md git remote add origin git@github.com:chensoul/chensoul.github.io.git 3、将本地代码推送到仓库\ngit commit -m \u0026#34;first commit\u0026#34; git push -u origin main 4、创建 GitHub Actions 的 workflow\nmkdir -p .github/workflows touch .github/workflows/gh-page.yml gh-page.yml 内容如下：\nname: github pages on: workflow_dispatch: push: branches: - hugo jobs: deploy: runs-on: ubuntu-18.04 timeout-minutes: 3 steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build web run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_branch: gh-pages publish_dir: ./public 上面的工作流是在 gh-pages 分支上触发，当有代码提交时候，会运行 hugo 命令生成静态文件（public 目录），并且将他们推送到 main 分支。\n所以，我们需要基于当前分支创建一个新分支 gh-pages ，并且推送到远程仓库：\ngit branch gh-pages git checkout gh-pages git push origin gh-pages 5、修改代码，推送到仓库，触发工作流\n在本地修改某个文件，提交代码，然后在 github 网站 查看工作流\ngit push origin gh-pages 7、设置自定义域名\n参考管理 GitHub Pages 站点的自定义域，添加一个自定义域名：blog.chensoul.cc：\n或者，在仓库的 static 目录创建一个 CNAME 文件，内容为：blog.chensoul.cc，然后，保存提交，Github Actions 会将该文件推送到 main 分支。\n然后，在亚马逊网站添加 CNAME 记录：\n8、部署到 CloudFlare Pages\n参考 从 GitHub Pages 迁移到 CloudFlare Pages 的体验与踩坑小记\n","permalink":"https://blog.chensoul.cc/posts/2021/09/09/build-personal-blog-from-zero/","summary":"从零开始搭建博客，包括注册域名、购买服务器、部署程序及网站配置和优化。\n域名 搭建一个博客或者网站，需要有一个域名。那什么是域名呢？看看百度百科上的解释：\n域名（英语：Domain Name），又称网域，是由一串用点分隔的名字组成的Internet上某一台计算机或计算机组的名称，用于在数据传输时对计算机的定位标识（有时也指地理位置）。\n由于IP 地址具有不方便记忆并且不能显示地址组织的名称和性质等缺点，人们设计出了域名，并通过网域名称系统（DNS，Domain Name System）来将域名和IP 地址相互映射，使人更方便地访问互联网，而不用去记住能够被机器直接读取的IP 地址数串。\n简单来说，IP 地址可以标识一台计算机，但是不容易记忆，所以，设计出了域名。而域名就是标识因特网上的一台计算机，由网域名称系统 DNS 来完成域名和 IP 之间的映射。\n如何注册域名？有很多网站提供域名注册服务，比如国内的：\n阿里云 腾讯云 华为云 国外的：\nGoDaddy Namecheap Amazon 注册域名的建议：\n1、建议在正规、出名的网站注册域名，防止网站跑路。我曾经在一个小网站注册了一个域名，使用了几年之后，续期的时候，联系不上对方，导致无法使用该域名，甚至该域名被别人抢注册了。 2、在国内网站注册域名，都需要备案。如果不想备案，请在国外网站注册域名。我的域名 chensoul.cc 就是在亚马逊上注册的。一是不想备案，二是对比了上面几个网站，发现亚马逊上的 com 域名价格相对便宜，所以一次性购买了 5 年。 3、建议优先注册 com 域名，域名尽可能的简短并且方便记忆。 我曾经注册过的域名：\njavachen.com、javachen.space、javachen.xyz huaiu.com 服务器 注册了域名之后，需要一台服务器运行程序。服务器可以是一台物理机，比如你可以使用自己的电脑作为服务器；也可以是一台虚拟的云服务器，比如在云服务提供商购买一台独立的服务器；也可以使用第三方提供的服务器空间，比如 Github 上可以部署静态程序。不管哪种方式，服务器都需要有一个公网 IP，这样才能在因特网上访问你服务器上部署的程序。有了服务器之后，就可以给服务器公网 IP 设置域名解析。\n我的服务器是在搬瓦工购买的，一年 49.99 美元。\n程序 安装 Hugo 在 Mac 下安装 Hugo：\nbrew install hugo 新建站点 hugo new site chensoul.github.io -y yaml 上述命令会生成一个名为 chensoul.github.io 的文件夹，下面对文件夹结构做个说明：\n$ tree chensoul.github.io chensoul.github.io ├── archetypes │ └── default.md ├── config.yaml ├── content ├── data ├── layouts ├── static └── themes 6 directories, 2 files 新建的站点，还没有加入 Git 版本管理，进入到这个目录下，执行一下如下命令，完成 Git Repo 的初始化：","title":"从零开始搭建个人博客"}]